<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://tinaxiawuhao.github.io</id>
    <title>tianxia</title>
    <updated>2022-06-11T13:55:41.166Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://tinaxiawuhao.github.io"/>
    <link rel="self" href="https://tinaxiawuhao.github.io/atom.xml"/>
    <subtitle>In me the tiger sniffs the rose</subtitle>
    <logo>https://tinaxiawuhao.github.io/images/avatar.png</logo>
    <icon>https://tinaxiawuhao.github.io/favicon.ico</icon>
    <rights>All rights reserved 2022, tianxia</rights>
    <entry>
        <title type="html"><![CDATA[k8s高可用集群搭建]]></title>
        <id>https://tinaxiawuhao.github.io/post/McgbXRFnx/</id>
        <link href="https://tinaxiawuhao.github.io/post/McgbXRFnx/">
        </link>
        <updated>2022-06-11T13:48:56.000Z</updated>
        <content type="html"><![CDATA[<h2 id="整体环境">整体环境</h2>
<p>3台master节点，3台<a href="https://so.csdn.net/so/search?q=node&amp;spm=1001.2101.3001.7020">node</a>节点。采用了Centos 7，有网络，互相可以ping通。</p>
<p><strong>准备工作查看单集群部署</strong></p>
<h3 id="1安装keepalived-和-haproxy">1.安装keepalived 和 haproxy</h3>
<h4 id="11安装keepalived和-haproxy">1.1安装keepalived和 haproxy</h4>
<pre><code class="language-shell">1yum install keepalived haproxy -y
</code></pre>
<h4 id="12-配置-keepalived">1.2 配置 keepalived</h4>
<pre><code class="language-shell">cat &lt;&lt;EOF &gt; /etc/keepalived/keepalived.conf
! Configuration File for keepalived

global_defs {
   router_id k8s
}

vrrp_script check_haproxy {
    script &quot;/bin/bash -c 'if [[ $(netstat -nlp | grep 16443) ]]; then exit 0; else exit 1; fi'&quot;
    interval 3
    weight -2
    fall 10
    rise 2
}

vrrp_instance VI_1 {
    state MASTER 
    interface ens33 
    virtual_router_id 51
    priority 250
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass ceb1b3ec013d66163d6ab
    }
    virtual_ipaddress {
        192.168.40.19
    }
    track_script {
        check_haproxy
    }

}

EOF
</code></pre>
<pre><code>cat &lt;&lt;EOF &gt; /etc/keepalived/keepalived.conf
! Configuration File for keepalived

global_defs {
   router_id k8s
}

vrrp_script check_haproxy {
    script &quot;/bin/bash -c 'if [[ $(netstat -nlp | grep 16443) ]]; then exit 0; else exit 1; fi'&quot;
    interval 3
    weight -2
    fall 10
    rise 2
}

vrrp_instance VI_1 {
    state BACKUP 
    interface ens33 
    virtual_router_id 51
    priority 150
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass ceb1b3ec013d66163d6ab
    }
    virtual_ipaddress {
        192.168.40.19
    }
    track_script {
        check_haproxy
    }

}

EOF
</code></pre>
<pre><code>cat &lt;&lt;EOF &gt; /etc/keepalived/keepalived.conf
! Configuration File for keepalived

global_defs {
   router_id k8s
}

vrrp_script check_haproxy {
    script &quot;/bin/bash -c 'if [[ $(netstat -nlp | grep 16443) ]]; then exit 0; else exit 1; fi'&quot;
    interval 3
    weight -2
    fall 10
    rise 2
}

vrrp_instance VI_1 {
    state BACKUP 
    interface ens33 
    virtual_router_id 51
    priority 200
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass ceb1b3ec013d66163d6ab
    }
    virtual_ipaddress {
        192.168.40.19
    }
    track_script {
        check_haproxy
    }

}

EOF
</code></pre>
<blockquote>
<ul>
<li>vrrp_script 用于检测 haproxy 是否正常。如果本机的 haproxy 挂掉，即使 keepalived 劫持vip，也无法将流量负载到 apiserver。</li>
<li>我所查阅的网络教程全部为检测进程, 类似 killall -0 haproxy。这种方式用在主机部署上可以，但容器部署时，在 keepalived 容器中无法知道另一个容器 haproxy 的活跃情况，因此我在此处通过检测端口号来判断 haproxy 的健康状况。</li>
<li>weight 可正可负。为正时检测成功 +weight，相当与节点检测失败时本身 priority 不变，但其他检测成功节点 priority 增加。为负时检测失败本身 priority 减少。</li>
<li>另外很多文章中没有强调 nopreempt 参数，意为不可抢占，此时 master 节点失败后，backup 节点也不能接管 vip，因此我将此配置删去</li>
</ul>
</blockquote>
<h4 id="13-配置haproxy">1.3 配置haproxy</h4>
<pre><code class="language-shell">cat &lt;&lt;EOF &gt; /etc/haproxy/haproxy.cfg
#---------------------------------------------------------------------
# Global settings
#---------------------------------------------------------------------
global
    # to have these messages end up in /var/log/haproxy.log you will
    # need to:
    # 1) configure syslog to accept network log events.  This is done
    #    by adding the '-r' option to the SYSLOGD_OPTIONS in
    #    /etc/sysconfig/syslog
    # 2) configure local2 events to go to the /var/log/haproxy.log
    #   file. A line like the following can be added to
    #   /etc/sysconfig/syslog
    #
    #    local2.*                       /var/log/haproxy.log
    #
    log         127.0.0.1 local0
    
    chroot      /var/lib/haproxy
    pidfile     /var/run/haproxy.pid
    maxconn     4000
    user        haproxy
    group       haproxy
    daemon 
       
    # turn on stats unix socket
    stats socket /var/lib/haproxy/stats
#---------------------------------------------------------------------
# common defaults that all the 'listen' and 'backend' sections will
# use if not designated in their block
#---------------------------------------------------------------------  
defaults
    mode                    http
    log                     global
    option                  httplog
    option                  dontlognull
    option http-server-close
    option forwardfor       except 127.0.0.0/8
    option                  redispatch
    retries                 3
    timeout http-request    10s
    timeout queue           1m
    timeout connect         10s
    timeout client          1m
    timeout server          1m
    timeout http-keep-alive 10s
    timeout check           10s
    maxconn                 3000
#---------------------------------------------------------------------
# kubernetes apiserver frontend which proxys to the backends
#--------------------------------------------------------------------- 
frontend kubernetes-apiserver
    mode                 tcp
    bind                 *:16443
    option               tcplog
    default_backend      kubernetes-apiserver    
#---------------------------------------------------------------------
# round robin balancing between the various backends
#---------------------------------------------------------------------
backend kubernetes-apiserver
    mode        tcp
    balance     roundrobin
    server      gk8s-master   192.168.40.20:6443 check
    server      gk8s-master2   192.168.40.21:6443 check
    server      gk8s-master3   192.168.40.22:6443 check
#---------------------------------------------------------------------
# collection haproxy statistics message
#---------------------------------------------------------------------
listen stats
    bind                 *:1080
    stats auth           admin:awesomePassword
    stats refresh        5s
    stats realm          HAProxy\ Statistics
    stats uri            /admin?stats
    
EOF
</code></pre>
<p>设置开机启动</p>
<pre><code>systemctl enable haproxy &amp;&amp; systemctl start haproxy 
systemctl enable keepalived &amp;&amp; systemctl start keepalived 
</code></pre>
<h3 id="2安装kubeadm-kubelet-kubectl">2.安装kubeadm、kubelet、kubectl</h3>
<h4 id="1配置文件修改">1.配置文件修改</h4>
<pre><code class="language-shell">cat &lt;&lt;EOF | sudo tee /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=0
repo_gpgcheck=0
gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF
</code></pre>
<h4 id="2安装启用">2.安装启用</h4>
<pre><code class="language-shell">sudo yum install -y kubelet-1.24.1 kubeadm-1.24.1 kubectl-1.24.1 --disableexcludes=kubernetes 
sudo systemctl enable kubelet &amp;&amp; systemctl start kubelet
</code></pre>
<h4 id="3修改kubelet的配置文件">3.修改kubelet的配置文件</h4>
<p>先查看配置文件位置</p>
<pre><code class="language-shell">systemctl status kubelet
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1653818855680.png" alt="" loading="lazy"></figure>
<pre><code class="language-shell">vi /usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf
</code></pre>
<p>并添加以下内容(使用和docker相同的cgroup-driver)。</p>
<pre><code class="language-shell">Environment=&quot;KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --cgroup-driver=systemd&quot;
</code></pre>
<h4 id="4重启kubelet">4.重启kubelet</h4>
<pre><code class="language-shell">systemctl daemon-reload &amp;&amp; systemctl restart kubelet
</code></pre>
<h3 id="3获取k8s镜像可忽略">3.获取K8S镜像（可忽略）</h3>
<h4 id="1获取镜像列表">1.获取镜像列表</h4>
<p><strong>使用阿里云镜像仓库下载（国内环境该命令可不执行，下步骤kubeadm init --image-repository registry.cn-hangzhou.aliyuncs.com/google_containers已经默认为国内环境）</strong></p>
<p>由于官方镜像地址被墙，所以我们需要首先获取所需镜像以及它们的版本。然后从国内镜像站获取。</p>
<pre><code class="language-bash">kubeadm config images list
</code></pre>
<p>获取镜像列表后可以通过下面的脚本从阿里云获取：</p>
<pre><code class="language-shell">vi /usr/local/k8s/k8s-images.sh
</code></pre>
<blockquote>
<p>下面的镜像应该去除&quot;k8s.gcr.io/&quot;的前缀，版本换成上面获取到的版本</p>
</blockquote>
<pre><code class="language-bash">images=(  
    kube-apiserver:v1.24.1
    kube-controller-manager:v1.24.1
    kube-scheduler:v1.24.1
    kube-proxy:v1.24.1
    pause:3.7
    etcd:3.5.3-0
    coredns:v1.8.6
)

for imageName in ${images[@]} ; do
    docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName
    docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName k8s.gcr.io/$imageName
    docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName
done
</code></pre>
<h4 id="2赋权执行">2.赋权执行</h4>
<pre><code class="language-shell">chmod +x k8s-images.sh &amp;&amp; ./k8s-images.sh
</code></pre>
<p><strong>以上操作在所有机器执行</strong></p>
<h3 id="4初始化环境master操作">4.初始化环境（master操作）</h3>
<h4 id="1安装镜像">1.安装镜像</h4>
<p><strong>采用模板配置文件加载</strong></p>
<pre><code class="language-shell">kubeadm config print init-defaults  &gt; kubeadm-config.yaml
</code></pre>
<pre><code class="language-yaml"># 模板随版本更新
[root@master1 ~]# cat kubeadm-config.yaml 
apiVersion: kubeadm.k8s.io/v1beta2
bootstrapTokens:
- groups:
  - system:bootstrappers:kubeadm:default-node-token
  token: abcdef.0123456789abcdef
  ttl: 24h0m0s
  usages:
  - signing
  - authentication
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 192.168.40.131    # 本机IP
  bindPort: 6443
nodeRegistration:
  criSocket: unix:///var/run/cri-docker.sock  # 此处千万不要忘记修改，如果不修改等于没有替换。(此处已经更改完了)
  #criSocket: unix:///run/containerd/containerd.sock      # 此处千万不要忘记修改，如果不修改等于没有替换。(此处已经更改完了)
  name: master1        # 本主机名
  taints:
  - effect: NoSchedule
    key: node-role.kubernetes.io/master
---
apiServer:
  certSANs:
    - k8s-master-01
    - k8s-master-02
    - k8s-master-03
    - master.k8s.io
    - 192.168.40.19
    - 192.168.40.20
    - 192.168.40.21
    - 192.168.40.22
    - 127.0.0.1
  extraArgs:
    authorization-mode: Node,RBAC
  timeoutForControlPlane: 4m0s
apiVersion: kubeadm.k8s.io/v1beta2
certificatesDir: /etc/kubernetes/pki
clusterName: kubernetes
controlPlaneEndpoint: &quot;192.168.40.19:16443&quot;      # 虚拟IP和haproxy端口
controllerManager: {}
dns:
  type: CoreDNS
etcd:
  local:
    dataDir: /var/lib/etcd
imageRepository: registry.aliyuncs.com/google_containers    # 镜像仓库源要根据自己实际情况修改
kind: ClusterConfiguration
kubernetesVersion: v1.24.1     # k8s版本
networking:
  dnsDomain: cluster.local
  podSubnet: &quot;10.244.0.0/16&quot;   #设置网段，和下面网络插件对应
  serviceSubnet: 10.96.0.0/12
scheduler: {}
 
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
featureGates:
  SupportIPVSProxyMode: true
mode: ipvs
</code></pre>
<h4 id="2查看kubeadm版本修改命令参数">2.查看kubeadm版本，修改命令参数</h4>
<pre><code class="language-shell">kubeadm version
</code></pre>
<p>这个就很简单了，只需要简单的一个命令：</p>
<pre><code class="language-bash">#直接使用已经下载好的镜像
kubeadm init --kubernetes-version=v1.24.1 --control-plane-endpoint &quot;192.168.40.19:16443&quot; --apiserver-advertise-address=192.168.40.20 --pod-network-cidr=10.244.0.0/16 --service-cidr=10.96.0.0/12 --ignore-preflight-errors=Swap  --cri-socket unix:///var/run/cri-docker.sock | tee kubeadm-init.log
#或者采用aliyuncs镜像下载
kubeadm init --kubernetes-version=v1.24.1 --control-plane-endpoint &quot;192.168.40.19:16443&quot; --apiserver-advertise-address=192.168.40.20 --image-repository  registry.aliyuncs.com/google_containers  --service-cidr=10.1.0.0/16 --pod-network-cidr=10.244.0.0/16 --cri-socket unix:///var/run/cri-docker.sock| tee kubeadm-init.log
#使用上面系统生成配置文件加载
kubeadm init --config kubeadm-config.yaml
</code></pre>
<h4 id="3初始化命令说明">3.初始化命令说明：</h4>
<blockquote>
<p>虚拟ip节点端口号</p>
</blockquote>
<pre><code class="language-bash">--control-plane-endpoint
</code></pre>
<blockquote>
<p>指明用 Master 的哪个 interface 与 Cluster 的其他节点通信。如果 Master 有多个 interface，建议明确指定，如果不指定，kubeadm 会自动选择有默认网关的 interface。</p>
</blockquote>
<pre><code class="language-bash">--apiserver-advertise-address
</code></pre>
<blockquote>
<p>指定 Pod 网络的范围。Kubernetes 支持多种网络方案，而且不同网络方案对 --pod-network-cidr 有自己的要求，这里设置为 10.244.0.0/16 是因为我们将使用 flannel 网络方案，必须设置成这个 CIDR。</p>
</blockquote>
<pre><code class="language-bash">--pod-network-cidr
</code></pre>
<blockquote>
<p>Kubenetes默认Registries地址是 k8s.gcr.io，在国内并不能访问 gcr.io，在1.19.3版本中我们可以增加–image-repository参数，默认值是 k8s.gcr.io，将其指定为阿里云镜像地址：registry.aliyuncs.com/google_containers。</p>
</blockquote>
<pre><code class="language-bash">--image-repository
</code></pre>
<blockquote>
<p>关闭版本探测，因为它的默认值是stable-1，会导致从https://dl.k8s.io/release/stable-1.txt下载最新的版本号，我们可以将其指定为固定版本（最新版：v1.24.1）来跳过网络请求。</p>
</blockquote>
<pre><code class="language-bash">--kubernetes-version=v1.24.1 
</code></pre>
<blockquote>
<p>指定启动时使用cri-docker调用docker</p>
</blockquote>
<pre><code class="language-shell">--cri-socket unix:///var/run/cri-docker.sock 
</code></pre>
<h4 id="4错误启动重置">4.错误启动重置</h4>
<pre><code class="language-shell"># 重置 如果有需要
kubeadm reset --cri-socket unix:///var/run/cri-docker.sock
</code></pre>
<h4 id="5初始化成功后为顺利使用kubectl执行以下命令">5.初始化成功后，为顺利使用kubectl，执行以下命令：</h4>
<pre><code class="language-shell">mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
</code></pre>
<h4 id="6添加其他主节点">6.添加其他主节点</h4>
<h5 id="1复制密钥及相关文件">1.复制密钥及相关文件</h5>
<pre><code class="language-shell">ssh root@192.168.40.21 mkdir -p /etc/kubernetes/pki/etcd
scp /etc/kubernetes/admin.conf root@192.168.40.21:/etc/kubernetes 
scp /etc/kubernetes/pki/{ca.*,sa.*,front-proxy-ca.*}root@192.168.40.21:/etc/kubernetes/pki
scp /etc/kubernetes/pki/etcd/ca.* root@192.168.40.21:/etc/kubernetes/pki/etcd
</code></pre>
<pre><code class="language-shell">ssh root@192.168.40.22 mkdir -p /etc/kubernetes/pki/etcd
scp /etc/kubernetes/admin.conf root@192.168.40.22:/etc/kubernetes 
scp /etc/kubernetes/pki/{ca.*,sa.*,front-proxy-ca.*} root@192.168.40.22:/etc/kubernetes/pki
scp /etc/kubernetes/pki/etcd/ca.* root@192.168.40.22:/etc/kubernetes/pki/etcd
</code></pre>
<h5 id="2添加节点">2.添加节点</h5>
<pre><code class="language-shell">kubeadm join 192.168.40.19:16443 --token pqir66.66fy6pexw3kprt2b --discovery-token-ca-cert-hash sha256:cd4c42e956fdc7e0ad48c990484c22cfd43da63cb3f3887bedc481e7f33a0be1 --control-plane --cri-socket unix:///var/run/cri-docker.sock 
</code></pre>
<h4 id="7执行kubectl-get-nodes查看master节点状态">7.执行kubectl get nodes，查看master节点状态：</h4>
<pre><code class="language-shell">kubectl get node
</code></pre>
<h4 id="8通过如下命令查看kubelet状态">8.通过如下命令查看kubelet状态：</h4>
<pre><code class="language-bash">journalctl -xef -u kubelet -n 20
</code></pre>
<p>提示未安装cni 网络插件。</p>
<h3 id="51安装flannel网络插件cni">5.1安装flannel网络插件(CNI)</h3>
<p>master执行以下命令安装flannel即可：</p>
<pre><code class="language-shell">kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
</code></pre>
<p>kube-flannel.yaml文件中的net-conf.json-&gt;Network地址默认为命令中–pod-network-cidr=值相同</p>
<p><strong>输入命令kubectl get pods -n kube-system,等待所有插件为running状态</strong>。</p>
<p><strong>待所有pod status为Running的时候，再次执行kubectl get nodes：</strong></p>
<pre><code class="language-shell">[root@k8s-master ~]# kubectl get node
NAME         STATUS   ROLES    AGE   VERSION
k8s-master   Ready    master   16m   v1.24.1
</code></pre>
<p><strong>如上所示，master状态变为，表明Master节点部署成功！</strong></p>
<h3 id="52安装calico网络功能更完善">5.2安装calico网络(功能更完善)</h3>
<h4 id="1在master上下载配置calico网络的yaml">1.在master上下载配置calico网络的yaml。</h4>
<pre><code class="language-shell">kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml
</code></pre>
<h4 id="2提前下载所需要的镜像">2.提前下载所需要的镜像。</h4>
<pre><code class="language-shell"># 查看此文件用哪些镜像：
[root@k8s-master ~]# grep image calico.yaml
image: docker.io/calico/cni:v3.23.1
image: docker.io/calico/node:v3.23.1
image: docker.io/calico/kube-controllers:v3.23.1
</code></pre>
<h4 id="3安装calico网络">3.安装calico网络。</h4>
<p>在master上执行如下命令：</p>
<pre><code class="language-shell">kubectl apply -f calico.yaml
</code></pre>
<h4 id="5验证结果">5.验证结果。</h4>
<p>再次在master上运行命令 kubectl get nodes查看运行结果：</p>
<pre><code class="language-shell">[root@k8s-master ~]# kubectl get nodes
NAME       STATUS   ROLES                  AGE   VERSION
master01   Ready    control-plane,master   21h   v1.23.4
worker01   Ready    control-plane,master   16h   v1.23.4
worker02   Ready    control-plane,master   16h   v1.23.4
</code></pre>
<h3 id="20部署k8s-node1-k8s-node2-k8s-node3集群">20.部署k8s-node1、k8s-node2、k8s-node3集群</h3>
<p><strong>1、在k8s-node1、k8s-node2、k8s-node3等三台虚拟机中重复执行上面的步骤，安装好docker、kubelet、kubectl、kubeadm。</strong></p>
<h4 id="1node节点加入集群">1.node节点加入集群</h4>
<p>在上面第初始化master节点成功后，输出了下面的kubeadm join命令：</p>
<pre><code class="language-shell">kubeadm join 192.168.40.131:6443 --token zj0u08.ge77y7uv76flqgdk --discovery-token-ca-cert-hash sha256:7cd23cec6afb192b2d34c5c719b378082a6315a9d91a22d91b83066c870d4db5 --cri-socket unix:///var/run/cri-docker.sock 
</code></pre>
<p>该命令就是node加入集群的命令，分别在k8s-node1、k8s-node2上执行该命令加入集群。</p>
<p>如果忘记该命令，可以通过以下命令重新生成：</p>
<pre><code class="language-shell">kubeadm token create --print-join-command
</code></pre>
<h4 id="2在master节点执行下面命令查看集群状态">2.在master节点执行下面命令查看集群状态：</h4>
<pre><code class="language-shell">kubectl get nodes
</code></pre>
<pre><code class="language-shell">[root@k8s-master ~]# kubectl get node
NAME         STATUS   ROLES    AGE     VERSION
k8s-master   Ready    master   24m     v1.24.1
k8s-master2  Ready    master   24m     v1.24.1
k8s-master3  Ready    master   24m     v1.24.1
k8s-node1    Ready    &lt;none&gt;   5m50s   v1.24.1
k8s-node2    Ready    &lt;none&gt;   5m21s   v1.24.1
k8s-node3    Ready    &lt;none&gt;   5m21s   v1.24.1
</code></pre>
<p>如上所示，所有节点都为ready，集群搭建成功。</p>
<h2 id="卸载集群命令">卸载集群命令</h2>
<pre><code class="language-shell">#建议所有服务器都执行
#!/bin/bash
kubeadm reset -f
modprobe -r ipip
lsmod
rm -rf ~/.kube/
rm -rf /etc/kubernetes/
rm -rf /etc/systemd/system/kubelet.service.d
rm -rf /etc/systemd/system/kubelet.service
rm -rf /usr/bin/kube*
rm -rf /etc/cni
rm -rf /opt/cni
rm -rf /var/lib/etcd
rm -rf /var/etcd
yum -y remove kubeadm* kubectl* kubelet* docker*
reboot
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[k8s资源操作]]></title>
        <id>https://tinaxiawuhao.github.io/post/HhauOMn26/</id>
        <link href="https://tinaxiawuhao.github.io/post/HhauOMn26/">
        </link>
        <updated>2022-06-04T03:34:10.000Z</updated>
        <content type="html"><![CDATA[<h3 id="1资源类型">1.资源类型</h3>
<table>
<thead>
<tr>
<th>资源分类</th>
<th>类型</th>
<th>具体资源</th>
</tr>
</thead>
<tbody>
<tr>
<td>名称空间级别</td>
<td>工作负载型资源</td>
<td>Pod(pod:k8s 系统中可以创建和管理的最小单元)</td>
</tr>
<tr>
<td>名称空间级别</td>
<td>工作负载型资源</td>
<td>ReplicaSet(rs:用来确保容器应用的副本数始终保持在用户定义的副本数)</td>
</tr>
<tr>
<td>名称空间级别</td>
<td>工作负载型资源</td>
<td>Deployment(deployment:为 Pod 和 ReplicaSet 提供了一个 声明式定义 (declarative) 方法)</td>
</tr>
<tr>
<td>名称空间级别</td>
<td>工作负载型资源</td>
<td>StatefulSet(sts:为了解决有状态服务的问题)</td>
</tr>
<tr>
<td>名称空间级别</td>
<td>工作负载型资源</td>
<td>DaemonSet(ds:)</td>
</tr>
<tr>
<td>名称空间级别</td>
<td>工作负载型资源</td>
<td>Job(jobs:负责批处理任务，即仅执行一次的任务，它保证批处理任务的一个或多个 Pod)</td>
</tr>
<tr>
<td>名称空间级别</td>
<td>工作负载型资源</td>
<td>CronJob(jobs:管理基于时间的 Job)</td>
</tr>
<tr>
<td>名称空间级别</td>
<td>服务发现及负载均衡型资源</td>
<td>Service(svc:为一组功能相同的Pod提供一个供外界访问的地址)</td>
</tr>
<tr>
<td>名称空间级别</td>
<td>服务发现及负载均衡型资源</td>
<td>Ingress(ing:官方只能实现四层代理，INGRESS 可以实现七层代理)</td>
</tr>
<tr>
<td>名称空间级别</td>
<td>配置与存储型资源</td>
<td>Volume(存储卷)</td>
</tr>
<tr>
<td>名称空间级别</td>
<td>配置与存储型资源</td>
<td>CSI(容器存储接口-- 第三方存储卷)</td>
</tr>
<tr>
<td>名称空间级别</td>
<td>特殊类型的存储卷</td>
<td>ConfigMap(当配置中心来使用的资源类型)</td>
</tr>
<tr>
<td>名称空间级别</td>
<td>特殊类型的存储卷</td>
<td>Secret(保存敏感数据)</td>
</tr>
<tr>
<td>名称空间级别</td>
<td>特殊类型的存储卷</td>
<td>DownwardApi(把外部环境中的信息输出给容器)</td>
</tr>
<tr>
<td>集群级资源</td>
<td>集群级资源</td>
<td>Namespace(命名空间)</td>
</tr>
<tr>
<td>集群级资源</td>
<td>集群级资源</td>
<td>Node(集群节点)</td>
</tr>
<tr>
<td>集群级资源</td>
<td>集群级资源</td>
<td>Role(角色)</td>
</tr>
<tr>
<td>集群级资源</td>
<td>集群级资源</td>
<td>ClusterRole(集群角色)</td>
</tr>
<tr>
<td>集群级资源</td>
<td>集群级资源</td>
<td>RoleBinding(角色绑定)</td>
</tr>
<tr>
<td>集群级资源</td>
<td>集群级资源</td>
<td>ClusterRoleBinging(集群角色绑定)</td>
</tr>
<tr>
<td>元数据型资源</td>
<td>元数据型资源</td>
<td>HPA(根据 Pod的 CPU 利用率扩所容)</td>
</tr>
<tr>
<td>元数据型资源</td>
<td>元数据型资源</td>
<td>PodTemplate(pod资源模板)</td>
</tr>
<tr>
<td>元数据型资源</td>
<td>元数据型资源</td>
<td>LimitRange(资源限制)</td>
</tr>
</tbody>
</table>
<h3 id="2操作指令">2.操作指令</h3>
<table>
<thead>
<tr>
<th style="text-align:center">命令名</th>
<th style="text-align:center">类型</th>
<th style="text-align:center">作用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><code>get</code></td>
<td style="text-align:center">查</td>
<td style="text-align:center">列出某个类型的下属资源</td>
</tr>
<tr>
<td style="text-align:center"><code>describe</code></td>
<td style="text-align:center">查</td>
<td style="text-align:center">查看某个资源的详细信息</td>
</tr>
<tr>
<td style="text-align:center"><code>logs</code></td>
<td style="text-align:center">查</td>
<td style="text-align:center">查看某个 pod 的日志</td>
</tr>
<tr>
<td style="text-align:center"><code>create</code></td>
<td style="text-align:center">增</td>
<td style="text-align:center">新建资源</td>
</tr>
<tr>
<td style="text-align:center"><code>explain</code></td>
<td style="text-align:center">查</td>
<td style="text-align:center">查看某个资源的配置项</td>
</tr>
<tr>
<td style="text-align:center"><code>delete</code></td>
<td style="text-align:center">删</td>
<td style="text-align:center">删除某个资源</td>
</tr>
<tr>
<td style="text-align:center"><code>edit</code></td>
<td style="text-align:center">改</td>
<td style="text-align:center">修改某个资源的配置项</td>
</tr>
<tr>
<td style="text-align:center"><code>apply</code></td>
<td style="text-align:center">改</td>
<td style="text-align:center">应用某个资源的配置项</td>
</tr>
</tbody>
</table>
<h3 id="3查看和进入空间">3.查看和进入空间</h3>
<table>
<thead>
<tr>
<th style="text-align:center">命令名</th>
<th style="text-align:center">作用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">kubectl get pod -n名称空间</td>
<td style="text-align:center">查看对应名称空间内的pod</td>
</tr>
<tr>
<td style="text-align:center">kubectl exec -it pod名字 -n名称空间 bash</td>
<td style="text-align:center">进入对应名称空间的pod内</td>
</tr>
<tr>
<td style="text-align:center">kubectl get nodes -o wide</td>
<td style="text-align:center">获取节点和服务版本信息，并查看附加信息</td>
</tr>
<tr>
<td style="text-align:center">kubectl get pod</td>
<td style="text-align:center">获取pod信息，默认是default名称空间</td>
</tr>
<tr>
<td style="text-align:center">kubectl get pod -o wide</td>
<td style="text-align:center">获取pod信息，默认是default名称空间，并查看附加信息</td>
</tr>
<tr>
<td style="text-align:center">kubectl get pod -n kube-system</td>
<td style="text-align:center">获取指定名称空间的pod</td>
</tr>
<tr>
<td style="text-align:center">kubectl get pod -n kube-system podName</td>
<td style="text-align:center">获取指定名称空间中的指定pod</td>
</tr>
<tr>
<td style="text-align:center">kubectl get pod -A</td>
<td style="text-align:center">获取所有名称空间的pod</td>
</tr>
<tr>
<td style="text-align:center">kubectl get pods -o yaml<br />kubectl get pods -o json</td>
<td style="text-align:center">查看pod的详细信息，以yaml格式或json格式显示</td>
</tr>
<tr>
<td style="text-align:center">kubectl get pod -A --show-labels</td>
<td style="text-align:center">查看pod的标签信息</td>
</tr>
<tr>
<td style="text-align:center">kubectl get pod -A --selector=“k8s-app=kube-dns”</td>
<td style="text-align:center">根据Selector（label query）来查询pod</td>
</tr>
<tr>
<td style="text-align:center">kubectl exec podName env</td>
<td style="text-align:center">查看运行pod的环境变量</td>
</tr>
<tr>
<td style="text-align:center">kubectl logs -f --tail 500 -n kube-system kube-apiserver-k8s-master</td>
<td style="text-align:center">查看指定pod的日志</td>
</tr>
<tr>
<td style="text-align:center">kubectl get svc -A</td>
<td style="text-align:center">查看所有名称空间的service信息</td>
</tr>
<tr>
<td style="text-align:center">kubectl get svc -n kube-system</td>
<td style="text-align:center">查看指定名称空间的service信息</td>
</tr>
<tr>
<td style="text-align:center">kubectl get cs</td>
<td style="text-align:center">查看componentstatuses信息</td>
</tr>
<tr>
<td style="text-align:center">kubectl get cm -A</td>
<td style="text-align:center">查看所有configmaps信息</td>
</tr>
<tr>
<td style="text-align:center">kubectl get sa -A</td>
<td style="text-align:center">查看所有serviceaccounts信息</td>
</tr>
<tr>
<td style="text-align:center">kubectl get ds -A</td>
<td style="text-align:center">查看所有daemonsets信息</td>
</tr>
<tr>
<td style="text-align:center">kubectl get deploy -A</td>
<td style="text-align:center">查看所有deployments信息</td>
</tr>
<tr>
<td style="text-align:center">kubectl get rs -A</td>
<td style="text-align:center">查看所有replicasets信息</td>
</tr>
<tr>
<td style="text-align:center">kubectl get sts -A</td>
<td style="text-align:center">查看所有statefulsets信息</td>
</tr>
<tr>
<td style="text-align:center">kubectl get jobs -A</td>
<td style="text-align:center">查看所有jobs信息</td>
</tr>
<tr>
<td style="text-align:center">kubectl get ing -A</td>
<td style="text-align:center">查看所有ingresses信息</td>
</tr>
<tr>
<td style="text-align:center">kubectl get ns</td>
<td style="text-align:center">查看有哪些名称空间</td>
</tr>
<tr>
<td style="text-align:center">kubectl describe pod podName<br/>kubectl describe pod -n kube-system kube-apiserver-k8s-master</td>
<td style="text-align:center">查看pod的描述信息</td>
</tr>
<tr>
<td style="text-align:center">kubectl describe deploy -n kube-system coredns</td>
<td style="text-align:center">查看指定名称空间中指定deploy的描述信息</td>
</tr>
<tr>
<td style="text-align:center">kubectl top node<br/>kubectl top pod</td>
<td style="text-align:center">查看node或pod的资源使用情况<br/>（需要heapster 或metrics-server支持）</td>
</tr>
<tr>
<td style="text-align:center">kubectl cluster-info <br /> kubectl cluster-info dump</td>
<td style="text-align:center">查看集群信息</td>
</tr>
<tr>
<td style="text-align:center">kubectl -s https://172.16.1.110:6443 get componentstatuses</td>
<td style="text-align:center">查看各组件信息【172.16.1.110为master机器】</td>
</tr>
</tbody>
</table>
<h3 id="4进入pod启动的容器">4.进入pod启动的容器</h3>
<table>
<thead>
<tr>
<th style="text-align:center">命令名</th>
<th style="text-align:center">作用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">kubectl exec -it podName -n nsName /bin/sh</td>
<td style="text-align:center">进入容器</td>
</tr>
<tr>
<td style="text-align:center">kubectl exec -it podName -n nsName /bin/bash</td>
<td style="text-align:center">进入容器</td>
</tr>
</tbody>
</table>
<h3 id="5添加label值">5.添加label值</h3>
<table>
<thead>
<tr>
<th style="text-align:center">命令名</th>
<th style="text-align:center">作用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">kubectl label nodes k8s-node01 zone=north</td>
<td style="text-align:center">为指定节点添加标签</td>
</tr>
<tr>
<td style="text-align:center">kubectl label nodes k8s-node01 zone</td>
<td style="text-align:center">为指定节点删除标签</td>
</tr>
<tr>
<td style="text-align:center">kubectl label pod podName -n nsName role-name=test</td>
<td style="text-align:center">为指定pod添加标签</td>
</tr>
<tr>
<td style="text-align:center">kubectl label pod podName -n nsName role-name=dev --overwrite</td>
<td style="text-align:center">修改lable标签值</td>
</tr>
<tr>
<td style="text-align:center">kubectl label pod podName -n nsName role-name</td>
<td style="text-align:center">删除lable标签</td>
</tr>
</tbody>
</table>
<h3 id="6滚动升级">6.滚动升级</h3>
<table>
<thead>
<tr>
<th style="text-align:center">命令名</th>
<th style="text-align:center">作用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">kubectl apply -f myapp-deployment-v2.yaml</td>
<td style="text-align:center">通过配置文件滚动升级</td>
</tr>
<tr>
<td style="text-align:center">kubectl set image deploy/myapp-deployment myapp=“registry.cn-beijing.aliyuncs.com/google_registry/myapp:v3”</td>
<td style="text-align:center">通过命令滚动升级</td>
</tr>
<tr>
<td style="text-align:center">kubectl rollout undo deploy/myapp-deployment <br />kubectl rollout undo deploy myapp-deployment</td>
<td style="text-align:center">pod回滚到前一个版本</td>
</tr>
<tr>
<td style="text-align:center">kubectl rollout undo deploy/myapp-deployment --to-revision=2</td>
<td style="text-align:center">回滚到指定历史版本</td>
</tr>
</tbody>
</table>
<h3 id="7动态伸缩">7.动态伸缩</h3>
<table>
<thead>
<tr>
<th style="text-align:center">命令名</th>
<th style="text-align:center">作用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">kubectl scale deploy myapp-deployment --replicas=5</td>
<td style="text-align:center">动态伸缩</td>
</tr>
<tr>
<td style="text-align:center">kubectl scale --replicas=8 -f myapp-deployment-v2.yaml</td>
<td style="text-align:center">动态伸缩（根据yaml文件）</td>
</tr>
</tbody>
</table>
<h3 id="8操作类命令">8.操作类命令</h3>
<table>
<thead>
<tr>
<th style="text-align:center">命令名</th>
<th style="text-align:center">作用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">kubectl create -f xxx.yaml</td>
<td style="text-align:center">创建资源</td>
</tr>
<tr>
<td style="text-align:center">kubectl apply -f xxx.yaml</td>
<td style="text-align:center">应用资源</td>
</tr>
<tr>
<td style="text-align:center">kubectl apply -f</td>
<td style="text-align:center">应用资源，该目录下的所有 .yaml, .yml, 或 .json 文件都会被使用</td>
</tr>
<tr>
<td style="text-align:center">kubectl create namespace test</td>
<td style="text-align:center">创建test名称空间</td>
</tr>
<tr>
<td style="text-align:center">kubectl delete -f xxx.yaml<br/>kubectl delete -f</td>
<td style="text-align:center">删除资源</td>
</tr>
<tr>
<td style="text-align:center">kubectl delete pod podName</td>
<td style="text-align:center">删除指定的pod</td>
</tr>
<tr>
<td style="text-align:center">kubectl delete pod -n test podName</td>
<td style="text-align:center">删除指定名称空间的指定pod</td>
</tr>
<tr>
<td style="text-align:center">kubectl delete svc svcName<br/>kubectl delete deploy deployName<br/>kubectl delete ns nsName</td>
<td style="text-align:center">删除其他资源</td>
</tr>
<tr>
<td style="text-align:center">kubectl delete pod podName -n nsName --grace-period=0 --force<br/>kubectl delete pod podName -n nsName --grace-period=1<br/>kubectl delete pod podName -n nsName --now</td>
<td style="text-align:center">强制删除</td>
</tr>
<tr>
<td style="text-align:center">kubectl edit pod podName</td>
<td style="text-align:center">编辑资源</td>
</tr>
</tbody>
</table>
<h3 id="9状态">9.状态</h3>
<table>
<thead>
<tr>
<th style="text-align:center">状态名</th>
<th style="text-align:center">含义</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><code>Running</code></td>
<td style="text-align:center">运行中</td>
</tr>
<tr>
<td style="text-align:center"><code>Error</code></td>
<td style="text-align:center">异常，无法提供服务</td>
</tr>
<tr>
<td style="text-align:center"><code>Pending</code></td>
<td style="text-align:center">准备中，暂时无法提供服务</td>
</tr>
<tr>
<td style="text-align:center"><code>Terminaling</code></td>
<td style="text-align:center">结束中，即将被移除</td>
</tr>
<tr>
<td style="text-align:center"><code>Unknown</code></td>
<td style="text-align:center">未知状态，多发生于节点宕机</td>
</tr>
<tr>
<td style="text-align:center"><code>PullImageBackOff</code></td>
<td style="text-align:center">镜像拉取失败</td>
</tr>
</tbody>
</table>
<p>必须存在的属性</p>
<table>
<thead>
<tr>
<th>参数名</th>
<th>字段类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>version</td>
<td>String</td>
<td>K8S API版本, 可以使用kubectl api-version命令查询</td>
</tr>
<tr>
<td>kind</td>
<td>String</td>
<td>指的是yaml文件定义的资源类型和角色, 比如Pod</td>
</tr>
<tr>
<td>metadata</td>
<td>Object</td>
<td>元数据对象, 固定值就写metadata</td>
</tr>
<tr>
<td>metadata.name</td>
<td>String</td>
<td>元数据对象的名字, 比如命名Pod的名字</td>
</tr>
<tr>
<td>metadata.namespace</td>
<td>String</td>
<td>元数据对象的命名空间</td>
</tr>
<tr>
<td>Spec</td>
<td>Object</td>
<td>详细定义对象, 固定值就写Spec</td>
</tr>
<tr>
<td>spec.containers[]</td>
<td>list</td>
<td>Spec对象的容器列表定义, 是个列表</td>
</tr>
<tr>
<td>spec.containers[].name</td>
<td>String</td>
<td>容器的名字</td>
</tr>
<tr>
<td>spec.containers[].image</td>
<td>String</td>
<td>使用到的镜像名称</td>
</tr>
</tbody>
</table>
<p><strong>主要对象</strong></p>
<pre><code class="language-yaml">apiVersion: v1                  #必选，版本号，例如v1，可以用 kubectl api-versions 查询到
kind: Pod                       #必选，指yaml文件定义的k8s 资源类型或角色，比如：Pod
metadata:                       #必选，元数据对象
  name: string                  #必选，元数据对象的名字，自己定义，比如命名Pod的名字
  namespace: string             #必选，元数据对象的名称空间，默认为&quot;default&quot;
  labels:                       #自定义标签
    key1: value1      　        #自定义标签键值对1
    key2: value2      　        #自定义标签键值对2
  annotations:                  #自定义注解
    key1: value1      　        #自定义注解键值对1
    key2: value2      　        #自定义注解键值对2
spec:                           #必选，对象【如pod】的详细定义
  containers:                   #必选，spec对象的容器信息
  - name: string                #必选，容器名称
    image: string               #必选，要用到的镜像名称
    imagePullPolicy: [Always|Never|IfNotPresent]  #获取镜像的策略；(1)Always：意思是每次都尝试重新拉取镜像；(2)Never：表示仅使用本地镜像，即使本地没有镜像也不拉取；(3) IfNotPresent：如果本地有镜像就使用本地镜像，没有就拉取远程镜像。默认：Always
    command: [string]           #指定容器启动命令，由于是数组因此可以指定多个。不指定则使用镜像打包时指定的启动命令。
    args: [string]              #指定容器启动命令参数，由于是数组因此可以指定多个
    workingDir: string          #指定容器的工作目录
    volumeMounts:               #指定容器内部的存储卷配置
    - name: string              #指定可以被容器挂载的存储卷的名称。跟下面volume字段的name值相同表示使用这个存储卷
      mountPath: string         #指定可以被容器挂载的存储卷的路径，应少于512字符
      readOnly: boolean         #设置存储卷路径的读写模式，true或者false，默认为读写模式false
    ports:                      #需要暴露的端口号列表
    - name: string              #端口的名称
      containerPort: int        #容器监听的端口号
      #除非绝对必要，否则不要为 Pod 指定 hostPort。将 Pod 绑定到hostPort时，它会限制 Pod 可以调度的位置数
      #DaemonSet 中的 Pod 可以使用 hostPort，从而可以通过节点 IP 访问到 Pod；因为DaemonSet模式下Pod不会被调度到其他节点。
      #一般情况下 containerPort与hostPort值相同
      hostPort: int     #可以通过宿主机+hostPort的方式访问该Pod。例如：pod在/调度到了k8s-node02【172.16.1.112】，hostPort为8090，那么该Pod可以通过172.16.1.112:8090方式进行访问。
      protocol: string          #端口协议，支持TCP和UDP，默认TCP
    env:                        #容器运行前需设置的环境变量列表
    - name: string              #环境变量名称
      value: string             #环境变量的值
    resources:                  #资源限制和资源请求的设置（设置容器的资源上线）
      limits:                   #容器运行时资源使用的上线
        cpu: string             #CPU限制，单位为core数，允许浮点数，如0.1等价于100m，0.5等价于500m；因此如果小于1那么优先选择如100m的形式，精度为1m。这个数字用作 docker run 命令中的 --cpu-quota 参数。
        memory: string          #内存限制，单位：E,P,T,G,M,K；或者Ei,Pi,Ti,Gi,Mi,Ki；或者字节数。将用于docker run --memory参数
      requests:                 #容器启动和调度时的限制设定
        cpu: string             #CPU请求，容器启动时初始化可用数量，单位为core数，允许浮点数，如0.1等价于100m，0.5等价于500m；因此如果小于1那么优先选择如100m的形式，精度为1m。这个数字用作 docker run 命令中的 --cpu-shares 参数。
        memory: string          #内存请求,容器启动的初始化可用数量。单位：E,P,T,G,M,K；或者Ei,Pi,Ti,Gi,Mi,Ki；或者字节数
    # 参见官网地址：https://kubernetes.io/zh/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
    livenessProbe:      　　    #对Pod内各容器健康检查的设置，当探测无响应几次后将自动重启该容器，检查方法有exec、httpGet和tcpSocket，对一个容器【只需设置其中一种方法即可】
      exec:       　　　　　　  #对Pod内容器健康检查方式设置为exec方式
        command: [string]       #exec方式需要制定的命令或脚本
      httpGet:        　　　　  #对Pod内容器健康检查方法设置为HttpGet，需要制定Path、port
        path: string            #访问 HTTP 服务的路径
        port: number            #访问容器的端口号或者端口名。如果数字必须在 1 ~ 65535 之间。
        host: string            #当没有定义 &quot;host&quot; 时，使用 &quot;PodIP&quot;
        scheme: string          #当没有定义 &quot;scheme&quot; 时，使用 &quot;HTTP&quot;，scheme 只允许 &quot;HTTP&quot; 和 &quot;HTTPS&quot;
        HttpHeaders:            #请求中自定义的 HTTP 头。HTTP 头字段允许重复。
        - name: string
          value: string
      tcpSocket:      　　　　  #对Pod内容器健康检查方式设置为tcpSocket方式
         port: number
      initialDelaySeconds: 5    #容器启动完成后，kubelet在执行第一次探测前应该等待 5 秒。默认是 0 秒，最小值是 0。
      periodSeconds: 60    　　 #指定 kubelet 每隔 60 秒执行一次存活探测。默认是 10 秒。最小值是 1
      timeoutSeconds: 3    　　 #对容器健康检查探测等待响应的超时时间为 3 秒，默认1秒
      successThreshold: 1       #检测到有1次成功则认为服务是`就绪`
      failureThreshold: 5       #检测到有5次失败则认为服务是`未就绪`。默认值是 3，最小值是 1。
    restartPolicy: [Always|Never|OnFailure] #Pod的重启策略，默认Always。Always表示一旦不管以何种方式终止运行，kubelet都将重启；OnFailure表示只有Pod以非0退出码退出才重启；Nerver表示不再重启该Pod
    nodeSelector:           　　#定义Node的label过滤标签，以key：value的格式指定。节点选择，先给主机打标签kubectl label nodes kube-node01 key1=value1 
      key1: value1
    imagePullSecrets:     　　  #Pull镜像时使用的secret名称，以name：secretKeyName格式指定
    - name: string
    hostNetwork: false      　　#是否使用主机网络模式，默认为false。如果设置为true，表示使用宿主机网络，不使用docker网桥
  # volumes 和 containers 是同层级 ******************************
  # 参见官网地址：https://kubernetes.io/zh/docs/concepts/storage/volumes/
  volumes:        　　　　　　#定义了paues容器关联的宿主机或分布式文件系统存储卷列表 （volumes类型有很多种，选其中一种即可）
  - name: string     　　 　　#共享存储卷名称。
    emptyDir: {}      　　    #类型为emtyDir的存储卷，与Pod同生命周期的一个临时目录。当Pod因为某些原因被从节点上删除时，emptyDir卷中的数据也会永久删除。
    hostPath: string      　　#类型为hostPath的存储卷，表示挂载Pod所在宿主机的文件或目录
      path: string      　　  #在宿主机上文件或目录的路径
      type: [|DirectoryOrCreate|Directory|FileOrCreate|File] #空字符串（默认）用于向后兼容，这意味着在安装 hostPath 卷之前不会执行任何检查。DirectoryOrCreate：如果给定目录不存在则创建，权限设置为 0755，具有与 Kubelet 相同的组和所有权。Directory：给定目录必须存在。FileOrCreate：如果给定文件不存在，则创建空文件，权限设置为 0644，具有与 Kubelet 相同的组和所有权。File：给定文件必须存在。
    secret:       　　　　　  #类型为secret的存储卷，挂载集群预定义的secre对象到容器内部。Secret 是一种包含少量敏感信息例如密码、token 或 key 的对象。放在一个 secret 对象中可以更好地控制它的用途，并降低意外暴露的风险。
      secretName: string      #secret 对象的名字
      items:                  #可选，修改key 的目标路径
      - key: username         #username secret存储在/etc/foo/my-group/my-username 文件中而不是 /etc/foo/username 中。【此时存在spec.containers[].volumeMounts[].mountPath为/etc/foo】
        path: my-group/my-username
    configMap:      　　　　  #类型为configMap的存储卷，挂载预定义的configMap对象到容器内部。ConfigMap 允许您将配置文件与镜像文件分离，以使容器化的应用程序具有可移植性。
      name: string             #提供你想要挂载的 ConfigMap 的名字
</code></pre>
<blockquote>
<p>kubectl explain pod命令可以查看资源的模板</p>
<p>kubectl explain pod.apiVersion 查看详细字段</p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[k8s-ingress安装使用]]></title>
        <id>https://tinaxiawuhao.github.io/post/TX9ZIPxbq/</id>
        <link href="https://tinaxiawuhao.github.io/post/TX9ZIPxbq/">
        </link>
        <updated>2022-06-03T02:00:45.000Z</updated>
        <content type="html"><![CDATA[<h2 id="1nginx-ingress安装">1.Nginx ingress安装</h2>
<p>首先需要安装Nginx Ingress Controller控制器，控制器安装方式包含两种：DaemonSets和Deployments。</p>
<ul>
<li>DaemonSets通过hostPort的方式暴露80和443端口，可通过Node的调度由专门的节点实现部署</li>
<li>Deployments则通过NodePort的方式实现控制器端口的暴露，借助外部负载均衡实现高可用负载均衡</li>
</ul>
<p>除此之外，还需要部署Namespace，ServiceAccount，RBAC，Secrets，Custom Resource Definitions等资源，如下开始部署。</p>
<h3 id="11-基础依赖环境准备">1.1 基础依赖环境准备</h3>
<p><strong>1、github中下载源码包,安装部署文件在kubernetes-ingress/deployments/目录下</strong></p>
<pre><code class="language-shell">git clone https://github.com/nginxinc/kubernetes-ingress.git
</code></pre>
<pre><code class="language-js">kubernetes-ingress/deployments/
├── common
│   ├── custom-resource-definitions.yaml  自定义资源
│   ├── default-server-secret.yaml        Secrets
│   ├── nginx-config.yaml
│   └── ns-and-sa.yaml                    Namspace+ServiceAccount
├── daemon-set
│   ├── nginx-ingress.yaml                DaemonSets控制器
│   └── nginx-plus-ingress.yaml
├── deployment
│   ├── nginx-ingress.yaml                Deployments控制器
│   └── nginx-plus-ingress.yaml
├── helm-chart                            Helm安装包
│   ├── chart-icon.png
│   ├── Chart.yaml
│   ├── README.md
│   ├── templates
│   │   ├── controller-configmap.yaml
│   │   ├── controller-custom-resources.yaml
│   │   ├── controller-daemonset.yaml
│   │   ├── controller-deployment.yaml
│   │   ├── controller-leader-election-configmap.yaml
│   │   ├── controller-secret.yaml
│   │   ├── controller-serviceaccount.yaml
│   │   ├── controller-service.yaml
│   │   ├── controller-wildcard-secret.yaml
│   │   ├── _helpers.tpl
│   │   ├── NOTES.txt
│   │   └── rbac.yaml
│   ├── values-icp.yaml
│   ├── values-plus.yaml
│   └── values.yaml
├── rbac                                RBAC认证授权
│   └── rbac.yaml
├── README.md
└── service                            Service定义
    ├── loadbalancer-aws-elb.yaml
    ├── loadbalancer.yaml              DaemonSets暴露服务方式
    └── nodeport.yaml                  Deployments暴露服务方式
</code></pre>
<p>**2、创建Namespace和ServiceAccount **</p>
<pre><code class="language-yaml">cat common/ns-and-sa.yaml

apiVersion: v1
kind: Namespace
metadata:
  name: nginx-ingress 
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: nginx-ingress 
  namespace: nginx-ingress
</code></pre>
<pre><code class="language-shell">kubectl apply -f common/ns-and-sa.yaml
</code></pre>
<p><strong>3、创建Secrets自签名证书</strong></p>
<pre><code>kubectl apply -f common/default-server-secret.yaml
</code></pre>
<pre><code class="language-yaml">apiVersion: v1
kind: Secret
metadata:
  name: default-server-secret
  namespace: nginx-ingress
type: Opaque
data:
  tls.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN2akNDQWFZQ0NRREFPRjl0THNhWFhEQU5CZ2txaGtpRzl3MEJBUXNGQURBaE1SOHdIUVlEVlFRRERCWk8KUjBsT1dFbHVaM0psYzNORGIyNTBjbTlzYkdWeU1CNFhEVEU0TURreE1qRTRNRE16TlZvWERUSXpNRGt4TVRFNApNRE16TlZvd0lURWZNQjBHQTFVRUF3d1dUa2RKVGxoSmJtZHlaWE56UTI5dWRISnZiR3hsY2pDQ0FTSXdEUVlKCktvWklodmNOQVFFQkJRQURnZ0VQQURDQ0FRb0NnZ0VCQUwvN2hIUEtFWGRMdjNyaUM3QlBrMTNpWkt5eTlyQ08KR2xZUXYyK2EzUDF0azIrS3YwVGF5aGRCbDRrcnNUcTZzZm8vWUk1Y2Vhbkw4WGM3U1pyQkVRYm9EN2REbWs1Qgo4eDZLS2xHWU5IWlg0Rm5UZ0VPaStlM2ptTFFxRlBSY1kzVnNPazFFeUZBL0JnWlJVbkNHZUtGeERSN0tQdGhyCmtqSXVuektURXUyaDU4Tlp0S21ScUJHdDEwcTNRYzhZT3ExM2FnbmovUWRjc0ZYYTJnMjB1K1lYZDdoZ3krZksKWk4vVUkxQUQ0YzZyM1lma1ZWUmVHd1lxQVp1WXN2V0RKbW1GNWRwdEMzN011cDBPRUxVTExSakZJOTZXNXIwSAo1TmdPc25NWFJNV1hYVlpiNWRxT3R0SmRtS3FhZ25TZ1JQQVpQN2MwQjFQU2FqYzZjNGZRVXpNQ0F3RUFBVEFOCkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQWpLb2tRdGRPcEsrTzhibWVPc3lySmdJSXJycVFVY2ZOUitjb0hZVUoKdGhrYnhITFMzR3VBTWI5dm15VExPY2xxeC9aYzJPblEwMEJCLzlTb0swcitFZ1U2UlVrRWtWcitTTFA3NTdUWgozZWI4dmdPdEduMS9ienM3bzNBaS9kclkrcUI5Q2k1S3lPc3FHTG1US2xFaUtOYkcyR1ZyTWxjS0ZYQU80YTY3Cklnc1hzYktNbTQwV1U3cG9mcGltU1ZmaXFSdkV5YmN3N0NYODF6cFErUyt1eHRYK2VBZ3V0NHh3VlI5d2IyVXYKelhuZk9HbWhWNThDd1dIQnNKa0kxNXhaa2VUWXdSN0diaEFMSkZUUkk3dkhvQXprTWIzbjAxQjQyWjNrN3RXNQpJUDFmTlpIOFUvOWxiUHNoT21FRFZkdjF5ZytVRVJxbStGSis2R0oxeFJGcGZnPT0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
  tls.key: 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
</code></pre>
<p><strong>4、创建ConfigMap自定义配置文</strong></p>
<pre><code class="language-shell">kubectl apply -f common/nginx-config.yaml 
</code></pre>
<pre><code class="language-yaml">kind: ConfigMap
apiVersion: v1
metadata:
  name: nginx-config
  namespace: nginx-ingress
data:
</code></pre>
<p><strong>5、为主机和主机路由定义自定义资源，支持自定义主机和路由</strong></p>
<pre><code class="language-shell">kubectl apply -f common/custom-resource-definitions.yaml
</code></pre>
<pre><code class="language-yaml">apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: virtualservers.k8s.nginx.org
spec:
  group: k8s.nginx.org
  versions:
  - name: v1
    served: true
    storage: true
  scope: Namespaced
  names:
    plural: virtualservers
    singular: virtualserver
    kind: VirtualServer
    shortNames:
    - vs
---
apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: virtualserverroutes.k8s.nginx.org
spec:
  group: k8s.nginx.org
  versions:
  - name: v1
    served: true
    storage: true
  scope: Namespaced
  names:
    plural: virtualserverroutes
    singular: virtualserverroute
    kind: VirtualServerRoute
    shortNames:
    - vsr
</code></pre>
<p><strong>6、配置RBAC认证授权，实现ingress控制器访问集群中的其他资源</strong></p>
<pre><code class="language-shell">kubectl apply -f rbac/rbac.yaml
</code></pre>
<pre><code class="language-yaml">kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: nginx-ingress
rules:
- apiGroups:
  - &quot;&quot;
  resources:
  - services
  - endpoints
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - &quot;&quot;
  resources:
  - secrets
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - &quot;&quot;
  resources:
  - configmaps
  verbs:
  - get
  - list
  - watch
  - update
  - create
- apiGroups:
  - &quot;&quot;
  resources:
  - pods
  verbs:
  - list
  - watch
- apiGroups:
  - &quot;&quot;
  resources:
  - events
  verbs:
  - create
  - patch
- apiGroups:
  - extensions
  resources:
  - ingresses
  verbs:
  - list
  - watch
  - get
- apiGroups:
  - &quot;extensions&quot;
  resources:
  - ingresses/status
  verbs:
  - update
- apiGroups:
  - k8s.nginx.org
  resources:
  - virtualservers
  - virtualserverroutes
  verbs:
  - list
  - watch
  - get
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: nginx-ingress
subjects:
- kind: ServiceAccount
  name: nginx-ingress
  namespace: nginx-ingress
roleRef:
  kind: ClusterRole
  name: nginx-ingress
  apiGroup: rbac.authorization.k8s.io
</code></pre>
<h3 id="12-部署ingress控制器">1.2 部署Ingress控制器</h3>
<p><strong>1、 部署控制器，控制器可以DaemonSets和Deployment的形式部署，如下是DaemonSets的配置文件</strong></p>
<pre><code class="language-js">apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: nginx-ingress
  namespace: nginx-ingress
spec:
  selector:
    matchLabels:
      app: nginx-ingress
  template:
    metadata:
      labels:
        app: nginx-ingress
     #annotations:
       #prometheus.io/scrape: &quot;true&quot;
       #prometheus.io/port: &quot;9113&quot;
    spec:
      serviceAccountName: nginx-ingress
      containers:
      - image: nginx/nginx-ingress:edge
        imagePullPolicy: Always
        name: nginx-ingress
        ports:
        - name: http
          containerPort: 80
          hostPort: 80            #通过hostPort的方式暴露端口
        - name: https
          containerPort: 443
          hostPort: 443
       #- name: prometheus
         #containerPort: 9113
        securityContext:
          allowPrivilegeEscalation: true
          runAsUser: 101 #nginx
          capabilities:
            drop:
            - ALL
            add:
            - NET_BIND_SERVICE
        env:
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        args:
          - -nginx-configmaps=$(POD_NAMESPACE)/nginx-config
          - -default-server-tls-secret=$(POD_NAMESPACE)/default-server-secret
         #- -v=3 # Enables extensive logging. Useful for troubleshooting.
         #- -report-ingress-status
         #- -external-service=nginx-ingress
         #- -enable-leader-election
         #- -enable-prometheus-metrics
</code></pre>
<p><strong>Deployments的配置文件</strong></p>
<pre><code class="language-js">apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-ingress
  namespace: nginx-ingress
spec:
  replicas: 1                  #副本的个数
  selector:
    matchLabels:
      app: nginx-ingress
  template:
    metadata:
      labels:
        app: nginx-ingress
     #annotations:
       #prometheus.io/scrape: &quot;true&quot;
       #prometheus.io/port: &quot;9113&quot;
    spec:
      serviceAccountName: nginx-ingress
      containers:
      - image: nginx/nginx-ingress:edge
        imagePullPolicy: Always
        name: nginx-ingress
        ports:                #内部暴露的服务端口，需要通过NodePort的方式暴露给外部
        - name: http
          containerPort: 80
        - name: https
          containerPort: 443
       #- name: prometheus
         #containerPort: 9113
        securityContext:
          allowPrivilegeEscalation: true
          runAsUser: 101 #nginx
          capabilities:
            drop:
            - ALL
            add:
            - NET_BIND_SERVICE
        env:
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        args:
          - -nginx-configmaps=$(POD_NAMESPACE)/nginx-config
          - -default-server-tls-secret=$(POD_NAMESPACE)/default-server-secret
         #- -v=3 # Enables extensive logging. Useful for troubleshooting.
         #- -report-ingress-status
         #- -external-service=nginx-ingress
         #- -enable-leader-election
         #- -enable-prometheus-metrics
</code></pre>
<p><strong>2、我们以DaemonSets的方式部署，DaemonSet部署集群中各个节点都是对等，如果有外部LoadBalancer则通过外部负载均衡路由至Ingress中</strong></p>
<pre><code class="language-shell">[root@node-1 deployments]# kubectl apply -f daemon-set/nginx-ingress.yaml 
daemonset.apps/nginx-ingress created
[root@node-1 deployments]# kubectl get daemonsets -n nginx-ingress
NAME            DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE
nginx-ingress   3         3         3       3            3           &lt;none&gt;          15s

[root@node-1 ~]# kubectl get pods -n nginx-ingress -o wide 
NAME                  READY   STATUS    RESTARTS   AGE     IP             NODE     NOMINATED NODE   READINESS GATES
nginx-ingress-7mpfc   1/1     Running   0          2m44s   10.244.0.50    node-1   &lt;none&gt;           &lt;none&gt;
nginx-ingress-l2rtj   1/1     Running   0          2m44s   10.244.1.144   node-2   &lt;none&gt;           &lt;none&gt;
nginx-ingress-tgf6r   1/1     Running   0          2m44s   10.244.2.160   node-3   &lt;none&gt;           &lt;none&gt;
</code></pre>
<p><strong>3、校验Nginx Ingress安装情况</strong></p>
<p>此时三个节点均是对等，即访问任意一个节点均能实现相同的效果，统一入口则通过外部负载均衡，如果在云环境下执行<code>kubectl apply -f service/loadbalancer.yaml</code>创建外部负载均衡实现入口调度，自建的可以通过lvs或nginx等负载均衡实现接入。</p>
<figure data-type="image" tabindex="1"><img src="https://ask.qcloudimg.com/draft/4405893/88fb7v82cj.png?imageView2/2/w/1620" alt="img" loading="lazy"></figure>
<p><strong>备注说明</strong>：如果以Deployments的方式部署，则需要执行service/nodeport.yaml创建NodePort类型的Service，实现的效果和DaemonSets类似。</p>
<h2 id="2-ingress资源定义">2. Ingress资源定义</h2>
<p>上面的已安装了一个Nginx Ingress Controller控制器，有了Ingress控制器后，我们就可以定义Ingress资源来实现七层负载转发了，大体上Ingress支持三种使用方式：1. 基于虚拟主机转发，2. 基于虚拟机主机URI转发，3. 支持TLS加密转发。</p>
<h3 id="21-ingress定义">2.1 Ingress定义</h3>
<p><strong>1、环境准备，先创建一个nginx的Deployment应用，包含2个副本</strong></p>
<pre><code class="language-shell">[root@node-1 ~]# kubectl run ingress-demo --image=nginx:1.7.9 --port=80 --replicas=2
[root@node-1 ~]# kubectl get deployments
NAME           READY   UP-TO-DATE   AVAILABLE   AGE
ingress-demo   2/2     2            2           116s
</code></pre>
<p><strong>2、以service方式暴露服务端口</strong></p>
<pre><code class="language-shell">[root@node-1 ~]# kubectl expose deployment ingress-demo --port=80 --protocol=TCP --target-port=80
service/ingress-demo exposed
[root@node-1 ~]# kubectl get services 
NAME           TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE
ingress-demo   ClusterIP   10.109.33.91   &lt;none&gt;        80/TCP    2m15s
</code></pre>
<p><strong>3、上述两个步骤已创建了一个service，如下我们定义一个ingress对象将流量转发至ingress-demo这个service，通过ingress.class指定控制器的类型为nginx</strong></p>
<pre><code class="language-yaml">[root@node-1 nginx-ingress]# cat nginx-ingress-demo.yaml 
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: nginx-ingress-demo
  labels:
    ingres-controller: nginx
  annotations:
    kubernets.io/ingress.class: nginx
spec:
  rules:
  - host: www.test.cn
    http:
      paths:
      - path: /
        backend:
          serviceName: ingress-demo
          servicePort: 80
</code></pre>
<p><strong>4、创建ingress对象</strong></p>
<pre><code class="language-shell">[root@node-1 nginx-ingress]# kubectl apply -f nginx-ingress-demo.yaml 
ingress.extensions/nginx-ingress-demo created

查看ingress资源列表
[root@node-1 nginx-ingress]# kubectl get ingresses
NAME                 HOSTS                ADDRESS   PORTS   AGE
nginx-ingress-demo   www.test.cn             80      4m4s
</code></pre>
<p><strong>5、查看ingress详情，可以在Rules规则中看到后端Pod的列表，自动发现和关联相关Pod</strong></p>
<pre><code class="language-shell">[root@node-1 ~]# kubectl describe ingresses nginx-ingress-demo 
Name:             nginx-ingress-demo
Namespace:        default
Address:          
Default backend:  default-http-backend:80 (&lt;none&gt;)
Rules:
  Host                Path  Backends
  ----                ----  --------
  www.test.cn  
                      /   ingress-demo:80 (10.244.1.146:80,10.244.2.162:80)
Annotations:
  kubectl.kubernetes.io/last-applied-configuration:  {&quot;apiVersion&quot;:&quot;extensions/v1beta1&quot;,&quot;kind&quot;:&quot;Ingress&quot;,&quot;metadata&quot;:{&quot;annotations&quot;:{&quot;kubernets.io/ingress.class&quot;:&quot;nginx&quot;},&quot;labels&quot;:{&quot;ingres-controller&quot;:&quot;nginx&quot;},&quot;name&quot;:&quot;nginx-ingress-demo&quot;,&quot;namespace&quot;:&quot;default&quot;},&quot;spec&quot;:{&quot;rules&quot;:[{&quot;host&quot;:&quot;www.happylaulab.cn&quot;,&quot;http&quot;:{&quot;paths&quot;:[{&quot;backend&quot;:{&quot;serviceName&quot;:&quot;ingress-demo&quot;,&quot;servicePort&quot;:80},&quot;path&quot;:&quot;/&quot;}]}}]}}

  kubernets.io/ingress.class:  nginx
Events:
  Type    Reason          Age   From                      Message
  ----    ------          ----  ----                      -------
  Normal  AddedOrUpdated  9m7s  nginx-ingress-controller  Configuration for default/nginx-ingress-demo was added or updated
  Normal  AddedOrUpdated  9m7s  nginx-ingress-controller  Configuration for default/nginx-ingress-demo was added or updated
  Normal  AddedOrUpdated  9m7s  nginx-ingress-controller  Configuration for default/nginx-ingress-demo was added or updated
</code></pre>
<p><strong>6、测试验证</strong></p>
<p>ingress规则的配置信息已注入到Ingress Controller中，环境中Ingress Controller是以DaemonSets的方式部署在集群中，如果有外部的负载均衡，则将www.test.cn域名的地址解析为负载均衡VIP。由于测试环境没有搭建负载均衡，将hosts解析执行node-1，node-2或者node-3任意一个IP都能实现相同的功能。</p>
<figure data-type="image" tabindex="2"><img src="https://ask.qcloudimg.com/draft/4405893/47noa95oaa.png?imageView2/2/w/1620" alt="img" loading="lazy"></figure>
<p>上述测试解析正常，当然也可以解析为node-1和node-2的IP，如下：</p>
<pre><code class="language-shell">[root@node-1 ~]# curl -I http://www.happylau.cn --resolve www.happylau.cn:80:10.254.100.101
HTTP/1.1 200 OK
Server: nginx/1.17.6
Date: Tue, 24 Dec 2019 10:32:22 GMT
Content-Type: text/html
Content-Length: 612
Connection: keep-alive
Last-Modified: Tue, 23 Dec 2014 16:25:09 GMT
ETag: &quot;54999765-264&quot;
Accept-Ranges: bytes

[root@node-1 ~]# curl -I http://www.happylau.cn --resolve www.happylau.cn:80:10.254.100.102
HTTP/1.1 200 OK
Server: nginx/1.17.6
Date: Tue, 24 Dec 2019 10:32:24 GMT
Content-Type: text/html
Content-Length: 612
Connection: keep-alive
Last-Modified: Tue, 23 Dec 2014 16:25:09 GMT
ETag: &quot;54999765-264&quot;
Accept-Ranges: bytes
</code></pre>
<h2 id="3-ingress动态配置">3 Ingress动态配置</h2>
<p>上面介绍了ingress资源对象的申明配置，这里我们探究一下Nginx Ingress Controller的实现机制和动态配置更新机制，以方便了解Ingress控制器的工作机制。</p>
<p><strong>1、 查看Nginx Controller控制器的配置文件，在nginx-ingress pod中存储着ingress的配置文件</strong></p>
<pre><code class="language-shell">[root@node-1 ~]# kubectl get pods -n nginx-ingress 
NAME                  READY   STATUS    RESTARTS   AGE
nginx-ingress-7mpfc   1/1     Running   0          6h15m
nginx-ingress-l2rtj   1/1     Running   0          6h15m
nginx-ingress-tgf6r   1/1     Running   0          6h15m

#查看配置文件，每个ingress生成一个配置文件，文件名为：命名空间-ingres名称.conf
[root@node-1 ~]# kubectl exec -it nginx-ingress-7mpfc -n nginx-ingress -- ls -l /etc/nginx/conf.d
total 4
-rw-r--r-- 1 nginx nginx 1005 Dec 24 10:06 default-nginx-ingress-demo.conf

#查看配置文件
[root@node-1 ~]# kubectl exec -it nginx-ingress-7mpfc -n nginx-ingress -- cat /etc/nginx/conf.d/default-nginx-ingress-demo.conf
# configuration for default/nginx-ingress-demo

#upstream的配置，会用least_conn算法，通过service服务发现机制动态识别到后端的Pod
upstream default-nginx-ingress-demo-www.test.cn-ingress-demo-80 {
	zone default-nginx-ingress-demo-www.test.cn-ingress-demo-80 256k;
	random two least_conn;
	server 10.244.1.146:80 max_fails=1 fail_timeout=10s max_conns=0;
	server 10.244.2.162:80 max_fails=1 fail_timeout=10s max_conns=0;
}

server {
	listen 80;
	server_tokens on;
	server_name www.test.cn;
	location / {
		proxy_http_version 1.1;
		proxy_connect_timeout 60s;
		proxy_read_timeout 60s;
		proxy_send_timeout 60s;
		client_max_body_size 1m;
		proxy_set_header Host $host;
		proxy_set_header X-Real-IP $remote_addr;
		proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
		proxy_set_header X-Forwarded-Host $host;
		proxy_set_header X-Forwarded-Port $server_port;
		proxy_set_header X-Forwarded-Proto $scheme;
		proxy_buffering on;
		proxy_pass http://default-nginx-ingress-demo-www.test.cn-ingress-demo-80;	#调用upstream实现代理
	}
}
</code></pre>
<p>通过上述查看配置文件可得知，Nginx Ingress Controller实际是根据ingress规则生成对应的nginx配置文件，以实现代理转发的功能，加入Deployments的副本数变更后nginx的配置文件会发生什么改变呢？</p>
<p><strong>2、更新控制器的副本数，由2个Pod副本扩容至3个</strong></p>
<pre><code class="language-js">[root@node-1 ~]# kubectl scale --replicas=3 deployment ingress-demo 
deployment.extensions/ingress-demo scaled
[root@node-1 ~]# kubectl get deployments
NAME           READY   UP-TO-DATE   AVAILABLE   AGE
ingress-demo   3/3     3            3           123m
</code></pre>
<p><strong>3、再次查看nginx的配置文件，ingress借助于service的服务发现机制，将加入的Pod自动加入到nginx upstream中</strong></p>
<figure data-type="image" tabindex="3"><img src="https://ask.qcloudimg.com/draft/4405893/14725qbjdh.png?imageView2/2/w/1620" alt="img" loading="lazy"></figure>
<p><strong>4、查看nginx pod的日志（kubectl logs nginx-ingress-7mpfc -n nginx-ingress），有reload优雅重启的记录，即通过更新配置文件+reload实现配置动态更新。</strong></p>
<figure data-type="image" tabindex="4"><img src="https://ask.qcloudimg.com/draft/4405893/lilxwe1u13.png?imageView2/2/w/1620" alt="img" loading="lazy"></figure>
<p>通过上述的配置可知，ingress调用kubernetes api去感知kubernetes集群中的变化情况，Pod的增加或减少这些变化，然后动态更新nginx ingress controller的配置文件，并重新载入配置。当集群规模越大时，会频繁涉及到配置文件的变动和重载，因此nginx这方面会存在先天的劣势，专门为微服务负载均衡应运而生，如Traefik，Envoy，Istio，这些负载均衡工具能够提供大规模，频繁动态更新的场景，但性能相比Nginx，HAproxy还存在一定的劣势。</p>
<h2 id="4-ingress路径转发">4 Ingress路径转发</h2>
<p>Ingress支持URI格式的转发方式，同时支持URL重写，如下以两个service为例演示，service-1安装nginx，service-2安装httpd，分别用http://demo.happylau.cn/news和http://demo.happylau.cn/sports转发到两个不同的service</p>
<p><strong>1、环境准备，创建两个应用并实现service暴露，创建deployments时指定--explose创建service</strong></p>
<pre><code class="language-js">[root@node-1 ~]# kubectl run service-1 --image=nginx:1.7.9 --port=80 --replicas=1 --expose=true 
service/service-1 created
deployment.apps/service-1 created

[root@node-1 ~]# kubectl run service-2 --image=httpd --port=80 --replicas=1 --expose=true 
service/service-2 created
deployment.apps/service-2 created

查看deployment状态
[root@node-1 ~]# kubectl get deployments 
NAME           READY   UP-TO-DATE   AVAILABLE   AGE
ingress-demo   4/4     4            4           4h36m
service-1      1/1     1            1           65s
service-2      1/1     1            1           52s

查看service状态，服务已经正常
[root@node-1 ~]# kubectl get services 
NAME           TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE
ingress-demo   ClusterIP   10.109.33.91     &lt;none&gt;        80/TCP    4h36m
kubernetes     ClusterIP   10.96.0.1        &lt;none&gt;        443/TCP   101d
service-1      ClusterIP   10.106.245.71    &lt;none&gt;        80/TCP    68s
service-2      ClusterIP   10.104.204.158   &lt;none&gt;        80/TCP    55s
</code></pre>
<p><strong>2、创建ingress对象，通过一个域名将请求转发至后端两个service</strong></p>
<pre><code class="language-js">[root@node-1 nginx-ingress]# cat nginx-ingress-uri-demo.yaml 
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: nginx-ingress-uri-demo
  labels:
    ingres-controller: nginx
  annotations:
    kubernets.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
  - host: 
    http:
      paths:
      - path: /news
        backend:
          serviceName: service-1 
          servicePort: 80
      - path: /sports
        backend:
          serviceName: service-2
          servicePort: 80
</code></pre>
<p><strong>3、创建ingress规则，查看详情</strong></p>
<pre><code class="language-js">[root@node-1 nginx-ingress]# kubectl apply -f nginx-ingress-uri-demo.yaml 
ingress.extensions/nginx-ingress-uri-demo created

#查看详情
[root@node-1 nginx-ingress]# kubectl get ingresses.
NAME                     HOSTS              ADDRESS   PORTS   AGE
nginx-ingress-demo       www.happylau.cn              80      4h35m
nginx-ingress-uri-demo   demo.happylau.cn             80      4s
[root@node-1 nginx-ingress]# kubectl describe ingresses nginx-ingress-uri-demo 
Name:             nginx-ingress-uri-demo
Namespace:        default
Address:          
Default backend:  default-http-backend:80 (&lt;none&gt;)
Rules:              #对应的转发url规则
  Host              Path  Backends
  ----              ----  --------
  demo.happylau.cn  
                    /news     service-1:80 (10.244.2.163:80)
                    /sports   service-2:80 (10.244.1.148:80)
Annotations:
  kubectl.kubernetes.io/last-applied-configuration:  {&quot;apiVersion&quot;:&quot;extensions/v1beta1&quot;,&quot;kind&quot;:&quot;Ingress&quot;,&quot;metadata&quot;:{&quot;annotations&quot;:{&quot;kubernets.io/ingress.class&quot;:&quot;nginx&quot;,&quot;nginx.ingress.kubernetes.io/rewrite-target&quot;:&quot;/&quot;},&quot;labels&quot;:{&quot;ingres-controller&quot;:&quot;nginx&quot;},&quot;name&quot;:&quot;nginx-ingress-uri-demo&quot;,&quot;namespace&quot;:&quot;default&quot;},&quot;spec&quot;:{&quot;rules&quot;:[{&quot;host&quot;:&quot;demo.happylau.cn&quot;,&quot;http&quot;:{&quot;paths&quot;:[{&quot;backend&quot;:{&quot;serviceName&quot;:&quot;service-1&quot;,&quot;servicePort&quot;:80},&quot;path&quot;:&quot;/news&quot;},{&quot;backend&quot;:{&quot;serviceName&quot;:&quot;service-2&quot;,&quot;servicePort&quot;:80},&quot;path&quot;:&quot;/sports&quot;}]}}]}}

  kubernets.io/ingress.class:                  nginx
  nginx.ingress.kubernetes.io/rewrite-target:  /
Events:
  Type    Reason          Age   From                      Message
  ----    ------          ----  ----                      -------
  Normal  AddedOrUpdated  11s   nginx-ingress-controller  Configuration for default/nginx-ingress-uri-demo was added or updated
  Normal  AddedOrUpdated  11s   nginx-ingress-controller  Configuration for default/nginx-ingress-uri-demo was added or updated
  Normal  AddedOrUpdated  11s   nginx-ingress-controller  Configuration for default/nginx-ingress-uri-demo was added or updated
</code></pre>
<p><strong>4、准备测试，站点中创建对应的路径</strong></p>
<pre><code class="language-js">[root@node-1 ~]# kubectl exec -it service-1-7b66bf758f-xj9jh /bin/bash
root@service-1-7b66bf758f-xj9jh:/# echo &quot;service-1 website page&quot; &gt;/usr/share/nginx/html/news

[root@node-1 ~]# kubectl exec -it service-2-7c7444684d-w9cv9 /bin/bash
root@service-2-7c7444684d-w9cv9:/usr/local/apache2# echo &quot;service-2 website page&quot; &gt;/usr/local/apache2/htdocs/sports
</code></pre>
<p><strong>5、测试验证</strong></p>
<pre><code class="language-js">[root@node-1 ~]# curl http://demo.happylau.cn/news --resolve demo.happylau.cn:80:10.254.100.101
service-1 website page
[root@node-1 ~]# curl http://demo.happylau.cn/sports --resolve demo.happylau.cn:80:10.254.100.101
service-2 website page
</code></pre>
<p><strong>6、总结</strong></p>
<p>通过上述的验证测试可以得知，ingress支持URI的路由方式转发，其对应在ingress中的配置文件内容是怎样的呢，我们看下ingress controller生成对应的nginx配置文件内容，实际是通过ingress的location来实现，将不同的localtion转发至不同的upstream以实现service的关联，配置文件如下：</p>
<pre><code class="language-js">[root@node-1 ~]# kubectl exec -it nginx-ingress-7mpfc -n nginx-ingress /bin/bash
nginx@nginx-ingress-7mpfc:/$ cat /etc/nginx/conf.d/default-nginx-ingress-uri-demo.conf |grep -v &quot;^$&quot;
# configuration for default/nginx-ingress-uri-demo
#定义两个upstream和后端的service关联
upstream default-nginx-ingress-uri-demo-demo.happylau.cn-service-1-80 {
	zone default-nginx-ingress-uri-demo-demo.happylau.cn-service-1-80 256k;
	random two least_conn;
	server 10.244.2.163:80 max_fails=1 fail_timeout=10s max_conns=0;
}

upstream default-nginx-ingress-uri-demo-demo.happylau.cn-service-2-80 {
	zone default-nginx-ingress-uri-demo-demo.happylau.cn-service-2-80 256k;
	random two least_conn;
	server 10.244.1.148:80 max_fails=1 fail_timeout=10s max_conns=0;	
}

server {
	listen 80;
	server_tokens on;
	server_name demo.happylau.cn;
	
  #定义location实现代理，通过proxy_pass和后端的service关联
	location /news {
		proxy_http_version 1.1;
		proxy_connect_timeout 60s;
		proxy_read_timeout 60s;
		proxy_send_timeout 60s;
		client_max_body_size 1m;
		proxy_set_header Host $host;
		proxy_set_header X-Real-IP $remote_addr;
		proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
		proxy_set_header X-Forwarded-Host $host;
		proxy_set_header X-Forwarded-Port $server_port;
		proxy_set_header X-Forwarded-Proto $scheme;
		proxy_buffering on;
		proxy_pass http://default-nginx-ingress-uri-demo-demo.happylau.cn-service-1-80;
	}

	location /sports {
		proxy_http_version 1.1;
		proxy_connect_timeout 60s;
		proxy_read_timeout 60s;
		proxy_send_timeout 60s;
		client_max_body_size 1m;
		proxy_set_header Host $host;
		proxy_set_header X-Real-IP $remote_addr;
		proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
		proxy_set_header X-Forwarded-Host $host;
		proxy_set_header X-Forwarded-Port $server_port;
		proxy_set_header X-Forwarded-Proto $scheme;
		proxy_buffering on;
		proxy_pass http://default-nginx-ingress-uri-demo-demo.happylau.cn-service-2-80;	
	}	
}
</code></pre>
<h2 id="5-ingress虚拟主机">5 Ingress虚拟主机</h2>
<p>ingress支持基于名称的虚拟主机，实现单个IP多个域名转发的需求，通过请求头部携带主机名方式区分开，将上个章节的ingress删除，使用service-1和service-2两个service来做演示。</p>
<p><strong>1、创建ingress规则，通过主机名实现转发规则</strong></p>
<pre><code class="language-js">apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: nginx-ingress-virtualname-demo
  labels:
    ingres-controller: nginx
  annotations:
    kubernets.io/ingress.class: nginx
spec:
  rules:
  - host: news.happylau.cn
    http:
      paths:
      - path: /
        backend:
          serviceName: service-1 
          servicePort: 80
  - host: sports.happylau.cn
    http:
      paths:
      - path: /
        backend:
          serviceName: service-2 
          servicePort: 80
</code></pre>
<p><strong>2、生成ingress规则并查看详情，一个ingress对应两个HOSTS</strong></p>
<pre><code class="language-js">[root@node-1 nginx-ingress]# kubectl apply -f nginx-ingress-virtualname.yaml 
ingress.extensions/nginx-ingress-virtualname-demo created

#查看列表
[root@node-1 nginx-ingress]# kubectl get ingresses nginx-ingress-virtualname-demo 
NAME                             HOSTS                                 ADDRESS   PORTS   AGE
nginx-ingress-virtualname-demo   news.happylau.cn,sports.happylau.cn             80      12s

#查看详情
[root@node-1 nginx-ingress]# kubectl describe ingresses nginx-ingress-virtualname-demo
Name:             nginx-ingress-virtualname-demo
Namespace:        default
Address:          
Default backend:  default-http-backend:80 (&lt;none&gt;)
Rules:
  Host                Path  Backends
  ----                ----  --------
  news.happylau.cn    
                      /   service-1:80 (10.244.2.163:80)
  sports.happylau.cn  
                      /   service-2:80 (10.244.1.148:80)
Annotations:
  kubectl.kubernetes.io/last-applied-configuration:  {&quot;apiVersion&quot;:&quot;extensions/v1beta1&quot;,&quot;kind&quot;:&quot;Ingress&quot;,&quot;metadata&quot;:{&quot;annotations&quot;:{&quot;kubernets.io/ingress.class&quot;:&quot;nginx&quot;},&quot;labels&quot;:{&quot;ingres-controller&quot;:&quot;nginx&quot;},&quot;name&quot;:&quot;nginx-ingress-virtualname-demo&quot;,&quot;namespace&quot;:&quot;default&quot;},&quot;spec&quot;:{&quot;rules&quot;:[{&quot;host&quot;:&quot;news.happylau.cn&quot;,&quot;http&quot;:{&quot;paths&quot;:[{&quot;backend&quot;:{&quot;serviceName&quot;:&quot;service-1&quot;,&quot;servicePort&quot;:80},&quot;path&quot;:&quot;/&quot;}]}},{&quot;host&quot;:&quot;sports.happylau.cn&quot;,&quot;http&quot;:{&quot;paths&quot;:[{&quot;backend&quot;:{&quot;serviceName&quot;:&quot;service-2&quot;,&quot;servicePort&quot;:80},&quot;path&quot;:&quot;/&quot;}]}}]}}

  kubernets.io/ingress.class:  nginx
Events:
  Type    Reason          Age   From                      Message
  ----    ------          ----  ----                      -------
  Normal  AddedOrUpdated  28s   nginx-ingress-controller  Configuration for default/nginx-ingress-virtualname-demo was added or updated
  Normal  AddedOrUpdated  28s   nginx-ingress-controller  Configuration for default/nginx-ingress-virtualname-demo was added or updated
  Normal  AddedOrUpdated  28s   nginx-ingress-controller  Configuration for default/nginx-ingress-virtualname-demo was added or updated
</code></pre>
<p><strong>3、准备测试数据并测试</strong></p>
<pre><code class="language-js">[root@node-1 ~]# kubectl exec -it service-1-7b66bf758f-xj9jh /bin/bash
root@service-1-7b66bf758f-xj9jh:/# echo &quot;news demo&quot; &gt;/usr/share/nginx/html/index.html

[root@node-1 ~]# kubectl exec -it service-2-7c7444684d-w9cv9 /bin/bash  
root@service-2-7c7444684d-w9cv9:/usr/local/apache2# echo &quot;sports demo&quot;  &gt;/usr/local/apache2/htdocs/index.html
</code></pre>
<p><strong>测试：</strong></p>
<pre><code class="language-js">[root@node-1 ~]# curl http://news.happylau.cn --resolve news.happylau.cn:80:10.254.100.102
news demo
[root@node-1 ~]# curl http://sports.happylau.cn --resolve sports.happylau.cn:80:10.254.100.102
sports demo
</code></pre>
<p><strong>4、查看nginx的配置文件内容，通过在server中定义不同的server_name以区分，代理到不同的upstream以实现service的代理。</strong></p>
<pre><code class="language-js"># configuration for default/nginx-ingress-virtualname-demo
upstream default-nginx-ingress-virtualname-demo-news.happylau.cn-service-1-80 {
	zone default-nginx-ingress-virtualname-demo-news.happylau.cn-service-1-80 256k;
	random two least_conn;
	server 10.244.2.163:80 max_fails=1 fail_timeout=10s max_conns=0;
}

upstream default-nginx-ingress-virtualname-demo-sports.happylau.cn-service-2-80 {
	zone default-nginx-ingress-virtualname-demo-sports.happylau.cn-service-2-80 256k;
	random two least_conn;
	server 10.244.1.148:80 max_fails=1 fail_timeout=10s max_conns=0;
}

server {
	listen 80;
	server_tokens on;
	server_name news.happylau.cn;
	location / {
		proxy_http_version 1.1;
		proxy_connect_timeout 60s;
		proxy_read_timeout 60s;
		proxy_send_timeout 60s;
		client_max_body_size 1m;
		proxy_set_header Host $host;
		proxy_set_header X-Real-IP $remote_addr;
		proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
		proxy_set_header X-Forwarded-Host $host;
		proxy_set_header X-Forwarded-Port $server_port;
		proxy_set_header X-Forwarded-Proto $scheme;
		proxy_buffering on;
		
		proxy_pass http://default-nginx-ingress-virtualname-demo-news.happylau.cn-service-1-80;
	
  }
}
server {
	listen 80;	
	server_tokens on;
	server_name sports.happylau.cn;

	location / {
		proxy_http_version 1.1;
		proxy_connect_timeout 60s;
		proxy_read_timeout 60s;
		proxy_send_timeout 60s;
		client_max_body_size 1m;
		proxy_set_header Host $host;
		proxy_set_header X-Real-IP $remote_addr;
		proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
		proxy_set_header X-Forwarded-Host $host;
		proxy_set_header X-Forwarded-Port $server_port;
		proxy_set_header X-Forwarded-Proto $scheme;
		proxy_buffering on;
		
		proxy_pass http://default-nginx-ingress-virtualname-demo-sports.happylau.cn-service-2-80;	

	}	
}
</code></pre>
<h2 id="6-ingress-tls加密">6 Ingress TLS加密</h2>
<p>四层的负载均衡无法支持https请求，当前大部分业务都要求以https方式接入，Ingress能支持https的方式接入，通过Secrets存储证书+私钥，实现https接入，同时还能支持http跳转功能。对于用户的请求流量来说，客户端到ingress controller是https流量，ingress controller到后端service则是http，提高用户访问性能，如下介绍ingress TLS功能实现步骤。</p>
<p><strong>1、生成自签名证书和私钥</strong></p>
<pre><code class="language-js">[root@node-1 ~]# openssl req -x509 -newkey rsa:2048 -nodes -days 365 -keyout tls.key -out tls.crt
Generating a 2048 bit RSA private key
....................................................+++
........................................+++
writing new private key to 'tls.key'
-----
You are about to be asked to enter information that will be incorporated
into your certificate request.
What you are about to enter is what is called a Distinguished Name or a DN.
There are quite a few fields but you can leave some blank
For some fields there will be a default value,
If you enter '.', the field will be left blank.
-----
Country Name (2 letter code) [XX]:CN        #国家
State or Province Name (full name) []:GD    #省份
Locality Name (eg, city) [Default City]:ShenZhen  #城市
Organization Name (eg, company) [Default Company Ltd]:Tencent    #公司 
Organizational Unit Name (eg, section) []:HappyLau  #组织
Common Name (eg, your name or your server's hostname) []:www.happylau.cn  #域名
Email Address []:573302346@qq.com       #邮箱地址


#tls.crt为证书，tls.key为私钥
[root@node-1 ~]# ls tls.* -l
-rw-r--r-- 1 root root 1428 12月 26 13:21 tls.crt
-rw-r--r-- 1 root root 1708 12月 26 13:21 tls.key
</code></pre>
<p><strong>2、配置Secrets，将证书和私钥配置到Secrets中</strong></p>
<pre><code class="language-js">[root@node-1 ~]# kubectl create secret tls happylau-sslkey --cert=tls.crt --key=tls.key 
secret/happylau-sslkey created

查看Secrets详情,证书和私要包含在data中，文件名为两个不同的key：tls.crt和tls.key
[root@node-1 ~]# kubectl describe secrets happylau-sslkey 
Name:         happylau-sslkey
Namespace:    default
Labels:       &lt;none&gt;
Annotations:  &lt;none&gt;

Type:  kubernetes.io/tls

Data
====
tls.crt:  1428 bytes
tls.key:  1708 bytes
</code></pre>
<p><strong>3、配置ingress调用Secrets实现SSL证书加密</strong></p>
<pre><code class="language-js">apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: nginx-ingress-tls-demo
  labels:
    ingres-controller: nginx
  annotations:
    kubernets.io/ingress.class: nginx
spec:
  tls:
  - hosts:
    - news.happylau.cn
    - sports.happylau.cn
    secretName: happylau-sslkey
  rules:
  - host: news.happylau.cn
    http:
      paths:
      - path: /
        backend:
          serviceName: service-1 
          servicePort: 80
  - host: sports.happylau.cn
    http:
      paths:
      - path: /
        backend:
          serviceName: service-2 
          servicePort: 80
</code></pre>
<p><strong>4、创建ingress并查看ingress详情</strong></p>
<pre><code class="language-js">[root@node-1 nginx-ingress]# kubectl describe ingresses nginx-ingress-tls-demo 
Name:             nginx-ingress-tls-demo
Namespace:        default
Address:          
Default backend:  default-http-backend:80 (&lt;none&gt;)
TLS:
  happylau-sslkey terminates news.happylau.cn,sports.happylau.cn
Rules:
  Host                Path  Backends
  ----                ----  --------
  news.happylau.cn    
                      /   service-1:80 (10.244.2.163:80)
  sports.happylau.cn  
                      /   service-2:80 (10.244.1.148:80)
Annotations:
  kubectl.kubernetes.io/last-applied-configuration:  {&quot;apiVersion&quot;:&quot;extensions/v1beta1&quot;,&quot;kind&quot;:&quot;Ingress&quot;,&quot;metadata&quot;:{&quot;annotations&quot;:{&quot;kubernets.io/ingress.class&quot;:&quot;nginx&quot;},&quot;labels&quot;:{&quot;ingres-controller&quot;:&quot;nginx&quot;},&quot;name&quot;:&quot;nginx-ingress-tls-demo&quot;,&quot;namespace&quot;:&quot;default&quot;},&quot;spec&quot;:{&quot;rules&quot;:[{&quot;host&quot;:&quot;news.happylau.cn&quot;,&quot;http&quot;:{&quot;paths&quot;:[{&quot;backend&quot;:{&quot;serviceName&quot;:&quot;service-1&quot;,&quot;servicePort&quot;:80},&quot;path&quot;:&quot;/&quot;}]}},{&quot;host&quot;:&quot;sports.happylau.cn&quot;,&quot;http&quot;:{&quot;paths&quot;:[{&quot;backend&quot;:{&quot;serviceName&quot;:&quot;service-2&quot;,&quot;servicePort&quot;:80},&quot;path&quot;:&quot;/&quot;}]}}],&quot;tls&quot;:[{&quot;hosts&quot;:[&quot;news.happylau.cn&quot;,&quot;sports.happylau.cn&quot;],&quot;secretName&quot;:&quot;happylau-sslkey&quot;}]}}

  kubernets.io/ingress.class:  nginx
Events:
  Type    Reason          Age   From                      Message
  ----    ------          ----  ----                      -------
  Normal  AddedOrUpdated  22s   nginx-ingress-controller  Configuration for default/nginx-ingress-tls-demo was added or updated
  Normal  AddedOrUpdated  22s   nginx-ingress-controller  Configuration for default/nginx-ingress-tls-demo was added or updated
  Normal  AddedOrUpdated  22s   nginx-ingress-controller  Configuration for default/nginx-ingress-tls-demo was added or updated
</code></pre>
<p><strong>5、访问</strong></p>
<p>将news.happylau.cn和sports.happylau.cn写入到hosts文件中，并通过<a href="https://news.happylau.cn/">https://news.happylau.cn</a> 的方式访问，浏览器访问内容提示证书如下，信任证书即可访问到站点内容。</p>
<figure data-type="image" tabindex="5"><img src="https://ask.qcloudimg.com/draft/4405893/ijw044j6yx.png?imageView2/2/w/1620" alt="img" loading="lazy"></figure>
<p>查看证书详情，正是我们制作的自签名证书，生产实际使用时，推荐使用CA机构颁发签名证书。</p>
<figure data-type="image" tabindex="6"><img src="https://ask.qcloudimg.com/draft/4405893/t3clag54i5.png?imageView2/2/w/1620" alt="img" loading="lazy"></figure>
<p><strong>6、接下来查看一下tls配置https的nginx配置文件内容，可以看到在server块启用了https并配置证书，同时配置了http跳转，因此直接访问http也能够实现自动跳转到https功能。</strong></p>
<pre><code class="language-shell"># configuration for default/nginx-ingress-tls-demo
upstream default-nginx-ingress-tls-demo-news.happylau.cn-service-1-80 {
	zone default-nginx-ingress-tls-demo-news.happylau.cn-service-1-80 256k;
	random two least_conn;
	server 10.244.2.163:80 max_fails=1 fail_timeout=10s max_conns=0;	
}

upstream default-nginx-ingress-tls-demo-sports.happylau.cn-service-2-80 {
	zone default-nginx-ingress-tls-demo-sports.happylau.cn-service-2-80 256k;
	random two least_conn;
	server 10.244.1.148:80 max_fails=1 fail_timeout=10s max_conns=0;	
}

server {
	listen 80;

	listen 443 ssl;     #https监听端口，证书和key，实现和Secrets关联
	ssl_certificate /etc/nginx/secrets/default-happylau-sslkey;
	ssl_certificate_key /etc/nginx/secrets/default-happylau-sslkey;

	server_tokens on;
	server_name news.happylau.cn;
	
  #http跳转功能，即访问http会自动跳转至https
	if ($scheme = http) {
		return 301 https://$host:443$request_uri;
	}
	
	location / {
		proxy_http_version 1.1;
		proxy_connect_timeout 60s;
		proxy_read_timeout 60s;
		proxy_send_timeout 60s;
		client_max_body_size 1m;
		proxy_set_header Host $host;
		proxy_set_header X-Real-IP $remote_addr;
		proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
		proxy_set_header X-Forwarded-Host $host;
		proxy_set_header X-Forwarded-Port $server_port;
		proxy_set_header X-Forwarded-Proto $scheme;
		proxy_buffering on;
		
		proxy_pass http://default-nginx-ingress-tls-demo-news.happylau.cn-service-1-80;	
  }	
}

server {
	listen 80;
	listen 443 ssl;
	ssl_certificate /etc/nginx/secrets/default-happylau-sslkey;
	ssl_certificate_key /etc/nginx/secrets/default-happylau-sslkey;

	server_tokens on;
	server_name sports.happylau.cn;

	if ($scheme = http) {
		return 301 https://$host:443$request_uri;
	}

	location / {
		proxy_http_version 1.1;
		proxy_connect_timeout 60s;
		proxy_read_timeout 60s;
		proxy_send_timeout 60s;
		client_max_body_size 1m;
		proxy_set_header Host $host;
		proxy_set_header X-Real-IP $remote_addr;
		proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
		proxy_set_header X-Forwarded-Host $host;
		proxy_set_header X-Forwarded-Port $server_port;
		proxy_set_header X-Forwarded-Proto $scheme;
		proxy_buffering on;
		
		proxy_pass http://default-nginx-ingress-tls-demo-sports.happylau.cn-service-2-80;	
	}	
}
</code></pre>
<h2 id="7-nginx-ingress高级功能">7. Nginx Ingress高级功能</h2>
<h3 id="71-定制化参数">7.1 定制化参数</h3>
<p>ingress controller提供了基础反向代理的功能，如果需要定制化nginx的特性或参数，需要通过ConfigMap和Annotations来实现，两者实现的方式有所不同，ConfigMap用于指定整个ingress集群资源的基本参数，修改后会被所有的ingress对象所继承；Annotations则被某个具体的ingress对象所使用，修改只会影响某个具体的ingress资源，冲突时其优先级高于ConfigMap。</p>
<h4 id="711-configmap自定义参数">7.1.1 ConfigMap自定义参数</h4>
<p>安装nginx ingress controller时默认会包含一个空的ConfigMap，可以通过ConfigMap来自定义nginx controller的默认参数，如下以修改一些参数为例：</p>
<p><strong>1、 定义ConfigMap参数</strong></p>
<pre><code class="language-yaml">kind: ConfigMap
apiVersion: v1
metadata:
  name: nginx-config
  namespace: nginx-ingress
data:
  proxy-connect-timeout: &quot;10s&quot;
  proxy-read-timeout: &quot;10s&quot;
  proxy-send-timeout: &quot;10&quot;
  client-max-body-size: &quot;3m&quot;
</code></pre>
<p><strong>2、 应用配置并查看ConfigMap配置</strong></p>
<pre><code class="language-shell">[root@node-1 ~]# kubectl get configmaps -n nginx-ingress nginx-config -o yaml
apiVersion: v1
data:
  client-max-body-size: 3m
  proxy-connect-timeout: 10s
  proxy-read-timeout: 10s
  proxy-send-timeout: 10s
kind: ConfigMap
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {&quot;apiVersion&quot;:&quot;v1&quot;,&quot;data&quot;:{&quot;client-max-body-size&quot;:&quot;3m&quot;,&quot;proxy-connect-timeout&quot;:&quot;10s&quot;,&quot;proxy-read-timeout&quot;:&quot;10s&quot;,&quot;proxy-send-timeout&quot;:&quot;10&quot;},&quot;kind&quot;:&quot;ConfigMap&quot;,&quot;metadata&quot;:{&quot;annotations&quot;:{},&quot;name&quot;:&quot;nginx-config&quot;,&quot;namespace&quot;:&quot;nginx-ingress&quot;}}
  creationTimestamp: &quot;2019-12-24T04:39:23Z&quot;
  name: nginx-config
  namespace: nginx-ingress
  resourceVersion: &quot;13845543&quot;
  selfLink: /api/v1/namespaces/nginx-ingress/configmaps/nginx-config
  uid: 9313ae47-a0f0-463e-a25a-1658f1ca0d57
</code></pre>
<p><strong>3 、此时，ConfigMap定义的配置参数会被集群中所有的Ingress资源继承（除了annotations定义之外）</strong></p>
<figure data-type="image" tabindex="7"><img src="https://ask.qcloudimg.com/draft/4405893/w3dcxxnxfa.png?imageView2/2/w/1620" alt="img" loading="lazy"></figure>
<p>有很多参数可以定义，详情配置可参考方文档说明：https://github.com/nginxinc/kubernetes-ingress/blob/master/docs/configmap-and-annotations.md#Summary-of-ConfigMap-and-Annotations</p>
<h4 id="712-annotations自定义参数">7.1.2 Annotations自定义参数</h4>
<p>ConfigMap定义的是全局的配置参数，修改后所有的配置都会受影响，如果想针对某个具体的ingress资源自定义参数，则可以通过Annotations来实现，下面开始以实际的例子演示Annotations的使用。</p>
<p><strong>1、修改ingress资源，添加annotations的定义,通过nginx.org组修改了一些参数，如proxy-connect-timeout，调度算法为round_robin（默认为least _conn）</strong></p>
<pre><code class="language-yaml">apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: nginx-ingress-demo
  labels:
    ingres-controller: nginx
  annotations:
    kubernets.io/ingress.class: nginx
    nginx.org/proxy-connect-timeout: &quot;30s&quot;
    nginx.org/proxy-send-timeout: &quot;20s&quot;
    nginx.org/proxy-read-timeout: &quot;20s&quot;
    nginx.org/client-max-body-size: &quot;2m&quot;
    nginx.org/fail-timeout: &quot;5s&quot;
    nginx.org/lb-method: &quot;round_robin&quot; 
spec:
  rules:
  - host: www.happylau.cn
    http:
      paths:
      - path: /
        backend:
          serviceName: ingress-demo
          servicePort: 80
</code></pre>
<p><strong>2、 重新应用ingress对象并查看参数配置情况</strong></p>
<figure data-type="image" tabindex="8"><img src="https://ask.qcloudimg.com/draft/4405893/b02oqllujm.png?imageView2/2/w/1620" alt="img" loading="lazy"></figure>
<p>由上面的演示可得知，Annotations的优先级高于ConfigMapMap，Annotations修改参数只会影响到某一个具体的ingress资源，其定义的方法和ConfigMap相相近似，但又有差别，部分ConfigMap的参数Annotations无法支持，反过来Annotations定义的参数ConfigMap也不一定支持，下图列举一下常规支持参数情况：</p>
<p><img src="https://ask.qcloudimg.com/draft/4405893/9uco9v1rs6.png?imageView2/2/w/1620" alt="img" loading="lazy">通用参数</p>
<p><img src="https://ask.qcloudimg.com/draft/4405893/kvbsl1udm3.png?imageView2/2/w/1620" alt="img" loading="lazy">日志支持</p>
<p><img src="https://ask.qcloudimg.com/draft/4405893/2bexxnq0b4.png?imageView2/2/w/1620" alt="img" loading="lazy">请求头部</p>
<p><img src="https://ask.qcloudimg.com/draft/4405893/hbfmi960e9.png?imageView2/2/w/1620" alt="img" loading="lazy">认证和安全</p>
<p><img src="https://ask.qcloudimg.com/draft/4405893/0h2kio34c5.png?imageView2/2/w/1620" alt="img" loading="lazy">upstream支持</p>
<h3 id="72-虚拟主机和路由">7.2 虚拟主机和路由</h3>
<p>安装nginx ingress时我们安装了一个customresourcedefinitions自定义资源，其能够提供除了默认ingress功能之外的一些高级特性如</p>
<ul>
<li>虚拟主机VirtualServer</li>
<li>虚拟路由VirtualServerRoute</li>
<li>健康检查Healthcheck</li>
<li>流量切割Split</li>
<li>会话保持SessionCookie</li>
<li>重定向Redirect</li>
</ul>
<p>这些功能大部分依赖于Nginx Plus高级版本的支持，社区版本仅支持部分，对于企业级开发而言，丰富更多的功能可以购买企业级Nginx Plus版本。如下以通过VirtualServer和VirtualServerRoute定义upstream配置为例演示功能使用。</p>
<p><strong>1、定义VirtualServer资源,其配置和ingress资源对象类似，能支持的功能会更丰富一点</strong></p>
<pre><code class="language-yaml">apiVersion: k8s.nginx.org/v1
kind: VirtualServer
metadata:
  name: cafe
spec:
  host: cafe.example.com
  tls:
    secret: cafe-secret
  upstreams:
  - name: tea
    service: tea-svc
    port: 80
    name: tea
    service: ingress-demo 
    subselector:
    version: canary
    lb-method: round_robin
    fail-timeout: 10s
    max-fails: 1
    max-conns: 32
    keepalive: 32
    connect-timeout: 30s
    read-timeout: 30s
    send-timeout: 30s
    next-upstream: &quot;error timeout non_idempotent&quot;
    next-upstream-timeout: 5s
    next-upstream-tries: 10
    client-max-body-size: 2m
    tls:
      enable: true
  routes:
  - path: /tea
    action:
      pass: tea
</code></pre>
<p><strong>2、 应用资源并查看VirtualServer资源列表</strong></p>
<pre><code class="language-shell">[root@node-1 ~]# kubectl apply -f vs.yaml 
virtualserver.k8s.nginx.org/cafe unchanged
[root@node-1 ~]# kubectl get virtualserver
NAME                 AGE
cafe                 2m52s
</code></pre>
<p><strong>3、检查ingress控制器的配置文件情况,生成的配置和upstream定义一致</strong></p>
<pre><code class="language-shell">nginx@nginx-ingress-7mpfc:/etc/nginx/conf.d$ cat vs_default_cafe.conf 
upstream vs_default_cafe_tea {
    zone vs_default_cafe_tea 256k;
    server 10.244.0.51:80 max_fails=1 fail_timeout=10s max_conns=32;
    server 10.244.1.146:80 max_fails=1 fail_timeout=10s max_conns=32;
    server 10.244.1.147:80 max_fails=1 fail_timeout=10s max_conns=32;
    server 10.244.2.162:80 max_fails=1 fail_timeout=10s max_conns=32;
    keepalive 32;
}

server {
    listen 80;
    server_name cafe.example.com;
    listen 443 ssl;
    ssl_certificate /etc/nginx/secrets/default;
    ssl_certificate_key /etc/nginx/secrets/default;
    ssl_ciphers NULL;
    server_tokens &quot;on&quot;;

    location /tea {
        proxy_connect_timeout 30s;
        proxy_read_timeout 30s;
        proxy_send_timeout 30s;
        client_max_body_size 2m;
        proxy_max_temp_file_size 1024m;
        proxy_buffering on;
        proxy_http_version 1.1;
        set $default_connection_header &quot;&quot;;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection $vs_connection_header;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Host $host;
        proxy_set_header X-Forwarded-Port $server_port;
        proxy_set_header X-Forwarded-Proto $scheme;

        proxy_pass https://vs_default_cafe_tea;
        proxy_next_upstream error timeout non_idempotent;
        proxy_next_upstream_timeout 5s;
        proxy_next_upstream_tries 10;   
    }   
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[k8s界面kubesphere安装]]></title>
        <id>https://tinaxiawuhao.github.io/post/ULtZ5rQXA/</id>
        <link href="https://tinaxiawuhao.github.io/post/ULtZ5rQXA/">
        </link>
        <updated>2022-05-30T06:18:50.000Z</updated>
        <content type="html"><![CDATA[<p><strong>在 Kubernetes 上安装 KubeSphere 3.2.1，您的 Kubernetes 版本必须为：1.19.x、1.20.x、1.21.x 或 1.22.x（实验性支持）</strong></p>
<h3 id="1-搭建nfs作为默认sc主节点作为服务器主节点操作">1 搭建NFS作为默认sc（（主节点作为服务器，主节点操作）</h3>
<h4 id="11-配置nfs服务器">1.1   配置NFS服务器</h4>
<pre><code class="language-shell">yum install -y nfs-utils rpcbind  &amp;&amp; echo &quot;/nfs *(insecure,rw,sync,no_root_squash)&quot; &gt; /etc/exports
</code></pre>
<h4 id="12-创建nfs服务器目录">1.2   创建nfs服务器目录</h4>
<pre><code class="language-shell">mkdir -p /nfs
</code></pre>
<h4 id="13-启动rpcbindnfs服务命令">1.3   启动rpcbind,nfs服务命令</h4>
<pre><code class="language-shell">systemctl restart rpcbind &amp;&amp; systemctl enable rpcbind
systemctl restart nfs-server &amp;&amp; systemctl enable nfs-server
</code></pre>
<h4 id="14-检查配置是否生效">1.4   检查配置是否生效</h4>
<pre><code class="language-shell">exportfs -r
exportfs
</code></pre>
<h4 id="15-测试pod直接挂载nfs了主节点操作">1.5   测试Pod直接挂载NFS了（主节点操作）</h4>
<h5 id="151-在opt目录下创建一个nginxyaml的文件">1.5.1     在opt目录下创建一个nginx.yaml的文件</h5>
<pre><code class="language-shell">vi nginx.yaml
</code></pre>
<h5 id="152-写入以下的命令">1.5.2     写入以下的命令</h5>
<pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata:
  name: vol-nfs
  namespace: default
spec:
  volumes:
  - name: html
    nfs:
      path: /nfs   
      server: 192.168.40.131 #自己的nfs服务器地址
  containers:
  - name: myapp
    image: nginx
    volumeMounts:
    - name: html
      mountPath: /usr/share/nginx/html/
</code></pre>
<h5 id="153-应用该yaml的pod服务">1.5.3     应用该yaml的pod服务</h5>
<pre><code class="language-shell">kubectl apply -f nginx.yaml
</code></pre>
<h5 id="154-检查该pod是否允许状态">1.5.4     检查该pod是否允许状态</h5>
<pre><code class="language-shell">kubectl get pod
</code></pre>
<pre><code class="language-shell">kubectl get pods -A
</code></pre>
<p>这里需要注意的是，必须等所有的状态为Runing才能进行下一步操作。</p>
<h3 id="2-搭建nfs-clientnode节点操作">2   搭建NFS-Client（node节点操作）</h3>
<p>服务器端防火墙开放111、662、875、892、2049的 tcp / udp 允许，否则远端客户无法连接。</p>
<h4 id="21-安装客户端工具">2.1  安装客户端工具</h4>
<pre><code class="language-shell">yum install -y nfs-utils rpcbind
showmount -e 192.168.40.131
</code></pre>
<p>该IP地址是master的IP地址</p>
<h4 id="22-创建同步文件夹">2.2  创建同步文件夹</h4>
<pre><code class="language-shell">mkdir /nfs/data/
</code></pre>
<h4 id="23-将客户端的nfsdata和nfs做同步node节点操作">2.3  将客户端的/nfs/data和/nfs/做同步（node节点操作）</h4>
<pre><code class="language-shell">mount -t nfs 192.168.40.131:/nfs/ /nfs/data/
</code></pre>
<p>192.168.40.131：是nfs的服务器的地址，这里是master的IP地址。</p>
<h3 id="3-设置动态供应">3   设置动态供应</h3>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1653892179794.png" alt="" loading="lazy"></figure>
<h4 id="31-创建provisionernfs环境前面已经搭好">3.1  创建provisioner（NFS环境前面已经搭好）</h4>
<table>
<thead>
<tr>
<th>字段名称</th>
<th>填入内容</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td>名称</td>
<td>nfs-storage</td>
<td>自定义存储类名称</td>
</tr>
<tr>
<td>NFS Server</td>
<td>192.168.40.131</td>
<td>NFS服务的IP地址</td>
</tr>
<tr>
<td>NFS Path</td>
<td>/nfs</td>
<td>NFS服务所共享的路径</td>
</tr>
</tbody>
</table>
<h5 id="311-先创建授权master节点操作">3.1.1   先创建授权（master节点操作）</h5>
<pre><code class="language-shell">vim nfs-rbac.yaml  #在opt目录下
</code></pre>
<p>新建内容如下：</p>
<pre><code class="language-yaml">---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: nfs-provisioner
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
   name: nfs-provisioner-runner
rules:
   -  apiGroups: [&quot;&quot;]
      resources: [&quot;persistentvolumes&quot;]
      verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;delete&quot;]
   -  apiGroups: [&quot;&quot;]
      resources: [&quot;persistentvolumeclaims&quot;]
      verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;update&quot;]
   -  apiGroups: [&quot;storage.k8s.io&quot;]
      resources: [&quot;storageclasses&quot;]
      verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]
   -  apiGroups: [&quot;&quot;]
      resources: [&quot;events&quot;]
      verbs: [&quot;watch&quot;, &quot;create&quot;, &quot;update&quot;, &quot;patch&quot;]
   -  apiGroups: [&quot;&quot;]
      resources: [&quot;services&quot;, &quot;endpoints&quot;]
      verbs: [&quot;get&quot;,&quot;create&quot;,&quot;list&quot;, &quot;watch&quot;,&quot;update&quot;]
   -  apiGroups: [&quot;extensions&quot;]
      resources: [&quot;podsecuritypolicies&quot;]
      resourceNames: [&quot;nfs-provisioner&quot;]
      verbs: [&quot;use&quot;]
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: run-nfs-provisioner
subjects:
  - kind: ServiceAccount
    name: nfs-provisioner
    namespace: default
roleRef:
  kind: ClusterRole
  name: nfs-provisioner-runner
  apiGroup: rbac.authorization.k8s.io
---
kind: Deployment
apiVersion: apps/v1
metadata:
   name: nfs-client-provisioner
spec:
   replicas: 1
   strategy:
     type: Recreate
   selector:
     matchLabels:
        app: nfs-client-provisioner
   template:
      metadata:
         labels:
            app: nfs-client-provisioner
      spec:
         serviceAccount: nfs-provisioner
         containers:
            -  name: nfs-client-provisioner
               image: lizhenliang/nfs-client-provisioner
               volumeMounts:
                 -  name: nfs-client-root
                    mountPath:  /persistentvolumes
               env:
                 -  name: PROVISIONER_NAME
                    value: storage.pri/nfs
                 -  name: NFS_SERVER
                    value: 192.168.40.131
                 -  name: NFS_PATH
                    value: /nfs
         volumes:
           - name: nfs-client-root
             nfs:
               server: 192.168.40.131
               path: /nfs
</code></pre>
<p>这个镜像中volume的mountPath默认为/persistentvolumes，不能修改，否则运行时会报错。ip的必须是自己的master的IP地址。</p>
<h5 id="312-执行创建nfs的yaml文件信息">3.1.2   执行创建nfs的yaml文件信息</h5>
<pre><code class="language-shell">kubectl apply -f nfs-rbac.yaml
</code></pre>
<h5 id="313-如果发现pod有问题想删除pod进行重新kubectl-apply-f-nfs-rbacyaml的话可以参照这个博客文档">3.1.3   如果发现pod有问题，想删除pod进行重新kubectl apply-f nfs-rbac.yaml的话，可以参照这个博客文档：</h5>
<p>https://blog.csdn.net/qq_43542988/article/details/101277263?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&amp;depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param</p>
<h5 id="314-查看pod的状态信息">3.1.4   查看pod的状态信息</h5>
<pre><code class="language-shell">kubectl get pods -A
# 如果报错：查看报错信息，这个命令：
kubectl describe pod xxx -n kube-system
</code></pre>
<h5 id="315-创建storageclassmaster节点操作">3.1.5   创建storageclass（master节点操作）</h5>
<pre><code class="language-yaml">vim storageclass-nfs.yaml
 
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: storage-nfs
provisioner: storage.pri/nfs
reclaimPolicy: Delete
</code></pre>
<h5 id="316-应用storageclass-nfsyaml文件">3.1.6   应用storageclass-nfs.yaml文件</h5>
<pre><code class="language-shell">kubectl apply -f storageclass-nfs.yaml
</code></pre>
<h5 id="317-修改默认的驱动">3.1.7   修改默认的驱动</h5>
<pre><code class="language-shell">kubectl patch storageclass storage-nfs -p '{&quot;metadata&quot;: {&quot;annotations&quot;:{&quot;storageclass.kubernetes.io/is-default-class&quot;:&quot;true&quot;}}}'
</code></pre>
<pre><code>kubectl get sc
</code></pre>
<h3 id="4-安装metrics-server">4   安装metrics-server</h3>
<h4 id="41-准备metrics-serveryaml文件主节点操作">4.1  准备metrics-server.yaml文件（主节点操作）</h4>
<pre><code class="language-shell">vim metrics-server.yaml
</code></pre>
<h4 id="42-编写以下的内容">4.2  编写以下的内容</h4>
<pre><code class="language-yaml">---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: system:aggregated-metrics-reader
  labels:
    rbac.authorization.k8s.io/aggregate-to-view: &quot;true&quot;
    rbac.authorization.k8s.io/aggregate-to-edit: &quot;true&quot;
    rbac.authorization.k8s.io/aggregate-to-admin: &quot;true&quot;
rules:
- apiGroups: [&quot;metrics.k8s.io&quot;]
  resources: [&quot;pods&quot;, &quot;nodes&quot;]
  verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: metrics-server:system:auth-delegator
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: system:auth-delegator
subjects:
- kind: ServiceAccount
  name: metrics-server
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: metrics-server-auth-reader
  namespace: kube-system
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: extension-apiserver-authentication-reader
subjects:
- kind: ServiceAccount
  name: metrics-server
  namespace: kube-system
---
apiVersion: apiregistration.k8s.io/v1
kind: APIService
metadata:
  name: v1beta1.metrics.k8s.io
spec:
  service:
    name: metrics-server
    namespace: kube-system
  group: metrics.k8s.io
  version: v1beta1
  insecureSkipTLSVerify: true
  groupPriorityMinimum: 100
  versionPriority: 100
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: metrics-server
  namespace: kube-system
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: metrics-server
  namespace: kube-system
  labels:
    k8s-app: metrics-server
spec:
  selector:
    matchLabels:
      k8s-app: metrics-server
  template:
    metadata:
      name: metrics-server
      labels:
        k8s-app: metrics-server
    spec:
      serviceAccountName: metrics-server
      volumes:
      # mount in tmp so we can safely use from-scratch images and/or read-only containers
      - name: tmp-dir
        emptyDir: {}
      containers:
      - name: metrics-server
        image: mirrorgooglecontainers/metrics-server-amd64:v0.3.6
        imagePullPolicy: IfNotPresent
        args:
          - --cert-dir=/tmp
          - --secure-port=4443
          - --kubelet-insecure-tls
          - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
        ports:
        - name: main-port
          containerPort: 4443
          protocol: TCP
        securityContext:
          readOnlyRootFilesystem: true
          runAsNonRoot: true
          runAsUser: 1000
        volumeMounts:
        - name: tmp-dir
          mountPath: /tmp
      nodeSelector:
        kubernetes.io/os: linux
        kubernetes.io/arch: &quot;amd64&quot;
---
apiVersion: v1
kind: Service
metadata:
  name: metrics-server
  namespace: kube-system
  labels:
    kubernetes.io/name: &quot;Metrics-server&quot;
    kubernetes.io/cluster-service: &quot;true&quot;
spec:
  selector:
    k8s-app: metrics-server
  ports:
  - port: 443
    protocol: TCP
    targetPort: main-port
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: system:metrics-server
rules:
- apiGroups:
  - &quot;&quot;
  resources:
  - pods
  - nodes
  - nodes/stats
  - namespaces
  - configmaps
  verbs:
  - get
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: system:metrics-server
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: system:metrics-server
subjects:
- kind: ServiceAccount
  name: metrics-server
  namespace: kube-system
</code></pre>
<h4 id="43-应用该文件pod">4.3  应用该文件pod</h4>
<pre><code class="language-shell">kubectl apply -f metrics-server.yaml
</code></pre>
<h4 id="44-查看部署的应用信息状态">4.4  查看部署的应用信息状态</h4>
<pre><code class="language-shell">kubectl get pod -A
</code></pre>
<h4 id="45-查看系统的监控状态">4.5  查看系统的监控状态</h4>
<pre><code class="language-shell">kubectl top nodes
 
如果运行kubectl top nodes这个命令，爆metrics not available yet 这个命令还没有用，那就稍等一会，就能用了
</code></pre>
<p>这里，kubesphere3.0的前置环境全部结束。</p>
<h2 id="5-安装kubesphere-v300">5 安装kubesphere v3.0.0</h2>
<h3 id="51-文档地址">5.1 文档地址</h3>
<pre><code class="language-shell">https://kubesphere.com.cn/
</code></pre>
<h3 id="152-部署文档地址">1.5.2 部署文档地址</h3>
<pre><code class="language-shell">https://kubesphere.com.cn/docs/quick-start/minimal-kubesphere-on-k8s/
</code></pre>
<h3 id="153-安装步骤说明master节点">1.5.3 安装步骤说明（master节点）</h3>
<h4 id="1531-安装集群配置文件">1.5.3.1   安装集群配置文件</h4>
<h5 id="15311-准备配置文件cluster-configurationyaml">1.5.3.1.1     准备配置文件cluster-configuration.yaml</h5>
<pre><code class="language-shell">vim cluster-configuration.yaml
</code></pre>
<h5 id="15312-编写以下的内容配置">1.5.3.1.2     编写以下的内容配置</h5>
<pre><code class="language-yaml">---
apiVersion: installer.kubesphere.io/v1alpha1
kind: ClusterConfiguration
metadata:
  name: ks-installer
  namespace: kubesphere-system
  labels:
    version: v3.2.1
spec:
  persistence:
    storageClass: &quot;&quot;        # If there is no default StorageClass in your cluster, you need to specify an existing StorageClass here.
  authentication:
    jwtSecret: &quot;&quot;           # Keep the jwtSecret consistent with the Host Cluster. Retrieve the jwtSecret by executing &quot;kubectl -n kubesphere-system get cm kubesphere-config -o yaml | grep -v &quot;apiVersion&quot; | grep jwtSecret&quot; on the Host Cluster.
  local_registry: &quot;&quot;        # Add your private registry address if it is needed.
  # dev_tag: &quot;&quot;               # Add your kubesphere image tag you want to install, by default it's same as ks-install release version.
  etcd:
    monitoring: false       # Enable or disable etcd monitoring dashboard installation. You have to create a Secret for etcd before you enable it.
    endpointIps: localhost  # etcd cluster EndpointIps. It can be a bunch of IPs here.
    port: 2379              # etcd port.
    tlsEnable: true
  common:
    core:
      console:
        enableMultiLogin: true  # Enable or disable simultaneous logins. It allows different users to log in with the same account at the same time.
        port: 30880
        type: NodePort
    # apiserver:            # Enlarge the apiserver and controller manager's resource requests and limits for the large cluster
    #  resources: {}
    # controllerManager:
    #  resources: {}
    redis:
      enabled: false
      volumeSize: 2Gi # Redis PVC size.
    openldap:
      enabled: false
      volumeSize: 2Gi   # openldap PVC size.
    minio:
      volumeSize: 20Gi # Minio PVC size.
    monitoring:
      # type: external   # Whether to specify the external prometheus stack, and need to modify the endpoint at the next line.
      endpoint: http://prometheus-operated.kubesphere-monitoring-system.svc:9090 # Prometheus endpoint to get metrics data.
      GPUMonitoring:     # Enable or disable the GPU-related metrics. If you enable this switch but have no GPU resources, Kubesphere will set it to zero. 
        enabled: false
    gpu:                 # Install GPUKinds. The default GPU kind is nvidia.com/gpu. Other GPU kinds can be added here according to your needs. 
      kinds:         
      - resourceName: &quot;nvidia.com/gpu&quot;
        resourceType: &quot;GPU&quot;
        default: true
    es:   # Storage backend for logging, events and auditing.
      # master:
      #   volumeSize: 4Gi  # The volume size of Elasticsearch master nodes.
      #   replicas: 1      # The total number of master nodes. Even numbers are not allowed.
      #   resources: {}
      # data:
      #   volumeSize: 20Gi  # The volume size of Elasticsearch data nodes.
      #   replicas: 1       # The total number of data nodes.
      #   resources: {}
      logMaxAge: 7             # Log retention time in built-in Elasticsearch. It is 7 days by default.
      elkPrefix: logstash      # The string making up index names. The index name will be formatted as ks-&lt;elk_prefix&gt;-log.
      basicAuth:
        enabled: false
        username: &quot;&quot;
        password: &quot;&quot;
      externalElasticsearchUrl: &quot;&quot;
      externalElasticsearchPort: &quot;&quot;
  alerting:                # (CPU: 0.1 Core, Memory: 100 MiB) It enables users to customize alerting policies to send messages to receivers in time with different time intervals and alerting levels to choose from.
    enabled: false         # Enable or disable the KubeSphere Alerting System.
    # thanosruler:
    #   replicas: 1
    #   resources: {}
  auditing:                # Provide a security-relevant chronological set of records，recording the sequence of activities happening on the platform, initiated by different tenants.
    enabled: false         # Enable or disable the KubeSphere Auditing Log System.
    # operator:
    #   resources: {}
    # webhook:
    #   resources: {}
  devops:                  # (CPU: 0.47 Core, Memory: 8.6 G) Provide an out-of-the-box CI/CD system based on Jenkins, and automated workflow tools including Source-to-Image &amp; Binary-to-Image.
    enabled: false             # Enable or disable the KubeSphere DevOps System.
    # resources: {}
    jenkinsMemoryLim: 2Gi      # Jenkins memory limit.
    jenkinsMemoryReq: 1500Mi   # Jenkins memory request.
    jenkinsVolumeSize: 8Gi     # Jenkins volume size.
    jenkinsJavaOpts_Xms: 512m  # The following three fields are JVM parameters.
    jenkinsJavaOpts_Xmx: 512m
    jenkinsJavaOpts_MaxRAM: 2g
  events:                  # Provide a graphical web console for Kubernetes Events exporting, filtering and alerting in multi-tenant Kubernetes clusters.
    enabled: false         # Enable or disable the KubeSphere Events System.
    # operator:
    #   resources: {}
    # exporter:
    #   resources: {}
    # ruler:
    #   enabled: true
    #   replicas: 2
    #   resources: {}
  logging:                 # (CPU: 57 m, Memory: 2.76 G) Flexible logging functions are provided for log query, collection and management in a unified console. Additional log collectors can be added, such as Elasticsearch, Kafka and Fluentd.
    enabled: false         # Enable or disable the KubeSphere Logging System.
    containerruntime: docker
    logsidecar:
      enabled: true
      replicas: 2
      # resources: {}
  metrics_server:                    # (CPU: 56 m, Memory: 44.35 MiB) It enables HPA (Horizontal Pod Autoscaler).
    enabled: false                   # Enable or disable metrics-server.
  monitoring:
    storageClass: &quot;&quot;                 # If there is an independent StorageClass you need for Prometheus, you can specify it here. The default StorageClass is used by default.
    # kube_rbac_proxy:
    #   resources: {}
    # kube_state_metrics:
    #   resources: {}
    # prometheus:
    #   replicas: 1  # Prometheus replicas are responsible for monitoring different segments of data source and providing high availability.
    #   volumeSize: 20Gi  # Prometheus PVC size.
    #   resources: {}
    #   operator:
    #     resources: {}
    #   adapter:
    #     resources: {}
    # node_exporter:
    #   resources: {}
    # alertmanager:
    #   replicas: 1          # AlertManager Replicas.
    #   resources: {}
    # notification_manager:
    #   resources: {}
    #   operator:
    #     resources: {}
    #   proxy:
    #     resources: {}
    gpu:                           # GPU monitoring-related plug-in installation. 
      nvidia_dcgm_exporter:        # Ensure that gpu resources on your hosts can be used normally, otherwise this plug-in will not work properly.
        enabled: false             # Check whether the labels on the GPU hosts contain &quot;nvidia.com/gpu.present=true&quot; to ensure that the DCGM pod is scheduled to these nodes.
        # resources: {}
  multicluster:
    clusterRole: none  # host | member | none  # You can install a solo cluster, or specify it as the Host or Member Cluster.
  network:
    networkpolicy: # Network policies allow network isolation within the same cluster, which means firewalls can be set up between certain instances (Pods).
      # Make sure that the CNI network plugin used by the cluster supports NetworkPolicy. There are a number of CNI network plugins that support NetworkPolicy, including Calico, Cilium, Kube-router, Romana and Weave Net.
      enabled: false # Enable or disable network policies.
    ippool: # Use Pod IP Pools to manage the Pod network address space. Pods to be created can be assigned IP addresses from a Pod IP Pool.
      type: none # Specify &quot;calico&quot; for this field if Calico is used as your CNI plugin. &quot;none&quot; means that Pod IP Pools are disabled.
    topology: # Use Service Topology to view Service-to-Service communication based on Weave Scope.
      type: none # Specify &quot;weave-scope&quot; for this field to enable Service Topology. &quot;none&quot; means that Service Topology is disabled.
  openpitrix: # An App Store that is accessible to all platform tenants. You can use it to manage apps across their entire lifecycle.
    store:
      enabled: false # Enable or disable the KubeSphere App Store.
  servicemesh:         # (0.3 Core, 300 MiB) Provide fine-grained traffic management, observability and tracing, and visualized traffic topology.
    enabled: false     # Base component (pilot). Enable or disable KubeSphere Service Mesh (Istio-based).
  kubeedge:          # Add edge nodes to your cluster and deploy workloads on edge nodes.
    enabled: false   # Enable or disable KubeEdge.
    cloudCore:
      nodeSelector: {&quot;node-role.kubernetes.io/worker&quot;: &quot;&quot;}
      tolerations: []
      cloudhubPort: &quot;10000&quot;
      cloudhubQuicPort: &quot;10001&quot;
      cloudhubHttpsPort: &quot;10002&quot;
      cloudstreamPort: &quot;10003&quot;
      tunnelPort: &quot;10004&quot;
      cloudHub:
        advertiseAddress: # At least a public IP address or an IP address which can be accessed by edge nodes must be provided.
          - &quot;&quot;            # Note that once KubeEdge is enabled, CloudCore will malfunction if the address is not provided.
        nodeLimit: &quot;100&quot;
      service:
        cloudhubNodePort: &quot;30000&quot;
        cloudhubQuicNodePort: &quot;30001&quot;
        cloudhubHttpsNodePort: &quot;30002&quot;
        cloudstreamNodePort: &quot;30003&quot;
        tunnelNodePort: &quot;30004&quot;
    edgeWatcher:
      nodeSelector: {&quot;node-role.kubernetes.io/worker&quot;: &quot;&quot;}
      tolerations: []
      edgeWatcherAgent:
        nodeSelector: {&quot;node-role.kubernetes.io/worker&quot;: &quot;&quot;}
        tolerations: []

</code></pre>
<p>endpointIps: 192.168.40.131：master节点的地址。</p>
<h5 id="15313-准备配置文件kubesphere-installeryaml">1.5.3.1.3     准备配置文件kubesphere-installer.yaml</h5>
<pre><code class="language-shell">vim kubesphere-installer.yaml
</code></pre>
<h5 id="15314-编写以下的内容配置">1.5.3.1.4    编写以下的内容配置</h5>
<pre><code class="language-yaml">---
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: clusterconfigurations.installer.kubesphere.io
spec:
  group: installer.kubesphere.io
  versions:
    - name: v1alpha1
      served: true
      storage: true
      schema:
        openAPIV3Schema:
          type: object
          properties:
            spec:
              type: object
              x-kubernetes-preserve-unknown-fields: true
            status:
              type: object
              x-kubernetes-preserve-unknown-fields: true
  scope: Namespaced
  names:
    plural: clusterconfigurations
    singular: clusterconfiguration
    kind: ClusterConfiguration
    shortNames:
      - cc

---
apiVersion: v1
kind: Namespace
metadata:
  name: kubesphere-system

---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: ks-installer
  namespace: kubesphere-system

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: ks-installer
rules:
- apiGroups:
  - &quot;&quot;
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - apps
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - extensions
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - batch
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - rbac.authorization.k8s.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - apiregistration.k8s.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - apiextensions.k8s.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - tenant.kubesphere.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - certificates.k8s.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - devops.kubesphere.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - monitoring.coreos.com
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - logging.kubesphere.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - jaegertracing.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - storage.k8s.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - admissionregistration.k8s.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - policy
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - autoscaling
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - networking.istio.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - config.istio.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - iam.kubesphere.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - notification.kubesphere.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - auditing.kubesphere.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - events.kubesphere.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - core.kubefed.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - installer.kubesphere.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - storage.kubesphere.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - security.istio.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - monitoring.kiali.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - kiali.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - networking.k8s.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - kubeedge.kubesphere.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - types.kubefed.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - monitoring.kubesphere.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - application.kubesphere.io
  resources:
  - '*'
  verbs:
  - '*'


---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: ks-installer
subjects:
- kind: ServiceAccount
  name: ks-installer
  namespace: kubesphere-system
roleRef:
  kind: ClusterRole
  name: ks-installer
  apiGroup: rbac.authorization.k8s.io

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ks-installer
  namespace: kubesphere-system
  labels:
    app: ks-install
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ks-install
  template:
    metadata:
      labels:
        app: ks-install
    spec:
      serviceAccountName: ks-installer
      containers:
      - name: installer
        image: kubesphere/ks-installer:v3.2.1
        imagePullPolicy: &quot;Always&quot;
        resources:
          limits:
            cpu: &quot;1&quot;
            memory: 1Gi
          requests:
            cpu: 20m
            memory: 100Mi
        volumeMounts:
        - mountPath: /etc/localtime
          name: host-time
          readOnly: true
      volumes:
      - hostPath:
          path: /etc/localtime
          type: &quot;&quot;
        name: host-time
</code></pre>
<h5 id="15315-分别执行两个文件">1.5.3.1.5     分别执行两个文件</h5>
<pre><code class="language-shell">kubectl apply -f kubesphere-installer.yaml
kubectl apply -f cluster-configuration.yaml
#或者直接用网络文件安装
kubectl apply -f https://github.com/kubesphere/ks-installer/releases/download/v3.2.1/kubesphere-installer.yaml
   
kubectl apply -f https://github.com/kubesphere/ks-installer/releases/download/v3.2.1/cluster-configuration.yaml
</code></pre>
<h5 id="15316-监控安装的日志信息">1.5.3.1.6     监控安装的日志信息</h5>
<pre><code class="language-shell">kubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l app=ks-install -o jsonpath='{.items[0].metadata.name}') -f
</code></pre>
<h5 id="15317-查看pod启动状态信息">1.5.3.1.7     查看pod启动状态信息</h5>
<pre><code class="language-shell">kubectl get pods -A
</code></pre>
<p>需要等待漫长的时间。</p>
<h3 id="154-访问验证是否安装成功">1.5.4 访问验证是否安装成功</h3>
<p>访问地址：</p>
<p>http://192.168.40.131:30880/login</p>
<p>帐号：admin</p>
<p>密码：P@88w0rd</p>
<h3 id="155-harbor目录下重新启动harbor">1.5.5 harbor目录下重新启动harbor</h3>
<pre><code class="language-shell">docker-compose stop
docker-compose up -d
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[harbor自建镜像仓库]]></title>
        <id>https://tinaxiawuhao.github.io/post/WOO39eqh2/</id>
        <link href="https://tinaxiawuhao.github.io/post/WOO39eqh2/">
        </link>
        <updated>2022-05-29T13:51:16.000Z</updated>
        <content type="html"><![CDATA[<h2 id="centos网络配置">centos网络配置</h2>
<h3 id="1设置主机名">1.设置主机名</h3>
<pre><code class="language-shell">[root@localhost ~]# hostnamectl  set-hostname harbor
</code></pre>
<h3 id="2添加-host-解析">2.添加 Host 解析</h3>
<pre><code class="language-shell">[root@harbor ~]# cat /etc/hosts
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
192.168.40.131 k8s-master
192.168.40.132 k8s-node1
192.168.40.133 k8s-node2
192.168.40.150 hub.test.com
</code></pre>
<p><strong>k8s 集群每个节点添加解析（注意：K8s 每个节点，不是 Harbor）</strong></p>
<pre><code class="language-shell">[root@k8s-master ~]# echo &quot;192.168.40.150 hub.test.com&quot; &gt;&gt; /etc/hosts
[root@k8s-node1 ~]# echo &quot;192.168.40.150 hub.test.com&quot; &gt;&gt; /etc/hosts
[root@k8s-node2 ~]# echo &quot;192.168.40.150 hub.test.com&quot; &gt;&gt; /etc/hosts
</code></pre>
<h3 id="3网络环境设置">3.网络环境设置</h3>
<pre><code class="language-shell">vi /etc/sysconfig/network-scripts/ifcfg-ens33 
</code></pre>
<p><strong>内容替换如下：</strong></p>
<pre><code class="language-shell">BOOTPROTO=static #静态连接
ONBOOT=yes #网络设备开机启动
IPADDR=192.168.40.150 
NETMASK=255.255.255.0 #子网掩码
GATEWAY=192.168.40.2 #网关
DNS1=114.114.114.114 #DNS解析
</code></pre>
<p><strong>网络服务重启</strong></p>
<pre><code class="language-shell">service network restart
</code></pre>
<h2 id="安装环境">安装环境</h2>
<h3 id="1安装docker-ce">1.安装Docker-CE</h3>
<pre><code class="language-shell"># 卸载旧版本
yum remove docker docker-client docker-client-latest docker-common docker-latest docker-latest-logrotate docker-logrotate docker-engine  
# 安装所需的软件包
yum install -y yum-utils device-mapper-persistent-data lvm2    
# 添加docker存储库
yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo     
#安装最新版的docker-ce
yum install -y docker-ce docker-ce-cli containerd.io    
#启动docker并设置为开机自启动
systemctl enable --now docker    
</code></pre>
<h3 id="2配置docker镜像加速器">2.配置Docker镜像加速器</h3>
<pre><code class="language-bash">tee /etc/docker/daemon.json &lt;&lt;-'EOF'
{
  &quot;registry-mirrors&quot;: [&quot;https://hub-mirror.c.163.com/&quot;],
  &quot;insecure-registries&quot;: [&quot;https://hub.test.com&quot;]
}
EOF
# 重启
systemctl daemon-reload &amp;&amp; systemctl restart docker
</code></pre>
<h3 id="3安装docker-compose">3.安装docker-compose</h3>
<pre><code class="language-shell">#1、安装pip
yum -y install epel-release
yum install python3-pip
pip3 install --upgrade pip
#2、安装docker-compose
pip3 install docker-compose
#3、查看版本
docker-compose version
</code></pre>
<h3 id="4创建-https-证书">4.创建 https 证书</h3>
<p><strong>安装 openssl</strong></p>
<pre><code class="language-shell">[root@harbor]# yum install openssl -y
</code></pre>
<p><strong>创建证书目录，并赋予权限</strong></p>
<pre><code class="language-shell">[root@harbor ~]# mkdir -p /cert/harbor
[root@harbor ~]# chmod -R 777 /cert/harbor
[root@harbor ~]# cd /cert/harbor
</code></pre>
<p><strong>创建服务器证书密钥文件 harbor.key</strong></p>
<pre><code class="language-shell">[root@harbor harbor]# openssl genrsa -des3 -out harbor.key 2048
</code></pre>
<blockquote>
<p>输入密码，确认密码，自己随便定义，但是要记住，后面会用到。</p>
</blockquote>
<p><strong>创建服务器证书的申请文件 harbor.csr</strong></p>
<pre><code class="language-shell">[root@harbor harbor]# openssl req -new -key harbor.key -out harbor.csr
</code></pre>
<blockquote>
<p>输入密钥文件的密码, 然后一路回车。</p>
</blockquote>
<p><strong>备份一份服务器密钥文件</strong></p>
<pre><code class="language-shell">[root@harbor harbor]# cp harbor.key harbor.key.org
</code></pre>
<p><strong>去除文件口令</strong></p>
<pre><code class="language-shell">[root@harbor harbor]# openssl rsa -in harbor.key.org -out harbor.key
</code></pre>
<blockquote>
<p>输入密钥文件的密码</p>
</blockquote>
<p><strong>创建一个自当前日期起为期十年的证书 harbor.crt</strong></p>
<pre><code class="language-shell">[root@harbor harbor]# openssl x509 -req -days 3650 -in harbor.csr -signkey harbor.key -out harbor.crt
</code></pre>
<h3 id="5下载harbor安装包并解压">5.下载Harbor安装包并解压</h3>
<blockquote>
<p>链接：https://pan.baidu.com/s/1AUEw0Qw3w9lZP-rnAYaWjA<br>
提取码：qutg</p>
</blockquote>
<pre><code class="language-shell">wget https://github.com/goharbor/harbor/releases/download/v2.5.0/harbor-offline-installer-v2.5.0.tgz
tar zxvf harbor-offline-installer-v2.5.0.tgz
</code></pre>
<h3 id="6配置harborcfg和安装harbor">6.配置harbor.cfg和安装Harbor</h3>
<pre><code class="language-bash">vi harbor.yml
</code></pre>
<blockquote>
<p>将http端口改成10086，因为默认用的80端口已经被占用，http可以指定任意端口；</p>
</blockquote>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1654235318168.png" alt="" loading="lazy"></figure>
<p>接下来运行install.sh安装和启动harbor</p>
<pre><code class="language-shell">./prepare
./install.sh
</code></pre>
<h3 id="7测试-harbor">7.测试 Harbor</h3>
<pre><code class="language-shell">[root@k8s-master01 ~]# docker login https://hub.test.com
Username: admin
Password: Harbor12345 # 默认密码，可通过 harbor.yml 配置文件修改
</code></pre>
<p><strong>登录时报：Error response from daemon: Get https://hub.test.com/v2/: x509: certificate is not valid for any names, but wanted to match hub.test.com</strong><br>
解决：修改客户端（即需要登陆harbor的机器）的docker.service 文件</p>
<pre><code class="language-shell">vi /lib/systemd/system/docker.service
添加 --insecure-registry hub.test.com 
</code></pre>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1654236299657.png" alt="" loading="lazy"></figure>
<p>重新加载服务配置文件，并且重启docker服务</p>
<pre><code class="language-shell">systemctl daemon-reload &amp;&amp; systemctl restart docker
</code></pre>
<p>下载镜像推送到 Harbor</p>
<pre><code class="language-shell">[root@k8s-node01 ~]# docker pull nginx
[root@k8s-node01 ~]# docker tag nginx:latest hub.test.com/library/test:v1
[root@k8s-node01 ~]# docker push hub.test.com/library/test:v1
</code></pre>
<h3 id="8windows-访问-harbor-web界面">8.Windows 访问 Harbor Web界面</h3>
<p><strong>Windows 添加 hosts 解析路径</strong></p>
<pre><code class="language-shell">C:\Windows\System32\drivers\etc\hosts
</code></pre>
<p><strong>添加信息</strong></p>
<pre><code class="language-shell">192.168.40.150 hub.test.com
</code></pre>
<p><strong>浏览器访问测试</strong></p>
<blockquote>
<p><a href="https://hub.test.com/harbor/projects">https://hub.test.com</a></p>
</blockquote>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1654235306601.png" alt="" loading="lazy"></figure>
<blockquote>
<p>用户密码：admin / Harbor12345</p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[k8s1.24.1安装（基于Centos 7）]]></title>
        <id>https://tinaxiawuhao.github.io/post/oqAZb-4wU/</id>
        <link href="https://tinaxiawuhao.github.io/post/oqAZb-4wU/">
        </link>
        <updated>2022-05-28T09:26:47.000Z</updated>
        <content type="html"><![CDATA[<p><strong>注意：除了Master节点初始化及Node节点添加分别在Master节点和Node节点执行外，其余所有命令均在所有节点执行</strong></p>
<h2 id="整体环境">整体环境</h2>
<p>一台master节点，2台<a href="https://so.csdn.net/so/search?q=node&amp;spm=1001.2101.3001.7020">node</a>节点。采用了Centos 7，有网络，互相可以ping通。</p>
<h3 id="1内核升级可忽略">1.内核升级（可忽略）</h3>
<p>为避免出现不可预知的问题，提升centos 7内核到最新版本</p>
<h4 id="联网升级内核">联网升级内核</h4>
<h5 id="1-查看内核版本">1. 查看内核版本</h5>
<pre><code class="language-shell">uname -r
</code></pre>
<h5 id="2-导入elrepo软件仓库的公共秘钥">2. 导入ELRepo软件仓库的公共秘钥</h5>
<pre><code class="language-shell">rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org
</code></pre>
<h5 id="3-安装elrepo软件仓库的yum源">3. 安装ELRepo软件仓库的yum源</h5>
<pre><code class="language-shell">rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm
</code></pre>
<h5 id="4-启用-elrepo-软件源并下载安装最新稳定版内核">4. 启用 elrepo 软件源并下载安装最新稳定版内核</h5>
<pre><code class="language-shell">yum --enablerepo=elrepo-kernel install kernel-ml -y
</code></pre>
<h5 id="5-查看系统可用内核并设置内核启动顺序">5. 查看系统可用内核，并设置内核启动顺序</h5>
<pre><code class="language-shell">sudo awk -F\' '$1==&quot;menuentry &quot; {print i++ &quot; : &quot; $2}' /etc/grub2.cfg
</code></pre>
<h5 id="6-生成-grub-配置文件">6. 生成 grub 配置文件</h5>
<p>机器上存在多个内核，我们要使用最新版本，可以通过 grub2-set-default 0 命令生成 grub 配置文件</p>
<pre><code class="language-shell">grub2-set-default 0 　　#初始化页面的第一个内核将作为默认内核
grub2-mkconfig -o /boot/grub2/grub.cfg　　#重新创建内核配置
</code></pre>
<h5 id="7-重启系统并验证">7. 重启系统并验证</h5>
<pre><code class="language-shell">yum update
reboot
uname -r
</code></pre>
<h5 id="8-删除旧内核">8. 删除旧内核</h5>
<pre><code class="language-shell">yum -y remove kernel kernel-tools
</code></pre>
<h3 id="2centos网络配置文件">2.centos网络配置文件</h3>
<p>网络配置文件名可能会有不同，在输入到ifcfg时，可以连续按两下tab键，获取提示，比如我的机器 为 ifcfg-ens33</p>
<pre><code class="language-shell">vi /etc/sysconfig/network-scripts/ifcfg-ens33 
</code></pre>
<h4 id="1内容替换如下">1.内容替换如下：</h4>
<pre><code class="language-shell">BOOTPROTO=static #静态连接
ONBOOT=yes #网络设备开机启动
IPADDR=192.168.40.131 #192.168.40.132,192.168.40.133.
NETMASK=255.255.255.0 #子网掩码
GATEWAY=192.168.40.2 #网关
DNS1=114.114.114.114 #DNS解析
</code></pre>
<h4 id="2网络服务重启">2.网络服务重启</h4>
<pre><code class="language-shell">service network restart
</code></pre>
<h4 id="3查看ip地址">3.查看IP地址</h4>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1653818770568.png" alt="" loading="lazy"></figure>
<h3 id="3安装依赖包">3.安装依赖包</h3>
<pre><code class="language-shell">yum install -y  wget 
</code></pre>
<h3 id="4修改yum源视网络情况操作">4.修改yum源（视网络情况操作）</h3>
<h4 id="1备份">1.备份</h4>
<pre><code class="language-shell">cp /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup
</code></pre>
<h4 id="2下载">2.下载</h4>
<pre><code class="language-shell">wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo
</code></pre>
<p>或者使用清华大学站</p>
<pre><code class="language-shell">sudo sed -e 's|^mirrorlist=|#mirrorlist=|g' -e 's|^#baseurl=http://mirror.centos.org/$contentdir|baseurl=https://mirrors.tuna.tsinghua.edu.cn/centos|g' -i.bak /etc/yum.repos.d/CentOS-Base.repo
</code></pre>
<h4 id="3清除生成缓存">3.清除生成缓存</h4>
<pre><code class="language-shell">yum clean all     # 清除系统所有的yum缓存
yum makecache     # 生成yum缓存
</code></pre>
<h3 id="5修改主机名">5.修改主机名</h3>
<pre><code class="language-shell">hostnamectl set-hostname k8s-master
hostnamectl set-hostname k8s-node1
hostnamectl set-hostname k8s-node2
</code></pre>
<h4 id="查看主机名称">查看主机名称</h4>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1653818810010.png" alt="" loading="lazy"></figure>
<h3 id="6添加hosts解析">6.添加hosts解析</h3>
<pre><code class="language-shell">echo -e &quot;192.168.40.131 k8s-master\n192.168.40.132 k8s-node1\n192.168.40.133 k8s-node2&quot; &gt;&gt; /etc/hosts
</code></pre>
<h3 id="7关闭防火墙firewalld">7.关闭防火墙firewalld</h3>
<pre><code class="language-shell">systemctl stop firewalld &amp;&amp; systemctl disable firewalld
</code></pre>
<h3 id="8关闭selinux">8.关闭selinux</h3>
<pre><code class="language-shell">setenforce 0 &amp;&amp; sed -i 's/^SELINUX=.*/SELINUX=disabled/' /etc/selinux/config
</code></pre>
<h3 id="9关闭swap分区交换">9.关闭swap分区交换</h3>
<pre><code class="language-shell">swapoff -a &amp;&amp; sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab
</code></pre>
<h3 id="10配置内核参数">10.配置内核参数</h3>
<p><strong>将桥接的IPv4流量传递倒iptables的链</strong></p>
<h4 id="1设置内核参数">1.设置内核参数</h4>
<pre><code class="language-shell">cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt;EOF
net.bridge.bridge-nf-call-iptables=1
net.bridge.bridge-nf-call-ip6tables=1
net.ipv4.ip_forward=1
net.ipv4.tcp_tw_recycle=0
vm.swappiness=0 # 禁止使用swap空间，只有当系统00M时才允许使用它
vm.overcommit_memory=1 # 不检查物理内存是否够用
vm.panic_on_oom=0 # 开启oom
fs.inotify.max_user_instances=8192
fs.inotify.max_user_watches=1048576
fs.file-max=52786963
fs.nr_open=52706963
net.ipv6.conf.all.disable_ipv6=1
net.netfilter.nf_conntrack_max=2310720
EOF
</code></pre>
<h4 id="2加载内核模块">2.加载内核模块</h4>
<pre><code class="language-shell">modprobe br_netfilter &amp;&amp; echo &quot;modprobe br_netfilter&quot; &gt;&gt; /etc/rc.local
</code></pre>
<h4 id="3使内核参数生效">3.使内核参数生效</h4>
<pre><code class="language-shell">sysctl -p /etc/sysctl.d/k8s.conf
</code></pre>
<h3 id="11时间同步">11.时间同步</h3>
<pre><code class="language-shell">timedatectl set-timezone Asia/Shanghai &amp;&amp; timedatectl set-local-rtc 0
#重启依赖于系统时间的服务 
systemctl restart rsyslog &amp;&amp; systemctl restart crond
</code></pre>
<h3 id="12安装iptables设置空表">12.安装iptables，设置空表</h3>
<pre><code class="language-shell">yum -y install iptables-services &amp;&amp; systemctl start iptables &amp;&amp; systemctl enable iptables &amp;&amp; iptables -F &amp;&amp; service iptables save
</code></pre>
<p>检查服务的的规则：<code>iptables -L -n</code></p>
<h3 id="13开启ipvs">13.开启IPVS</h3>
<p><strong>由于ipvs已经加入到了内核的主干，所以为kube-proxy开启ipvs的前提需要加载以下的内核模块</strong></p>
<pre><code class="language-shell">cat &gt; /etc/sysconfig/modules/ipvs.modules &lt;&lt;EOF
#！/bin/bash
modprobe -- ip_vs
modprobe -- ip_vs_rr
modprobe -- ip_vs_wrr
modprobe -- ip_vs_sh
modprobe -- nf_conntrack_ipv4
EOF
</code></pre>
<h4 id="授权启动">授权启动</h4>
<pre><code class="language-shell">chmod 755 /etc/sysconfig/modules/ipvs.modules &amp;&amp; bash /etc/sysconfig/modules/ipvs.modules &amp;&amp; lsmod 
</code></pre>
<p><strong>接下来还需要确保各个节点上已经安装了ipset软件包。 为了便于查看ipvs的代理规则，最好安装一下管理工具ipvsadm。</strong></p>
<pre><code class="language-shell">yum install ipset ipvsadm -y
</code></pre>
<blockquote>
<p>service底层实现主要由两个网络模式组成：iptables与IPVS。他们都是有kube-proxy维护</p>
<p><strong>Iptables VS IPVS</strong></p>
<p><strong>Iptables：</strong></p>
<p><strong>• 灵活，功能强大</strong></p>
<p><strong>• 规则遍历匹配和更新，呈线性时延</strong></p>
<p><strong>IPVS：</strong></p>
<p><strong>• 工作在内核态，有更好的性能</strong></p>
<p><strong>• 调度算法丰富：rr，wrr，lc，wlc，ip hash</strong></p>
</blockquote>
<p>等集群部署成功，mode由空值修改成ipvs模式</p>
<pre><code>kubectl edit configmap kube-proxy -n kube-system configmap/kube-proxy edited
</code></pre>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1654316987021.png" alt="" loading="lazy"></figure>
<p><strong>删除所有kube-proxy的pod,等待重启</strong></p>
<pre><code>kubectl delete pod/kube-proxy-84p9n -n kube-system
# 查看ipvs相关规则
ipvsadm
</code></pre>
<h3 id="14安装docker软件">14.安装docker软件</h3>
<blockquote>
<p>自1.20版本被弃用之后，dockershim组件终于在1.24的kubelet中被删除。从1.24开始，大家需要使用其他受到支持的运行时选项（例如containerd或CRI-O）；如果您选择Docker Engine作为运行时，则需要使用cri-dockerd。</p>
</blockquote>
<h4 id="1删除自带的docker">1.删除自带的docker</h4>
<pre><code class="language-shell">yum remove docker \
                  docker-client \
                  docker-client-latest \
                  docker-common \
                  docker-latest \
                  docker-latest-logrotate \
                  docker-logrotate \
                  docker-selinux \
                  docker-engine-selinux \
                  docker-engine
</code></pre>
<h4 id="2安装依赖包">2.安装依赖包</h4>
<pre><code class="language-shell">yum install -y yum-utils device-mapper-persistent-data lvm2
</code></pre>
<h4 id="3安装yum源">3.安装yum源</h4>
<pre><code class="language-shell">yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
</code></pre>
<h4 id="4安装docker-ce">4.安装docker-ce</h4>
<pre><code class="language-shell">yum -y install docker-ce
</code></pre>
<h4 id="5设置docker">5.设置docker</h4>
<pre><code class="language-shell">cat &gt; /etc/docker/daemon.conf &lt;&lt;EOF
{
  &quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;,&quot;https://heusyzko.mirror.aliyuncs.com&quot;],
  &quot;insecure-registries&quot;: [&quot;https://hub.test.com&quot;],
  &quot;exec-opts&quot;:[&quot;native.cgroupdriver=systemd&quot;],
  &quot;log-driver&quot;:&quot;json-file&quot;,
  &quot;log-opts&quot;:{
    &quot;max-size&quot;: &quot;100m&quot;
    },
    &quot;storage-driver&quot;: &quot;overlay2&quot;
}
EOF

mkdir -p /etc/systemd/system/docker.service.d 
</code></pre>
<h4 id="6重启docker服务">6.重启docker服务</h4>
<pre><code class="language-shell">systemctl daemon-reload &amp;&amp; systemctl start docker &amp;&amp; systemctl enable docker
systemctl daemon-reload &amp;&amp; systemctl restart docker 
</code></pre>
<p>以下的NO_PROXY表示对这些网段的服务器不使用代理，如果不需要用到代理服务器，以下的配置可以不写，注意，以下的代理是不通的。不建议使用代理，因为国内有资源可以访问到gcr.io需要的镜像，下文会介绍</p>
<pre><code class="language-shell">#放在Type=notify下面
vi /usr/lib/systemd/system/docker.service
Environment=&quot;HTTPS_PROXY=http://www.ik8s.io:10080&quot;
Environment=&quot;HTTP_PROXY=http://www.ik8s.io:10080&quot;
Environment=&quot;NO_PROXY=127.0.0.0/8,172.20.0.0/16&quot;
#保存退出后，执行
systemctl  daemon-reload
#确保如下两个参数值为1，默认为1。
 cat /proc/sys/net/bridge/bridge-nf-call-ip6tables
 cat /proc/sys/net/bridge/bridge-nf-call-iptables
#启动docker-ce
systemctl restart docker
#设置开机启动
systemctl enable docker.service
</code></pre>
<pre><code class="language-shell">#想要删除容器，则要先停止所有容器（当然，也可以加-f强制删除，但是不推荐）：
docker stop $(docker ps -a -q)
#删除所有容器
docker  rm $(docker ps -a -q)
#.删除所有镜像（慎重）
docker rmi $(docker images -q)
</code></pre>
<h3 id="142cri-dockerd安装">14.2.cri-dockerd安装</h3>
<p><strong>CRI-Dockerd 其实就是从被移除的 Docker Shim 中，独立出来的一个项目，用于解决历史遗留的节点升级 Kubernetes 的问题。</strong></p>
<blockquote>
<p>kubelet并没有直接和dockerd交互，而是通过了一个dockershim的组件间接操作dockerd。dockershim提供了一个标准的接口，让kubelet能够专注于容器调度逻辑本身，而不用去适配dockerd的接口变动。而其他实现了相同标准接口的容器技术也可以被kubelet集成使用，这个接口称作CRI。dockershim和CRI的出现也是容器生态系统演化的历史产物。在k8s最早期的版本中是不存在dockershim的，kubelet直接和dockerd交互。但为了支持更多不同的容器技术（避免完全被docker控制容器技术市场），kubelet在之后的版本开始支持另一种容器技术rkt。这给kubelet的维护工作造成了巨大的挑战，因为两种容器技术没有统一的接口和使用逻辑，kubelet同时支持两种技术的使用还要保证一致的容器功能表现，对代码逻辑和功能可靠性都有很大的影响。为了解决这个问题，k8s提出了一个统一接口CRI，kubelet统一通过这个接口来调用容器功能。但是dockerd并不支持CRI，k8s就自己实现了配套的dockershim将CRI接口调用转换成dockerd接口调用来支持CRI。因此，dockershim并不是docker技术的一部分，而是k8s系统的一部分</p>
</blockquote>
<p><strong>使用 CRI-Dockerd 项目</strong></p>
<pre><code class="language-html">项目地址：https://github.com/Mirantis/cri-dockerd
</code></pre>
<h4 id="1下载cri-dockerd二进制包或者源码自己编译">1.下载cri-dockerd二进制包或者源码自己编译</h4>
<pre><code class="language-shell"># 下载文件
wget https://github.com/Mirantis/cri-dockerd/releases/download/v0.2.0/cri-dockerd-v0.2.0-linux-amd64.tar.gz
# 解压文件
tar -xvf cri-dockerd-v0.2.0-linux-amd64.tar.gz
# 复制二进制文件到指定目录
cp cri-dockerd /usr/bin/
</code></pre>
<h4 id="2配置启动文件">2.配置启动文件</h4>
<pre><code class="language-shell"># 配置启动文件
cat &lt;&lt;&quot;EOF&quot; &gt; /usr/lib/systemd/system/cri-docker.service
[Unit]
Description=CRI Interface for Docker Application Container Engine
Documentation=https://docs.mirantis.com
After=network-online.target firewalld.service docker.service
Wants=network-online.target
Requires=cri-docker.socket

[Service]
Type=notify

ExecStart=/usr/bin/cri-dockerd --container-runtime-endpoint=unix:///var/run/cri-docker.sock --network-plugin=cni --cni-bin-dir=/opt/cni/bin \
          --cni-conf-dir=/etc/cni/net.d --image-pull-progress-deadline=30s --pod-infra-container-image=registry.aliyuncs.com/google_containers/pause:3.7 \
          --docker-endpoint=unix:///var/run/docker.sock --cri-dockerd-root-directory=/var/lib/docker
ExecReload=/bin/kill -s HUP $MAINPID
TimeoutSec=0
RestartSec=2
Restart=always

# Note that StartLimit* options were moved from &quot;Service&quot; to &quot;Unit&quot; in systemd 229.
# Both the old, and new location are accepted by systemd 229 and up, so using the old location
# to make them work for either version of systemd.
StartLimitBurst=3

# Note that StartLimitInterval was renamed to StartLimitIntervalSec in systemd 230.
# Both the old, and new name are accepted by systemd 230 and up, so using the old name to make
# this option work for either version of systemd.
StartLimitInterval=60s

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Comment TasksMax if your systemd version does not support it.
# Only systemd 226 and above support this option.
TasksMax=infinity
Delegate=yes
KillMode=process

[Install]
WantedBy=multi-user.target

EOF
</code></pre>
<pre><code class="language-shell"># 生成socket 文件
cat &lt;&lt;&quot;EOF&quot; &gt; /usr/lib/systemd/system/cri-docker.socket
[Unit]
Description=CRI Docker Socket for the API
PartOf=cri-docker.service

[Socket]
ListenStream=/var/run/cri-dockerd.sock
SocketMode=0660
SocketUser=root
SocketGroup=docker

[Install]
WantedBy=sockets.target

EOF
</code></pre>
<pre><code class="language-shell"># 启动 cri-dockerd
systemctl daemon-reload
systemctl start cri-docker
#设置开机启动
systemctl enable cri-docker
# 查看启动状态
systemctl status cri-docker
</code></pre>
<h4 id="3下载cri-tools验证cri-docker-是否正常">3.下载cri-tools验证cri-docker 是否正常</h4>
<pre><code class="language-shell"># 下载二进制文件
wget https://github.com/kubernetes-sigs/cri-tools/releases/download/v1.24.0/crictl-v1.24.0-linux-amd64.tar.gz
# 解压
tar -xvf crictl-v1.24.0-linux-amd64.tar.gz
# 复制二进制文件到指定目录
cp crictl /usr/bin/
# 创建配置文件
vim /etc/crictl.yaml
runtime-endpoint: &quot;unix:///var/run/cri-docker.sock&quot;
image-endpoint: &quot;unix:///var/run/cri-docker.sock&quot;
timeout: 10
debug: false
pull-image-on-create: true
disable-pull-on-run: false
# 测试能否访问docker
# 查看运行的容器
crictl ps
# 查看拉取的镜像
 crictl images
 # 拉取镜像
 crictl pull busybox
 [root@k8s-node-4 ~]# crictl pull busybox
Image is up to date for busybox@sha256:5ecba83a746c7608ed511dc1533b87c737a0b0fb730301639a0179f9344b13448
返回一切正常cri-dockerd接入docker完整
</code></pre>
<h3 id="15部署-containerdk8s-124版本以上">15.部署 containerd(k8s-1.24版本以上)</h3>
<p><strong>服务版本</strong></p>
<table>
<thead>
<tr>
<th>服务名称</th>
<th>版本号</th>
</tr>
</thead>
<tbody>
<tr>
<td>内核</td>
<td>5.14.3-1.el7.elrepo.x86_64</td>
</tr>
<tr>
<td>containerd</td>
<td>v1.6.4（加入）</td>
</tr>
<tr>
<td>ctr</td>
<td>v1.6.4</td>
</tr>
<tr>
<td>k8s</td>
<td>1.24</td>
</tr>
</tbody>
</table>
<h4 id="1安装containerd">1.安装containerd</h4>
<p><strong>创建配置文件</strong></p>
<pre><code class="language-shell">mkdir /etc/modules-load.d/containerd.conf 
</code></pre>
<p><strong>创建完配置文件执行以下命令</strong></p>
<pre><code class="language-shell">modprobe overlay &amp;&amp; modprobe br_netfilter
</code></pre>
<p><strong>立即生效</strong></p>
<pre><code class="language-shell">sysctl --system
</code></pre>
<p><strong>下载 docker-ce 源</strong></p>
<pre><code class="language-shell">wget http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
或者
yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
</code></pre>
<p><strong>安装 containerd 服务并加入开机启动</strong></p>
<pre><code class="language-shell">yum install -y containerd.io
systemctl enable containerd &amp;&amp; systemctl start containerd
</code></pre>
<h4 id="2配置-containerd">2.配置 containerd</h4>
<p><strong>创建路径</strong></p>
<pre><code class="language-shell">mkdir -p /etc/containerd
</code></pre>
<p><strong>获取默认配置文件</strong></p>
<pre><code class="language-shell">containerd config default | sudo tee /etc/containerd/config.toml
</code></pre>
<p><strong>修改配置文件，新增 &quot;SystemdCgroup = true&quot;，使用 systemd 作为 cgroup 驱动程序</strong></p>
<pre><code class="language-shell">[root@master1 ~]# vi /etc/containerd/config.toml 
#修改以下内容
[plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.runc.options]
     SystemdCgroup = true                               ## 修改为true
</code></pre>
<p><strong>替换默认pause镜像地址</strong></p>
<p>默认情况下k8s.gcr.io无法访问，所以使用阿里云镜像仓库地址即可</p>
<pre><code class="language-shell"># 所有节点更换默认镜像地址
sed -i 's/k8s.gcr.io/registry.cn-beijing.aliyuncs.com\/abcdocker/' /etc/containerd/config.toml 
</code></pre>
<p><strong>重启 containerd</strong></p>
<pre><code class="language-shell">systemctl restart containerd
</code></pre>
<p><strong>查看 containerd 运行状态(以下状态视为正常)</strong></p>
<pre><code class="language-shell">[root@master1 ~]# systemctl status containerd
● containerd.service - containerd container runtime
   Loaded: loaded (/usr/lib/systemd/system/containerd.service; enabled; vendor preset: disabled)
   Active: active (running) since Sun 2022-03-06 08:09:00 CST; 1h 43min ago
     Docs: https://containerd.io
  Process: 931 ExecStartPre=/sbin/modprobe overlay (code=exited, status=0/SUCCESS)
 Main PID: 941 (containerd)
    Tasks: 11
   Memory: 61.4M
   CGroup: /system.slice/containerd.service
           └─941 /usr/bin/containerd
</code></pre>
<h3 id="16安装kubeadm-kubelet-kubectl">16.安装kubeadm、kubelet、kubectl</h3>
<h4 id="1配置文件修改">1.配置文件修改</h4>
<pre><code class="language-shell">cat &lt;&lt;EOF | sudo tee /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=0
repo_gpgcheck=0
gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF
</code></pre>
<h4 id="2安装启用">2.安装启用</h4>
<pre><code class="language-shell">sudo yum install -y kubelet-1.24.1 kubeadm-1.24.1 kubectl-1.24.1 --disableexcludes=kubernetes 
sudo systemctl enable kubelet &amp;&amp; systemctl start kubelet
</code></pre>
<h4 id="3修改kubelet的配置文件">3.修改kubelet的配置文件</h4>
<p>先查看配置文件位置</p>
<pre><code class="language-shell">systemctl status kubelet
</code></pre>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1653818855680.png" alt="" loading="lazy"></figure>
<pre><code class="language-shell">vi /usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf
</code></pre>
<p>并添加以下内容(使用和docker相同的cgroup-driver)。</p>
<pre><code class="language-shell">Environment=&quot;KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --cgroup-driver=systemd&quot;
</code></pre>
<h4 id="4重启kubelet">4.重启kubelet</h4>
<pre><code class="language-shell">systemctl daemon-reload &amp;&amp; systemctl restart kubelet
</code></pre>
<h3 id="17获取k8s镜像可忽略">17.获取K8S镜像（可忽略）</h3>
<h4 id="1获取镜像列表">1.获取镜像列表</h4>
<p><strong>使用阿里云镜像仓库下载（国内环境该命令可不执行，下步骤kubeadm init --image-repository registry.cn-hangzhou.aliyuncs.com/google_containers已经默认为国内环境）</strong></p>
<p>由于官方镜像地址被墙，所以我们需要首先获取所需镜像以及它们的版本。然后从国内镜像站获取。</p>
<pre><code class="language-bash">kubeadm config images list
</code></pre>
<p>获取镜像列表后可以通过下面的脚本从阿里云获取：</p>
<pre><code class="language-shell">vi /usr/local/k8s/k8s-images.sh
</code></pre>
<blockquote>
<p>下面的镜像应该去除&quot;k8s.gcr.io/&quot;的前缀，版本换成上面获取到的版本</p>
</blockquote>
<pre><code class="language-bash">images=(  
    kube-apiserver:v1.24.1
    kube-controller-manager:v1.24.1
    kube-scheduler:v1.24.1
    kube-proxy:v1.24.1
    pause:3.7
    etcd:3.5.3-0
    coredns:v1.8.6
)

for imageName in ${images[@]} ; do
    docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName
    docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName k8s.gcr.io/$imageName
    docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName
done
</code></pre>
<h4 id="2赋权执行">2.赋权执行</h4>
<pre><code class="language-shell">chmod +x k8s-images.sh &amp;&amp; ./k8s-images.sh
</code></pre>
<p><strong>以上操作在所有机器执行</strong></p>
<h3 id="18初始化环境master操作">18.初始化环境（master操作）</h3>
<h4 id="1安装镜像">1.安装镜像</h4>
<p><strong>采用模板配置文件加载</strong></p>
<pre><code class="language-shell">kubeadm config print init-defaults  &gt; kubeadm-config.yaml
</code></pre>
<pre><code class="language-yaml">
[root@master1 ~]# cat kubeadm-config.yaml 
apiVersion: kubeadm.k8s.io/v1beta2
bootstrapTokens:
- groups:
  - system:bootstrappers:kubeadm:default-node-token
  token: abcdef.0123456789abcdef
  ttl: 24h0m0s
  usages:
  - signing
  - authentication
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 192.168.40.131    # 本机IP
  bindPort: 6443
nodeRegistration:
  criSocket: unix:///var/run/cri-docker.sock  # 此处千万不要忘记修改，如果不修改等于没有替换。(此处已经更改完了)
  #criSocket: unix:///run/containerd/containerd.sock      # 此处千万不要忘记修改，如果不修改等于没有替换。(此处已经更改完了)
  name: master1        # 本主机名
  taints:
  - effect: NoSchedule
    key: node-role.kubernetes.io/master
---
apiServer:
  timeoutForControlPlane: 4m0s
apiVersion: kubeadm.k8s.io/v1beta2
certificatesDir: /etc/kubernetes/pki
clusterName: kubernetes
controlPlaneEndpoint: &quot;192.168.40.151:16443&quot;      # 虚拟IP和haproxy端口
controllerManager: {}
dns:
  type: CoreDNS
etcd:
  local:
    dataDir: /var/lib/etcd
imageRepository: registry.aliyuncs.com/google_containers    # 镜像仓库源要根据自己实际情况修改
kind: ClusterConfiguration
kubernetesVersion: v1.24.1     # k8s版本
networking:
  dnsDomain: cluster.local
  podSubnet: &quot;10.244.0.0/16&quot;   #设置网段，和下面网络插件对应
  serviceSubnet: 10.96.0.0/12
scheduler: {}
 
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
featureGates:
  SupportIPVSProxyMode: true
mode: ipvs
</code></pre>
<h4 id="2查看kubeadm版本修改命令参数">2.查看kubeadm版本，修改命令参数</h4>
<pre><code class="language-shell">kubeadm version
</code></pre>
<p>这个就很简单了，只需要简单的一个命令：</p>
<pre><code class="language-bash">#直接使用已经下载好的镜像
kubeadm init --kubernetes-version=v1.24.1 --apiserver-advertise-address=192.168.40.131 --pod-network-cidr=10.244.0.0/16 --service-cidr=10.96.0.0/12 --ignore-preflight-errors=Swap  --cri-socket unix:///var/run/cri-docker.sock | tee kubeadm-init.log
#或者采用aliyuncs镜像下载
kubeadm init --kubernetes-version=v1.24.1 --apiserver-advertise-address=192.168.40.131 --image-repository  registry.aliyuncs.com/google_containers  --service-cidr=10.1.0.0/16 --pod-network-cidr=10.244.0.0/16 --cri-socket unix:///var/run/cri-docker.sock| tee kubeadm-init.log
#使用上面系统生成配置文件加载
kubeadm init --config kubeadm-config.yaml
</code></pre>
<h4 id="3初始化命令说明">3.初始化命令说明：</h4>
<blockquote>
<p>指明用 Master 的哪个 interface 与 Cluster 的其他节点通信。如果 Master 有多个 interface，建议明确指定，如果不指定，kubeadm 会自动选择有默认网关的 interface。</p>
</blockquote>
<pre><code class="language-bash">--apiserver-advertise-address
</code></pre>
<blockquote>
<p>指定 Pod 网络的范围。Kubernetes 支持多种网络方案，而且不同网络方案对 --pod-network-cidr 有自己的要求，这里设置为 10.244.0.0/16 是因为我们将使用 flannel 网络方案，必须设置成这个 CIDR。</p>
</blockquote>
<pre><code class="language-bash">--pod-network-cidr
</code></pre>
<blockquote>
<p>Kubenetes默认Registries地址是 k8s.gcr.io，在国内并不能访问 gcr.io，在1.19.3版本中我们可以增加–image-repository参数，默认值是 k8s.gcr.io，将其指定为阿里云镜像地址：registry.aliyuncs.com/google_containers。</p>
</blockquote>
<pre><code class="language-bash">--image-repository
</code></pre>
<blockquote>
<p>关闭版本探测，因为它的默认值是stable-1，会导致从https://dl.k8s.io/release/stable-1.txt下载最新的版本号，我们可以将其指定为固定版本（最新版：v1.24.1）来跳过网络请求。</p>
</blockquote>
<pre><code class="language-bash">--kubernetes-version=v1.24.1 
</code></pre>
<blockquote>
<p>指定启动时使用cri-docker调用docker</p>
</blockquote>
<pre><code class="language-shell">--cri-socket unix:///var/run/cri-docker.sock 
</code></pre>
<h4 id="4错误启动重置">4.错误启动重置</h4>
<pre><code class="language-shell"># 重置 如果有需要
kubeadm reset --cri-socket unix:///var/run/cri-docker.sock
</code></pre>
<h4 id="5初始化成功后为顺利使用kubectl执行以下命令">5.初始化成功后，为顺利使用kubectl，执行以下命令：</h4>
<pre><code class="language-shell">mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
</code></pre>
<h4 id="6添加节点">6.添加节点</h4>
<pre><code class="language-shell">kubeadm join 192.168.40.131:6443 --token eyr8v6.j84sxak8aptse8j9 --discovery-token-ca-cert-hash sha256:c082f3c546bdbac02d0d0a3b696de4004b0d449e37838fa38d4752b39682676b --cri-socket unix:///var/run/cri-docker.sock 
</code></pre>
<h4 id="7执行kubectl-get-nodes查看master节点状态">7.执行kubectl get nodes，查看master节点状态：</h4>
<pre><code class="language-shell">kubectl get node
</code></pre>
<h4 id="8通过如下命令查看kubelet状态">8.通过如下命令查看kubelet状态：</h4>
<pre><code class="language-bash">journalctl -xef -u kubelet -n 20
</code></pre>
<p>提示未安装cni 网络插件。</p>
<h3 id="191安装flannel网络插件cni">19.1安装flannel网络插件(CNI)</h3>
<p>master执行以下命令安装flannel即可：</p>
<pre><code class="language-shell">kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
</code></pre>
<p>kube-flannel.yaml文件中的net-conf.json-&gt;Network地址默认为命令中–pod-network-cidr=值相同</p>
<p><strong>输入命令kubectl get pods -n kube-system,等待所有插件为running状态</strong>。</p>
<p><strong>待所有pod status为Running的时候，再次执行kubectl get nodes：</strong></p>
<pre><code class="language-shell">[root@k8s-master ~]# kubectl get node
NAME         STATUS   ROLES    AGE   VERSION
k8s-master   Ready    master   16m   v1.19.3
</code></pre>
<p><strong>如上所示，master状态变为，表明Master节点部署成功！</strong></p>
<h3 id="192安装calico网络功能更完善">19.2安装calico网络(功能更完善)</h3>
<h4 id="1在master上下载配置calico网络的yaml">1.在master上下载配置calico网络的yaml。</h4>
<pre><code class="language-shell">kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml
</code></pre>
<h4 id="2提前下载所需要的镜像">2.提前下载所需要的镜像。</h4>
<pre><code class="language-shell"># 查看此文件用哪些镜像：
[root@k8s-master ~]# grep image calico.yaml
image: docker.io/calico/cni:v3.23.1
image: docker.io/calico/node:v3.23.1
image: docker.io/calico/kube-controllers:v3.23.1
</code></pre>
<h4 id="3安装calico网络">3.安装calico网络。</h4>
<p>在master上执行如下命令：</p>
<pre><code class="language-csharp">kubectl apply -f calico.yaml
</code></pre>
<h4 id="5验证结果">5.验证结果。</h4>
<p>再次在master上运行命令 kubectl get nodes查看运行结果：</p>
<pre><code class="language-css">[root@k8s-master ~]# kubectl get nodes
NAME       STATUS   ROLES                  AGE   VERSION
master01   Ready    control-plane,master   21h   v1.23.4
worker01   Ready    &lt;none&gt;                 16h   v1.23.4
worker02   Ready    &lt;none&gt;                 16h   v1.23.4
</code></pre>
<h3 id="20部署k8s-node1-k8s-node2集群">20.部署k8s-node1、k8s-node2集群</h3>
<p><strong>1、在k8s-node1、k8s-node2等两台虚拟机中重复执行上面的步骤，安装好docker、kubelet、kubectl、kubeadm。</strong></p>
<h4 id="1node节点加入集群">1.node节点加入集群</h4>
<p>在上面第初始化master节点成功后，输出了下面的kubeadm join命令：</p>
<pre><code class="language-shell">kubeadm join 192.168.40.131:6443 --token zj0u08.ge77y7uv76flqgdk --discovery-token-ca-cert-hash sha256:7cd23cec6afb192b2d34c5c719b378082a6315a9d91a22d91b83066c870d4db5 --cri-socket unix:///var/run/cri-docker.sock 
</code></pre>
<p>该命令就是node加入集群的命令，分别在k8s-node1、k8s-node2上执行该命令加入集群。</p>
<p>如果忘记该命令，可以通过以下命令重新生成：</p>
<pre><code class="language-shell">kubeadm token create --print-join-command
</code></pre>
<h4 id="2在master节点执行下面命令查看集群状态">2.在master节点执行下面命令查看集群状态：</h4>
<pre><code class="language-shell">kubectl get nodes
</code></pre>
<pre><code class="language-shell">[root@k8s-master ~]# kubectl get node
NAME         STATUS   ROLES    AGE     VERSION
k8s-master   Ready    master   24m     v1.19.3
k8s-node1    Ready    &lt;none&gt;   5m50s   v1.19.3
k8s-node2    Ready    &lt;none&gt;   5m21s   v1.19.3

</code></pre>
<p>如上所示，所有节点都为ready，集群搭建成功。</p>
<h3 id="21安装ingress-nginx">21.安装ingress-nginx</h3>
<pre><code class="language-yaml">vi ingress-nginx-deploy.yaml
apiVersion: v1
kind: Namespace
metadata:
  labels:
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
  name: ingress-nginx
---
apiVersion: v1
automountServiceAccountToken: true
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.2.0
  name: ingress-nginx
  namespace: ingress-nginx
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/component: admission-webhook
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.2.0
  name: ingress-nginx-admission
  namespace: ingress-nginx
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.2.0
  name: ingress-nginx
  namespace: ingress-nginx
rules:
- apiGroups:
  - &quot;&quot;
  resources:
  - namespaces
  verbs:
  - get
- apiGroups:
  - &quot;&quot;
  resources:
  - configmaps
  - pods
  - secrets
  - endpoints
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - &quot;&quot;
  resources:
  - services
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - networking.k8s.io
  resources:
  - ingresses
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - networking.k8s.io
  resources:
  - ingresses/status
  verbs:
  - update
- apiGroups:
  - networking.k8s.io
  resources:
  - ingressclasses
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - &quot;&quot;
  resourceNames:
  - ingress-controller-leader
  resources:
  - configmaps
  verbs:
  - get
  - update
- apiGroups:
  - &quot;&quot;
  resources:
  - configmaps
  verbs:
  - create
- apiGroups:
  - &quot;&quot;
  resources:
  - events
  verbs:
  - create
  - patch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  labels:
    app.kubernetes.io/component: admission-webhook
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.2.0
  name: ingress-nginx-admission
  namespace: ingress-nginx
rules:
- apiGroups:
  - &quot;&quot;
  resources:
  - secrets
  verbs:
  - get
  - create
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.2.0
  name: ingress-nginx
rules:
- apiGroups:
  - &quot;&quot;
  resources:
  - configmaps
  - endpoints
  - nodes
  - pods
  - secrets
  - namespaces
  verbs:
  - list
  - watch
- apiGroups:
  - &quot;&quot;
  resources:
  - nodes
  verbs:
  - get
- apiGroups:
  - &quot;&quot;
  resources:
  - services
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - networking.k8s.io
  resources:
  - ingresses
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - &quot;&quot;
  resources:
  - events
  verbs:
  - create
  - patch
- apiGroups:
  - networking.k8s.io
  resources:
  - ingresses/status
  verbs:
  - update
- apiGroups:
  - networking.k8s.io
  resources:
  - ingressclasses
  verbs:
  - get
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app.kubernetes.io/component: admission-webhook
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.2.0
  name: ingress-nginx-admission
rules:
- apiGroups:
  - admissionregistration.k8s.io
  resources:
  - validatingwebhookconfigurations
  verbs:
  - get
  - update
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.2.0
  name: ingress-nginx
  namespace: ingress-nginx
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: ingress-nginx
subjects:
- kind: ServiceAccount
  name: ingress-nginx
  namespace: ingress-nginx
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  labels:
    app.kubernetes.io/component: admission-webhook
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.2.0
  name: ingress-nginx-admission
  namespace: ingress-nginx
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: ingress-nginx-admission
subjects:
- kind: ServiceAccount
  name: ingress-nginx-admission
  namespace: ingress-nginx
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.2.0
  name: ingress-nginx
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: ingress-nginx
subjects:
- kind: ServiceAccount
  name: ingress-nginx
  namespace: ingress-nginx
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app.kubernetes.io/component: admission-webhook
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.2.0
  name: ingress-nginx-admission
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: ingress-nginx-admission
subjects:
- kind: ServiceAccount
  name: ingress-nginx-admission
  namespace: ingress-nginx
---
apiVersion: v1
data:
  allow-snippet-annotations: &quot;true&quot;
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.2.0
  name: ingress-nginx-controller
  namespace: ingress-nginx
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.2.0
  name: ingress-nginx-controller
  namespace: ingress-nginx
spec:
  ports:
  - appProtocol: http
    name: http
    port: 80
    protocol: TCP
    targetPort: http
  - appProtocol: https
    name: https
    port: 443
    protocol: TCP
    targetPort: https
  selector:
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
  type: NodePort
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.2.0
  name: ingress-nginx-controller-admission
  namespace: ingress-nginx
spec:
  ports:
  - appProtocol: https
    name: https-webhook
    port: 443
    targetPort: webhook
  selector:
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
  type: ClusterIP
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.2.0
  name: ingress-nginx-controller
  namespace: ingress-nginx
spec:
  minReadySeconds: 0
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-nginx
      app.kubernetes.io/name: ingress-nginx
  template:
    metadata:
      labels:
        app.kubernetes.io/component: controller
        app.kubernetes.io/instance: ingress-nginx
        app.kubernetes.io/name: ingress-nginx
    spec:
      containers:
      - args:
        - /nginx-ingress-controller
        - --election-id=ingress-controller-leader
        - --controller-class=k8s.io/ingress-nginx
        - --ingress-class=nginx
        - --configmap=$(POD_NAMESPACE)/ingress-nginx-controller
        - --validating-webhook=:8443
        - --validating-webhook-certificate=/usr/local/certificates/cert
        - --validating-webhook-key=/usr/local/certificates/key
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: LD_PRELOAD
          value: /usr/local/lib/libmimalloc.so
        image: registry.aliyuncs.com/google_containers/nginx-ingress-controller:v1.2.0
        imagePullPolicy: IfNotPresent
        lifecycle:
          preStop:
            exec:
              command:
              - /wait-shutdown
        livenessProbe:
          failureThreshold: 5
          httpGet:
            path: /healthz
            port: 10254
            scheme: HTTP
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 1
        name: controller
        ports:
        - containerPort: 80
          name: http
          protocol: TCP
        - containerPort: 443
          name: https
          protocol: TCP
        - containerPort: 8443
          name: webhook
          protocol: TCP
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /healthz
            port: 10254
            scheme: HTTP
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 1
        resources:
          requests:
            cpu: 100m
            memory: 90Mi
        securityContext:
          allowPrivilegeEscalation: true
          capabilities:
            add:
            - NET_BIND_SERVICE
            drop:
            - ALL
          runAsUser: 101
        volumeMounts:
        - mountPath: /usr/local/certificates/
          name: webhook-cert
          readOnly: true
      dnsPolicy: ClusterFirst
      nodeSelector:
        kubernetes.io/os: linux
      serviceAccountName: ingress-nginx
      terminationGracePeriodSeconds: 300
      volumes:
      - name: webhook-cert
        secret:
          secretName: ingress-nginx-admission
---
apiVersion: batch/v1
kind: Job
metadata:
  labels:
    app.kubernetes.io/component: admission-webhook
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.2.0
  name: ingress-nginx-admission-create
  namespace: ingress-nginx
spec:
  template:
    metadata:
      labels:
        app.kubernetes.io/component: admission-webhook
        app.kubernetes.io/instance: ingress-nginx
        app.kubernetes.io/name: ingress-nginx
        app.kubernetes.io/part-of: ingress-nginx
        app.kubernetes.io/version: 1.2.0
      name: ingress-nginx-admission-create
    spec:
      containers:
      - args:
        - create
        - --host=ingress-nginx-controller-admission,ingress-nginx-controller-admission.$(POD_NAMESPACE).svc
        - --namespace=$(POD_NAMESPACE)
        - --secret-name=ingress-nginx-admission
        env:
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        image: registry.aliyuncs.com/google_containers/kube-webhook-certgen:v1.1.1
        imagePullPolicy: IfNotPresent
        name: create
        securityContext:
          allowPrivilegeEscalation: false
      nodeSelector:
        kubernetes.io/os: linux
      restartPolicy: OnFailure
      securityContext:
        fsGroup: 2000
        runAsNonRoot: true
        runAsUser: 2000
      serviceAccountName: ingress-nginx-admission
---
apiVersion: batch/v1
kind: Job
metadata:
  labels:
    app.kubernetes.io/component: admission-webhook
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.2.0
  name: ingress-nginx-admission-patch
  namespace: ingress-nginx
spec:
  template:
    metadata:
      labels:
        app.kubernetes.io/component: admission-webhook
        app.kubernetes.io/instance: ingress-nginx
        app.kubernetes.io/name: ingress-nginx
        app.kubernetes.io/part-of: ingress-nginx
        app.kubernetes.io/version: 1.2.0
      name: ingress-nginx-admission-patch
    spec:
      containers:
      - args:
        - patch
        - --webhook-name=ingress-nginx-admission
        - --namespace=$(POD_NAMESPACE)
        - --patch-mutating=false
        - --secret-name=ingress-nginx-admission
        - --patch-failure-policy=Fail
        env:
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        image: registry.aliyuncs.com/google_containers/kube-webhook-certgen:v1.1.1
        imagePullPolicy: IfNotPresent
        name: patch
        securityContext:
          allowPrivilegeEscalation: false
      nodeSelector:
        kubernetes.io/os: linux
      restartPolicy: OnFailure
      securityContext:
        fsGroup: 2000
        runAsNonRoot: true
        runAsUser: 2000
      serviceAccountName: ingress-nginx-admission
---
apiVersion: networking.k8s.io/v1
kind: IngressClass
metadata:
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.2.0
  name: nginx
spec:
  controller: k8s.io/ingress-nginx
---
apiVersion: admissionregistration.k8s.io/v1
kind: ValidatingWebhookConfiguration
metadata:
  labels:
    app.kubernetes.io/component: admission-webhook
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.2.0
  name: ingress-nginx-admission
webhooks:
- admissionReviewVersions:
  - v1
  clientConfig:
    service:
      name: ingress-nginx-controller-admission
      namespace: ingress-nginx
      path: /networking/v1/ingresses
  failurePolicy: Fail
  matchPolicy: Equivalent
  name: validate.nginx.ingress.kubernetes.io
  rules:
  - apiGroups:
    - networking.k8s.io
    apiVersions:
    - v1
    operations:
    - CREATE
    - UPDATE
    resources:
    - ingresses
  sideEffects: None
  
kubectl create -f ingress-nginx-deploy.yaml
</code></pre>
<h2 id="卸载集群命令">卸载集群命令</h2>
<pre><code class="language-shell">#建议所有服务器都执行
#!/bin/bash
kubeadm reset -f
modprobe -r ipip
lsmod
rm -rf ~/.kube/
rm -rf /etc/kubernetes/
rm -rf /etc/systemd/system/kubelet.service.d
rm -rf /etc/systemd/system/kubelet.service
rm -rf /usr/bin/kube*
rm -rf /etc/cni
rm -rf /opt/cni
rm -rf /var/lib/etcd
rm -rf /var/etcd
yum -y remove kubeadm* kubectl* kubelet* docker*
reboot
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[centos7安装Docker详细步骤]]></title>
        <id>https://tinaxiawuhao.github.io/post/4kG3rvwit/</id>
        <link href="https://tinaxiawuhao.github.io/post/4kG3rvwit/">
        </link>
        <updated>2022-05-26T12:28:21.000Z</updated>
        <content type="html"><![CDATA[<h2 id="一-安装前必读">一、安装前必读</h2>
<p>在安装 Docker 之前，先说一下配置，我这里是Centos7  Linux 内核：官方建议 3.10 以上，3.8以上貌似也可。</p>
<p>注意：本文的命令使用的是 root 用户登录执行，不是 root 的话所有命令前面要加 <code>sudo</code></p>
<p><strong>1.查看当前的内核版本</strong></p>
<pre><code class="language-javascript">uname -r
</code></pre>
<p><strong>2.使用 root 权限更新 yum 包（生产环境中此步操作需慎重，看自己情况，学习的话随便搞）</strong></p>
<pre><code class="language-javascript">yum -y update
</code></pre>
<p>这个命令不是必须执行的，看个人情况，后面出现不兼容的情况的话就必须update了</p>
<pre><code class="language-javascript">注意 
yum -y update：升级所有包同时也升级软件和系统内核； 
yum -y upgrade：只升级所有包，不升级软件和系统内核
</code></pre>
<p><strong>3.卸载旧版本（如果之前安装过的话）</strong></p>
<pre><code class="language-javascript">yum remove docker  docker-common docker-selinux docker-engine
</code></pre>
<h2 id="二-安装docker的详细步骤">二、安装Docker的详细步骤</h2>
<p><strong>1.安装需要的软件包， yum-util 提供yum-config-manager功能，另两个是devicemapper驱动依赖</strong></p>
<pre><code class="language-javascript">yum install -y yum-utils device-mapper-persistent-data lvm2
</code></pre>
<p><strong>2.设置 yum 源</strong></p>
<p>设置一个yum源，下面两个都可用</p>
<pre><code class="language-javascript">yum-config-manager --add-repo http://download.docker.com/linux/centos/docker-ce.repo（中央仓库）

yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo（阿里仓库）
</code></pre>
<p>3.选择docker版本并安装</p>
<p>（1）查看可用版本有哪些</p>
<pre><code class="language-javascript">yum list docker-ce --showduplicates | sort -r
</code></pre>
<p>（2）选择一个版本并安装：<code>yum install docker-ce-版本号</code></p>
<pre><code class="language-javascript">yum -y install docker-ce-18.03.1.ce
</code></pre>
<p>4.启动 Docker 并设置开机自启</p>
<pre><code class="language-javascript">systemctl start docker
systemctl enable docker
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ES6新语法]]></title>
        <id>https://tinaxiawuhao.github.io/post/MKTk7DnaM/</id>
        <link href="https://tinaxiawuhao.github.io/post/MKTk7DnaM/">
        </link>
        <updated>2022-03-01T02:22:06.000Z</updated>
        <content type="html"><![CDATA[<h3 id="const-与-let-变量">const 与 let 变量</h3>
<p>使用var带来的麻烦:</p>
<pre><code class="language-js">function getClothing(isCold) {
  if (isCold) {
    var freezing = 'Grab a jacket!';
  } else {
    var hot = 'It's a shorts kind of day.';
    console.log(freezing);
  }
}
</code></pre>
<p>运行getClothing(false)后输出的是undefined,这是因为执行function函数之前,所有变量都会被提升, 提升到函数作用域顶部.</p>
<p>let与const声明的变量解决了这种问题,因为他们是块级作用域, 在代码块(用{}表示)中使用let或const声明变量, 该变量会陷入暂时性死区直到该变量的声明被处理.</p>
<pre><code class="language-js">function getClothing(isCold) {
  if (isCold) {
    const freezing = 'Grab a jacket!';
  } else {
    const hot = 'It's a shorts kind of day.';
    console.log(freezing);
  }
}
</code></pre>
<p>运行getClothing(false)后输出的是ReferenceError: freezing is not defined,因为 freezing 没有在 else 语句、函数作用域或全局作用域内声明，所以抛出 ReferenceError。</p>
<p><strong>关于使用let与const规则:</strong></p>
<p>使用let声明的变量可以重新赋值,但是不能在同一作用域内重新声明<br>
使用const声明的变量必须赋值初始化,但是不能在同一作用域类重新声明也无法重新赋值.</p>
<h3 id="模板字面量">模板字面量</h3>
<p>在ES6之前,将字符串连接到一起的方法是+或者concat()方法,如</p>
<pre><code class="language-js">const student = {
  name: 'Richard Kalehoff',
  guardian: 'Mr. Kalehoff'
};
const teacher = {
  name: 'Mrs. Wilson',
  room: 'N231'
}
let message = student.name + ' please see ' + teacher.name + ' in ' + teacher.room + ' to pick up your report card.';
</code></pre>
<p>模板字面量本质上是包含嵌入式表达式的字符串字面量.<br>
模板字面量用倒引号 ( `` )（而不是单引号 ( '' ) 或双引号( &quot;&quot; )）表示，可以包含用 ${expression} 表示的占位符</p>
<pre><code class="language-js">let message = `${student.name} please see ${teacher.name} in ${teacher.room} to pick up your report card.`;
</code></pre>
<h3 id="解构">解构</h3>
<p>在ES6中,可以使用解构从数组和对象提取值并赋值给独特的变量</p>
<p>解构数组的值:</p>
<pre><code class="language-js">const point = [10, 25, -34];
const [x, y, z] = point;
console.log(x, y, z);
Prints: 10 25 -34
</code></pre>
<p>[]表示被解构的数组, x,y,z表示要将数组中的值存储在其中的变量, 在解构数组是, 还可以忽略值, 例如const[x,,z]=point,忽略y坐标.</p>
<p>解构对象中的值:</p>
<pre><code class="language-js">const gemstone = {
  type: 'quartz',
  color: 'rose',
  karat: 21.29
};
const {type, color, karat} = gemstone;
console.log(type, color, karat);
</code></pre>
<p>花括号 { } 表示被解构的对象，type、color 和 karat 表示要将对象中的属性存储到其中的变量</p>
<p>对象字面量简写法</p>
<pre><code class="language-js">let type = 'quartz';
let color = 'rose';
let carat = 21.29;
const gemstone = {
  type: type,
  color: color,
  carat: carat
};
console.log(gemstone);
</code></pre>
<p>使用和所分配的变量名称相同的名称初始化对象时如果属性名称和所分配的变量名称一样，那么就可以从对象属性中删掉这些重复的变量名称。</p>
<pre><code class="language-js">let type = 'quartz';
let color = 'rose';
let carat = 21.29;
const gemstone = {type,color,carat};
console.log(gemstone);
</code></pre>
<p>简写方法的名称:</p>
<pre><code class="language-js">const gemstone = {
  type,
  color,
  carat,
  calculateWorth: function() {
    // 将根据类型(type)，颜色(color)和克拉(carat)计算宝石(gemstone)的价值
  }
};
</code></pre>
<p>匿名函数被分配给属性 calculateWorth，但是真的需要 function 关键字吗？在 ES6 中不需要！</p>
<pre><code class="language-js">let gemstone = {
  type,
  color,
  carat,
  calculateWorth() { ... }
};
</code></pre>
<h3 id="forof循环">for...of循环</h3>
<p>for...of循环是最新添加到 JavaScript 循环系列中的循环。<br>
它结合了其兄弟循环形式 for 循环和 for...in 循环的优势，可以循环任何可迭代（也就是遵守可迭代协议）类型的数据。默认情况下，包含以下数据类型：String、Array、Map 和 Set，注意不包含 Object 数据类型（即 {}）。默认情况下，对象不可迭代。</p>
<h4 id="for循环">for循环</h4>
<pre><code class="language-js">const digits = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9];
for (let i = 0; i &lt; digits.length; i++) {
  console.log(digits[i]);
}
</code></pre>
<p>for 循环的最大缺点是需要跟踪计数器和退出条件。<br>
虽然 for 循环在循环数组时的确具有优势，但是某些数据结构不是数组，因此并非始终适合使用 loop 循环。</p>
<h4 id="forin循环">for...in循环</h4>
<pre><code class="language-js">const digits = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9];
for (const index in digits) {
  console.log(digits[index]);
}
</code></pre>
<p>依然需要使用 index 来访问数组的值<br>
当你需要向数组中添加额外的方法（或另一个对象）时，for...in 循环会带来很大的麻烦。因为 for...in 循环循环访问所有可枚举的属性，意味着如果向数组的原型中添加任何其他属性，这些属性也会出现在循环中。</p>
<pre><code class="language-js">Array.prototype.decimalfy = function() {
  for (let i = 0; i &lt; this.length; i++) {
    this[i] = this[i].toFixed(2);
  }
};
const digits = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9];
for (const index in digits) {
  console.log(digits[index]);
}
</code></pre>
<h4 id="foreach-循环">forEach 循环</h4>
<p>forEach 循环是另一种形式的 JavaScript 循环。但是，forEach() 实际上是数组方法，因此只能用在数组中。也无法停止或退出 forEach 循环。如果希望你的循环中出现这种行为，则需要使用基本的 for 循环。</p>
<h4 id="forof循环-2">for...of循环</h4>
<p>for...of 循环用于循环访问任何可迭代的数据类型。<br>
for...of 循环的编写方式和 for...in 循环的基本一样，只是将 in 替换为 of，可以忽略索引。</p>
<pre><code class="language-js">const digits = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9];
for (const digit of digits) {
  console.log(digit);
}
</code></pre>
<p>建议使用复数对象名称来表示多个值的集合。这样，循环该集合时，可以使用名称的单数版本来表示集合中的单个值。例如，for (const button of buttons) {…}。</p>
<p>for...of 循环还具有其他优势，解决了 for 和 for...in 循环的不足之处。你可以随时停止或退出 for...of 循环。</p>
<pre><code class="language-js">for (const digit of digits) {
  if (digit % 2 === 0) {
    continue;
  }
  console.log(digit);
}
</code></pre>
<p>不用担心向对象中添加新的属性。for...of 循环将只循环访问对象中的值。</p>
<pre><code class="language-js">Array.prototype.decimalfy = function() {
  for (i = 0; i &lt; this.length; i++) {
    this[i] = this[i].toFixed(2);
  }
};
const digits = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9];
for (const digit of digits) {
  console.log(digit);
}

</code></pre>
<h3 id="展开运算符">展开运算符</h3>
<p>展开运算符（用三个连续的点 (...) 表示）是 ES6 中的新概念，使你能够将字面量对象展开为多个元素</p>
<pre><code class="language-js">const books = [&quot;Don Quixote&quot;, &quot;The Hobbit&quot;, &quot;Alice in Wonderland&quot;, &quot;Tale of Two Cities&quot;];
console.log(...books);
Prints: Don Quixote The Hobbit Alice in Wonderland Tale of Two Cities
</code></pre>
<p>展开运算符的一个用途是结合数组。</p>
<p>如果你需要结合多个数组，在有展开运算符之前，必须使用 Array的 concat() 方法。</p>
<pre><code class="language-js">const fruits = [&quot;apples&quot;, &quot;bananas&quot;, &quot;pears&quot;];
const vegetables = [&quot;corn&quot;, &quot;potatoes&quot;, &quot;carrots&quot;];
const produce = fruits.concat(vegetables);
console.log(produce);
Prints: [&quot;apples&quot;, &quot;bananas&quot;, &quot;pears&quot;, &quot;corn&quot;, &quot;potatoes&quot;, &quot;carrots&quot;]
</code></pre>
<p>使用展开符来结合数组</p>
<pre><code class="language-js">const fruits = [&quot;apples&quot;, &quot;bananas&quot;, &quot;pears&quot;];
const vegetables = [&quot;corn&quot;, &quot;potatoes&quot;, &quot;carrots&quot;];
const produce = [...fruits,...vegetables];
console.log(produce);
</code></pre>
<p><strong>剩余参数(可变参数)</strong><br>
使用展开运算符将数组展开为多个元素, 使用剩余参数可以将多个元素绑定到一个数组中.<br>
剩余参数也用三个连续的点 ( ... ) 表示，使你能够将不定数量的元素表示为数组.</p>
<p><strong>用途1: 将变量赋数组值时:</strong></p>
<pre><code class="language-js">const order = [20.17, 18.67, 1.50, &quot;cheese&quot;, &quot;eggs&quot;, &quot;milk&quot;, &quot;bread&quot;];
const [total, subtotal, tax, ...items] = order;
console.log(total, subtotal, tax, items);
</code></pre>
<p><strong>用途2: 可变参数函数</strong><br>
对于参数不固定的函数,ES6之前是使用参数对象(arguments)处理:</p>
<pre><code class="language-js">function sum() {
  let total = 0;  
  for(const argument of arguments) {
    total += argument;
  }
  return total;
}
</code></pre>
<p>在ES6中使用剩余参数运算符则更为简洁,可读性提高:</p>
<pre><code class="language-js">function sum(...nums) {
  let total = 0;  
  for(const num of nums) {
    total += num;
  }
  return total;
}
</code></pre>
<h3 id="es6箭头函数">ES6箭头函数</h3>
<p>ES6之前,使用普通函数把其中每个名字转换为大写形式：</p>
<pre><code class="language-js">const upperizedNames = ['Farrin', 'Kagure', 'Asser'].map(function(name) { 
  return name.toUpperCase();
});
</code></pre>
<p>箭头函数表示:</p>
<pre><code class="language-js">const upperizedNames = ['Farrin', 'Kagure', 'Asser'].map(
  name =&gt; name.toUpperCase()
);
</code></pre>
<p>普通函数可以是函数声明或者函数表达式, 但是箭头函数始终都是表达式, 全程是箭头函数表达式, 因此因此仅在表达式有效时才能使用，包括：</p>
<p>存储在变量中，<br>
当做参数传递给函数，<br>
存储在对象的属性中。</p>
<pre><code class="language-js">const greet = name =&gt; `Hello ${name}!`;
</code></pre>
<p>可以如下调用:</p>
<pre><code class="language-js">greet('Asser');
</code></pre>
<p>如果函数的参数只有一个,不需要使用()包起来,但是只有一个或者多个, 则必须需要将参数列表放在圆括号内:</p>
<pre><code class="language-js">// 空参数列表需要括号
const sayHi = () =&gt; console.log('Hello Udacity Student!');
// 多个参数需要括号
const orderIceCream = (flavor, cone) =&gt; console.log(`Here's your ${flavor} ice cream in a ${cone} cone.`);
orderIceCream('chocolate', 'waffle');
</code></pre>
<p>一般箭头函数都只有一个表达式作为函数主题:</p>
<pre><code class="language-js">const upperizedNames = ['Farrin', 'Kagure', 'Asser'].map(
  name =&gt; name.toUpperCase()
);
</code></pre>
<p>这种函数表达式形式称为简写主体语法:</p>
<p>1,在函数主体周围没有花括号,<br>
2,自动返回表达式<br>
3,但是如果箭头函数的主体内需要多行代码, 则需要使用常规主体语法:</p>
<p>它将函数主体放在花括号内<br>
需要使用 return 语句来返回内容。</p>
<pre><code class="language-js">const upperizedNames = ['Farrin', 'Kagure', 'Asser'].map( name =&gt; {
  name = name.toUpperCase();
  return `${name} has ${name.length} characters in their name`;
});

</code></pre>
<h3 id="javascript标准函数this">javascript标准函数this</h3>
<p><strong>new 对象</strong></p>
<pre><code class="language-js">const mySundae = new Sundae('Chocolate', ['Sprinkles', 'Hot Fudge']);
</code></pre>
<p>sundae这个构造函数内的this的值是实例对象, 因为他使用new被调用.</p>
<p><strong>指定的对象</strong></p>
<pre><code class="language-js">const result = obj1.printName.call(obj2);
</code></pre>
<p>函数使用call/apply被调用,this的值指向指定的obj2,因为call()第一个参数明确设置this的指向</p>
<p><strong>上下文对象</strong></p>
<pre><code class="language-js">data.teleport();
</code></pre>
<p>函数是对象的方法, this指向就是那个对象,此处this就是指向data.</p>
<p><strong>全局对象或 undefined</strong></p>
<pre><code class="language-js">teleport();
</code></pre>
<p>此处是this指向全局对象,在严格模式下,指向undefined.</p>
<p>javascript中this是很复杂的概念, 要详细判断this,请参考this豁然开朗</p>
<h4 id="箭头函数和this">箭头函数和this</h4>
<p>对于普通函数, this的值基于函数如何被调用, 对于箭头函数,this的值基于函数周围的上下文, 换句话说,this的值和函数外面的this的值是一样的.</p>
<pre><code class="language-js">function IceCream() {
    this.scoops = 0;
}
// 为 IceCream 添加 addScoop 方法
IceCream.prototype.addScoop = function() {
    setTimeout(function() {
        this.scoops++;
        console.log('scoop added!');
        console.log(this.scoops); // undefined+1=NaN
        console.log(dessert.scoops); //0
    }, 500);
};
</code></pre>
<pre><code class="language-js">const dessert = new IceCream();
dessert.addScoop();
</code></pre>
<p>传递给 setTimeout() 的函数被调用时没用到 new、call() 或 apply()，也没用到上下文对象。意味着函数内的 this 的值是全局对象，不是 dessert 对象。实际上发生的情况是，创建了新的 scoops 变量（默认值为 undefined），然后递增（undefined + 1 结果为 NaN）;</p>
<p>解决此问题的方式之一是使用闭包(closure):</p>
<pre><code class="language-js">// 构造函数
function IceCream() {
  this.scoops = 0;
}
// 为 IceCream 添加 addScoop 方法
IceCream.prototype.addScoop = function() {
  const cone = this; // 设置 `this` 给 `cone`变量
  setTimeout(function() {
    cone.scoops++; // 引用`cone`变量
    console.log('scoop added!'); 
    console.log(dessert.scoops);//1
  }, 0.5);
};
const dessert = new IceCream();
dessert.addScoop();
</code></pre>
<p>箭头函数的作用正是如此, 将setTimeOut()的函数改为剪头函数:</p>
<pre><code class="language-js">// 构造函数
function IceCream() {
  this.scoops = 0;
}
// 为 IceCream 添加 addScoop 方法
IceCream.prototype.addScoop = function() {
  setTimeout(() =&gt; { // 一个箭头函数被传递给setTimeout
    this.scoops++;
    console.log('scoop added!');
    console.log(dessert.scoops);//1
  }, 0.5);
};
const dessert = new IceCream();
dessert.addScoop();
</code></pre>
<p><strong>默认参数函数</strong></p>
<pre><code class="language-js">function greet(name, greeting) {
  name = (typeof name !== 'undefined') ?  name : 'Student';
  greeting = (typeof greeting !== 'undefined') ?  greeting : 'Welcome';
  return `${greeting} ${name}!`;
}
greet(); // Welcome Student!
greet('James'); // Welcome James!
greet('Richard', 'Howdy'); // Howdy Richard!

</code></pre>
<p>greet() 函数中混乱的前两行的作用是什么？它们的作用是当所需的参数未提供时，为函数提供默认的值。但是看起来很麻烦, ES6引入一种新的方式创建默认值, 他叫默认函数参数:</p>
<pre><code class="language-js">function greet(name = 'Student', greeting = 'Welcome') {
  return `${greeting} ${name}!`;
}
greet(); // Welcome Student!
greet('James'); // Welcome James!
greet('Richard', 'Howdy'); // Howdy Richard!

</code></pre>
<h3 id="默认值与解构">默认值与解构</h3>
<p><strong>默认值与解构数组</strong></p>
<pre><code class="language-js">function createGrid([width = 5, height = 5]) {
  return `Generates a ${width} x ${height} grid`;
}
createGrid([]); // Generates a 5 x 5 grid
createGrid([2]); // Generates a 2 x 5 grid
createGrid([2, 3]); // Generates a 2 x 3 grid
createGrid([undefined, 3]); // Generates a 5 x 3 grid
</code></pre>
<p>createGrid() 函数预期传入的是数组。它通过解构将数组中的第一项设为 width，第二项设为 height。如果数组为空，或者只有一项，那么就会使用默认参数，并将缺失的参数设为默认值 5。</p>
<p>但是存在一个问题:</p>
<pre><code class="language-js">createGrid(); // throws an error
Uncaught TypeError: Cannot read property 'Symbol(Symbol.iterator)' of undefined
</code></pre>
<p>出现错误，因为 createGrid() 预期传入的是数组，然后对其进行解构。因为函数被调用时没有传入数组，所以出现问题。但是，我们可以使用默认的函数参数！</p>
<pre><code class="language-js">function createGrid([width = 5, height = 5] = []) {
  return `Generating a grid of ${width} by ${height}`;
}
createGrid(); // Generates a 5 x 5 grid
Returns: Generates a 5 x 5 grid
</code></pre>
<p><strong>默认值与解构函数</strong><br>
就像使用数组默认值解构数组一样，函数可以让对象成为一个默认参数，并使用对象解构：</p>
<pre><code class="language-js">function createSundae({scoops = 1, toppings = ['Hot Fudge']}={}) {
  const scoopText = scoops === 1 ? 'scoop' : 'scoops';
  return `Your sundae has ${scoops} ${scoopText} with ${toppings.join(' and ')} toppings.`;
}
createSundae({}); // Your sundae has 1 scoop with Hot Fudge toppings.
createSundae({scoops: 2}); // Your sundae has 2 scoops with Hot Fudge toppings.
createSundae({scoops: 2, toppings: ['Sprinkles']}); // Your sundae has 2 scoops with Sprinkles toppings.
createSundae({toppings: ['Cookie Dough']}); // Your sundae has 1 scoop with Cookie Dough toppings.
createSundae(); // Your sundae has 1 scoop with Hot Fudge toppings.
</code></pre>
<p><strong>数组默认值与对象默认值</strong><br>
默认函数参数只是个简单的添加内容，但是却带来很多便利！与数组默认值相比，对象默认值具备的一个优势是能够处理跳过的选项。看看下面的代码：</p>
<pre><code class="language-js">function createSundae({scoops = 1, toppings = ['Hot Fudge']} = {}) { … }
</code></pre>
<p>在 createSundae() 函数使用对象默认值进行解构时，如果你想使用 scoops 的默认值，但是更改 toppings，那么只需使用 toppings 传入一个对象：</p>
<pre><code class="language-js">createSundae({toppings: ['Hot Fudge', 'Sprinkles', 'Caramel']});
</code></pre>
<p>将上述示例与使用数组默认值进行解构的同一函数相对比。</p>
<pre><code class="language-js">function createSundae([scoops = 1, toppings = ['Hot Fudge']] = []) { … }
</code></pre>
<p>对于这个函数，如果想使用 scoops 的默认数量，但是更改 toppings，则必须以这种奇怪的方式调用你的函数：</p>
<pre><code class="language-js">createSundae([undefined, ['Hot Fudge', 'Sprinkles', 'Caramel']]);
</code></pre>
<p>因为数组是基于位置的，我们需要传入 undefined 以跳过第一个参数（并使用默认值）来到达第二个参数。</p>
<h3 id="javascript类">Javascript类</h3>
<p><strong>ES5创建类:</strong></p>
<pre><code class="language-js">function Plane(numEngines) {
  this.numEngines = numEngines;
  this.enginesActive = false;
}
// 由所有实例 &quot;继承&quot; 的方法
Plane.prototype.startEngines = function () {
  console.log('starting engines...');
  this.enginesActive = true;
};
</code></pre>
<p><strong>ES6创建类</strong><br>
ES6类只是一个语法糖,原型继续实际上在底层隐藏起来, 与传统类机制语言有些区别.</p>
<pre><code class="language-js">class Plane {
  //constructor方法虽然在类中,但不是原型上的方法,只是用来生成实例的.
  constructor(numEngines) {
    this.numEngines = numEngines;
    this.enginesActive = false;
  }
  //原型上的方法, 由所有实例对象共享.
  startEngines() {
    console.log('starting engines…');
    this.enginesActive = true;
  }
}
console.log(typeof Plane); //function

</code></pre>
<p>javascript中类其实只是function, 方法之间不能使用,,不用逗号区分属性和方法.</p>
<h3 id="静态方法">静态方法</h3>
<p>要添加静态方法，请在方法名称前面加上关键字 static</p>
<pre><code class="language-js">class Plane {
  constructor(numEngines) {
    this.numEngines = numEngines;
    this.enginesActive = false;
  }
  static badWeather(planes) {
    for (plane of planes) {
      plane.enginesActive = false;
    }
  }
  startEngines() {
    console.log('starting engines…');
    this.enginesActive = true;
  }
}
</code></pre>
<p>关键字class带来其他基于类的语言的很多思想,但是没有向javascript中添加此功能<br>
javascript类实际上还是原型继承<br>
创建javascript类的新实例时必须使用new关键字</p>
<h3 id="super-和-extends">super 和 extends</h3>
<p>使用新的super和extends关键字扩展类:</p>
<pre><code class="language-js">class Tree {
  constructor(size = '10', leaves = {spring: 'green', summer: 'green', fall: 'orange', winter: null}) {
    this.size = size;
    this.leaves = leaves;
    this.leafColor = null;
  }
  changeSeason(season) {
    this.leafColor = this.leaves[season];
    if (season === 'spring') {
      this.size += 1;
    }
  }
}
class Maple extends Tree {
  constructor(syrupQty = 15, size, leaves) {
    super(size, leaves); //super用作函数
    this.syrupQty = syrupQty;
  }
  changeSeason(season) {
    super.changeSeason(season);//super用作对象
    if (season === 'spring') {
      this.syrupQty += 1;
    }
  }
  gatherSyrup() {
    this.syrupQty -= 3;
  }
}
</code></pre>
<p>使用ES5编写同样功能的类:</p>
<pre><code class="language-js">function Tree(size, leaves) {
  this.size = size || 10;
  this.leaves = leaves || {spring: 'green', summer: 'green', fall: 'orange', winter: null};
  this.leafColor;
}
Tree.prototype.changeSeason = function(season) {
  this.leafColor = this.leaves[season];
  if (season === 'spring') {
    this.size += 1;
  }
}
function Maple (syrupQty, size, leaves) {
  Tree.call(this, size, leaves);
  this.syrupQty = syrupQty || 15;
}
Maple.prototype = Object.create(Tree.prototype);
Maple.prototype.constructor = Maple;
Maple.prototype.changeSeason = function(season) {
  Tree.prototype.changeSeason.call(this, season);
  if (season === 'spring') {
    this.syrupQty += 1;
  }
}
Maple.prototype.gatherSyrup = function() {
  this.syrupQty -= 3;
}
</code></pre>
<p>super 必须在 this 之前被调用</p>
<p>在子类构造函数中，在使用 this 之前，必须先调用超级类。</p>
<pre><code class="language-js">class Apple {}
class GrannySmith extends Apple {
  constructor(tartnessLevel, energy) {
    this.tartnessLevel = tartnessLevel; // 在 'super' 之前会抛出一个错误！
    super(energy); 
  }
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[springBoot参数和业务校验]]></title>
        <id>https://tinaxiawuhao.github.io/post/d4XUQj9K0/</id>
        <link href="https://tinaxiawuhao.github.io/post/d4XUQj9K0/">
        </link>
        <updated>2022-02-25T03:05:50.000Z</updated>
        <content type="html"><![CDATA[<h2 id="为什么需要参数校验">为什么需要参数校验</h2>
<p>在日常的接口开发中，为了防止非法参数对业务造成影响，经常需要对接口的参数做校验，例如登录的时候需要校验用户名密码是否为空，创建用户的时候需要校验邮件、手机号码格式是否准确。靠代码对接口参数一个个校验的话就太繁琐了，代码可读性极差。</p>
<p>Validator框架就是为了解决开发人员在开发的时候少写代码，提升开发效率</p>
<blockquote>
<p>Validator校验框架遵循了JSR-303验证规范（参数校验规范）, JSR是<code>Java Specification Requests</code>的缩写。</p>
</blockquote>
<p>接下来我们看看在SpringbBoot中如何集成参数校验框架。</p>
<h2 id="springboot中集成参数校验">SpringBoot中集成参数校验</h2>
<h3 id="第一步引入依赖">第一步，引入依赖</h3>
<pre><code>&lt;dependency&gt;
  &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
  &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
&lt;/dependency&gt;

&lt;dependency&gt;
  &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
  &lt;artifactId&gt;spring-boot-starter-validation&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<blockquote>
<p>注：从<code>springboot-2.3</code>开始，校验包被独立成了一个<code>starter</code>组件，所以需要引入validation和web，而<code>springboot-2.3</code>之前的版本只需要引入 web 依赖就可以了。</p>
</blockquote>
<h3 id="第二步定义要参数校验的实体类">第二步，定义要参数校验的实体类</h3>
<pre><code>@Data
public class ValidVO {
    private String id;

    @Length(min = 6,max = 12,message = &quot;appId长度必须位于6到12之间&quot;)
    private String appId;

    @NotBlank(message = &quot;名字为必填项&quot;)
    private String name;

    @Email(message = &quot;请填写正确的邮箱地址&quot;)
    private String email;

    private String sex;

    @NotEmpty(message = &quot;级别不能为空&quot;)
    private String level;
}
</code></pre>
<p>在实际开发中对于需要校验的字段都需要设置对应的业务提示，即message属性。</p>
<p>常见的约束注解如下：</p>
<table>
<thead>
<tr>
<th style="text-align:left">注解</th>
<th style="text-align:left">功能</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">@AssertFalse</td>
<td style="text-align:left">可以为null,如果不为null的话必须为false</td>
</tr>
<tr>
<td style="text-align:left">@AssertTrue</td>
<td style="text-align:left">可以为null,如果不为null的话必须为true</td>
</tr>
<tr>
<td style="text-align:left">@DecimalMax</td>
<td style="text-align:left">设置不能超过最大值</td>
</tr>
<tr>
<td style="text-align:left">@DecimalMin</td>
<td style="text-align:left">设置不能超过最小值</td>
</tr>
<tr>
<td style="text-align:left">@Digits</td>
<td style="text-align:left">设置必须是数字且数字整数的位数和小数的位数必须在指定范围内</td>
</tr>
<tr>
<td style="text-align:left">@Future</td>
<td style="text-align:left">日期必须在当前日期的未来</td>
</tr>
<tr>
<td style="text-align:left">@Past</td>
<td style="text-align:left">日期必须在当前日期的过去</td>
</tr>
<tr>
<td style="text-align:left">@Max</td>
<td style="text-align:left">最大不得超过此最大值</td>
</tr>
<tr>
<td style="text-align:left">@Min</td>
<td style="text-align:left">最大不得小于此最小值</td>
</tr>
<tr>
<td style="text-align:left">@NotNull</td>
<td style="text-align:left">不能为null，可以是空</td>
</tr>
<tr>
<td style="text-align:left">@Null</td>
<td style="text-align:left">必须为null</td>
</tr>
<tr>
<td style="text-align:left">@Pattern</td>
<td style="text-align:left">必须满足指定的正则表达式</td>
</tr>
<tr>
<td style="text-align:left">@Size</td>
<td style="text-align:left">集合、数组、map等的size()值必须在指定范围内</td>
</tr>
<tr>
<td style="text-align:left">@Email</td>
<td style="text-align:left">必须是email格式</td>
</tr>
<tr>
<td style="text-align:left">@Length</td>
<td style="text-align:left">长度必须在指定范围内</td>
</tr>
<tr>
<td style="text-align:left">@NotBlank</td>
<td style="text-align:left">字符串不能为null,字符串trim()后也不能等于“”</td>
</tr>
<tr>
<td style="text-align:left">@NotEmpty</td>
<td style="text-align:left">不能为null，集合、数组、map等size()不能为0；字符串trim()后可以等于“”</td>
</tr>
<tr>
<td style="text-align:left">@Range</td>
<td style="text-align:left">值必须在指定范围内</td>
</tr>
<tr>
<td style="text-align:left">@URL</td>
<td style="text-align:left">必须是一个URL</td>
</tr>
</tbody>
</table>
<p>注：此表格只是简单的对注解功能的说明，并没有对每一个注解的属性进行说明；可详见源码。</p>
<h3 id="第三步定义校验类进行测试">第三步，定义校验类进行测试</h3>
<pre><code>@RestController
@Slf4j
@Validated
public class ValidController {

    @ApiOperation(&quot;RequestBody校验&quot;)
    @PostMapping(&quot;/valid/test1&quot;)   
    public String test1(@Validated @RequestBody ValidVO validVO){
        log.info(&quot;validEntity is {}&quot;, validVO);
        return &quot;test1 valid success&quot;;
    }

    @ApiOperation(&quot;Form校验&quot;)
    @PostMapping(value = &quot;/valid/test2&quot;)
    public String test2(@Validated ValidVO validVO){
        log.info(&quot;validEntity is {}&quot;, validVO);
        return &quot;test2 valid success&quot;;
    }
  
   @ApiOperation(&quot;单参数校验&quot;)
    @PostMapping(value = &quot;/valid/test3&quot;)
    public String test3(@Email String email){
        log.info(&quot;email is {}&quot;, email);
        return &quot;email valid success&quot;;
    }
}
</code></pre>
<p>这里我们先定义三个方法test1，test2，test3，test1使用了<code>@RequestBody</code>注解，用于接受前端发送的json数据，test2模拟表单提交，test3模拟单参数提交。<strong>注意，当使用单参数校验时需要在Controller上加上@Validated注解，否则不生效</strong>。</p>
<h3 id="第四步体验效果">第四步，体验效果</h3>
<ol>
<li>调用test1方法，提示的是<code>org.springframework.web.bind.MethodArgumentNotValidException</code>异常</li>
</ol>
<pre><code>POST http://localhost:8080/valid/test1
Content-Type: application/json

{
  &quot;id&quot;: 1,
  &quot;level&quot;: &quot;12&quot;,
  &quot;email&quot;: &quot;47693899&quot;,
  &quot;appId&quot;: &quot;ab1c&quot;
}
{
  &quot;status&quot;: 500,
  &quot;message&quot;: &quot;Validation failed for argument [0] in public java.lang.String com.jianzh5.blog.valid.ValidController.test1(com.jianzh5.blog.valid.ValidVO) with 3 errors: [Field error in object 'validVO' on field 'email': rejected value [47693899]; codes [Email.validVO.email,Email.email,Email.java.lang.String,Email]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [validVO.email,email]; arguments []; default message [email],[Ljavax.validation.constraints.Pattern$Flag;@26139123,.*]; default message [不是一个合法的电子邮件地址]]...&quot;,
  &quot;data&quot;: null,
  &quot;timestamp&quot;: 1628239624332
}
</code></pre>
<ol>
<li>调用test2方法，提示的是<code>org.springframework.validation.BindException</code>异常</li>
</ol>
<pre><code>POST http://localhost:8080/valid/test2
Content-Type: application/x-www-form-urlencoded

id=1&amp;level=12&amp;email=476938977&amp;appId=ab1c
{
  &quot;status&quot;: 500,
  &quot;message&quot;: &quot;org.springframework.validation.BeanPropertyBindingResult: 3 errors\nField error in object 'validVO' on field 'name': rejected value [null]; codes [NotBlank.validVO.name,NotBlank.name,NotBlank.java.lang.String,NotBlank]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [validVO.name,name]; arguments []; default message [name]]; default message [名字为必填项]...&quot;,
  &quot;data&quot;: null,
  &quot;timestamp&quot;: 1628239301951
}
</code></pre>
<ol>
<li>调用test3方法，提示的是<code>javax.validation.ConstraintViolationException</code>异常</li>
</ol>
<pre><code>POST http://localhost:8080/valid/test3
Content-Type: application/x-www-form-urlencoded

email=476938977
{
  &quot;status&quot;: 500,
  &quot;message&quot;: &quot;test3.email: 不是一个合法的电子邮件地址&quot;,
  &quot;data&quot;: null,
  &quot;timestamp&quot;: 1628239281022
}
</code></pre>
<p>通过加入<code>Validator</code>校验框架可以帮助我们自动实现参数的校验。</p>
<h2 id="参数异常加入全局异常处理器">参数异常加入全局异常处理器</h2>
<p><code>Validator</code>校验框架返回的错误提示太臃肿了，不便于阅读，为了方便前端提示，我们需要将其简化一下。</p>
<p>创建RestExceptionHandler<code>，单独拦截参数校验的三个异常：</code>javax.validation.ConstraintViolationException<code>，</code>org.springframework.validation.BindException<code>，</code>org.springframework.web.bind.MethodArgumentNotValidException`，代码如下：</p>
<pre><code>@ExceptionHandler(value = {BindException.class, ValidationException.class, MethodArgumentNotValidException.class})
public ResponseEntity&lt;ResultData&lt;String&gt;&gt; handleValidatedException(Exception e) {
  ResultData&lt;String&gt; resp = null;

  if (e instanceof MethodArgumentNotValidException) {
    // BeanValidation exception
    MethodArgumentNotValidException ex = (MethodArgumentNotValidException) e;
    resp = ResultData.fail(HttpStatus.BAD_REQUEST.value(),
                           ex.getBindingResult().getAllErrors().stream()
                           .map(ObjectError::getDefaultMessage)
                           .collect(Collectors.joining(&quot;; &quot;))
                          );
  } else if (e instanceof ConstraintViolationException) {
    // BeanValidation GET simple param
    ConstraintViolationException ex = (ConstraintViolationException) e;
    resp = ResultData.fail(HttpStatus.BAD_REQUEST.value(),
                           ex.getConstraintViolations().stream()
                           .map(ConstraintViolation::getMessage)
                           .collect(Collectors.joining(&quot;; &quot;))
                          );
  } else if (e instanceof BindException) {
    // BeanValidation GET object param
    BindException ex = (BindException) e;
    resp = ResultData.fail(HttpStatus.BAD_REQUEST.value(),
                           ex.getAllErrors().stream()
                           .map(ObjectError::getDefaultMessage)
                           .collect(Collectors.joining(&quot;; &quot;))
                          );
  }

  return new ResponseEntity&lt;&gt;(resp,HttpStatus.BAD_REQUEST);
}
</code></pre>
<h3 id="体验效果">体验效果</h3>
<pre><code>POST http://localhost:8080/valid/test1
Content-Type: application/json

{
  &quot;id&quot;: 1,
  &quot;level&quot;: &quot;12&quot;,
  &quot;email&quot;: &quot;47693899&quot;,
  &quot;appId&quot;: &quot;ab1c&quot;
}
{
  &quot;status&quot;: 400,
  &quot;message&quot;: &quot;名字为必填项; 不是一个合法的电子邮件地址; appId长度必须位于6到12之间&quot;,
  &quot;data&quot;: null,
  &quot;timestamp&quot;: 1628435116680
}
</code></pre>
<p>是不是感觉清爽多了？</p>
<h2 id="自定义参数校验">自定义参数校验</h2>
<p>虽然Spring Validation 提供的注解基本上够用，但是面对复杂的定义，我们还是需要自己定义相关注解来实现自动校验。</p>
<p>比如上面实体类中的sex性别属性，只允许前端传递传 M，F 这2个枚举值，如何实现呢？</p>
<h3 id="第一步创建自定义注解">第一步，创建自定义注解</h3>
<pre><code>@Target({METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER, TYPE_USE})
@Retention(RUNTIME)
@Repeatable(EnumString.List.class)
@Documented
@Constraint(validatedBy = EnumStringValidator.class)//标明由哪个类执行校验逻辑
public @interface EnumString {
    String message() default &quot;value not in enum values.&quot;;

    Class&lt;?&gt;[] groups() default {};

    Class&lt;? extends Payload&gt;[] payload() default {};

    /**
     * @return date must in this value array
     */
    String[] value();

    /**
     * Defines several {@link EnumString} annotations on the same element.
     *
     * @see EnumString
     */
    @Target({METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER, TYPE_USE})
    @Retention(RUNTIME)
    @Documented
    @interface List {

        EnumString[] value();
    }
}
</code></pre>
<h3 id="第二步自定义校验逻辑">第二步，自定义校验逻辑</h3>
<pre><code>public class EnumStringValidator implements ConstraintValidator&lt;EnumString, String&gt; {
    private List&lt;String&gt; enumStringList;

    @Override
    public void initialize(EnumString constraintAnnotation) {
        enumStringList = Arrays.asList(constraintAnnotation.value());
    }

    @Override
    public boolean isValid(String value, ConstraintValidatorContext context) {
        if(value == null){
            return true;
        }
        return enumStringList.contains(value);
    }
}
</code></pre>
<h3 id="第三步在字段上增加注解">第三步，在字段上增加注解</h3>
<pre><code>@ApiModelProperty(value = &quot;性别&quot;)
@EnumString(value = {&quot;F&quot;,&quot;M&quot;}, message=&quot;性别只允许为F或M&quot;)
private String sex;
</code></pre>
<h3 id="第四步体验效果-2">第四步，体验效果</h3>
<pre><code>POST http://localhost:8080/valid/test2
Content-Type: application/x-www-form-urlencoded

id=1&amp;name=javadaily&amp;level=12&amp;email=476938977@qq.com&amp;appId=ab1cdddd&amp;sex=N
{
  &quot;status&quot;: 400,
  &quot;message&quot;: &quot;性别只允许为F或M&quot;,
  &quot;data&quot;: null,
  &quot;timestamp&quot;: 1628435243723
}
</code></pre>
<h2 id="分组校验">分组校验</h2>
<p>一个VO对象在新增的时候某些字段为必填，在更新的时候又非必填。如上面的<code>ValidVO</code>中 id 和 appId 属性在新增操作时都是<strong>非必填</strong>，而在编辑操作时都为<strong>必填</strong>，name在新增操作时为<strong>必填</strong>，面对这种场景你会怎么处理呢？</p>
<p>在实际开发中我见到很多同学都是建立两个VO对象，<code>ValidCreateVO</code>，<code>ValidEditVO</code>来处理这种场景，这样确实也能实现效果，但是会造成类膨胀，而且极其容易被开发老鸟们嘲笑。</p>
<p>其实<code>Validator</code>校验框架已经考虑到了这种场景并且提供了解决方案，就是<strong>分组校验</strong>，只不过很多同学不知道而已。要使用分组校验，只需要三个步骤：</p>
<h3 id="第一步定义分组接口">第一步：定义分组接口</h3>
<pre><code>public interface ValidGroup extends Default {
  
    interface Crud extends ValidGroup{
        interface Create extends Crud{

        }

        interface Update extends Crud{

        }

        interface Query extends Crud{

        }

        interface Delete extends Crud{

        }
    }
}
</code></pre>
<p>这里我们定义一个分组接口ValidGroup让其继承<code>javax.validation.groups.Default</code>，再在分组接口中定义出多个不同的操作类型，Create，Update，Query，Delete。至于为什么需要继承Default我们稍后再说。</p>
<h3 id="第二步在模型中给参数分配分组">第二步，在模型中给参数分配分组</h3>
<pre><code>@Data
@ApiModel(value = &quot;参数校验类&quot;)
public class ValidVO {
    @ApiModelProperty(&quot;ID&quot;)
    @Null(groups = ValidGroup.Crud.Create.class)
    @NotNull(groups = ValidGroup.Crud.Update.class, message = &quot;应用ID不能为空&quot;)
    private String id;

    @Null(groups = ValidGroup.Crud.Create.class)
    @NotNull(groups = ValidGroup.Crud.Update.class, message = &quot;应用ID不能为空&quot;)
    @ApiModelProperty(value = &quot;应用ID&quot;,example = &quot;cloud&quot;)
    private String appId;

    @ApiModelProperty(value = &quot;名字&quot;)
    @NotBlank(groups = ValidGroup.Crud.Create.class,message = &quot;名字为必填项&quot;)
    private String name;
  
   @ApiModelProperty(value = &quot;邮箱&quot;)
    @Email(message = &quot;请填写正取的邮箱地址&quot;)
    privte String email;

    ...

}
</code></pre>
<p>给参数指定分组，对于未指定分组的则使用的是默认分组。</p>
<h3 id="第三步给需要参数校验的方法指定分组">第三步，给需要参数校验的方法指定分组</h3>
<pre><code>@RestController
@Api(&quot;参数校验&quot;)
@Slf4j
@Validated
public class ValidController {

    @ApiOperation(&quot;新增&quot;)
    @PostMapping(value = &quot;/valid/add&quot;)
    public String add(@Validated(value = ValidGroup.Crud.Create.class) ValidVO validVO){
        log.info(&quot;validEntity is {}&quot;, validVO);
        return &quot;test3 valid success&quot;;
    }


    @ApiOperation(&quot;更新&quot;)
    @PostMapping(value = &quot;/valid/update&quot;)
    public String update(@Validated(value = ValidGroup.Crud.Update.class) ValidVO validVO){
        log.info(&quot;validEntity is {}&quot;, validVO);
        return &quot;test4 valid success&quot;;
    }
}
</code></pre>
<p>这里我们通过<code>value</code>属性给<code>add()</code>和<code>update()</code>方法分别指定Create和Update分组。</p>
<h3 id="第四步体验效果-3">第四步，体验效果</h3>
<pre><code>POST http://localhost:8080/valid/add
Content-Type: application/x-www-form-urlencoded

name=javadaily&amp;level=12&amp;email=476938977@qq.com&amp;sex=F
</code></pre>
<p>在Create时我们没有传递id和appId参数，校验通过。</p>
<p>当我们使用同样的参数调用update方法时则提示参数校验错误。</p>
<pre><code>{
  &quot;status&quot;: 400,
  &quot;message&quot;: &quot;ID不能为空; 应用ID不能为空&quot;,
  &quot;data&quot;: null,
  &quot;timestamp&quot;: 1628492514313
}
</code></pre>
<p>由于email属于默认分组，而我们的分组接口<code>ValidGroup</code>已经继承了<code>Default</code>分组，所以也是可以对email字段作参数校验的。如：</p>
<pre><code>POST http://localhost:8080/valid/add
Content-Type: application/x-www-form-urlencoded

name=javadaily&amp;level=12&amp;email=476938977&amp;sex=F
{
  &quot;status&quot;: 400,
  &quot;message&quot;: &quot;请填写正取的邮箱地址&quot;,
  &quot;data&quot;: null,
  &quot;timestamp&quot;: 1628492637305
}
</code></pre>
<p>当然如果你的ValidGroup没有继承Default分组，那在代码属性上就需要加上<code>@Validated(value = {ValidGroup.Crud.Create.class, Default.class}</code>才能让<code>email</code>字段的校验生效。</p>
<h2 id="业务规则校验">业务规则校验</h2>
<p>业务规则校验指接口需要满足某些特定的业务规则，举个例子：业务系统的用户需要保证其唯一性，用户属性不能与其他用户产生冲突，不允许与数据库中任何已有用户的用户名称、手机号码、邮箱产生重复。</p>
<p>这就要求在<strong>创建用户时需要校验用户名称、手机号码、邮箱是否被注册</strong>；<strong>编辑用户时不能将信息修改成已有用户的属性</strong>。</p>
<p>95%的程序员当面对这种业务规则校验时往往选择写在service逻辑中，常见的代码逻辑如下：</p>
<pre><code>public void create(User user) {
    Account account = accountDao.queryByUserNameOrPhoneOrEmail(user.getName(),user.getPhone(),user.getEmail());
    if (account != null) {
        throw new IllegalArgumentException(&quot;用户已存在，请重新输入&quot;);
    }
}
</code></pre>
<p><strong>最优雅的实现方法应该是参考 Bean Validation 的标准方式，借助自定义校验注解完成业务规则校验。</strong></p>
<p>接下来我们通过上面提到的用户接口案例，通过自定义注解完成业务规则校验。</p>
<h2 id="代码实战">代码实战</h2>
<p>需求很容易理解，注册新用户时，应约束不与任何已有用户的关键信息重复；而修改自己的信息时，只能与自己的信息重复，不允许修改成已有用户的信息。</p>
<p>这些约束规则不仅仅为这两个方法服务，它们可能会在用户资源中的其他入口被使用到，乃至在其他分层的代码中被使用到，在 Bean 上做校验就能全部覆盖上述这些使用场景。</p>
<h3 id="自定义注解">自定义注解</h3>
<p>首先我们需要创建两个自定义注解，用于业务规则校验：</p>
<ul>
<li><code>UniqueUser</code>:表示一个用户是唯一的，唯一性包含：用户名，手机号码、邮箱</li>
</ul>
<pre><code>@Documented
@Retention(RUNTIME)
@Target({FIELD, METHOD, PARAMETER, TYPE})
@Constraint(validatedBy = UserValidation.UniqueUserValidator.class)
public @interface UniqueUser {

    String message() default &quot;用户名、手机号码、邮箱不允许与现存用户重复&quot;;

    Class&lt;?&gt;[] groups() default {};

    Class&lt;? extends Payload&gt;[] payload() default {};
}
</code></pre>
<ul>
<li><code>NotConflictUser</code>:表示一个用户的信息是无冲突的，无冲突是指该用户的敏感信息与其他用户不重合</li>
</ul>
<pre><code>@Documented
@Retention(RUNTIME)
@Target({FIELD, METHOD, PARAMETER, TYPE})
@Constraint(validatedBy = UserValidation.NotConflictUserValidator.class)
public @interface NotConflictUser {
    String message() default &quot;用户名称、邮箱、手机号码与现存用户产生重复&quot;;

    Class&lt;?&gt;[] groups() default {};

    Class&lt;? extends Payload&gt;[] payload() default {};
}
</code></pre>
<h3 id="实现业务校验规则">实现业务校验规则</h3>
<p>想让自定义验证注解生效，需要实现 <code>ConstraintValidator</code> 接口。接口的第一个参数是 <strong>自定义注解类型</strong>，第二个参数是 <strong>被注解字段的类</strong>，因为需要校验多个参数，我们直接传入用户对象。需要提到的一点是 <code>ConstraintValidator</code> 接口的实现类无需添加 <code>@Component</code> 它在启动的时候就已经被加载到容器中了。</p>
<pre><code>@Slf4j
public class UserValidation&lt;T extends Annotation&gt; implements ConstraintValidator&lt;T, User&gt; {

    protected Predicate&lt;User&gt; predicate = c -&gt; true;

    @Resource
    protected UserRepository userRepository;

    @Override
    public boolean isValid(User user, ConstraintValidatorContext constraintValidatorContext) {
        return userRepository == null || predicate.test(user);
    }

    /**
     * 校验用户是否唯一
     * 即判断数据库是否存在当前新用户的信息，如用户名，手机，邮箱
     */
    public static class UniqueUserValidator extends UserValidation&lt;UniqueUser&gt;{
        @Override
        public void initialize(UniqueUser uniqueUser) {
            predicate = c -&gt; !userRepository.existsByUserNameOrEmailOrTelphone(c.getUserName(),c.getEmail(),c.getTelphone());
        }
    }

    /**
     * 校验是否与其他用户冲突
     * 将用户名、邮件、电话改成与现有完全不重复的，或者只与自己重复的，就不算冲突
     */
    public static class NotConflictUserValidator extends UserValidation&lt;NotConflictUser&gt;{
        @Override
        public void initialize(NotConflictUser notConflictUser) {
            predicate = c -&gt; {
                log.info(&quot;user detail is {}&quot;,c);
                Collection&lt;User&gt; collection = userRepository.findByUserNameOrEmailOrTelphone(c.getUserName(), c.getEmail(), c.getTelphone());
                // 将用户名、邮件、电话改成与现有完全不重复的，或者只与自己重复的，就不算冲突
                return collection.isEmpty() || (collection.size() == 1 &amp;&amp; collection.iterator().next().getId().equals(c.getId()));
            };
        }
    }

}
</code></pre>
<p>这里使用Predicate函数式接口对业务规则进行判断。</p>
<h3 id="使用">使用</h3>
<pre><code>@RestController
@RequestMapping(&quot;/senior/user&quot;)
@Slf4j
@Validated
public class UserController {
    @Autowired
    private UserRepository userRepository;
    

    @PostMapping
    public User createUser(@UniqueUser @Valid User user){
        User savedUser = userRepository.save(user);
        log.info(&quot;save user id is {}&quot;,savedUser.getId());
        return savedUser;
    }

    @SneakyThrows
    @PutMapping
    public User updateUser(@NotConflictUser @Valid @RequestBody User user){
        User editUser = userRepository.save(user);
        log.info(&quot;update user is {}&quot;,editUser);
        return editUser;
    }
}
</code></pre>
<p>使用很简单，只需要在方法上加入自定义注解即可，业务逻辑中不需要添加任何业务规则的代码。</p>
<h3 id="测试">测试</h3>
<p>调用接口后出现如下错误，说明业务规则校验生效。</p>
<pre><code>{
  &quot;status&quot;: 400,
  &quot;message&quot;: &quot;用户名、手机号码、邮箱不允许与现存用户重复&quot;,
  &quot;data&quot;: null,
  &quot;timestamp&quot;: 1644309081037
}
</code></pre>
<h3 id="小结">小结</h3>
<p>通过上面几步操作，业务校验便和业务逻辑就完全分离开来，在需要校验时用<code>@Validated</code>注解自动触发，或者通过代码手动触发执行，可根据你们项目的要求，将这些注解应用于控制器、服务层、持久层等任何层次的代码之中。</p>
<p>这种方式比任何业务规则校验的方法都优雅，推荐大家在项目中使用。在开发时可以将不带业务含义的格式校验注解放到 Bean 的类定义之上，将带业务逻辑的校验放到 Bean 的类定义的外面。<strong>这两者的区别是放在类定义中的注解能够自动运行，而放到类外面则需要像前面代码那样，明确标出注解时才会运行。</strong></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[WebFlux与WebMVC区别]]></title>
        <id>https://tinaxiawuhao.github.io/post/OoSJ8O7Jf/</id>
        <link href="https://tinaxiawuhao.github.io/post/OoSJ8O7Jf/">
        </link>
        <updated>2022-02-24T02:30:44.000Z</updated>
        <content type="html"><![CDATA[<p>在构建响应式 Web 服务上，Spring 5 中引入了全新的编程框架，那就是 Spring WebFlux。作为一款新型的 Web 服务开发框架，它与传统的 WebMVC 相比具体有哪些优势呢？</p>
<h2 id="spring-webflux-的应用场景">Spring WebFlux 的应用场景</h2>
<p>WebFlux 用于构建响应式 Web 服务。在详细介绍 WebFlux 之前，我们先梳理一下这个新框架的应用场景，了解应用场景才能帮助我们对所要采用的技术体系做出正确的选择。</p>
<p>微服务架构的兴起为 WebFlux 的应用提供了一个很好的场景。我们知道在一个微服务系统中，存在数十乃至数百个独立的微服务，它们相互通信以完成复杂的业务流程。这个过程势必会涉及大量的 I/O 操作，尤其是阻塞式 I/O 操作会整体增加系统的延迟并降低吞吐量。如果能够在复杂的流程中集成非阻塞、异步通信机制，我们就可以高效处理跨服务之间的网络请求。针对这种场景，WebFlux 是一种非常有效的解决方案。</p>
<h3 id="从-webmvc-到-webflux">从 WebMVC 到 WebFlux</h3>
<p>接下来，我们将讨论 WebMVC 与 WebFlux 之间的差别，而这些差别实际上正是体现在从 WebMVC 到 WebFlux 的演进过程中。让我们先从传统的 Spring WebMVC 技术栈开始说起。</p>
<h4 id="spring-webmvc技术栈">Spring WebMVC技术栈</h4>
<p>一般而言，Web 请求处理机制都会使用“管道-过滤器（Pipe-Filter）”架构模式，而 Spring WebMVC 作为一种处理 Web 请求的典型实现方案，同样使用了 Servlet 中的过滤器链（FilterChain）来对请求进行拦截，如下图所示。</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1645756459790.jpg" alt="" loading="lazy"></figure>
<p>我们知道 WebMVC 运行在 Servlet 容器上，这些容器常用的包括 Tomcat、JBoss 等。当 HTTP 请求通过 Servlet 容器时就会被转换为一个 ServletRequest 对象，而最终返回一个 ServletResponse 对象，FilterChain 的定义如下所示。</p>
<pre><code>public interface FilterChain {    
    public void doFilter (ServletRequest request, ServletResponse response ) throws IOException, ServletException; 
}
</code></pre>
<p>当 ServletRequest 通过过滤器链中所包含的一系列过滤器之后，最终就会到达作为前端控制器的 DispatcherServlet。DispatcherServlet 是 WebMVC 的核心组件，扩展了 Servlet 对象，并持有一组 HandlerMapping 和 HandlerAdapter。</p>
<p>当 ServletRequest 请求到达时，DispatcherServlet 负责搜索 HandlerMapping 实例并使用合适的 HandlerAdapter 对其进行适配。其中，HandlerMapping 的作用是根据当前请求找到对应的处理器 Handler，它只定义了一个方法，如下所示。</p>
<pre><code>public interface HandlerMapping {
 
    //找到与请求对应的 Handler，封装为一个 HandlerExecutionChain 返回
 HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception;
}
</code></pre>
<p>而 HandlerAdapter 根据给定的 HttpServletRequest 和 HttpServletResponse 对象真正调用给定的 Handler，核心方法如下所示。</p>
<pre><code>public interface HandlerAdapter { 
  //针对给定的请求/响应对象调用目标 Handler
  ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception;
}
</code></pre>
<p>在执行过程中，DispatcherServlet 会在应用上下文中搜索所有 HandlerMapping。日常开发过程中，最常用的 HandlerMapping 包含 BeanNameUrlHandlerMapping 和 RequestMappingHandlerMapping，前者负责检测所有 Controller 并根据请求 URL 的匹配规则映射到具体的 Controller 实例上，而后者基于 @RequestMapping 注解来找到目标 Controller。</p>
<p>如果我们使用了 RequestMappingHandlerMapping，那么对应的 HandlerAdapter 就是 RequestMappingHandlerAdapter，它负责将传入的 ServletRequest 绑定到添加了 @RequestMapping 注解的控制器方法上，从而实现对请求的正确响应。同时， HandlerAdapter 还提供请求验证和响应转换等辅助性功能，使得 Spring WebMVC 框架在日常 Web 开发中非常实用。</p>
<p>作为总结，我梳理了 Spring WebMVC 的整体架构，如下图所示。</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1645756470064.jpg" alt="" loading="lazy"></figure>
<p>一直以来，Spring WebMVC 是我们开发 Web 服务的主流框架。但要注意的是，尽管 Servlet 本身在新版本中提供了异步非阻塞的通信机制，但 Spring WebMVC 在实现上并不允许在整个请求生命周期中都采用非阻塞式的操作方式。因此，Spring 在尽量沿用原有的开发模式以及 API 设计上提供了支持异步非阻塞的 Spring WebFlux 框架。</p>
<h4 id="spring-webflux-技术栈">Spring WebFlux 技术栈</h4>
<p>介绍完 Spring WebMVC，我们来说说 Spring WebFlux。事实上，前面介绍的 HandlerMapping、HandlerAdapter 等组件在 WebFlux 里都有同名的响应式版本，这是 WebFlux 的一种设计理念，即在既有设计的基础上，提供新的实现版本，只对部分需要增强和弱化的地方做了调整。</p>
<p>我们先来看第一个需要调整的地方，显然，我们应该替换掉原有的 Servlet API 以便融入响应式流。因此，在 WebFlux 中，代表请求和响应的是全新的 ServerHttpRequest 和 ServerHttpResponse 对象。</p>
<p>同样，WebFlux 中同样提供了一个过滤器链 WebFilterChain，定义如下。</p>
<pre><code>public interface WebFilterChain {
    Mono&lt;Void&gt; filter(ServerWebExchange exchange);
}
</code></pre>
<p>这里的 ServerWebExchange 相当于一个上下文容器，保存了 ServerHttpRequest、ServerHttpResponse 以及一些框架运行时状态信息。</p>
<p>在 WebFlux 中，和 WebMVC 中的 DispatcherServlet 相对应的组件是 DispatcherHandler。与 DispatcherServlet 类似，DispatcherHandler 同样使用了一套响应式版本的 HandlerMapping 和 HandlerAdapter 完成对请求的处理。请注意，这两个接口是定义在 org.springframework.web.reactive 包中，而不是在原有的 org.springframework.web 包中。响应式版本的 HandlerMapping 接口定义如下，可以看到这里返回的是一个 Mono 对象，从而启用了响应式行为模式。</p>
<pre><code>public interface HandlerMapping {  
 Mono&lt;Object&gt; getHandler(ServerWebExchange exchange);
}
</code></pre>
<p>同样，我们找到响应式版本的 HandlerAdapter，如下所示。</p>
<pre><code>public interface HandlerAdapter {
    Mono&lt;HandlerResult&gt; handle(ServerWebExchange exchange, Object handler);
}
</code></pre>
<p>对比非响应式版本的 HandlerAdapter，这里的 ServerWebExchange 中同时包含了 ServerHttpRequest 和 ServerHttpResponse 对象，而 HandlerResult 则代表了处理结果。相比 WebMVC 中 ModelAndView 这种比较模糊的返回结果，HandlerResult 更加直接和明确。</p>
<p>在 WebFlux 中，同样实现了响应式版本的 RequestMappingHandlerMapping 和 RequestMappingHandlerAdapter，因此我们仍然可以采用注解的方法来构建 Controller。另一方面，WebFlux 中还提供了 RouterFunctionMapping 和 HandlerFunctionAdapter 组合，专门用来提供基于函数式编程的开发模式。这样 Spring WebFlux 的整体架构图就演变成这样。</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1645756480125.jpg" alt="" loading="lazy"></figure>
<p>请注意，在处理 HTTP 请求上，我们需要使用支持异步非阻塞的响应式服务器引擎，常见的包括 Netty、Undertow 以及支持 Servlet 3.1 及以上版本的 Servlet 容器。</p>
<h3 id="对比-webflux-和-webmvc-的处理模型">对比 WebFlux 和 WebMVC 的处理模型</h3>
<p>现在我们已经明确了 WebMVC 到 WebFlux 的演进过程，但你可能会问，新的 WebFlux 要比传统 WebMVC 好在哪里呢？从两者的处理模型上入手可以帮助你很好地理解这个问题，我们一起来看一下。</p>
<h4 id="webflux-和-web-mvc-中的处理模型">WebFlux 和 Web MVC 中的处理模型</h4>
<p>通过前面的讨论你已经知道 Servlet 是阻塞式的，所以 WebMVC 建立在阻塞 I/O 之上，我们来分析这种模型下线程处理请求的过程。假设有一个工作线程会处理来自客户端的请求，所有请求构成一个请求队列，并由一个线程按顺序进行处理。针对一个请求，线程需要执行两部分工作，首先是接受请求，然后再对其进行处理，如下图所示。</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1645756487462.jpg" alt="" loading="lazy"></figure>
<p>在前面的示例中，正如你可能注意到的，工作线程的实际处理时间远小于花费在阻塞操作上的时间。这意味着工作线程会被 I/O 读取或写入数据这一操作所阻塞。从这个简单的图中，<strong>我们可以得出结论，线程效率低下</strong>。同时，因为所有请求是排队的，相当于一个请求队列，所以接受请求和处理请求这两部分操作实际上是可以共享等待时间的。</p>
<p>相比之下，WebFlux 构建在非阻塞 API 之上，这意味着没有操作需要与 I/O 阻塞线程进行交互。接受和处理请求的效率很高，如下图所示。</p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1645756494658.jpg" alt="" loading="lazy"></figure>
<p>将上图中所展示的异步非阻塞请求处理与前面的阻塞过程进行比较，我们会注意到，现在没有在读取请求数据时发生等待，工作线程高效接受新连接。然后，提供了非阻塞 I/O 机制的底层操作系统会告诉我们请求数据是否已经接收完成，并且处理器可以在不阻塞的情况下进行处理。</p>
<p>类似的，写入响应结果时同样不需要阻塞，操作系统会在准备好将一部分数据非阻塞地写入 I/O 时通知我们。这样，我们就拥有了最佳的 CPU 利用率。</p>
<p>前面的示例展示了 WebFlux 比 WebMVC 更有效地利用一个工作线程，因此可以在相同的时间内处理更多的请求。那么，如果是在多线程的场景下会发生什么呢？我们来看下面这张图。</p>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1645756501100.jpg" alt="" loading="lazy"></figure>
<p>从上图中可以看出，多线程模型允许更快地处理排队请求，能够同时接受、处理和响应几乎相同数量的请求。当然，我们明白多线程技术有利有弊。当处理用户请求涉及太多的线程实例时，相互之间就需要协调资源，这是由于它们之间的不一致性会导致性能下降。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Spring Boot 自带 Buff 工具类]]></title>
        <id>https://tinaxiawuhao.github.io/post/I1j63ouUN/</id>
        <link href="https://tinaxiawuhao.github.io/post/I1j63ouUN/">
        </link>
        <updated>2022-01-23T07:28:20.000Z</updated>
        <content type="html"><![CDATA[<h2 id="断言">断言</h2>
<ol>
<li>断言是一个逻辑判断，用于检查不应该发生的情况</li>
<li>Assert 关键字在 JDK1.4 中引入，可通过 JVM 参数<code>-enableassertions</code>开启</li>
<li>SpringBoot 中提供了 Assert 断言工具类，通常用于数据合法性检查</li>
</ol>
<pre><code class="language-java">// 要求参数 object 必须为非空（Not Null），否则抛出异常，不予放行
// 参数 message 参数用于定制异常信息。
void notNull(Object object, String message)
// 要求参数必须空（Null），否则抛出异常，不予『放行』。
// 和 notNull() 方法断言规则相反
void isNull(Object object, String message)
// 要求参数必须为真（True），否则抛出异常，不予『放行』。
void isTrue(boolean expression, String message)
// 要求参数（List/Set）必须非空（Not Empty），否则抛出异常，不予放行
void notEmpty(Collection collection, String message)
// 要求参数（String）必须有长度（即，Not Empty），否则抛出异常，不予放行
void hasLength(String text, String message)
// 要求参数（String）必须有内容（即，Not Blank），否则抛出异常，不予放行
void hasText(String text, String message)
// 要求参数是指定类型的实例，否则抛出异常，不予放行
void isInstanceOf(Class type, Object obj, String message)
// 要求参数 `subType` 必须是参数 superType 的子类或实现类，否则抛出异常，不予放行
void isAssignable(Class superType, Class subType, String message)
</code></pre>
<h2 id="对象-数组-集合">对象、数组、集合</h2>
<h3 id="objectutils">ObjectUtils</h3>
<ol>
<li>获取对象的基本信息</li>
</ol>
<pre><code class="language-java">// 获取对象的类名。参数为 null 时，返回字符串：&quot;null&quot; 
String nullSafeClassName(Object obj)
// 参数为 null 时，返回 0
int nullSafeHashCode(Object object)
// 参数为 null 时，返回字符串：&quot;null&quot;
String nullSafeToString(boolean[] array)
// 获取对象 HashCode（十六进制形式字符串）。参数为 null 时，返回 0 
String getIdentityHexString(Object obj)
// 获取对象的类名和 HashCode。 参数为 null 时，返回字符串：&quot;&quot; 
String identityToString(Object obj)
// 相当于 toString()方法，但参数为 null 时，返回字符串：&quot;&quot;
String getDisplayString(Object obj)
</code></pre>
<ol>
<li>判断工具</li>
</ol>
<pre><code class="language-java">// 判断数组是否为空
boolean isEmpty(Object[] array)
// 判断参数对象是否是数组
boolean isArray(Object obj)
// 判断数组中是否包含指定元素
boolean containsElement(Object[] array, Object element)
// 相等，或同为 null时，返回 true
boolean nullSafeEquals(Object o1, Object o2)
/*
判断参数对象是否为空，判断标准为：
   Optional: Optional.empty()
      Array: length == 0
CharSequence: length == 0
 Collection: Collection.isEmpty()
        Map: Map.isEmpty()
*/
boolean isEmpty(Object obj)
</code></pre>
<ol>
<li>其他工具方法</li>
</ol>
<pre><code class="language-java">// 向参数数组的末尾追加新元素，并返回一个新数组
&lt;A, O extends A&gt; A[] addObjectToArray(A[] array, O obj)
// 原生基础类型数组 --&gt; 包装类数组
Object[] toObjectArray(Object source)
</code></pre>
<h3 id="stringutils">StringUtils</h3>
<ol>
<li>字符串判断工具</li>
</ol>
<pre><code class="language-java">// 判断字符串是否为 null，或 &quot;&quot;。注意，包含空白符的字符串为非空
boolean isEmpty(Object str)
// 判断字符串是否是以指定内容结束。忽略大小写
boolean endsWithIgnoreCase(String str, String suffix)
// 判断字符串是否已指定内容开头。忽略大小写
boolean startsWithIgnoreCase(String str, String prefix) 
// 是否包含空白符
boolean containsWhitespace(String str)
// 判断字符串非空且长度不为 0，即，Not Empty
boolean hasLength(CharSequence str)
// 判断字符串是否包含实际内容，即非仅包含空白符，也就是 Not Blank
boolean hasText(CharSequence str)
// 判断字符串指定索引处是否包含一个子串。
boolean substringMatch(CharSequence str, int index, CharSequence substring)
// 计算一个字符串中指定子串的出现次数
int countOccurrencesOf(String str, String sub)
</code></pre>
<ol>
<li>字符串操作工具</li>
</ol>
<pre><code class="language-java">// 查找并替换指定子串
String replace(String inString, String oldPattern, String newPattern)
// 去除尾部的特定字符
String trimTrailingCharacter(String str, char trailingCharacter) 
// 去除头部的特定字符
String trimLeadingCharacter(String str, char leadingCharacter)
// 去除头部的空白符
String trimLeadingWhitespace(String str)
// 去除头部的空白符
String trimTrailingWhitespace(String str)
// 去除头部和尾部的空白符
String trimWhitespace(String str)
// 删除开头、结尾和中间的空白符
String trimAllWhitespace(String str)
// 删除指定子串
String delete(String inString, String pattern)
// 删除指定字符（可以是多个）
String deleteAny(String inString, String charsToDelete)
// 对数组的每一项执行 trim() 方法
String[] trimArrayElements(String[] array)
// 将 URL 字符串进行解码
String uriDecode(String source, Charset charset)
</code></pre>
<ol>
<li>路径相关工具方法</li>
</ol>
<pre><code class="language-java">// 解析路径字符串，优化其中的 “..” 
String cleanPath(String path)
// 解析路径字符串，解析出文件名部分
String getFilename(String path)
// 解析路径字符串，解析出文件后缀名
String getFilenameExtension(String path)
// 比较两个两个字符串，判断是否是同一个路径。会自动处理路径中的 “..” 
boolean pathEquals(String path1, String path2)
// 删除文件路径名中的后缀部分
String stripFilenameExtension(String path) 
// 以 “. 作为分隔符，获取其最后一部分
String unqualify(String qualifiedName)
// 以指定字符作为分隔符，获取其最后一部分
String unqualify(String qualifiedName, char separator)
</code></pre>
<h3 id="collectionutils">CollectionUtils</h3>
<ol>
<li>集合判断工具</li>
</ol>
<pre><code class="language-java">// 判断 List/Set 是否为空
boolean isEmpty(Collection&lt;?&gt; collection)
// 判断 Map 是否为空
boolean isEmpty(Map&lt;?,?&gt; map)
// 判断 List/Set 中是否包含某个对象
boolean containsInstance(Collection&lt;?&gt; collection, Object element)
// 以迭代器的方式，判断 List/Set 中是否包含某个对象
boolean contains(Iterator&lt;?&gt; iterator, Object element)
// 判断 List/Set 是否包含某些对象中的任意一个
boolean containsAny(Collection&lt;?&gt; source, Collection&lt;?&gt; candidates)
// 判断 List/Set 中的每个元素是否唯一。即 List/Set 中不存在重复元素
boolean hasUniqueObject(Collection&lt;?&gt; collection)
</code></pre>
<ol>
<li>集合操作工具</li>
</ol>
<pre><code class="language-java">// 将 Array 中的元素都添加到 List/Set 中
&lt;E&gt; void mergeArrayIntoCollection(Object array, Collection&lt;E&gt; collection)  
// 将 Properties 中的键值对都添加到 Map 中
&lt;K,V&gt; void mergePropertiesIntoMap(Properties props, Map&lt;K,V&gt; map)
// 返回 List 中最后一个元素
&lt;T&gt; T lastElement(List&lt;T&gt; list)  
// 返回 Set 中最后一个元素
&lt;T&gt; T lastElement(Set&lt;T&gt; set) 
// 返回参数 candidates 中第一个存在于参数 source 中的元素
&lt;E&gt; E findFirstMatch(Collection&lt;?&gt; source, Collection&lt;E&gt; candidates)
// 返回 List/Set 中指定类型的元素。
&lt;T&gt; T findValueOfType(Collection&lt;?&gt; collection, Class&lt;T&gt; type)
// 返回 List/Set 中指定类型的元素。如果第一种类型未找到，则查找第二种类型，以此类推
Object findValueOfType(Collection&lt;?&gt; collection, Class&lt;?&gt;[] types)
// 返回 List/Set 中元素的类型
Class&lt;?&gt; findCommonElementType(Collection&lt;?&gt; collection)
</code></pre>
<h2 id="文件-资源-io-流">文件、资源、IO 流</h2>
<h3 id="filecopyutils">FileCopyUtils</h3>
<ol>
<li>输入</li>
</ol>
<pre><code class="language-java">// 从文件中读入到字节数组中
byte[] copyToByteArray(File in)
// 从输入流中读入到字节数组中
byte[] copyToByteArray(InputStream in)
// 从输入流中读入到字符串中
String copyToString(Reader in)
</code></pre>
<ol>
<li>输出</li>
</ol>
<pre><code class="language-java">// 从字节数组到文件
void copy(byte[] in, File out)
// 从文件到文件
int copy(File in, File out)
// 从字节数组到输出流
void copy(byte[] in, OutputStream out) 
// 从输入流到输出流
int copy(InputStream in, OutputStream out) 
// 从输入流到输出流
int copy(Reader in, Writer out)
// 从字符串到输出流
void copy(String in, Writer out)
</code></pre>
<h3 id="resourceutils">ResourceUtils</h3>
<ol>
<li>从资源路径获取文件</li>
</ol>
<pre><code class="language-java">// 判断字符串是否是一个合法的 URL 字符串。
static boolean isUrl(String resourceLocation)
// 获取 URL
static URL getURL(String resourceLocation) 
// 获取文件（在 JAR 包内无法正常使用，需要是一个独立的文件）
static File getFile(String resourceLocation)
</code></pre>
<ol>
<li>Resource</li>
</ol>
<pre><code class="language-java">// 文件系统资源 D:\...
FileSystemResource
// URL 资源，如 file://... http://...
UrlResource
// 类路径下的资源，classpth:...
ClassPathResource
// Web 容器上下文中的资源（jar 包、war 包）
ServletContextResource
复制代码
// 判断资源是否存在
boolean exists()
// 从资源中获得 File 对象
File getFile()
// 从资源中获得 URI 对象
URI getURI()
// 从资源中获得 URI 对象
URL getURL()
// 获得资源的 InputStream
InputStream getInputStream()
// 获得资源的描述信息
String getDescription()
</code></pre>
<h3 id="streamutils">StreamUtils</h3>
<ol>
<li>输入</li>
</ol>
<pre><code class="language-java">void copy(byte[] in, OutputStream out)
int copy(InputStream in, OutputStream out)
void copy(String in, Charset charset, OutputStream out)
long copyRange(InputStream in, OutputStream out, long start, long end)
</code></pre>
<ol>
<li>输出</li>
</ol>
<pre><code class="language-java">byte[] copyToByteArray(InputStream in)
String copyToString(InputStream in, Charset charset)
// 舍弃输入流中的内容
int drain(InputStream in) 
</code></pre>
<h2 id="反射-aop">反射、AOP</h2>
<h3 id="reflectionutils">ReflectionUtils</h3>
<ol>
<li>获取方法</li>
</ol>
<pre><code class="language-java">// 在类中查找指定方法
Method findMethod(Class&lt;?&gt; clazz, String name) 
// 同上，额外提供方法参数类型作查找条件
Method findMethod(Class&lt;?&gt; clazz, String name, Class&lt;?&gt;... paramTypes) 
// 获得类中所有方法，包括继承而来的
Method[] getAllDeclaredMethods(Class&lt;?&gt; leafClass) 
// 在类中查找指定构造方法
Constructor&lt;T&gt; accessibleConstructor(Class&lt;T&gt; clazz, Class&lt;?&gt;... parameterTypes) 
// 是否是 equals() 方法
boolean isEqualsMethod(Method method) 
// 是否是 hashCode() 方法 
boolean isHashCodeMethod(Method method) 
// 是否是 toString() 方法
boolean isToStringMethod(Method method) 
// 是否是从 Object 类继承而来的方法
boolean isObjectMethod(Method method) 
// 检查一个方法是否声明抛出指定异常
boolean declaresException(Method method, Class&lt;?&gt; exceptionType) 
</code></pre>
<ol>
<li>执行方法</li>
</ol>
<pre><code class="language-java">// 执行方法
Object invokeMethod(Method method, Object target)  
// 同上，提供方法参数
Object invokeMethod(Method method, Object target, Object... args) 
// 取消 Java 权限检查。以便后续执行该私有方法
void makeAccessible(Method method) 
// 取消 Java 权限检查。以便后续执行私有构造方法
void makeAccessible(Constructor&lt;?&gt; ctor) 
</code></pre>
<ol>
<li>获取字段</li>
</ol>
<pre><code class="language-java">// 在类中查找指定属性
Field findField(Class&lt;?&gt; clazz, String name) 
// 同上，多提供了属性的类型
Field findField(Class&lt;?&gt; clazz, String name, Class&lt;?&gt; type) 
// 是否为一个 &quot;public static final&quot; 属性
boolean isPublicStaticFinal(Field field) 
</code></pre>
<ol>
<li>设置字段</li>
</ol>
<pre><code class="language-java">// 获取 target 对象的 field 属性值
Object getField(Field field, Object target) 
// 设置 target 对象的 field 属性值，值为 value
void setField(Field field, Object target, Object value) 
// 同类对象属性对等赋值
void shallowCopyFieldState(Object src, Object dest)
// 取消 Java 的权限控制检查。以便后续读写该私有属性
void makeAccessible(Field field) 
// 对类的每个属性执行 callback
void doWithFields(Class&lt;?&gt; clazz, ReflectionUtils.FieldCallback fc) 
// 同上，多了个属性过滤功能。
void doWithFields(Class&lt;?&gt; clazz, ReflectionUtils.FieldCallback fc, 
                 ReflectionUtils.FieldFilter ff) 
// 同上，但不包括继承而来的属性
void doWithLocalFields(Class&lt;?&gt; clazz, ReflectionUtils.FieldCallback fc) 
</code></pre>
<h3 id="aoputils">AopUtils</h3>
<ol>
<li>判断代理类型</li>
</ol>
<pre><code class="language-java">// 判断是不是 Spring 代理对象
boolean isAopProxy()
// 判断是不是 jdk 动态代理对象
isJdkDynamicProxy()
// 判断是不是 CGLIB 代理对象
boolean isCglibProxy()
</code></pre>
<ol>
<li>获取被代理对象的 class</li>
</ol>
<pre><code class="language-java">// 获取被代理的目标 class
Class&lt;?&gt; getTargetClass()
</code></pre>
<h3 id="aopcontext">AopContext</h3>
<ol>
<li>获取当前对象的代理对象</li>
</ol>
<pre><code class="language-java">Object currentProxy()
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[nginx.conf中文详解]]></title>
        <id>https://tinaxiawuhao.github.io/post/yRJDaVAsJ/</id>
        <link href="https://tinaxiawuhao.github.io/post/yRJDaVAsJ/">
        </link>
        <updated>2022-01-18T09:17:06.000Z</updated>
        <content type="html"><![CDATA[<pre><code class="language-js">#定义Nginx运行的用户和用户组
user www www;

#nginx进程数，建议设置为等于CPU总核心数。
worker_processes 8;

#全局错误日志定义类型，[ debug | info | notice | warn | error | crit ]
error_log /usr/local/nginx/logs/error.log info;

#进程pid文件
pid /usr/local/nginx/logs/nginx.pid;

#指定进程可以打开的最大描述符：数目
#工作模式与连接数上限
#这个指令是指当一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（ulimit -n）与nginx进程数相除，但是nginx分配请求并不是那么均匀，所以最好与ulimit -n 的值保持一致。
#现在在linux 2.6内核下开启文件打开数为65535，worker_rlimit_nofile就相应应该填写65535。
#这是因为nginx调度时分配请求到进程并不是那么的均衡，所以假如填写10240，总并发量达到3-4万时就有进程可能超过10240了，这时会返回502错误。
worker_rlimit_nofile 65535;

events{
​    #参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型
​    #是Linux 2.6以上版本内核中的高性能网络I/O模型，linux建议epoll，如果跑在FreeBSD上面，就用kqueue模型。
​    #补充说明：
​    #与apache相类，nginx针对不同的操作系统，有不同的事件模型
​    #A）标准事件模型
​    #Select、poll属于标准事件模型，如果当前系统不存在更有效的方法，nginx会选择select或poll
​    #B）高效事件模型
​    #Kqueue：使用于FreeBSD 4.1+, OpenBSD 2.9+, NetBSD 2.0 和 MacOS X.使用双处理器的MacOS X系统使用kqueue可能会造成内核崩溃。
​    #Epoll：使用于Linux内核2.6版本及以后的系统。
​    #/dev/poll：使用于Solaris 7 11/99+，HP/UX 11.22+ (eventport)，IRIX 6.5.15+ 和 Tru64 UNIX 5.1A+。
​    #Eventport：使用于Solaris 10。 为了防止出现内核崩溃的问题， 有必要安装安全补丁。
​    use epoll;

​    #单个进程最大连接数（最大连接数=连接数*进程数）
​    #根据硬件调整，和前面工作进程配合起来用，尽量大，但是别把cpu跑到100%就行。每个进程允许的最多连接数，理论上每台nginx服务器的最大连接数为。
​    worker_connections 65535;

​    #keepalive超时时间。
​    keepalive_timeout 60;

​    #客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求头的大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。
​    #分页大小可以用命令getconf PAGESIZE 取得。
​    #[root@web001 ~]# getconf PAGESIZE
​    #4096
​    #但也有client_header_buffer_size超过4k的情况，但是client_header_buffer_size该值必须设置为“系统分页大小”的整倍数。
​    client_header_buffer_size 4k;

​    #这个将为打开文件指定缓存，默认是没有启用的，max指定缓存数量，建议和打开文件数一致，inactive是指经过多长时间文件没被请求后删除缓存。
​    open_file_cache max=65535 inactive=60s;

​    #这个是指多长时间检查一次缓存的有效信息。
​    #语法:open_file_cache_valid time 默认值:open_file_cache_valid 60 使用字段:http, server, location 这个指令指定了何时需要检查open_file_cache中缓存项目的有效信息.
​    open_file_cache_valid 80s;

​    #open_file_cache指令中的inactive参数时间内文件的最少使用次数，如果超过这个数字，文件描述符一直是在缓存中打开的，如上例，如果有一个文件在inactive时间内一次没被使用，它将被移除。
​    #语法:open_file_cache_min_uses number 默认值:open_file_cache_min_uses 1 使用字段:http, server, location  这个指令指定了在open_file_cache指令无效的参数中一定的时间范围内可以使用的最小文件数,如果使用更大的值,文件描述符在cache中总是打开状态.
​    open_file_cache_min_uses 1;

​    #语法:open_file_cache_errors on | off 默认值:open_file_cache_errors off 使用字段:http, server, location 这个指令指定是否在搜索一个文件时记录cache错误.
​    open_file_cache_errors on;

}

#设定http服务器，利用它的反向代理功能提供负载均衡支持
http{

​    #文件扩展名与文件类型映射表
​    include mime.types;

​    #默认文件类型
​    default_type application/octet-stream;

​    #默认编码
​    #charset utf-8;
​    #服务器名字的hash表大小
​    #保存服务器名字的hash表是由指令server_names_hash_max_size 和server_names_hash_bucket_size所控制的。参数hash bucket size总是等于hash表的大小，并且是一路处理器缓存大小的倍数。在减少了在内存中的存取次数后，使在处理器中加速查找hash表键值成为可能。如果hash bucket size等于一路处理器缓存的大小，那么在查找键的时候，最坏的情况下在内存中查找的次数为2。第一次是确定存储单元的地址，第二次是在存储单元中查找键 值。因此，如果Nginx给出需要增大hash max size 或 hash bucket size的提示，那么首要的是增大前一个参数的大小.
​    server_names_hash_bucket_size 128;

​    #客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求的头部大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。分页大小可以用命令getconf PAGESIZE取得。
​    client_header_buffer_size 32k;

​    #客户请求头缓冲大小。nginx默认会用client_header_buffer_size这个buffer来读取header值，如果header过大，它会使用large_client_header_buffers来读取。
​    large_client_header_buffers 4 64k;

​    #设定通过nginx上传文件的大小
​    client_max_body_size 8m;

​    #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。
​    #sendfile指令指定 nginx 是否调用sendfile 函数（zero copy 方式）来输出文件，对于普通应用，必须设为on。如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络IO处理速度，降低系统uptime。
​    sendfile on;

​    #开启目录列表访问，合适下载服务器，默认关闭。
​    autoindex on;

​    #此选项允许或禁止使用socke的TCP_CORK的选项，此选项仅在使用sendfile的时候使用
​    tcp_nopush on;

​    tcp_nodelay on;

​    #长连接超时时间，单位是秒
​    keepalive_timeout 120;

​    #FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解。
​    fastcgi_connect_timeout 300;
​    fastcgi_send_timeout 300;
​    fastcgi_read_timeout 300;
​    fastcgi_buffer_size 64k;
​    fastcgi_buffers 4 64k;
​    fastcgi_busy_buffers_size 128k;
​    fastcgi_temp_file_write_size 128k;

​    #gzip模块设置
​    gzip on; #开启gzip压缩输出
​    gzip_min_length 1k;    #最小压缩文件大小
​    gzip_buffers 4 16k;    #压缩缓冲区
​    gzip_http_version 1.0;    #压缩版本（默认1.1，前端如果是squid2.5请使用1.0）
​    gzip_comp_level 2;    #压缩等级
​    gzip_types text/plain application/x-javascript text/css application/xml;    #压缩类型，默认就已经包含textml，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn。
​    gzip_vary on;

​    #开启限制IP连接数的时候需要使用
​    #limit_zone crawler $binary_remote_addr 10m;
​    #负载均衡配置
​    upstream jh.w3cschool.cn {

​        #upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。
​        server 192.168.80.121:80 weight=3;
​        server 192.168.80.122:80 weight=2;
​        server 192.168.80.123:80 weight=3;

​        #nginx的upstream目前支持4种方式的分配
​        #1、轮询（默认）
​        #每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。
​        #2、weight
​        #指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。
​        #例如：
​        #upstream bakend {
​        #    server 192.168.0.14 weight=10;
​        #    server 192.168.0.15 weight=10;
​        #}
​        #2、ip_hash
​        #每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。
​        #例如：
​        #upstream bakend {
​        #    ip_hash;
​        #    server 192.168.0.14:88;
​        #    server 192.168.0.15:80;
​        #}
​        #3、fair（第三方）
​        #按后端服务器的响应时间来分配请求，响应时间短的优先分配。
​        #upstream backend {
​        #    server server1;
​        #    server server2;
​        #    fair;
​        #}
​        #4、url_hash（第三方）
​        #按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。
​        #例：在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法
​        #upstream backend {
​        #    server squid1:3128;
​        #    server squid2:3128;
​        #    hash $request_uri;
​        #    hash_method crc32;
​        #}
​        #tips:
​        #upstream bakend{#定义负载均衡设备的Ip及设备状态}{
​        #    ip_hash;
​        #    server 127.0.0.1:9090 down;
​        #    server 127.0.0.1:8080 weight=2;
​        #    server 127.0.0.1:6060;
​        #    server 127.0.0.1:7070 backup;
​        #}
​        #在需要使用负载均衡的server中增加 proxy_pass http://bakend/;
​        #每个设备的状态设置为:
​        #1.down表示单前的server暂时不参与负载
​        #2.weight为weight越大，负载的权重就越大。
​        #3.max_fails：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream模块定义的错误
​        #4.fail_timeout:max_fails次失败后，暂停的时间。
​        #5.backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。
​        #nginx支持同时设置多组的负载均衡，用来给不用的server来使用。
​        #client_body_in_file_only设置为On 可以讲client post过来的数据记录到文件中用来做debug
​        #client_body_temp_path设置记录文件的目录 可以设置最多3层目录
​        #location对URL进行匹配.可以进行重定向或者进行新的代理 负载均衡
​    }

​    #虚拟主机的配置
​    server{

​        #监听端口
​        listen 80;

​        #域名可以有多个，用空格隔开
​        server_name www.w3cschool.cn w3cschool.cn;
​        index index.html index.htm index.php;
​        root /data/www/w3cschool;

​        #对******进行负载均衡
​        location ~ .*.(php|php5)?${
​            fastcgi_pass 127.0.0.1:9000;
​            fastcgi_index index.php;
​            include fastcgi.conf;
​        }

​        #图片缓存时间设置
​        location ~ .*.(gif|jpg|jpeg|png|bmp|swf)${
​            expires 10d;
​        }

​        #JS和CSS缓存时间设置

​        location ~ .*.(js|css)?${
​            expires 1h;
​        }

​        #日志格式设定
​        #$remote_addr与$http_x_forwarded_for用以记录客户端的ip地址；
​        #$remote_user：用来记录客户端用户名称；
​        #$time_local： 用来记录访问时间与时区；
​        #$request： 用来记录请求的url与http协议；
​        #$status： 用来记录请求状态；成功是200，
​        #$body_bytes_sent ：记录发送给客户端文件主体内容大小；
​        #$http_referer：用来记录从那个页面链接访问过来的；
​        #$http_user_agent：记录客户浏览器的相关信息；
​        #通常web服务器放在反向代理的后面，这样就不能获取到客户的IP地址了，通过$remote_add拿到的IP地址是反向代理服务器的iP地址。反向代理服务器在转发请求的http头信息中，可以增加x_forwarded_for信息，用以记录原有客户端的IP地址和原来客户端的请求的服务器地址。
​        log_format access '$remote_addr - $remote_user [$time_local] &quot;$request&quot; '
​        '$status $body_bytes_sent &quot;$http_referer&quot; '
​        '&quot;$http_user_agent&quot; $http_x_forwarded_for';

​        #定义本虚拟主机的访问日志
​        access_log  /usr/local/nginx/logs/host.access.log  main;
​        access_log  /usr/local/nginx/logs/host.access.404.log  log404;

​        #对 &quot;/&quot; 启用反向代理
​        location / {
​            proxy_pass http://127.0.0.1:88;
​            proxy_redirect off;
​            proxy_set_header X-Real-IP $remote_addr;

​            #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP
​            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

​            #以下是一些反向代理的配置，可选。
​            proxy_set_header Host $host;

​            #允许客户端请求的最大单文件字节数
​            client_max_body_size 10m;

​            #缓冲区代理缓冲用户端请求的最大字节数，
​            #如果把它设置为比较大的数值，例如256k，那么，无论使用firefox还是IE浏览器，来提交任意小于256k的图片，都很正常。如果注释该指令，使用默认的client_body_buffer_size设置，也就是操作系统页面大小的两倍，8k或者16k，问题就出现了。
​            #无论使用firefox4.0还是IE8.0，提交一个比较大，200k左右的图片，都返回500 Internal Server Error错误
​            client_body_buffer_size 128k;

​            #表示使nginx阻止HTTP应答代码为400或者更高的应答。
​            proxy_intercept_errors on;

​            #后端服务器连接的超时时间_发起握手等候响应超时时间
​            #nginx跟后端服务器连接超时时间(代理连接超时)
​            proxy_connect_timeout 90;

​            #后端服务器数据回传时间(代理发送超时)
​            #后端服务器数据回传时间_就是在规定时间之内后端服务器必须传完所有的数据
​            proxy_send_timeout 90;

​            #连接成功后，后端服务器响应时间(代理接收超时)
​            #连接成功后_等候后端服务器响应时间_其实已经进入后端的排队之中等候处理（也可以说是后端服务器处理请求的时间）
​            proxy_read_timeout 90;

​            #设置代理服务器（nginx）保存用户头信息的缓冲区大小
​            #设置从被代理服务器读取的第一部分应答的缓冲区大小，通常情况下这部分应答中包含一个小的应答头，默认情况下这个值的大小为指令proxy_buffers中指定的一个缓冲区的大小，不过可以将其设置为更小
​            proxy_buffer_size 4k;

​            #proxy_buffers缓冲区，网页平均在32k以下的设置
​            #设置用于读取应答（来自被代理服务器）的缓冲区数目和大小，默认情况也为分页大小，根据操作系统的不同可能是4k或者8k
​            proxy_buffers 4 32k;

​            #高负荷下缓冲大小（proxy_buffers*2）
​            proxy_busy_buffers_size 64k;

​            #设置在写入proxy_temp_path时数据的大小，预防一个工作进程在传递文件时阻塞太长
​            #设定缓存文件夹大小，大于这个值，将从upstream服务器传
​            proxy_temp_file_write_size 64k;
​        }   

​        #设定查看Nginx状态的地址
​        location /NginxStatus {
​            stub_status on;
​            access_log on;
​            auth_basic &quot;NginxStatus&quot;;
​            auth_basic_user_file confpasswd;
​            #htpasswd文件的内容可以用apache提供的htpasswd工具来产生。
​        }

​        #本地动静分离反向代理配置
​        #所有jsp的页面均交由tomcat或resin处理
​        location ~ .(jsp|jspx|do)?$ {
​            proxy_set_header Host $host;
​            proxy_set_header X-Real-IP $remote_addr;
​            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
​            proxy_pass http://127.0.0.1:8080;
​        }

​        #所有静态文件由nginx直接读取不经过tomcat或resin
​        location ~ .*.(htm|html|gif|jpg|jpeg|png|bmp|swf|ioc|rar|zip|txt|flv|mid|doc|ppt|
​        pdf|xls|mp3|wma)${
​            expires 15d; 
​        }

​        location ~ .*.(js|css)?${
​            expires 1h;
​        }
​    }
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[docker 宿主机定时清除容器的运行日志]]></title>
        <id>https://tinaxiawuhao.github.io/post/KW_02xshc/</id>
        <link href="https://tinaxiawuhao.github.io/post/KW_02xshc/">
        </link>
        <updated>2022-01-17T03:35:08.000Z</updated>
        <content type="html"><![CDATA[<p>一般docker容器都是最小化安装，不仅如此系统定时器相关的服务也不存在，自己去安装也很麻烦，故此直接使用宿主机的定时器即可。</p>
<h4 id="一-在容器中编写清除日志脚本">一、在容器中编写清除日志脚本</h4>
<p>这一部分不论你是把定时器加在宿主机或者是容器都必须要去做的 ；</p>
<p>网上随意一搜就可以看到如下的删除模板：</p>
<pre><code class="language-shell">find 对应目录 -mtime +天数 -name &quot;文件名&quot; -exec rm -rf {} \;
</code></pre>
<p>因为本人的日志目录层级比较深 所以改良了如下：</p>
<pre><code class="language-shell">1. -- /opt/auto-del-log.sh 
2. \#!/bin/sh
3. find /home/schedule_log/ -mtime -5 -type f -iname &quot;*.log&quot; -exec rm -rf {} \;
</code></pre>
<p>一定记得加可执行权限</p>
<pre><code class="language-shell">chmod +777 /opt/auto-del-log.sh
</code></pre>
<p>后面经过验证 其实效果是一样的! 重点就是你要去验证你的脚本有无效！ 你可以这样直接输入验证</p>
<pre><code class="language-shell">1. find /home/schedule_log/  -type f -iname &quot;*.log&quot;
2. 或者
3. find /home/schedule_log/  -name &quot;*.log&quot;
</code></pre>
<p>如果能查出你想删除的文件那么后面就可以开始套模板了。</p>
<pre><code class="language-shell">-mtime：标准语句写法；
+30：查找30天前的文件，这里用数字代表天数；
&quot;*.log&quot;：希望查找的数据类型，&quot;*.jpg&quot;表示查找扩展名为jpg的所有文件，&quot;*&quot;表示查找所有文件，这个可以灵活运用，举一反三；
-exec：固定写法；
rm -rf：强制删除文件，包括目录；
{} \; ：固定写法，一对大括号+空格+\+; 
</code></pre>
<h4 id="二-宿主机加入定时器">二、宿主机加入定时器</h4>
<p>使用docker exec 命令校验之前写的脚本是否有效 如下：</p>
<pre><code class="language-shell">docker exec -it tomcat8002 /opt/auto-del-log.sh
tomcat8002 ： 容器名称或者ID
/opt/auto-del-log.sh :脚本在容器中的位置
</code></pre>
<p>如果此命令有效那么就可以编辑定时器了 本人采用的是centos7 具体可以参看网上介绍的挺全的一篇博客如下： <a href="https://blog.csdn.net/xudailong_blog/article/details/79303785">centos7 linux定时任务详解</a></p>
<pre><code class="language-shell">crontab -e
02 4 * * *  docker exec -it tomcat8002 /opt/auto-del-log.sh
</code></pre>
<p>接下来就OK啦！</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[docker安装elasticsearch]]></title>
        <id>https://tinaxiawuhao.github.io/post/2K9TL16e1/</id>
        <link href="https://tinaxiawuhao.github.io/post/2K9TL16e1/">
        </link>
        <updated>2022-01-16T03:27:56.000Z</updated>
        <content type="html"><![CDATA[<pre><code class="language-shell">docker search elasticsearch
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1641958220593.png" alt="" loading="lazy"></figure>
<p>选择一个版本，拉取镜像</p>
<pre><code class="language-shell">docker pull elasticsearch:2.4.4
</code></pre>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1641958232628.png" alt="" loading="lazy"></figure>
<p>查看镜像</p>
<pre><code class="language-shell">docker images
</code></pre>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1641958242342.png" alt="" loading="lazy"></figure>
<p>通过镜像，启动一个容器，并将9200和9300端口映射到本机</p>
<pre><code class="language-shell">docker run -d -p 9200:9200 -p 9300:9300 -e ES_JAVA_OPTS=&quot;-Xms512m -Xmx512m&quot; --name elasticsearch elasticsearch:2.4.4
</code></pre>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1641958249892.png" alt="" loading="lazy"></figure>
<p>查看已启动容器</p>
<pre><code class="language-shell">docker ps
</code></pre>
<p>验证是否安装成功？访问：</p>
<p>http://localhost:9200/</p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1641958263133.png" alt="" loading="lazy"></figure>
<p>安装插件，先进入容器：</p>
<pre><code class="language-shell">docker exec -it 4d34fbf944a5 /bin/bash
</code></pre>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1641958286588.png" alt="" loading="lazy"></figure>
<p>进入容器bin目录，并执行安装插件命令：</p>
<pre><code class="language-shell">cd bin ls
</code></pre>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1641958295695.png" alt="" loading="lazy"></figure>
<pre><code class="language-shell"> plugin install mobz/elasticsearch-head /**（低版本执行命令有所不同）**/ plugin -install mobz/elasticsearch-head
</code></pre>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1641958307262.png" alt="" loading="lazy"></figure>
<p>访问：</p>
<p>http://localhost:9200/_plugin/head/</p>
<figure data-type="image" tabindex="9"><img src="https://tinaxiawuhao.github.io/post-images/1641958315308.png" alt="" loading="lazy"></figure>
<p>插件安装成功</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[使用docker搭建FastDFS文件系统]]></title>
        <id>https://tinaxiawuhao.github.io/post/yIe_yl-14/</id>
        <link href="https://tinaxiawuhao.github.io/post/yIe_yl-14/">
        </link>
        <updated>2022-01-15T03:20:42.000Z</updated>
        <content type="html"><![CDATA[<h3 id="1首先下载fastdfs文件系统的docker镜像">1.首先下载FastDFS文件系统的docker镜像</h3>
<p>查询镜像</p>
<pre><code class="language-shell">[root@localhost /]# docker search fastdfs
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1641957924999.png" alt="" loading="lazy"></figure>
<p>安装镜像</p>
<pre><code class="language-shell">[root@localhost ~]# docker pull season/fastdfs [root@localhost ~]# docker images
</code></pre>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1641957936532.png" alt="" loading="lazy"></figure>
<h3 id="2使用docker镜像构建tracker容器跟踪服务器起到调度的作用">2.使用docker镜像构建tracker容器（跟踪服务器，起到调度的作用）：</h3>
<p>创建tracker容器</p>
<pre><code class="language-shell">[root@localhost /]# docker run -ti -d --name trakcer -v ~/tracker_data:/fastdfs/tracker/data --net=host season/fastdfs tracker
</code></pre>
<p>Tracker服务器的端口默认是22122，你可以查看是否启用端口</p>
<pre><code class="language-shell">[root@localhost /]# netstat -aon | grep 22122
</code></pre>
<h3 id="3使用docker镜像构建storage容器存储服务器提供容量和备份服务">3.使用docker镜像构建storage容器（存储服务器，提供容量和备份服务）：</h3>
<pre><code class="language-shell">docker run -tid --name storage -v ~/storage_data:/fastdfs/storage/data -v ~/store_path:/fastdfs/store_path --net=host -e TRACKER_SERVER:192.168.115.130:22122 -e GROUP_NAME=group1 season/fastdfs storage
</code></pre>
<h3 id="4此时两个服务都以启动进行服务的配置">4.此时两个服务都以启动，进行服务的配置。</h3>
<p>进入storage容器，到storage的配置文件中配置http访问的端口，配置文件在<strong>fdfs_conf</strong>目录下的<strong>storage.conf。</strong></p>
<pre><code class="language-shell">[root@localhost /]# docker exec -it storage bash root@localhost:/# cd fdfs_conf root@localhost:/fdfs_conf# more storage.conf
</code></pre>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1641957952610.png" alt="" loading="lazy"></figure>
<p>往下拉，你会发现storage容器的ip不是你linux的ip，如下：</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1641957960584.png" alt="" loading="lazy"></figure>
<p>接下来，退出storage容器，并将配置文件拷贝一份出来：</p>
<pre><code class="language-shell">[root@localhost ~]# docker cp storage:/fdfs_conf/storage.conf ~/ [root@localhost ~]# vi ~/storage.conf
</code></pre>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1641957970483.png" alt="" loading="lazy"></figure>
<p>将修改后的配置文件拷贝到storagee的配置目录下：</p>
<pre><code class="language-shell">[root@localhost ~]# docker cp ~/storage.conf storage:/fdfs_conf/
</code></pre>
<p>重新启动storage容器</p>
<pre><code class="language-shell">[root@localhost ~]# docker stop storage [root@localhost ~]# docker start storage
</code></pre>
<p>查看tracker容器和storage容器的关联</p>
<pre><code class="language-shell">[root@localhost ~]# docker exec -it storage bash root@localhost:/# cd fdfs_conf root@localhost:/fdfs_conf# fdfs_monitor storage.conf
</code></pre>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1641957980436.png" alt="" loading="lazy"></figure>
<h3 id="5在docker模拟客户端上传文件到storage容器">5.在docker模拟客户端上传文件到storage容器</h3>
<p>开启一个客户端</p>
<pre><code class="language-shell">[root@localhost 00]# docker run -tid --name fdfs_sh --net=host season/fastdfs sh
</code></pre>
<p>更改配置文件，因为之前已经改过一次了，所以现在直接拷贝</p>
<pre><code class="language-shell">[root@localhost 00]# docker cp ~/storage.conf  fdfs_sh:/fdfs_conf/
</code></pre>
<p>创建一个txt文件</p>
<pre><code class="language-shell">[root@localhost 00]# docker exec -it fdfs_sh bash root@localhost:/# echo hello&gt;a.txt
</code></pre>
<p>进入<strong>fdfs_conf</strong>目录，并将文件上传到<strong>storage</strong>容器</p>
<pre><code class="language-shell">root@localhost:/# cd fdfs_conf root@localhost:/fdfs_conf# fdfs_upload_file storage.conf /a.txt
</code></pre>
<p><strong>/a.txt</strong>：指要上传的文件</p>
<p>上传之后，根据返回的路径去找<strong>a.txt</strong></p>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1641957990375.png" alt="" loading="lazy"></figure>
<p>退出去查看上传的txt文件</p>
<p>[root@localhost ~]# cd ~/store_path/data/00/00 [root@localhost 00]# ls</p>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1641958001513.png" alt="" loading="lazy"></figure>
<p>查看是否和输入的值是否相同</p>
<pre><code class="language-shell">[root@localhost 00]# more wKhzg1wGsieAL-3RAAAABncc3SA337.txt
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dockerfile详解]]></title>
        <id>https://tinaxiawuhao.github.io/post/jw7hb2R8R/</id>
        <link href="https://tinaxiawuhao.github.io/post/jw7hb2R8R/">
        </link>
        <updated>2022-01-14T03:00:49.000Z</updated>
        <content type="html"><![CDATA[<p><strong>Dockerfile详解</strong></p>
<h2 id="环境介绍">环境介绍</h2>
<ol>
<li>
<p>Dockerfile中所用的所有文件一定要和Dockerfile文件在同一级父目录下，可以为Dockerfile父目录的子目录</p>
</li>
<li>
<p>Dockerfile中相对路径默认都是Dockerfile所在的目录</p>
</li>
<li>
<p>Dockerfile中一定要惜字如金，能写到一行的指令，一定要写到一行，原因是分层构建，联合挂载这个特性。</p>
<p>Dockerfile中每一条指令被视为一层</p>
</li>
<li>
<p>Dockerfile中指明大写（约定俗成）</p>
</li>
</ol>
<h2 id="指令介绍">指令介绍</h2>
<h3 id="from">FROM</h3>
<blockquote>
<p>功能为指定基础镜像，并且必须是第一条指令。</p>
</blockquote>
<p>如果不以任何镜像为基础，那么写法为：<code>FROM scratch</code>。</p>
<p>同时意味着接下来所写的指令将作为镜像的第一层开始</p>
<p>语法：</p>
<pre><code class="language-shell">FROM &lt;image&gt;
FROM &lt;image&gt;:&lt;tag&gt;
FROM &lt;image&gt;:&lt;digest&gt; 
三种写法，其中&lt;tag&gt;和&lt;digest&gt; 是可选项，如果没有选择，那么默认值为latest
</code></pre>
<h3 id="maintainer">MAINTAINER</h3>
<blockquote>
<p>指定作者</p>
</blockquote>
<p>语法：</p>
<pre><code class="language-shell">MAINTAINER &lt;name&gt;
</code></pre>
<ul>
<li>新版docker中使用LABEL指明</li>
</ul>
<h3 id="label">LABEL</h3>
<blockquote>
<p>功能是为镜像指定标签</p>
</blockquote>
<p>语法：</p>
<pre><code class="language-shell">LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; ...
 一个Dockerfile种可以有多个LABEL，如下：

LABEL &quot;com.example.vendor&quot;=&quot;ACME Incorporated&quot;
LABEL com.example.label-with-value=&quot;foo&quot;
LABEL version=&quot;1.0&quot;
LABEL description=&quot;This text illustrates 
that label-values can span multiple lines.&quot;
 但是并不建议这样写，最好就写成一行，如太长需要换行的话则使用\符号

如下：

LABEL multi.label1=&quot;value1&quot; 
multi.label2=&quot;value2&quot; 
other=&quot;value3&quot;
</code></pre>
<p>说明：LABEL会继承基础镜像种的LABEL，如遇到key相同，则值覆盖</p>
<h3 id="add">ADD</h3>
<blockquote>
<p>一个复制命令，把文件复制到镜像中。</p>
</blockquote>
<p>如果把虚拟机与容器想象成两台linux服务器的话，那么这个命令就类似于scp，只是scp需要加用户名和密码的权限验证，而ADD不用。</p>
<p>语法如下：</p>
<pre><code class="language-shell">1. ADD &lt;src&gt;... &lt;dest&gt;
2. ADD [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;]
</code></pre>
<ul>
<li>路径的填写可以是容器内的绝对路径，也可以是相对于工作目录的相对路径，推荐写成绝对路径</li>
<li>可以是一个本地文件或者是一个本地压缩文件，还可以是一个url</li>
<li>如果把写成一个url，那么ADD就类似于wget命令</li>
</ul>
<p>示例</p>
<pre><code class="language-shell">ADD test relativeDir/ 
ADD test /relativeDir
ADD http://example.com/foobar/ 
</code></pre>
<p>注意事项</p>
<ul>
<li>src为一个目录的时候，会自动把目录下的文件复制过去，目录本身不会复制</li>
<li>如果src为多个文件，dest一定要是一个目录</li>
</ul>
<h3 id="copy">COPY</h3>
<blockquote>
<p>看这个名字就知道，又是一个复制命令</p>
</blockquote>
<p>语法如下：</p>
<pre><code class="language-shell">COPY &lt;src&gt;... &lt;dest&gt;
COPY [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;]
</code></pre>
<p>与ADD的区别</p>
<ul>
<li>COPY的只能是本地文件，其他用法一致</li>
</ul>
<h3 id="expose">EXPOSE</h3>
<blockquote>
<p>功能为暴漏容器运行时的监听端口给外部</p>
</blockquote>
<blockquote>
<p>但是EXPOSE并不会使容器访问主机的端口</p>
</blockquote>
<blockquote>
<p>如果想使得容器与主机的端口有映射关系，必须在容器启动的时候加上 -P参数</p>
</blockquote>
<p>语法：</p>
<pre><code class="language-shell">EXPOSE &lt;port&gt;/&lt;tcp/udp&gt;
</code></pre>
<h3 id="env">ENV</h3>
<blockquote>
<p>功能为设置环境变量</p>
</blockquote>
<p>语法有两种</p>
<pre><code class="language-shell"> ENV &lt;key&gt; &lt;value&gt;
 ENV &lt;key&gt;=&lt;value&gt; ...
</code></pre>
<p>两者的区别就是第一种是一次设置一个，第二种是一次设置多个</p>
<p><strong>在Dockerfile中使用变量的方式</strong></p>
<ul>
<li>$varname</li>
<li>${varname}</li>
<li>${varname:-default value}</li>
<li>$(varname:+default value}</li>
</ul>
<p>第一种和第二种相同</p>
<p>第三种表示当变量不存在使用-号后面的值</p>
<p>第四种表示当变量存在时使用+号后面的值（当然不存在也是使用后面的值）</p>
<h3 id="run">RUN</h3>
<blockquote>
<p>功能为运行指定的命令</p>
</blockquote>
<p>RUN命令有两种格式</p>
<pre><code class="language-shell">1. RUN &lt;command&gt;
2. RUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]
</code></pre>
<p>第一种后边直接跟shell命令</p>
<ul>
<li>在linux操作系统上默认 /bin/sh -c</li>
<li>在windows操作系统上默认 cmd /S /C</li>
</ul>
<p>第二种是类似于函数调用。</p>
<ul>
<li>可将executable理解成为可执行文件，后面就是两个参数。</li>
</ul>
<h3 id="cmd">CMD</h3>
<blockquote>
<p>功能为容器启动时默认命令或参数</p>
</blockquote>
<p>语法有三种写法</p>
<pre><code class="language-shell">CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;]
CMD [&quot;param1&quot;,&quot;param2&quot;]
CMD command param1 param2
</code></pre>
<p>第三种比较好理解了，就时shell这种执行方式和写法</p>
<p>第一种和第二种其实都是可执行文件加上参数的形式</p>
<p>举例说明两种写法：</p>
<pre><code class="language-shell">CMD [ &quot;sh&quot;, &quot;-c&quot;, &quot;echo $HOME&quot; 
CMD [ &quot;echo&quot;, &quot;$HOME&quot; ]
</code></pre>
<p>补充细节：这里边包括参数的一定要用双引号，就是&quot;,不能是单引号。千万不能写成单引号。</p>
<p>原因是参数传递后，docker解析的是一个JSON array</p>
<p><strong>RUN&amp;&amp;CMD</strong></p>
<blockquote>
<p>不要把RUN和CMD搞混了。 RUN是构件容器时就运行的命令以及提交运行结果 CMD是容器启动时执行的命令，在构件时并不运行，构件时紧紧指定了这个命令到底是个什么样子</p>
</blockquote>
<h3 id="entrypoint">ENTRYPOINT</h3>
<blockquote>
<p>功能是：容器启动时运行得启动命令</p>
</blockquote>
<p>语法如下：</p>
<pre><code class="language-shell">ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]  
ENTRYPOINT command param1 param2
</code></pre>
<p>如果从上到下看到这里的话，那么你应该对这两种语法很熟悉啦。</p>
<ul>
<li>第二种就是写shell</li>
<li>第一种就是可执行文件加参数</li>
</ul>
<p>与CMD比较说明（这俩命令太像了，而且还可以配合使用）：</p>
<ol>
<li>相同点：</li>
</ol>
<ul>
<li>只能写一条，如果写了多条，那么只有最后一条生效</li>
</ul>
<p>容器启动时才运行，运行时机相同</p>
<ol>
<li>不同点：</li>
</ol>
<ul>
<li>ENTRYPOINT不会被运行的command覆盖，而CMD则会被覆盖</li>
<li>如果我们在Dockerfile种同时写了ENTRYPOINT和CMD，并且CMD指令不是一个完整的可执行命令，那么CMD指定的内容将会作为ENTRYPOINT的参数</li>
</ul>
<p>如下：</p>
<pre><code class="language-shell">FROM ubuntu
ENTRYPOINT [&quot;top&quot;, &quot;-b&quot;]
CMD [&quot;-c&quot;]
</code></pre>
<p>如果我们在Dockerfile种同时写了ENTRYPOINT和CMD，并且CMD是一个完整的指令，那么它们两个会互相覆盖，谁在最后谁生效</p>
<p>如下：</p>
<pre><code class="language-shell">FROM ubuntu
ENTRYPOINT [&quot;top&quot;, &quot;-b&quot;]
CMD ls -al
</code></pre>
<p>那么将执行ls -al ,top -b不会执行。</p>
<p>Docker官方使用一张表格来展示了ENTRYPOINT 和</p>
<p>CMD不同组合的执行情况</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1645236614794.jpeg" alt="" loading="lazy"></figure>
<h3 id="volume">VOLUME</h3>
<blockquote>
<p>可实现挂载功能，可以将宿主机目录挂载到容器中</p>
</blockquote>
<p>说的这里大家都懂了，可用专用的文件存储当作Docker容器的数据存储部分</p>
<p>语法如下：</p>
<pre><code class="language-shell">VOLUME [&quot;/data&quot;]
</code></pre>
<p>说明：</p>
<p>[&quot;/data&quot;]可以是一个JsonArray ，也可以是多个值。所以如下几种写法都是正确的</p>
<pre><code class="language-shell">VOLUME [&quot;/var/log/&quot;]
VOLUME /var/log
VOLUME /var/log /var/db
</code></pre>
<p>一般的使用场景为需要持久化存储数据时</p>
<p>容器使用的是AUFS，这种文件系统不能持久化数据，当容器关闭后，所有的更改都会丢失。</p>
<h3 id="user">USER</h3>
<blockquote>
<p>设置启动容器的用户，可以是用户名或UID，所以，只有下面的两种写法是正确的</p>
</blockquote>
<pre><code class="language-shell">USER daemo
USER UID
</code></pre>
<p>注意：如果设置了容器以daemon用户去运行，那么RUN, CMD 和 ENTRYPOINT 都会以这个用户去运行,</p>
<p>使用这个命令一定要确认容器中拥有这个用户，并且拥有足够权限</p>
<h3 id="workdir">WORKDIR</h3>
<blockquote>
<p>设置工作目录</p>
</blockquote>
<p>语法：</p>
<pre><code class="language-shell">WORKDIR /path/to/workdir
</code></pre>
<p>设置工作目录，对RUN,CMD,ENTRYPOINT,COPY,ADD生效。如果不存在则会创建，也可以设置多次。</p>
<p>如：</p>
<pre><code class="language-shell">WORKDIR /a
WORKDIR b
WORKDIR c
RUN pwd
</code></pre>
<p>pwd执行的结果是/a/b/c</p>
<p>WORKDIR也可以解析环境变量</p>
<p>如：</p>
<pre><code class="language-shell">ENV DIRPATH /path
WORKDIR $DIRPATH/$DIRNAME
RUN pwd
</code></pre>
<p>pwd的执行结果是/path/$DIRNAME</p>
<h3 id="arg">ARG</h3>
<blockquote>
<p>设置变量命令</p>
</blockquote>
<p>语法：</p>
<pre><code class="language-shell">ARG &lt;name&gt;[=&lt;default value&gt;]
</code></pre>
<p>设置变量命令，ARG命令定义了一个变量，在docker build创建镜像的时候，使用 --build-arg =来指定参数</p>
<p>如果用户在build镜像时指定了一个参数没有定义在Dockerfile种，那么将有一个Warning</p>
<p>提示如下：</p>
<pre><code class="language-shell">[Warning] One or more build-args [foo] were not consumed.
</code></pre>
<p>我们可以定义一个或多个参数，如下：</p>
<pre><code class="language-shell">FROM busybox
ARG user1
ARG buildno
</code></pre>
<p>也可以给参数一个默认值：</p>
<pre><code class="language-shell">FROM busybox
ARG user1=someuser
ARG buildno=1
</code></pre>
<p>如果我们给了ARG定义的参数默认值，那么当build镜像时没有指定参数值，将会使用这个默认值</p>
<h3 id="onbuild">ONBUILD</h3>
<p>语法：</p>
<pre><code class="language-shell">ONBUILD [INSTRUCTION]
</code></pre>
<p>这个命令只对当前镜像的子镜像生效。</p>
<p>比如当前镜像为A，在Dockerfile种添加：</p>
<pre><code class="language-shell">ONBUILD RUN ls -al
</code></pre>
<ul>
<li>这个 ls -al 命令不会在A镜像构建或启动的时候执行</li>
</ul>
<p>此时有一个镜像B是基于A镜像构建的，那么这个ls -al 命令会在B镜像构建的时候被执行。</p>
<h3 id="stopsignal">STOPSIGNAL</h3>
<p>语法：</p>
<pre><code class="language-shell">STOPSIGNAL signal
</code></pre>
<p>STOPSIGNAL命令是的作用是当容器停止时给系统发送什么样的指令，默认是15</p>
<h3 id="healthcheck">HEALTHCHECK</h3>
<blockquote>
<p>容器健康状况检查命令</p>
</blockquote>
<p>语法有两种：</p>
<pre><code class="language-shell"> HEALTHCHECK [OPTIONS] CMD command
 HEALTHCHECK NONE
</code></pre>
<p>第一个的功能是在容器内部运行一个命令来检查容器的健康状况</p>
<p>第二个的功能是在基础镜像中取消健康检查命令</p>
<p>[OPTIONS]的选项支持以下三中选项：</p>
<ul>
<li>–interval=DURATION 两次检查默认的时间间隔为30秒</li>
<li>–timeout=DURATION 健康检查命令运行超时时长，默认30秒</li>
<li>–retries=N 当连续失败指定次数后，则容器被认为是不健康的，状态为unhealthy，默认次数是3</li>
</ul>
<p>注意：</p>
<p>HEALTHCHECK命令只能出现一次，如果出现了多次，只有最后一个生效。</p>
<p>CMD后边的命令的返回值决定了本次健康检查是否成功，具体的返回值如下：</p>
<ul>
<li>0: success - 表示容器是健康的</li>
<li>1: unhealthy - 表示容器已经不能工作了</li>
<li>2: reserved - 保留值</li>
</ul>
<p>例子：</p>
<pre><code class="language-shell">HEALTHCHECK --interval=5m --timeout=3s 
CMD curl -f http://localhost/ || exit 1
</code></pre>
<p>健康检查命令是：curl -f http://localhost/ || exit 1</p>
<p>两次检查的间隔时间是5秒</p>
<p>命令超时时间为3秒</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Docker ]]></title>
        <id>https://tinaxiawuhao.github.io/post/VSWRPm3xo/</id>
        <link href="https://tinaxiawuhao.github.io/post/VSWRPm3xo/">
        </link>
        <updated>2022-01-13T02:37:47.000Z</updated>
        <content type="html"><![CDATA[<h1 id="docker">Docker</h1>
<p>学习目标：</p>
<ul>
<li>
<p>掌握Docker基础知识，能够理解Docker镜像与容器的概念</p>
</li>
<li>
<p>完成Docker安装与启动</p>
</li>
<li>
<p>掌握Docker镜像与容器相关命令</p>
</li>
<li>
<p>掌握Tomcat Nginx 等软件的常用应用的安装</p>
</li>
<li>
<p>掌握docker迁移与备份相关命令</p>
</li>
<li>
<p>能够运用Dockerfile编写创建容器的脚本</p>
</li>
<li>
<p>能够搭建与使用docker私有仓库</p>
</li>
</ul>
<h1 id="1-docker简介">1 Docker简介</h1>
<h2 id="11-什么是虚拟化">1.1 什么是虚拟化</h2>
<p>​	在计算机中，虚拟化（英语：Virtualization）是一种资源管理技术，是将计算机的各种实体资源，如服务器、网络、内存及存储等，予以抽象、转换后呈现出来，打破实体结构间的不可切割的障碍，使用户可以比原本的组态更好的方式来应用这些资源。这些资源的新虚拟部份是不受现有资源的架设方式，地域或物理组态所限制。一般所指的虚拟化资源包括计算能力和资料存储。</p>
<p>​	在实际的生产环境中，虚拟化技术主要用来解决高性能的物理硬件产能过剩和老的旧的硬件产能过低的重组重用，透明化底层物理硬件，从而最大化的利用物理硬件   对资源充分利用</p>
<p>​	虚拟化技术种类很多，例如：软件虚拟化、硬件虚拟化、内存虚拟化、网络虚拟化(vip)、桌面虚拟化、服务虚拟化、虚拟机等等。</p>
<h2 id="12-什么是docker">1.2 什么是Docker</h2>
<p>​	Docker 是一个开源项目，诞生于 2013 年初，最初是 dotCloud 公司内部的一个业余项目。它基于 Google 公司推出的 Go 语言实现。 项目后来加入了 Linux 基金会，遵从了 Apache 2.0 协议，项目代码在 <a href="https://github.com/docker/docker">GitHub</a> 上进行维护。</p>
<p>​	<img src="https://tinaxiawuhao.github.io/post-images/1641955175988.png" alt="" loading="lazy"></p>
<p>​	Docker 自开源后受到广泛的关注和讨论，以至于 dotCloud 公司后来都改名为 Docker Inc。Redhat 已经在其 RHEL6.5 中集中支持 Docker；Google 也在其 PaaS 产品中广泛应用。</p>
<p>​	Docker 项目的目标是实现轻量级的操作系统虚拟化解决方案。 Docker 的基础是 Linux 容器（LXC）等技术。</p>
<p>​	在 LXC 的基础上 Docker 进行了进一步的封装，让用户不需要去关心容器的管理，使得操作更为简便。用户操作 Docker 的容器就像操作一个快速轻量级的虚拟机一样简单。</p>
<p>为什么选择Docker?</p>
<p>（1）上手快。</p>
<p>​	用户只需要几分钟，就可以把自己的程序“Docker化”。Docker依赖于“写时复制”（copy-on-write）模型，使修改应用程序也非常迅速，可以说达到“随心所致，代码即改”的境界。</p>
<p>随后，就可以创建容器来运行应用程序了。大多数Docker容器只需要不到1秒中即可启动。由于去除了管理程序的开销，Docker容器拥有很高的性能，同时同一台宿主机中也可以运行更多的容器，使用户尽可能的充分利用系统资源。</p>
<p>（2）职责的逻辑分类</p>
<p>​	使用Docker，开发人员只需要关心容器中运行的应用程序，而运维人员只需要关心如何管理容器。Docker设计的目的就是要加强开发人员写代码的开发环境与应用程序要部署的生产环境一致性。从而降低那种“开发时一切正常，肯定是运维的问题（测试环境都是正常的，上线后出了问题就归结为肯定是运维的问题）”</p>
<p>（3）快速高效的开发生命周期</p>
<p>​	Docker的目标之一就是缩短代码从开发、测试到部署、上线运行的周期，让你的应用程序具备可移植性，易于构建，并易于协作。（通俗一点说，Docker就像一个盒子，里面可以装很多物件，如果需要这些物件的可以直接将该大盒子拿走，而不需要从该盒子中一件件的取。）</p>
<p>（4）鼓励使用面向服务的架构</p>
<p>​	Docker还鼓励面向服务的体系结构和微服务架构。Docker推荐单个容器只运行一个应用程序或进程，这样就形成了一个分布式的应用程序模型，在这种模型下，应用程序或者服务都可以表示为一系列内部互联的容器，从而使分布式部署应用程序，扩展或调试应用程序都变得非常简单，同时也提高了程序的内省性。（当然，可以在一个容器中运行多个应用程序）</p>
<h2 id="13-容器与虚拟机比较">1.3 容器与虚拟机比较</h2>
<p>​	下面的图片比较了 Docker 和传统虚拟化方式的不同之处，可见容器是在操作系统层面上实现虚拟化，直接复用本地主机的操作系统，而传统方式则是在硬件层面实现。</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1641955189369.png" alt="" loading="lazy"></figure>
<p>与传统的虚拟机相比，Docker优势体现为启动速度快、占用体积小。</p>
<h2 id="14-docker-组件">1.4 Docker 组件</h2>
<h3 id="141-docker服务器与客户端">1.4.1 Docker服务器与客户端</h3>
<p>​	Docker是一个客户端-服务器（C/S）架构程序。Docker客户端只需要向Docker服务器或者守护进程发出请求，服务器或者守护进程将完成所有工作并返回结果。Docker提供了一个命令行工具Docker以及一整套RESTful API。你可以在同一台宿主机上运行Docker守护进程和客户端，也可以从本地的Docker客户端连接到运行在另一台宿主机上的远程Docker守护进程。</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1641955202177.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1645597883819.png" alt="" loading="lazy"></figure>
<h3 id="142-docker镜像与容器">1.4.2 Docker镜像与容器</h3>
<p>​	镜像是构建Docker的基石。用户基于镜像来运行自己的容器。镜像也是Docker生命周期中的“构建”部分。镜像是基于联合文件系统的一种层式结构，由一系列指令一步一步构建出来。例如：</p>
<p>添加一个文件；</p>
<p>执行一个命令；</p>
<p>打开一个窗口。</p>
<p>也可以将镜像当作容器的“源代码”。镜像体积很小，非常“便携”，易于分享、存储和更新。</p>
<p>​	Docker可以帮助你构建和部署容器，你只需要把自己的应用程序或者服务打包放进容器即可。容器是基于镜像启动起来的，容器中可以运行一个或多个进程。我们可以认为，镜像是Docker生命周期中的构建或者打包阶段，而容器则是启动或者执行阶段。  容器基于镜像启动，一旦容器启动完成后，我们就可以登录到容器中安装自己需要的软件或者服务。</p>
<p>所以Docker容器就是：</p>
<p>​	一个镜像格式；</p>
<p>​	一些列标准操作；</p>
<p>​	一个执行环境。</p>
<p>​	Docker借鉴了标准集装箱的概念。标准集装箱将货物运往世界各地，Docker将这个模型运用到自己的设计中，唯一不同的是：集装箱运输货物，而Docker运输软件。</p>
<p>和集装箱一样，Docker在执行上述操作时，并不关心容器中到底装了什么，它不管是web服务器，还是数据库，或者是应用程序服务器什么的。所有的容器都按照相同的方式将内容“装载”进去。</p>
<p>Docker也不关心你要把容器运到何方：我们可以在自己的笔记本中构建容器，上传到Registry，然后下载到一个物理的或者虚拟的服务器来测试，在把容器部署到具体的主机中。像标准集装箱一样，Docker容器方便替换，可以叠加，易于分发，并且尽量通用。</p>
<h3 id="143-registry注册中心">1.4.3 Registry（注册中心）</h3>
<p>​	Docker用Registry来保存用户构建的镜像。Registry分为公共和私有两种。Docker公司运营公共的Registry叫做Docker Hub。用户可以在Docker Hub注册账号，分享并保存自己的镜像（说明：在Docker Hub下载镜像巨慢，可以自己构建私有的Registry）。</p>
<p>​	https://hub.docker.com/</p>
<h1 id="2-docker安装与启动">2 Docker安装与启动</h1>
<h2 id="21-安装docker">2.1 安装Docker</h2>
<p>​	Docker官方建议在Ubuntu中安装，因为Docker是基于Ubuntu发布的，而且一般Docker出现的问题Ubuntu是最先更新或者打补丁的。在很多版本的CentOS中是不支持更新最新的一些补丁包的。</p>
<p>​	由于我们学习的环境都使用的是CentOS，因此这里我们将Docker安装到CentOS上。注意：这里建议安装在CentOS7.x以上的版本，在CentOS6.x的版本中，安装前需要安装其他很多的环境而且Docker很多补丁不支持更新。</p>
<p>​	请直接挂载课程配套的Centos7.x镜像</p>
<p>（1）yum 包更新到最新</p>
<pre><code class="language-shell">sudo yum update
</code></pre>
<p>（2）安装需要的软件包， yum-util 提供yum-config-manager功能，另外两个是devicemapper驱动依赖的</p>
<pre><code class="language-shell">sudo yum install -y yum-utils device-mapper-persistent-data lvm2
</code></pre>
<p>（3）设置yum源为阿里云</p>
<pre><code class="language-shell">sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
</code></pre>
<p>（4）安装docker</p>
<pre><code class="language-shell">sudo yum install docker-ce
</code></pre>
<p>（5）安装后查看docker版本</p>
<pre><code class="language-shell">docker -v
</code></pre>
<h2 id="22-设置ustc的镜像">2.2 设置ustc的镜像</h2>
<p>ustc是老牌的linux镜像服务提供者了，还在遥远的ubuntu 5.04版本的时候就在用。ustc的docker镜像加速器速度很快。ustc docker mirror的优势之一就是不需要注册，是真正的公共服务。</p>
<p><a href="https://lug.ustc.edu.cn/wiki/mirrors/help/docker">https://lug.ustc.edu.cn/wiki/mirrors/help/docker</a></p>
<p>编辑该文件：</p>
<pre><code class="language-shell">vi /etc/docker/daemon.json  
</code></pre>
<p>在该文件中输入如下内容：</p>
<pre><code class="language-shell">{
&quot;registry-mirrors&quot;: [&quot;https://docker.mirrors.ustc.edu.cn&quot;]
}
</code></pre>
<h2 id="23-docker的启动与停止">2.3 Docker的启动与停止</h2>
<p><strong>systemctl</strong>命令是系统服务管理器指令</p>
<p>启动docker：</p>
<pre><code class="language-shell">systemctl start docker
</code></pre>
<p>停止docker：</p>
<pre><code class="language-shell">systemctl stop docker
</code></pre>
<p>重启docker：</p>
<pre><code class="language-shell">systemctl restart docker
</code></pre>
<p>查看docker状态：</p>
<pre><code class="language-shell">systemctl status docker
</code></pre>
<p>开机启动：</p>
<pre><code class="language-shell">systemctl enable docker
</code></pre>
<p>查看docker概要信息</p>
<pre><code class="language-shell">docker info
</code></pre>
<p>查看docker帮助文档</p>
<pre><code class="language-shell">docker --help
</code></pre>
<h1 id="3-常用命令">3 常用命令</h1>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1645597935806.png" alt="" loading="lazy"></figure>
<h2 id="31-镜像相关命令">3.1 镜像相关命令</h2>
<h3 id="311-查看镜像">3.1.1 查看镜像</h3>
<pre><code class="language-shell">docker images
</code></pre>
<p>REPOSITORY：镜像名称</p>
<p>TAG：镜像标签</p>
<p>IMAGE ID：镜像ID</p>
<p>CREATED：镜像的创建日期（不是获取该镜像的日期）</p>
<p>SIZE：镜像大小</p>
<p>这些镜像都是存储在Docker宿主机的/var/lib/docker目录下</p>
<h3 id="312-搜索镜像">3.1.2 搜索镜像</h3>
<p>如果你需要从网络中查找需要的镜像，可以通过以下命令搜索</p>
<pre><code class="language-shell">docker search 镜像名称
</code></pre>
<p>NAME：仓库名称</p>
<p>DESCRIPTION：镜像描述</p>
<p>STARS：用户评价，反应一个镜像的受欢迎程度</p>
<p>OFFICIAL：是否官方</p>
<p>AUTOMATED：自动构建，表示该镜像由Docker Hub自动构建流程创建的</p>
<h3 id="313-拉取镜像">3.1.3 拉取镜像</h3>
<p>拉取镜像就是从中央仓库中下载镜像到本地</p>
<pre><code class="language-shell">docker pull 镜像名称
</code></pre>
<p>例如，我要下载centos7镜像</p>
<pre><code class="language-shell">docker pull centos:7
</code></pre>
<p>Docker采用联合文件系统，不同镜像的相同文件无需再次下载：<br>
<img src="https://tinaxiawuhao.github.io/post-images/1645597963050.png" alt="" loading="lazy"></p>
<h3 id="4-删除镜像">4 删除镜像</h3>
<p>按镜像ID删除镜像</p>
<pre><code class="language-shell">docker rmi 镜像ID
</code></pre>
<p>删除所有镜像</p>
<pre><code class="language-shell">docker rmi `docker images -q`
</code></pre>
<h2 id="32-容器相关命令">3.2 容器相关命令</h2>
<h3 id="321-查看容器">3.2.1 查看容器</h3>
<p>查看正在运行的容器</p>
<pre><code class="language-shell">docker ps
</code></pre>
<p>查看所有容器</p>
<pre><code class="language-shell">docker ps –a
</code></pre>
<p>查看最后一次运行的容器</p>
<pre><code class="language-shell">docker ps –l
</code></pre>
<p>查看停止的容器</p>
<pre><code class="language-shell">docker ps -f status=exited
</code></pre>
<h3 id="322-创建与启动容器">3.2.2 创建与启动容器</h3>
<p>创建容器常用的参数说明：</p>
<p>创建容器命令：docker run</p>
<p>-i：表示运行容器</p>
<p>-t：表示容器启动后会进入其命令行。加入这两个参数后，容器创建就能登录进去。即分配一个伪终端。</p>
<p>--name :为创建的容器命名。</p>
<p>-v：表示目录映射关系（前者是宿主机目录，后者是映射到宿主机上的目录），可以使用多个－v做多个目录或文件映射。注意：最好做目录映射，在宿主机上做修改，然后共享到容器上。</p>
<p>-d：在run后面加上-d参数,则会创建一个守护式容器在后台运行（这样创建容器后不会自动登录容器，如果只加-i -t两个参数，创建后就会自动进去容器）。</p>
<p>-p：表示端口映射，前者是宿主机端口，后者是容器内的映射端口。可以使用多个-p做多个端口映射</p>
<p>（1）交互式方式创建容器</p>
<pre><code class="language-shell">docker run -it --name=容器名称 镜像名称:标签 /bin/bash
</code></pre>
<p>这时我们通过ps命令查看，发现可以看到启动的容器，状态为启动状态</p>
<p>退出当前容器</p>
<pre><code class="language-shell">exit
</code></pre>
<p>（2）守护式方式创建容器：</p>
<pre><code class="language-shell">docker run -di --name=容器名称 镜像名称:标签
</code></pre>
<p>登录守护式容器方式：</p>
<pre><code class="language-shell">docker exec -it 容器名称 (或者容器ID)  /bin/bash
</code></pre>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1645598588933.jpg" alt="" loading="lazy"></figure>
<pre><code class="language-bash">Exit                         # 从容器中退回主机 
CTRL+Q+P                     # 容器不停止退出
</code></pre>
<h3 id="323-停止与启动容器">3.2.3 停止与启动容器</h3>
<p>停止容器：</p>
<pre><code class="language-shell">docker stop 容器名称（或者容器ID）
</code></pre>
<p>启动容器：</p>
<pre><code class="language-shell">docker start 容器名称（或者容器ID）
</code></pre>
<h3 id="324-文件拷贝">3.2.4 文件拷贝</h3>
<p>如果我们需要将文件拷贝到容器内可以使用cp命令</p>
<pre><code class="language-shell">docker cp 需要拷贝的文件或目录 容器名称:容器目录
</code></pre>
<p>也可以将文件从容器内拷贝出来</p>
<pre><code class="language-shell">docker cp 容器名称:容器目录 需要拷贝的文件或目录
</code></pre>
<h3 id="325-目录挂载">3.2.5 目录挂载</h3>
<p>我们可以在创建容器的时候，将宿主机的目录与容器内的目录进行映射，这样我们就可以通过修改宿主机某个目录的文件从而去影响容器。<br>
创建容器 添加-v参数 后边为   宿主机目录:容器目录，例如：</p>
<pre><code class="language-shell">docker run -di -v /usr/local/myhtml:/usr/local/myhtml --name=mycentos3 centos:7
</code></pre>
<p>如果你共享的是多级的目录，可能会出现权限不足的提示。</p>
<p>这是因为CentOS7中的安全模块selinux把权限禁掉了，我们需要添加参数  --privileged=true  来解决挂载的目录没有权限的问题</p>
<h4 id="匿名挂载">匿名挂载</h4>
<pre><code class="language-bash">docker run -d  -v 容器内目录  镜像名/id  # 匿名挂载
</code></pre>
<p>匿名挂载后，使用<strong>docker volume ls</strong>命令查看所有挂载的卷：</p>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1645598000069.png" alt="" loading="lazy"></figure>
<p>每一个VOLUME NAME对应一个挂载的卷，由于挂载时未指定主机目录，因此无法直接找到目录。</p>
<h4 id="具名挂载">具名挂载</h4>
<pre><code class="language-bash">docker run -d  -v 卷名：容器内目录  镜像名/id  # 具名挂载
</code></pre>
<p><img src="https://tinaxiawuhao.github.io/post-images/1645598609101.png" alt="" loading="lazy"><br>
可以发现挂载的卷：volume01，并通过<strong>docker volume inspect 卷名</strong> 命令找到主机内目录：<br>
<img src="https://tinaxiawuhao.github.io/post-images/1645598023382.png" alt="" loading="lazy"></p>
<p>所有docker容器内的卷，在未指定主机内目录时，都在：<em>/var/lib/docker/volumes/卷名/_data</em> 下，可通过具名挂载可以方便的找到卷，因此广泛使用这种方式进行挂载。</p>
<h4 id="数据卷容器">数据卷容器</h4>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1645598045974.png" alt="" loading="lazy"></figure>
<pre><code class="language-bash">docker run -it --name container02 --volumes from container01 镜像名/id  # 将两个容器进行挂载
</code></pre>
<h3 id="326-查看容器ip地址">3.2.6 查看容器IP地址</h3>
<p>我们可以通过以下命令查看容器运行的各种数据</p>
<pre><code class="language-shell">docker inspect 容器名称（容器ID） 
</code></pre>
<p>也可以直接执行下面的命令直接输出IP地址</p>
<pre><code class="language-shell">docker inspect --format='{{.NetworkSettings.IPAddress}}' 容器名称（容器ID）
</code></pre>
<h3 id="327-删除容器">3.2.7 删除容器</h3>
<p>删除指定的容器：</p>
<pre><code class="language-shell">docker rm 容器名称（容器ID）
</code></pre>
<h3 id="328-其他命令">3.2.8 其他命令</h3>
<pre><code class="language-bash">docker start/restart/stop/kill 容器名/id               
docker logs -tf --tail 显示的日志条数 容器名/id  # 查看日志
docker top 容器名/id                 # 查看容器中的进程信息
docker inspect 容器名/id             # 查看镜像的元数据
docker exec -it 容器名/id /bin/bash  # 通常容器以后台方式运行，需要进入其中修改配置：进入容器后开启一个新终端         
docker attach 容器名/id              # 进入容器正在执行的终端
docker cp 容器名/id:容器内路径 主机文件路径       # 从容器内拷贝文件到主机上
</code></pre>
<h1 id="4-docker镜像详解">4  Docker镜像详解</h1>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1645598065040.png" alt="" loading="lazy"></figure>
<h2 id="unionfs联合文件系统">UnionFS（联合文件系统）</h2>
<ul>
<li>联合文件系统（UnionFS）是一种分层、轻量级并且高性能的文件系统，它支持对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下。联合文件系统是 Docker 镜像的基础。镜像可以通过分层来进行继承，基于基础镜像（没有父镜像），可以制作各种具体的应用镜像。</li>
<li>特性：一次同时加载多个文件系统，但从外面看起来只能看到一个文件系统。联合加载会把各层文件系统叠加起来，这样最终的文件系统会包含所有底层的文件和目录。</li>
</ul>
<h2 id="镜像加载原理">镜像加载原理</h2>
<p>Docker的镜像实际由一层一层的文件系统组成：</p>
<ul>
<li>bootfs（boot file system）主要包含bootloader和kernel。bootloader主要是引导加载kernel，完成后整个内核就都在内存中了。此时内存的使用权已由bootfs转交给内核，系统卸载bootfs。可以被不同的Linux发行版公用。</li>
<li>rootfs（root file system），包含典型Linux系统中的/dev，/proc，/bin，/etc等标准目录和文件。rootfs就是各种不同操作系统发行版（Ubuntu，Centos等）。因为底层直接用Host的kernel，rootfs只包含最基本的命令，工具和程序就可以了。</li>
<li>分层理解<br>
所有的Docker镜像都起始于一个基础镜像层，当进行修改或增加新的内容时，就会在当前镜像层之上，创建新的容器层。<br>
容器在启动时会在镜像最外层上建立一层可读写的容器层（R/W），而镜像层是只读的（R/O）。<br>
<img src="https://tinaxiawuhao.github.io/post-images/1645598082318.png" alt="" loading="lazy"></li>
</ul>
<pre><code class="language-bash">docker commit -m=&quot;描述信息&quot; -a=&quot;作者&quot; 容器id 目标镜像名:[tag]  # 编辑容器后提交容器成为一个新镜像
</code></pre>
<h1 id="4-应用部署">4 应用部署</h1>
<h2 id="41-mysql部署">4.1 MySQL部署</h2>
<p>（1）拉取mysql镜像</p>
<pre><code class="language-shell">docker pull centos/mysql-57-centos7
</code></pre>
<p>（2）创建容器</p>
<pre><code class="language-shell">docker run -di --name=tensquare_mysql -p 33306:3306 -e MYSQL_ROOT_PASSWORD=123456 mysql
</code></pre>
<p>-p 代表端口映射，格式为  宿主机映射端口:容器运行端口</p>
<p>-e 代表添加环境变量  MYSQL_ROOT_PASSWORD  是root用户的登陆密码</p>
<p>（3）远程登录mysql</p>
<p>连接宿主机的IP  ,指定端口为33306</p>
<h2 id="42-tomcat部署">4.2 tomcat部署</h2>
<p>（1）拉取镜像</p>
<pre><code class="language-shell">docker pull tomcat:7-jre7
</code></pre>
<p>（2）创建容器</p>
<p>创建容器  -p表示地址映射</p>
<pre><code class="language-shell">docker run -di --name=mytomcat -p 9000:8080 
-v /usr/local/webapps:/usr/local/tomcat/webapps tomcat:7-jre7
</code></pre>
<h2 id="43-nginx部署">4.3 Nginx部署</h2>
<p>（1）拉取镜像</p>
<pre><code class="language-shell">docker pull nginx
</code></pre>
<p>（2）创建Nginx容器</p>
<pre><code class="language-shell">docker run -di --name=mynginx -p 80:80 nginx
</code></pre>
<h2 id="44-redis部署">4.4 Redis部署</h2>
<p>（1）拉取镜像</p>
<pre><code class="language-shell">docker pull redis
</code></pre>
<p>（2）创建容器</p>
<pre><code class="language-shell">docker run -di --name=myredis -p 6379:6379 redis
</code></pre>
<h2 id="45-redis集群部署">4.5 Redis集群部署</h2>
<pre><code class="language-shell"># 创建网卡
docker network create redis --subnet 172.38.0.0/16
# 通过脚本创建六个redis配置
for port in $(seq 1 6);\
do \
mkdir -p /mydata/redis/node-${port}/conf
touch /mydata/redis/node-${port}/conf/redis.conf
cat &lt;&lt; EOF &gt;&gt; /mydata/redis/node-${port}/conf/redis.conf
port 6379
bind 0.0.0.0
cluster-enabled yes
cluster-config-file nodes.conf
cluster-node-timeout 5000
cluster-announce-ip 172.38.0.1${port}
cluster-announce-port 6379
cluster-announce-bus-port 16379
appendonly yes
EOF
done

# 通过脚本运行六个redis
for port in $(seq 1 6);\
docker run -p 637${port}:6379 -p 1667${port}:16379 --name redis-${port} \
-v /mydata/redis/node-${port}/data:/data \
-v /mydata/redis/node-${port}/conf/redis.conf:/etc/redis/redis.conf \
-d --net redis --ip 172.38.0.1${port} redis:5.0.9-alpine3.11 redis-server /etc/redis/redis.conf
docker exec -it redis-1 /bin/sh #redis默认没有bash
redis-cli --cluster create 172.38.0.11:6379 172.38.0.12:6379 172.38.0.13:6379 172.38.0.14:6379 172.38.0.15:6379 172.38.0.16:6379  --cluster-replicas 1
</code></pre>
<h1 id="5-迁移与备份">5 迁移与备份</h1>
<h2 id="51-容器保存为镜像">5.1 容器保存为镜像</h2>
<p>我们可以通过以下命令将容器保存为镜像</p>
<pre><code class="language-shell">docker commit mynginx mynginx_i
</code></pre>
<h2 id="52-镜像备份">5.2 镜像备份</h2>
<p>我们可以通过以下命令将镜像保存为tar 文件</p>
<pre><code class="language-shell">docker  save -o mynginx.tar mynginx_i
</code></pre>
<h2 id="53-镜像恢复与迁移">5.3 镜像恢复与迁移</h2>
<p>首先我们先删除掉mynginx_img镜像  然后执行此命令进行恢复</p>
<pre><code class="language-shell">docker load -i mynginx.tar
</code></pre>
<p>-i 输入的文件</p>
<p>执行后再次查看镜像，可以看到镜像已经恢复</p>
<h1 id="6-dockerfile">6 Dockerfile</h1>
<h2 id="61-什么是dockerfile">6.1 什么是Dockerfile</h2>
<p>Dockerfile是由一系列命令和参数构成的脚本，这些命令应用于基础镜像并最终创建一个新的镜像。</p>
<p>1、对于开发人员：可以为开发团队提供一个完全一致的开发环境；<br>
2、对于测试人员：可以直接拿开发时所构建的镜像或者通过Dockerfile文件构建一个新的镜像开始工作了；<br>
3、对于运维人员：在部署时，可以实现应用的无缝移植。</p>
<h2 id="62-常用命令">6.2 常用命令</h2>
<table>
<thead>
<tr>
<th>命令</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr>
<td>FROM image_name:tag</td>
<td>定义了使用哪个基础镜像启动构建流程</td>
</tr>
<tr>
<td>MAINTAINER user_name</td>
<td>声明镜像的创建者</td>
</tr>
<tr>
<td>ENV key value</td>
<td>设置环境变量 (可以写多条)</td>
</tr>
<tr>
<td>RUN command</td>
<td>是Dockerfile的核心部分(可以写多条)</td>
</tr>
<tr>
<td>ADD source_dir/file dest_dir/file</td>
<td>将宿主机的文件复制到容器内，如果是一个压缩文件，将会在复制后自动解压</td>
</tr>
<tr>
<td>COPY source_dir/file dest_dir/file</td>
<td>和ADD相似，但是如果有压缩文件并不能解压</td>
</tr>
<tr>
<td>WORKDIR path_dir</td>
<td>设置工作目录</td>
</tr>
</tbody>
</table>
<h2 id="63-使用脚本创建镜像">6.3 使用脚本创建镜像</h2>
<p>步骤：</p>
<p>（1）创建目录</p>
<pre><code class="language-shell">mkdir –p /usr/local/dockerjdk8
</code></pre>
<p>（2）下载jdk-8u171-linux-x64.tar.gz并上传到服务器（虚拟机）中的/usr/local/dockerjdk8目录</p>
<p>（3）创建文件Dockerfile  <code>vi Dockerfile</code></p>
<pre><code class="language-shell">#依赖镜像名称和ID
FROM centos:7
#指定镜像创建者信息
MAINTAINER ITCAST
#切换工作目录
WORKDIR /usr
RUN mkdir  /usr/local/java
#ADD 是相对路径jar,把java添加到容器中
ADD jdk-8u171-linux-x64.tar.gz /usr/local/java/

#配置java环境变量
ENV JAVA_HOME /usr/local/java/jdk1.8.0_171
ENV JRE_HOME $JAVA_HOME/jre
ENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib:$CLASSPATH
ENV PATH $JAVA_HOME/bin:$PATH
</code></pre>
<p>（4）执行命令构建镜像</p>
<pre><code class="language-shell">docker build -t='jdk1.8' .
</code></pre>
<p>注意后边的空格和点，不要省略</p>
<p>（5）查看镜像是否建立完成</p>
<pre><code class="language-shell">docker images
</code></pre>
<h1 id="7-docker私有仓库">7 Docker私有仓库</h1>
<h2 id="71-私有仓库搭建与配置">7.1 私有仓库搭建与配置</h2>
<p>（1）拉取私有仓库镜像（此步省略）</p>
<pre><code class="language-shell">docker pull registry
</code></pre>
<p>（2）启动私有仓库容器</p>
<pre><code class="language-shell">docker run -di --name=registry -p 5000:5000 registry
</code></pre>
<p>（3）打开浏览器 输入地址http://192.168.184.141:5000/v2/_catalog看到<code>{&quot;repositories&quot;:[]}</code> 表示私有仓库搭建成功并且内容为空</p>
<p>（4）修改daemon.json</p>
<pre><code class="language-shell">vi /etc/docker/daemon.json
</code></pre>
<p>添加以下内容，保存退出。</p>
<pre><code class="language-json">{&quot;insecure-registries&quot;:[&quot;192.168.184.141:5000&quot;]} 
</code></pre>
<p>此步用于让 docker信任私有仓库地址</p>
<p>（5）重启docker 服务</p>
<pre><code class="language-shell">systemctl restart docker
</code></pre>
<h2 id="72-镜像上传至私有仓库">7.2 镜像上传至私有仓库</h2>
<p>（1）标记此镜像为私有仓库的镜像</p>
<pre><code class="language-shell">docker tag jdk1.8 192.168.184.141:5000/jdk1.8
</code></pre>
<p>（2）再次启动私服容器</p>
<pre><code class="language-shell">docker start registry
</code></pre>
<p>（3）上传标记的镜像</p>
<pre><code class="language-shell">docker push 192.168.184.141:5000/jdk1.8
</code></pre>
<h1 id="8-docker网络">8 Docker网络</h1>
<h2 id="81-理解doker0">8.1 理解Doker0</h2>
<p>通过命令<strong>ip addr</strong>查看本地ip地址，我们发现除了本机回环地址和埃里远的内网地址外，还多了一个网卡：Docker0，这是Docker服务启动后自动生成的。<br>
<img src="https://tinaxiawuhao.github.io/post-images/1645598117584.png" alt="" loading="lazy"><br>
而如果进入一个正在后台运行的tomcat容器，同样使用<strong>ip addr</strong>命令，发现容器得到了一个新的网络：<strong>12: eth@if13</strong>，ip地址：<strong>172.17.0.2</strong>。这是Docker在容器启动时为其分配的。<br>
<img src="https://tinaxiawuhao.github.io/post-images/1645598157386.png" alt="" loading="lazy"><br>
思考一个问题：此时我们的linux主机可以ping通容器内部（<strong>172.17.0.2</strong>）吗？（<strong>注意与容器暴露端口相区分</strong>)<br>
<img src="https://tinaxiawuhao.github.io/post-images/1645598173437.png" alt="" loading="lazy"></p>
<ul>
<li>linux可以ping通docker容器内部，因为docker0的ip地址为<strong>172.17.0.1</strong>，容器为<strong>172.17.0.2</strong>。</li>
<li>原理：我们每启动一个docker容器，docker就会给容器分配一个默认的可用ip，我们只要安装了docker，就会有一个网卡docker0(bridge)。网卡采用桥接模式，并使用veth-pair技术（veth-pair就是一堆虚拟设备接口，成对出现，一段连着协议，一段彼此相连，充当一个桥梁。）。</li>
<li>这时我们退出容器，回到主机再次观察主机的ip地址：<br>
<img src="https://tinaxiawuhao.github.io/post-images/1645598197831.png" alt="" loading="lazy"><br>
我们惊奇地发现了一个新网络<strong>13: vethda1df4b@if12</strong>，对应容器内网络地址的<strong>12: eth@if13</strong>。</li>
<li>容器和容器之间是可以互相ping通的：容器1→Docker0→容器2<br>
<img src="https://tinaxiawuhao.github.io/post-images/1645598226949.png" alt="" loading="lazy"><br>
docker中的所有网络接口都是虚拟的 ，转发效率高。删除容器后，对应的网桥也随之删除。</li>
</ul>
<h2 id="82-link">8.2 --link</h2>
<p>若编写一个微服务并连接数据库，如果数据库ip改变，如何根据容器名而不是ip访问容器？显然，直接使用容器名是无法ping通容器内部的：<br>
<img src="https://tinaxiawuhao.github.io/post-images/1645598261672.png" alt="" loading="lazy"><br>
这时我们可以在容器启动命令中加入一个选项：<strong>--link</strong>，使得我们可以根据容器名来访问容器。</p>
<pre><code class="language-bash">docker run -d -P --link 容器名/id 镜像名/id
</code></pre>
<p><img src="https://tinaxiawuhao.github.io/post-images/1645598278472.png" alt="" loading="lazy"><br>
然而反向就不可以ping通，这是因为--link的本质是把需要连接的容器名/id写入启动容器的配置文件中，即增加了一个ip和容器名/id的映射：<br>
<img src="https://tinaxiawuhao.github.io/post-images/1645598294726.png" alt="" loading="lazy"><br>
目前已经不建议使用这种方式。</p>
<h2 id="83-自定义网络">8.3 自定义网络</h2>
<p>我们使用命令：</p>
<pre><code class="language-bash">docker network ls    # 查看所有的docker网络
</code></pre>
<p><img src="https://tinaxiawuhao.github.io/post-images/1645598309260.png" alt="" loading="lazy"><br>
docker中的网络模式有：</p>
<ul>
<li>bridge：桥接（docker默认）/</li>
<li>none：不配置网络 /</li>
<li>host：和宿主机共享网络</li>
</ul>
<p><strong>docker run</strong> 命令默认带有一个参数--net bridge，此处的bridge指的就是docker0。如果我们不想使用docker0，那如何创建一个新的网络呢？</p>
<pre><code class="language-bash">docker  network create --driver 网络模式 --subnet 子网ip --gateway 网关 网络名         
</code></pre>
<p><img src="https://tinaxiawuhao.github.io/post-images/1645598354804.png" alt="" loading="lazy"><br>
我们不仅在<strong>docker network ls</strong>命令下发现了这个新创建的网络newnet，还可以使用<strong>docker network inspect</strong>命令查看其详细信息，包括了我们创建时定义的子网ip和网关：<br>
<img src="https://tinaxiawuhao.github.io/post-images/1645598372176.png" alt="" loading="lazy"><br>
只要两个容器启动时都通过 <strong>--net</strong>，选用了同一个已创建的网络，不同容器间即可通过ip地址或容器名/id连通:<br>
<img src="https://tinaxiawuhao.github.io/post-images/1645598422921.png" alt="" loading="lazy"></p>
<h2 id="84-网络连通">8.4 网络连通</h2>
<p><img src="https://tinaxiawuhao.github.io/post-images/1645598436013.png" alt="" loading="lazy"><br>
对于建立在不同网络下(docker0, newnet)的两个容器tomcat01和tomcat02，他们的网段不同，因此是无法彼此ping通容器内部的：<br>
<img src="https://tinaxiawuhao.github.io/post-images/1645598445887.png" alt="" loading="lazy"><br>
这时我们需要通过<strong>docker network connect</strong>命令打通容器与网络之间的连接：</p>
<pre><code class="language-bash">docker network connect 网络名 容器名/id
</code></pre>
<p><img src="https://tinaxiawuhao.github.io/post-images/1645598457014.png" alt="" loading="lazy"><br>
这个功能类似于将一个容器赋予多个ip地址，同样可以用<strong>docker network inspect</strong>命令查看网络连通后，该网络的变化：<br>
<img src="https://tinaxiawuhao.github.io/post-images/1645598464633.png" alt="" loading="lazy"><br>
原本newnet网络中只含有tomcat02，现在增加了tomcat01，因此可以连通。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Git 操作命令清单]]></title>
        <id>https://tinaxiawuhao.github.io/post/awhwcpAEp/</id>
        <link href="https://tinaxiawuhao.github.io/post/awhwcpAEp/">
        </link>
        <updated>2022-01-12T02:26:35.000Z</updated>
        <content type="html"><![CDATA[<p>git工作流程图</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1641954851042.jpg" alt="" loading="lazy"></figure>
<p>下面是常用 的Git 命令清单。几个专用名词的译名如下：</p>
<ul>
<li>Workspace：工作区</li>
<li>Index / Stage：暂存区</li>
<li>Repository：仓库区（或本地仓库）</li>
<li>Remote：远程仓库</li>
</ul>
<h3 id="一-新建代码库">一、新建代码库</h3>
<pre><code class="language-shell"># 在当前目录新建一个Git代码库
$ git init

# 新建一个目录，将其初始化为Git代码库
$ git init [project-name]

# 下载一个项目和它的整个代码历史
$ git clone [url]
</code></pre>
<h3 id="二-配置">二、配置</h3>
<p>Git的设置文件为<code>.gitconfig</code>，它可以在用户主目录下（全局配置），也可以在项目目录下（项目配置）。</p>
<pre><code class="language-shell"># 显示当前的Git配置
$ git config --list

# 编辑Git配置文件
$ git config -e [--global]

# 设置提交代码时的用户信息
$ git config [--global] user.name &quot;[name]&quot;
$ git config [--global] user.email &quot;[email address]&quot;
</code></pre>
<h3 id="三-增加删除文件">三、增加/删除文件</h3>
<pre><code class="language-shell"># 添加指定文件到暂存区
$ git add [file1] [file2] ...

# 添加指定目录到暂存区，包括子目录
$ git add [dir]

# 添加当前目录的所有文件到暂存区
$ git add .

# 添加每个变化前，都会要求确认
# 对于同一个文件的多处变化，可以实现分次提交
$ git add -p

# 删除工作区文件，并且将这次删除放入暂存区
$ git rm [file1] [file2] ...

# 停止追踪指定文件，但该文件会保留在工作区
$ git rm --cached [file]

# 改名文件，并且将这个改名放入暂存区
$ git mv [file-original] [file-renamed]
</code></pre>
<h3 id="四-代码提交">四、代码提交</h3>
<pre><code class="language-shell"># 提交暂存区到仓库区
$ git commit -m [message]

# 提交暂存区的指定文件到仓库区
$ git commit [file1] [file2] ... -m [message]

# 提交工作区自上次commit之后的变化，直接到仓库区
$ git commit -a

# 提交时显示所有diff信息
$ git commit -v

# 使用一次新的commit，替代上一次提交
# 如果代码没有任何新变化，则用来改写上一次commit的提交信息
$ git commit --amend -m [message]

# 重做上一次commit，并包括指定文件的新变化
$ git commit --amend [file1] [file2] ...
</code></pre>
<h3 id="五-分支">五、分支</h3>
<pre><code class="language-shell"># 列出所有本地分支
$ git branch

# 列出所有远程分支
$ git branch -r

# 列出所有本地分支和远程分支
$ git branch -a

# 新建一个分支，但依然停留在当前分支
$ git branch [branch-name]

# 新建一个分支，并切换到该分支
$ git checkout -b [branch]

# 新建一个分支，指向指定commit
$ git branch [branch] [commit]

# 新建一个分支，与指定的远程分支建立追踪关系
$ git branch --track [branch] [remote-branch]

# 切换到指定分支，并更新工作区
$ git checkout [branch-name]

# 切换到上一个分支
$ git checkout -

# 建立追踪关系，在现有分支与指定的远程分支之间
$ git branch --set-upstream [branch] [remote-branch]

# 合并指定分支到当前分支
$ git merge [branch]

# 选择一个commit，合并进当前分支
$ git cherry-pick [commit]

# 删除分支
$ git branch -d [branch-name]

# 删除远程分支
$ git push origin --delete [branch-name]
$ git branch -dr [remote/branch]
</code></pre>
<h3 id="六-标签">六、标签</h3>
<pre><code class="language-shell"># 列出所有tag
$ git tag

# 新建一个tag在当前commit
$ git tag [tag]

# 新建一个tag在指定commit
$ git tag [tag] [commit]

# 删除本地tag
$ git tag -d [tag]

# 删除远程tag
$ git push origin :refs/tags/[tagName]

# 查看tag信息
$ git show [tag]

# 提交指定tag
$ git push [remote] [tag]

# 提交所有tag
$ git push [remote] --tags

# 新建一个分支，指向某个tag
$ git checkout -b [branch] [tag]
</code></pre>
<h3 id="七-查看信息">七、查看信息</h3>
<pre><code class="language-shell"># 显示有变更的文件
$ git status

# 显示当前分支的版本历史
$ git log

# 显示commit历史，以及每次commit发生变更的文件
$ git log --stat

# 搜索提交历史，根据关键词
$ git log -S [keyword]

# 显示某个commit之后的所有变动，每个commit占据一行
$ git log [tag] HEAD --pretty=format:%s

# 显示某个commit之后的所有变动，其&quot;提交说明&quot;必须符合搜索条件
$ git log [tag] HEAD --grep feature

# 显示某个文件的版本历史，包括文件改名
$ git log --follow [file]
$ git whatchanged [file]

# 显示指定文件相关的每一次diff
$ git log -p [file]

# 显示过去5次提交
$ git log -5 --pretty --oneline

# 显示所有提交过的用户，按提交次数排序
$ git shortlog -sn

# 显示指定文件是什么人在什么时间修改过
$ git blame [file]

# 显示暂存区和工作区的差异
$ git diff

# 显示暂存区和上一个commit的差异
$ git diff --cached [file]

# 显示工作区与当前分支最新commit之间的差异
$ git diff HEAD

# 显示两次提交之间的差异
$ git diff [first-branch]...[second-branch]

# 显示今天你写了多少行代码
$ git diff --shortstat &quot;@{0 day ago}&quot;

# 显示某次提交的元数据和内容变化
$ git show [commit]

# 显示某次提交发生变化的文件
$ git show --name-only [commit]

# 显示某次提交时，某个文件的内容
$ git show [commit]:[filename]

# 显示当前分支的最近几次提交
$ git reflog
</code></pre>
<h3 id="八-远程同步">八、远程同步</h3>
<pre><code class="language-shell"># 下载远程仓库的所有变动
$ git fetch [remote]

# 显示所有远程仓库
$ git remote -v

# 显示某个远程仓库的信息
$ git remote show [remote]

# 增加一个新的远程仓库，并命名
$ git remote add [shortname] [url]

# 取回远程仓库的变化，并与本地分支合并
$ git pull [remote] [branch]

# 上传本地指定分支到远程仓库
$ git push [remote] [branch]

# 强行推送当前分支到远程仓库，即使有冲突
$ git push [remote] --force

# 推送所有分支到远程仓库
$ git push [remote] --all
</code></pre>
<h3 id="九-撤销">九、撤销</h3>
<pre><code class="language-shell"># 恢复暂存区的指定文件到工作区
$ git checkout [file]

# 恢复某个commit的指定文件到暂存区和工作区
$ git checkout [commit] [file]

# 恢复暂存区的所有文件到工作区
$ git checkout .

# 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变
$ git reset [file]

# 重置暂存区与工作区，与上一次commit保持一致
$ git reset --hard

# 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变
$ git reset [commit]

# 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致
$ git reset --hard [commit]

# 重置当前HEAD为指定commit，但保持暂存区和工作区不变
$ git reset --keep [commit]

# 新建一个commit，用来撤销指定commit
# 后者的所有变化都将被前者抵消，并且应用到当前分支
$ git revert [commit]

# 暂时将未提交的变化移除，稍后再移入
$ git stash
$ git stash pop
</code></pre>
<h3 id="十-其他">十、其他</h3>
<pre><code class="language-shell"># 生成一个可供发布的压缩包
$ git archive
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[jar包内类动态加载]]></title>
        <id>https://tinaxiawuhao.github.io/post/E2kaihQ5a/</id>
        <link href="https://tinaxiawuhao.github.io/post/E2kaihQ5a/">
        </link>
        <updated>2022-01-04T03:13:15.000Z</updated>
        <content type="html"><![CDATA[<h3 id="实体对象">实体对象</h3>
<pre><code class="language-java">public class CmptDef {
    private String idCmptDef; //组件在DB里的唯一ID号
    private String name;//组件的唯一名称，只能是字母、数字、下划线组成，大于1小雨50，通常为Jar的名字
    private CmptCategory cmptCategory; //种类
    private String fullQualifiedName; //组件入口类全限定名
    private String extraParas; //组件额外参数
    private String formUrl; //组件自定义表单
    private Float version = 1.0f; //组件版本
    private CmptExecutePos executePos = CmptExecutePos.PRE; //组件在网关中执行的位置
    private Integer priority = 100; //组件在相同位置的执行优先级，数字越小越高
    private Integer timeout = 1000;//组件执行超时时间，单位毫秒
    private String description; //组件描述
    private Boolean defaultVersion; //是否是默认有效版本
    private CmptStatus cmptStatus = CmptStatus.editing; // 组件状态
    private String remarks; // 组件发布时需要填写备注信息
    private String code; // 组件code，同一个组件的多个版本的code是一样的
    private Date releaseTime; // 组件发布时间
    private CustomFormCode customFormCode; // 自定义表单里类型
    private String cmptType; //组件类型（特殊组件|普通组件|默认组件）
}
/**
 * 组件类型。
 */
public enum CmptCategory {
    AUTHENTICATION, //认证
    AUTHORIZATION, //鉴权
    FLOW_MANAGEMENT, //流量管理
    REQUEST_COUNT_MANAGEMENT, //请求次数管理
    CACHE, //缓存
    ROUTER, //路由
    TRANSFORM, //数据转换
    LOGGER, //日志
    OTHER//其它
}
/**
 * 组件执行的位置。
 */
public enum CmptExecutePos {
    PRE, //调用上游服务前
    ROUTING, //调用中
    AFTER //调用后
}
public enum CmptStatus {
    editing, //编辑中
    published, //已经发布
    offline //已经下线
}
/**
 * 组件风格。
 */
public enum CustomFormCode {
    RESTFUL_FORM,
    SQL_FORM,
    DUBBO_FORM,
    OTHER,
    MQ_FORM,
    WEBSERVICE_FORM
}
</code></pre>
<h3 id="方法接口">方法接口</h3>
<pre><code class="language-java">public interface ICmptService {
    /**
     * 根据组件类名和版本从缓存中获取组件,如果不存在则尝试动态加载组件类，实例化并刷新缓存后再获取，还是不存在则返回null；
     * 另外配置更新会有单独的线程刷新缓存。
     *
     * @return
     */
    ICmpt getCmptInstance(final CmptDef cmptDef);

    /**
     * 刷新API关联的组件配置信息
     *
     * @param apis
     * @param ignoreRefreshTime
     * @return
     */
    boolean refreshCmptInstanceCache(List&lt;Api&gt; apis, boolean ignoreRefreshTime);

    /**
     * 删除组件实例缓存
     *
     * @param fullQualifiedName
     * @param code
     */
    void removeCmpt(final String fullQualifiedName, final Float version, final String code);
}
</code></pre>
<h3 id="方法实现">方法实现</h3>
<pre><code class="language-java">@Service
public class CmptServiceImpl implements ICmptService {
    private static Logger logger = LoggerFactory.getLogger(CmptServiceImpl.class);

    @Value(&quot;${cmpt.dynamicLoadCmptClass}&quot;)
    private boolean dynamicLoadCmptClass;

    @Autowired
    private ICmptDefService cmptDefService;

    @Override
    public synchronized ICmpt getCmptInstance(final CmptDef cmptDef) {
        ICmpt cmpt = CmptInstanceHolder.getInstance().getCmpt(cmptDef.getFullQualifiedName(), cmptDef.getVersion(), cmptDef.getCode());
        if (null == cmpt) {
            if (logger.isDebugEnabled()) {
                logger.debug(&quot;反射拿到实例&gt;&gt;&gt; &quot; + cmptDef.getFullQualifiedName());
            }
            if (this.dynamicLoadCmptClass) {
                cmpt = CmptClassLoaderUtil.newInstance(cmptDef);
            } else {
                try {
                    Class clazz = Class.forName(cmptDef.getFullQualifiedName());
                    cmpt = (ICmpt) clazz.newInstance();
                } catch (Exception e) {
                    e.printStackTrace();
                }
            }
            if (null != cmpt) {
                if (cmpt instanceof AbstractCmpt) {
                    //设置版本号
                    ((AbstractCmpt) cmpt).setVersion(cmptDef.getVersion());
                    ((AbstractCmpt) cmpt).setIdCmptDef(cmptDef.getIdCmptDef());
                }
                CmptInstanceHolder.getInstance().addEntry(cmpt, cmptDef.getFullQualifiedName(), cmptDef.getVersion(), cmptDef.getCode());
            }
        } else {
            if (logger.isDebugEnabled()) {
                logger.debug(&quot;缓存拿到实例&gt;&gt;&gt; &quot; + cmptDef.getFullQualifiedName());
            }
        }
        if (null != cmpt) {
            ApplicationContext context = SpringContextHolder.getContext();
            if (null != context) {
                ZkClient zkClient = context.getBean(ZkClient.class);
                if (null != zkClient) {
                    BaseListener listener = zkClient.getListener();
                    listener.addObserver((AbstractCmpt) cmpt);
                }
            }
        }
        return cmpt;
    }

    @Override
    public boolean refreshCmptInstanceCache(List&lt;Api&gt; apis, boolean ignoreRefreshTime) {
        return false;
    }

    @Override
    public synchronized void removeCmpt(final String fullQualifiedName, final Float version, final String code) {
        ICmpt cmpt = CmptInstanceHolder.getInstance().getCmpt(fullQualifiedName, version, code);
        if (null != cmpt) {
            ApplicationContext context = SpringContextHolder.getContext();
            if (null != context) {
                ZkClient zkClient = context.getBean(ZkClient.class);
                if (null != zkClient) {
                    BaseListener listener = zkClient.getListener();
                    listener.deleteObserver((AbstractCmpt) cmpt);
                }
            }
            cmpt.destroy();
            CmptDef cmptDef = CmptDefHolder.getInstance().getCmptDef(fullQualifiedName, version, code);
            if (null == cmptDef) {
                cmptDef = new CmptDef();
                cmptDef.setFullQualifiedName(fullQualifiedName);
                cmptDef.setVersion(version);
                cmptDef.setCode(code);
            }
            //删除引用实体
            CmptInstanceHolder.getInstance().removeEntry(fullQualifiedName, version, code);
            cmpt = null;

            String jarPath = CmptClassLoaderUtil.getJarPath(cmptDef);
            if (logger.isDebugEnabled()) {
                logger.debug(&quot;尝试卸载jar包: &quot; + jarPath);
            }
            CmptClassLoaderManager.unLoadJar(jarPath);
        }
        CmptInstanceHolder.getInstance().removeEntry(fullQualifiedName, version, code);
    }
}
</code></pre>
<h3 id="工具类">工具类</h3>
<pre><code class="language-java">/**
 * 组件配置缓存持有者
 */
public class CmptInstanceHolder {
    private static CmptInstanceHolder cmptInstanceHolder = new CmptInstanceHolder();
    //API所关联的组件配置缓存 key: fullQualifiedName    value: ICmpt
    private Map&lt;String, ICmpt&gt; cmpts = new ConcurrentHashMap&lt;&gt;();

    private CmptInstanceHolder() {
    }

    public static CmptInstanceHolder getInstance() {
        return CmptInstanceHolder.cmptInstanceHolder;
    }

    /**
     * 根据类名加版本从缓存中获取组件实例,如果不存在直接返回null；
     *
     * @return
     */
    public ICmpt getCmpt(final String fullQualifiedName, final Float version, String code) {
        final String key = buildKey(fullQualifiedName, version, code);
        return this.cmpts.get(key);
    }

    /**
     * 添加对象
     */
    public void addEntry(final ICmpt cmpt, final String fullQualifiedName, final Float version, final String code) {
        if (cmpt == null || StringUtils.isEmpty(fullQualifiedName) || StringUtils.isEmpty(code)) {
            return;
        }
        final String key = buildKey(fullQualifiedName, version, code);
        removeEntry(fullQualifiedName, version, code);
        this.cmpts.put(key, cmpt);
    }

    private String buildKey(final String fullQualifiedName, Float version, final String code) {
        return fullQualifiedName + &quot;.&quot; + version + code;
    }

    public void removeEntry(final String fullQualifiedName, final Float version, final String code) {
        ICmpt remove = this.cmpts.remove(buildKey(fullQualifiedName, version, code));
        if (null != remove) {
            remove.destroy();
        }
    }

    /**
     * 获取所有的组件实例
     * @return
     */
    public Map&lt;String, ICmpt&gt; getAllCmpts(){
        return this.cmpts;
    }
}
</code></pre>
<pre><code class="language-java">public class CmptClassLoaderUtil {

    private static Logger logger = LoggerFactory.getLogger(CmptClassLoaderUtil.class);

    public static ICmpt newInstance(final CmptDef cmptDef) {
        ICmpt cmpt = null;
        try {
            final String jarPath = getJarPath(cmptDef);
            logger.info(&quot;尝试载入jar包,jar包路径: &quot; + jarPath);
            //加载依赖jar
            CmptClassLoader cmptClassLoader = CmptClassLoaderManager.loadJar(cmptDef.getIdCmptDef(), jarPath, true);
            // 创建实例
            if (null != cmptClassLoader) {
                cmpt = LoadClassUtil.newObject(cmptDef, ICmpt.class, cmptClassLoader);
            } else {
                logger.error(&quot;加载组件jar包失败! jarPath: &quot; + jarPath);
            }
        } catch (Exception e) {
            logger.error(&quot;组件类加载失败，请检查类名和版本是否正确。ClassName=&quot; + cmptDef.getFullQualifiedName() + &quot;, Version=&quot; + cmptDef.getVersion());
            e.printStackTrace();
        }
        return cmpt;
    }

    public static String getJarPath(final CmptDef cmptDef) {
        StringBuffer sb = new StringBuffer();
        sb.append(AppConfigUtil.getValue(&quot;app.home&quot;));
        sb.append(AppConfigUtil.getValue(&quot;cmpt.location&quot;));
        sb.append(&quot;/&quot;);
        //开发中关闭多级目录,不好部署
        sb.append(cmptDef.getCode());
        sb.append(&quot;/&quot;);
        sb.append(cmptDef.getVersion());
        sb.append(&quot;/&quot;);
        String[] split = cmptDef.getFullQualifiedName().split(&quot;\\.&quot;);
        sb.append(split[split.length - 1]);
        sb.append(&quot;_&quot;);
        sb.append(cmptDef.getVersion());
        sb.append(&quot;.jar&quot;);
        if (logger.isDebugEnabled()) {
            logger.debug(&quot;构建jar包路径: &quot; + sb.toString());
        }
        return sb.toString();
    }

}
</code></pre>
<pre><code class="language-shell">#linux版home目录
app.home=/work/sharestore
#组件资源存放路径，&lt;home&gt;/cmpt/&lt;code&gt;/&lt;version&gt;/&lt;name&gt;_&lt;version&gt;.jar,html
cmpt.location=/cmpt
</code></pre>
<pre><code class="language-java">/**
 * 类加载器管理, 加载, 卸载jar包
 */
public class CmptClassLoaderManager {

    private static final Logger logger = Logger.getLogger(CmptClassLoaderManager.class);

    private static Map&lt;String, CmptClassLoader&gt; classLoaderMap = new ConcurrentHashMap&lt;&gt;();

    private CmptClassLoaderManager() {
    }

    /**
     * 载入Jar包, 判断是否重新载入Jar包
     *
     * @param fileName
     * @param isReloadJar
     * @return
     */
    public static CmptClassLoader loadJar(String IdCmptDef, String fileName, boolean isReloadJar) {
        fileName = FileUtil.fixFileName(fileName);
        CmptClassLoader cmptClassLoader = classLoaderMap.get(IdCmptDef);
        if (isReloadJar || null == cmptClassLoader) {
            if (logger.isDebugEnabled()) {
                logger.debug(&quot;从文件载入jar组件&quot;);
            }
            return loadJar(IdCmptDef, fileName);
        } else {
            if (logger.isDebugEnabled()) {
                logger.debug(&quot;从缓存载入jar组件&quot;);
            }
            return cmptClassLoader;
        }
    }

    /**
     * 载入Jar包, 以新Jar包载入
     *
     * @param fileName
     * @return 返回一个类加载器
     */
    private static CmptClassLoader loadJar(String IdCmptDef, String fileName) {
        CmptClassLoader loader;
        try {
            boolean exists = new File(fileName).exists();
            if (exists) {
                if (null == classLoaderMap.get(IdCmptDef) || unLoadJar(IdCmptDef)) {
                    loader = new CmptClassLoader();
                    boolean loadJar = loader.addURL(fileName);
                    if (loadJar) {
                        classLoaderMap.put(IdCmptDef, loader);
                        return loader;
                    } else {
                        loader.close();
                    }
                }
            } else {
                throw new IllegalArgumentException(&quot;传入参数错误,文件不存在! file: &quot; + fileName);
            }
        } catch (Exception e) {
            logger.error(&quot;&quot;,e);
        }
        return null;
    }

    public static boolean unLoadJar(String IdCmptDef) {
        boolean unLoadJar = false;
        if (logger.isDebugEnabled()) {
            logger.debug(&quot;请求卸载jar包: &quot; + IdCmptDef);
        }
        try {
            CmptClassLoader loader = classLoaderMap.remove(IdCmptDef);
            if (null != loader) {
                loader.close();
            }
            unLoadJar = true;
        } catch (Exception e) {
            logger.error(&quot;&quot;,e);
        }
        return unLoadJar;
    }

    /**
     * 获取组件定义对应的实例的类加载器
     *
     * @param idCmptDef
     * @return
     */
    public static ClassLoader getCmptClassLoader(String idCmptDef) {
        return classLoaderMap.get(idCmptDef);
    }
}
</code></pre>
<pre><code class="language-java">public class FileUtil {
	public static String fixFileName(String fileName) {
        if (null == fileName) fileName = &quot;&quot;;
        fileName = fileName.replaceAll(&quot;\\\\&quot;, &quot;/&quot;);
        fileName = fileName.replaceAll(&quot;//&quot;, &quot;/&quot;);
        return fileName;
    }
}
</code></pre>
<pre><code class="language-java">/**
 * 类加载器终极版, 加载, 卸载jar包
 */
public class CmptClassLoader extends URLClassLoader {

    private static final Logger logger = Logger.getLogger(CmptClassLoader.class);

    CmptClassLoader(URL[] urls, ClassLoader parent) {
        super(urls, parent);
    }

    CmptClassLoader(URL[] urls) {
        super(urls);
    }

    CmptClassLoader(URL[] urls, ClassLoader parent, URLStreamHandlerFactory factory) {
        super(urls, parent, factory);
    }

    CmptClassLoader() {
        super(new URL[]{}, findParentClassLoader());
    }

    /**
     * 载入Jar
     *
     * @param fileName
     * @return
     */
    boolean addURL(String fileName) {
        try {
            URL url = new File(fileName).toURL();
            URLClassPath ucp = this.getUCP();
            ucp.addURL(url);
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
        return true;
    }

    /**
     * 定位当前父类加载器
     *
     * @return
     */
    private static ClassLoader findParentClassLoader() {
        ClassLoader parent = logger.getClass().getClassLoader();
        if (parent == null) {
            throw new RuntimeException(&quot;无法获取当前父加载器!&quot;);
        }
        return parent;
    }

    private URLClassPath getUCP() {
        URLClassPath ucp = null;
        try {
            Field declaredField = URLClassLoader.class.getDeclaredField(&quot;ucp&quot;);
            declaredField.setAccessible(true);
            Object o = declaredField.get(this);
            ucp = (URLClassPath) o;
        } catch (IllegalAccessException e) {
            e.printStackTrace();
        } catch (NoSuchFieldException e) {
            e.printStackTrace();
        }
        return ucp;
    }

    @Override
    protected void finalize() throws Throwable {
        super.finalize();
        this.close();
    }
}
</code></pre>
<pre><code class="language-java">/**
 * 类加载器工具类
 */
public class LoadClassUtil {
    private final static LoadClassUtil LOAD_JAR_UTIL = new LoadClassUtil();
    private static Logger logger = LoggerFactory.getLogger(LoadClassUtil.class);

    private LoadClassUtil() {
    }

    /**
     * 载入jar包
     * 将jar包路径添加到系统类加载器扫描类和资源的文件列表里
     *
     * @param fileName jar绝对路径
     * @return
     */
    public static boolean loadJar(String fileName) {
        try {
            if (strNotNull(fileName) &amp;&amp; fileExists(fileName)) {//(ClassLoader要与当前程序同一个loader)
                getMethod().invoke(LOAD_JAR_UTIL.getClass().getClassLoader(), getURL(fileName));//添加路径URL
                //getMethod().invoke(Launcher.getLauncher().getClassLoader(), getURL(fileName));//添加路径URL
                return true;
            } else {
                throw new IllegalArgumentException(&quot;传入参数错误,文件或不存在! file: &quot; + fileName);
            }
        } catch (Exception e) {
            logger.error(&quot;&quot;,e);
        }
        return false;
    }

    /**
     * 判断字符串不为空
     *
     * @param str
     * @return
     */
    private static boolean strNotNull(String str) {
        return null != str &amp;&amp; !str.equals(&quot;&quot;);
    }

    private static boolean fileExists(String fileName) {
        return new File(fileName).exists();
    }

    /**
     * 拿到添加扫描类和资源的路径URL的方法
     *
     * @return
     * @throws NoSuchMethodException
     */
    private static Method getMethod() throws NoSuchMethodException {
        Method method = URLClassLoader.class.getDeclaredMethod(&quot;addURL&quot;, URL.class);
        // 破解方法的访问权限
        method.setAccessible(true);
        return method;
    }

    /**
     * 得到一个URL
     *
     * @param fileName
     * @return
     * @throws MalformedURLException
     */
    private static URL getURL(String fileName) throws MalformedURLException {
        return new File(fileName).toURI().toURL();
    }

    /**
     * 创建对象实例
     *
     * @param className 全限定名
     * @return
     */
    public static Object newObject(String className) {
        try {
            return Class.forName(className).newInstance();
        } catch (Exception e) {
            logger.error(&quot;&quot;,e);
        }
        return null;
    }

    /**
     * 创建转换类型后的对象实例
     *
     * @param className 全限定名
     * @param tClass    返回类型
     * @param &lt;T&gt;
     * @return
     */
    public static &lt;T&gt; T newObject(String className, Class&lt;T&gt; tClass) {
        try {
            return (T) Class.forName(className).newInstance();
        } catch (Exception e) {
            logger.error(&quot;&quot;,e);
        }
        return null;
    }

    /**
     * 创建转换类型后的对象实例
     *
     * @param cmptDef 组件定义-&gt;全限定名
     * @param tClass    返回类型
     * @param loader    类加载器
     * @param &lt;T&gt;
     * @return
     */
    public static &lt;T&gt; T newObject(CmptDef cmptDef, Class&lt;T&gt; tClass, ClassLoader loader) {
        try {
            String className = cmptDef.getFullQualifiedName();
            Object newInstance = Class.forName(className, true, loader).newInstance();
            return (T) newInstance;
        } catch (Exception e) {
            String jarPath = CmptClassLoaderUtil.getJarPath(cmptDef);
            logger.error(&quot;创建组件实例失败! className=&quot; + cmptDef.getFullQualifiedName() + &quot; jarPath=&quot; + jarPath);
            logger.error(&quot;创建出错组件:&quot; + cmptDef.getName() + cmptDef.getVersion() + &quot; ,文件信息:&quot; + FileUtil.fileInfo(jarPath));
            try {
                Class&lt;?&gt; aClass = loader.loadClass(cmptDef.getFullQualifiedName());
            } catch (ClassNotFoundException e1) {
                e1.printStackTrace();
                logger.error(&quot;类未载入:&quot; + cmptDef.getFullQualifiedName());
            }
        }
        return null;
    }

    /**
     * 执行对象的方法
     *
     * @param o          实例对象
     * @param methodName 方法名称
     * @param args       形参
     * @return
     */
    public static Object invokeMethod(Object o, String methodName, Object... args) {
        try {
            Object invoke;
            if (null == args || args.length == 0) {//有缺陷,如果形参是任意Object,但传入参数是null,无法得到形参类型,得到有参的方法.
                Method method = o.getClass().getMethod(methodName);
                invoke = method.invoke(o);
            } else {
                Method method = o.getClass().getMethod(methodName, args.getClass());
                invoke = method.invoke(o, args);
            }
            return invoke;
        } catch (Exception e) {
            logger.error(&quot;&quot;,e);
        }
        return null;
    }

}
</code></pre>
<h3 id="组件实现公共接口类">组件实现公共接口类</h3>
<pre><code class="language-java">public interface ICmpt {

    /**
     * 组件执行入口
     *
     * @param request
     * @param config，组件实例的参数配置
     * @param actionNode,      当前执行的流程节点
     * @param procContextDTO,     流程引擎实例上下文
     * @return
     */
    CmptResult execute(CmptRequest request, Map&lt;String, FieldDTO&gt; config, ActionNode actionNode, ProcContextDTO procContextDTO);

    /**
     * 销毁组件持有的特殊资源，比如线程。
     */
    void destroy();
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[mybatis级联查询]]></title>
        <id>https://tinaxiawuhao.github.io/post/hIydIZSN1/</id>
        <link href="https://tinaxiawuhao.github.io/post/hIydIZSN1/">
        </link>
        <updated>2021-12-27T03:17:49.000Z</updated>
        <content type="html"><![CDATA[<h2 id="modelmapperxml">ModelMapper.xml</h2>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;
&lt;mapper namespace=&quot;com.haier.biz.mapper.ModelMapper&quot;&gt;
    &lt;resultMap id=&quot;BaseResultMap&quot; type=&quot;com.haier.biz.entity.Model&quot;&gt;
        &lt;id column=&quot;model_id&quot; jdbcType=&quot;BIGINT&quot; property=&quot;modelId&quot;/&gt;
        &lt;result column=&quot;equipment_model_mark&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;equipmentModelMark&quot;/&gt;
        &lt;result column=&quot;equipment_name&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;equipmentName&quot;/&gt;
        &lt;result column=&quot;specification_model&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;specificationModel&quot;/&gt;
        &lt;result column=&quot;model_description&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;modelDescription&quot;/&gt;
        &lt;result column=&quot;model_sort_key&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;modelSortKey&quot;/&gt;
        &lt;result column=&quot;model_classification_label&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;modelClassificationLabel&quot;/&gt;
        &lt;result column=&quot;tenant_product_id&quot; jdbcType=&quot;BIGINT&quot; property=&quot;tenantProductId&quot;/&gt;
        &lt;result column=&quot;tenant_product_name&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;tenantProductName&quot;/&gt;
        &lt;result column=&quot;manufacturer&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;manufacturer&quot;/&gt;
        &lt;result column=&quot;create_by&quot; jdbcType=&quot;BIGINT&quot; property=&quot;createBy&quot;/&gt;
        &lt;result column=&quot;create_time&quot; jdbcType=&quot;TIMESTAMP&quot; property=&quot;createTime&quot;/&gt;
        &lt;result column=&quot;update_by&quot; jdbcType=&quot;BIGINT&quot; property=&quot;updateBy&quot;/&gt;
        &lt;result column=&quot;update_time&quot; jdbcType=&quot;TIMESTAMP&quot; property=&quot;updateTime&quot;/&gt;
    &lt;/resultMap&gt;
    &lt;!--级联查询--&gt;
    &lt;resultMap id=&quot;BaseResultInstanceMap&quot; type=&quot;com.haier.biz.entity.DTO.ModelDTO&quot; extends=&quot;BaseResultMap&quot;&gt;
        &lt;result column=&quot;publishNumber&quot; jdbcType=&quot;BIGINT&quot; property=&quot;publishNumber&quot;/&gt;
        &lt;result column=&quot;customer_id&quot; jdbcType=&quot;BIGINT&quot; property=&quot;customerId&quot;/&gt;
        &lt;result column=&quot;topic&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;topic&quot;/&gt;
        &lt;!--property来源ModelDTO属性，column来源于selectInstancelList查询--&gt;
        &lt;!--查询单条--&gt;
        &lt;association property=&quot;equipmentPicture&quot; column=&quot;equipment_model_mark&quot;
                     select=&quot;getEquipmentPicture&quot;&gt;&lt;/association&gt;
        &lt;association property=&quot;instanceNumber&quot; column=&quot;{equipmentModelMark=equipment_model_mark,customerId=customer_id}&quot;
                     select=&quot;getCustomerInstanceNumber&quot;&gt;&lt;/association&gt;
        &lt;!--查询列表--&gt;
        &lt;collection property=&quot;equipmentPictures&quot; column=&quot;equipment_model_mark&quot;
                    select=&quot;getEquipmentPictures&quot;&gt;&lt;/collection&gt;
    &lt;/resultMap&gt;
    &lt;select id=&quot;selectInstancelList&quot; parameterType=&quot;com.haier.biz.entity.VO.InstanceSelectVo&quot;
            resultMap=&quot;BaseResultInstanceMap&quot;&gt;
        SELECT
        distinct model.model_id,
        equipment_model_mark,
        equipment_name,
        specification_model,
        model_description,
        model_sort_key,
        model_classification_label,
        tenant_product_id,
        tenant_product_name,
        manufacturer,
        model.create_by,
        model.create_time,
        model.update_by,
        model.update_time,
        0 as publishNumber,
        relation_model_customer.customer_id,
        relation_model_customer.topic
        FROM
        model
        LEFT JOIN relation_model_customer on relation_model_customer.model_id=model.model_id
        &lt;where&gt;
            &lt;if test=&quot;customerId != null&quot;&gt;
                and relation_model_customer.customer_id = #{customerId}
            &lt;/if&gt;
            &lt;if test=&quot;modelSortKey != null and modelSortKey!=''&quot;&gt;
                and `model`.model_sort_key = #{modelSortKey}
            &lt;/if&gt;
            &lt;if test=&quot;equipmentName != null and equipmentName!=''&quot;&gt;
                and `model`.equipment_name like CONCAT('%', #{equipmentName,jdbcType=VARCHAR},'%')
            &lt;/if&gt;
        &lt;/where&gt;
    &lt;/select&gt;
    &lt;select id=&quot;getEquipmentPicture&quot; parameterType=&quot;java.lang.String&quot; resultType=&quot;java.lang.String&quot;&gt;
        SELECT model_instance_file_associate.file_object_key as equipmentPicture
        from model_instance_file_associate
        where model_instance_file_associate.file_type=4
            and model_instance_file_associate.type=0
            and model_instance_file_associate.del_flag=0
            and model_instance_file_associate.model_or_instance_mark = #{equipmentModelMark,jdbcType=VARCHAR}
        limit 1
    &lt;/select&gt;
    &lt;select id=&quot;getCustomerInstanceNumber&quot; parameterType=&quot;java.util.Map&quot; resultType=&quot;java.lang.Long&quot;&gt;
        SELECT count(*)
        from model_instance_associate
        left join `instance` on model_instance_associate.instance_mark=`instance`.instance_mark
        where model_instance_associate.equipment_model_mark = #{equipmentModelMark,jdbcType=VARCHAR}
            and `instance`.customer_id=#{customerId}
    &lt;/select&gt;
    &lt;select id=&quot;getEquipmentPictures&quot; parameterType=&quot;java.lang.String&quot; resultType=&quot;java.lang.String&quot;&gt;
       SELECT model_instance_file_associate.file_object_key as equipmentPictures
        from model_instance_file_associate
        where model_instance_file_associate.file_type=4
            and model_instance_file_associate.type=0
            and model_instance_file_associate.del_flag=0
            and model_instance_file_associate.model_or_instance_mark = #{equipmentModelMark,jdbcType=VARCHAR}
    &lt;/select&gt;
&lt;/mapper&gt;
</code></pre>
<h2 id="modelmapper">ModelMapper</h2>
<pre><code class="language-java">@Repository
public interface ModelMapper extends BaseMapper&lt;Model&gt; {

    List&lt;ModelDTO&gt; selectInstancelList(InstanceSelectVo instanceSelectVo);

    List&lt;String&gt; getEquipmentPictures(@Param(&quot;equipmentModelMark&quot;) String equipmentModelMark);

}
</code></pre>
<h2 id="modeldto">ModelDTO</h2>
<pre><code class="language-java">@Data
@EqualsAndHashCode(callSuper = false)
@Accessors(chain = true)
@AllArgsConstructor
@NoArgsConstructor
public class ModelDTO extends Model {

    @ApiModelProperty(value = &quot;产品(模型)图片(取第一张)&quot;)
    private String equipmentPicture;

    @ApiModelProperty(value = &quot;产品(模型)图片&quot;)
    private List&lt;String&gt; equipmentPictures;

    @ApiModelProperty(value = &quot;发布客户数&quot;)
    private Long publishNumber;

    @ApiModelProperty(value = &quot;实例设备数&quot;)
    private Long instanceNumber;

    @ApiModelProperty(value = &quot;使用方Id&quot;)
    private Long customerId;

    @ApiModelProperty(value = &quot;实例设备运行情况&quot;)
    private List&lt;NumberDTO&gt; equipmentList;

    @ApiModelProperty(value = &quot;kafka实时推送的topic&quot;)
    private String topic;
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[clickhouse数据分区]]></title>
        <id>https://tinaxiawuhao.github.io/post/hle1ZXFqv/</id>
        <link href="https://tinaxiawuhao.github.io/post/hle1ZXFqv/">
        </link>
        <updated>2021-12-15T07:16:43.000Z</updated>
        <content type="html"><![CDATA[<h2 id="mergetree-数据分区规则">MergeTree 数据分区规则</h2>
<p>创建按照月份为分区条件的表 <strong>tab_partition</strong></p>
<pre><code class="language-csharp">CREATE TABLE tab_partition(`dt` Date, `v` UInt8) 
ENGINE = MergeTree PARTITION BY toYYYYMM(dt) ORDER BY v;
insert into tab_partition(dt,v) values ('2020-02-11',1),('2020-02-13',2);
insert into tab_partition(dt,v) values ('2020-04-11',3),('2020-04-13',4);
insert into tab_partition(dt,v) values ('2020-09-11',5),('2020-09-10',6);
insert into tab_partition(dt,v) values ('2020-10-12',7),('2020-10-09',8);
insert into tab_partition(dt,v) values ('2020-02-14',9),('2020-02-15',10);
insert into tab_partition(dt,v) values ('2020-02-11',23),('2020-02-13',45);
</code></pre>
<p>MergeTree 存储引擎在写入数据之后生成对应的分区文件为：</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1639552667308.webp" alt="" loading="lazy"></figure>
<p>MergeTree 的分区目录是在写入数据的过程中被创建出来，每 insert 一次，就会创建一批次分区目录。也就是说如果仅创建表结构，是不会创建分区目录的，因为木有数据。</p>
<p>MergeTree 数据分区目录命名规则其规则为：<strong>PartitionID_MinBlockNum_MaxBlockNum_Level</strong><br>
比如 <strong>202002_4_4_0</strong> 其中 202002 是分区ID ，<strong>4_4</strong> 对应的是<br>
最小的数据块编号和最大的数据块编号，最后的 _0 表示目前分区合并的层级。<br>
各部分的含义及命名规则如下：<br>
PartitionID：该值由 insert 数据时分区键的值来决定。分区键支持使用任何一个或者多个字段组合表达式，针对取值数据类型的不同，分区 ID 的生成逻辑目前有四种规则：</p>
<blockquote>
<p>不指定分区键：如果建表时未指定分区键，则分区 ID 默认使用 all，所有数据都被写入 all 分区中。</p>
<p>整型字段：如果分区键取值是整型字段，并且无法转换为 YYYYMMDD 的格式，则会按照该整型字段的字符形式输出，作为分区 ID 取值。</p>
<p>日期类型：如果分区键属于日期格式，或可以转换为 YYYYMMDD 格式的整型，则按照 YYYYMMDD 格式化后的字符形式输出，作为分区 ID 取值。</p>
<p>其他类型：如果使用其他类似 Float、String 等类型作为分区键，会通过对其插入数据的 128 位 Hash 值作为分区 ID 的取值。</p>
</blockquote>
<p>MinBlockNum 和 MaxBlockNum：BlockNum 是一个整型的自增长型编号，该编号在单张 MergeTree 表中从 1 开始全局累加，当有新的分区目录创建后，该值就加 1，对新的分区目录来讲，MinBlockNum 和 MaxBlockNum 取值相同。例如上面示例数据为 202002_1_1_0  202002_1_5_1，但当分区目录进行合并后，取值规则会发生变化，MinBlockNum 取同一分区所欲目录中最新的 MinBlockNum 值。MaxBlockNum 取同一分区内所有目录中的最大值。<br>
Level：表示合并的层级。相当于某个分区被合并的次数，它不是以表全局累加，而是以分区为单位，初始创建的分区，初始值为 0，相同分区 ID 发生合并动作时，在相应分区内累计加 1。</p>
<h2 id="mergetree-数据分区合并规则">MergeTree 数据分区合并规则</h2>
<p>随着数据的写入 MergeTree 存储引擎会很多分区目录。如果分区目录数太多怎么办？因为 Clickhouse 的 MergeTree 存储引擎是基于 LSM 实现的。MergeTree 可以通过分区合并将属于相同分区的多个目录合并为一个新的目录（官方描述在 10 到 15 分钟内会进行合并，也可直接执行 optimize 语句），已经存在的旧目录（也即 system.parts 表中 activie 为 0 的分区）在之后某个时刻通过后台任务删除（默认 8 分钟）。</p>
<h3 id="分区合并">分区合并</h3>
<p>我们回顾之前创建的表的分区目录</p>
<pre><code class="language-bash"># ls 
202002_1_1_0  202004_2_2_0  202009_3_3_0
202002_4_4_0  202002_5_5_0
</code></pre>
<p>手工触发分区合并</p>
<pre><code class="language-csharp">qabb-qa-ch00 :) optimize table tab_partition;
OPTIMIZE TABLE tab_partition
Ok.
0 rows in set. Elapsed: 0.003 sec.

qabb-qa-ch00 :) select partition,name,part_type, active from system.parts where  table ='tab_partition';
┌─partition─┬─name─────────┬─part_type─┬─active─┐
│ 202002    │ 202002_1_1_0 │ Wide      │      0 │
│ 202002    │ 202002_1_5_1 │ Wide      │      1 │
│ 202002    │ 202002_4_4_0 │ Wide      │      0 │
│ 202002    │ 202002_5_5_0 │ Wide      │      0 │
│ 202004    │ 202004_2_2_0 │ Wide      │      1 │
│ 202009    │ 202009_3_3_0 │ Wide      │      1 │
└───────────┴──────────────┴───────────┴────────┘

6 rows in set. Elapsed: 0.003 sec.
</code></pre>
<p>其中 active 为 1 表示经过合并之后的最新分区，为 0 则表示旧分区，查询时会自动过滤 active=0 的分区。<br>
我们通过分区 202002 最新的分区目录 <strong>202002_1_5_1</strong> 看到合并分区新目录的命名规则如下：</p>
<blockquote>
<p>PartitionID：分区 ID 保持不变<br>
MinBlockNum：取同一个分区内所有目录中最小的 MinBlockNum 值<br>
MaxBlockNUm：取同一个分区内所有目录中最大的 MaxBlockNum 值<br>
Level：取同一个分区内最大 Level 值并加 1</p>
</blockquote>
<p>合并之后的目录结构如下：</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1639552681661.webp" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[mysql 简单导入 clickhouse]]></title>
        <id>https://tinaxiawuhao.github.io/post/BHjbgcFm-/</id>
        <link href="https://tinaxiawuhao.github.io/post/BHjbgcFm-/">
        </link>
        <updated>2021-12-15T07:12:02.000Z</updated>
        <content type="html"><![CDATA[<p>数据迁移需要从 mysql 导入 clickhouse, clickhouse 自身支持的三种方式 。</p>
<h2 id="create-table-engin-mysql">create table engin mysql</h2>
<pre><code>CREATE TABLE [IF NOT EXISTS] [db.]table_name [ON CLUSTER cluster]
(
    name1 [type1] [DEFAULT|MATERIALIZED|ALIAS expr1] [TTL expr1],
    name2 [type2] [DEFAULT|MATERIALIZED|ALIAS expr2] [TTL expr2],
    ...
    INDEX index_name1 expr1 TYPE type1(...) GRANULARITY value1,
    INDEX index_name2 expr2 TYPE type2(...) GRANULARITY value2
) ENGINE = MySQL('host:port', 'database', 'table', 'user', 'password'[, replace_query, 'on_duplicate_clause']);
</code></pre>
<blockquote>
<p>官方文档: https://clickhouse.yandex/docs/en/operations/table_engines/mysql/</p>
</blockquote>
<p>注意，实际数据存储在远端 mysql 数据库中，可以理解成外表。<br>
可以通过在 mysql 增删数据进行验证。</p>
<h2 id="insert-into-select-from">insert into select from</h2>
<pre><code>-- 先建表
CREATE TABLE [IF NOT EXISTS] [db.]table_name [ON CLUSTER cluster]
(
    name1 [type1] [DEFAULT|MATERIALIZED|ALIAS expr1],
    name2 [type2] [DEFAULT|MATERIALIZED|ALIAS expr2],
    ...
) ENGINE = engine
-- 导入数据
INSERT INTO [db.]table [(c1, c2, c3)] select 列或者* from mysql('host:port', 'db', 'table_name', 'user', 'password')
</code></pre>
<p>可以自定义列类型，列数，使用 clickhouse 函数对数据进行处理，比如 <code>select toDate(xx) from mysql(&quot;host:port&quot;,&quot;db&quot;,&quot;table_name&quot;,&quot;user_name&quot;,&quot;password&quot;)</code></p>
<h2 id="create-table-as-select-from">create table as select from</h2>
<pre><code>CREATE TABLE [IF NOT EXISTS] [db.]table_name
ENGINE =Log
AS
SELECT *
FROM mysql('host:port', 'db', 'article_clientuser_sum', 'user', 'password')
</code></pre>
<blockquote>
<p>网友文章: http://jackpgao.github.io/2018/02/04/ClickHouse-Use-MySQL-Data/</p>
</blockquote>
<p>不支持自定义列，参考资料里的博主写的 <code>ENGIN=MergeTree</code> 测试失败。<br>
可以理解成 create table 和 insert into select 的组合</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ClickHouse初识]]></title>
        <id>https://tinaxiawuhao.github.io/post/GwxNFXsxh/</id>
        <link href="https://tinaxiawuhao.github.io/post/GwxNFXsxh/">
        </link>
        <updated>2021-12-15T03:00:13.000Z</updated>
        <content type="html"><![CDATA[<h2 id="一-简介">一、简介</h2>
<h4 id="11-clickhouse-是什么">1.1 ClickHouse 是什么？</h4>
<p>ClickHouse 是 Yandex（俄罗斯最大的搜索引擎）开源的一个用于实时数据分析的基于列存储的数据库，其处理数据的速度比传统方法快 100-1000 倍。ClickHouse 的性能超过了目前市场上可比的面向列的 DBMS，每秒钟每台服务器每秒处理数亿至十亿多行和数十千兆字节的数据。</p>
<h4 id="12-clickhouse的一些特性">1.2 ClickHouse的一些特性：</h4>
<ol>
<li>快速：ClickHouse 会充分利用所有可用的硬件，以尽可能快地处理每个查询。单个查询的峰值处理性能超过每秒 2 TB（解压缩后，仅使用的列）。在分布式设置中，读取是在健康副本之间自动平衡的，以避免增加延迟。</li>
<li>容错：ClickHouse 支持多主机异步复制，并且可以跨多个数据中心进行部署。所有节点都相等，这可以避免出现单点故障。单个节点或整个数据中心的停机时间不会影响系统的读写可用性。</li>
<li>可伸缩：ClickHouse 可以在垂直和水平方向上很好地缩放。ClickHouse 易于调整以在具有数百或数千个节点的群集上或在单个服务器上，甚至在小型虚拟机上执行。当前，每个单节点安装的数据量超过数万亿行或数百兆兆字节。</li>
<li>易用：ClickHouse 简单易用，开箱即用。它简化了所有数据处理：将所有结构化数据吸收到系统中，并且立即可用于构建报告。SQL 允许表达期望的结果，而无需涉及某些 DBMS 中可以找到的任何自定义非标准 API。</li>
<li>充分利用硬件：ClickHouse 与具有相同的可用 I/O 吞吐量和 CPU 容量的传统的面向行的系统相比，其处理典型的分析查询要快两到三个数量级。列式存储格式允许在 RAM 中容纳更多热数据，从而缩短了响应时间。</li>
<li>提高 CPU 效率：向量化查询执行涉及相关的 SIMD 处理器指令和运行时代码生成。处理列中的数据会提高 CPU 行缓存的命中率。</li>
<li>优化磁盘访问：ClickHouse 可以最大程度地减少范围查询的次数，从而提高了使用旋转磁盘驱动器的效率，因为它可以保持连续存储数据。</li>
<li>最小化数据传输：ClickHouse 使公司无需使用专门针对高性能计算的专用网络即可管理其数据。</li>
</ol>
<p><strong>何时使用 ClickHouse：</strong><br>
用于分析结构良好且不可变的事件或日志流，建议将每个此类流放入具有预连接维度的单个宽表中。<br>
<strong>何时不使用 ClickHouse：</strong><br>
不适合事务性工作负载（OLTP）、高价值的键值请求、Blob 或文档存储。</p>
<h4 id="13-为什么-clickhouse-速度这么快">1.3 为什么 ClickHouse 速度这么快？</h4>
<p>首先我们了解一下 OLAP 场景的特点：</p>
<ol>
<li>读多于写。</li>
<li>大宽表，读大量行但是少量列，结果集较小。</li>
<li>数据批量写入，且数据不更新或少更新。</li>
</ol>
<p>针对分析类查询，通常只需要读取表的一小部分列。在列式数据库中你可以只读取你需要的数据。例如，如果只需要读取 100 列中的 5 列，这将帮助你最少减少 20 倍的 I/O 消耗。</p>
<p>由于数据总是打包成批量读取的，所以压缩是非常容易的。同时数据按列分别存储这也更容易压缩。这进一步降低了 I/O 的体积。由于 I/O 的降低，这将帮助更多的数据被系统缓存。</p>
<p>例如，查询《统计每个广告平台的记录数量》需要读取《广告平台 ID》这一列，它在未压缩的情况下需要 1 个字节进行存储。如果大部分流量不是来自广告平台，那么这一列至少可以以十倍的压缩率被压缩。当采用快速压缩算法，它的解压速度最少在十亿字节（未压缩数据）每秒。换句话说，这个查询可以在单个服务器上以每秒大约几十亿行的速度进行处理。这实际上是当前实现的速度。</p>
<p>ClickHouse 从 OLAP 场景需求出发，定制开发了一套全新的高效列式存储引擎</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1639537283959.webp" alt="" loading="lazy"></figure>
<p><code>column-oriented</code>  图片来源见水印相比于行式存储，列式存储在分析场景下有着许多优良的特性。</p>
<ol>
<li>如前所述，分析场景中往往需要读大量行但是少数几个列。在行存模式下，数据按行连续存储，所有列的数据都存储在一个 block 中，不参与计算的列在 IO 时也要全部读出，读取操作被严重放大。而列存模式下，只需要读取参与计算的列即可，极大的减低了 IO cost，加速了查询。</li>
<li>同一列中的数据属于同一类型，压缩效果显著。列存往往有着高达十倍甚至更高的压缩比，节省了大量的存储空间，降低了存储成本。</li>
<li>更高的压缩比意味着更小的 data size，从磁盘中读取相应数据耗时更短。</li>
<li>自由的压缩算法选择。不同列的数据具有不同的数据类型，适用的压缩算法也就不尽相同。可以针对不同列类型，选择最合适的压缩算法。</li>
<li>高压缩比，意味着同等大小的内存能够存放更多数据，系统 cache 效果更好。</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Thingsboard源码编译]]></title>
        <id>https://tinaxiawuhao.github.io/post/DseKIIHw3/</id>
        <link href="https://tinaxiawuhao.github.io/post/DseKIIHw3/">
        </link>
        <updated>2021-12-02T07:49:30.000Z</updated>
        <content type="html"><![CDATA[<h2 id="环境安装">环境安装</h2>
<p>开发环境要求： Jdk 1.11 版本 Postgresql 9 以上 Node.js Npm Maven 3.6 以上 Git 工具 Idea 开发工具 Redis</p>
<h3 id="jdk">JDK</h3>
<p><strong>下载安装</strong></p>
<p>JDK 官方下载地址： <a href="https://www.oracle.com/java/technologies/downloads/#java11-windows">Java Downloads | Oracle</a></p>
<p>JDK 版本选择 JDK11，我本地环境是 Windos10 64 位，所以选择 jdk-11.0.13-windows-x64.exe</p>
<p><img src="https://tinaxiawuhao.github.io/post-images/1638431548398.png" alt="" loading="lazy"><br>
下载好了之后直接默认安装就行</p>
<p><strong>免安装版本</strong></p>
<p>下载jdk11<br>
http://openjdk.java.net/install/index.html</p>
<p>这个页面大部分都是linux系统的；</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1638431591806.png" alt="" loading="lazy"></figure>
<p>然后我们点击jdk.java.net ，接着我们选择下载Java SE 11；</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1638431626019.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1638431650013.png" alt="" loading="lazy"></figure>
<p>下好了后，我们得到这样的文件：openjdk-11+28_windows-x64_bin.zip，解压后得到：jdk-11这样的文件夹；将该文件夹放到你习惯的地方；</p>
<p><strong>配置环境变量</strong></p>
<p><strong>步骤 1：</strong> 在 JAVA_HOME 中增加 JDK 的安装地址：C:\Program Files\Java\jdk1.8.0_221 <img src="https://tinaxiawuhao.github.io/post-images/1638431720261.png" alt="" loading="lazy"></p>
<p><strong>步骤 2：</strong> 在 CLASSPATH 中增加 JDK 的安装地址中的文件：.;%JAVA_HOME%\lib;%JAVA_HOME%\lib\dt.jar;%JAVA_HOME%\lib\tools.jar <img src="https://tinaxiawuhao.github.io/post-images/1638431747039.png" alt="" loading="lazy"></p>
<p><strong>步骤 3：</strong> 在 Path 中增加 JDK 的地址：%JAVA_HOME%\bin;%JAVA_HOME%\jre\bin; <img src="https://tinaxiawuhao.github.io/post-images/1638431804325.png" alt="" loading="lazy"></p>
<p><strong>步骤 4</strong> 输入以下命令</p>
<pre><code class="language-shell">java -version
</code></pre>
<p>如果能出现以下的提示信息，就算安装成功了<img src="https://tinaxiawuhao.github.io/post-images/1638431854451.png" alt="" loading="lazy"></p>
<h3 id="安装-idea">安装 IDEA</h3>
<p>参考：<a href="https://www.iotschool.com/topics/72">IDEA 安装教程</a></p>
<h3 id="安装-maven">安装 Maven</h3>
<p>步骤 1：下载 maven，进入地址：http://maven.apache.org/download.cgi <img src="https://tinaxiawuhao.github.io/post-images/1638431903988.png" alt="" loading="lazy"></p>
<p>步骤 2：下载到本地 <img src="https://tinaxiawuhao.github.io/post-images/1638431943007.png" alt="" loading="lazy"></p>
<p>步骤 3：配置环境变量 增加 MAVEN_HOME，即 maven 的地址：D:\tb\apache-maven-3.6.1-bin，请注意，如果直接解压，有可能会有两个 apache-maven-3.6.1-bin<img src="https://tinaxiawuhao.github.io/post-images/1638432216067.png" alt="" loading="lazy"></p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1638432310973.png" alt="" loading="lazy"></figure>
<p>MAVEN_OPTS，参数是 -Xms128m -Xmx1024m<img src="https://tinaxiawuhao.github.io/post-images/1638432342300.png" alt="" loading="lazy"></p>
<p>修改 Path，增加 Maven 的地址%MAVEN_HOME%\bin; <img src="https://tinaxiawuhao.github.io/post-images/1638432408010.png" alt="" loading="lazy"></p>
<p>测试 Maven 安装，打开命令行工具。使用命令 mvn -v，如果能出现以下提示，即安装成功 <img src="https://tinaxiawuhao.github.io/post-images/1638432460487.png" alt="" loading="lazy"></p>
<h3 id="nodejs-安装">Nodejs 安装</h3>
<p>步骤 1：下载 Nodejs 安装包，Nodejs 官网地址：https://nodejs.org/en/download/ <img src="https://tinaxiawuhao.github.io/post-images/1638432643509.png" alt="" loading="lazy"></p>
<p>步骤 2：安装完成后，使用命令查看 Nodejs 是否已经安装完成，能出现以下提示说明已经安装成功 !<img src="https://tinaxiawuhao.github.io/post-images/1638432779272.png" alt="" loading="lazy"></p>
<h3 id="安装-git">安装 git</h3>
<p>步骤 1：下载 git 安装包，git 官网地址是：https://git-scm.com/download/win<img src="https://tinaxiawuhao.github.io/post-images/1638433242163.png" alt="" loading="lazy"></p>
<p>步骤 2：安装完成后，使用命令行测试 git <img src="https://tinaxiawuhao.github.io/post-images/1638433294783.png" alt="" loading="lazy"></p>
<h3 id="安装-npm-全局依赖">安装 npm 全局依赖</h3>
<p>步骤 1：使用管理员 CMD 命令行，执行下面命令</p>
<pre><code class="language-shell">#npm 环境读取环境变量包
npm install -g cross-env
#webpack打包工具
npm install -g webpack
</code></pre>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1638433336020.png" alt="" loading="lazy"></figure>
<h3 id="安装-redis">安装 redis</h3>
<p>Redis 安装参考：https://www.iotschool.com/wiki/redis</p>
<p>环境安装到此结束，接下来是通过 Git 拉取代码。</p>
<h2 id="克隆-thingsboard-代码">克隆 thingsboard 代码</h2>
<h3 id="确定代码存放位置">确定代码存放位置</h3>
<p>在本地创建代码存放位置的文件目录，然后进入当前目录点击鼠标右键，选择 Git Bash Here <img src="https://tinaxiawuhao.github.io/post-images/1638433373069.png" alt="" loading="lazy"></p>
<h3 id="输入-git-命令克隆源代码">输入 git 命令克隆源代码</h3>
<pre><code class="language-shell">git clone https://github.com/thingsboard/thingsboard.git
</code></pre>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1638433403642.png" alt="" loading="lazy"></figure>
<p>耐心等待一段时间后，看到以下界面就算下载成功 <img src="https://tinaxiawuhao.github.io/post-images/1638433434959.png" alt="" loading="lazy"></p>
<h3 id="切换-git-分支">切换 git 分支</h3>
<p>默认下载的代码是 master 主分支的，我们开发需要切换到最新版本的分支。</p>
<p>查看项目源码的所有分支，下载源码后，需要进入到 thingsboard 文件夹 <img src="https://tinaxiawuhao.github.io/post-images/1638433484980.png" alt="" loading="lazy"></p>
<p>发现最新发布的版本是 2.4，所以我这里选择 2.4，当然你可以根据自己的情况进行分支选择</p>
<p>输入命令以下，即可切换至 2.4 的分支</p>
<pre><code class="language-shell">git checkout release-2.4
</code></pre>
<p>看到下图这样，即切换成成功 <img src="https://tinaxiawuhao.github.io/post-images/1638433523862.png" alt="" loading="lazy"></p>
<h2 id="准备工作">准备工作</h2>
<h3 id="外网连接">外网连接</h3>
<p>因为 TB 在编译过程中需要依赖很多国外的包，那么需要外网才能连接，有连接外网支持，可以到社区求助：https://www.iotschool.com/topics/node8</p>
<h3 id="设置-maven-为淘宝镜像">设置 Maven 为淘宝镜像</h3>
<p>工程是基于 Maven 管理，直接通过 idea open，之后会自动下载各种依赖包。依赖包的默认存储地址为：C:\Users\用户名.m2\repository，内容如下：</p>
<pre><code class="language-shell">$tree ~/.m2 -L 2
/home/jay/.m2
└── repository
    ├── antlr
    ├── aopalliance
    ├── asm
    ├── backport-util-concurrent
    ├── ch
    ...
</code></pre>
<p>一般情况下，使用官方镜像更新依赖包，网速不稳定，可将 Maven 镜像源设置为淘宝的，在 maven 安装包目录下找到 settings.xml 设置</p>
<p>大概位置截图：</p>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1638433563017.png" alt="" loading="lazy"></figure>
<p>把 settings.xml 里面内容设置成以下：</p>
<pre><code class="language-xml">&lt;mirrors&gt;
  &lt;mirror&gt;
       &lt;!--This sends everything else to /public --&gt;
       &lt;id&gt;aliyun_nexus&lt;/id&gt;
       &lt;mirrorOf&gt;*,!maven_nexus_201&lt;/mirrorOf&gt; 
       &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt;
   &lt;/mirror&gt;
&lt;/mirrors&gt;
</code></pre>
<p>不会设置的，可以参考这个文件：https://cdn.iotschool.com/iotschool/settings.xml</p>
<p>thingsboard QQ 群也有这个资源：121202538</p>
<h3 id="设置-npm-为淘宝镜像">设置 npm 为淘宝镜像</h3>
<p>同上，网速不好 npm 过程中也会下载失败，这是导致很多同学 thingsboard 编译失败的主要原因，所以我们在进行编译之前，也将 npm 替换为淘宝镜像：</p>
<pre><code class="language-shell">npm install -g mirror-config-china --registry=http://registry.npm.taobao.org        #使用淘宝镜像
npm config get registry                                                             #查询当前镜像
npm config rm registry                                                              #删除自定义镜像，使用官方镜像
npm info express
</code></pre>
<h3 id="设置-idea-管理员启动">设置 IDEA 管理员启动</h3>
<p>我本地开发环境编译项目使用 IDEA 工具进行编译，所以需要设置管理员启动，这样才有所有的权限执行编译命令。 步骤 1：点击 IDEA 图标右键，选择属性。<img src="https://tinaxiawuhao.github.io/post-images/1638433591413.png" alt="" loading="lazy"></p>
<p>步骤 2：点击兼容性 - 更改所有用户设置 - 以管理员身份运行此程序<img src="https://tinaxiawuhao.github.io/post-images/1638433662301.png" alt="" loading="lazy"></p>
<h2 id="开始编译">开始编译</h2>
<p>编译项目跟网速有关，最好连接上外网进行编译，一般 5~30 分钟都有可能，超过 30 分钟要检查你的网络。</p>
<h3 id="清理项目编译文件">清理项目编译文件</h3>
<p>使用 IDEA Maven 工具进行清理 <img src="https://tinaxiawuhao.github.io/post-images/1638433705438.png" alt="" loading="lazy"></p>
<h3 id="输入编译命令开始编译">输入编译命令开始编译</h3>
<p>在 IDEA 控制台（左下方）Terminal 输入以下命令进行编译：</p>
<pre><code class="language-shell">mvn clean install -DskipTests
</code></pre>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1638433732682.png" alt="" loading="lazy"></figure>
<p>等一段时间后，看到下面这张图就算编译成功，如果没有编译成功请按照本教程最后的常见问题进行排查，一般都是网络问题。如果还有问题，请到社区<a href="https://www.iotschool.com/topics/node8">thingsboard 专题</a>中提问。</p>
<figure data-type="image" tabindex="9"><img src="https://tinaxiawuhao.github.io/post-images/1638433762968.png" alt="" loading="lazy"></figure>
<h2 id="常见问题">常见问题</h2>
<h3 id="pom包pkgname等标签未定义">pom包pkg.name等标签未定义</h3>
<pre><code class="language-xml">    &lt;properties&gt;
        &lt;pkg.name&gt;thingsboard&lt;/pkg.name&gt;
        &lt;main.dir&gt;${basedir}&lt;/main.dir&gt;
        &lt;pkg.type&gt;java&lt;/pkg.type&gt;
        &lt;pkg.mainClass&gt;org.thingsboard.server.ThingsboardServerApplication&lt;/pkg.mainClass&gt;
        &lt;pkg.copyInstallScripts&gt;true&lt;/pkg.copyInstallScripts&gt;


        &lt;main.dir&gt;${basedir}&lt;/main.dir&gt;
        &lt;pkg.disabled&gt;true&lt;/pkg.disabled&gt;
        &lt;pkg.process-resources.phase&gt;none&lt;/pkg.process-resources.phase&gt;
        &lt;pkg.package.phase&gt;none&lt;/pkg.package.phase&gt;
        &lt;pkg.user&gt;thingsboard&lt;/pkg.user&gt;
        &lt;pkg.implementationTitle&gt;${project.name}&lt;/pkg.implementationTitle&gt;
        &lt;pkg.unixLogFolder&gt;/var/log/${pkg.name}&lt;/pkg.unixLogFolder&gt;
        &lt;pkg.installFolder&gt;/usr/share/${pkg.name}&lt;/pkg.installFolder&gt;
  &lt;/properties&gt;
</code></pre>
<h3 id="缓存导致编译失败">缓存导致编译失败</h3>
<p>每次编译失败进行二次编译时，要清理缓存，并杀死遗留进程 步骤 1：执行下面命令，杀死遗留进程</p>
<pre><code class="language-shell">taskkill /f /im java.exe
</code></pre>
<p>步骤 2：使用 IDEA Maven 工具进行清理 <img src="https://tinaxiawuhao.github.io/post-images/1638433793132.png" alt="" loading="lazy"></p>
<p><strong>温馨提示：要进行二次编译前，最好重启一次电脑！</strong></p>
<h3 id="server-ui-编译失败">Server UI 编译失败</h3>
<pre><code class="language-java">[ERROR] Failed to execute goal com.github.eirslett:frontend-maven-plugin:1.0:npm (npm install) on project ui: Failed to run task: 'npm install' failed. (error code 1) -&gt; [Help 1]
</code></pre>
<figure data-type="image" tabindex="10"><img src="https://tinaxiawuhao.github.io/post-images/1638433824944.png" alt="" loading="lazy"></figure>
<p>如果遇到这个问题，可从以下几个原因进行分析：</p>
<h4 id="原因-1node-npm-版本号问题">原因 1：node、npm 版本号问题</h4>
<p>本地环境安装的 node、npm 版本号与源码中 pom.xml 文件配置的版本号不一致。</p>
<p>解决方案： 步骤 1：使用 node -v、npm -v 查看安装的 node 和 npm 版本号 <img src="https://tinaxiawuhao.github.io/post-images/1638433858043.png" alt="" loading="lazy"></p>
<p>步骤 2：修改源码中 pom.xml 文件中的版本号</p>
<pre><code class="language-xml">&lt;configuration&gt;
   &lt;nodeVersion&gt;v12.13.1&lt;/nodeVersion&gt;
   &lt;npmVersion&gt;6.12.1&lt;/npmVersion&gt;
&lt;/configuration&gt;
</code></pre>
<p>需要修改的文件有三处，位置如下： <img src="https://tinaxiawuhao.github.io/post-images/1638433897767.png" alt="" loading="lazy"></p>
<h4 id="原因-2node-sass-下载失败">原因 2：node-sass 下载失败</h4>
<p>编译 Server UI 时，会下载 node-sass 依赖，如果因为网络原因没有下载成功，也会编译失败。如果你是按照本本教材一步一步来的，应该不会有问题，上面准备工作中，将 npm 镜像源切换为淘宝，那么下载会很快的。</p>
<pre><code class="language-shell">[INFO] Downloading binary from https://github.com/sass/node-sass/releases/download/v4.12.0/win32-x64-72_binding.node
[ERROR] Cannot download &quot;https://github.com/sass/node-sass/releases/download/v4.12.0/win32-x64-72_binding.node&quot;:
[ERROR]
[ERROR] ESOCKETTIMEDOUT
[ERROR]
[ERROR] Hint: If github.com is not accessible in your location
[ERROR]       try setting a proxy via HTTP_PROXY, e.g.
[ERROR]
[ERROR]       export HTTP_PROXY=http://example.com:1234
[ERROR]
[ERROR] or configure npm proxy via
[ERROR]
[ERROR]       npm config set proxy http://example.com:8080
[INFO]
[INFO] &gt; node-sass@4.12.0 postinstall F:\workspace\thingsboard\thingsboard\ui\node_modules\node-sass
[INFO] &gt; node scripts/build.js
[INFO]
</code></pre>
<figure data-type="image" tabindex="11"><img src="https://tinaxiawuhao.github.io/post-images/1638433935418.png" alt="" loading="lazy"></figure>
<p>解决方案：<a href="https://www.iotschool.com/wiki/tbinstall#%E8%AE%BE%E7%BD%AEnpm%E4%B8%BA%E6%B7%98%E5%AE%9D%E9%95%9C%E5%83%8F">切换镜像源为淘宝</a></p>
<p>解决方案：重启电脑，清理缓存</p>
<h4 id="原因-3thingsboard-30-版本编译遇到的问题">原因 3：Thingsboard 3.0 版本编译遇到的问题</h4>
<p>亲测：2.4 版本也可以通过这种方式来解决</p>
<pre><code class="language-shell">Failed to execute goal com.github.eirslett:frontend-maven-plugin:1.7.5:npm (npm install) on project ui-ngx: Failed to run task: 'npm install' failed. org.apache.commons.exec.ExecuteException: Process exited with an error: -4048 (Exit value: -4048) -&gt; [Help 1]
</code></pre>
<p>解决方案：https://www.iotschool.com/topics/84</p>
<h4 id="原因-4二次编译导致残留进程">原因 4：二次编译导致残留进程</h4>
<p>报错：</p>
<pre><code class="language-shell">[ERROR] Failed to execute goal org.apache.maven.plugins:maven-clean-plugin:2.5:clean (default-clean) on project ui: Failed to clean project: Failed to delete F:\workspace\thingsboard\thingsboard\ui\target\node\node.exe -&gt; [Help 1]
</code></pre>
<figure data-type="image" tabindex="12"><img src="https://tinaxiawuhao.github.io/post-images/1638433961674.png" alt="" loading="lazy"></figure>
<h3 id="server-tool-编译失败">Server Tool 编译失败</h3>
<figure data-type="image" tabindex="13"><img src="https://tinaxiawuhao.github.io/post-images/1638433985854.png" alt="" loading="lazy"></figure>
<pre><code class="language-shell">[ERROR] Failed to execute goal on project tools: Could not resolve dependencies for project org.thingsboard:tools:jar:2.4.3: Failed to collect dependencies at org.eclipse.paho:org.eclipse.paho.client.mqttv3:jar:1.1.0: Failed to read artifact descriptor for org.eclipse.paho:org.eclipse.paho.clien
t.mqttv3:jar:1.1.0: Could not transfer artifact org.eclipse.paho:org.eclipse.paho.client.mqttv3:pom:1.1.0 from/to aliyun_nexus (http://maven.aliyun.com/nexus/content/groups/public/): Failed to transfer file http://maven.aliyun.com/nexus/content/groups/public/org/eclipse/paho/org.eclipse.paho.cli
ent.mqttv3/1.1.0/org.eclipse.paho.client.mqttv3-1.1.0.pom with status code 502 -&gt; [Help 1]
</code></pre>
<p>一般由于网络原因，IoTSchool 小编至少编译了 3 次才成功，每次编译都重启电脑，并清理环境。</p>
<p>解决方案：如果使用的是 mvn clean install -DskipTests 命令进行编译，那么就多尝试几次，每次编译前，要清理环境。</p>
<p>参考：https://github.com/thingsboard/performance-tests/issues/10</p>
<h3 id="javascript-executor-编译失败">JavaScript Executor 编译失败</h3>
<p>JavaScript Executor Microservice 编译失败 <img src="https://tinaxiawuhao.github.io/post-images/1638434020950.png" alt="" loading="lazy"></p>
<pre><code class="language-shell">[ERROR] Failed to execute goal com.github.eirslett:frontend-maven-plugin:1.0:npm (npm install) on project js-executor: Failed to run task: 'npm install' failed. (error code 2) -&gt; [Help 1]
[ERROR]
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR]
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR]
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &lt;goals&gt; -rf :js-executor
</code></pre>
<p>原因：本地缓存缺少 fetched-v10.15.3-linux-x64 和 fetched-v10.15.3-win-x64 这两个文件。</p>
<p>解决方案： 步骤 1：下载这两个文件到本地，下载后记得重命名，下载地址：https://github.com/zeit/pkg-fetch/releases <img src="https://tinaxiawuhao.github.io/post-images/1638434130104.png" alt="" loading="lazy"></p>
<p>步骤 2: 将下载的两个文件放到：放到：C:\Users\你的用户名 \ .pkg-cache\v2.6。并将名字分别修改为：fetched-v10.15.3-linux-x64 和 fetched-v10.15.3-win-x64</p>
<p>参考：https://github.com/thingsboard/thingsboard/issues/2084</p>
<h3 id="license-检查不通过">License 检查不通过</h3>
<pre><code class="language-shell">[ERROR] Failed to execute goal com.mycila:license-maven-plugin:3.0:check (default) on project thingsboard: Some files do not have the expected license header -&gt; [Help 1]
</code></pre>
<p>解决方案：在根目录 pom.xml 中屏蔽 license-maven-plugin</p>
<figure data-type="image" tabindex="14"><img src="https://tinaxiawuhao.github.io/post-images/1638434154303.png" alt="" loading="lazy"></figure>
<p>搜索 license-maven-plugin，将整个 plugin 都注释掉 <img src="https://tinaxiawuhao.github.io/post-images/1638434302255.png" alt="" loading="lazy"></p>
<h3 id="web-ui-编译失败">Web UI 编译失败</h3>
<p>Web UI 编译失败请参考[Server UI 编译失败第一个原因](https://www.iotschool.com/wiki/tbinstall#Server Tool编译失败)</p>
<h3 id="mavencould-not-resolve-dependencies-for-project-orgthingsboardapplication">maven:Could not resolve dependencies for project org.thingsboard:application:</h3>
<p>错误信息</p>
<pre><code class="language-shell">[ERROR] Failed to execute goal on project application: Could not resolve dependencies for project org.thingsboard:application:jar:2.4.1: The following artifacts could not be resolved: org.thingsboard.rule-engine:rule-engine-components:jar:2.4.1, org.thingsboard:dao:jar:2.4.1: Could not find artifact org.thingsboard.rule-engine:rule-engine-components:jar:2.4.1 in jenkins (http://repo.jenkins-ci.org/releases) -&gt; [Help 1]
</code></pre>
<p>解决方案：根目录下去 maven 编译，不要在每个单独编译，否则不能自动解决依赖，如果你已经在子模块进行了编译，请回到根目录先 clean 一下，再重新编译。</p>
<h3 id="mavenfailed-to-delete-tb-http-transportrpm">maven:Failed to delete tb-http-transport.rpm</h3>
<p>错误信息：</p>
<pre><code class="language-shell">[ERROR] Failed to execute goal org.apache.maven.plugins:maven-clean-plugin:2.5:clean (default-clean) on project http: Failed to clean project: Failed to delete D:\my_project\thingsboard\transport\http\target\tb-http-transport.rpm -&gt; [Help 1]
</code></pre>
<p>解决方案：第一次编译失败，再次编译可能会提示该错误，可以手动到报错路径删除，如果提示文件正在使用，需要在任务管理器杀死 java 进程后再手动删除。</p>
<h3 id="npmnpmcb-never-called">npm:npm:cb() never called!</h3>
<p>错误信息：</p>
<pre><code class="language-shell">npm ERR! cb() never called!
npm ERR! This is an error with npm itself. Please report this error at:
npm ERR!     &lt;https://npm.community&gt;
npm ERR! A complete log of this run can be found in:
npm ERR!     C:\Users\yuren\AppData\Roaming\npm-cache\_logs\2019-11-06T10_55_28_258Z-debug.log
</code></pre>
<p>解决方案： 尝试 npm cache clean --force 后再次 npm install 无果； 尝试更换淘宝镜像源后再次 npm install 无果； 怀疑有些包下载需要翻墙，全局代理翻墙后问题依然存在； 参考网上关闭所有代理后问题依然存在； 通过 log 日志分析最后一个解包报错的地方，屏蔽需要的 material-design-icons，新 modules rxjs 仍然报错；</p>
<pre><code class="language-shell">extract material-design-icons@3.0.1 extracted to node_modules\.staging\material-design-icons-61b4d55e (72881ms)
extract rxjs@6.5.2 extracted to node_modules\.staging\rxjs-e901ba4c (24280ms)
</code></pre>
<p>参考 npm ERR cb() never called 执行</p>
<pre><code class="language-shell">npm install --no-package-lock
</code></pre>
<p>之后提示 npm ERR! path git，添加 git 到环境变量后正常。</p>
<h3 id="npmnpm-err-path-git">npm:npm ERR! path git</h3>
<p>错误信息</p>
<pre><code class="language-shell">npm ERR! path git
npm ERR! code ENOENT
npm ERR! errno ENOENT
npm ERR! syscall spawn git
npm ERR! enoent Error while executing:
npm ERR! enoent undefined ls-remote -h -t git://github.com/fabiobiondi/angular-
</code></pre>
<p>解决方案：添加 git 到环境变量。</p>
<h3 id="no-compiler-is-provided-in-this-environment">No compiler is provided in this environment</h3>
<p>错误信息：</p>
<pre><code class="language-shell">[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.
1:compile (default-compile) on project netty-mqtt: Compilation failure
[ERROR] No compiler is provided in this environment. Perhaps you are running on
a JRE rather than a JDK?
</code></pre>
<p>需要在环境变量中设置 java，包含%JAVA_HOME%bin;%JAVA_HOME%lib;</p>
<h3 id="failed-to-execute-goal-orgthingsboardgradle-maven-plugin1010invoke-default-on-project-http-orggradletoolingbuildexception-could-not-execute-build-using-gradle-distribution-httpsservicesgradleorgdistributionsgradle-63-binzip">Failed to execute goal org.thingsboard:gradle-maven-plugin:1.0.10:invoke (default) on project http: org.gradle.tooling.BuildException: Could not execute build using Gradle distribution 'https://services.gradle.org/distributions/gradle-6.3-bin.zip'.</h3>
<h3 id="failed-to-execute-goal-orgapachemavenpluginsmaven-compiler-plugin381compile-default-compile-on-project-rest-client-compilation-failure">Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.8.1:compile (default-compile) on project rest-client: Compilation failure</h3>
<p>An unknown compilation problem occurred</p>
<p>这个问题主要是jdk版本跟项目不一致导致的，如果项目的版本是大于(不含！)3.2.1，则需要JDK11，反之JDK8</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Docker安装clickhouse]]></title>
        <id>https://tinaxiawuhao.github.io/post/BBgY7nkHa/</id>
        <link href="https://tinaxiawuhao.github.io/post/BBgY7nkHa/">
        </link>
        <updated>2021-11-30T05:45:31.000Z</updated>
        <content type="html"><![CDATA[<p>ClickHouse 很多大厂都在用，本篇主要使用Docker进行安装</p>
<h3 id="安装配置">安装配置</h3>
<p>创建目录并更改权限</p>
<pre><code class="language-shell">mkdir -p /app/cloud/clickhouse/data
mkdir -p /app/cloud/clickhouse/conf
mkdir -p /app/cloud/clickhouse/log

chmod -R 777 /app/cloud/clickhouse/data
chmod -R 777 /app/cloud/clickhouse/conf
chmod -R 777 /app/cloud/clickhouse/log
</code></pre>
<h3 id="拉取镜像">拉取镜像</h3>
<pre><code class="language-shell">docker pull yandex/clickhouse-server:20.3.5.21
docker pull yandex/clickhouse-client:20.3.5.21
</code></pre>
<p>查看 <a href="https://hub.docker.com/r/yandex/clickhouse-server/dockerfile">https://hub.docker.com/r/yandex/clickhouse-server/dockerfile</a> 文件，EXPOSE  9000  8123  9009 了三个端口</p>
<h3 id="创建临时容器">创建临时容器</h3>
<pre><code class="language-shell">docker run --rm -d --name=clickhouse-server --ulimit nofile=262144:262144 -p 8123:8123 -p 9009:9009 -p 9000:9000 yandex/clickhouse-server:20.3.5.21
</code></pre>
<h3 id="复制临时容器内配置文件到宿主机">复制临时容器内配置文件到宿主机</h3>
<pre><code class="language-shell">docker cp clickhouse-server:/etc/clickhouse-server/config.xml D:/clickhouse/conf/config.xml
docker cp clickhouse-server:/etc/clickhouse-server/users.xml D:/clickhouse/conf/users.xml
</code></pre>
<h3 id="停掉临时容器">停掉临时容器</h3>
<pre><code class="language-shell">docker stop clickhouse-server
</code></pre>
<h3 id="创建default账号密码">创建default账号密码</h3>
<pre><code class="language-shell">PASSWORD=$(base64 &lt; /dev/urandom | head -c8); echo &quot;$PASSWORD&quot;; echo -n &quot;$PASSWORD&quot; | sha256sum | tr -d '-'
</code></pre>
<pre><code class="language-shell">SEGByR98
211371f5bc54970907173acf6facb35f0acbc17913e1b71b814117667c01d96d
</code></pre>
<p>会输出明码和SHA256密码</p>
<h3 id="创建root账号密码">创建root账号密码</h3>
<pre><code class="language-shell">PASSWORD=$(base64 &lt; /dev/urandom | head -c8); echo &quot;$PASSWORD&quot;; echo -n &quot;$PASSWORD&quot; | sha256sum | tr -d '-'
</code></pre>
<pre><code class="language-shell">092j3AnV
35542ded44184b1b4b6cd621e052662578025b58b4187176a3ad2b9548c8356e
</code></pre>
<p>会输出明码和SHA256密码</p>
<p>修改 D:/clickhouse/conf/users.xml<br>
把default账号设为只读权限，并设置密码yandex--&gt;users--&gt;default--&gt;profile节点设为 <code>readonly</code> 注释掉 yandex--&gt;users--&gt;default--&gt;password 节点 新增  yandex--&gt;users--&gt;default--&gt;password_sha256_hex 节点，填入生成的密码</p>
<p>修改default账号</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot;?&gt;
&lt;yandex&gt;
    &lt;users&gt;
        &lt;default&gt;
            &lt;password_sha256_hex&gt;211371f5bc54970907173acf6facb35f0acbc17913e1b71b814117667c01d96d&lt;/password_sha256_hex&gt;
            &lt;networks incl=&quot;networks&quot; replace=&quot;replace&quot;&gt;
                &lt;ip&gt;::/0&lt;/ip&gt;
            &lt;/networks&gt;
            &lt;profile&gt;readonly&lt;/profile&gt;
            &lt;quota&gt;default&lt;/quota&gt;
        &lt;/default&gt;
	&lt;/users&gt;
&lt;/yandex&gt;
</code></pre>
<p>新增root账号</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot;?&gt;
&lt;yandex&gt;
    &lt;users&gt;
        &lt;root&gt;
                    &lt;password_sha256_hex&gt;35542ded44184b1b4b6cd621e052662578025b58b4187176a3ad2b9548c8356e&lt;/password_sha256_hex&gt;
             &lt;networks incl=&quot;networks&quot; replace=&quot;replace&quot;&gt;
                &lt;ip&gt;::/0&lt;/ip&gt;
            &lt;/networks&gt;
            &lt;profile&gt;default&lt;/profile&gt;
            &lt;quota&gt;default&lt;/quota&gt;
        &lt;/root&gt;
	&lt;/users&gt;
&lt;/yandex&gt;
</code></pre>
<h3 id="创建容器">创建容器</h3>
<pre><code class="language-shell">docker run -d --name=clickhouse-server -p 8123:8123 -p 9009:9009 -p 9000:9000 --ulimit nofile=262144:262144 -v D:/clickhouse/data:/var/lib/clickhouse:rw -v D:/clickhouse/conf/config.xml:/etc/clickhouse-server/config.xml -v D:/clickhouse/conf/users.xml:/etc/clickhouse-server/users.xml -v D:/clickhouse/log:/var/log/clickhouse-server:rw yandex/clickhouse-server
</code></pre>
<h3 id="操作">操作</h3>
<ol>
<li>docker exec -it docker-clickhouse /bin/bash 进入容器</li>
<li>clickhouse-client 进入clickhouse命令行</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[clickhouse安装]]></title>
        <id>https://tinaxiawuhao.github.io/post/r2VmiGgor/</id>
        <link href="https://tinaxiawuhao.github.io/post/r2VmiGgor/">
        </link>
        <updated>2021-11-30T01:50:16.000Z</updated>
        <content type="html"><![CDATA[<h1 id="1clickhouse的安装">1.ClickHouse的安装</h1>
<h2 id="11-准备工作">1.1    准备工作</h2>
<p>下载RPM包:</p>
<p><a href="https://repo.yandex.ru/clickhouse/rpm/stable/x86_64/">https://repo.yandex.ru/clickhouse/rpm/stable/x86_64/</a></p>
<p>下载完毕如下:</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1638237245375.png" alt="" loading="lazy"></figure>
<p>​</p>
<h3 id="111-确定防火墙处于关闭状态">1.1.1 确定防火墙处于关闭状态</h3>
<p>相关命令:</p>
<pre><code class="language-shell">sudo systemctl status firewalld

sudo systemctl start firewalld

sudo systemctl stop firewalld

sudo systemctl restart firewalld
</code></pre>
<h3 id="112-centos取消打开文件数限制">1.1.2 CentOS取消打开文件数限制</h3>
<p>Ø 在 /etc/security/limits.conf文件的末尾加入以下内容</p>
<pre><code class="language-shell">vim /etc/security/limits.conf

* soft nofile 65536
* hard nofile 65536
* soft nproc 131072
* hard nproc 131072
</code></pre>
<p>Ø 在/etc/security/limits.d/20-nproc.conf文件的末尾加入以下内容</p>
<pre><code class="language-shell">vim /etc/security/limits.d/20-nproc.conf

* soft nofile 65536
* hard nofile 65536
* soft nproc 131072
* hard nproc 131072
</code></pre>
<p>Ø 执行同步操作(同步到集群其他机器)</p>
<pre><code class="language-shell">xsync /etc/security/limits.conf
xsync /etc/security/limits.d/20-nproc.conf
</code></pre>
<h3 id="113-安装依赖">1.1.3 安装依赖</h3>
<pre><code class="language-shell">sudo yum install -y libtool
</code></pre>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1638237268510.png" alt="" loading="lazy"></figure>
<pre><code class="language-shell">sudo yum install -y *unixODBC*
</code></pre>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1638237282605.png" alt="" loading="lazy"></figure>
<p>同样在集群其他机器上执行以上操作</p>
<h3 id="114-centos取消selinux">1.1.4 CentOS取消SELINUX</h3>
<p>SELINUX(美国开源的linux安全增强功能)</p>
<p>Ø 修改/etc/selinux/config中的SELINUX=disabled</p>
<pre><code class="language-shell">sudo vim /etc/selinux/config

SELINUX=disabled
</code></pre>
<p>Ø 执行同步操作</p>
<pre><code class="language-shell">sudo /home/atguigu/bin/xsync /etc/selinux/config
</code></pre>
<p>Ø 重启三台服务器</p>
<h3 id="115-将安装文件同步到其他两个服务器">1.1.5 将安装文件同步到其他两个服务器</h3>
<h3 id="116-分别在三台机子上安装这4个rpm文件">1.1.6 分别在三台机子上安装这4个rpm文件</h3>
<pre><code class="language-shell">sudo rpm -ivh *.rpm(提前把四个*.rpm放在一个目录下)
</code></pre>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1638237307245.png" alt="" loading="lazy"></figure>
<pre><code class="language-shell">sudo rpm -qa|grep clickhouse查看安装情况
</code></pre>
<h3 id="117-修改配置文件">1.1.7 修改配置文件</h3>
<pre><code class="language-shell">vim /etc/clickhouse-server/config.xml
</code></pre>
<p>把 <strong>&lt;listen_host&gt;::&lt;/listen_host&gt;</strong> 的注释打开，这样的话才能让ClickHouse被除本机以外的服务器访问</p>
<pre><code class="language-shell">#分发配置文件

xsync /etc/clickhouse-server/config.xml
</code></pre>
<h3 id="118-启动server">1.1.8 启动Server</h3>
<pre><code class="language-shell">sudo systemctl start clickhouse-server
</code></pre>
<h3 id="119-三台机器上关闭开机自启">1.1.9 三台机器上关闭开机自启</h3>
<pre><code class="language-shell">systemctl disable clickhouse-server
</code></pre>
<h3 id="1110-使用client连接server">1.1.10    使用client连接server</h3>
<pre><code class="language-shell">clickhouse-client -m
</code></pre>
<p>Clickhouse常用端口号:</p>
<p><img src="https://tinaxiawuhao.github.io/post-images/1638237372637.png" alt="" loading="lazy"><br>
<img src="https://tinaxiawuhao.github.io/post-images/1638237379416.png" alt="" loading="lazy"><br>
<img src="https://tinaxiawuhao.github.io/post-images/1638237384947.png" alt="" loading="lazy"><br>
<img src="https://tinaxiawuhao.github.io/post-images/1638237390491.png" alt="" loading="lazy"></p>
<h1 id="第2章-副本">第2章  副本</h1>
<p>副本的目的主要是保障数据的高可用性，即使一台ClickHouse节点宕机，那么也可以从其他服务器获得相同的数据。</p>
<h2 id="21-副本写入流程">2.1    副本写入流程</h2>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1638237403217.png" alt="" loading="lazy"></figure>
<h2 id="22-配置步骤">2.2    配置步骤</h2>
<p>Ø 启动zookeeper集群</p>
<p>Ø 注意:服务器的hostname需要改成对应的ck101、ck102、ck103</p>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1638237417573.png" alt="" loading="lazy"></figure>
<p>Ø 在/etc/clickhouse-server/config.d目录下创建一个名为metrika.xml的配置文件,内容如下：</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot;?&gt;
&lt;yandex&gt;
	&lt;zookeeper-servers&gt;
		&lt;node index=&quot;1&quot;&gt;
			&lt;host&gt;ck101&lt;/host&gt;
			&lt;port&gt;2181&lt;/port&gt;
		&lt;/node&gt;
		&lt;node index=&quot;2&quot;&gt;
            &lt;host&gt;ck102&lt;/host&gt;
            &lt;port&gt;2181&lt;/port&gt;
        &lt;/node&gt;
        &lt;node index=&quot;3&quot;&gt;
            &lt;host&gt;ck103&lt;/host&gt;
            &lt;port&gt;2181&lt;/port&gt;
        &lt;/node&gt;
	&lt;/zookeeper-servers&gt;
&lt;/yandex&gt;
</code></pre>
<p>Ø 同步到另外两个机器上</p>
<pre><code class="language-shell">xsync /etc/clickhouse-server/config.d/metrika.xml
</code></pre>
<p>Ø 在 /etc/clickhouse-server/config.xml中增加</p>
<pre><code class="language-xml">&lt;zookeeper incl=&quot;zookeeper-servers&quot; optional=&quot;true&quot; /&gt;
&lt;include_from&gt;/etc/clickhouse-server/config.d/metrika.xml&lt;/include_from&gt;
</code></pre>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1638237432131.png" alt="" loading="lazy"></figure>
<p>Ø 同步到另外两个机器上</p>
<pre><code class="language-shell">xsync /etc/clickhouse-server/config.xml
</code></pre>
<p>Ø 分别在另外两个机器上启动ClickHouse服务</p>
<p>注意：因为修改了配置文件，如果以前启动了服务需要重启</p>
<pre><code class="language-shell">systemctl start clickhouse-server
</code></pre>
<p>Ø 在另外两个机器上分别建表</p>
<p><strong>副本只能同步数据，不能同步表结构，所以我们需要在每台机器上自己手动建表</strong></p>
<p>Ck101</p>
<pre><code class="language-sql">create table t_order_rep (
  id UInt32,
  sku_id String,
  total_amount Decimal(16,2),
  create_time Datetime
 ) engine =ReplicatedMergeTree('/clickhouse/table/01/t_order_rep','rep_102')
  partition by toYYYYMMDD(create_time)
  primary key (id)
  order by (id,sku_id);
</code></pre>
<p>Ck102</p>
<pre><code class="language-sql">create table t_order_rep (
  id UInt32,
  sku_id String,
  total_amount Decimal(16,2),
  create_time Datetime
 ) engine =ReplicatedMergeTree('/clickhouse/table/01/t_order_rep','rep_103')
  partition by toYYYYMMDD(create_time)
  primary key (id)
  order by (id,sku_id);
</code></pre>
<p>参数解释</p>
<p>ReplicatedMergeTree 中，</p>
<p><strong>第一个参数是</strong>分片的zk_path一般按照： /clickhouse/table/{shard}/{table_name} 的格式写，如果只有一个分片就写01即可。</p>
<p><strong>第二个参数是</strong>副本名称，相同的分片副本名称不能相同。</p>
<p>Ø 在ck101上执行insert语句</p>
<pre><code class="language-sql">insert into t_order_rep values
(101,'sku_001',1000.00,'2020-06-01 12:00:00'),
(102,'sku_002',2000.00,'2020-06-01 12:00:00'),
(103,'sku_004',2500.00,'2020-06-01 12:00:00'),
(104,'sku_002',2000.00,'2020-06-01 12:00:00'),
(105,'sku_003',600.00,'2020-06-02 12:00:00');
</code></pre>
<p>Ø 在<strong>ck102</strong>上执行select，可以查询出结果，说明副本配置正确</p>
<h1 id="第3章-分片集群">第3章  分片集群</h1>
<p>副本虽然能够提高数据的可用性，降低丢失风险，但是每台服务器实际上必须容纳全量数据，对数据的横向扩容没有解决。</p>
<p>要解决数据水平切分的问题，需要引入分片的概念。通过分片把一份完整的数据进行切分，不同的分片分布到不同的节点上，再通过Distributed表引擎把数据拼接起来一同使用。</p>
<p>Distributed表引擎本身不存储数据，有点类似于MyCat之于MySql，成为一种中间件，通过分布式逻辑表来写入、分发、路由来操作多台节点不同分片的分布式数据。</p>
<p>注意：ClickHouse的集群是表级别的，实际企业中，大部分做了高可用，但是没有用分片，避免降低查询性能以及操作集群的复杂性。</p>
<h2 id="31-集群写入流程3分片2副本共6个节点">3.1    集群写入流程（3分片2副本共6个节点）</h2>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1638237448353.png" alt="" loading="lazy"></figure>
<h2 id="32-集群读取流程3分片2副本共6个节点">3.2    集群读取流程（3分片2副本共6个节点）</h2>
<figure data-type="image" tabindex="9"><img src="https://tinaxiawuhao.github.io/post-images/1638237458923.png" alt="" loading="lazy"></figure>
<h2 id="33-配置三节点版本集群及副本">3.3    配置三节点版本集群及副本</h2>
<figure data-type="image" tabindex="10"><img src="https://tinaxiawuhao.github.io/post-images/1638237469738.png" alt="" loading="lazy"></figure>
<h3 id="331-集群及副本规划2个分片只有第一个分片有副本">3.3.1 集群及副本规划（2个分片，只有第一个分片有副本）</h3>
<table>
<thead>
<tr>
<th><strong>ck101</strong></th>
<th><strong>ck102</strong></th>
<th><strong>ck103</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><macros>  <shard>01</shard>    <replica>rep_1_1</replica>  </macros></td>
<td><macros>  <shard>01</shard>    <replica>rep_1_2</replica>  </macros></td>
<td><macros>  <shard>02</shard>    <replica>rep_2_1</replica>  </macros></td>
</tr>
</tbody>
</table>
<h3 id="332-配置步骤">3.3.2 配置步骤</h3>
<h4 id="1-在ck101的etcclickhouse-serverconfigd目录下创建metrika-shardxml文件">(1) 在ck101的/etc/clickhouse-server/config.d目录下创建metrika-shard.xml文件</h4>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot;?&gt;
&lt;yandex&gt;
    &lt;remote_servers&gt;
        &lt;my_cluster&gt; &lt;!-- 集群名称--&gt; 
            &lt;shard&gt;     &lt;!--集群的第一个分片--&gt;
                &lt;internal_replication&gt;true&lt;/internal_replication&gt;
                &lt;replica&gt;  &lt;!--该分片的第一个副本--&gt;
                &lt;host&gt;ck101&lt;/host&gt;
                &lt;port&gt;9000&lt;/port&gt;
                &lt;/replica&gt;
                &lt;replica&gt;  &lt;!--该分片的第二个副本--&gt;
                &lt;host&gt;ck102&lt;/host&gt;
                &lt;port&gt;9000&lt;/port&gt;
                &lt;/replica&gt;
            &lt;/shard&gt;

            &lt;shard&gt; &lt;!--集群的第二个分片--&gt;
                &lt;internal_replication&gt;true&lt;/internal_replication&gt;
                &lt;replica&gt;  &lt;!--该分片的第一个副本--&gt;
                &lt;host&gt;ck103&lt;/host&gt;
                &lt;port&gt;9000&lt;/port&gt;
                &lt;/replica&gt;
            &lt;/shard&gt;
        &lt;/my_cluster&gt;
    &lt;/remote_servers&gt;

    &lt;zookeeper-servers&gt;
        &lt;node index=&quot;1&quot;&gt;
            &lt;host&gt; ck101&lt;/host&gt;
            &lt;port&gt;2181&lt;/port&gt;
        &lt;/node&gt;
        &lt;node index=&quot;2&quot;&gt;
            &lt;host&gt; ck102&lt;/host&gt;
            &lt;port&gt;2181&lt;/port&gt;
        &lt;/node&gt;
        &lt;node index=&quot;3&quot;&gt;
            &lt;host&gt; ck103&lt;/host&gt;
            &lt;port&gt;2181&lt;/port&gt;
        &lt;/node&gt;
    &lt;/zookeeper-servers&gt;

    &lt;macros&gt;
        &lt;shard&gt;01&lt;/shard&gt;  &lt;!--不同机器放的分片数不一样--&gt;
        &lt;replica&gt;rep_1_1&lt;/replica&gt; &lt;!--不同机器放的副本数不一样--&gt;
    &lt;/macros&gt;
&lt;/yandex&gt;
</code></pre>
<h4 id="2-将ck101的metrika-shardxml同步到102和103">(2) 将ck101的metrika-shard.xml同步到102和103</h4>
<pre><code class="language-shell">xsync /etc/clickhouse-server/config.d/metrika-shard.xml
</code></pre>
<h4 id="3-修改102和103中metrika-shardxml宏的配置">(3) 修改102和103中metrika-shard.xml宏的配置</h4>
<p>Ø <strong>102</strong></p>
<pre><code class="language-shell">vim /etc/clickhouse-server/config.d/metrika-shard.xml
</code></pre>
<figure data-type="image" tabindex="11"><img src="https://tinaxiawuhao.github.io/post-images/1638237484666.png" alt="" loading="lazy"></figure>
<p>Ø <strong>103</strong></p>
<pre><code class="language-shell">vim /etc/clickhouse-server/config.d/metrika-shard.xml
</code></pre>
<figure data-type="image" tabindex="12"><img src="https://tinaxiawuhao.github.io/post-images/1638237492998.png" alt="" loading="lazy"></figure>
<h4 id="4-在hadoop102上修改etcclickhouse-serverconfigxml">(4) 在hadoop102上修改/etc/clickhouse-server/config.xml</h4>
<figure data-type="image" tabindex="13"><img src="https://tinaxiawuhao.github.io/post-images/1638237502544.png" alt="" loading="lazy"></figure>
<h4 id="5-同步etcclickhouse-serverconfigxml到103和104">(5) 同步/etc/clickhouse-server/config.xml到103和104</h4>
<pre><code class="language-shell">sudo /home/atguigu/bin/xsync /etc/clickhouse-server/config.xml
</code></pre>
<h4 id="6-重启三台服务器上的clickhouse服务">(6) 重启三台服务器上的ClickHouse服务</h4>
<pre><code class="language-shell">systemctl stop clickhouse-server
systemctl start clickhouse-server
systemctl status clickhouse-server
</code></pre>
<h4 id="7-在ck101上执行建表语句">(7) 在ck101上执行建表语句</h4>
<p>Ø 会自动同步到ck102和ck103上</p>
<p>Ø 集群名字要和配置文件中的一致</p>
<p>Ø 分片和副本名称从配置文件的宏定义中获取</p>
<pre><code class="language-sql">create table st_order_mt on cluster my_cluster (
  id UInt32,
  sku_id String,
  total_amount Decimal(16,2),
  create_time Datetime
 ) engine =ReplicatedMergeTree('/clickhouse/tables/{shard}/st_order_mt','{replica}')
  partition by toYYYYMMDD(create_time)
  primary key (id)
  order by (id,sku_id);
</code></pre>
<p>可以到ck102和ck103上查看表是否创建成功</p>
<h4 id="8-在ck101上创建distribute-分布式表">(8) 在ck101上创建Distribute 分布式表</h4>
<pre><code class="language-sql">create table st_order_mt_all on cluster my_cluster
(
  id UInt32,
  sku_id String,
  total_amount Decimal(16,2),
  create_time Datetime
)engine = Distributed(my_cluster,default, st_order_mt,hiveHash(sku_id));
</code></pre>
<p><strong>参数含义</strong></p>
<p>​    Distributed(集群名称，库名，本地表名，分片键)</p>
<p>分片键必须是整型数字，所以用hiveHash函数转换，也可以rand()</p>
<h4 id="9-在ck101上插入测试数据">(9) 在ck101上插入测试数据</h4>
<pre><code class="language-sql">insert into st_order_mt_all values
(201,'sku_001',1000.00,'2020-06-01 12:00:00') ,
(202,'sku_002',2000.00,'2020-06-01 12:00:00'),
(203,'sku_004',2500.00,'2020-06-01 12:00:00'),
(204,'sku_002',2000.00,'2020-06-01 12:00:00'),
(205,'sku_003',600.00,'2020-06-02 12:00:00');
</code></pre>
<h4 id="10-通过查询分布式表和本地表观察输出结果">(10)   通过查询分布式表和本地表观察输出结果</h4>
<p>Ø <strong>分布式表</strong></p>
<pre><code class="language-sql">SELECT *  FROM st_order_mt_all;
</code></pre>
<p>Ø <strong>本地表</strong></p>
<pre><code class="language-sql">select * from st_order_mt;
</code></pre>
<p>Ø 观察数据的分布</p>
<table>
<thead>
<tr>
<th>st_order_mt_all</th>
<th><img src="https://tinaxiawuhao.github.io/post-images/1638237523851.png" alt="" loading="lazy"></th>
</tr>
</thead>
<tbody>
<tr>
<td>Ck101:  st_order_mt</td>
<td><img src="https://tinaxiawuhao.github.io/post-images/1638237534695.png" alt="" loading="lazy"></td>
</tr>
<tr>
<td>Ck102:  st_order_mt</td>
<td><img src="https://tinaxiawuhao.github.io/post-images/1638237544313.png" alt="" loading="lazy"></td>
</tr>
<tr>
<td>Ck103:  st_order_mt</td>
<td><img src="https://tinaxiawuhao.github.io/post-images/1638237554783.png" alt="" loading="lazy"></td>
</tr>
</tbody>
</table>
<h1 id="第4章-版本信息">第4章  版本信息</h1>
<p>Clickhouse: clickhouse-21.9.4.35</p>
<p>Zookeeper: zookeeper-3.4.6</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Kafka 架构深入]]></title>
        <id>https://tinaxiawuhao.github.io/post/KM-0yw6ab/</id>
        <link href="https://tinaxiawuhao.github.io/post/KM-0yw6ab/">
        </link>
        <updated>2021-11-01T05:59:18.000Z</updated>
        <content type="html"><![CDATA[<h2 id="31-kafka-工作流程及文件存储机制">3.1 Kafka 工作流程及文件存储机制</h2>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1635746429452.png" alt="" loading="lazy"></figure>
<p>Kafka 中消息是以 topic 进行分类的， 生产者生产消息，消费者消费消息，都是面向 <strong>topic</strong><br>
的。</p>
<p><strong>topic 是逻辑上的概念，而 partition 是物理上的概念</strong>，每个 partition 对应于一个 log 文件，该 log 文件中存储的就是 producer 生产的数据。 Producer 生产的数据会被不断追加到该 log 文件末端，且每条数据都有自己的 offset。 消费者组中的每个消费者， 都会实时记录自己消费到了哪个 offset，以便出错恢复时，从上次的位置继续消费 。</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1635746436346.png" alt="" loading="lazy"></figure>
<p>由于生产者生产的消息会不断追加到 log 文件末尾， 为防止 log 文件过大导致数据定位效率低下， Kafka 采取了分片和索引机制，将每个 partition 分为多个 segment。 每个 segment 对应两个文件——“.index”文件和“.log”文件。 这些文件位于一个文件夹下， 该文件夹的命名规则为： topic名称+分区序号。例如， first 这个 topic 有三个分区，则其对应的文件夹为 first-0,first-1,first-2。</p>
<pre><code class="language-java">00000000000000000000.index
00000000000000000000.log
00000000000000170410.index
00000000000000170410.log
00000000000000239430.index
00000000000000239430.log
</code></pre>
<p>index 和 log 文件以当前 segment 的第一条消息的 offset 命名。下图为 index 文件和 log文件的结构示意图。</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1635746443977.png" alt="" loading="lazy"></figure>
<p><strong>“.index”文件存储大量的索引信息，“.log”文件存储大量的数据</strong>，索引文件中的元数据指向对应数据文件中 message 的物理偏移地址。</p>
<h2 id="32-kafka-生产者">3.2 Kafka 生产者</h2>
<h3 id="321-分区策略">3.2.1 分区策略</h3>
<ol>
<li>
<p>分区的原因</p>
<p>（1） <strong>方便在集群中扩展</strong>，每个 Partition 可以通过调整以适应它所在的机器，而一个 topic<br>
又可以有多个 Partition 组成，因此整个集群就可以适应任意大小的数据了；<br>
（2） <strong>可以提高并发</strong>，因为可以以 Partition 为单位读写了。</p>
</li>
<li>
<p>分区的原则</p>
<p>我们需要将 producer 发送的数据封装成一个 <code>ProducerRecord</code> 对象。</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1635746457132.png" alt="" loading="lazy"></figure>
<p>（1） 指明 partition 的情况下，直接将指明的值直接作为 partiton 值；<br>
（2）没有指明 partition 值但有 key 的情况下，将 key 的 hash 值与 topic 的 partition<br>
数进行取余得到 partition 值；<br>
（3） 既没有 partition 值又没有 key 值的情况下，第一次调用时随机生成一个整数（后<br>
面每次调用在这个整数上自增），将这个值与 topic 可用的 partition 总数取余得到 partition<br>
值，也就是常说的 round-robin 算法。</p>
</li>
</ol>
<h3 id="322-数据可靠性保证">3.2.2 数据可靠性保证</h3>
<p>为保证 producer 发送的数据，能可靠的发送到指定的 topic， topic 的每个 partition 收到<br>
producer 发送的数据后， 都需要向 producer 发送 <strong>ack</strong>（acknowledgement 确认收到） ，如果<br>
producer 收到 ack， 就会进行下一轮的发送，否则重新发送数据。</p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1635746468488.png" alt="" loading="lazy"></figure>
<h4 id="1-副本数据同步策略">1） 副本数据同步策略</h4>
<table>
<thead>
<tr>
<th>方案</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody>
<tr>
<td>半数以上完成同步， 就发 送 ack</td>
<td>延迟低</td>
<td>选举新的 leader 时， 容忍 n 台 节点的故障，需要 2n+1 个副 本</td>
</tr>
<tr>
<td>全部完成同步，才发送 ack</td>
<td>选举新的 leader 时， 容忍 n 台 节点的故障，需要 n+1 个副 本</td>
<td>延迟高</td>
</tr>
</tbody>
</table>
<p>Kafka 选择了<strong>第二种方案</strong>，原因如下：</p>
<ol>
<li>同样为了容忍 n 台节点的故障，第一种方案需要 2n+1 个副本，而第二种方案只需要 n+1<br>
个副本，而 Kafka 的每个分区都有大量的数据， 第一种方案会造成大量数据的冗余。</li>
<li>虽然第二种方案的网络延迟会比较高，但网络延迟对 Kafka 的影响较小。</li>
</ol>
<h4 id="2-isr">2） ISR</h4>
<p>采用第二种方案之后，设想以下情景： leader 收到数据，所有 follower 都开始同步数据，<br>
但有一个 follower，因为某种故障，迟迟不能与 leader 进行同步，那 leader 就要一直等下去，<br>
直到它完成同步，才能发送 ack。这个问题怎么解决呢？</p>
<p>Leader 维护了一个动态的 in-sync replica set (ISR)，意为和 leader 保持同步的 follower 集<br>
合。当 ISR 中的 follower 完成数据的同步之后， leader 就会给 follower 发送 ack。如果 follower<br>
长 时 间 未 向 leader 同 步 数 据 ， 则 该 follower 将 被 踢 出 ISR ， 该 时 间 阈 值 由<code>replica.lag.time.max.ms</code> 参数设定。 Leader 发生故障之后，就会从 ISR 中选举新的 leader。</p>
<h4 id="3-ack-应答机制">3） ack 应答机制</h4>
<p>对于某些不太重要的数据，对数据的可靠性要求不是很高，能够容忍数据的少量丢失，<br>
所以没必要等 ISR 中的 follower 全部接收成功。</p>
<p>所以 Kafka 为用户提供了三种可靠性级别，用户根据对可靠性和延迟的要求进行权衡，<br>
选择以下的配置。</p>
<p><strong>acks 参数配置</strong>：</p>
<p>acks：</p>
<p><code>0</code>： producer 不等待 broker 的 ack，这一操作提供了一个最低的延迟， broker 一接收到还<br>
没有写入磁盘就已经返回，当 broker 故障时有可能<strong>丢失数据</strong>；</p>
<p><code>1</code>： producer 等待 broker 的 ack， partition 的 leader 落盘成功后返回 ack，如果在 follower<br>
同步成功之前 leader 故障，那么将会<strong>丢失数据</strong>；</p>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1635746480264.png" alt="" loading="lazy"></figure>
<p><code>-1</code>（all） ： producer 等待 broker 的 ack， partition 的 leader 和 follower 全部落盘成功后才<br>
返回 ack。但是如果在 follower 同步完成后， broker 发送 ack 之前， leader 发生故障，那么会<br>
造成<strong>数据重复</strong>。</p>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1635746490157.png" alt="" loading="lazy"></figure>
<h4 id="4-故障处理细节">4） 故障处理细节</h4>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1635746502677.png" alt="" loading="lazy"></figure>
<p><code>LEO</code>：指的是每个副本最大的 offset；<br>
<code>HW</code>：指的是消费者能见到的最大的 offset， ISR 队列中最小的 LEO。</p>
<p>（1） follower 故障</p>
<p>follower 发生故障后会被临时踢出 ISR，待该 follower 恢复后， follower 会读取本地磁盘记录的上次的 HW，并将 log 文件高于 HW 的部分截取掉，从 HW 开始向 leader 进行同步。等该 <strong>follower 的 LEO 大于等于该 Partition 的 HW</strong>，即 follower 追上 leader 之后，就可以重新加入 ISR 了。</p>
<p>（2） leader 故障</p>
<p>leader 发生故障之后，会从 ISR 中选出一个新的 leader，之后，为保证多个副本之间的 数据一致性， 其余的 follower 会先将各自的 log 文件<strong>高于 HW 的部分截掉</strong>，然后从新的 leader同步数据。</p>
<p><strong>注意</strong>： 这只能保证副本之间的数据一致性，并不能保证数据不丢失或者不重复。</p>
<h3 id="323-exactly-once-语义">3.2.3 Exactly Once 语义</h3>
<p>将服务器的 ACK 级别设置为<code>-1</code>，可以保证 Producer 到 Server 之间不会丢失数据，即 <code>At</code><br>
<code>Least Once</code> 语义。相对的，将服务器 ACK 级别设置为 <code>0</code>，可以保证生产者每条消息只会被<br>
发送一次，即 <code>At Most Once</code> 语义。</p>
<p>At Least Once 可以保证数据不丢失，但是不能保证数据不重复；相对的， At Most Once<br>
可以保证数据不重复，但是不能保证数据不丢失。 但是，对于一些非常重要的信息，比如说<br>
交易数据，下游数据消费者要求数据既不重复也不丢失，即 <code>Exactly Once</code> 语义。 在 0.11 版<br>
本以前的 Kafka，对此是无能为力的，只能保证数据不丢失，再在下游消费者对数据做全局<br>
去重。对于多个下游应用的情况，每个都需要单独做全局去重，这就对性能造成了很大影响。<br>
0.11 版本的 Kafka，引入了一项重大特性：<strong>幂等性</strong>。所谓的幂等性就是指 Producer 不论向 Server 发送多少次重复数据， Server 端都只会持久化一条。幂等性结合 At Least Once 语义，就构成了 Kafka 的 Exactly Once 语义。即：</p>
<pre><code>At Least Once + 幂等性 = Exactly Once
</code></pre>
<p>要启用幂等性，只需要将 Producer 的参数中 <code>enable.idompotence</code> 设置为 <code>true</code> 即可。 Kafka<br>
的幂等性实现其实就是将原来下游需要做的去重放在了数据上游。开启幂等性的 Producer 在<br>
初始化的时候会被分配一个 <code>PID</code>，发往同一 <code>Partition</code> 的消息会附带 <code>Sequence Number</code>。而<br>
Broker 端会对<code>&lt;PID, Partition, SeqNumber&gt;</code>做缓存，当具有相同主键的消息提交时， Broker 只<br>
会持久化一条。</p>
<p>但是 PID 重启就会变化，同时不同的 Partition 也具有不同主键，所以<strong>幂等性无法保证跨</strong><br>
<strong>分区跨会话的 Exactly Once</strong>。</p>
<h2 id="33-kafka-消费者">3.3 Kafka 消费者</h2>
<h3 id="331-消费方式">3.3.1 消费方式</h3>
<p><strong>consumer 采用 pull（拉） 模式从 broker 中读取数据</strong>。</p>
<p><strong>push（推）模式很难适应消费速率不同的消费者，因为消息发送速率是由 broker 决定的</strong>。<br>
它的目标是尽可能以最快速度传递消息，但是这样很容易造成 consumer 来不及处理消息， 典型的表现就是拒绝服务以及网络拥塞。而 pull 模式则可以根据 consumer 的消费能力以适<br>
当的速率消费消息。</p>
<p><strong>pull 模式不足之处是，如果 kafka 没有数据，消费者可能会陷入循环中， 一直返回空数</strong><br>
<strong>据</strong>。 针对这一点， Kafka 的消费者在消费数据时会传入一个时长参数 timeout，如果当前没有<br>
数据可供消费， consumer 会等待一段时间之后再返回，这段时长即为 timeout。</p>
<h3 id="332-分区分配策略">3.3.2 分区分配策略</h3>
<p>一个 consumer group 中有多个 consumer，一个 topic 有多个 partition，所以必然会涉及<br>
到 partition 的分配问题，即确定那个 partition 由哪个 consumer 来消费。</p>
<p>Kafka 有两种分配策略，一是 RoundRobin，一是 Range。</p>
<p>当消费者个数改变时，会用到分区分配策略</p>
<p>1） RoundRobin</p>
<p><code>RoundRobinAssignor</code>策略的原理是将消费组内所有消费者以及消费者所订阅的所有topic的partition按照字典序排序，然后通过轮询方式逐个将分区以此分配给每个消费者。<code>RoundRobinAssignor</code>策略对应的<code>partition.assignment.strategy</code>参数值为：<code>org.apache.kafka.clients.consumer.RoundRobinAssignor</code>。</p>
<p>使用RoundRobin策略有两个前提条件必须满足：</p>
<ol>
<li>同一个消费者组里面的所有消费者的num.streams（消费者消费线程数）必须相等；</li>
<li>每个消费者订阅的主题必须相同。</li>
</ol>
<p>所以这里假设前面提到的2个消费者的num.streams = 2。RoundRobin策略的工作原理：将所有主题的分区组成 TopicAndPartition 列表，然后对 TopicAndPartition 列表按照 hashCode 进行排序,在我们的例子里面，按照 hashCode 排序完的topic-partitions组依次为T1-5, T1-3, T1-0, T1-8, T1-2, T1-1, T1-4, T1-7, T1-6, T1-9，我们的消费者线程排序为C1-0, C1-1, C2-0, C2-1，最后分区分配的结果为：</p>
<pre><code class="language-java">C1-0 将消费 T1-5, T1-2, T1-6 分区；
C1-1 将消费 T1-3, T1-1, T1-9 分区；
C2-0 将消费 T1-0, T1-4 分区；
C2-1 将消费 T1-8, T1-7 分区；
</code></pre>
<p>2） <strong>Range（默认策略）</strong></p>
<p>Range是<strong>对每个Topic而言</strong>的（即一个Topic一个Topic分），首先对同一个Topic里面的分区按照序号进行排序，并对消费者按照字母顺序进行排序。然后用Partitions分区的个数除以消费者线程的总数来决定每个消费者线程消费几个分区。如果除不尽，那么前面几个消费者线程将会多消费一个分区。</p>
<p>假设n=分区数/消费者数量，m=分区数%消费者数量，那么前m个消费者每个分配n+1个分区，后面的（消费者数量-m）个消费者每个分配n个分区。</p>
<p>假如有10个分区，3个消费者线程，把分区按照序号排列0，1，2，3，4，5，6，7，8，9；消费者线程为C1-0，C2-0，C2-1，那么用partition数除以消费者线程的总数来决定每个消费者线程消费几个partition，如果除不尽，前面几个消费者将会多消费一个分区。在我们的例子里面，我们有10个分区，3个消费者线程，10/3 = 3，而且除除不尽，那么消费者线程C1-0将会多消费一个分区，所以最后分区分配的结果看起来是这样的：</p>
<pre><code class="language-java">C1-0：0，1，2，3
C2-0：4，5，6
C2-1：7，8，9
</code></pre>
<h3 id="333-offset-的维护">3.3.3 offset 的维护</h3>
<p>由于 consumer 在消费过程中可能会出现断电宕机等故障， consumer 恢复后，需要从故<br>
障前的位置的继续消费，所以 consumer 需要实时记录自己消费到了哪个 offset，以便故障恢<br>
复后继续消费。</p>
<figure data-type="image" tabindex="9"><img src="https://tinaxiawuhao.github.io/post-images/1635746518265.png" alt="" loading="lazy"></figure>
<p><strong>Kafka 0.9 版本之前， consumer 默认将 offset 保存在 Zookeeper 中，从 0.9 版本开始，</strong><br>
<strong>consumer 默认将 offset 保存在 Kafka 一个内置的 topic 中，该 topic 为__consumer_offsets。</strong></p>
<p>1）修改配置文件 consumer.properties</p>
<pre><code>exclude.internal.topics=false
</code></pre>
<p>2）读取 offset</p>
<p>0.11.0.0 之前版本:</p>
<pre><code>bin/kafka-console-consumer.sh --topic __consumer_offsets --zookeeper hadoop102:2181 --formatter &quot;kafka.coordinator.GroupMetadataManager\$OffsetsMessageFormatter&quot; --consumer.config config/consumer.properties --from-beginning
</code></pre>
<p>0.11.0.0 之后版本(含):</p>
<pre><code>bin/kafka-console-consumer.sh --topic __consumer_offsets --
zookeeper hadoop102:2181 --formatter
&quot;kafka.coordinator.group.GroupMetadataManager\$OffsetsMessageForm
atter&quot; --consumer.config config/consumer.properties --frombeginning
</code></pre>
<h3 id="334-消费者组案例">3.3.4 消费者组案例</h3>
<p>1） 需求：测试同一个消费者组中的消费者， 同一时刻只能有一个消费者消费。</p>
<p>2） 案例实操</p>
<p>（1）在 hadoop102、 hadoop103 上修改<code>/opt/module/kafka/config/consumer.properties</code> 配置<br>
文件中的 <code>group.id</code> 属性为任意组名。</p>
<pre><code>[atguigu@hadoop103 config]$ vi consumer.properties
group.id=atguigu
</code></pre>
<p>（2）在 hadoop102、 hadoop103 上分别启动消费者</p>
<pre><code>[atguigu@hadoop102 kafka]$ bin/kafka-console-consumer.sh \
--zookeeper hadoop102:2181 --topic first --consumer.config config/consumer.properties

[atguigu@hadoop103 kafka]$ bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic first --consumer.config config/consumer.properties
</code></pre>
<p>（3）在 hadoop104 上启动生产者</p>
<pre><code>[atguigu@hadoop104 kafka]$ bin/kafka-console-producer.sh \
--broker-list hadoop102:9092 --topic first
&gt;hello world
</code></pre>
<p>（4）查看 hadoop102 和 hadoop103 的接收者。</p>
<p>同一时刻消费组内只有一个消费者接收到消息。</p>
<h2 id="34-kafka-高效读写数据">3.4 Kafka 高效读写数据</h2>
<p>1）顺序写磁盘</p>
<p>Kafka 的 producer 生产数据，要写入到 log 文件中，写的过程是一直追加到文件末端，<br>
为顺序写。 官网有数据表明，同样的磁盘，顺序写能到 600M/s，而随机写只有 100K/s。这<br>
与磁盘的机械机构有关，顺序写之所以快，是因为其省去了大量磁头寻址的时间。</p>
<p>2）零复制技术</p>
<figure data-type="image" tabindex="10"><img src="https://tinaxiawuhao.github.io/post-images/1635746530028.png" alt="" loading="lazy"></figure>
<p>3）分布式</p>
<h2 id="35-zookeeper-在-kafka-中的作用">3.5 Zookeeper 在 Kafka 中的作用</h2>
<p>Kafka 集群中有一个 broker 会被选举为 Controller，负责管理集群 broker 的上下线，所有 topic 的分区副本分配和 leader 选举等工作。Controller 的管理工作都是依赖于 Zookeeper 的。</p>
<p>以下为 partition 的 leader 选举过程：</p>
<figure data-type="image" tabindex="11"><img src="https://tinaxiawuhao.github.io/post-images/1635746537395.png" alt="" loading="lazy"></figure>
<h2 id="36-kafka-事务">3.6 Kafka 事务</h2>
<p>Kafka 从 0.11 版本开始引入了事务支持。事务可以保证 Kafka 在 Exactly Once 语义的基<br>
础上，生产和消费可以跨分区和会话，要么全部成功，要么全部失败。</p>
<h3 id="361-producer-事务">3.6.1 Producer 事务</h3>
<p>为了实现跨分区跨会话的事务，需要引入一个全局唯一的 Transaction ID，并将 Producer<br>
获得的PID 和Transaction ID 绑定。这样当Producer 重启后就可以通过正在进行的 Transaction ID 获得原来的 PID。</p>
<p>为了管理 Transaction， Kafka 引入了一个新的组件 <strong>Transaction Coordinator</strong>。 Producer 就是通过和 Transaction Coordinator 交互获得 Transaction ID 对应的任务状态。 Transaction Coordinator 还负责将事务所有写入 Kafka 的一个内部 Topic，这样即使整个服务重启，由于事务状态得到保存，进行中的事务状态可以得到恢复，从而继续进行。</p>
<h3 id="362-consumer-事务">3.6.2 Consumer 事务</h3>
<p>上述事务机制主要是从 Producer 方面考虑，对于 Consumer 而言，事务的保证就会相对<br>
较弱，尤其时无法保证 Commit 的信息被精确消费。这是由于 Consumer 可以通过 offset 访<br>
问任意信息，而且不同的 Segment File 生命周期不同，同一事务的消息可能会出现重启后被<br>
删除的情况。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[kafka常用命令]]></title>
        <id>https://tinaxiawuhao.github.io/post/cvzf4T4Wn/</id>
        <link href="https://tinaxiawuhao.github.io/post/cvzf4T4Wn/">
        </link>
        <updated>2021-10-29T07:15:38.000Z</updated>
        <content type="html"><![CDATA[<h3 id="管理">管理</h3>
<pre><code class="language-shell">## 创建topic（4个分区，2个副本）
bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 2 --partitions 4 --topic test

### kafka版本 &gt;= 2.2
bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic test

## 分区扩容
### kafka版本 &lt; 2.2
bin/kafka-topics.sh --zookeeper localhost:2181 --alter --topic topic1 --partitions 2

### kafka版本 &gt;= 2.2
bin/kafka-topics.sh --bootstrap-server broker_host:port --alter --topic topic1 --partitions 2

## 删除topic
bin/kafka-topics.sh --zookeeper localhost:2181 --delete --topic test
</code></pre>
<h3 id="查询">查询</h3>
<pre><code class="language-shell">## 查询集群描述
bin/kafka-topics.sh --describe --zookeeper 127.0.0.1:2181

## 查询集群描述（新）
bin/kafka-topics.sh --bootstrap-server localhost:9092 --topic foo --describe

## topic列表查询
bin/kafka-topics.sh --zookeeper 127.0.0.1:2181 --list

## topic列表查询（支持0.9版本+）
bin/kafka-topics.sh --list --bootstrap-server localhost:9092

## 消费者列表查询（存储在zk中的）
bin/kafka-consumer-groups.sh --zookeeper localhost:2181 --list

## 消费者列表查询（支持0.9版本+）
bin/kafka-consumer-groups.sh --new-consumer --bootstrap-server localhost:9092 --list

## 消费者列表查询（支持0.10版本+）
bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list

## 显示某个消费组的消费详情（仅支持offset存储在zookeeper上的）
bin/kafka-run-class.sh kafka.tools.ConsumerOffsetChecker --zookeeper localhost:2181 --group test

## 显示某个消费组的消费详情（0.9版本 - 0.10.1.0 之前）
bin/kafka-consumer-groups.sh --new-consumer --bootstrap-server localhost:9092 --describe --group test-consumer-group

## 显示某个消费组的消费详情（0.10.1.0版本+）
bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group my-group
</code></pre>
<h3 id="发送和消费">发送和消费</h3>
<pre><code class="language-shell">## 生产者
bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test

## 消费者（已失效）
bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test

## 生产者（支持0.9版本+）
bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test --producer.config config/producer.properties

## 消费者（支持0.9版本+，已失效）
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --new-consumer --from-beginning --consumer.config config/consumer.properties

## 消费者（最新）
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning --consumer.config config/consumer.properties


## kafka-verifiable-consumer.sh（消费者事件，例如：offset提交等）
bin/kafka-verifiable-consumer.sh --broker-list localhost:9092 --topic test --group-id groupName

## 高级点的用法
bin/kafka-simple-consumer-shell.sh --brist localhost:9092 --topic test --partition 0 --offset 1234  --max-messages 10
</code></pre>
<h3 id="切换leader">切换leader</h3>
<pre><code class="language-shell">## kafka版本 &lt;= 2.4
bin/kafka-preferred-replica-election.sh --zookeeper zk_host:port/chroot

## kafka新版本
bin/kafka-preferred-replica-election.sh --bootstrap-server broker_host:port
</code></pre>
<h3 id="kafka自带压测命令">kafka自带压测命令</h3>
<pre><code class="language-shell">bin/kafka-producer-perf-test.sh --topic test --num-records 100 --record-size 1 --throughput 100  --producer-props bootstrap.servers=localhost:9092
</code></pre>
<h3 id="kafka持续发送消息">kafka持续发送消息</h3>
<p>持续发送消息到指定的topic中，且每条发送的消息都会有响应信息：</p>
<pre><code class="language-shell">kafka-verifiable-producer.sh --broker-list $(hostname -i):9092 --topic test --max-messages 100000
</code></pre>
<h3 id="zookeeper-shellsh">zookeeper-shell.sh</h3>
<p>如果kafka集群的zk配置了chroot路径，那么需要加上<code>/path</code>。</p>
<pre><code class="language-shell">bin/zookeeper-shell.sh localhost:2181[/path]
ls /brokers/ids
get /brokers/ids/0
</code></pre>
<h3 id="迁移分区">迁移分区</h3>
<ol>
<li>
<p>创建规则json</p>
<pre><code class="language-shell">cat &gt; increase-replication-factor.json &lt;&lt;EOF
{&quot;version&quot;:1, &quot;partitions&quot;:[
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:3,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:4,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:5,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:6,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:7,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:8,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:9,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:10,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:11,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:12,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:13,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:14,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:15,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:16,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:17,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:18,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:19,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:20,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:21,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:22,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:23,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:24,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:25,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:26,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:27,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:28,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:29,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:30,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:31,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:32,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:33,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:34,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:35,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:36,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:37,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:38,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:39,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:40,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:41,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:42,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:43,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:44,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:45,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:46,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:47,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:48,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:49,&quot;replicas&quot;:[0,1]}]
}
EOF
</code></pre>
</li>
<li>
<p>执行</p>
<pre><code class="language-shell">bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 --reassignment-json-file increase-replication-factor.json --execute
</code></pre>
</li>
<li>
<p>验证</p>
<pre><code class="language-shell">bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 --reassignment-json-file increase-replication-factor.json --verify
</code></pre>
</li>
</ol>
<h3 id="删除消费者组">删除消费者组</h3>
<p>查询消费者组列表：</p>
<pre><code class="language-shell">kafka-consumer-groups.sh --bootstrap-server 172.31.1.245:9092 --list
</code></pre>
<p>查询消费者组明细：</p>
<pre><code class="language-shell">kafka-consumer-groups.sh --bootstrap-server {Kafka instance connection address} --describe --group {consumer group name}
</code></pre>
<p>删除消费者组：</p>
<pre><code class="language-shell">kafka-consumer-groups.sh --bootstrap-server {Kafka instance connection address} --delete --group {consumer group name}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[zookeeper选举过程]]></title>
        <id>https://tinaxiawuhao.github.io/post/Rz0qPOGXr/</id>
        <link href="https://tinaxiawuhao.github.io/post/Rz0qPOGXr/">
        </link>
        <updated>2021-10-22T08:02:27.000Z</updated>
        <content type="html"><![CDATA[<h3 id="初始化选举">初始化选举</h3>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1634890367738.png" alt="" loading="lazy"></figure>
<h3 id="运行期间选举">运行期间选举</h3>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1634890194753.png" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ReentrantLock源码详解]]></title>
        <id>https://tinaxiawuhao.github.io/post/CxCcIUkNX/</id>
        <link href="https://tinaxiawuhao.github.io/post/CxCcIUkNX/">
        </link>
        <updated>2021-10-21T06:20:51.000Z</updated>
        <content type="html"><![CDATA[<p><code>ReentrantLock</code>重入锁，是实现Lock接口的一个类，也是在实际编程中使用频率很高的一个锁，支持重入性，表示能够对共享资源能够重复加锁，即当前线程获取该锁再次获取不会被阻塞。</p>
<p>ReentrantLock还支持公平锁和非公平锁两种方式。那么，要想完完全全的弄懂ReentrantLock的话，主要也就是ReentrantLock同步语义的学习：</p>
<ol>
<li>重入性的实现原理；</li>
<li>公平锁和非公平锁</li>
</ol>
<h3 id="reentrantlock源码解析">ReentrantLock源码解析</h3>
<h4 id="加锁">加锁</h4>
<pre><code class="language-java">//使用案例
class Bank{
      /**
       * volatile实现
       */
      private  int count=0;
      /**
       * 使用可重入锁
       */
      private Lock lock=new ReentrantLock();

      public void getCount(){
            System.out.println(&quot;账户余额为：&quot;+count);
      }
      /**
       * 同步方法实现存钱
       * @param money
       */
      public void save(int money){
            lock.lock();
            try {
                  count+=money;
                  System.out.println(System.currentTimeMillis()+&quot;存进：&quot;+money);
            } catch (Exception e) {
                  // TODO Auto-generated catch block
                  e.printStackTrace();
            }finally {
                  lock.unlock();//释放锁
            }
      }
      /**
       * 同步代码块实现取钱
       * @param money
       */
      public  void remove(int money){
            if (count-money&lt;0) {
                  System.err.println(&quot;余额不足。&quot;);
                  return;
            }
                lock.lock();
                  try {
                        count-=money;
                        System.err.println(System.currentTimeMillis()+&quot;取出：&quot;+money);
                  } catch (Exception e) {
                        // TODO Auto-generated catch block
                        e.printStackTrace();
                  }finally {
                        lock.unlock();
                  }

      }
}
</code></pre>
<pre><code class="language-java">	/**
     * Creates an instance of {@code ReentrantLock}.
     * This is equivalent to using {@code ReentrantLock(false)}.
     */
    public ReentrantLock() {
        sync = new NonfairSync();
    }

    /**
     * Creates an instance of {@code ReentrantLock} with the
     * given fairness policy.
     *
     * @param fair {@code true} if this lock should use a fair ordering policy
     */
    public ReentrantLock(boolean fair) {
        sync = fair ? new FairSync() : new NonfairSync();
    }
</code></pre>
<p>初始化默认使用非公平锁</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1634801159801.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1634801206315.png" alt="" loading="lazy"></figure>
<p>公平锁和非公平锁继承AbstractQueuedSynchronizer接口（抽象的队列式的同步器，AQS定义了一套多线程访问共享资源的同步器框架）</p>
<p>AQS框架</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1634801241636.png" alt="" loading="lazy"></figure>
<ul>
<li>NonfairSync的类继承关系<br>
<img src="https://tinaxiawuhao.github.io/post-images/1634801286878.png" alt="" loading="lazy"></li>
<li>FairSync的类继承关系<br>
<img src="https://tinaxiawuhao.github.io/post-images/1634801320830.png" alt="" loading="lazy"></li>
</ul>
<p>下面以非公平锁为例</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1634801531856.png" alt="" loading="lazy"></figure>
<pre><code class="language-java">/**
 * Performs lock.  Try immediate barge, backing up to normal
 * acquire on failure.
 */
//加锁流程真正意义上的入口
final void lock() {
    //以cas方式尝试将AQS中的state从0更新为1
    if (compareAndSetState(0, 1))
        setExclusiveOwnerThread(Thread.currentThread());//获取锁成功则将当前线程标记为持有锁的线程,然后直接返回
    else
        acquire(1);//获取锁失败则执行该方法
}

</code></pre>
<p>加锁时调用lock方法，首先判断AQS中的sate参数是否被标记,尝试以cas方式尝试将AQS中的state从0更新为1，成功将当前线程赋予AQS</p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1634801522921.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1634801553641.png" alt="" loading="lazy"></figure>
<p>失败则调用AQS类的acquire(1)方法</p>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1634801668520.png" alt="" loading="lazy"></figure>
<pre><code class="language-java">//非公平模式下尝试获取锁的方法
protected final boolean tryAcquire(int acquires) {
    return nonfairTryAcquire(acquires);
}
</code></pre>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1634801709991.png" alt="" loading="lazy"></figure>
<pre><code class="language-java">/**
 * Performs non-fair tryLock.  tryAcquire is implemented in
 * subclasses, but both need nonfair try for trylock method.
 */
final boolean nonfairTryAcquire(int acquires) {
    final Thread current = Thread.currentThread();//获取当前线程实例
    int c = getState();//获取state变量的值,即当前锁被重入的次数
    if (c == 0) {   //state为0,说明当前锁未被任何线程持有
        if (compareAndSetState(0, acquires)) { //以cas方式获取锁
            setExclusiveOwnerThread(current);  //将当前线程标记为持有锁的线程
            return true;//获取锁成功,非重入
        }
    }
    else if (current == getExclusiveOwnerThread()) { //当前线程就是持有锁的线程,说明该锁被重入了
        int nextc = c + acquires;//计算state变量要更新的值
        if (nextc &lt; 0) // overflow
            throw new Error(&quot;Maximum lock count exceeded&quot;);
        setState(nextc);//非同步方式更新state值
        return true;  //获取锁成功,重入
    }
    return false;     //走到这里说明尝试获取锁失败
}
</code></pre>
<p>这是非公平模式下获取锁的通用方法。它囊括了当前线程在尝试获取锁时的所有可能情况：</p>
<ul>
<li>1.当前锁未被任何线程持有(state=0),则以cas方式获取锁,若获取成功则设置exclusiveOwnerThread为当前线程,然后返回成功的结果；若cas失败,说明在得到state=0和cas获取锁之间有其他线程已经获取了锁,返回失败结果。</li>
<li>2.若锁已经被当前线程获取(state&gt;0,exclusiveOwnerThread为当前线程),则将锁的重入次数加1(state+1),然后返回成功结果。因为该线程之前已经获得了锁,所以这个累加操作不用同步。</li>
<li>3.若当前锁已经被其他线程持有(state&gt;0,exclusiveOwnerThread不为当前线程),则直接返回失败结果</li>
</ul>
<p>因为我们用state来统计锁被线程重入的次数,所以当前线程尝试获取锁的操作是否成功可以简化为:state值是否成功累加1,是则尝试获取锁成功,否则尝试获取锁失败。</p>
<p>其实这里还可以思考一个问题:nonfairTryAcquire已经实现了一个囊括所有可能情况的尝试获取锁的方式,为何在刚进入lock方法时还要通过compareAndSetState(0, 1)去获取锁,毕竟后者只有在锁未被任何线程持有时才能执行成功,我们完全可以把compareAndSetState(0, 1)去掉,对最后的结果不会有任何影响。这种在进行通用逻辑处理之前针对某些特殊情况提前进行处理的方式在后面还会看到,一个直观的想法就是它能提升性能，而代价是牺牲一定的代码简洁性。</p>
<p>退回到上层的acquire方法,</p>
<pre><code class="language-java">public final void acquire(int arg) {
    if (!tryAcquire(arg) &amp;&amp;  //当前线程尝试获取锁,若获取成功返回true,否则false
        acquireQueued(addWaiter(Node.EXCLUSIVE), arg))  //只有当前线程获取锁失败才会执行者这部分代码
        selfInterrupt();
}
</code></pre>
<p>tryAcquire(arg)返回成功,则说明当前线程成功获取了锁(第一次获取或者重入),由取反和&amp;&amp;可知,整个流程到这结束，只有当前线程获取锁失败才会执行后面的判断。先来看addWaiter(Node.EXCLUSIVE)部分,这部分代码描述了当线程获取锁失败时如何安全的加入同步等待队列。</p>
<p>这部分逻辑在addWaiter()方法中</p>
<pre><code class="language-java">/**
 * Creates and enqueues node for current thread and given mode.
 *
 * @param mode Node.EXCLUSIVE for exclusive, Node.SHARED for shared
 * @return the new node
 */
private Node addWaiter(Node mode) {
    Node node = new Node(Thread.currentThread(), mode);//首先创建一个新节点,并将当前线程实例封装在内部,mode这里为null
    // Try the fast path of enq; backup to full enq on failure
    Node pred = tail;
    if (pred != null) {
        node.prev = pred;
        if (compareAndSetTail(pred, node)) {
            pred.next = node;
            return node;
        }
    }
    enq(node);//入队的逻辑这里都有
    return node;
}
</code></pre>
<p>首先创建了一个新节点,并将当前线程实例封装在其内部,之后我们直接看enq(node)方法就可以了,中间这部分逻辑在enq(node)中都有,之所以加上这部分“重复代码”和尝试获取锁时的“重复代码”一样,对某些特殊情况<br>
进行提前处理,牺牲一定的代码可读性换取性能提升。</p>
<pre><code class="language-java">/**
 * Inserts node into queue, initializing if necessary. See picture above.
 * @param node the node to insert
 * @return node's predecessor
 */
private Node enq(final Node node) {
    for (;;) {
        Node t = tail;//t指向当前队列的最后一个节点,队列为空则为null
        if (t == null) { // Must initialize  //队列为空
            if (compareAndSetHead(new Node())) //构造新结点,CAS方式设置为队列首元素,当head==null时更新成功
                tail = head;//尾指针指向首结点
        } else {  //队列不为空
            node.prev = t;
            if (compareAndSetTail(t, node)) { //CAS将尾指针指向当前结点,当t(原来的尾指针)==tail(当前真实的尾指针)时执行成功
                t.next = node;    //原尾结点的next指针指向当前结点
                return t;
            }
        }
    }
}
</code></pre>
<p>这里有两个CAS操作:</p>
<ul>
<li>compareAndSetHead(new Node()),CAS方式更新head指针,仅当原值为null时更新成功</li>
</ul>
<pre><code class="language-java">/**
 * CAS head field. Used only by enq.
 */
private final boolean compareAndSetHead(Node update) {
    return unsafe.compareAndSwapObject(this, headOffset, null, update);
}
</code></pre>
<ul>
<li>compareAndSetTail(t, node),CAS方式更新tial指针,仅当原值为t时更新成功</li>
</ul>
<pre><code class="language-java">/**
 * CAS tail field. Used only by enq.
 */
private final boolean compareAndSetTail(Node expect, Node update) {
    return unsafe.compareAndSwapObject(this, tailOffset, expect, update);
}
</code></pre>
<p>外层的for循环保证了所有获取锁失败的线程经过失败重试后最后都能加入同步队列。因为AQS的同步队列是不带哨兵结点的,故当队列为空时要进行特殊处理,这部分在if分句中。注意当前线程所在的结点不能直接插入<br>
空队列,因为阻塞的线程是由前驱结点进行唤醒的。故先要插入一个结点作为队列首元素,当锁释放时由它来唤醒后面被阻塞的线程,从逻辑上这个队列首元素也可以表示当前正获取锁的线程,虽然并不一定真实持有其线程实例。</p>
<p>首先通过new Node()创建一个空结点，然后以CAS方式让头指针指向该结点(该结点并非当前线程所在的结点),若该操作成功,则将尾指针也指向该结点。这部分的操作流程可以用下图表示<br>
<img src="https://tinaxiawuhao.github.io/post-images/1634801748941.png" alt="" loading="lazy"></p>
<p>当队列不为空,则执行通用的入队逻辑,这部分在else分句中</p>
<pre><code class="language-java">else {  //队列不为空
    node.prev = t;
    if (compareAndSetTail(t, node)) { //CAS将尾指针指向当前结点,当t(原来的尾指针)==tail(当前真实的尾指针)时执行成功
        t.next = node;    //原尾结点的next指针指向当前结点
        return t;
    }
</code></pre>
<p>首先当前线程所在的结点的前向指针pre指向当前线程认为的尾结点,源码中用t表示。然后以CAS的方式将尾指针指向当前结点,该操作仅当tail=t,即尾指针在进行CAS前未改变时成功。若CAS执行成功,则将原尾结点的后向指针next指向新的尾结点。整个过程如下图所示</p>
<figure data-type="image" tabindex="9"><img src="https://tinaxiawuhao.github.io/post-images/1634801777081.png" alt="" loading="lazy"></figure>
<p>整个入队的过程并不复杂,是典型的CAS加失败重试的乐观锁策略。其中只有更新头指针和更新尾指针这两步进行了CAS同步,可以预见高并发场景下性能是非常好的。但是本着质疑精神我们不禁会思考下这么做真的线程安全吗？<br>
<img src="https://tinaxiawuhao.github.io/post-images/1634801800984.png" alt="" loading="lazy"></p>
<ul>
<li>1.队列为空的情况:<br>
因为队列为空,故head=tail=null,假设线程执行2成功,则在其执行3之前,因为tail=null,其他进入该方法的线程因为head不为null将在2处不停的失败,所以3即使没有同步也不会有线程安全问题。</li>
<li>2.队列不为空的情况:<br>
假设线程执行5成功,则此时4的操作必然也是正确的(当前结点的prev指针确实指向了队列尾结点,换句话说tail指针没有改变,如若不然5必然执行失败),又因为4执行成功,当前节点在队列中的次序已经确定了,所以6何时执行对线程安全不会有任何影响,比如下面这种情况</li>
</ul>
<figure data-type="image" tabindex="10"><img src="https://tinaxiawuhao.github.io/post-images/1634801836174.png" alt="" loading="lazy"></figure>
<p>为了确保真的理解了它,可以思考这个问题:把enq方法图中的4放到5之后,整个入队的过程还线程安全吗？</p>
<p>到这为止,获取锁失败的线程加入同步队列的逻辑就结束了。但是线程加入同步队列后会做什么我们并不清楚,这部分在acquireQueued方法中</p>
<figure data-type="image" tabindex="11"><img src="https://tinaxiawuhao.github.io/post-images/1634801857466.png" alt="" loading="lazy"></figure>
<p>acquireQueued方法的源码</p>
<pre><code class="language-java">/**
 * Acquires in exclusive uninterruptible mode for thread already in
 * queue. Used by condition wait methods as well as acquire.
 *
 * @param node the node
 * @param arg the acquire argument
 * @return {@code true} if interrupted while waiting
 */
final boolean acquireQueued(final Node node, int arg) {
    boolean failed = true;
    try {
        boolean interrupted = false;
        //死循环,正常情况下线程只有获得锁才能跳出循环
        for (;;) {
            final Node p = node.predecessor();//获得当前线程所在结点的前驱结点
            //第一个if分句
            if (p == head &amp;&amp; tryAcquire(arg)) { 
                setHead(node); //将当前结点设置为队列头结点
                p.next = null; // help GC
                failed = false;
                return interrupted;//正常情况下死循环唯一的出口
            }
            //第二个if分句
            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;  //判断是否要阻塞当前线程
                parkAndCheckInterrupt())      //阻塞当前线程
                interrupted = true;
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}
</code></pre>
<p>这段代码主要的内容都在for循环中,这是一个死循环,主要有两个if分句构成。第一个if分句中,当前线程首先会判断前驱结点是否是头结点,如果是则尝试获取锁,获取锁成功则会设置当前结点为头结点(更新头指针)。为什么必须前驱结点为头结点才尝试去获取锁？因为头结点表示当前正占有锁的线程,正常情况下该线程释放锁后会通知后面结点中阻塞的线程,阻塞线程被唤醒后去获取锁,这是我们希望看到的。然而还有一种情况,就是前驱结点取消了等待,此时当前线程也会被唤醒,这时候就不应该去获取锁,而是往前回溯一直找到一个没有取消等待的结点,然后将自身连接在它后面。一旦我们成功获取了锁并成功将自身设置为头结点,就会跳出for循环。否则就会执行第二个if分句:确保前驱结点的状态为SIGNAL,然后阻塞当前线程。</p>
<p>先来看shouldParkAfterFailedAcquire(p, node)，从方法名上我们可以大概猜出这是判断是否要阻塞当前线程的,方法内容如下</p>
<pre><code class="language-java">/**
 * Checks and updates status for a node that failed to acquire.
 * Returns true if thread should block. This is the main signal
 * control in all acquire loops.  Requires that pred == node.prev.
 *
 * @param pred node's predecessor holding status
 * @param node the node
 * @return {@code true} if thread should block
 */
private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) {
    int ws = pred.waitStatus;
    if (ws == Node.SIGNAL) //状态为SIGNAL

        /*
         * This node has already set status asking a release
         * to signal it, so it can safely park.
         */
        return true;
    if (ws &gt; 0) { //状态为CANCELLED,
        /*
         * Predecessor was cancelled. Skip over predecessors and
         * indicate retry.
         */
        do {
            node.prev = pred = pred.prev;
        } while (pred.waitStatus &gt; 0);
        pred.next = node;
    } else { //状态为初始化状态(ReentrentLock语境下)
        /*
         * waitStatus must be 0 or PROPAGATE.  Indicate that we
         * need a signal, but don't park yet.  Caller will need to
         * retry to make sure it cannot acquire before parking.
         */
        compareAndSetWaitStatus(pred, ws, Node.SIGNAL);
    }
    return false;
}
</code></pre>
<p>可以看到针对前驱结点pred的状态会进行不同的处理</p>
<ul>
<li>1.pred状态为SIGNAL,则返回true,表示要阻塞当前线程。</li>
<li>2.pred状态为CANCELLED,则一直往队列头部回溯直到找到一个状态不为CANCELLED的结点,将当前节点node挂在这个结点的后面。</li>
<li>3.pred的状态为初始化状态,此时通过compareAndSetWaitStatus(pred, ws, Node.SIGNAL)方法将pred的状态改为SIGNAL。</li>
</ul>
<p>其实这个方法的含义很简单,就是确保当前结点的前驱结点的状态为SIGNAL,SIGNAL意味着线程释放锁后会唤醒后面阻塞的线程。毕竟,只有确保能够被唤醒，当前线程才能放心的阻塞。</p>
<p>但是要注意只有在前驱结点已经是SIGNAL状态后才会执行后面的方法立即阻塞,对应上面的第一种情况。其他两种情况则因为返回false而重新执行一遍<br>
for循环。这种延迟阻塞其实也是一种高并发场景下的优化,试想我如果在重新执行循环的时候成功获取了锁,是不是线程阻塞唤醒的开销就省了呢？</p>
<p>最后我们来看看阻塞线程的方法parkAndCheckInterrupt</p>
<p>shouldParkAfterFailedAcquire返回true表示应该阻塞当前线程,则会执行parkAndCheckInterrupt方法,这个方法比较简单,底层调用了LockSupport来阻塞当前线程,源码如下:</p>
<pre><code class="language-java">/**
 * Convenience method to park and then check if interrupted
 *
 * @return {@code true} if interrupted
 */
private final boolean parkAndCheckInterrupt() {
    LockSupport.park(this);
    return Thread.interrupted();
}
</code></pre>
<p>该方法内部通过调用LockSupport的park方法来阻塞当前线程</p>
<blockquote>
<p>LockSupport就是通过控制变量<code>_counter</code>来对线程阻塞唤醒进行控制的。原理有点类似于信号量机制。</p>
<ul>
<li>当调用<code>park()</code>方法时，会将_counter置为0，同时判断前值，小于1说明前面被<code>unpark</code>过,则直接退出，否则将使该线程阻塞。</li>
<li>当调用<code>unpark()</code>方法时，会将_counter置为1，同时判断前值，小于1会进行线程唤醒，否则直接退出。<br>
形象的理解，线程阻塞需要消耗凭证(permit)，这个凭证最多只有1个。当调用park方法时，如果有凭证，则会直接消耗掉这个凭证然后正常退出；但是如果没有凭证，就必须阻塞等待凭证可用；而unpark则相反，它会增加一个凭证，但凭证最多只能有1个。</li>
<li>为什么可以先唤醒线程后阻塞线程？<br>
因为unpark获得了一个凭证,之后调用park因为有凭证消费，故不会阻塞。</li>
<li>为什么唤醒两次后阻塞两次会阻塞线程。<br>
因为凭证的数量最多为1，连续调用两次unpark和调用一次unpark效果一样，只会增加一个凭证；而调用两次park却需要消费两个凭证。</li>
</ul>
</blockquote>
<p>下面通过一张流程图来说明线程从加入同步队列到成功获取锁的过程<br>
<img src="https://tinaxiawuhao.github.io/post-images/1634801891432.png" alt="" loading="lazy"></p>
<p>概括的说,线程在同步队列中会尝试获取锁,失败则被阻塞,被唤醒后会不停的重复这个过程,直到线程真正持有了锁,并将自身结点置于队列头部。</p>
<p>ReentrantLock非公平模式下的加锁流程如下<br>
<img src="https://tinaxiawuhao.github.io/post-images/1634801907228.png" alt="" loading="lazy"></p>
<h4 id="解锁">解锁</h4>
<p>解锁源码如下：</p>
<figure data-type="image" tabindex="12"><img src="https://tinaxiawuhao.github.io/post-images/1634801926669.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="13"><img src="https://tinaxiawuhao.github.io/post-images/1634801941512.png" alt="" loading="lazy"></figure>
<pre><code class="language-java">public void unlock() {
    sync.release(1);  
}
public final boolean release(int arg) {
    if (tryRelease(arg)) { //释放锁(state-1),若释放后锁可被其他线程获取(state=0),返回true
        Node h = head;
        //当前队列不为空且头结点状态不为初始化状态(0)   
        if (h != null &amp;&amp; h.waitStatus != 0)
            unparkSuccessor(h);  //唤醒同步队列中被阻塞的线程
        return true;
    }
    return false;
}
</code></pre>
<p>正确找到sync的实现类,找到真正的入口方法,主要内容都在一个if语句中,先看下判断条件tryRelease方法</p>
<figure data-type="image" tabindex="14"><img src="https://tinaxiawuhao.github.io/post-images/1634801958450.png" alt="" loading="lazy"></figure>
<pre><code class="language-java">protected final boolean tryRelease(int releases) {
    int c = getState() - releases; //计算待更新的state值
    if (Thread.currentThread() != getExclusiveOwnerThread())
        throw new IllegalMonitorStateException();
    boolean free = false;
    if (c == 0) { //待更新的state值为0,说明持有锁的线程未重入,一旦释放锁其他线程将能获取
        free = true; 
        setExclusiveOwnerThread(null);//清除锁的持有线程标记
    }
    setState(c);//更新state值
    return free;
}
</code></pre>
<p>tryRelease其实只是将线程持有锁的次数减1,即将state值减1,若减少后线程将完全释放锁(state值为0),则该方法将返回true,否则返回false。由于执行该方法的线程必然持有锁,故该方法不需要任何同步操作。<br>
若当前线程已经完全释放锁,即锁可被其他线程使用,则还应该唤醒后续等待线程。不过在此之前需要进行两个条件的判断：</p>
<ul>
<li>h!=null是为了防止队列为空,即没有任何线程处于等待队列中,那么也就不需要进行唤醒的操作</li>
<li>h.waitStatus != 0是为了防止队列中虽有线程,但该线程还未阻塞,由前面的分析知,线程在阻塞自己前必须设置前驱结点的状态为SIGNAL,否则它不会阻塞自己。</li>
</ul>
<p>接下来就是唤醒线程的操作,unparkSuccessor(h)源码如下</p>
<figure data-type="image" tabindex="15"><img src="https://tinaxiawuhao.github.io/post-images/1634801976600.png" alt="" loading="lazy"></figure>
<pre><code class="language-java">private void unparkSuccessor(Node node) {
    /*
     * If status is negative (i.e., possibly needing signal) try
     * to clear in anticipation of signalling.  It is OK if this
     * fails or if status is changed by waiting thread.
     */
    int ws = node.waitStatus;
    if (ws &lt; 0)
        compareAndSetWaitStatus(node, ws, 0);

    /*
     * Thread to unpark is held in successor, which is normally
     * just the next node.  But if cancelled or apparently null,
     * traverse backwards from tail to find the actual
     * non-cancelled successor.
     */
    Node s = node.next;
    if (s == null || s.waitStatus &gt; 0) {
        s = null;
        for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev)
            if (t.waitStatus &lt;= 0)
                s = t;
    }
    if (s != null)
        LockSupport.unpark(s.thread);
}
</code></pre>
<p>一般情况下只要唤醒后继结点的线程就行了,但是后继结点可能已经取消等待,所以从队列尾部往前回溯,找到离头结点最近的正常结点,并唤醒其线程。</p>
<p><strong>解锁流程源码总结</strong></p>
<figure data-type="image" tabindex="16"><img src="https://tinaxiawuhao.github.io/post-images/1634801989557.png" alt="" loading="lazy"></figure>
<h3 id="公平锁相比非公平锁的不同">公平锁相比非公平锁的不同</h3>
<p>公平锁模式下,对锁的获取有严格的条件限制。在同步队列有线程等待的情况下,所有线程在获取锁前必须先加入同步队列。队列中的线程按加入队列的先后次序获得锁。<br>
从公平锁加锁的入口开始,<br>
<img src="https://tinaxiawuhao.github.io/post-images/1634802000468.png" alt="" loading="lazy"></p>
<p>对比非公平锁,少了非重入式获取锁的方法,这是第一个不同点</p>
<p>接着看获取锁的通用方法tryAcquire(),该方法在线程未进入队列,加入队列阻塞前和阻塞后被唤醒时都会执行。<br>
<img src="https://tinaxiawuhao.github.io/post-images/1634802012961.png" alt="" loading="lazy"></p>
<p>在真正CAS获取锁之前加了判断,内容如下</p>
<pre><code class="language-java">public final boolean hasQueuedPredecessors() {
    // The correctness of this depends on head being initialized
    // before tail and on head.next being accurate if the current
    // thread is first in queue.
    Node t = tail; // Read fields in reverse initialization order
    Node h = head;
    Node s;
    return h != t &amp;&amp;
        ((s = h.next) == null || s.thread != Thread.currentThread());
}
</code></pre>
<p>从方法名我们就可知道这是判断队列中是否有优先级更高的等待线程,队列中哪个线程优先级最高？由于头结点是当前获取锁的线程,队列中的第二个结点代表的线程优先级最高。<br>
那么我们只要判断队列中第二个结点是否存在以及这个结点是否代表当前线程就行了。这里分了两种情况进行探讨:</p>
<ol>
<li>第二个结点已经完全插入,但是这个结点是否就是当前线程所在结点还未知,所以通过s.thread != Thread.currentThread()进行判断,如果为true,说明第二个结点代表其他线程。</li>
<li>第二个结点并未完全插入,我们知道结点入队一共分三步：</li>
</ol>
<ul>
<li>1.待插入结点的pre指针指向原尾结点</li>
<li>2.CAS更新尾指针</li>
<li>3.原尾结点的next指针指向新插入结点</li>
</ul>
<p>所以(s = h.next) == null 就是用来判断2刚执行成功但还未执行3这种情况的。这种情况第二个结点必然属于其他线程。<br>
以上两种情况都会使该方法返回true,即当前有优先级更高的线程在队列中等待,那么当前线程将不会执行CAS操作去获取锁,保证了线程获取锁的顺序与加入同步队列的顺序一致，很好的保证了公平性,但也增加了获取锁的成本。</p>
<h3 id="一些疑问的解答">一些疑问的解答</h3>
<h4 id="为什么基于fifo的同步队列可以实现非公平锁">为什么基于FIFO的同步队列可以实现非公平锁？</h4>
<p>由FIFO队列的特性知,先加入同步队列等待的线程会比后加入的线程更靠近队列的头部,那么它将比后者更早的被唤醒,它也就能更早的得到锁。从这个意义上,对于在同步队列中等待的线程而言,它们获得锁的顺序和加入同步队列的顺序一致，这显然是一种公平模式。然而,线程并非只有在加入队列后才有机会获得锁,哪怕同步队列中已有线程在等待,非公平锁的不公平之处就在于此。回看下非公平锁的加锁流程,线程在进入同步队列等待之前有两次抢占锁的机会:</p>
<ul>
<li>第一次是非重入式的获取锁,只有在当前锁未被任何线程占有(包括自身)时才能成功;</li>
<li>第二次是在进入同步队列前,包含所有情况的获取锁的方式。</li>
</ul>
<p>只有这两次获取锁都失败后,线程才会构造结点并加入同步队列等待。而线程释放锁时是先释放锁(修改state值),然后才唤醒后继结点的线程的。试想下这种情况,线程A已经释放锁,但还没来得及唤醒后继线程C,而这时另一个线程B刚好尝试获取锁,此时锁恰好不被任何线程持有,它将成功获取锁而不用加入队列等待。线程C被唤醒尝试获取锁,而此时锁已经被线程B抢占,故而其获取失败并继续在队列中等待。整个过程如下图所示<br>
<img src="https://tinaxiawuhao.github.io/post-images/1634802025981.png" alt="" loading="lazy"></p>
<p>如果以线程第一次尝试获取锁到最后成功获取锁的次序来看,非公平锁确实很不公平。因为在队列中等待很久的线程相比还未进入队列等待的线程并没有优先权,甚至竞争也处于劣势:在队列中的线程要等待其他线程唤醒,在获取锁之前还要检查前驱结点是否为头结点。在锁竞争激烈的情况下,在队列中等待的线程可能迟迟竞争不到锁。这也就非公平在高并发情况下会出现的饥饿问题。那我们再开发中为什么大多使用会导致饥饿的非公平锁？很简单,因为它性能好啊。</p>
<h4 id="为什么非公平锁性能好">为什么非公平锁性能好</h4>
<p>非公平锁对锁的竞争是抢占式的(队列中线程除外),线程在进入等待队列前可以进行两次尝试,这大大增加了获取锁的机会。这种好处体现在两个方面:</p>
<ul>
<li>1.线程不必加入等待队列就可以获得锁,不仅免去了构造结点并加入队列的繁琐操作,同时也节省了线程阻塞唤醒的开销,线程阻塞和唤醒涉及到线程上下文的切换和操作系统的系统调用,是非常耗时的。在高并发情况下,如果线程持有锁的时间非常短,短到线程入队阻塞的过程超过线程持有并释放锁的时间开销,那么这种抢占式特性对并发性能的提升会更加明显。</li>
<li>2.减少CAS竞争。如果线程必须要加入阻塞队列才能获取锁,那入队时CAS竞争将变得异常激烈,CAS操作虽然不会导致失败线程挂起,但不断失败重试导致的对CPU的浪费也不能忽视。除此之外,加锁流程中至少有两处通过将某些特殊情况提前来减少CAS操作的竞争,增加并发情况下的性能。一处就是获取锁时将非重入的情况提前,如下图所示<br>
<img src="https://tinaxiawuhao.github.io/post-images/1634802037809.png" alt="" loading="lazy"></li>
</ul>
<p>另一处就是入队的操作,将同步队列非空的情况提前处理<br>
<img src="https://tinaxiawuhao.github.io/post-images/1634802048793.png" alt="" loading="lazy"></p>
<p>这两部分的代码在之后的通用逻辑处理中都有,很显然属于重复代码,但因为避免了执行无意义的流程代码,比如for循环,获取同步状态等,高并发场景下也能减少CAS竞争失败的可能。</p>
<h3 id="读写锁reentrantreadwritelock">读写锁ReentrantReadWriteLock</h3>
<p>首先明确一下，不是说 ReentrantLock 不好，只是 ReentrantLock 某些时候有局限。如果使用 ReentrantLock，可能本身是为了防止线程 A 在写数据、线程 B 在读数据造成的数据不一致，但这样，如果线程 C 在读数据、线程 D 也在读数据，读数据是不会改变数据的，没有必要加锁，但是还是加锁了，降低了程序的性能。因为这个，才诞生了读写锁 ReadWriteLock。</p>
<p>ReadWriteLock 是一个读写锁接口，读写锁是用来提升并发程序性能的锁分离技术，ReentrantReadWriteLock 是 ReadWriteLock 接口的一个具体实现，实现了读写的分离，读锁是共享的，写锁是独占的，读和读之间不会互斥，读和写、写和读、写和写之间才会互斥，提升了读写的性能。</p>
<p>而读写锁有以下三个重要的特性：</p>
<p>（1）公平选择性：支持非公平（默认）和公平的锁获取方式，吞吐量还是非公平优于公平。</p>
<p>（2）重进入：读锁和写锁都支持线程重进入。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[netty零拷贝]]></title>
        <id>https://tinaxiawuhao.github.io/post/Ts_mpMa6r/</id>
        <link href="https://tinaxiawuhao.github.io/post/Ts_mpMa6r/">
        </link>
        <updated>2021-10-13T06:11:02.000Z</updated>
        <content type="html"><![CDATA[<p>零拷贝的应用程序要求内核（kernel）直接将数据从磁盘文件拷贝到套接字（Socket），而无须通过应用程序。零拷贝不仅提高了应用程序的性能，而且减少了内核和用户模式见上下文切换。</p>
<h3 id="数据传输传统方法">数据传输：传统方法</h3>
<p>从文件中读取数据，并将数据传输到网络上的另一个程序的场景：从下图可以看出，拷贝的操作需要4次用户模式和内核模式之间的上下文切换，而且在操作完成前数据被复制了4次。(DMA：直接内存拷贝)</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1634105723930.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1634105729894.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1634107211607.png" alt="" loading="lazy"></figure>
<p>从磁盘中copy放到一个内存buf中，然后将buf通过socket传输给用户,下面是伪代码实现：</p>
<p>read(file, tmp_buf, len);<br>
write(socket, tmp_buf, len);</p>
<p>从图中可以看出文件经历了4次copy过程：</p>
<p>1.首先，调用read方法，文件从user模式拷贝到了kernel模式；（用户模式-&gt;内核模式的上下文切换，在内部发送sys_read() 从文件中读取数据，存储到一个内核地址空间缓存区中）</p>
<p>2.之后CPU控制将kernel模式数据拷贝到user模式下；（内核模式-&gt; 用户模式的上下文切换，read()调用返回，数据被存储到用户地址空间的缓存区中）</p>
<p>3.调用write时候，先将user模式下的内容copy到kernel模式下的socket的buffer中（用户模式-&gt;内核模式，数据再次被放置在内核缓存区中，send（）套接字调用）</p>
<p>4.最后将kernel模式下的socket buffer的数据copy到网卡设备中；（send套接字调用返回）</p>
<p>从图中看2，3两次copy是多余的，数据从kernel模式到user模式走了一圈，浪费了2次copy。</p>
<h3 id="数据传输mmap-优化">数据传输：mmap 优化</h3>
<p>mmap 通过内存映射，将文件映射到内核缓冲区，同时，用户空间可以共享内核空间的数据。这样，在进行网络传输时，就可以减少内核空间到用户空间的拷贝次数。如下图：</p>
<figure data-type="image" tabindex="4"><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MjM2NTUzLWM1ZWEwMGI3OGUxYjkzZmQucG5n?x-oss-process=image/format,png" alt="mmap 流程" loading="lazy"></figure>
<p>如上图，user buffer 和 kernel buffer 共享 index.html。如果你想把硬盘的 index.html 传输到网络中，再也不用拷贝到用户空间，再从用户空间拷贝到 Socket 缓冲区。</p>
<p>现在，你只需要从内核缓冲区拷贝到 Socket 缓冲区即可，这将减少一次内存拷贝（从 4 次变成了 3 次），但不减少上下文切换次数。</p>
<h3 id="数据传输零拷贝方法">数据传输：零拷贝方法</h3>
<p>从传统的场景看，会注意到上图，第2次和第3次拷贝根本就是多余的。应用程序只是起到缓存数据被将传回到套接字的作用而已，别无他用。</p>
<p>应用程序使用zero-copy来请求kernel直接把disk的数据传输到socket中，而不是通过应用程序传输。zero-copy大大提高了应用程序的性能，并且减少了kernel和user模式的上下文切换。</p>
<p>数据可以直接从read buffer 读缓存区传输到套接字缓冲区，也就是省去了将操作系统的read buffer 拷贝到程序的buffer，以及从程序buffer拷贝到socket buffer的步骤，直接将read buffer拷贝到socket buffer。JDK NIO中的的<code>transferTo()</code> 方法就能够让您实现这个操作，这个实现依赖于操作系统底层的sendFile（）实现的：</p>
<pre><code class="language-java">public void transferTo(long position, long count, WritableByteChannel target);
</code></pre>
<p>底层调用sendFile方法：</p>
<pre><code class="language-java">#include &lt;sys/socket.h&gt;
ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);
</code></pre>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1634105775492.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1634105782639.png" alt="" loading="lazy"></figure>
<p>使用了zero-copy技术后，整个过程如下：</p>
<p>1.transferTo()方法使得文件的内容直接copy到了一个read buffer（kernel buffer）中</p>
<p>2.然后数据（kernel buffer）copy到socket buffer中</p>
<p>3.最后将socket buffer中的数据copy到网卡设备（protocol engine）中传输；</p>
<p>这个显然是一个伟大的进步：这里上下文切换从4次减少到2次，同时把数据copy的次数从4次降低到3次；</p>
<p><strong>但是这是zero-copy么，答案是否定的；</strong></p>
<p>linux 2.1 内核开始引入了sendfile函数，用于将文件通过socket传输。</p>
<pre><code class="language-java">sendfile(socket, file, len);
</code></pre>
<p>该函数通过一次调用完成了文件的传输。 该函数通过一次系统调用完成了文件的传输，减少了原来read/write方式的模式切换。此外更是减少了数据的copy，sendfile的详细过程如图：</p>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1634107245108.png" alt="" loading="lazy"></figure>
<p>通过sendfile传送文件只需要一次系统调用，当调用sendfile时：</p>
<p>1.首先通过DMA将数据从磁盘读取到kernel buffer中</p>
<p>2.然后将kernel buffer数据拷贝到socket buffer中</p>
<p>3.最后将socket buffer中的数据copy到网卡设备中（protocol buffer）发送；</p>
<p>sendfile与read/write模式相比，少了一次copy。但是从上述过程中发现从kernel buffer中将数据copy到socket buffer是没有必要的；</p>
<p>Linux2.4 内核对sendfile做了改进，如图：</p>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1634107253678.png" alt="" loading="lazy"></figure>
<p>改进后的处理过程如下：</p>
<ol>
<li>将文件拷贝到kernel buffer中；(DMA引擎将文件内容copy到内核缓存区)</li>
<li>向socket buffer中追加当前要发生的数据在kernel buffer中的位置和偏移量；</li>
<li>根据socket buffer中的位置和偏移量直接将kernel buffer的数据copy到网卡设备（protocol engine）中；</li>
</ol>
<p>从图中看到，linux 2.1内核中的 “<strong>数据被copy到socket buffe</strong>r”的动作，在Linux2.4 内核做了优化，取而代之的是只包含关于数据的位置和长度的信息的描述符被追加到了socket buffer 缓冲区中。<strong>DMA引擎直接把数据从内核缓冲区传输到协议引擎</strong>（protocol engine），从而消除了最后一次CPU copy。经过上述过程，数据只经过了2次copy就从磁盘传送出去了。这个才是真正的Zero-Copy(这里的零拷贝是针对kernel来讲的，数据在kernel模式下是Zero-Copy)。</p>
<p>正是Linux2.4的内核做了改进，Java中的TransferTo()实现了Zero-Copy,如下图：</p>
<figure data-type="image" tabindex="9"><img src="https://tinaxiawuhao.github.io/post-images/1634105813030.png" alt="" loading="lazy"></figure>
<p>Zero-Copy技术的使用场景有很多，比如Kafka, 又或者是Netty等，可以大大提升程序的性能。</p>
<p>首先我们说零拷贝，是从操作系统的角度来说的。因为内核缓冲区之间，没有数据是重复的（只有 kernel buffer 有一份数据，sendFile 2.1 版本实际上有 2 份数据，算不上零拷贝）。例如我们刚开始的例子，内核缓存区和 Socket 缓冲区的数据就是重复的。</p>
<p>而零拷贝不仅仅带来更少的数据复制，还能带来其他的性能优势，例如更少的上下文切换，更少的 CPU 缓存伪共享以及无 CPU 校验和计算。</p>
<p>mmap 和 sendFile 的区别。</p>
<ol>
<li>mmap 适合小数据量读写，sendFile 适合大文件传输。</li>
<li>mmap 需要 4 次上下文切换，3 次数据拷贝；sendFile 需要 3 次上下文切换，最少 2 次数据拷贝。</li>
<li>sendFile 可以利用 DMA 方式，减少 CPU 拷贝，mmap 则不能（必须从内核拷贝到 Socket 缓冲区）。</li>
</ol>
<p>在这个选择上：rocketMQ 在消费消息时，使用了 mmap。kafka 使用了 sendFile。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[netty异步任务调度 ( TaskQueue | ScheduleTaskQueue | SocketChannel 管理 )]]></title>
        <id>https://tinaxiawuhao.github.io/post/b3vVP1a3A/</id>
        <link href="https://tinaxiawuhao.github.io/post/b3vVP1a3A/">
        </link>
        <updated>2021-10-08T03:13:12.000Z</updated>
        <content type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1633676052562.jfif" alt="" loading="lazy"></figure>
<h3 id="一-任务队列">一、 任务队列</h3>
<p>任务队列的任务 Task 应用场景 :</p>
<ol>
<li>
<p>自定义任务 : 自己开发的任务 , 然后将该任务提交到任务队列中 ;</p>
</li>
<li>
<p>自定义定时任务 : 自己开发的任务 , 然后将该任务提交到任务队列中 , 同时可以指定任务的执行时间 ;</p>
</li>
<li>
<p>其它线程调度任务 : 上面的任务都是在当前的 NioEventLoop ( 反应器 Reactor 线程 ) 中的任务队列中排队执行 , 在其它线程中也可以调度本线程的 Channel 通道与该线程对应的客户端进行数据读写 ;</p>
</li>
</ol>
<h3 id="二-处理器-handler-同步异步操作">二、 处理器 Handler 同步异步操作</h3>
<p>在之前的 Netty 服务器与客户端项目中 , 用户自定义的 Handler 处理器 , 该处理器继承了 ChannelInboundHandlerAdapter 类 , 在重写的 public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception 方法中 , 执行的业务逻辑要注意以下两点 :</p>
<p><code>同步操作</code> : 如果在该业务逻辑中只执行一个短时间的操作 , 那么可以直接执行 ;<br>
<code>异步操作</code> : 如果在该业务逻辑中执行访问数据库 , 访问网络 , 读写本地文件 , 执行一系列复杂计算等耗时操作 , 肯定不能在该方法中处理 , 这样会阻塞整个线程 ; 正确的做法是将耗时的操作放入任务队列 TaskQueue , 异步执行 ;</p>
<p>在 ChannelInboundHandlerAdapter 的 channelRead 方法执行时 , 客户端与服务器端的反应器 Reactor 线程 NioEventLoop 是处于阻塞状态的 , 此时服务器端与客户端同时都处于阻塞状态 , 这样肯定不行 , 因为 NioEventLoop 需要为多个客户端服务 , 不能因为与单一客户端交互而产生阻塞 ;</p>
<h3 id="三-异步任务-用户自定义任务">三、 异步任务 ( 用户自定义任务 )</h3>
<ol>
<li>
<p>用户自定义任务流程 :</p>
<p>① 获取通道 : 首先获取 通道 Channel ;</p>
<p>② 获取线程 : 获取通道对应的 EventLoop 线程 , 就是 NioEventLoop , 该 NioEventLoop 中封装了任务队列 TaskQueue ;</p>
<p>③ 任务入队 : 向任务队列 TaskQueue 中放入异步任务 Runnable , 调用 NioEventLoop 线程的 execute 方法 , 即可将上述 Runnable 异步任务放入任务队列 TaskQueue ;</p>
</li>
<li>
<p>多任务执行 : 如果用户连续向任务队列中放入了多个任务 , NioEventLoop 会按照顺序先后执行这些任务 , 注意任务队列中的任务 是先后执行 , 不是同时执行 ;</p>
<p>顺序执行任务 ( 不是并发 ) : 任务队列任务执行机制是顺序执行的 ; 先执行第一个 , 执行完毕后 , 从任务队列中获取第二个任务 , 执行完毕之后 , 依次从任务队列中取出任务执行 , 前一个任务执行完毕后 , 才从任务队列中取出下一个任务执行 ;</p>
</li>
<li>
<p>代码示例 : 监听到客户端上传数据后 , channelRead 回调 , 执行 获取通道 -&gt; 获取线程 -&gt; 异步任务调度 流程 ;</p>
<pre><code class="language-java">/**
 * Handler 处理者, 是 NioEventLoop 线程中处理业务逻辑的类
 *
 * 继承 : 该业务逻辑处理者 ( Handler ) 必须继承 Netty 中的 ChannelInboundHandlerAdapter 类
 * 才可以设置给 NioEventLoop 线程
 *
 * 规范 : 该 Handler 类中需要按照业务逻辑处理规范进行开发
 */
public class ServerHandr extends ChannelInboundHandlerAdapter {

    /**
     * 读取数据 : 在服务器端读取客户端发送的数据
     * @param ctx
     *      通道处理者上下文对象 : 封装了 管道 ( Pipeline ) , 通道 ( Channel ), 客户端地址信息
     *      管道 ( Pipeline ) : 注重业务逻辑处理 , 可以关联很多 Handler
     *      通道 ( Channel ) : 注重数据读写
     * @param msg
     *      客户端上传的数据
     * @throws Exception
     */
    @Override
    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
        // 1 . 从 ChannelHandlerContext ctx 中获取通道
        Channel channel = ctx.channel();
        // 2 . 获取通道对应的事件循环
        EventLoop eventLoop = channel.eventLoop();
        // 3 . 在 Runnable 中用户自定义耗时操作, 异步执行该操作, 该操作不能阻塞在此处执行
        eventLoop.execute(new Runnable() {
            @Override
            public void run() {
                //执行耗时操作
            }
        });
    }
}
</code></pre>
</li>
</ol>
<h3 id="四-异步任务-用户自定义定时任务">四、 异步任务 ( 用户自定义定时任务 )</h3>
<ol>
<li>
<p>用户自定义定时任务 与 用户自定义任务流程基本类似 , 有以下两个不同之处 :</p>
<p><em>① 调度方法 :</em></p>
<p>定时异步任务使用 schedule 方法进行调度 ;<br>
普通异步任务使用 execute 方法进行调度 ;</p>
<p><em>② 任务队列 :</em></p>
<p>定时异步任务提交到 ScheduleTaskQueue 任务队列中 ;<br>
普通异步任务提交到 TaskQueue 任务队列中 ;</p>
</li>
<li>
<p>用户自定义定时任务流程 :</p>
<p>① 获取通道 : 首先获取 通道 Channel ;</p>
<p>② 获取线程 : 获取通道对应的 EventLoop 线程 , 就是 NioEventLoop , 该 NioEventLoop 中封装了任务队列 TaskQueue ;</p>
<p>③ 任务入队 : 向任务队列 ScheduleTaskQueue 中放入异步任务 Runnable , 调用 NioEventLoop 线程的 schedule 方法 , 即可将上述 Runnable 异步任务放入任务队列 ScheduleTaskQueue ;</p>
</li>
<li>
<p>代码示例 : 监听到客户端上传数据后 , channelRead 回调 , 执行 获取通道 -&gt; 获取线程 -&gt; 异步任务调度 流程 ;</p>
<pre><code class="language-java">/**
 * Handler 处理者, 是 NioEventLoop 线程中处理业务逻辑的类
 *
 * 继承 : 该业务逻辑处理者 ( Handler ) 必须继承 Netty 中的 ChannelInboundHandlerAdapter 类
 * 才可以设置给 NioEventLoop 线程
 *
 * 规范 : 该 Handler 类中需要按照业务逻辑处理规范进行开发
 */
public class ServerHandr extends ChannelInboundHandlerAdapter {

    /**
     * 读取数据 : 在服务器端读取客户端发送的数据
     * @param ctx
     *      通道处理者上下文对象 : 封装了 管道 ( Pipeline ) , 通道 ( Channel ), 客户端地址信息
     *      管道 ( Pipeline ) : 注重业务逻辑处理 , 可以关联很多 Handler
     *      通道 ( Channel ) : 注重数据读写
     * @param msg
     *      客户端上传的数据
     * @throws Exception
     */
    @Override
    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
        // 1 . 从 ChannelHandlerContext ctx 中获取通道
        Channel channel = ctx.channel();
        // 2 . 获取通道对应的事件循环
        EventLoop eventLoop = channel.eventLoop();
        // 3 . 在 Runnable 中用户自定义耗时操作, 异步执行该操作, 该操作不能阻塞在此处执行
        // schedule(Runnable command, long delay, TimeUnit unit)
        // Runnable command 参数 : 异步任务
        // long delay 参数 : 延迟执行时间
        // TimeUnit unit参数 : 延迟时间单位, 秒, 毫秒, 分钟
        eventLoop.schedule(new Runnable() {
            @Override
            public void run() {
                //执行耗时操作
            }
        }, 100, TimeUnit.MILLISECONDS);
    }
}
</code></pre>
</li>
</ol>
<h3 id="五-异步任务-其它线程向本线程调度任务">五、 异步任务 ( 其它线程向本线程调度任务 )</h3>
<ol>
<li>
<p>通过EventExecutorGroup线程池获取不同线程执行异步耗时任务</p>
</li>
<li>
<p>代码示例（一）</p>
<pre><code class="language-java">// 服务器启动对象, 需要为该对象配置各种参数
ServerBootstrap bootstrap = new ServerBootstrap();
// 添加线程组异步执行耗时任务
final EventExecutorGroup businessGroup = new DefaultEventExecutorGroup(16);
bootstrap.group(bossGroup, workerGroup) // 设置 主从 线程组 , 分别对应 主 Reactor 和 从 Reactor
        .channel(NioServerSocketChannel.class)  // 设置 NIO 网络套接字通道类型
        .option(ChannelOption.SO_BACKLOG, 128)  // 设置线程队列维护的连接个数
        .childOption(ChannelOption.SO_KEEPALIVE, true)  // 设置连接状态行为, 保持连接状态
        .childHandler(  // 为 WorkerGroup 线程池对应的 NioEventLoop 设置对应的事件 处理器 Handler
                new ChannelInitializer&lt;SocketChannel&gt;() {// 创建通道初始化对象
                    @Override
                    protected void initChannel(SocketChannel ch) throws Exception {
                        // 该方法在服务器与客户端连接建立成功后会回调
                        // 为 管道 Pipeline 设置处理器 Hanedler
                        ch.pipeline().addLast(businessGroup,new NettyServerHandler());
                    }
                }
        );
</code></pre>
</li>
<li>
<p>代码示例（二）</p>
<pre><code class="language-java">public class NettyServerHandler extends SimpleChannelInboundHandler&lt;Object&gt; {
	final EventExecutorGroup businessGroup = new DefaultEventExecutorGroup(16);

    @Override
    protected void channelRead0(ChannelHandlerContext ctx, Object obj) throws Exception {
       businessGroup.submit(new Callable&lt;Object&gt;() {
            @Override
            public Object call() throws Exception {
                //业务处理
                return null;
            }
        });
    }
}
</code></pre>
</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[netty_nio_Reactor模式]]></title>
        <id>https://tinaxiawuhao.github.io/post/wvy4g9Zbn/</id>
        <link href="https://tinaxiawuhao.github.io/post/wvy4g9Zbn/">
        </link>
        <updated>2021-09-30T02:14:42.000Z</updated>
        <content type="html"><![CDATA[<p>Reactor有三种模式：</p>
<ol>
<li>单reactor单线程工作原理图</li>
</ol>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1636082432432.jfif" alt="" loading="lazy"></figure>
<blockquote>
<p>dispatch与handler在同一个线程中处理. redis就是采用这种模式</p>
</blockquote>
<ol>
<li>单reactor多线程工作原理图</li>
</ol>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1632969385152.png" alt="" loading="lazy"></figure>
<blockquote>
<p>（1） reactor对象通过select监控客户端请求事件，收到事件后，通过dispatch进行分发</p>
</blockquote>
<blockquote>
<p>（2）如果建立连接请求，则由Acceptor通过accept处理连接请求，然后创建一个Handler对象处理完成连接后的各种事件</p>
</blockquote>
<blockquote>
<p>（3）如果不是连接请求，则由reactor分发调用连接对应的Handler来处理</p>
</blockquote>
<blockquote>
<p>（4）Handler只负责响应事件，不做具体的业务处理， 通过read读取数据后分发给后面的work线程池中的某个线程。</p>
</blockquote>
<blockquote>
<p>（5）work线程池会分配一个独立的线程完成真正的业务 ，并将处理完的业务结果返回给Handler</p>
</blockquote>
<blockquote>
<p>（6）Handler收到响应结果后，通过send将结果返回给client</p>
</blockquote>
<p>优点：</p>
<blockquote>
<p>（1） 可以充分利用多核cpu的处理能力</p>
</blockquote>
<blockquote>
<p>（2） 多线程数据共享和访问比较复杂 ，reactor处理了所有的事件监听和响应，而且是在单线程中运行，在高并发场景容易出现性能瓶颈</p>
</blockquote>
<ol start="3">
<li>主从reactor多线程工作原理图</li>
</ol>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1632969541257.png" alt="" loading="lazy"></figure>
<blockquote>
<p>（1）Reactor主线程MainReactor对象通过select监听连接事件，收到连接事件后，通过Acceptor处理连接事件</p>
</blockquote>
<blockquote>
<p>（2）当Acceptor处理连接事件后，MainReactor将连接分配给SubReactor,</p>
</blockquote>
<blockquote>
<p>（3）SubReactor将连接加入到连接监听队列进行监听，并创建Handler进行各种事件处理</p>
</blockquote>
<blockquote>
<p>（4）当有新的事件发生时， subreactor就会调用对应的handler处理，</p>
</blockquote>
<blockquote>
<p>（5）handler通过read读取数据后，分发给后面的worker线程处理</p>
</blockquote>
<blockquote>
<p>（6）worker线程池会分配独立的worker线程进行业务处理，并返回结果</p>
</blockquote>
<blockquote>
<p>（7）handler收到响应结果后，再通过send将结果返回给client</p>
</blockquote>
<p><img src="https://tinaxiawuhao.github.io/post-images/1632970988216.jpg" alt="" loading="lazy"><br>
<img src="https://tinaxiawuhao.github.io/post-images/1632970993792.jpg" alt="" loading="lazy"></p>
<p>实现Reactor模式我们需要实现以下几个类：</p>
<p><strong>InputSource:</strong> 外部输入类，用来表示需要reactor去处理的原始对象</p>
<p><strong>Event</strong>: reactor模式的事件类，可以理解为将输入原始对象根据不同状态包装成一个事件类，reactor模式里处理的斗士event事件对象</p>
<p><strong>EventType</strong>: 枚举类型表示事件的不同类型</p>
<p><strong>EventHandler</strong>: 处理事件的抽象类，里面包含了不同事件处理器的公共逻辑和公共对象</p>
<p><strong>AcceptEventHandler\ReadEventhandler等</strong>: 继承自EventHandler的具体事件处理器的实现类，一般根据事件不同的状态来定义不同的处理器</p>
<p><strong>Dispatcher</strong>: 事件分发器，整个reactor模式解决的主要问题就是在接收到任务后根据分发器快速进行分发给相应的事件处理器，不需要从开始状态就阻塞</p>
<p><strong>Selector</strong>: 事件轮循选择器，selector主要实现了轮循队列中的事件状态，取出当前能够处理的状态</p>
<p><strong>Acceptor</strong>:reactor的事件接收类，负责初始化selector和接收缓冲队列</p>
<p><strong>Server</strong>:负责启动reactor服务并启动相关服务接收请求</p>
<p><strong>InputSource.java</strong></p>
<pre><code class="language-java">import lombok.AllArgsConstructor;
import lombok.Data;

@Data
@AllArgsConstructor
public class InputSource {
    private final Object data;
    private final long id;
}
</code></pre>
<p><strong>Event.java</strong></p>
<pre><code class="language-java">import lombok.Getter;
import lombok.Setter;

@Getter
@Setter
public class Event {
    private InputSource source;
    private EventType type;
}
</code></pre>
<p><strong>EventType</strong></p>
<pre><code class="language-java">public enum EventType {
    ACCEPT,
    READ,
    WRITE;
}
</code></pre>
<p><strong>EventHandler.java</strong></p>
<pre><code class="language-java">@Getter
@Setter
public abstract class EventHandler {

    private InputSource source;
    public abstract void handle(Event event);
}
</code></pre>
<p><strong>AcceptEventHandler.java</strong></p>
<pre><code class="language-java">public class AcceptEventHandler extends EventHandler {
    private Selector selector;

    public AcceptEventHandler(Selector selector) {
        this.selector = selector;
    }

    @Override
    public void handle(Event event) {
        //处理Accept的event事件
        if (event.getType() == EventType.ACCEPT) {

            //TODO 处理ACCEPT状态的事件

            //将事件状态改为下一个READ状态，并放入selector的缓冲队列中
            Event readEvent = new Event();
            readEvent.setSource(event.getSource());
            readEvent.setType(EventType.READ);

            selector.addEvent(readEvent);
        }
    }
}
</code></pre>
<p><strong>Dispatcher.java</strong></p>
<pre><code class="language-java">import java.util.List;
import java.util.Map;
import java.util.concurrent.ConcurrentHashMap;

public class Dispatcher {
    //通过ConcurrentHashMap来维护不同事件处理器
    Map&lt;EventType, EventHandler&gt; eventHandlerMap = new ConcurrentHashMap&lt;EventType, EventHandler&gt;();
    //本例只维护一个selector负责事件选择，netty为了保证性能实现了多个selector来保证循环处理性能，不同事件加入不同的selector的事件缓冲队列
    Selector selector;

    Dispatcher(Selector selector) {
        this.selector = selector;
    }

    //在Dispatcher中注册eventHandler
    public void registEventHandler(EventType eventType, EventHandler eventHandler) {
        eventHandlerMap.put(eventType, eventHandler);

    }

    public void removeEventHandler(EventType eventType) {
        eventHandlerMap.remove(eventType);
    }

    public void handleEvents() {
        dispatch();
    }

    //此例只是实现了简单的事件分发给相应的处理器处理，例子中的处理器都是同步，在reactor模式的典型实现NIO中都是在handle异步处理，来保证非阻塞
    private void dispatch() {
        while (true) {
            List&lt;Event&gt; events = selector.select();

            for (Event event : events) {
                EventHandler eventHandler = eventHandlerMap.get(event.getType());
                eventHandler.handle(event);
            }
        }
    }
}
</code></pre>
<p><strong>Selector.java</strong></p>
<pre><code class="language-java">import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.BlockingQueue;
import java.util.concurrent.LinkedBlockingQueue;

public class Selector {
    //定义一个链表阻塞queue实现缓冲队列，用于保证线程安全
    private final BlockingQueue&lt;Event&gt; eventQueue = new LinkedBlockingQueue&lt;Event&gt;();
    //定义一个object用于synchronize方法块上锁
    private final Object lock = new Object();

    List&lt;Event&gt; select() {
        return select(0);
    }

    //
    List&lt;Event&gt; select(long timeout) {
        if (timeout &gt; 0) {
            if (eventQueue.isEmpty()) {
                synchronized (lock) {
                    if (eventQueue.isEmpty()) {
                        try {
                            lock.wait(timeout);
                        } catch (InterruptedException ignored) {
                        }
                    }
                }

            }
        }
        //TODO 例子中只是简单的将event列表全部返回，可以在此处增加业务逻辑，选出符合条件的event进行返回
        List&lt;Event&gt; events = new ArrayList&lt;Event&gt;();
        eventQueue.drainTo(events);
        return events;
    }

    public void addEvent(Event e) {
        //将event事件加入队列
        boolean success = eventQueue.offer(e);
        if (success) {
            synchronized (lock) {
                //如果有新增事件则对lock对象解锁
                lock.notify();
            }

        }
    }

}
</code></pre>
<p><strong>Acceptor.java</strong></p>
<pre><code class="language-java">import java.util.concurrent.BlockingQueue;
import java.util.concurrent.LinkedBlockingQueue;

public class Acceptor implements Runnable{
    private final int port; // server socket port
    private final Selector selector;

    // 代表 serversocket，通过LinkedBlockingQueue来模拟外部输入请求队列
    private final BlockingQueue&lt;InputSource&gt; sourceQueue = new LinkedBlockingQueue&lt;InputSource&gt;();

    Acceptor(Selector selector, int port) {
        this.selector = selector;
        this.port = port;
    }

    //外部有输入请求后，需要加入到请求队列中
    public void addNewConnection(InputSource source) {
        sourceQueue.offer(source);
    }

    public int getPort() {
        return this.port;
    }

    public void run() {
        while (true) {

            InputSource source = null;
            try {
                // 相当于 serversocket.accept()，接收输入请求，该例从请求队列中获取输入请求
                source = sourceQueue.take();
            } catch (InterruptedException e) {
                // ignore it;
            }

            //接收到InputSource后将接收到event设置type为ACCEPT，并将source赋值给event
            if (source != null) {
                Event acceptEvent = new Event();
                acceptEvent.setSource(source);
                acceptEvent.setType(EventType.ACCEPT);

                selector.addEvent(acceptEvent);
            }

        }
    }
}
</code></pre>
<p><strong>Server.java</strong></p>
<pre><code class="language-java">public class Server {
    Selector selector = new Selector();
    Dispatcher eventLooper = new Dispatcher(selector);
    Acceptor acceptor;

    Server(int port) {
        acceptor = new Acceptor(selector, port);
    }

    public void start() {
        eventLooper.registEventHandler(EventType.ACCEPT, new AcceptEventHandler(selector));
        new Thread(acceptor, &quot;Acceptor-&quot; + acceptor.getPort()).start();
        eventLooper.handleEvents();
    }
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[saiku自动对接kylin]]></title>
        <id>https://tinaxiawuhao.github.io/post/0wQHSTDWt/</id>
        <link href="https://tinaxiawuhao.github.io/post/0wQHSTDWt/">
        </link>
        <updated>2021-09-28T06:56:08.000Z</updated>
        <content type="html"><![CDATA[<p>saiku通过添加schema和datasource的形式管理对接入系统的数据源，然后提供界面作为直观的分析数据方式，界面产生mdx，由mondrian连接数据源，解析mdx和执行查询</p>
<p>kylin提供大规模数据的olap能力，通过saiku与kylin的对接，利用saiku的友好界面来很方面的查询</p>
<p>如上的整合，需要手动配置数据源，编写schema的操作，感觉比较繁琐，可以通过修改saiku的代码，到kylin中获取project和cube的各种信息，根据一定规则转换生成schema并作为数据源管理起来，这样就很直接将saiku与kylin无缝对接起来。</p>
<h3 id="代码案例">代码案例</h3>
<p><strong>saiku-wabapp</strong></p>
<pre><code class="language-xml">#saiku-beans.properties
sylin.user=ADMIN
sylin.password=ADMIN
sylin.cube.url=http://localhost:7070/kylin/api/cubes
sylin.cubedesc.url=http://localhost:7070/kylin/api/cube_desc
sylin.model.url=http://localhost:7070/kylin/api/model
sylin.url=localhost:7070
</code></pre>
<pre><code class="language-java">//saiku-beans.xml
 &lt;bean id=&quot;repositoryDsManager&quot; class=&quot;org.saiku.service.datasource.RepositoryDatasourceManager&quot; init-method=&quot;load&quot; destroy-method=&quot;unload&quot;&gt;
     &lt;!--aop:scoped-proxy/--&gt;
         ......
         &lt;property name=&quot;sylinUser&quot; value=&quot;${sylin.user}&quot;/&gt;
         &lt;property name=&quot;sylinPassWord&quot; value=&quot;${sylin.password}&quot;/&gt;
         &lt;property name=&quot;sylinCubeUrl&quot; value=&quot;${sylin.cube.url}&quot;/&gt;
         &lt;property name=&quot;sylinCubeDescUrl&quot; value=&quot;${sylin.cubedesc.url}&quot;/&gt;
         &lt;property name=&quot;sylinModelUrl&quot; value=&quot;${sylin.model.url}&quot;/&gt;
         &lt;property name=&quot;sylinUrl&quot; value=&quot;${sylin.url}&quot;/&gt;
 &lt;/bean&gt;
</code></pre>
<p><strong>saiku-service</strong></p>
<pre><code class="language-java">public class RepositoryDatasourceManager implements IDatasourceManager, ApplicationListener&lt;HttpSessionCreatedEvent&gt; {
	private String sylinUser;
    private String sylinPassWord;
    private String sylinCubeUrl;
    private String sylinCubeDescUrl;
    private String sylinModelUrl;
    private String sylinUrl;
    //get.set省略
    ......
    private void loadDatasources(Properties ext) {
        datasources.clear();

        List&lt;DataSource&gt; exporteddatasources = null;

        try {
            String result = execute(sylinCubeUrl);
            JSONArray ja = JSON.parseArray(result);
            for (int i = 0; i &lt; ja.size(); i++) {
                JSONObject js = JSONObject.parseObject(ja.getString(i));
                String newCubeName = js.getString(&quot;project&quot;) + &quot;#&quot; + js.getString(&quot;name&quot;);
                datasources.put(js.getString(&quot;name&quot;), getSaikuDatasource(newCubeName));
            }
        } catch (Exception e) {
            log.error(&quot;Failed add sylin cube to datasource&quot;, e);
            e.printStackTrace();
        }

       ......
    }
     private SaikuDatasource getSaikuDatasource(String datasourceName) throws Exception {
        if (datasourceName.contains(&quot;#&quot;)) {
            String cubeName = datasourceName.split(&quot;#&quot;)[1].trim();
            String cubeDescString = execute(sylinCubeDescUrl + &quot;/&quot; + cubeName);
            CubeDesc cubeDesc = OBJECT_MAPPER.readValue(JSON.parseArray(cubeDescString).getString(0), CubeDesc.class);
            //CubeDesc cubeDesc = JSONObject.parseObject(JSON.parseArray(cubeDescString).getString(0), CubeDesc.class);
            String modelName = cubeDesc.getModelName();
            String cubeModelString = execute(sylinModelUrl + &quot;/&quot; + modelName);
            DataModelDesc modelDesc = OBJECT_MAPPER.readValue(cubeModelString, DataModelDesc.class);
            //DataModelDesc modelDesc = JSONObject.parseObject(cubeModelString, DataModelDesc.class);
            if (cubeDesc != null &amp;&amp; modelDesc != null) {
                addSchema(SchemaUtil.createSchema(datasourceName, cubeDesc, modelDesc), &quot;/datasources/&quot; + datasourceName.replace(&quot;#&quot;, &quot;.&quot;) + &quot;.xml&quot;, datasourceName);
            }
            String project = new String();
            if (datasourceName.contains(&quot;#&quot;)) {
                project = datasourceName.split(&quot;#&quot;)[0].trim();
            } else {
                project = datasourceName;
            }

            Properties properties = new Properties();
            properties.put(&quot;location&quot;, &quot;jdbc:mondrian:Jdbc=jdbc:kylin://&quot; + sylinUrl + &quot;/&quot; + project + &quot;;JdbcDrivers=org.apache.kylin.jdbc.Driver&quot; + &quot;;Catalog=mondrian:///datasources/&quot; + datasourceName.replace(&quot;#&quot;, &quot;.&quot;) + &quot;.xml&quot;);
            properties.put(&quot;driver&quot;, &quot;mondrian.olap4j.MondrianOlap4jDriver&quot;);
            properties.put(&quot;username&quot;, sylinUser);
            properties.put(&quot;password&quot;, sylinPassWord);
            properties.put(&quot;security.enabled&quot;, false);
            properties.put(&quot;advanced&quot;, false);
            return new SaikuDatasource(cubeName, SaikuDatasource.Type.OLAP, properties);
        }
        return null;
    }

    private String execute(String url) throws URISyntaxException, IOException {
        int httpConnectionTimeoutMs = 30000;
        int httpSocketTimeoutMs = 120000;
        final HttpParams httpParams = new BasicHttpParams();
        final PoolingClientConnectionManager cm = new PoolingClientConnectionManager();
        HttpConnectionParams.setSoTimeout(httpParams, httpSocketTimeoutMs);
        HttpConnectionParams.setConnectionTimeout(httpParams, httpConnectionTimeoutMs);
        cm.setDefaultMaxPerRoute(20);
        cm.setMaxTotal(200);
        HttpGet get = newGet(url);
        get.setURI(new URI(url));
        DefaultHttpClient client = new DefaultHttpClient(cm, httpParams);
        if (sylinUser != null &amp;&amp; sylinPassWord != null) {
            CredentialsProvider provider = new BasicCredentialsProvider();
            UsernamePasswordCredentials credentials = new UsernamePasswordCredentials(sylinUser, sylinPassWord);
            provider.setCredentials(AuthScope.ANY, credentials);
            client.setCredentialsProvider(provider);
        }
        HttpResponse response = client.execute(get);
        if (response.getStatusLine().getStatusCode() != 200) {
            throw new IOException(&quot;Invalid response &quot; + response.getStatusLine().getStatusCode());
        }

        String result = getContent(response);
        return result;
    }

    private HttpGet newGet(String url) {
        HttpGet get = new HttpGet();
        addHttpHeaders(get);
        return get;
    }

    private void addHttpHeaders(HttpRequestBase method) {
        method.addHeader(&quot;Accept&quot;, &quot;application/json, text/plain, */*&quot;);
        method.addHeader(&quot;Content-Type&quot;, &quot;application/json&quot;);
        String basicAuth = DatatypeConverter
                .printBase64Binary((sylinUser + &quot;:&quot; + sylinPassWord).getBytes(StandardCharsets.UTF_8));
        method.addHeader(&quot;Authorization&quot;, &quot;Basic &quot; + basicAuth);
    }

    private String getContent(HttpResponse response) throws IOException {
        InputStreamReader reader = null;
        BufferedReader rd = null;
        StringBuffer result = new StringBuffer();
        try {
            reader = new InputStreamReader(response.getEntity().getContent(), StandardCharsets.UTF_8);
            rd = new BufferedReader(reader);
            String line = null;
            while ((line = rd.readLine()) != null) {
                result.append(line);
            }
        } finally {
            IOUtils.closeQuietly(reader);
            IOUtils.closeQuietly(rd);
        }
        return result.toString();
    }
}
</code></pre>
<p><strong>mondrian3.0语法工具类</strong></p>
<pre><code class="language-java">package org.saiku.service.util;

import org.apache.kylin.cube.model.CubeDesc;
import org.apache.kylin.cube.model.DimensionDesc;
import org.apache.kylin.metadata.model.*;

import java.util.*;

public class SchemaUtil1 {
    private static String newLine = &quot;\r\n&quot;;
    private static Set&lt;String&gt; aggSet = new HashSet&lt;String&gt;(){
        {
            add(&quot;sum&quot;);
            add(&quot;min&quot;);
            add(&quot;max&quot;);
            add(&quot;count&quot;);
            add(&quot;count_distinct&quot;);
        }

    };


    public static String createSchema(String dataSourceName, CubeDesc cubeDesc, DataModelDesc modelDesc) {
        StringBuffer sb = new StringBuffer();
        sb = appendSchema(sb, dataSourceName, cubeDesc, modelDesc);
        return sb.toString();
    }

    public static StringBuffer appendSchema(StringBuffer sb, String dataSourceName, CubeDesc cubeDesc, DataModelDesc modelDesc) {
        sb.append(&quot;&lt;?xml version='1.0'?&gt;&quot;).append(newLine)
                .append(&quot;&lt;Schema name='&quot; + dataSourceName.split(&quot;#&quot;)[0].trim()+&quot;'&gt;&quot;)
                .append(newLine);
        sb = appendCube(sb, dataSourceName, cubeDesc, modelDesc);
        sb.append(&quot;&lt;/Schema&gt;&quot;).append(newLine);
        return sb;
    }

    public static StringBuffer appendCube(StringBuffer sb, String cubeName, CubeDesc cubeDesc, DataModelDesc modelDesc) {
        sb.append(&quot;&lt;Cube name='&quot; + cubeName.split(&quot;#&quot;)[1] + &quot;'&gt;&quot;).append(newLine);
        sb.append(&quot;&lt;Table name='&quot;+dealTableName(modelDesc.getRootFactTableName())+&quot;'/&gt;&quot;).append(newLine);
        HashMap&lt;String,String&gt; aliasTableMap = new HashMap&lt;String,String&gt;();
        HashMap&lt;String,String&gt; aliasTableJoinMap = new HashMap&lt;String,String&gt;();
        aliasTableMap.put(dealTableName(modelDesc.getRootFactTableName()),dealTableName(modelDesc.getRootFactTableName()));
        for(JoinTableDesc joinTableDesc:modelDesc.getJoinTables()) {
            aliasTableMap.put(joinTableDesc.getAlias(),dealTableName(joinTableDesc.getTable()));
            if(joinTableDesc.getJoin().getPrimaryKey().length == 1){
                aliasTableJoinMap.put(dealTableName(joinTableDesc.getAlias()),joinTableDesc.getJoin().getPrimaryKey()[0].concat(&quot;#&quot;).concat(joinTableDesc.getJoin().getForeignKey()[0]));
            }
        }

        for(DimensionDesc dimensionDesc: cubeDesc.getDimensions()){
            // tableSet.add(dealTableName(dimensionDesc.getTable()));
            if(aliasTableMap.get(dealTableName(dimensionDesc.getTable())).equals(dealTableName(modelDesc.getRootFactTableName()))){
                sb.append(&quot;&lt;Dimension name='&quot;+dimensionDesc.getName()+&quot;'&gt;&quot;).append(newLine);
                sb.append(&quot;&lt;Hierarchy name='&quot;+dimensionDesc.getName()+&quot;' hasAll='true' allMemberName='All &quot;+dimensionDesc.getName()+&quot;'&gt;&quot;).append(newLine);

            }else if(aliasTableJoinMap.get(dealTableName(dimensionDesc.getTable()))==null){
                continue;
            } else if(aliasTableJoinMap.get(dealTableName(dimensionDesc.getTable()))!=null &amp;&amp; aliasTableJoinMap.get(dealTableName(dimensionDesc.getTable())).split(&quot;#&quot;)[1].split(&quot;\\.&quot;)[0]
                    .equals(dealTableName(modelDesc.getRootFactTableName()))){
                sb.append(&quot;&lt;Dimension name='&quot;+dimensionDesc.getName()+&quot;' foreignKey='&quot;+aliasTableJoinMap.get(dealTableName(dimensionDesc.getTable()))
                        .split(&quot;#&quot;)[1].split(&quot;\\.&quot;)[1]+&quot;'&gt;&quot;).append(newLine);

                sb.append(&quot;&lt;Hierarchy name='&quot;+dimensionDesc.getName()+&quot;' hasAll='true' allMemberName='All &quot;+dimensionDesc.getName()+&quot;' primaryKey='&quot;+
                        aliasTableJoinMap.get(dealTableName(dimensionDesc.getTable())).split(&quot;#&quot;)[0].split(&quot;\\.&quot;)[1]+&quot;'&gt;&quot;).append(newLine);

                sb.append(&quot;&lt;Table name='&quot;+aliasTableMap.get(dealTableName(dimensionDesc.getTable()))+&quot;'/&gt;&quot;).append(newLine);

            } else if(aliasTableJoinMap.get(aliasTableJoinMap.get(dealTableName(dimensionDesc.getTable())).split(&quot;#&quot;)[1].split(&quot;\\.&quot;)[0])
                    .split(&quot;#&quot;)[1].split(&quot;\\.&quot;)[0].equals(dealTableName(modelDesc.getRootFactTableName()))){
                sb.append(&quot;&lt;Dimension name='&quot;+dimensionDesc.getName()+&quot;' foreignKey='&quot;+aliasTableJoinMap.get(aliasTableJoinMap.get(dealTableName(dimensionDesc.getTable()))
                        .split(&quot;#&quot;)[1].split(&quot;\\.&quot;)[0]).split(&quot;#&quot;)[1].split(&quot;\\.&quot;)[1]+&quot;'&gt;&quot;).append(newLine);

                sb.append(&quot;&lt;Hierarchy name='&quot;+dimensionDesc.getName()+&quot;' hasAll='true' allMemberName='All &quot;+dimensionDesc.getName()+&quot;' primaryKey='&quot;+
                        aliasTableJoinMap.get(aliasTableJoinMap.get(dealTableName(dimensionDesc.getTable())).split(&quot;#&quot;)[1].split(&quot;\\.&quot;)[0])
                                .split(&quot;#&quot;)[0].split(&quot;\\.&quot;)[1]+&quot;' primaryKeyTable='&quot;+aliasTableMap.get(aliasTableJoinMap.get(dealTableName(dimensionDesc.getTable()))
                        .split(&quot;#&quot;)[1].split(&quot;\\.&quot;)[0])+&quot;'&gt;&quot;).append(newLine);

                sb.append(&quot;&lt;Join leftKey='&quot;+aliasTableJoinMap.get(dealTableName(dimensionDesc.getTable())).split(&quot;#&quot;)[1].split(&quot;\\.&quot;)[1]+&quot;' rightAlias='&quot;+aliasTableMap.get(dimensionDesc.getTable())+
                        &quot;' rightKey='&quot;+aliasTableJoinMap.get(dealTableName(dimensionDesc.getTable())).split(&quot;#&quot;)[0].split(&quot;\\.&quot;)[1]+&quot;'&gt;&quot;).append(newLine);

                sb.append(&quot;&lt;Table name='&quot;+aliasTableMap.get(aliasTableJoinMap.get(dealTableName(dimensionDesc.getTable())).split(&quot;#&quot;)[1].split(&quot;\\.&quot;)[0])+&quot;'/&gt;&quot;).append(newLine);
                sb.append(&quot;&lt;Table name='&quot;+aliasTableMap.get(dimensionDesc.getTable())+&quot;'/&gt;&quot;).append(newLine);
                sb.append(&quot;&lt;/Join&gt;&quot;).append(newLine);
            } else {
                continue;
            }
            Set&lt;String&gt; columns = getColumns(dimensionDesc);
            for(String column:columns){
                sb.append(&quot;&lt;Level name='&quot;+column+&quot;' column='&quot;+column+&quot;' table='&quot;+aliasTableMap.get(dimensionDesc.getTable())+&quot;'/&gt;&quot;).append(newLine);
            }
            sb.append(&quot;&lt;/Hierarchy&gt;&quot;).append(newLine);
            sb.append(&quot;&lt;/Dimension&gt;&quot;).append(newLine);
        }
        for (MeasureDesc measureDesc : cubeDesc.getMeasures()) {
            int i=0;
            String table = measureDesc.getFunction().getParameter().getValue().split(&quot;\\.&quot;)[0];
            final boolean flag = Arrays.stream(modelDesc.getJoinTables()).anyMatch(item -&gt; table.equals(dealTableName(item.getTable())));
            if(table.equals(dealTableName(modelDesc.getRootFactTableName()))||flag||table.equals(&quot;1&quot;)){
                addMeasure(sb,measureDesc,getColumn(cubeDesc,modelDesc,dealTableName(modelDesc.getRootFactTableName())));
            }
        }

        sb.append(&quot;&lt;/Cube&gt;&quot;).append(newLine);
        return sb;
    }



    public static String dealTableName(String tableName){
        if(tableName.contains(&quot;.&quot;))
            return tableName.split(&quot;\\.&quot;)[1];
        else
            return tableName;
    }

    public static StringBuffer addMeasure(StringBuffer sb, MeasureDesc measureDesc, String defaultColumn) {
        FunctionDesc funtionDesc = measureDesc.getFunction();
        String aggregator = funtionDesc.getExpression().trim().toLowerCase();
        if(aggSet.contains(aggregator.toLowerCase())){
            //mondrian only have distinct-count
            if(aggregator.equals(&quot;count_distinct&quot;)){
                aggregator = &quot;distinct-count&quot;;
            }
            if(funtionDesc.getParameter().getValue().equals(&quot;1&quot;)) {
                sb.append(&quot;&lt;Measure aggregator='&quot; + aggregator + &quot;' column='&quot; + defaultColumn + &quot;' name='&quot; + measureDesc.getName() + &quot;' visible='true'/&gt;&quot;)
                        .append(newLine);
            }
            else
                sb.append(&quot;&lt;Measure aggregator='&quot; + aggregator + &quot;' column='&quot; + funtionDesc.getParameter().getValue().split(&quot;\\.&quot;)[1] + &quot;' name='&quot; + measureDesc.getName() + &quot;' visible='true'/&gt;&quot;)
                        .append(newLine);
            return sb;
        }
        return sb;
    }

    public static String getColumn(CubeDesc cubeDesc,DataModelDesc dataModelDesc,String tableName){
        List&lt;MeasureDesc&gt; measureDescList = cubeDesc.getMeasures();
        for(MeasureDesc measureDesc:measureDescList){
            if(measureDesc.getFunction().getParameter().getValue().split(&quot;\\.&quot;)[0].equals(tableName)){
                return measureDesc.getFunction().getParameter().getValue().split(&quot;\\.&quot;)[1];
            }
        }
        if(dataModelDesc.getMetrics().length&gt;0){
            return dataModelDesc.getMetrics()[0];
        }

        for(ModelDimensionDesc modelDimensionDesc:dataModelDesc.getDimensions()){
            if(modelDimensionDesc.getTable().equals(tableName)){
                return modelDimensionDesc.getColumns()[0];
            }
        }
        return null;
    }

    public static Set&lt;String&gt; getColumns(DimensionDesc dimensionDesc){
        Set&lt;String&gt; columns = new HashSet&lt;String&gt;();
        if (dimensionDesc.getColumn() != null || dimensionDesc.getDerived() != null) {
            if(dimensionDesc.getColumn() != null) {
                columns.add(dimensionDesc.getColumn());
            }
            if (dimensionDesc.getDerived() != null) {
                for (String derived : dimensionDesc.getDerived()) {
                    columns.add(derived);
                }
            }
        } else {
            columns.add(dimensionDesc.getName());
        }
        return columns;
    }
}
</code></pre>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;Schema name=&quot;Mondrian&quot;&gt;  &lt;!--模型定义--&gt;
&lt;Cube name=&quot;Person&quot;&gt;     &lt;!--立方体 ，一个立方体有多个维度--&gt;
    &lt;Table name=&quot;PERSON&quot; /&gt;  &lt;!--立方体对应的表 --&gt;
     &lt;Dimension name=&quot;部门&quot; foreignKey=&quot;USERID&quot; &gt; &lt;!--定义维度 --&gt;
        &lt;Hierarchy  hasAll=&quot;true&quot; primaryKey=&quot;USERID&quot; allMemberName=&quot;所有部门&quot; &gt; &lt;!--定义维度下面的层次，层次包含很多层 --&gt;
          &lt;Table name=&quot;PERSON&quot; alias=&quot;a&quot;/&gt;                                   &lt;!--定义维度获取数据的来源-表 --&gt;
        &lt;Level name=&quot;部门&quot; column=&quot;DEPARTMENT&quot; uniqueMembers=&quot;true&quot; /&gt; &lt;!--定义层次的层，每个层对应数据库中对应的字段 --&gt;
        &lt;Level name=&quot;姓名&quot; column=&quot;USERNAME&quot; uniqueMembers=&quot;true&quot; /&gt;           
        &lt;/Hierarchy&gt;
    &lt;/Dimension&gt;     
    &lt;Dimension name=&quot;性别&quot;  foreignKey=&quot;USERID&quot; &gt;
        &lt;Hierarchy hasAll=&quot;true&quot; primaryKey=&quot;USERID&quot; allMemberName=&quot;所有性别&quot;&gt;         
            &lt;Table name=&quot;PERSON&quot; alias=&quot;b&quot; /&gt;
        &lt;Level name=&quot;性别&quot; column=&quot;SEX&quot;   uniqueMembers=&quot;true&quot; /&gt;
        &lt;/Hierarchy&gt;
    &lt;/Dimension&gt;
    &lt;Dimension name=&quot;专业技术资格类别&quot;  foreignKey=&quot;USERID&quot; &gt;
        &lt;Hierarchy hasAll=&quot;true&quot; primaryKey=&quot;USERID&quot; allMemberName=&quot;所有专业技术资格类别&quot;&gt;         
            &lt;Table name=&quot;PERSON&quot; alias=&quot;c&quot; /&gt;
        &lt;Level name=&quot;资格类别&quot; column=&quot;ZYJSLB&quot;   uniqueMembers=&quot;true&quot; /&gt;
        &lt;/Hierarchy&gt;
    &lt;/Dimension&gt;
    &lt;Dimension name=&quot;专业技术资格等级&quot;  foreignKey=&quot;USERID&quot; &gt;
        &lt;Hierarchy hasAll=&quot;true&quot; primaryKey=&quot;USERID&quot; allMemberName=&quot;所有专业技术资格等级&quot;&gt;         
            &lt;Table name=&quot;PERSON&quot; alias=&quot;d&quot; /&gt;
        &lt;Level name=&quot;资格等级&quot; column=&quot;ZYJSDJ&quot;   uniqueMembers=&quot;true&quot; /&gt;
        &lt;/Hierarchy&gt;
    &lt;/Dimension&gt;
     &lt;Dimension name=&quot;职系&quot;  foreignKey=&quot;USERID&quot; &gt;
        &lt;Hierarchy hasAll=&quot;true&quot; primaryKey=&quot;USERID&quot; allMemberName=&quot;所有职系&quot;&gt;         
            &lt;Table name=&quot;PERSON&quot; alias=&quot;e&quot; /&gt;
        &lt;Level name=&quot;职系&quot; column=&quot;ZHIXI&quot;   uniqueMembers=&quot;true&quot; /&gt;
        &lt;/Hierarchy&gt;
    &lt;/Dimension&gt;
    &lt;Dimension name=&quot;民族&quot;  foreignKey=&quot;USERID&quot; &gt;
        &lt;Hierarchy hasAll=&quot;true&quot; primaryKey=&quot;USERID&quot; allMemberName=&quot;所有民族&quot;&gt;         
            &lt;Table name=&quot;PERSON&quot; alias=&quot;f&quot; /&gt;
        &lt;Level name=&quot;民族&quot; column=&quot;NATIONALITY&quot;   uniqueMembers=&quot;true&quot; /&gt;
        &lt;/Hierarchy&gt;
    &lt;/Dimension&gt;
    &lt;Dimension name=&quot;学历&quot;  foreignKey=&quot;USERID&quot; &gt;
        &lt;Hierarchy hasAll=&quot;true&quot; primaryKey=&quot;USERID&quot; allMemberName=&quot;所有学历&quot;&gt;         
            &lt;Table name=&quot;PERSON&quot; alias=&quot;g&quot; /&gt;
        &lt;Level name=&quot;学历&quot; column=&quot;XUELI&quot;   uniqueMembers=&quot;true&quot; /&gt;
        &lt;/Hierarchy&gt;
    &lt;/Dimension&gt;       
    &lt;Measure name=&quot;人数&quot; column=&quot;USERID&quot; aggregator=&quot;distinct count&quot; /&gt;       &lt;!--指标/度量，采用distinct count聚合 --&gt;
    &lt;/Cube&gt;
&lt;/Schema&gt;
</code></pre>
<p><strong>mondrian4.0语法工具类</strong></p>
<pre><code class="language-java">package org.saiku.service.util;

import org.apache.kylin.cube.model.CubeDesc;
import org.apache.kylin.cube.model.DimensionDesc;
import org.apache.kylin.cube.model.RowKeyDesc;
import org.apache.kylin.metadata.model.*;

import java.util.*;

public class SchemaUtil {
    private static final String newLine = &quot;\r\n&quot;;
    private static Map&lt;String, String&gt; map;

    public static String createSchema(String dataSourceName, CubeDesc cubeDesc, DataModelDesc modelDesc) {
        StringBuffer sb = new StringBuffer();
        sb = appendSchema(sb, dataSourceName, cubeDesc, modelDesc);
//        System.out.println(&quot;********************************&quot; + sb.toString());
        return sb.toString();
    }

    public static StringBuffer appendSchema(StringBuffer sb, String dataSourceName, CubeDesc cubeDesc, DataModelDesc modelDesc) {
        sb.append(&quot;&lt;?xml version='1.0'?&gt;&quot;).append(newLine)
                .append(&quot;&lt;Schema name='&quot;).append(dataSourceName.split(&quot;#&quot;)[0].trim()).append(&quot;' metamodelVersion='4.0'&gt;&quot;)
//                .append(&quot;&lt;Schema name='&quot; + dataSourceName + &quot;' metamodelVersion='4.0'&gt;&quot;)
                .append(newLine);
        appendTable(sb, modelDesc);
        appendDimension(sb, modelDesc);
        appendCube(sb, dataSourceName, cubeDesc, modelDesc);
        sb.append(&quot;&lt;/Schema&gt;&quot;).append(newLine);
        return sb;
    }

    public static StringBuffer appendTable(StringBuffer sb, DataModelDesc modelDesc) {
        StringBuilder linkSb = new StringBuilder();
        //获取所有关系表
        final List&lt;ModelDimensionDesc&gt; tables = modelDesc.getDimensions();
        sb.append(&quot;&lt;PhysicalSchema&gt;&quot;).append(newLine);
        //添加表关联关系
        final JoinTableDesc[] joinTables = modelDesc.getJoinTables();
        for (JoinTableDesc joinTableDesc : joinTables) {
            String factTablename = dealModelTableName(joinTableDesc.getJoin().getForeignKey()[0]);
            String Column = dealTableName(joinTableDesc.getJoin().getForeignKey()[0]);
            String joinTablename = dealModelTableName(joinTableDesc.getJoin().getPrimaryKey()[0]);
            String joinColumn = dealTableName(joinTableDesc.getJoin().getPrimaryKey()[0]);
            linkSb.append(&quot;&lt;Link source='&quot;).append(factTablename).append(&quot;' target='&quot;).append(joinTablename).append(&quot;'&gt;&quot;).append(newLine)
                    .append(&quot;&lt;ForeignKey&gt;&quot;).append(newLine)
                    .append(&quot;&lt;Column name='&quot;).append(Column).append(&quot;'/&gt;&quot;).append(newLine)
                    .append(&quot;&lt;/ForeignKey&gt;&quot;).append(newLine)
                    .append(&quot;&lt;/Link&gt;&quot;).append(newLine);
            //清空map
            map = new HashMap&lt;&gt;();
            tables.forEach(item -&gt; {
                if (item.getTable().equals(factTablename)) {
                    map.put(factTablename, Column);
                }
                if (item.getTable().equals(joinTablename)) {
                    map.put(joinTablename, joinColumn);
                }
            });
        }
        //添加表
        for (String tableName : map.keySet()) {
            sb.append(&quot;&lt;Table name='&quot;).append(tableName).append(&quot;'&gt;&quot;).append(newLine)
                    .append(&quot;&lt;Key&gt;&quot;).append(newLine).append(&quot;&lt;Column name='&quot;).append(map.get(tableName)).append(&quot;'/&gt;&quot;).append(newLine)
                    .append(&quot;&lt;/Key&gt;&quot;).append(newLine)
                    .append(&quot;&lt;/Table&gt;&quot;).append(newLine);
        }

        sb.append(linkSb);
        linkSb.delete(0, linkSb.length());
        sb.append(&quot;&lt;/PhysicalSchema&gt;&quot;).append(newLine);
        return sb;
    }

    public static Map&lt;String, JoinDesc&gt; getJoinDesc(DataModelDesc modelDesc) {
        Map&lt;String, JoinDesc&gt; joinDescMap = new HashMap&lt;String, JoinDesc&gt;();
        for (JoinTableDesc lookupDesc : modelDesc.getJoinTables()) {
            if (!joinDescMap.containsKey(dealTableName(lookupDesc.getTable())))
                joinDescMap.put(dealTableName(lookupDesc.getTable()), lookupDesc.getJoin());
        }
        return joinDescMap;
    }

    public static void appendDimension(StringBuffer sb, DataModelDesc modelDesc) {
        StringBuilder hierSb = new StringBuilder();
        for (ModelDimensionDesc dimensionDesc : modelDesc.getDimensions()) {
            sb.append(&quot;&lt;Dimension name='&quot;).append(dimensionDesc.getTable()).append(&quot;' key='&quot;).append(map.get(dimensionDesc.getTable())).append(&quot;' table='&quot;).append(dimensionDesc.getTable()).append(&quot;'&gt;&quot;).append(newLine);
            sb.append(&quot;&lt;Attributes&gt;&quot;).append(newLine);
            hierSb.append(&quot;&lt;Hierarchies&gt;&quot;).append(newLine);
            hierSb.append(&quot;&lt;Hierarchy  name='&quot;).append(dimensionDesc.getTable()).append(&quot;' hasAll='true'&gt;&quot;).append(newLine);
            for (String column : dimensionDesc.getColumns()) {
                // add Attributes to stringbuffer
                addAttribute(sb, column);
                addHierarchy(hierSb, column);
            }
            sb.append(&quot;&lt;/Attributes&gt;&quot;).append(newLine);
            hierSb.append(&quot;&lt;/Hierarchy&gt;&quot;).append(newLine);
            hierSb.append(&quot;&lt;/Hierarchies&gt;&quot;).append(newLine);
            sb.append(hierSb);
            hierSb.delete(0, hierSb.length());
            sb.append(&quot;&lt;/Dimension&gt;&quot;).append(newLine);
        }
    }

    public static Set&lt;String&gt; getColumns(DimensionDesc dimensionDesc) {
        Set&lt;String&gt; columns = new HashSet&lt;String&gt;();
        if (dimensionDesc.getColumn() != null || dimensionDesc.getDerived() != null) {
            if (dimensionDesc.getColumn() != null) {
//                for (String column : dimensionDesc.getColumn()) {
                columns.add(dimensionDesc.getColumn());
//                }
            }
            if (dimensionDesc.getDerived() != null) {
                columns.addAll(Arrays.asList(dimensionDesc.getDerived()));
            }
        } else {
            columns.add(dimensionDesc.getName());
        }
        return columns;
    }

    public static StringBuffer addAttribute(StringBuffer sb, String attr) {
        sb.append(&quot;&lt;Attribute name='&quot;).append(attr).append(&quot;' keyColumn='&quot;).append(attr).append(&quot;' hasHierarchy='false'/&gt;&quot;).append(newLine);
        return sb;
    }

    public static void addHierarchy(StringBuilder sb, String attr) {
        sb.append(&quot;&lt;Level attribute='&quot;).append(attr).append(&quot;'/&gt;&quot;).append(newLine);
    }


    public static String dealTableName(String tableName) {
        if (tableName.contains(&quot;.&quot;))
            return tableName.split(&quot;\\.&quot;)[1];
        else
            return tableName;
    }

    public static String dealModelTableName(String tableName) {
        if (tableName.contains(&quot;.&quot;))
            return tableName.split(&quot;\\.&quot;)[0];
        else
            return tableName;
    }

    public static StringBuffer appendCube(StringBuffer sb, String cubeName, CubeDesc cubeDesc, DataModelDesc modelDesc) {
        sb.append(&quot;&lt;Cube name='&quot;).append(cubeName.split(&quot;#&quot;)[1].trim()).append(&quot;'&gt;&quot;).append(newLine);
        addCubeDimension(sb, modelDesc.getDimensions());
        sb.append(&quot;&lt;MeasureGroups&gt;&quot;).append(newLine);

        Map&lt;String, Map&lt;String, MeasureDesc&gt;&gt; allMap = new HashMap();

        MeasureDesc one = new MeasureDesc();
        for (MeasureDesc measureDesc : cubeDesc.getMeasures()) {
            final String tableName = dealModelTableName(measureDesc.getFunction().getParameter().getValue());
            final String columnName = dealTableName(measureDesc.getFunction().getParameter().getValue());
            if (&quot;1&quot;.equals(tableName)) {
                one = measureDesc;
            } else {
                if (Objects.isNull(allMap.get(tableName))) {
                    Map&lt;String, MeasureDesc&gt; map = new HashMap();
                    if (Objects.nonNull(one)) {
                        map.put(columnName, one);
                        one = null;
                    }
                    map.put(columnName, measureDesc);
                    allMap.put(tableName, map);
                } else {
                    allMap.get(tableName).put(columnName, measureDesc);
                }
            }
        }

        allMap.forEach((tableName, value) -&gt; {
            sb.append(&quot;&lt;MeasureGroup table='&quot;).append(dealTableName(tableName)).append(&quot;'&gt;&quot;).append(newLine);
            addDimensionLink(sb, modelDesc);
            sb.append(&quot;&lt;Measures&gt;&quot;).append(newLine);
            value.forEach((columnName, measureDesc) -&gt; {
                addMeasure(sb, measureDesc, getColumn(cubeDesc));
            });
            sb.append(&quot;&lt;/Measures&gt;&quot;).append(newLine);
            sb.append(&quot;&lt;/MeasureGroup&gt;&quot;).append(newLine);
        });
        sb.append(&quot;&lt;/MeasureGroups&gt;&quot;).append(newLine);
        sb.append(&quot;&lt;/Cube&gt;&quot;).append(newLine);
        return sb;
    }

    public static void addCubeDimension(StringBuffer sb, List&lt;ModelDimensionDesc&gt; dimensionDescs) {
        sb.append(&quot;&lt;Dimensions&gt;&quot;).append(newLine);
        for (ModelDimensionDesc dimensionDesc : dimensionDescs) {
            sb.append(&quot;&lt;Dimension source='&quot;).append(dimensionDesc.getTable()).append(&quot;' visible='true'/&gt;&quot;).append(newLine);
        }
        sb.append(&quot;&lt;/Dimensions&gt;&quot;).append(newLine);
    }

    public static void addDimensionLink(StringBuffer sb, DataModelDesc modelDesc) {
        sb.append(&quot;&lt;DimensionLinks&gt;&quot;).append(newLine);
        for(ModelDimensionDesc dimensionDesc : modelDesc.getDimensions()) {
            if(dimensionDesc.getTable().contains(dealTableName(modelDesc.getRootFactTableName()))) {
                sb.append(&quot;&lt;FactLink dimension='&quot;).append(dimensionDesc.getTable()).append(&quot;'/&gt;&quot;).append(newLine);
            }else{
                sb.append(&quot;&lt;ForeignKeyLink dimension='&quot;).append(dimensionDesc.getTable()).append(&quot;' foreignKeyColumn='&quot;).append(map.get(dimensionDesc.getTable())).append(&quot;'/&gt;&quot;).append(newLine);
            }
        }
        sb.append(&quot; &lt;/DimensionLinks&gt;&quot;).append(newLine);
    }

    public static StringBuffer addMeasure(StringBuffer sb, MeasureDesc measureDesc, String defaultColumn) {
        FunctionDesc funtionDesc = measureDesc.getFunction();
        String aggregator = funtionDesc.getExpression().trim().toLowerCase();
        //mondrian only have distinct-count
        if (aggregator.equals(&quot;count_distinct&quot;)) {
            aggregator = &quot;distinct-count&quot;;
        }
        if (funtionDesc.getParameter().getValue().equals(&quot;1&quot;)) {
            sb.append(&quot;&lt;Measure aggregator='&quot;).append(aggregator).append(&quot;' column='&quot;).append(dealTableName(defaultColumn)).append(&quot;' name='&quot;).append(measureDesc.getName()).append(&quot;' visible='true'/&gt;&quot;)
                    .append(newLine);
        } else
            sb.append(&quot;&lt;Measure aggregator='&quot;).append(aggregator).append(&quot;' column='&quot;).append(dealTableName(funtionDesc.getParameter().getValue())).append(&quot;' name='&quot;).append(measureDesc.getName()).append(&quot;' visible='true'/&gt;&quot;)
                    .append(newLine);
        return sb;
    }

    public static Set&lt;String&gt; getTables(List&lt;DimensionDesc&gt; dimensionDescList) {
        Set&lt;String&gt; tables = new HashSet&lt;String&gt;();
        for (DimensionDesc dimensionDesc : dimensionDescList) {
            String table = dealTableName(dimensionDesc.getTable());
            tables.add(table);
        }
        return tables;
    }

    public static String getColumn(CubeDesc cubeDesc) {
        RowKeyDesc rowKey = cubeDesc.getRowkey();
        return rowKey.getRowKeyColumns()[0].getColumn();
    }
}
</code></pre>
<pre><code class="language-xml">&lt;?xml version='1.0'?&gt;
&lt;Schema name='xiaowei' metamodelVersion='4.0'&gt;
&lt;PhysicalSchema&gt;
	&lt;Table name='TBL_FARM_INCOME_STATICS'&gt;
		&lt;Key&gt;
			&lt;Column name='COMPANY_ID'/&gt;
		&lt;/Key&gt;
	&lt;/Table&gt;
	&lt;Table name='TBL_CUSTOMER'&gt;
		&lt;Key&gt;
			&lt;Column name='COMPANY_ID'/&gt;
		&lt;/Key&gt;
	&lt;/Table&gt;
	&lt;Link source='TBL_FARM_INCOME_STATICS' target='TBL_CUSTOMER'&gt;
		&lt;ForeignKey&gt;
			&lt;Column name='COMPANY_ID'/&gt;
		&lt;/ForeignKey&gt;
	&lt;/Link&gt;
&lt;/PhysicalSchema&gt;
&lt;Dimension name='TBL_FARM_INCOME_STATICS' table='TBL_FARM_INCOME_STATICS' key='COMPANY_ID'&gt;
	&lt;Attributes&gt;
		&lt;Attribute name='COMPANY_ID' keyColumn='COMPANY_ID' hasHierarchy='false'/&gt;
		&lt;Attribute name='INCOME_DATE' keyColumn='INCOME_DATE' hasHierarchy='false'/&gt;
	&lt;/Attributes&gt;

	&lt;Hierarchies&gt;
		&lt;Hierarchy name='TBL_FARM_INCOME_STATICS' allMemberName='All Warehouses'&gt;
			&lt;Level attribute='COMPANY_ID'/&gt;
			&lt;Level attribute='INCOME_DATE'/&gt;
		&lt;/Hierarchy&gt;
	&lt;/Hierarchies&gt;
&lt;/Dimension&gt;

&lt;Dimension name='TBL_CUSTOMER' table='TBL_CUSTOMER' key='COMPANY_ID'&gt;
	&lt;Attributes&gt;
		&lt;Attribute name='COMPANY_ID' keyColumn='COMPANY_ID' hasHierarchy='false'/&gt;
		&lt;Attribute name='CUSTOMER_TYPE' keyColumn='CUSTOMER_TYPE' hasHierarchy='false'/&gt;
		&lt;Attribute name='PHONE' keyColumn='PHONE' hasHierarchy='false'/&gt;
	&lt;/Attributes&gt;

	&lt;Hierarchies&gt;
		&lt;Hierarchy name='TBL_CUSTOMER' allMemberName='All Warehouses'&gt;
			&lt;Level attribute='COMPANY_ID'/&gt;
			&lt;Level attribute='CUSTOMER_TYPE'/&gt;
			&lt;Level attribute='PHONE'/&gt;
		&lt;/Hierarchy&gt;
	&lt;/Hierarchies&gt;
&lt;/Dimension&gt;

&lt;Cube name='tbl_farm_income_statics'&gt;
&lt;Dimensions&gt;
&lt;Dimension source='TBL_FARM_INCOME_STATICS' visible='true'/&gt;
&lt;Dimension source='TBL_CUSTOMER' visible='true'/&gt;
&lt;/Dimensions&gt;
&lt;MeasureGroups&gt;
	&lt;MeasureGroup table='TBL_CUSTOMER'&gt;
		&lt;Measures&gt;
			&lt;Measure aggregator='sum' column='CONSUME_AMMOUT' name='CONSUME_AMMOUT_SUM' visible='true'/&gt;
		&lt;/Measures&gt;
		&lt;DimensionLinks&gt;
			&lt;FactLink dimension='TBL_FARM_INCOME_STATICS'/&gt;
			&lt;ForeignKeyLink dimension='TBL_CUSTOMER' foreignKeyColumn='COMPANY_ID'/&gt;
		&lt;/DimensionLinks&gt;
	&lt;/MeasureGroup&gt;

	&lt;MeasureGroup table='TBL_FARM_INCOME_STATICS'&gt;
		&lt;Measures&gt;
			&lt;Measure aggregator='count' column='COMPANY_ID' name='_COUNT_' visible='true'/&gt;
			&lt;Measure aggregator='sum' column='REFUND_AMOUNT' name='REFUND_AMOUNT_SUM' visible='true'/&gt;
			&lt;Measure aggregator='sum' column='COMMON_REFUND_AMOUNT' name='COMMON_REFUND_AMOUNT_SUM' visible='true'/&gt;
			&lt;Measure aggregator='sum' column='COMMON_INCOME' name='COMMON_INCOME_SUM' visible='true'/&gt;
			&lt;Measure aggregator='sum' column='SALE_AMOUNT' name='SALE_AMOUNT_SUM' visible='true'/&gt;
			&lt;Measure aggregator='sum' column='RENEW_AMOUNT' name='RENEW_AMOUNT_SUM' visible='true'/&gt;
			&lt;Measure aggregator='sum' column='TOTAL_AMOUNT' name='TOTAL_AMOUNT_SUM' visible='true'/&gt;
		&lt;/Measures&gt;
		&lt;DimensionLinks&gt;
			&lt;FactLink dimension='TBL_FARM_INCOME_STATICS'/&gt;
			&lt;ForeignKeyLink dimension='TBL_CUSTOMER' foreignKeyColumn='COMPANY_ID'/&gt;
		&lt;/DimensionLinks&gt;
	&lt;/MeasureGroup&gt;
&lt;/MeasureGroups&gt;
&lt;/Cube&gt;
&lt;/Schema&gt;

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[同步 异步 阻塞 非阻塞]]></title>
        <id>https://tinaxiawuhao.github.io/post/1SOcADwUR/</id>
        <link href="https://tinaxiawuhao.github.io/post/1SOcADwUR/">
        </link>
        <updated>2021-09-27T02:28:54.000Z</updated>
        <content type="html"><![CDATA[<h3 id="io操作">IO操作</h3>
<pre><code>CopyIO分两阶段（一旦拿到数据后就变成了数据操作，不再是IO）：
    1.数据准备阶段
    2.内核空间复制数据到用户进程缓冲区（用户空间）阶段

在操作系统中，程序运行的空间分为内核空间和用户空间。
    应用程序都是运行在用户空间的，所以它们能操作的数据也都在用户空间。


阻塞IO和非阻塞IO的区别在于第一步发起IO请求是否会被阻塞：
    如果阻塞直到完成那么就是传统的阻塞IO，如果不阻塞，那么就是非阻塞IO。

一般来讲：
    阻塞IO模型、非阻塞IO模型、IO复用模型(select/poll/epoll)、信号驱动IO模型都属于同步IO，因为阶段2是阻塞的(尽管时间很短)。

同步IO和异步IO的区别就在于第二个步骤是否阻塞：
    如果不阻塞，而是操作系统帮你做完IO操作再将结果返回给你，那么就是异步IO
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1632709893088.png" alt="" loading="lazy"></figure>
<h3 id="同步和异步io-阻塞和非阻塞io">同步和异步IO 阻塞和非阻塞IO</h3>
<pre><code>Copy同步和异步IO的概念：

	同步是用户线程发起I/O请求后需要等待或者轮询内核I/O操作完成后才能继续执行

	异步是用户线程发起I/O请求后仍需要继续执行，当内核I/O操作完成后会通知用户线程，或者调用用户线程注册的回调函数

阻塞和非阻塞IO的概念：

	阻塞是指I/O操作需要彻底完成后才能返回用户空间

	非阻塞是指I/O操作被调用后立即返回一个状态值，无需等I/O操作彻底完成
</code></pre>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1632709914348.png" alt="" loading="lazy"></figure>
<h3 id="同步与异步线程间调用">同步与异步（线程间调用）</h3>
<pre><code>Copy同步与异步是对应于调用者与被调用者，它们是线程之间的关系，两个线程之间要么是同步的，要么是异步的

	同步操作时，调用者需要等待被调用者返回结果，才会进行下一步操作

	而异步则相反，调用者不需要等待被调用者返回调用，即可进行下一步操作，被调用者通常依靠事件、回调等机制来通知调用者结果
</code></pre>
<h3 id="阻塞与非阻塞线程内调用">阻塞与非阻塞（线程内调用）</h3>
<pre><code>Copy阻塞与非阻塞是对同一个线程来说的，在某个时刻，线程要么处于阻塞，要么处于非阻塞


阻塞和非阻塞关注的是程序在等待调用结果（消息，返回值）时的状态：

    阻塞调用是指调用结果返回之前，当前线程会被挂起。调用线程只有在得到结果之后才会返回。

    非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。
</code></pre>
<h3 id="同步与异步调用线程通信">同步与异步调用/线程/通信</h3>
<pre><code>Copy同步就是两种东西通过一种机制实现步调一致，异步是两种东西不必步调一致


一、同步调用与异步调用：

    在用在调用场景中，无非是对调用结果的不同处理。

    同步调用就是调用一但返回，就能知道结果，而异步是返回时不一定知道结果，还得通过其他机制来获知结果，如：

        a. 状态 b. 通知 c. 回调函数


二、同步线程与异步线程：

    同步线程：即两个线程步调要一致，其中一个线程可能要阻塞等待另外一个线程的运行，要相互协商。快的阻塞一下等到慢的步调一致。

    异步线程：步调不用一致，各自按各自的步调运行，不受另一个线程的影响。


三、同步通信与异步通信：

    同步和异步是指：发送方和接收方是否协调步调一致

    同步通信是指：发送方和接收方通过一定机制，实现收发步调协调。
        如：发送方发出数据后，等接收方发回响应以后才发下一个数据包的通讯方式

    异步通信是指：发送方的发送不管接收方的接收状态。
        如：发送方发出数据后，不等接收方发回响应，接着发送下个数据包的通讯方式。


阻塞可以是实现同步的一种手段！例如两个东西需要同步，一旦出现不同步情况，我就阻塞快的一方，使双方达到同步。

同步是两个对象之间的关系，而阻塞是一个对象的状态。
</code></pre>
<h3 id="四种组合方式">四种组合方式</h3>
<pre><code>Copy同步阻塞方式：
    发送方发送请求之后一直等待响应。
    接收方处理请求时进行的IO操作如果不能马上等到返回结果，就一直等到返回结果后，才响应发送方，期间不能进行其他工作。

同步非阻塞方式：
	发送方发送请求之后，一直等待响应。
	接受方处理请求时进行的IO操作如果不能马上的得到结果，就立即返回，取做其他事情。
	但是由于没有得到请求处理结果，不响应发送方，发送方一直等待。
	当IO操作完成以后，将完成状态和结果通知接收方，接收方再响应发送方，发送方才进入下一次请求过程。（实际不应用）

异步阻塞方式：
	发送方向接收方请求后，不等待响应，可以继续其他工作。
	接收方处理请求时进行IO操作如果不能马上得到结果，就一直等到返回结果后，才响应发送方，期间不能进行其他操作。 （实际不应用）

异步非阻塞方式：
	发送方向接收方请求后，不等待响应，可以继续其他工作。
	接收方处理请求时进行IO操作如果不能马上得到结果，也不等待，而是马上返回去做其他事情。
	当IO操作完成以后，将完成状态和结果通知接收方，接收方再响应发送方。（效率最高）
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[NIO-FileChannel]]></title>
        <id>https://tinaxiawuhao.github.io/post/7Wmx9Q2PP/</id>
        <link href="https://tinaxiawuhao.github.io/post/7Wmx9Q2PP/">
        </link>
        <updated>2021-09-17T08:28:44.000Z</updated>
        <content type="html"><![CDATA[<h3 id="nio介绍">NIO介绍</h3>
<p>在讲解Channel之前，首先了解一下NIO， Java NIO全称java non-blocking IO，是从Java 1.4版本开始引入的一个新的IO API（New IO），可以替代标准的Java IO API，NIO与原来的IO有同样的作用和目的，但是使用的方式完全不同。IO与 NIO区别：</p>
<table>
<thead>
<tr>
<th>IO</th>
<th>NIO</th>
</tr>
</thead>
<tbody>
<tr>
<td>面向流（Stream Orientend）</td>
<td>面向缓冲区（Buffer Orientend）</td>
</tr>
<tr>
<td>阻塞IO（Blocking IO )</td>
<td>非阻塞IO（Non Blocking IO）</td>
</tr>
<tr>
<td></td>
<td>选择器（Selector）</td>
</tr>
</tbody>
</table>
<p>NIO支持面向缓冲区的、基于通道的IO操作并以更加高效的方式进行文件的读写操作，其核心API为Channel(通道)，Buffer(缓冲区), Selector(选择器)。Channel负责传输，Buffer负责存储 。</p>
<h3 id="缓冲区">缓冲区</h3>
<pre><code class="language-java">public class BioTest {
    @Test
    public void test1() {
        //1.初始化缓冲区数组
        ByteBuffer bf = ByteBuffer.allocate(1024);
        System.out.println(&quot;==========allocate============&quot;);
        System.out.println(bf.position());
        System.out.println(bf.limit());
        System.out.println(bf.capacity());

        //2.put插入数据
        bf.put(&quot;asasas&quot;.getBytes());
        System.out.println(&quot;==========put============&quot;);
        System.out.println(bf.position());
        System.out.println(bf.limit());
        System.out.println(bf.capacity());

        //3.改为读状态
        bf.flip();
        System.out.println(&quot;==========flip============&quot;);
        System.out.println(bf.position());
        System.out.println(bf.limit());
        System.out.println(bf.capacity());

        //4.获取缓冲区数据
        final byte[] bytes = new byte[bf.limit()];
        bf.get(bytes);
        System.out.println(&quot;==========get============&quot;);
        System.out.println(new String(bytes,0,bytes.length));
        System.out.println(bf.position());
        System.out.println(bf.limit());
        System.out.println(bf.capacity());

        //5.重置读状态
        bf.rewind();
        System.out.println(&quot;==========rewind============&quot;);
        System.out.println(bf.position());
        System.out.println(bf.limit());
        System.out.println(bf.capacity());

        //6.清除数据标识
        bf.clear();
        System.out.println(&quot;==========clear============&quot;);
        System.out.println(bf.position());
        System.out.println(bf.limit());
        System.out.println(bf.capacity());
    }
}
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1631867929854.png" alt="" loading="lazy"></figure>
<h3 id="直接缓冲区与非直接缓冲区">直接缓冲区与非直接缓冲区：</h3>
<p>非直接缓冲区：通过 allocate() 方法分配缓冲区，将缓冲区建立在 JVM 的内存中<br>
直接缓冲区：通过 allocateDirect() 方法分配直接缓冲区，将缓冲区建立在物理内存中。可以提高效率</p>
<ol>
<li>字节缓冲区要么是直接的，要么是非直接的。如果为直接字节缓冲区，则 Java 虚拟机会尽最大努力直接在机 此缓冲区上执行本机 I/O 操作。也就是说，在每次调用基础操作系统的一个本机 I/O 操作之前（或之后），</li>
<li>虚拟机都会尽量避免将缓冲区的内容复制到中间缓冲区中（或从中间缓冲区中复制内容）。</li>
<li>直接字节缓冲区可以通过调用此类的 allocateDirect() 工厂方法 来创建。此方法返回的 缓冲区进行分配和取消分配所需成本通常高于非直接缓冲区 。直接缓冲区的内容可以驻留在常规的垃圾回收堆之外，因此，它们对应用程序的内存需求量造成的影响可能并不明显。所以，建议将直接缓冲区主要分配给那些易受基础系统的本机 I/O 操作影响的大型、持久的缓冲区。一般情况下，最好仅在直接缓冲区能在程序性能方面带来明显好处时分配它们。</li>
<li>直接字节缓冲区还可以过 通过FileChannel 的 map() 方法 将文件区域直接映射到内存中来创建 。该方法返回MappedByteBuffer 。Java 平台的实现有助于通过 JNI 从本机代码创建直接字节缓冲区。如果以上这些缓冲区中的某个缓冲区实例指的是不可访问的内存区域，则试图访问该区域不会更改该缓冲区的内容，并且将会在访问期间或稍后的某个时间导致抛出不确定的异常。</li>
<li>字节缓冲区是直接缓冲区还是非直接缓冲区可通过调用其 isDirect() 方法来确定。提供此方法是为了能够在性能关键型代码中执行显式缓冲区管理。</li>
</ol>
<p>非直接缓冲区：</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1632797370169.png" alt="" loading="lazy"></figure>
<p>直接缓冲区：</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1632797378679.png" alt="" loading="lazy"></figure>
<h3 id="通道channel">通道（Channel ）</h3>
<p>通道表示打开到 IO 设备(例如：文件、套接字)的连接。若需要使用 NIO 系统，需要获取用于连接 IO 设备的通道以及用于容纳数据的缓冲区。然后操作缓冲区，对数据进行处理。<br>
　　Channel相比IO中的Stream更加高效，可以异步双向传输，但是必须和buffer一起使用。</p>
<p>主要实现类</p>
<pre><code class="language-java">FileChannel，读写文件中的数据。
SocketChannel，通过TCP读写网络中的数据。
ServerSockectChannel，监听新进来的TCP连接，像Web服务器那样。对每一个新进来的连接都会创建一个SocketChannel。
DatagramChannel，通过UDP读写网络中的数据。
</code></pre>
<h3 id="channel聚集gather写入">Channel聚集(gather)写入</h3>
<p>聚集写入（ Gathering Writes）是指将多个 Buffer 中的数据“聚集”到 Channel。 特别注意：按照缓冲区的顺序，写入 position 和 limit 之间的数据到 Channel 。</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1631867939574.png" alt="" loading="lazy"></figure>
<h3 id="channel分散scatter读取">Channel分散(scatter)读取</h3>
<p>分散读取（ Scattering Reads）是指从 Channel 中读取的数据“分散” 到多个 Buffer 中。 特别注意：按照缓冲区的顺序，从 Channel 中读取的数据依次将 Buffer 填满。</p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1631867947387.png" alt="" loading="lazy"></figure>
<h3 id="零拷贝filechannel的transferto和transferfrom">“零拷贝”（FileChannel的transferTo和transferFrom）</h3>
<blockquote>
<p>Java NIO中提供的FileChannel拥有transferTo和transferFrom两个方法，可直接把FileChannel中的数据拷贝到另外一个Channel，或者直接把另外一个Channel中的数据拷贝到FileChannel。该接口常被用于高效的网络/文件的数据传输和大文件拷贝。在操作系统支持的情况下，通过该方法传输数据并不需要将源数据从内核态拷贝到用户态，再从用户态拷贝到目标通道的内核态，同时也避免了两次用户态和内核态间的上下文切换，也即使用了“零拷贝”，所以其性能一般高于Java IO中提供的方法。</p>
</blockquote>
<h3 id="代码案例">代码案例</h3>
<pre><code class="language-java">/**
 * @author wuhao
 * @desc 本地io:
 * 　　 FileInputStreanm/FileOutputStream
 * 　　RandomAccessFile
 * 网络io:
 * 　　Socket
 * 　　ServerSocket
 * 　　DatagramSocket
 * @date 2021-09-17 15:22:26
 */
public class ChannelTest {

    //利用通道完成文件的复制,非直接缓冲区
    @Test
    @SneakyThrows
    public void test(){
        FileInputStream fis = new FileInputStream(&quot;D:\\1.jpg&quot;);
        FileOutputStream fos = new FileOutputStream(&quot;D:\\2.jpg&quot;);
        //获取通道
        FileChannel inChannel = fis.getChannel();
        FileChannel outChannel = fos.getChannel();
        //分配指定大小缓存区
        ByteBuffer buff = ByteBuffer.allocate(1024);// position 0 ,limit 1024
        //将通道的数据存入缓存区
        while(inChannel.read(buff)!=-1){// position 1024 ,limit 1024 ,相当于put
            //切换读模式
            buff.flip();//position 0 ,limit 1024
            //将缓存去的数据写入通道
            outChannel.write(buff);//position 1024 ,limit 1024,相当于get
            //清空缓冲区
            buff.clear();//position 0 ,limit 1024
        }
        outChannel.close();
        inChannel.close();
        fis.close();
        fos.close();
    }

    //利用通道完成文件的复制,直接缓冲区,利用物理内存映射文件
    //会出现文件复制完了，但程序还没结束，原因是JVM资源还在用，当垃圾回收机制回收之后程序就会结束,不稳定
    @Test
    @SneakyThrows
    public void test1(){
        FileChannel inChannel = FileChannel.open(Paths.get(&quot;D:\\1.jpg&quot;), StandardOpenOption.READ);
        FileChannel outChannel = FileChannel.open(Paths.get(&quot;D:\\4.jpg&quot;), StandardOpenOption.READ,StandardOpenOption.WRITE,StandardOpenOption.CREATE);
        //内存映射文件
        MappedByteBuffer inMapBuff = inChannel.map(FileChannel.MapMode.READ_ONLY, 0, inChannel.size());//==allocateDirect
        MappedByteBuffer outMapBuff = outChannel.map(FileChannel.MapMode.READ_WRITE, 0, inChannel.size());
        byte[] by = new byte[inMapBuff.limit()];
        inMapBuff.get(by);
        outMapBuff.put(by);
        outChannel.close();
        inChannel.close();
    }

    /**
     * 从源信道读取字节到这个通道的文件中。如果源通道的剩余空间小于 count 个字节，则所传输的字节数要小于请求的字节数。这种方法可能比从源通道读取并写入此通道的简单循环更有效率。
     * @param SRC 源通道
     * @param position 调动开始的文件内的位置，必须是非负的
     * @param count 要传输的最大字节数，必须是非负
     * @return 传输文件的大小（单位字节），可能为零，
     * public abstract long transferFrom(ReadableByteChannel src, long position, long count)　throws IOException;
     */
    //复制图片，利用直接缓存区
    @Test
    @SneakyThrows
    public void test2(){
        FileChannel inChannel = FileChannel.open(Paths.get(&quot;D:\\1.jpg&quot;), StandardOpenOption.READ);
        FileChannel outChannel = FileChannel.open(Paths.get(&quot;D:\\2.jpg&quot;), StandardOpenOption.READ, StandardOpenOption.WRITE, StandardOpenOption.CREATE);
        outChannel.transferFrom(inChannel, 0, inChannel.size());
        inChannel.close();
        outChannel.close();
    }

    /**
     * 将字节从这个通道的文件传输到给定的可写字节通道。
     * @param position 调动开始的文件内的位置，必须是非负的
     * @param count 要传输的最大字节数，必须是非负
     * @param target 目标通道
     * @return 传输文件的大小（单位字节），可能为零，
     * public abstract long transferTo(long position, long count, WritableByteChannel target) throws IOException;
     */
    //复制图片，利用直接缓存区
    @Test
    @SneakyThrows
    public void test3(){
        FileChannel inChannel = FileChannel.open(Paths.get(&quot;D:\\1.jpg&quot;), StandardOpenOption.READ);
        FileChannel outChannel = FileChannel.open(Paths.get(&quot;D:\\3.jpg&quot;), StandardOpenOption.READ, StandardOpenOption.WRITE, StandardOpenOption.CREATE);
        inChannel.transferTo(0, inChannel.size(), outChannel);
        inChannel.close();
        outChannel.close();
    }

    // 分散读取聚集写入实现文件复制

    @Test
    @SneakyThrows
    public void test4(){
        RandomAccessFile randomAccessFile = null;
        RandomAccessFile randomAccessFile1 = null;
        FileChannel inChannel = null;
        FileChannel outChannel = null;
        try {
            randomAccessFile = new RandomAccessFile(new File(&quot;d:\\old.txt&quot;), &quot;rw&quot;);
            randomAccessFile1 = new RandomAccessFile(new File(&quot;d:\\new.txt&quot;), &quot;rw&quot;);
            inChannel = randomAccessFile.getChannel();
            outChannel = randomAccessFile1.getChannel();
            // 分散为三个bytebuffer读取,capcity要设置的足够大，不然如果文件太大，会导致复制的内容不完整
            ByteBuffer byteBuffer1 = ByteBuffer.allocate(1024);
            ByteBuffer byteBuffer2 = ByteBuffer.allocate(1024);
            ByteBuffer byteBuffer3 = ByteBuffer.allocate(10240);
            ByteBuffer[] bbs = new ByteBuffer[]{byteBuffer1,byteBuffer2,byteBuffer3};

            inChannel.read(bbs);// 分散读取

            // 切换为写入模式
            for (int i = 0; i &lt; bbs.length; i++) {
                bbs[i].flip();
            }

            outChannel.write(bbs);

        } catch (Exception ex) {
            ex.printStackTrace();
        }
    }
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[服务器变慢诊断命令]]></title>
        <id>https://tinaxiawuhao.github.io/post/Um55sd5Z3/</id>
        <link href="https://tinaxiawuhao.github.io/post/Um55sd5Z3/">
        </link>
        <updated>2021-09-15T06:59:00.000Z</updated>
        <content type="html"><![CDATA[<h3 id="top命令详解">top命令详解</h3>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1631692082043.png" alt="" loading="lazy"></figure>
<p><strong>第一行，任务队列信息，同 uptime 命令的执行结果</strong></p>
<blockquote>
<p>系统时间：07:27:05</p>
<p>运行时间：up 1:57 min,</p>
<p>当前登录用户： 3 user</p>
<p>负载均衡(uptime) load average: 0.00, 0.00, 0.00</p>
<p>average后面的三个数分别是1分钟、5分钟、15分钟的负载情况。</p>
<p>load average数据是每隔5秒钟检查一次活跃的进程数，然后按特定算法计算出的数值。如果这个数除以逻辑CPU的数量，结果高于5的时候就表明系统在超负荷运转了</p>
</blockquote>
<p><strong>第二行，Tasks — 任务（进程）</strong></p>
<blockquote>
<p>总进程:150 total, 运行:1 running, 休眠:149 sleeping, 停止: 0 stopped, 僵尸进程: 0 zombie</p>
</blockquote>
<p><strong>第三行，cpu状态信息</strong></p>
<blockquote>
<p>0.0%us【user space】— 用户空间占用CPU的百分比。</p>
<p>0.3%sy【sysctl】— 内核空间占用CPU的百分比。</p>
<p>0.0%ni【】— 改变过优先级的进程占用CPU的百分比</p>
<p>99.7%id【idolt】— 空闲CPU百分比</p>
<p>0.0%wa【wait】— IO等待占用CPU的百分比</p>
<p>0.0%hi【Hardware IRQ】— 硬中断占用CPU的百分比</p>
<p>0.0%si【Software Interrupts】— 软中断占用CPU的百分比</p>
</blockquote>
<p><strong>第四行,内存状态</strong></p>
<blockquote>
<p>1003020k total,  234464k used,  777824k free,  24084k buffers【缓存的内存量】</p>
</blockquote>
<p><strong>第五行，swap交换分区信息</strong></p>
<blockquote>
<p>2031612k total,   536k used, 2031076k free,  505864k cached【缓冲的交换区总量】</p>
</blockquote>
<blockquote>
<p>备注：</p>
<p>可用内存=free + buffer + cached</p>
<p>对于内存监控，在top里我们要时刻监控第五行swap交换分区的used，如果这个数值在不断的变化，说明内核在不断进行内存和swap的数据交换，这是真正的内存不够用了。</p>
<p>第四行中使用中的内存总量（used）指的是现在系统内核控制的内存数，</p>
<p>第四行中空闲内存总量（free）是内核还未纳入其管控范围的数量。</p>
<p>纳入内核管理的内存不见得都在使用中，还包括过去使用过的现在可以被重复利用的内存，内核并不把这些可被重新使用的内存交还到free中去，因此在linux上free内存会越来越少，但不用为此担心。</p>
</blockquote>
<p><strong>第六行，空行</strong></p>
<p><strong>第七行以下：各进程（任务）的状态监控</strong></p>
<blockquote>
<p>PID — 进程id<br>
USER — 进程所有者<br>
PR — 进程优先级<br>
NI — nice值。负值表示高优先级，正值表示低优先级<br>
VIRT — 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES<br>
RES — 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA<br>
SHR — 共享内存大小，单位kb<br>
S —进程状态。D=不可中断的睡眠状态 R=运行 S=睡眠 T=跟踪/停止 Z=僵尸进程<br>
%CPU — 上次更新到现在的CPU时间占用百分比<br>
%MEM — 进程使用的物理内存百分比<br>
TIME+ — 进程使用的CPU时间总计，单位1/100秒<br>
COMMAND — 进程名称（命令名/命令行）</p>
</blockquote>
<p><strong>详解</strong></p>
<blockquote>
<p>**VIRT：virtual memory usage 虚拟内存<br>
**1、进程“需要的”虚拟内存大小，包括进程使用的库、代码、数据等<br>
2、假如进程申请100m的内存，但实际只使用了10m，那么它会增长100m，而不是实际的使用量</p>
<p><strong>RES：resident memory usage 常驻内存</strong><br>
1、进程当前使用的内存大小，但不包括swap out<br>
2、包含其他进程的共享<br>
3、如果申请100m的内存，实际使用10m，它只增长10m，与VIRT相反<br>
4、关于库占用内存的情况，它只统计加载的库文件所占内存大小</p>
<p><strong>SHR：shared memory 共享内存</strong><br>
1、除了自身进程的共享内存，也包括其他进程的共享内存<br>
2、虽然进程只使用了几个共享库的函数，但它包含了整个共享库的大小<br>
3、计算某个进程所占的物理内存大小公式：RES – SHR<br>
4、swap out后，它将会降下来</p>
<p><strong>DATA</strong><br>
1、数据占用的内存。如果top没有显示，按f键可以显示出来。<br>
2、真正的该程序要求的数据空间，是真正在运行中要使用的。</p>
<p><strong>top 运行中可以通过 top 的内部命令对进程的显示方式进行控制。内部命令如下：</strong><br>
s – 改变画面更新频率<br>
l – 关闭或开启第一部分第一行 top 信息的表示<br>
t – 关闭或开启第一部分第二行 Tasks 和第三行 Cpus 信息的表示<br>
m – 关闭或开启第一部分第四行 Mem 和 第五行 Swap 信息的表示<br>
N – 以 PID 的大小的顺序排列表示进程列表<br>
P – 以 CPU 占用率大小的顺序排列进程列表<br>
M – 以内存占用率大小的顺序排列进程列表<br>
h – 显示帮助<br>
n – 设置在进程列表所显示进程的数量<br>
q – 退出 top<br>
s – 改变画面更新周期</p>
</blockquote>
<h3 id="vmstat命令详解">vmstat命令详解</h3>
<p>vmstat命令是最常见的Linux/Unix监控工具，可以展现给定时间间隔的服务器的状态值,包括服务器的CPU使用率，内存使用，虚拟内存交换情况,IO读写情况。这个命令是我查看Linux/Unix最喜爱的命令，一个是Linux/Unix都支持，二是相比top，我可以看到整个机器的CPU,内存,IO的使用情况，而不是单单看到各个进程的CPU使用率和内存使用率(使用场景不一样)。</p>
<p>一般vmstat工具的使用是通过两个数字参数来完成的，第一个参数是采样的时间间隔数，单位是秒，第二个参数是采样的次数，如:</p>
<pre><code>root@ubuntu:~# vmstat 2 1
procs -----------memory---------- ---swap-- -----io---- -system-- ----cpu----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa
 1  0      0 3498472 315836 3819540    0    0     0     1    2    0  0  0 100  0
</code></pre>
<p>2表示每个两秒采集一次服务器状态，1表示只采集一次。</p>
<p>实际上，在应用过程中，我们会在一段时间内一直监控，不想监控直接结束vmstat就行了,例如:</p>
<pre><code>root@ubuntu:~# vmstat 2  
procs -----------memory---------- ---swap-- -----io---- -system-- ----cpu----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa
 1  0      0 3499840 315836 3819660    0    0     0     1    2    0  0  0 100  0
 0  0      0 3499584 315836 3819660    0    0     0     0   88  158  0  0 100  0
 0  0      0 3499708 315836 3819660    0    0     0     2   86  162  0  0 100  0
 0  0      0 3499708 315836 3819660    0    0     0    10   81  151  0  0 100  0
 1  0      0 3499732 315836 3819660    0    0     0     2   83  154  0  0 100  0
</code></pre>
<p>这表示vmstat每2秒采集数据，一直采集，直到我结束程序，这里采集了5次数据我就结束了程序。</p>
<p><strong>参数详解</strong></p>
<blockquote>
<p><strong>r</strong> 表示运行队列(就是说多少个进程真的分配到CPU)，我测试的服务器目前CPU比较空闲，没什么程序在跑，当这个值超过了CPU数目，就会出现CPU瓶颈了。这个也和top的负载有关系，一般负载超过了3就比较高，超过了5就高，超过了10就不正常了，服务器的状态很危险。top的负载类似每秒的运行队列。如果运行队列过大，表示你的CPU很繁忙，一般会造成CPU使用率很高。</p>
<p><strong>b</strong> 表示阻塞的进程,这个不多说，进程阻塞，大家懂的。</p>
<p><strong>swpd</strong> 虚拟内存已使用的大小，如果大于0，表示你的机器物理内存不足了，如果不是程序内存泄露的原因，那么你该升级内存了或者把耗内存的任务迁移到其他机器。</p>
<p><strong>free</strong>  空闲的物理内存的大小，我的机器内存总共8G，剩余3415M。</p>
<p><strong>buff</strong>  Linux/Unix系统是用来存储，目录里面有什么内容，权限等的缓存，我本机大概占用300多M</p>
<p><strong>cache</strong> cache直接用来记忆我们打开的文件,给文件做缓冲，我本机大概占用300多M(这里是Linux/Unix的聪明之处，把空闲的物理内存的一部分拿来做文件和目录的缓存，是为了提高 程序执行的性能，当程序使用内存时，buffer/cached会很快地被使用。)</p>
<p><strong>si</strong> 每秒从磁盘读入虚拟内存的大小，如果这个值大于0，表示物理内存不够用或者内存泄露了，要查找耗内存进程解决掉。我的机器内存充裕，一切正常。</p>
<p><strong>so</strong> 每秒虚拟内存写入磁盘的大小，如果这个值大于0，同上。</p>
<p><strong>bi</strong> 块设备每秒接收的块数量，这里的块设备是指系统上所有的磁盘和其他块设备，默认块大小是1024byte，我本机上没什么IO操作，所以一直是0，但是我曾在处理拷贝大量数据(2-3T)的机器上看过可以达到140000/s，磁盘写入速度差不多140M每秒</p>
<p><strong>bo</strong> 块设备每秒发送的块数量，例如我们读取文件，bo就要大于0。bi和bo一般都要接近0，不然就是IO过于频繁，需要调整。</p>
<p><strong>in</strong> 每秒CPU的中断次数，包括时间中断</p>
<p><strong>cs</strong> 每秒上下文切换次数，例如我们调用系统函数，就要进行上下文切换，线程的切换，也要进程上下文切换，这个值要越小越好，太大了，要考虑调低线程或者进程的数目,例如在apache和nginx这种web服务器中，我们一般做性能测试时会进行几千并发甚至几万并发的测试，选择web服务器的进程可以由进程或者线程的峰值一直下调，压测，直到cs到一个比较小的值，这个进程和线程数就是比较合适的值了。系统调用也是，每次调用系统函数，我们的代码就会进入内核空间，导致上下文切换，这个是很耗资源，也要尽量避免频繁调用系统函数。上下文切换次数过多表示你的CPU大部分浪费在上下文切换，导致CPU干正经事的时间少了，CPU没有充分利用，是不可取的。</p>
<p><strong>us</strong> 用户CPU时间，我曾经在一个做加密解密很频繁的服务器上，可以看到us接近100,r运行队列达到80(机器在做压力测试，性能表现不佳)。</p>
<p><strong>sy</strong> 系统CPU时间，如果太高，表示系统调用时间长，例如是IO操作频繁。</p>
<p><strong>id</strong> 空闲 CPU时间，一般来说，id + us + sy = 100,一般我认为id是空闲CPU使用率，us是用户CPU使用率，sy是系统CPU使用率。</p>
<p><strong>wt</strong> 等待IO CPU时间。</p>
</blockquote>
<h3 id="pid命令详解">pid命令详解</h3>
<p>pidstat是sysstat工具的一个命令，用于监控全部或指定进程的cpu、内存、线程、设备IO等系统资源的占用情况。pidstat首次运行时显示自系统启动开始的各项统计信息，之后运行pidstat将显示自上次运行该命令以后的统计信息。用户可以通过指定统计的次数和时间来获得所需的统计信息。</p>
<p>pidstat 的用法：</p>
<pre><code>pidstat [ 选项 ] [ &lt;时间间隔&gt; ] [ &lt;次数&gt; ]
</code></pre>
<p>如下图：</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1631692116794.png" alt="" loading="lazy"></figure>
<p><strong>常用的参数：</strong></p>
<ul>
<li>-u：默认的参数，显示各个进程的cpu使用统计</li>
<li>-r：显示各个进程的内存使用统计</li>
<li>-d：显示各个进程的IO使用情况</li>
<li>-p：指定进程号</li>
<li>-w：显示每个进程的上下文切换情况</li>
<li>-t：显示选择任务的线程的统计信息外的额外信息</li>
<li>-T { TASK | CHILD | ALL }<br>
这个选项指定了pidstat监控的。TASK表示报告独立的task，CHILD关键字表示报告进程下所有线程统计信息。ALL表示报告独立的task和task下面的所有线程。<br>
注意：task和子线程的全局的统计信息和pidstat选项无关。这些统计信息不会对应到当前的统计间隔，这些统计信息只有在子线程kill或者完成的时候才会被收集。</li>
<li>-V：版本号</li>
<li>-h：在一行上显示了所有活动，这样其他程序可以容易解析。</li>
<li>-I：在SMP环境，表示任务的CPU使用率/内核数量</li>
<li>-l：显示命令名和所有参数</li>
</ul>
<pre><code>pidstat
pidstat -u -p ALL
</code></pre>
<p>pidstat 和 pidstat -u -p ALL 是等效的。<br>
pidstat 默认显示了所有进程的cpu使用率。</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1631692161313.png" alt="" loading="lazy"></figure>
<p><strong>参数详解</strong></p>
<ul>
<li>
<p>PID：进程ID</p>
</li>
<li>
<p>%usr：进程在用户空间占用cpu的百分比</p>
</li>
<li>
<p>%system：进程在内核空间占用cpu的百分比</p>
</li>
<li>
<p>%guest：进程在虚拟机占用cpu的百分比</p>
</li>
<li>
<p>%CPU：进程占用cpu的百分比</p>
</li>
<li>
<p>CPU：处理进程的cpu编号</p>
</li>
<li>
<p>Command：当前进程对应的命令</p>
</li>
</ul>
<h3 id="free命令详解">free命令详解</h3>
<p>free 命令显示系统内存的使用情况，包括物理内存、交换内存(swap)和内核缓冲区内存。</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1631692175318.png" alt="" loading="lazy"></figure>
<p>如果加上 -h 选项，输出的结果会友好很多：</p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1631692195242.png" alt="" loading="lazy"></figure>
<p>有时我们需要持续的观察内存的状况，此时可以使用 -s 选项并指定间隔的秒数：</p>
<pre><code>$ free -h -s 3
</code></pre>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1631692210174.png" alt="" loading="lazy"></figure>
<p>上面的命令每隔 3 秒输出一次内存的使用情况，直到你按下 ctrl + c。</p>
<p>由于 free 命令本身比较简单，所以本文的重点会放在如何通过 free 命令了解系统当前的内存使用状况。</p>
<p><strong>输出说明</strong><br>
<strong>Mem</strong> 行(第二行)是内存的使用情况。<br>
<strong>Swap</strong> 行(第三行)是交换空间的使用情况。<br>
<strong>total</strong> 列显示系统总的可用物理内存和交换空间大小。<br>
<strong>used</strong> 列显示已经被使用的物理内存和交换空间。<br>
<strong>free</strong> 列显示还有多少物理内存和交换空间可用使用。<br>
<strong>shared</strong> 列显示被共享使用的物理内存大小。<br>
<strong>buff/cache</strong> 列显示被 buffer 和 cache 使用的物理内存大小。<br>
<strong>available</strong> 列显示还可以被应用程序使用的物理内存大小。</p>
<h3 id="df命令详解">df命令详解</h3>
<p>Linux df（英文全拼：disk free） 命令用于显示目前在 Linux 系统上的文件系统磁盘使用情况统计。</p>
<p><strong>语法</strong></p>
<pre><code>df [选项]... [FILE]...
</code></pre>
<ul>
<li>文件-a, --all 包含所有的具有 0 Blocks 的文件系统</li>
<li>文件--block-size={SIZE} 使用 {SIZE} 大小的 Blocks</li>
<li>文件-h, --human-readable 使用人类可读的格式(预设值是不加这个选项的...)</li>
<li>文件-H, --si 很像 -h, 但是用 1000 为单位而不是用 1024</li>
<li>文件-i, --inodes 列出 inode 资讯，不列出已使用 block</li>
<li>文件-k, --kilobytes 就像是 --block-size=1024</li>
<li>文件-l, --local 限制列出的文件结构</li>
<li>文件-m, --megabytes 就像 --block-size=1048576</li>
<li>文件--no-sync 取得资讯前不 sync (预设值)</li>
<li>文件-P, --portability 使用 POSIX 输出格式</li>
<li>文件--sync 在取得资讯前 sync</li>
<li>文件-t, --type=TYPE 限制列出文件系统的 TYPE</li>
<li>文件-T, --print-type 显示文件系统的形式</li>
<li>文件-x, --exclude-type=TYPE 限制列出文件系统不要显示 TYPE</li>
<li>文件-v (忽略)</li>
<li>文件--help 显示这个帮手并且离开</li>
<li>文件--version 输出版本资讯并且离开</li>
</ul>
<p><strong>实例</strong></p>
<p>显示文件系统的磁盘使用情况统计：</p>
<pre><code># df 
Filesystem     1K-blocks    Used     Available Use% Mounted on 
/dev/sda6       29640780 4320704     23814388  16%     / 
udev             1536756       4     1536752    1%     /dev 
tmpfs             617620     888     616732     1%     /run 
none                5120       0     5120       0%     /run/lock 
none             1544044     156     1543888    1%     /run/shm 
</code></pre>
<p>第一列指定文件系统的名称，第二列指定一个特定的文件系统1K-块1K是1024字节为单位的总内存。用和可用列正在使用中，分别指定的内存量。</p>
<p>使用列指定使用的内存的百分比，而最后一栏&quot;安装在&quot;指定的文件系统的挂载点。</p>
<p>df也可以显示磁盘使用的文件系统信息：</p>
<pre><code># df test 
Filesystem     1K-blocks    Used      Available Use% Mounted on 
/dev/sda6       29640780    4320600   23814492  16%       / 
</code></pre>
<p>用一个-i选项的df命令的输出显示inode信息而非块使用量。</p>
<pre><code>df -i 
Filesystem      Inodes    IUsed    IFree     IUse% Mounted on 
/dev/sda6      1884160    261964   1622196   14%        / 
udev           212748     560      212188    1%         /dev 
tmpfs          216392     477      215915    1%         /run 
none           216392     3        216389    1%         /run/lock 
none           216392     8        216384    1%         /run/shm 
</code></pre>
<p>显示所有的信息:</p>
<pre><code># df --total 
Filesystem     1K-blocks    Used    Available Use% Mounted on 
/dev/sda6       29640780 4320720    23814372  16%     / 
udev             1536756       4    1536752   1%      /dev 
tmpfs             617620     892    616728    1%      /run 
none                5120       0    5120      0%      /run/lock 
none             1544044     156    1543888   1%      /run/shm 
total           33344320 4321772    27516860  14% 
</code></pre>
<p>我们看到输出的末尾，包含一个额外的行，显示总的每一列。</p>
<p>-h选项，通过它可以产生可读的格式df命令的输出：</p>
<pre><code># df -h 
Filesystem      Size  Used   Avail Use% Mounted on 
/dev/sda6       29G   4.2G   23G   16%     / 
udev            1.5G  4.0K   1.5G   1%     /dev 
tmpfs           604M  892K   603M   1%     /run 
none            5.0M     0   5.0M   0%     /run/lock 
none            1.5G  156K   1.5G   1%     /run/shm 
</code></pre>
<p>我们可以看到输出显示的数字形式的'G'（千兆字节），&quot;M&quot;（兆字节）和&quot;K&quot;（千字节）。</p>
<p>这使输出容易阅读和理解，从而使显示可读的。请注意，第二列的名称也发生了变化，为了使显示可读的&quot;大小&quot;。</p>
<h3 id="iostat命令详解">iostat命令详解</h3>
<p>用法：iostat [ 选项 ] [ &lt;时间间隔&gt; [ &lt;次数&gt; ]]</p>
<p>常用选项说明：</p>
<pre><code>-c：只显示系统CPU统计信息，即单独输出avg-cpu结果，不包括device结果
-d：单独输出Device结果，不包括cpu结果
-k/-m：输出结果以kB/mB为单位，而不是以扇区数为单位
-x:输出更详细的io设备统计信息
interval/count：每次输出间隔时间，count表示输出次数，不带count表示循环输出
</code></pre>
<p>说明：更多选项使用使用man iostat查看</p>
<p><strong>实例</strong></p>
<p>1、iostat，结果为从系统开机到当前执行时刻的统计信息</p>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1631692226555.png" alt="" loading="lazy"></figure>
<p>输出含义：</p>
<p>avg-cpu: 总体cpu使用情况统计信息，对于多核cpu，这里为所有cpu的平均值。重点关注iowait值，表示CPU用于等待io请求的完成时间。</p>
<p>Device: 各磁盘设备的IO统计信息。各列含义如下：</p>
<pre><code>Device: 以sdX形式显示的设备名称
tps: 每秒进程下发的IO读、写请求数量
KB_read/s: 每秒从驱动器读入的数据量，单位为K。
KB_wrtn/s: 每秒从驱动器写入的数据量，单位为K。
KB_read: 读入数据总量，单位为K。
KB_wrtn: 写入数据总量，单位为K。
</code></pre>
<p>2、iostat -x -k -d 1 2。每隔1S输出磁盘IO的详细详细，总共采样2次。</p>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1631692235192.png" alt="" loading="lazy"></figure>
<p>以上各列的含义如下：</p>
<pre><code>rrqm/s: 每秒对该设备的读请求被合并次数，文件系统会对读取同块(block)的请求进行合并
wrqm/s: 每秒对该设备的写请求被合并次数
r/s: 每秒完成的读次数
w/s: 每秒完成的写次数
rkB/s: 每秒读数据量(kB为单位)
wkB/s: 每秒写数据量(kB为单位)
avgrq-sz:平均每次IO操作的数据量(扇区数为单位)
avgqu-sz: 平均等待处理的IO请求队列长度
await: 平均每次IO请求等待时间(包括等待时间和处理时间，毫秒为单位)
svctm: 平均每次IO请求的处理时间(毫秒为单位)
%util: 采用周期内用于IO操作的时间比率，即IO队列非空的时间比率
</code></pre>
<p>重点关注参数</p>
<blockquote>
<p>1、iowait% 表示CPU等待IO时间占整个CPU周期的百分比，如果iowait值超过50%，或者明显大于%system、%user以及%idle，表示IO可能存在问题。</p>
<p>2、avgqu-sz 表示磁盘IO队列长度，即IO等待个数。</p>
<p>3、await 表示每次IO请求等待时间，包括等待时间和处理时间</p>
<p>4、svctm 表示每次IO请求处理的时间</p>
<p>5、%util 表示磁盘忙碌情况，一般该值超过80%表示该磁盘可能处于繁忙状态。</p>
</blockquote>
<h3 id="ifstat命令详解">ifstat命令详解</h3>
<p>统计网络接口流量状态</p>
<p>下载</p>
<pre><code class="language-shell">wget http://gael.roualland.free.fr/ifstat/ifstat-1.1.tar.gz
</code></pre>
<p>编译安装</p>
<pre><code class="language-shell">tar -zxvf ifstat-1.1.tar.gz
cd ifstat-1.1
./configure            
make
make install # 默认会安装到/usr/local/bin/目录中
</code></pre>
<p><code>注释</code>：执行which ifstat输出/usr/local/bin/ifstat</p>
<p>选项</p>
<blockquote>
<p>-l 监测环路网络接口（lo）。缺省情况下，ifstat监测活动的所有非环路网络接口。经使用发现，加上-l参数能监测所有的网络接口的信息，而不是只监测 lo的接口信息，也就是说，加上-l参数比不加-l参数会多一个lo接口的状态信息。<br>
-a 监测能检测到的所有网络接口的状态信息。使用发现，比加上-l参数还多一个plip0的接口信息，搜索一下发现这是并口（网络设备中有一 个叫PLIP (Parallel Line Internet Protocol). 它提供了并口...）<br>
-z 隐藏流量是无的接口，例如那些接口虽然启动了但是未用的<br>
-i 指定要监测的接口,后面跟网络接口名<br>
-s 等于加-d snmp:[comm@][#]host[/nn]] 参数，通过SNMP查询一个远程主机<br>
-h 显示简短的帮助信息<br>
-n 关闭显示周期性出现的头部信息（也就是说，不加-n参数运行ifstat时最顶部会出现网络接口的名称，当一屏显示不下时，会再一次出现接口的名称，提示我们显示的流量信息具体是哪个网络接口的。加上-n参数把周期性的显示接口名称关闭，只显示一次）<br>
-t 在每一行的开头加一个时间 戳（能告诉我们具体的时间）<br>
-T 报告所有监测接口的全部带宽（最后一列有个total，显示所有的接口的in流量和所有接口的out流量，简单的把所有接口的in流量相加,out流量相 加）<br>
-w  用指定的列宽，而不是为了适应接口名称的长度而去自动放大列宽<br>
-W 如果内容比终端窗口的宽度还要宽就自动换行<br>
-S 在同一行保持状态更新（不滚动不换行）注：如果不喜欢屏幕滚动则此项非常方便，与bmon的显示方式类似<br>
-b 用kbits/s显示带宽而不是kbytes/s<br>
-q 安静模式，警告信息不出现<br>
-v 显示版本信息<br>
-d 指定一个驱动来收集状态信息</p>
</blockquote>
<p><strong>实例</strong><br>
默认使用</p>
<pre><code class="language-shell"> #ifstat
       eth0                eth1       
 KB/s in  KB/s out   KB/s in  KB/s out
    0.07      0.20      0.00      0.00
    0.07      0.15      0.58      0.00
</code></pre>
<p>默认ifstat不监控回环接口，显示的流量单位是KB。</p>
<pre><code class="language-shell">ifstat -tT
  time           eth0                eth1                eth2                eth3               Total      
HH:MM:ss   KB/s in  KB/s out   KB/s in  KB/s out   KB/s in  KB/s out   KB/s in  KB/s out   KB/s in  KB/s out
16:53:04      0.84      0.62   1256.27   1173.05      0.12      0.18      0.00      0.00   1257.22   1173.86
16:53:05      0.57      0.40      0.57      0.76      0.00      0.00      0.00      0.00      1.14      1.17
16:53:06      1.58      0.71      0.42      0.78      0.00      0.00      0.00      0.00      2.01      1.48
16:53:07      0.57      0.40      1.91      2.61      0.00      0.00      0.00      0.00      2.48      3.01
16:53:08      0.73      0.40    924.02   1248.91      0.00      0.00      0.00      0.00    924.76   1249.31
</code></pre>
<p>监控所有网络接口</p>
<pre><code class="language-shell">ifstat -a
        lo                 eth0                eth1       
 KB/s in  KB/s out   KB/s in  KB/s out   KB/s in  KB/s out
    0.00      0.00      0.28      0.58      0.06      0.06
    0.00      0.00      1.41      1.13      0.00      0.00
    0.61      0.61      0.26      0.23      0.00      0.00
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[CAS/ABA/AtomicReference]]></title>
        <id>https://tinaxiawuhao.github.io/post/2nzKhQbUe/</id>
        <link href="https://tinaxiawuhao.github.io/post/2nzKhQbUe/">
        </link>
        <updated>2021-09-13T03:27:29.000Z</updated>
        <content type="html"><![CDATA[<p>锁是用来做并发最简单的方式，当然代价也是最高的。</p>
<p>独占锁是一种悲观锁，synchronized就是一种独占锁；它假设最坏的情况，并且只有在确保其它线程不会造成干扰的情况下执行，会导致其它所有需要锁的线程挂起直到持有锁的线程释放锁。</p>
<p>所谓乐观锁就是每次不加锁,假设没有冲突而去完成某项操作;如果发生冲突了那就去重试，直到成功为止。</p>
<p>CAS(Compare And Swap)是一种有名的无锁算法。CAS算法是乐观锁的一种实现。CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B并返回true，否则返回false。</p>
<blockquote>
<p>注:synchronized和ReentrantLock都是悲观锁。</p>
</blockquote>
<blockquote>
<p>注:什么时候使用悲观锁效率更高、什么使用使用乐观锁效率更高，要根据实际情况来判断选择。</p>
</blockquote>
<p>提示:atomic中包下的类，采用的即为CAS乐观算法。</p>
<p>以AtomicInteger的public final int getAndSet(int newValue)方法，进行简单说明，<br>
该方法是这样的:</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1631512353549.png" alt="" loading="lazy"></figure>
<p>其调用了Unsafe类的public final int getAndSetInt(Object var1, long var2, int var4)方法:</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1631512364454.png" alt="" loading="lazy"></figure>
<p>而该方法又do{…}while(…)循环调用了本地方法public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5);</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1631512374405.png" alt="" loading="lazy"></figure>
<p>注:至于Windows/Linux下public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5)本地方法是如何实现的，推荐阅读https://blog.csdn.net/v123411739/article/details/79561458。</p>
<p><strong>CAS(Compare And Swap)原理简述：</strong></p>
<pre><code>   某一线程执行一个CAS逻辑(如上图线程A),如果中途有其他线程修改了共享变量的值(如:上图中线程A执行到笑脸那一刻时),导致这个线程的CAS逻辑运算后得到的值与期望结果不一致，那么这个线程会再次执行CAS逻辑(这里是一个do while循环),直到成功为止。
</code></pre>
<p><strong>ABA问题：</strong></p>
<pre><code>  就是说一个线程把数据A变为了B，然后又重新变成了A。此时另外一个线程读取的时候，发现A没有变化，就误以为是原来的那个A。这就是有名的ABA问题。
</code></pre>
<blockquote>
<p>注:根据实际情况，判断是否处理ABA问题。如果ABA问题并不会影响我们的业务结果，可以选择性处理或不处理;如果<br>
ABA会影响我们的业务结果的，这时就必须处理ABA问题了。<br>
追注:对于AtomicInteger等,没有什么可修改的属性;且我们只在意其结果值，所以对于这些类来说，本身就算发生了ABA现象，也不会对原线程的结果造成什么影响。</p>
</blockquote>
<p>AtomicReference原子应用类，可以保证你在修改对象引用时的线程安全性，比较时可以按照偏移量进行<br>
怎样使用AtomicReference：</p>
<pre><code class="language-java">AtomicReference&lt;String&gt; ar = new AtomicReference&lt;String&gt;();
ar.set(&quot;hello&quot;);
//CAS操作更新
ar.compareAndSet(&quot;hello&quot;, &quot;hello1&quot;);
</code></pre>
<p>AtomicReference的成员变量：</p>
<pre><code class="language-java">private static final long serialVersionUID = -1848883965231344442L;
//unsafe类,提供cas操作的功能
private static final Unsafe unsafe = Unsafe.getUnsafe();
//value变量的偏移地址,说的就是下面那个value,这个偏移地址在static块里初始化
private static final long valueOffset;
//实际传入需要原子操作的那个类实例
private volatile V value;
</code></pre>
<p>类装载的时候初始化偏移地址：</p>
<pre><code class="language-java">static {
        try {
            valueOffset = unsafe.objectFieldOffset
                (AtomicReference.class.getDeclaredField(&quot;value&quot;));
        } catch (Exception ex) { throw new Error(ex); }
    }
</code></pre>
<p>compareAndSet方法：</p>
<pre><code class="language-java">//就是调用Unsafe的cas操作,传入对象,expect值,偏移地址,需要更新的值,即可,如果更新成功,返回true,如果失败,返回false
public final boolean compareAndSet(V expect, V update) {
        return unsafe.compareAndSwapObject(this, valueOffset, expect, update);
    }
</code></pre>
<p>对于String变量来说,必须是对象相同才视为相同,而不是字符串的内容相同就可以相同:</p>
<pre><code class="language-java">AtomicReference&lt;String&gt; ar = new AtomicReference&lt;String&gt;();
ar.set(&quot;hello&quot;);
System.out.println(ar.compareAndSet(new String(&quot;hello&quot;), &quot;hello1&quot;));//false
</code></pre>
<p>AtomicReference可解决volatile不具有原子性i++操作<br>
AtomicReference可以保证结果是正确的.</p>
<pre><code class="language-java">private static volatile Integer num1 = 0;
private static AtomicReference&lt;Integer&gt; ar=new AtomicReference&lt;Integer&gt;(num1);

public void dfasd111() throws InterruptedException{
    for (int i = 0; i &lt; 1000; i++) {
        new Thread(new Runnable(){
            @Override
            public void run() {
                for (int i = 0; i &lt; 10000; i++)
                    while(true){
                        Integer temp=ar.get();
                        if(ar.compareAndSet(temp, temp+1))break;
                    }
            }       
        }).start();
    }
    Thread.sleep(10000);
    System.out.println(ar.get()); //10000000
}
</code></pre>
<p>类似i++这样的&quot;读-改-写&quot;复合操作(在一个操作序列中, 后一个操作依赖前一次操作的结果), 在多线程并发处理的时候会出现问题, 因为可能一个线程修改了变量, 而另一个线程没有察觉到这样变化, 当使用原子变量之后, 则将一系列的复合操作合并为一个原子操作,从而避免这种问题, i++=&gt;i.incrementAndGet()</p>
<p>这里的compareAndSet方法即cas操作本身是原子的，但是在某些场景下会出现异常场景</p>
<p>此处说一下ABA问题：</p>
<p>比如，我们只是简单得要做一个数值加法，即使在我取得期望值后，这个数字被不断的修改，只要它最终改回了我的期望值，我的加法计算就不会出错。也就是说，当你修改的对象没有过程的状态信息，所有的信息都只保存于对象的数值本身。</p>
<p>但是，在现实中，还可能存在另外一种场景。就是我们是否能修改对象的值，不仅取决于当前值，还和对象的过程变化有关，这时，AtomicReference就无能为力了。</p>
<p><strong>AtomicStampedReference与AtomicReference的区别：</strong><br>
AtomicStampedReference它内部不仅维护了对象值，还维护了一个时间戳（我这里把它称为时间戳，实际上它可以使任何一个整数，它使用整数来表示状态值）。当AtomicStampedReference对应的数值被修改时，除了更新数据本身外，还必须要更新时间戳。当AtomicStampedReference设置对象值时，对象值以及时间戳都必须满足期望值，写入才会成功。因此，即使对象值被反复读写，写回原值，只要时间戳发生变化，就能防止不恰当的写入。</p>
<p><strong>解决ABA问题</strong></p>
<pre><code class="language-java">
public static void main(String[] args) {
 
        String str1 = &quot;aaa&quot;;
        String str2 = &quot;bbb&quot;;
        AtomicStampedReference&lt;String&gt; reference = new AtomicStampedReference&lt;String&gt;(str1,1);
        reference.compareAndSet(str1,str2,reference.getStamp(),reference.getStamp()+1);
        System.out.println(&quot;reference.getReference() = &quot; + reference.getReference());
 
        boolean b = reference.attemptStamp(str2, reference.getStamp() + 1);
        System.out.println(&quot;b: &quot;+b);
        System.out.println(&quot;reference.getStamp() = &quot;+reference.getStamp());
 
        boolean c = reference.weakCompareAndSet(str2,&quot;ccc&quot;,4, reference.getStamp()+1);
        System.out.println(&quot;reference.getReference() = &quot;+reference.getReference());
        System.out.println(&quot;c = &quot; + c);
    }
 
输出:
reference.getReference() = bbb
b: true
reference.getStamp() = 3
reference.getReference() = bbb
c = false
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[代理模式]]></title>
        <id>https://tinaxiawuhao.github.io/post/CO5c8R39E/</id>
        <link href="https://tinaxiawuhao.github.io/post/CO5c8R39E/">
        </link>
        <updated>2021-09-13T03:18:02.000Z</updated>
        <content type="html"><![CDATA[<p>静态代理、JDK动态代理以及CGLIB动态代理<br>
代理模式是java中最常用的设计模式之一，尤其是在spring框架中广泛应用。对于java的代理模式，一般可分为：静态代理、动态代理、以及CGLIB实现动态代理。<br>
对于上述三种代理模式，分别进行说明。</p>
<h2 id="静态代理">静态代理</h2>
<p>静态代理其实就是在程序运行之前，提前写好被代理方法的代理类，编译后运行。在程序运行之前，class已经存在。<br>
下面我们实现一个静态代理demo:</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1634527030816.png" alt="" loading="lazy"></figure>
<p>定义一个接口Target</p>
<pre><code class="language-java">package com.test.proxy;

public interface Target {

    public String execute();

}
</code></pre>
<p>TargetImpl 实现接口Target</p>
<pre><code class="language-java">package com.test.proxy;

public class TargetImpl implements Target {

    @Override
    public String execute() {
        System.out.println(&quot;TargetImpl execute！&quot;);
        return &quot;execute&quot;;
    }

}
</code></pre>
<p>代理类</p>
<pre><code class="language-java">package com.test.proxy;

public class Proxy implements Target{

    private Target target;
    
    public Proxy(Target target) {
        this.target = target;
    }
    
    @Override
    public String execute() {
        System.out.println(&quot;perProcess&quot;);
        String result = this.target.execute();
        System.out.println(&quot;postProcess&quot;);
        return result;
    }

}
</code></pre>
<p>测试类:</p>
<pre><code class="language-java">package com.test.proxy;

public class ProxyTest {

    public static void main(String[] args) {
    
        Target target = new TargetImpl();
        Proxy p = new Proxy(target);
        String result =  p.execute();
        System.out.println(result);
    }

}
</code></pre>
<p>运行结果:</p>
<blockquote>
<p>perProcess<br>
TargetImpl execute！<br>
postProcess<br>
execute</p>
</blockquote>
<p>静态代理需要针对被代理的方法提前写好代理类，如果被代理的方法非常多则需要编写很多代码，因此，对于上述缺点，通过动态代理的方式进行了弥补。</p>
<h2 id="动态代理">动态代理</h2>
<h3 id="jdk代理">jdk代理</h3>
<p>动态代理主要是通过反射机制，在运行时动态生成所需代理的class.</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1634527039701.png" alt="" loading="lazy"></figure>
<p>接口</p>
<pre><code class="language-java">package com.test.dynamic;

public interface Target {

    public String execute();

}
</code></pre>
<p>实现类</p>
<pre><code class="language-java">package com.test.dynamic;

public class TargetImpl implements Target {

    @Override
    public String execute() {
        System.out.println(&quot;TargetImpl execute！&quot;);
        return &quot;execute&quot;;
    }

}
</code></pre>
<p>代理类</p>
<pre><code class="language-java">package com.test.dynamic;


import java.lang.reflect.InvocationHandler;
import java.lang.reflect.Method;

public class DynamicProxyHandler implements InvocationHandler{

    private Target target;
    
    public DynamicProxyHandler(Target target) {
        this.target = target;
    }
    
    @Override
    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
        System.out.println(&quot;========before==========&quot;);
        Object result = method.invoke(target,args);
        System.out.println(&quot;========after===========&quot;);
        return result;
    }

}
</code></pre>
<p>测试类</p>
<pre><code class="language-java">package com.test.dynamic;

import java.lang.reflect.Proxy;

public class DynamicProxyTest {

    public static void main(String[] args) {
        Target target = new TargetImpl();
        DynamicProxyHandler handler = new DynamicProxyHandler(target);
        Target proxySubject = (Target) Proxy.newProxyInstance(TargetImpl.class.getClassLoader(),TargetImpl.class.getInterfaces(),handler);
        String result = proxySubject.execute();
        System.out.println(result);
    }

}
</code></pre>
<p>运行结果：</p>
<blockquote>
<p><mark><mark><mark><mark>before</mark></mark></mark></mark>==<br>
TargetImpl execute！<br>
<mark><mark><mark><mark>after</mark></mark></mark></mark>===<br>
execute</p>
</blockquote>
<p>无论是动态代理还是静态带领，都需要定义接口，然后才能实现代理功能。这同样存在局限性，因此，为了解决这个问题，出现了第三种代理方式：cglib代理。</p>
<h3 id="cglib代理">cglib代理</h3>
<p>CGLib采用了非常底层的字节码技术，其原理是通过字节码技术为一个类创建子类，并在子类中采用方法拦截的技术拦截所有父类方法的调用，顺势织入横切逻辑。JDK动态代理与CGLib动态代理均是实现Spring AOP的基础。</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1634527048720.png" alt="" loading="lazy"></figure>
<p>目标类</p>
<pre><code class="language-java">package com.test.cglib;

public class Target {

    public String execute() {
        String message = &quot;-----------test------------&quot;;
        System.out.println(message);
        return message;
    }

}
</code></pre>
<p>通用代理类</p>
<pre><code class="language-java">package com.test.cglib;

import net.sf.cglib.proxy.MethodInterceptor;
import net.sf.cglib.proxy.MethodProxy;

import java.lang.reflect.Method;

public class MyMethodInterceptor implements MethodInterceptor{

    @Override
    public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable {
        System.out.println(&quot;&gt;&gt;&gt;&gt;MethodInterceptor start...&quot;);
        Object result = proxy.invokeSuper(obj,args);
        System.out.println(&quot;&gt;&gt;&gt;&gt;MethodInterceptor ending...&quot;);
        return &quot;result&quot;;
    }

}
</code></pre>
<p>测试类</p>
<pre><code class="language-java">package com.test.cglib;

import net.sf.cglib.proxy.Enhancer;

public class CglibTest {

    public static void main(String[] args) {
        System.out.println(&quot;***************&quot;);
        Target target = new Target();
        CglibTest test = new CglibTest();
        Target proxyTarget = (Target) test.createProxy(Target.class);
        String res = proxyTarget.execute();
        System.out.println(res);
    }
    
    public Object createProxy(Class targetClass) {
        Enhancer enhancer = new Enhancer();
        enhancer.setSuperclass(targetClass);
        enhancer.setCallback(new MyMethodInterceptor());
        return enhancer.create();
    }

}
</code></pre>
<p>执行结果:</p>
<hr>
<blockquote>
<p>MethodInterceptor start...<br>
-----------test------------<br>
MethodInterceptor ending...<br>
result</p>
</blockquote>
<p>代理对象的生成过程由Enhancer类实现，大概步骤如下：</p>
<ol>
<li>生成代理类Class的二进制字节码；</li>
<li>通过Class.forName加载二进制字节码，生成Class对象；</li>
<li>通过反射机制获取实例构造，并初始化代理类对象。</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[OOM]]></title>
        <id>https://tinaxiawuhao.github.io/post/QvbaHSogu/</id>
        <link href="https://tinaxiawuhao.github.io/post/QvbaHSogu/">
        </link>
        <updated>2021-09-13T01:54:41.000Z</updated>
        <content type="html"><![CDATA[<h3 id="stack-overflow">Stack overflow</h3>
<pre><code class="language-java">public class StackOverFlowErrorDemo {
    public static void main(String[] args) {
        StackOverFlowError();
    }

    private static void StackOverFlowError() {
        StackOverFlowError();
    }
}
</code></pre>
<pre><code class="language-java">Exception in thread &quot;main&quot; java.lang.StackOverflowError
	at com.example.interview.oom.StackOverFlowErrorDemo.StackOverFlowError(StackOverFlowErrorDemo.java:14)
</code></pre>
<p>递归调用自身方法，不断向栈内压入栈帧，直到撑破栈空间，重复次数不确定</p>
<h3 id="outofmemoryerrorjava-heap-space">OutOfMemoryError：Java heap space</h3>
<pre><code class="language-java">/**
 * @author wuhao
 * @desc -Xmx10m -Xms10m -XX:+PrintGCDetails
 * 最大堆内存10M,初始堆内存10M,打印GC详细信息
 * @date 2021-09-10 15:14:50
 */
public class JavaHeapSpaceDemo {
    public static void main(String[] args) {
//        String str= &quot;java&quot;;
//        while (true){
//            str+=str+new Random().nextInt(111111)+new Random().nextInt(121312);
//            str.intern();
//        }
        //创建大对象
        byte[] bytes=new byte[20*1024*1024];
    }
}
</code></pre>
<pre><code class="language-java">Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space
	at com.example.interview.oom.JavaHeapSpaceDemo.main(JavaHeapSpaceDemo.java:18)
</code></pre>
<p>常量池，对象空间地址位于堆空间中，循环生成String或者生成超大对象会导致堆空间被占满溢出</p>
<h3 id="outofmemoryerrorgc-overhead-limit-exceeded">OutOfMemoryError：GC overhead limit exceeded</h3>
<pre><code class="language-java">/**
 * @author wuhao
 * @desc -Xmx20m -Xms10m -XX:+PrintGCDetails
 * 最大堆内存20M,初始堆内存10M,堆外内存(直接内存)5M,打印GC信息
 * GC overhead limit exceeded:超出GC开销限制
 * @date 2021-09-10 15:24:48
 */
public class GCOverHeadDemo {
    public static void main(String[] args) {
        int i=0;
        List&lt;String&gt; list=new ArrayList&lt;&gt;();
        while (true){
            list.add(String.valueOf(++i).intern());
        }
    }
}
</code></pre>
<pre><code class="language-java">[Full GC (Ergonomics) [PSYoungGen: 2560K-&gt;0K(4608K)] [ParOldGen: 13581K-&gt;818K(10752K)] 16141K-&gt;818K(15360K), [Metaspace: 3626K-&gt;3626K(1056768K)], 0.0078165 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] 
Heap
 PSYoungGen      total 4608K, used 219K [0x00000000ff980000, 0x0000000100000000, 0x0000000100000000)
  eden space 2560K, 8% used [0x00000000ff980000,0x00000000ff9b6f28,0x00000000ffc00000)
  from space 2048K, 0% used [0x00000000ffe00000,0x00000000ffe00000,0x0000000100000000)
  to   space 2048K, 0% used [0x00000000ffc00000,0x00000000ffc00000,0x00000000ffe00000)
 ParOldGen       total 10752K, used 818K [0x00000000fec00000, 0x00000000ff680000, 0x00000000ff980000)
  object space 10752K, 7% used [0x00000000fec00000,0x00000000fecccac0,0x00000000ff680000)
 Metaspace       used 3719K, capacity 4536K, committed 4864K, reserved 1056768K
  class space    used 406K, capacity 428K, committed 512K, reserved 1048576K
Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: GC overhead limit exceeded
	at java.lang.Integer.toString(Integer.java:401)
	at java.lang.String.valueOf(String.java:3099)
	at com.example.interview.oom.GCOverHeadDemo.main(GCOverHeadDemo.java:17)
</code></pre>
<p>最大堆内存要大于初始堆内存给GC创造条件，如果两值相等就没有重新分配堆空间操作会直接爆出Java heap space异常</p>
<h3 id="outofmemoryerrordirect-buffer-memory">OutOfMemoryError：Direct buffer memory</h3>
<pre><code class="language-java">import java.nio.ByteBuffer;
/**
 * @author wuhao
 * @desc -Xmx20m -Xms10m -XX:+PrintGCDetails -XX:MaxDirectMemorySize=5m
 * 最大堆内存20M,初始堆内存10M,堆外内存(直接内存)5M,打印GC信息
 * @date 2021-09-10 15:38:57
 */
public class DirectBufferMemoryDemo {
    public static void main(String[] args) {
        System.out.println(&quot;配置的DirectMemory&quot;+(sun.misc.VM.maxDirectMemory()/(double)1024/1024)+&quot;mb&quot;);
        ByteBuffer bf=ByteBuffer.allocateDirect(6*1024*1024);
    }
}
</code></pre>
<pre><code class="language-java">[GC (Allocation Failure) [PSYoungGen: 2048K-&gt;504K(2560K)] 2048K-&gt;758K(9728K), 0.0008256 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
配置的DirectMemory5.0mb
[GC (System.gc()) [PSYoungGen: 908K-&gt;504K(2560K)] 1162K-&gt;862K(9728K), 0.0009251 secs] [Times: user=0.06 sys=0.00, real=0.00 secs] 
[Full GC (System.gc()) [PSYoungGen: 504K-&gt;0K(2560K)] [ParOldGen: 358K-&gt;801K(7168K)] 862K-&gt;801K(9728K), [Metaspace: 3500K-&gt;3500K(1056768K)], 0.0046698 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] 
Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Direct buffer memory
	at java.nio.Bits.reserveMemory(Bits.java:694)
	at java.nio.DirectByteBuffer.&lt;init&gt;(DirectByteBuffer.java:123)
	at java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:311)
	at com.example.interview.oom.DirectBufferMemoryDemo.main(DirectBufferMemoryDemo.java:13)
Heap
 PSYoungGen      total 2560K, used 1068K [0x00000000ff980000, 0x00000000ffc80000, 0x0000000100000000)
  eden space 2048K, 52% used [0x00000000ff980000,0x00000000ffa8b200,0x00000000ffb80000)
  from space 512K, 0% used [0x00000000ffc00000,0x00000000ffc00000,0x00000000ffc80000)
  to   space 512K, 0% used [0x00000000ffb80000,0x00000000ffb80000,0x00000000ffc00000)
 ParOldGen       total 7168K, used 801K [0x00000000fec00000, 0x00000000ff300000, 0x00000000ff980000)
  object space 7168K, 11% used [0x00000000fec00000,0x00000000fecc86d0,0x00000000ff300000)
 Metaspace       used 4057K, capacity 4568K, committed 4864K, reserved 1056768K
  class space    used 446K, capacity 460K, committed 512K, reserved 1048576K
</code></pre>
<p>allocateDirect分配的字节缓冲区用中文叫做直接缓冲区（DirectByteBuffer），用allocate分配的ByteBuffer叫做堆字节缓冲区(HeapByteBuffer)..</p>
<p>其实根据类名就可以看出，HeapByteBuffer所创建的字节缓冲区就是在jvm堆中的，即内部所维护的java字节数组。而DirectByteBuffer是直接操作操作系统本地代码创建的内存缓冲数组（c、c++的数组）。</p>
<p>HeapByteBuffer底层其实是java的字节数组，而java字节数组是一个java对象，对象的内存是由jvm的堆进行管理的，那么不可避免的是GC时年轻代的eden、suvivor到老年代的各种复制以及回收。。。当字节数组比较小的时候还好说，如果是大对象，那么对于jvm的GC来说是一个很大的负担。。而使用DirectByteBuffer，则是把字节数组交给操作系统管理（堆外内存）</p>
<h3 id="outofmemoryerrorunable-to-create-to-native-thread">OutOfMemoryError：Unable to create to native thread</h3>
<pre><code class="language-java">public class UnableToCreateToNativeThreadDemo {
   
    public static void main(String[] args) {
        for (int i = 0; ; i++) {
            System.out.println(&quot;================ i=&quot; + i);
            new Thread(() -&gt; {
                try {
                    Thread.sleep(Integer.MAX_VALUE);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }, &quot;&quot; + i).start();
        }
    }
}
</code></pre>
<p>linux一般用户可以最大创建1024个线程，不要在电脑上随意尝试</p>
<h3 id="meta-space">meta space</h3>
<pre><code class="language-java">/**
 * @author wuhao
 * @desc -XX:MetaspaceSize=8m -XX:MaxMetaspaceSize=8m -XX:+PrintGCDetails
 * @date 2021-09-13 10:36:15
 */
public class MetaSpaceOOMDemo {
    static class OOMTest{

    }
    public static void main(String[] args) {
        int i=0;
        try {
            while (true){
                i++;
                Enhancer enhancer=new Enhancer();
                enhancer.setSuperclass(OOMTest.class);
                enhancer.setUseCache(false);
                enhancer.setCallback(new MethodInterceptor() {
                    @Override
                    public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable {
                        return methodProxy.invokeSuper(o,args);
                    }
                });
                enhancer.create();
            }
        }catch (Throwable e){
            System.out.println(&quot;=========&quot;+i+&quot;次后发生了异常&quot;);
        }

    }
}
</code></pre>
<pre><code class="language-java">[Full GC (Last ditch collection) [PSYoungGen: 0K-&gt;0K(116224K)] [ParOldGen: 2016K-&gt;2016K(225792K)] 2016K-&gt;2016K(342016K), [Metaspace: 9911K-&gt;9911K(1058816K)], 0.0093402 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] 
Heap
 PSYoungGen      total 116224K, used 3425K [0x00000000d6400000, 0x00000000de400000, 0x0000000100000000)
  eden space 115712K, 2% used [0x00000000d6400000,0x00000000d67584a0,0x00000000dd500000)
  from space 512K, 0% used [0x00000000de380000,0x00000000de380000,0x00000000de400000)
  to   space 5120K, 0% used [0x00000000dda00000,0x00000000dda00000,0x00000000ddf00000)
 ParOldGen       total 225792K, used 2016K [0x0000000082c00000, 0x0000000090880000, 0x00000000d6400000)
  object space 225792K, 0% used [0x0000000082c00000,0x0000000082df8128,0x0000000090880000)
 Metaspace       used 9942K, capacity 10090K, committed 10240K, reserved 1058816K
  class space    used 884K, capacity 913K, committed 1024K, reserved 1048576K
Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Metaspace
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[类加载]]></title>
        <id>https://tinaxiawuhao.github.io/post/DikSLfU_z/</id>
        <link href="https://tinaxiawuhao.github.io/post/DikSLfU_z/">
        </link>
        <updated>2021-09-09T05:41:07.000Z</updated>
        <content type="html"><![CDATA[<h2 id="类加载过程">类加载过程</h2>
<p>在java中编译并不进行链接工作，类型的加载、链接和初始化工作都是在jvm执行过程中进行的。在Java程序启动时，jvm通过加载指定的类，然后调用该类的main方法而启动。在JVM启动过程中， 外部class字节码文件会经过一系列过程转化为JVM中执行的数据，这一系列过程我们称为类加载过程。</p>
<h3 id="类加载整体流程">类加载整体流程</h3>
<p>从类被JVM加载到内存开始到卸载出内存为止，整个生命周期包括：加载、链接、初始化、使用和卸载五个过程。其中链接又包括验证、准备和解析三个过程。如下图所示：</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1619321177632.png" alt="" loading="lazy"></figure>
<h3 id="类加载时机">类加载时机</h3>
<p>java虚拟机规范通过对初始化阶段进行严格规定，来保证初始化的完成，而作为其之前的必须启动的过程，加载、验证、准备也需要在此之前开始。</p>
<p>Java虚拟机规定，以下五种情况必须对类进行初始化：</p>
<ol>
<li>
<p>虚拟机在用户指定包含main方法的主类后启动时，必须先对主类进行初始化。</p>
</li>
<li>
<p>当使用new关键字对类进行实例化时、读取或者写入类的静态字段时、调用类的静态方法时，必须先触发对该类的实例化。</p>
</li>
<li>
<p>使用反射对类进行反射调用时，如果该类没有初始化先对其进行初始化。</p>
</li>
<li>
<p>初始化一个类，而该类的父类还未初始化，需要先对其父类进行初始化。</p>
</li>
<li>
<p>在JDK1.7之后的版本中使用动态语言支持，java.lang.invoke.MethodHandle实例解析的结果是REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，而该句柄对应的类 还未初始化，必须先触发其实例化。</p>
</li>
</ol>
<h3 id="加载">加载</h3>
<p>在加载阶段，虚拟机需要完成三件事：</p>
<ol>
<li>
<p>通过一个类的全限定名来获取此类的class字节码二进制流。</p>
</li>
<li>
<p>将这个字节码二进制流中的静态存储结构转化为方法区中的运行时数据结构。</p>
</li>
<li>
<p>在内存中生成一个代表该类的java.lang.Class对象，作为方法区中这个类的各种数据的访问入口。</p>
</li>
</ol>
<p>对于Class对象，Java虚拟机规范并没有规定要存储在堆中，HotSpot虚拟机将其存放在方法区中。</p>
<h3 id="验证">验证</h3>
<p>验证作为链接的第一步，大致会完成四个阶段的检验：</p>
<ol>
<li>
<p>文件格式验证：该阶段主要在字节流转化为方法区中的运行时数据时，负责检查字节流是否符合Class文件规范，保证其可以正确的被解析并存储在方法区中。后面的检查都是基于方法区的 存储结构进行检验，不会再直接操作字节流。</p>
</li>
<li>
<p>元数据验证：该阶段负责分析存储于方法区的结构是否符合Java语言规范。此阶段进行数据类型的校验，保证符合不存在非法的元数据信息。</p>
</li>
<li>
<p>字节码验证：元数据验证保证了字节码中的数据符合语言的规范，该阶段则负责分析数据流和控制流，确定方法体的合法性，保证被校验的方法在运行时不会危害虚拟机的运行。</p>
</li>
<li>
<p>符号引用验证：在解析阶段会将虚拟机中的符号引用转化为直接引用，该阶段则负责对各种符号引用进行匹配性校验，保证外部依赖真实存在，并且符合外部依赖类、字段、方法的访问性。</p>
</li>
</ol>
<h3 id="准备">准备</h3>
<p>准备阶段正式为类的字段变量（被static修饰的类变量）分配内存并设置初始值。这些变量存储在方法区中。当类字段为常量类型（即被static final修饰），由于字段的值已经确定，并不会在后面修改，此时会直接赋值为指定的值。</p>
<h3 id="解析">解析</h3>
<p>解析阶段将常量池中的符号引用替换为直接引用。在字节码文件中，类、接口、字段、方法等类型都是由一组符号来表示。其形式由java虚拟机规范中的Class文件格式定义。在虚拟机执行 指定指令之前，需要将符号引用转化为目标的指针、相对偏移量或者句柄，这样可以通过此类直接引用在内存中定位调用的具体位置。</p>
<h3 id="初始化">初始化</h3>
<p>在类的class文件中。包含两个特殊的方法：clinit和init，这两方法由编译器自动生成，分别代表类构造器和构造函数，其中构造函数编程实现，初始化阶段就是负责调用类构造器，来初始化 变量和资源。</p>
<p>clinit方法由编译器自动收集类的赋值动作和静态语句块（static）中的语句合并生成的，有以下特点：</p>
<ol>
<li>
<p>编译器收集顺序又代码顺序决定，静态语句块只能访问它之前定义的变量，在它之后定义的变量只能进行赋值不能访问。</p>
</li>
<li>
<p>虚拟机保证在子类的clinit方法执行前，父类的clinit已经执行完毕。</p>
</li>
<li>
<p>clinit不是必须的，如果一个类或接口没有变量赋值和静态代码块，则编译器可以不生成clinit。</p>
</li>
<li>
<p>虚拟机会保证clinit方法在多线程中被正确的加锁和同步。如果多个线程同时初始化一个类，那么只有一个线程执行clinit，其他线程会被阻塞。</p>
</li>
</ol>
<h2 id="双亲委派模型">双亲委派模型</h2>
<h3 id="类加载器">类加载器</h3>
<ol>
<li>
<p>定义：实现类加载阶段的“通过一个里的全限定名来获取描述此类的二进制字节流”的动作的代码模块成为“类加载器”。对于任意一个类，都需要由加载它的类加载器和这个类本身一同确立其在java虚拟机中的唯一性，每一个类加载器，都拥有一个独立的类名称空间。比较两个类是否“相等”，只有在这两个类是同一个类加载器加载的前提下才有意义。</p>
</li>
<li>
<p>类加载器种类</p>
<p>从Java虚拟机的角度只有两种类加载器：</p>
<p>（1）启动类加载器（BootStrap ClassLoader），这个类加载器使用C++语言实现，是虚拟机自身的一部分。</p>
<p>（2）另一种就是所有其他类的加载器，这些类加载器都是由Java语言实现，独立于虚拟机外部，并且都继承自抽象类java.lang.ClassLoader。</p>
<p>从Java开发人员的角度，类加载器还可分为3种系统提供的类加载器和用户自定义的类加载器。</p>
<p>（1）启动类加载器（BootStrap ClassLoader）：负责加载存放java_home\lib目录中的，或者被-Xbootclasspath参数所指定的路径中的类。</p>
<p>（2）扩展类加载器（Extension ClassLoader）：这个加载器sun.misc.Launcher</p>
<p>ExtClassLoader实现，它负责加载java_home\lib\ext目录中的，或者被java.ext.dirs系统变量所指定的路径中的所有类库，开发者可以直接使用扩展类加载器。 如果应用程序中没有自定义的类加载器，一般情况下 这个就是程序中默认的类加载器。</p>
<p>（3）自定义类加载器（User ClassLoader）：用户自定义的类加载器。用户在编写自己定义的类加载器时，如果需要把请求委派给引导类加载器，那直接使用numm代替即可。要创建用户自己 的类加载器，只需要继承java.lang.ClassLoader，然后覆盖它的findClass(String name)方法即可。如果要符合双亲委派模型，则重写findClass()方法。如果要破坏的话，则重写 loadClass()方法。</p>
</li>
</ol>
<p><strong>双亲委派模型</strong></p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1619321193747.webp" alt="" loading="lazy"></figure>
<p>上图展示的类加载器之间的这种层次关系称为类加载器的双亲委派模型。</p>
<ol>
<li>
<p>双亲委派模型要求除了顶层的启动类加载器之外，其余的类加载器都应当有自己的父类加载器。</p>
</li>
<li>
<p>类加载器的双亲委派模型在jdk1.2被引入，但它不是一个强制性的约束模型，而是Java设计者推荐给开发者的一种类加载器的实现方式。</p>
</li>
</ol>
<p>双亲委派模型的工作过程如下：</p>
<ol>
<li>
<p>如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成。</p>
</li>
<li>
<p>每一层的类加载器都重复第一步，因此所有的类加载请求最终都传送到了顶层的类加载器中。</p>
</li>
<li>
<p>只有父类加载器返回自己无法完成这个加载请求，子加载器才会尝试自己去加载。</p>
</li>
</ol>
<h2 id="对象的创建-存储和访问">对象的创建、存储和访问</h2>
<h3 id="对象的创建">对象的创建</h3>
<ol>
<li>
<p>类加载检查：虚拟机遇到一条new指令，首先检查这个指令的参数是否能在常量池中（Class文件的静态常量池）定位到这个类的符号引用，并且检查这个符号引用代表的类是否 已经被加载、解析和初始化过。如果没有，那必须先执行相应的类加载过程。</p>
</li>
<li>
<p>分配内存：对象所需内存大小在类加载完成后便可完全确定，为对象分配空间的任务等同于把一块确定大小的内存从Java堆中划分出来。但是不同垃圾回收器的算法会导致堆内存存在两种情况：绝对规整和相互交错。（比如标记清楚算法和标记整理算法）</p>
<p>（1）指针碰撞：假设Java堆内存是绝对规整的，所有用过的内存都存放在一起，空闲的内存存放在另一边，中间放着一个指示器作为分界点的指示器，所分配的内存就仅仅是把那个指针向空闲空间那边挪动一段与对象大小相等的距离，这种分配方式成为”指针碰撞“。</p>
<p>（2）空闲列表：如果是相互交错的，那么虚拟机会维护一个列表，记录哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划给对象实例，并更新列表上的记录。这种分配方式成为”空闲列表“。</p>
</li>
<li>
<p>分配内存的并发问题：即使是仅仅修改一个指针所指向的位置，在并发情况下也不是线程安全的，可能出现正在给对象A分配内存，指针还没来得及修改，对象B又同时使用了原来的 指针来分配内存的情况。针对这个问题有两种解决方案：</p>
<p>（1）失败重试：对分配内存空间的动作进行同步处理，虚拟机采用CAS和失败重试机制保证更新操作的原子性。</p>
<p>（2）本地线程分配缓存：哪个线程要分配内存，就在哪个线程的TLAB（Thread Local Allocation Buffer）上分配，只有TLAB用完并分配新的TLAB时，才需要同步锁定。</p>
</li>
<li>
<p>内存空间初始化零值：内存分配完成后，虚拟机需要将分配到的内存空间都初始化零值，这一步操作保证了对象的实例字段（成员变量）在Java代码中可以不赋值就直接使用，程序能够访问到这些字段的数据类型所对应的零值。</p>
</li>
<li>
<p>对象设置：接下来虚拟机会对对象进行必要的设置，例如这个对象是哪个类的实例，如何才能找到类的元数据信息、对象的哈希吗、对象的GC分代年龄等信息。这些信息存放在对象头中。至此一个新的对象产生了。</p>
</li>
<li>
<p>实例构造器的init方法：虽然对象产生了，但是init方法并没有执行，所欲字段还需要赋值（包括成员变量赋值，普通语句块执行，构造函数执行等。）</p>
</li>
</ol>
<h3 id="clinit和init">Clinit和init</h3>
<h4 id="clinit">Clinit</h4>
<p>类构造器的方法，与类的初始化有关。例如静态变量（类变量）和静态对象赋值，静态语句块的执行。如果一个类中没有静态语句块，也没有静态变量或静态对象的赋值， 那么编译器可以不为这个类生成方法。</p>
<h4 id="init">init</h4>
<p>实例构造器（即成员变量，成员对象等），例如成员变量和成员对象的赋值，普通语句块的执行，构造函数的执行。</p>
<h3 id="对象的内存布局">对象的内存布局</h3>
<p>在HotSpot虚拟机中，对象在内存中存储的布局可以分为三个区域：对象头、实例数据和对齐填充。</p>
<h4 id="对象头">对象头</h4>
<p>对象头包括两部分信息：运行时数据和类型指针。</p>
<h4 id="运行时数据">运行时数据</h4>
<p>第一部分用于存储对象自身的运行时数据，如哈希吗（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等。<br>
<img src="https://tinaxiawuhao.github.io/post-images/1619321205464.webp" alt="" loading="lazy"></p>
<p>下面是HotSpot虚拟机对象头Mark Word：</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1619321212070.webp" alt="" loading="lazy"></figure>
<h4 id="类型指针">类型指针</h4>
<p>对象头的另一部分是类型指针，即对象指向他元数据的指针，虚拟机可以通过这个指针确定这个对象是哪个类的实例。但是如果对象是一个Java数组，那么在对象头中还必须有一块用于记录数据长度的数据。</p>
<h4 id="对象的实例数据">对象的实例数据</h4>
<p>接着数据头的是对象的实例数据，这部分是真正存储的有效信息。无论是从父类中继承下来的还是在子类中定义的，都需要记录下来。</p>
<h4 id="对齐填充">对齐填充</h4>
<p>最后一部分对齐填充并不是必然存在的，也没有特别的含义，仅仅起着占位符的作用。由于HotSpot虚拟机的自动内存管理系统要求对象的起始地址必须是8字节的整数倍，也就是 对象的大小必须是8字节的整数倍。而对象头部分是8字节的倍数，当实例数据没有对齐的时候，需要对齐填充凑够8字节的整数倍。</p>
<h4 id="对象的访问定位">对象的访问定位</h4>
<p>建立对象是为了使用对象，我们的Java程序需要通过栈上的引用数据来操作堆上的具体对象。对象的访问方式取决于虚拟机的实现，目前主流的访问方式有使用句柄和直接指针两种。</p>
<p>句柄引用和直接引用不同在于：使用句柄引用的话，那么Java对堆中将会划分出一块内存来作为句柄池，引用中存储的就是对象的句柄地址，但是直接引用引用中存储的直接就是对象地址。Java使用的是直接指针访问对象的方式，因为它最大的好处就是速度更快，它节省了一次指针定位的时间开销，由于对象的访问在Java中非常频繁，因此这类开销积少成多后也是一项 非常可观的执行成本。</p>
<p>下面是通过直接指针访问对象<br>
<img src="https://tinaxiawuhao.github.io/post-images/1619321218990.png" alt="" loading="lazy"></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[线程池ThreadPoolExecutor]]></title>
        <id>https://tinaxiawuhao.github.io/post/y8VkHlUlp/</id>
        <link href="https://tinaxiawuhao.github.io/post/y8VkHlUlp/">
        </link>
        <updated>2021-09-08T08:05:07.000Z</updated>
        <content type="html"><![CDATA[<h3 id="executors目前提供了5种不同的线程池创建配置">Executors目前提供了5种不同的线程池创建配置：</h3>
<ol>
<li>
<p>newCachedThreadPool（），它是用来处理大量短时间工作任务的线程池，具有几个鲜明特点：它会试图缓存线程并重用，当无缓存线程可用时，就会创建新的工作线程；如果线程闲置时间超过60秒，则被终止并移除缓存；长时间闲置时，这种线程池，不会消耗什么资源。其内部使用SynchronousQueue作为工作队列。</p>
</li>
<li>
<p>newFixedThreadPool（int nThreads），重用指定数目（nThreads）的线程，其背后使用的是无界的工作队列，任何时候最多有nThreads个工作线程是活动的。这意味着，如果任务数量超过了活动线程数目，将在工作队列中等待空闲线程出现；如果工作线程退出，将会有新的工作线程被创建，以补足指定数目nThreads。</p>
</li>
<li>
<p>newSingleThreadExecutor()，它的特点在于工作线程数目限制为1，操作一个无界的工作队列，所以它保证了所有的任务都是被顺序执行，最多会有一个任务处于活动状态，并且不予许使用者改动线程池实例，因此可以避免改变线程数目。</p>
</li>
<li>
<p>newSingleThreadScheduledExecutor()和newScheduledThreadPool(int corePoolSize)，创建的是个ScheduledExecutorService，可以进行定时或周期性的工作调度，区别在于单一工作线程还是多个工作线程。</p>
</li>
<li>
<p>newWorkStealingPool(int parallelism)，这是一个经常被人忽略的线程池，Java 8 才加入这个创建方法，其内部会构建<a href="https://docs.oracle.com/javase/9/docs/api/java/util/concurrent/ForkJoinPool.html">ForkJoinPool</a>，利用<a href="https://en.wikipedia.org/wiki/Work_stealing">Work-Stealing</a>算法，并行地处理任务，不保证处理顺序。</p>
</li>
</ol>
<pre><code class="language-java">public class MyThreadPool {
    public static void main(String[] args) {
//        ExecutorService executorService = Executors.newFixedThreadPool(5);
//        ExecutorService executorService= Executors.newSingleThreadExecutor();
//        ExecutorService executorService= Executors.newCachedThreadPool();
//        ExecutorService executorService= Executors.newScheduledThreadPool(5);

        ExecutorService executorService = new ThreadPoolExecutor(2,
                5,
                2,
                TimeUnit.SECONDS,
                new LinkedBlockingQueue&lt;Runnable&gt;(3),
                Executors.defaultThreadFactory(),
                new ThreadPoolExecutor.AbortPolicy()
        );
        ThreadPoolInit(executorService);
    }

    private static void ThreadPoolInit(ExecutorService executorService) {

        try {
            for (int i = 1; i &lt;= 10; i++) {
                executorService.execute(() -&gt; {
                    System.out.println(Thread.currentThread().getName() + &quot;办理业务&quot;);
                });
            }
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            executorService.shutdown();
        }
    }
}

</code></pre>
<h3 id="executor框架的基本组成">Executor框架的基本组成</h3>
<p><img src="https://tinaxiawuhao.github.io/post-images/1631088364651.png" alt="" loading="lazy"><br>
而我们创建时，一般使用它的子类：ThreadPoolExecutor.</p>
<pre><code class="language-java">public ThreadPoolExecutor(int corePoolSize,  
                              int maximumPoolSize,  
                              long keepAliveTime,  
                              TimeUnit unit,  
                              BlockingQueue&lt;Runnable&gt; workQueue,  
                              ThreadFactory threadFactory,  
                              RejectedExecutionHandler handler)
</code></pre>
<p>这是其中最重要的一个构造方法，这个方法决定了创建出来的线程池的各种属性，下面依靠一张图来更好的理解线程池和这几个参数：</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1631088504377.png" alt="" loading="lazy"></figure>
<p>（1）corePoolSize：线程池中常驻核心线程数</p>
<p>（2）maximumPoolSize：线程池能够容纳同时执行的最大线程数，此值必须大于等于1</p>
<p>（3）keepAliveTime：多余的空闲线程存活时间。当前线程池数量超过corePoolSize时，当空闲时间到达keepAliveTime值时，多余空闲线程会被销毁直到只剩下corePoolSize个线程为止。</p>
<p>（4）unit：keepAliveTime的时间单位</p>
<p>（5）workQueue：任务队列，被提交但尚未执行的任务</p>
<p>（6）threadFactory：表示生成线程池中的工作线程的线程工厂，用于创建线程，一般为默认线程工厂即可</p>
<p>（7）handler：拒绝策略，表示当队列满了并且工作线程大于等于线程池的最大线程数（maximumPoolSize）时如何来拒绝来请求的Runnable的策略</p>
<h3 id="handler的拒绝策略">handler的拒绝策略：</h3>
<p>有四种：</p>
<ol>
<li>第一种AbortPolicy:不执行新任务，直接抛出异常，提示线程池已满</li>
<li>第二种DisCardPolicy:不执行新任务，也不抛出异常</li>
<li>第三种DisCardOldSetPolicy:将消息队列中的第一个任务替换为当前新进来的任务执行</li>
<li>第四种CallerRunsPolicy:直接调用execute来执行当前任务</li>
</ol>
<h3 id="在spring项目中的使用">在spring项目中的使用</h3>
<p>先创建一个线程池的配置，让Spring Boot加载，用来定义如何创建一个<code>ThreadPoolTaskExecutor</code>，要使用<code>@Configuration</code>和@<code>EnableAsync</code>这两个注解，表示这是个配置类，并且是线程池的配置类</p>
<pre><code class="language-java">@Configuration
@EnableAsync
public class ExecutorConfig {

    private static final Logger logger = LoggerFactory.getLogger(ExecutorConfig.class);

    @Value(&quot;${async.executor.thread.core_pool_size}&quot;)
    private int corePoolSize;
    @Value(&quot;${async.executor.thread.max_pool_size}&quot;)
    private int maxPoolSize;
    @Value(&quot;${async.executor.thread.queue_capacity}&quot;)
    private int queueCapacity;
    @Value(&quot;${async.executor.thread.name.prefix}&quot;)
    private String namePrefix;

    @Bean(name = &quot;asyncServiceExecutor&quot;)
    public Executor asyncServiceExecutor() {
        logger.info(&quot;start asyncServiceExecutor&quot;);
        ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();
        //配置核心线程数
        executor.setCorePoolSize(corePoolSize);
        //配置最大线程数
        executor.setMaxPoolSize(maxPoolSize);
        //配置队列大小
        executor.setQueueCapacity(queueCapacity);
        //配置线程池中的线程的名称前缀
        executor.setThreadNamePrefix(namePrefix);

        // rejection-policy：当pool已经达到max size的时候，如何处理新任务
        // CALLER_RUNS：不在新线程中执行任务，而是有调用者所在的线程来执行
        executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy());
        //执行初始化
        executor.initialize();
        return executor;
    }
}
</code></pre>
<p><code>@Value</code>是我配置在<code>application.properties</code>，可以参考配置，自由定义</p>
<pre><code class="language-xml"># 异步线程配置
# 配置核心线程数
async.executor.thread.core_pool_size = 5
# 配置最大线程数
async.executor.thread.max_pool_size = 5
# 配置队列大小
async.executor.thread.queue_capacity = 99999
# 配置线程池中的线程的名称前缀
async.executor.thread.name.prefix = async-service-
</code></pre>
<p>创建一个Service接口，是异步线程的接口</p>
<pre><code class="language-java">public interface AsyncService {

    /** * 执行异步任务 * 可以根据需求，自己加参数拟定，我这里就做个测试演示 */
    void executeAsync();
}
</code></pre>
<p>实现类</p>
<pre><code class="language-java">@Service
public class AsyncServiceImpl implements AsyncService {

    private static final Logger logger = LoggerFactory.getLogger(AsyncServiceImpl.class);

    @Override
    @Async(&quot;asyncServiceExecutor&quot;)
    public void executeAsync() {
        logger.info(&quot;start executeAsync&quot;);

        System.out.println(&quot;异步线程要做的事情&quot;);
        System.out.println(&quot;可以在这里执行批量插入等耗时的事情&quot;);

        logger.info(&quot;end executeAsync&quot;);
    }
}
</code></pre>
<p>将Service层的服务异步化，在<code>executeAsync()</code>方法上增加注解<code>@Async(&quot;asyncServiceExecutor&quot;)</code>，<code>asyncServiceExecutor</code>方法是前面<strong>ExecutorConfig.java</strong> 中的方法名，表明<code>executeAsync</code>方法进入的线程池是<code>asyncServiceExecutor</code>方法创建的</p>
<p>接下来就是在Controller里或者是哪里通过注解<code>@Autowired</code>注入这个Service</p>
<pre><code class="language-java">@Autowired
private AsyncService asyncService;

@GetMapping(&quot;/async&quot;)
public void async(){
    asyncService.executeAsync();
}
</code></pre>
<p><strong>用postmain或者其他工具来多次测试请求一下</strong></p>
<pre><code class="language-java"> 2018-07-16 22:15:47.655  INFO 10516 --- [async-service-5] c.u.d.e.executor.impl.AsyncServiceImpl   : start executeAsync
异步线程要做的事情
可以在这里执行批量插入等耗时的事情
2018-07-16 22:15:47.655  INFO 10516 --- [async-service-5] c.u.d.e.executor.impl.AsyncServiceImpl   : end executeAsync
2018-07-16 22:15:47.770  INFO 10516 --- [async-service-1] c.u.d.e.executor.impl.AsyncServiceImpl   : start executeAsync
异步线程要做的事情
可以在这里执行批量插入等耗时的事情
2018-07-16 22:15:47.770  INFO 10516 --- [async-service-1] c.u.d.e.executor.impl.AsyncServiceImpl   : end executeAsync
2018-07-16 22:15:47.816  INFO 10516 --- [async-service-2] c.u.d.e.executor.impl.AsyncServiceImpl   : start executeAsync
异步线程要做的事情
可以在这里执行批量插入等耗时的事情
2018-07-16 22:15:47.816  INFO 10516 --- [async-service-2] c.u.d.e.executor.impl.AsyncServiceImpl   : end executeAsync
2018-07-16 22:15:48.833  INFO 10516 --- [async-service-3] c.u.d.e.executor.impl.AsyncServiceImpl   : start executeAsync
异步线程要做的事情
可以在这里执行批量插入等耗时的事情
2018-07-16 22:15:48.834  INFO 10516 --- [async-service-3] c.u.d.e.executor.impl.AsyncServiceImpl   : end executeAsync
2018-07-16 22:15:48.986  INFO 10516 --- [async-service-4] c.u.d.e.executor.impl.AsyncServiceImpl   : start executeAsync
异步线程要做的事情
可以在这里执行批量插入等耗时的事情
2018-07-16 22:15:48.987  INFO 10516 --- [async-service-4] c.u.d.e.executor.impl.AsyncServiceImpl   : end executeAsync
</code></pre>
<p>通过以上日志可以发现，<code>[async-service-]</code>是有多个线程的，显然已经在我们配置的线程池中执行了，并且每次请求中，controller的起始和结束日志都是连续打印的，表明每次请求都快速响应了，而耗时的操作都留给线程池中的线程去异步执行；</p>
<p>虽然我们已经用上了线程池，但是还不清楚线程池当时的情况，有多少线程在执行，多少在队列中等待呢？这里我创建了一个ThreadPoolTaskExecutor的子类，在每次提交线程的时候都会将当前线程池的运行状况打印出来</p>
<pre><code class="language-java">import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor;
import org.springframework.util.concurrent.ListenableFuture;

import java.util.concurrent.Callable;
import java.util.concurrent.Future;
import java.util.concurrent.ThreadPoolExecutor;

/** * @Author: ChenBin * @Date: 2018/7/16/0016 22:19 */
public class VisiableThreadPoolTaskExecutor extends ThreadPoolTaskExecutor {


    private static final Logger logger = LoggerFactory.getLogger(VisiableThreadPoolTaskExecutor.class);

    private void showThreadPoolInfo(String prefix) {
        ThreadPoolExecutor threadPoolExecutor = getThreadPoolExecutor();

        if (null == threadPoolExecutor) {
            return;
        }

        logger.info(&quot;{}, {},taskCount [{}], completedTaskCount [{}], activeCount [{}], queueSize [{}]&quot;,
                this.getThreadNamePrefix(),
                prefix,
                threadPoolExecutor.getTaskCount(),
                threadPoolExecutor.getCompletedTaskCount(),
                threadPoolExecutor.getActiveCount(),
                threadPoolExecutor.getQueue().size());
    }

    @Override
    public void execute(Runnable task) {
        showThreadPoolInfo(&quot;1. do execute&quot;);
        super.execute(task);
    }

    @Override
    public void execute(Runnable task, long startTimeout) {
        showThreadPoolInfo(&quot;2. do execute&quot;);
        super.execute(task, startTimeout);
    }

    @Override
    public Future&lt;?&gt; submit(Runnable task) {
        showThreadPoolInfo(&quot;1. do submit&quot;);
        return super.submit(task);
    }

    @Override
    public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) {
        showThreadPoolInfo(&quot;2. do submit&quot;);
        return super.submit(task);
    }

    @Override
    public ListenableFuture&lt;?&gt; submitListenable(Runnable task) {
        showThreadPoolInfo(&quot;1. do submitListenable&quot;);
        return super.submitListenable(task);
    }

    @Override
    public &lt;T&gt; ListenableFuture&lt;T&gt; submitListenable(Callable&lt;T&gt; task) {
        showThreadPoolInfo(&quot;2. do submitListenable&quot;);
        return super.submitListenable(task);
    }
}
</code></pre>
<p>如上所示，showThreadPoolInfo方法中将任务总数、已完成数、活跃线程数，队列大小都打印出来了，然后Override了父类的execute、submit等方法，在里面调用showThreadPoolInfo方法，这样每次有任务被提交到线程池的时候，都会将当前线程池的基本情况打印到日志中；</p>
<p>修改<code>ExecutorConfig.java</code>的<code>asyncServiceExecutor</code>方法，将<code>ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor()</code>改为<code>ThreadPoolTaskExecutor executor = new VisiableThreadPoolTaskExecutor()</code></p>
<pre><code class="language-java">@Bean(name = &quot;asyncServiceExecutor&quot;)
    public Executor asyncServiceExecutor() {
        logger.info(&quot;start asyncServiceExecutor&quot;);
        //在这里修改
        ThreadPoolTaskExecutor executor = new VisiableThreadPoolTaskExecutor();
        //配置核心线程数
        executor.setCorePoolSize(corePoolSize);
        //配置最大线程数
        executor.setMaxPoolSize(maxPoolSize);
        //配置队列大小
        executor.setQueueCapacity(queueCapacity);
        //配置线程池中的线程的名称前缀
        executor.setThreadNamePrefix(namePrefix);

        // rejection-policy：当pool已经达到max size的时候，如何处理新任务
        // CALLER_RUNS：不在新线程中执行任务，而是有调用者所在的线程来执行
        executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy());
        //执行初始化
        executor.initialize();
        return executor;
    }
</code></pre>
<p>再次启动该工程测试</p>
<pre><code class="language-java">2018-07-16 22:23:30.951  INFO 14088 --- [nio-8087-exec-2] u.d.e.e.i.VisiableThreadPoolTaskExecutor : async-service-, 2. do submit,taskCount [0], completedTaskCount [0], activeCount [0], queueSize [0]
2018-07-16 22:23:30.952  INFO 14088 --- [async-service-1] c.u.d.e.executor.impl.AsyncServiceImpl   : start executeAsync
异步线程要做的事情
可以在这里执行批量插入等耗时的事情
2018-07-16 22:23:30.953  INFO 14088 --- [async-service-1] c.u.d.e.executor.impl.AsyncServiceImpl   : end executeAsync
2018-07-16 22:23:31.351  INFO 14088 --- [nio-8087-exec-3] u.d.e.e.i.VisiableThreadPoolTaskExecutor : async-service-, 2. do submit,taskCount [1], completedTaskCount [1], activeCount [0], queueSize [0]
2018-07-16 22:23:31.353  INFO 14088 --- [async-service-2] c.u.d.e.executor.impl.AsyncServiceImpl   : start executeAsync
异步线程要做的事情
可以在这里执行批量插入等耗时的事情
2018-07-16 22:23:31.353  INFO 14088 --- [async-service-2] c.u.d.e.executor.impl.AsyncServiceImpl   : end executeAsync
2018-07-16 22:23:31.927  INFO 14088 --- [nio-8087-exec-5] u.d.e.e.i.VisiableThreadPoolTaskExecutor : async-service-, 2. do submit,taskCount [2], completedTaskCount [2], activeCount [0], queueSize [0]
2018-07-16 22:23:31.929  INFO 14088 --- [async-service-3] c.u.d.e.executor.impl.AsyncServiceImpl   : start executeAsync
异步线程要做的事情
可以在这里执行批量插入等耗时的事情
2018-07-16 22:23:31.930  INFO 14088 --- [async-service-3] c.u.d.e.executor.impl.AsyncServiceImpl   : end executeAsync
2018-07-16 22:23:32.496  INFO 14088 --- [nio-8087-exec-7] u.d.e.e.i.VisiableThreadPoolTaskExecutor : async-service-, 2. do submit,taskCount [3], completedTaskCount [3], activeCount [0], queueSize [0]
2018-07-16 22:23:32.498  INFO 14088 --- [async-service-4] c.u.d.e.executor.impl.AsyncServiceImpl   : start executeAsync
异步线程要做的事情
可以在这里执行批量插入等耗时的事情
2018-07-16 22:23:32.499  INFO 14088 --- [async-service-4] c.u.d.e.executor.impl.AsyncServiceImpl   : end executeAsync
</code></pre>
<p>注意这一行日志：</p>
<pre><code class="language-java">2018-07-16 22:23:32.496  INFO 14088 --- [nio-8087-exec-7] u.d.e.e.i.VisiableThreadPoolTaskExecutor : async-service-, 2. do submit,taskCount [3], completedTaskCount [3], activeCount [0], queueSize [0]
</code></pre>
<p>这说明提交任务到线程池的时候，调用的是submit(Callable task)这个方法，当前已经提交了3个任务，完成了3个，当前有0个线程在处理任务，还剩0个任务在队列中等待，线程池的基本情况一路了然</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[手写一个生产者消费者模式]]></title>
        <id>https://tinaxiawuhao.github.io/post/5QxJ3UtmK/</id>
        <link href="https://tinaxiawuhao.github.io/post/5QxJ3UtmK/">
        </link>
        <updated>2021-09-08T07:46:13.000Z</updated>
        <content type="html"><![CDATA[<pre><code class="language-java">import lombok.SneakyThrows;
import org.springframework.util.StringUtils;

import java.util.concurrent.ArrayBlockingQueue;
import java.util.concurrent.BlockingQueue;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicInteger;

class MyResource {
    private volatile Boolean FLAG = true;
    private final AtomicInteger atomicInteger = new AtomicInteger();
    BlockingQueue&lt;String&gt; blockingQueue = null;

    public MyResource(BlockingQueue&lt;String&gt; blockingQueue) {
        this.blockingQueue = blockingQueue;
        System.out.println(blockingQueue.getClass().getName());
    }

    @SneakyThrows
    public void myProd() {
        String data = null;
        while (FLAG) {
            data = String.valueOf(atomicInteger.incrementAndGet());
            if (blockingQueue.offer(data, 2L, TimeUnit.SECONDS)) {
                System.out.println(Thread.currentThread().getName() + &quot;插入数据&quot; + data + &quot;成功&quot;);
            } else {
                System.out.println(Thread.currentThread().getName() + &quot;插入数据&quot; + data + &quot;失败&quot;);
            }
            TimeUnit.SECONDS.sleep(1L);
        }
        System.out.println(Thread.currentThread().getName() + &quot;生产停止&quot;);
    }

    @SneakyThrows
    public void myConsumer() {
        String result = null;
        while (FLAG) {
            result = blockingQueue.poll(2L, TimeUnit.SECONDS);
            if (StringUtils.isEmpty(result)) {
                FLAG = false;
                System.out.println(Thread.currentThread().getName() + &quot;超过2秒没有取到值，结束&quot;);
                return;
            }
            System.out.println(Thread.currentThread().getName() + &quot;消费数据&quot; + result + &quot;成功&quot;);
        }
    }

    public void stop(){
        FLAG=false;
    }
}

public class ProdConsumer_BlockQueue {

    @SneakyThrows
    public static void main(String[] args) {
        MyResource myResource = new MyResource(new ArrayBlockingQueue&lt;&gt;(10));
        new Thread(() -&gt; {
            System.out.println(Thread.currentThread().getName() + &quot;生产线程启动&quot;);
            myResource.myProd();
        }, &quot;Prod&quot;).start();

        new Thread(() -&gt; {
            System.out.println(Thread.currentThread().getName() + &quot;消费线程启动&quot;);
            myResource.myConsumer();
        }, &quot;Consumer&quot;).start();

        TimeUnit.SECONDS.sleep(5L);
        System.out.println(&quot;5秒时间到，结束&quot;);
        myResource.stop();
    }


}
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1631087515332.png" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[阻塞队列BlockingQueue]]></title>
        <id>https://tinaxiawuhao.github.io/post/volSqv4Kf/</id>
        <link href="https://tinaxiawuhao.github.io/post/volSqv4Kf/">
        </link>
        <updated>2021-09-08T07:40:12.000Z</updated>
        <content type="html"><![CDATA[<h2 id="为什么要使用阻塞队列">为什么要使用阻塞队列</h2>
<p>之前，介绍了一下 ThreadPoolExecutor 的各参数的含义（<a href="https://tianxiawuhao.github.io/post/y8VkHlUlp">线程池ThreadPoolExecutor</a>），其中有一个 BlockingQueue，它是一个阻塞队列。那么，小伙伴们有没有想过，为什么此处的线程池要用阻塞队列呢？</p>
<p>我们知道队列是先进先出的。当放入一个元素的时候，会放在队列的末尾，取出元素的时候，会从队头取。那么，当队列为空或者队列满的时候怎么办呢。</p>
<p>这时，阻塞队列，会自动帮我们处理这种情况。</p>
<p>当阻塞队列为空的时候，从队列中取元素的操作就会被阻塞。当阻塞队列满的时候，往队列中放入元素的操作就会被阻塞。</p>
<p>而后，一旦空队列有数据了，或者满队列有空余位置时，被阻塞的线程就会被自动唤醒。</p>
<p>这就是阻塞队列的好处，你不需要关心线程何时被阻塞，也不需要关心线程何时被唤醒，一切都由阻塞队列自动帮我们完成。我们只需要关注具体的业务逻辑就可以了。</p>
<p>而这种阻塞队列经常用在生产者消费者模式中。（可参看：<a href="https://tianxiawuhao.github.io/post/5QxJ3UtmK">手写一个生产者消费者模式</a>）</p>
<h2 id="常用的阻塞队列">常用的阻塞队列</h2>
<p>那么，一般我们用到的阻塞队列有哪些呢。下面，通过idea的类图，列出来常用的阻塞队列，然后一个一个讲解（不懂怎么用的，可以参考这篇文章：<a href="https://blog.csdn.net/qq_26542493/article/details/104512954">怎么用IDEA快速查看类图关系</a>）。</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1631086948386.jpg" alt="" loading="lazy"></figure>
<p>阻塞队列中，所有常用的方法都在 BlockingQueue 接口中定义。如</p>
<p>插入元素的方法： put，offer，add。移除元素的方法： remove，poll，take。</p>
<p>它们有四种不同的处理方式，第一种是在失败时抛出异常，第二种是在失败时返回特殊值，第三种是一直阻塞当前线程，最后一种是在指定时间内阻塞，否则返回特殊值。（以上特殊值，是指在插入元素时，失败返回false，在取出元素时，失败返回null）</p>
<table>
<thead>
<tr>
<th></th>
<th>抛异常</th>
<th>特殊值</th>
<th>阻塞</th>
<th>超时</th>
</tr>
</thead>
<tbody>
<tr>
<td>插入</td>
<td>add(e)</td>
<td>offer(e)</td>
<td>put(e)</td>
<td>offer(e,time,unit)</td>
</tr>
<tr>
<td>移除</td>
<td>remove()</td>
<td>poll()</td>
<td>take()</td>
<td>poll(time,unit)</td>
</tr>
</tbody>
</table>
<p><strong>1） ArrayBlockingQueue</strong></p>
<p>这是一个由数组结构组成的有界阻塞队列。首先看下它的构造方法，有三个。</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1631086962267.jpg" alt="" loading="lazy"></figure>
<p>第一个可以指定队列的大小，第二个还可以指定队列是否公平，不指定的话，默认是非公平。它是使用 ReentrantLock 的公平锁和非公平锁实现的（后续讲解AQS时，会详细说明）。</p>
<p>简单理解就是，ReentrantLock 内部会维护一个有先后顺序的等待队列，假如有五个任务一起过来，都被阻塞了。如果是公平的，则等待队列中等待最久的任务就会先进入阻塞队列。如果是非公平的，那么这五个线程就需要抢锁，谁先抢到，谁就先进入阻塞队列。</p>
<p>第三个构造方法，是把一个集合的元素初始化到阻塞队列中。</p>
<p>另外，ArrayBlockingQueue 没有实现读写分离，也就是说，读和写是不能同时进行的。因为，它读写时用的是同一把锁，如下图所示：</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1631086978381.jpg" alt="" loading="lazy"></figure>
<p><strong>2) LinkedBlockingQueue</strong></p>
<p>这是一个由链表结构组成的有界阻塞队列。它的构造方法有三个。</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1631086987611.jpg" alt="" loading="lazy"></figure>
<p>可以看到和 ArrayBlockingQueue 的构造方法大同小异，不过是，LinkedBlockingQueue 可以不指定队列的大小，默认值是 Integer.MAX_VALUE 。</p>
<p>但是，最好不要这样做，建议指定一个固定大小。因为，如果生产者的速度比消费者的速度大的多的情况下，这会导致阻塞队列一直膨胀，直到系统内存被耗尽（此时，还没达到队列容量的最大值）。</p>
<p>此外，LinkedBlockingQueue 实现了读写分离，可以实现数据的读和写互不影响，这在高并发的场景下，对于效率的提高无疑是非常巨大的。</p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1631086997560.jpg" alt="" loading="lazy"></figure>
<p><strong>3） SynchronousQueue</strong></p>
<p>这是一个没有缓冲的无界队列。什么意思，看一下它的 size 方法：</p>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1631087010961.jpg" alt="" loading="lazy"></figure>
<p>总是返回 0 ，因为它是一个没有容量的队列。</p>
<p>当执行插入元素的操作时，必须等待一个取出操作。也就是说，put元素的时候，必须等待 take 操作。</p>
<p>那么，有的同学就好奇了，这没有容量，还叫什么队列啊，这有什么意义呢。</p>
<p>我的理解是，这适用于并发任务不大，而且生产者和消费者的速度相差不多的场景下，直接把生产者和消费者对接，不用经过队列的入队出队这一系列操作。所以，效率上会高一些。</p>
<p>可以去查看一下 Excutors.newCachedThreadPool 方法用的就是这种队列。</p>
<p>这个队列有两个构造方法，用于传入是公平还是非公平，默认是非公平。</p>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1631087023429.jpg" alt="" loading="lazy"></figure>
<p><strong>4）PriorityBlockingQueue</strong></p>
<p>这是一个支持优先级排序的无界队列。有四个构造方法：</p>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1631087030940.jpg" alt="" loading="lazy"></figure>
<p>可以指定初始容量大小（注意初始容量并不代表最大容量），或者不指定，默认大小为 11。也可以传入一个比较器，把元素按一定的规则排序，不指定比较器的话，默认是自然顺序。</p>
<p>PriorityBlockingQueue 是基于二叉树最小堆实现的，每当取元素的时候，就会把优先级最高的元素取出来。我们测试一下：</p>
<pre><code class="language-java">public class Person {
    private int id;
    private String name;

    public int getId() {
        return id;
    }

    public void setId(int id) {
        this.id = id;
    }

    public String getName() {
        return name;
    }

    public void setName(String name) {
        this.name = name;
    }

    @Override
    public String toString() {
        return &quot;Person{&quot; +
                &quot;id=&quot; + id +
                &quot;, name='&quot; + name + '\'' +
                '}';
    }

    public Person(int id, String name) {
        this.id = id;
        this.name = name;
    }

    public Person() {
    }
}

public class QueueTest {
    public static void main(String[] args) throws InterruptedException {

        PriorityBlockingQueue&lt;Person&gt; priorityBlockingQueue = new PriorityBlockingQueue&lt;&gt;(1, new Comparator&lt;Person&gt;() {
            @Override
            public int compare(Person o1, Person o2) {
                return o1.getId() - o2.getId();
            }
        });

        Person p2 = new Person(7, &quot;李四&quot;);
        Person p1 = new Person(9, &quot;张三&quot;);
        Person p3 = new Person(6, &quot;王五&quot;);
        Person p4 = new Person(2, &quot;赵六&quot;);
        priorityBlockingQueue.add(p1);
        priorityBlockingQueue.add(p2);
        priorityBlockingQueue.add(p3);
        priorityBlockingQueue.add(p4);

		//由于二叉树最小堆实现，用这种方式直接打印元素，不能保证有序
        System.out.println(priorityBlockingQueue);
        System.out.println(priorityBlockingQueue.take());
        System.out.println(priorityBlockingQueue);
        System.out.println(priorityBlockingQueue.take());
        System.out.println(priorityBlockingQueue);

    }
}
</code></pre>
<p>打印结果：</p>
<pre><code class="language-json">[Person{id=2, name='赵六'}, Person{id=6, name='王五'}, Person{id=7, name='李四'}, Person{id=9, name='张三'}]
Person{id=2, name='赵六'}
[Person{id=6, name='王五'}, Person{id=9, name='张三'}, Person{id=7, name='李四'}]
Person{id=6, name='王五'}
[Person{id=7, name='李四'}, Person{id=9, name='张三'}]
</code></pre>
<p>可以看到，第一次取出的是 id 最小值 2， 第二次取出的是 6 。</p>
<p><strong>5）DelayQueue</strong></p>
<p>这是一个带有延迟时间的无界阻塞队列。队列中的元素，只有等延时时间到了，才能取出来。此队列一般用于过期数据的删除，或任务调度。以下，模拟一下定长时间的数据删除。</p>
<p>首先定义数据元素，需要实现 Delayed 接口，实现 getDelay 方法用于计算剩余时间，和 CompareTo方法用于优先级排序。</p>
<pre><code class="language-java">public class DelayData implements Delayed {

    private int id;
    private String name;
    //数据到期时间
    private long endTime;
    private TimeUnit timeUnit = TimeUnit.MILLISECONDS;

    public int getId() {
        return id;
    }

    public void setId(int id) {
        this.id = id;
    }

    public String getName() {
        return name;
    }

    public void setName(String name) {
        this.name = name;
    }

    public long getEndTime() {
        return endTime;
    }

    public void setEndTime(long endTime) {
        this.endTime = endTime;
    }

    public DelayData(int id, String name, long endTime) {
        this.id = id;
        this.name = name;
        //需要把传入的时间endTime 加上当前系统时间，作为数据的到期时间
        this.endTime = endTime + System.currentTimeMillis();
    }

    public DelayData() {
    }

    @Override
    public long getDelay(TimeUnit unit) {
        return this.endTime - System.currentTimeMillis();
    }

    @Override
    public int compareTo(Delayed o) {
        return o.getDelay(this.timeUnit) - this.getDelay(this.timeUnit) &lt; 0 ? 1: -1;
    }

}
</code></pre>
<p>模拟三条数据，分别设置不同的过期时间：</p>
<pre><code class="language-java">public class ProcessData {
    public static void main(String[] args) throws InterruptedException {
        DelayQueue&lt;DelayData&gt; delayQueue = new DelayQueue&lt;&gt;();

        DelayData a = new DelayData(5, &quot;A&quot;, 5000);
        DelayData b = new DelayData(8, &quot;B&quot;, 8000);
        DelayData c = new DelayData(2, &quot;C&quot;, 2000);

        delayQueue.add(a);
        delayQueue.add(b);
        delayQueue.add(c);

        System.out.println(&quot;开始计时时间:&quot; + System.currentTimeMillis());
        for (int i = 0; i &lt; 3; i++) {
            DelayData data = delayQueue.take();
            System.out.println(&quot;id:&quot;+data.getId()+&quot;，数据:&quot;+data.getName()+&quot;被移除，当前时间:&quot;+System.currentTimeMillis());
        }
    }
}
</code></pre>
<p>最后结果：</p>
<pre><code class="language-json">开始计时时间:1583333583216
id:2，数据:C被移除，当前时间:1583333585216
id:5，数据:A被移除，当前时间:1583333588216
id:8，数据:B被移除，当前时间:1583333591216
</code></pre>
<p>可以看到，数据是按过期时间长短，按顺序移除的。C的时间最短 2 秒，然后过了 3 秒 A 也过期，再过 3 秒，B 过期。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Redis的缓存淘汰策略LRU]]></title>
        <id>https://tinaxiawuhao.github.io/post/bGEB86JC1/</id>
        <link href="https://tinaxiawuhao.github.io/post/bGEB86JC1/">
        </link>
        <updated>2021-09-03T08:38:27.000Z</updated>
        <content type="html"><![CDATA[<p>redis缓存淘汰策略与Redis键的过期删除策略并不完全相同，前者是在Redis内存使用超过一定值的时候（一般这个值可以配置）使用的淘汰策略；而后者是通过定期删除+惰性删除两者结合的方式进行内存淘汰的。</p>
<h3 id="redis内存不足的缓存淘汰策略">Redis内存不足的缓存淘汰策略</h3>
<ul>
<li>noeviction：当内存使用超过配置的时候会返回错误，不会驱逐任何键</li>
<li>allkeys-lru：加入键的时候，如果过限，首先通过LRU算法驱逐最久没有使用的键</li>
<li>volatile-lru：加入键的时候如果过限，首先从设置了过期时间的键集合中驱逐最久没有使用的键</li>
<li>allkeys-random：加入键的时候如果过限，从所有key随机删除</li>
<li>volatile-random：加入键的时候如果过限，从过期键的集合中随机驱逐</li>
<li>volatile-ttl：从配置了过期时间的键中驱逐马上就要过期的键</li>
<li>volatile-lfu：从所有配置了过期时间的键中驱逐使用频率最少的键</li>
<li>allkeys-lfu：从所有键中驱逐使用频率最少的键</li>
</ul>
<h3 id="lru算法实现">lru算法实现</h3>
<h4 id="取巧算法">取巧算法</h4>
<pre><code class="language-java">
import java.util.LinkedHashMap;
import java.util.Map;

class LRUCache&lt;K,V&gt; extends LinkedHashMap&lt;K,V&gt; {

    private int capacity;

    /**
     * the ordering mode
     * - &lt;tt&gt;true&lt;/tt&gt; for access-order,
     * - &lt;tt&gt;false&lt;/tt&gt; for insertion-order
     * @param capacity
     */
    public LRUCache(int capacity) {
        super(capacity, 0.75F, true);
        this.capacity = capacity;
    }

    //数据超过容量大小删除
    @Override
    protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) {
        return super.size()&gt;capacity;
    }

}
</code></pre>
<h4 id="数据结构实现">数据结构实现</h4>
<pre><code class="language-java">
import java.util.HashMap;
import java.util.Map;

class LRUCacheDemo {

    //构建承载体node
    class Node&lt;K, V&gt; {
        K key;
        V value;
        Node&lt;K, V&gt; prev;
        Node&lt;K, V&gt; next;

        public Node() {
            this.prev = this.next = null;
        }

        public Node(K key, V value) {
            this.key = key;
            this.value = value;
            this.prev = this.next = null;
        }
    }

    //构建双向队列
    class DoubleLinkedList&lt;K, V&gt; {
        Node&lt;K, V&gt; head;
        Node&lt;K, V&gt; tail;

        public DoubleLinkedList() {
            head = new Node&lt;&gt;();
            tail = new Node&lt;&gt;();
            head.next = tail;
            tail.prev = head;
        }

        //添加头节点
        public void addHead(Node&lt;K, V&gt; node) {
            node.next = head.next;
            node.prev = head;
            head.next.prev = node;
            head.next = node;
        }

        //删除节点
        public void removeNode(Node&lt;K, V&gt; node) {
            node.next.prev = node.prev;
            node.prev.next = node.next;
            node.prev = null;
            node.next = null;
        }

        //获取最后一个节点
        public Node getLast() {
            return tail.prev;
        }
    }

    private int cacheSize;
    Map&lt;Object, Node&lt;Object, Object&gt;&gt; map;
    DoubleLinkedList&lt;Object, Object&gt; doubleLinkedList;

    public LRUCacheDemo(int cacheSize) {
        this.cacheSize = cacheSize;
        this.map = new HashMap&lt;&gt;();
        this.doubleLinkedList = new DoubleLinkedList&lt;&gt;();
    }

    public Object get(Object key) {
        if (!map.containsKey(key)) {
            return -1;
        }
        final Node&lt;Object, Object&gt; node = map.get(key);
        this.doubleLinkedList.removeNode(node);
        this.doubleLinkedList.addHead(node);
        return node.value;
    }

    public void put(Object key, Object value) {
        if (map.containsKey(key)) {
            final Node&lt;Object, Object&gt; node = map.get(key);
            node.value = value;
            map.put(key, node);
            this.doubleLinkedList.removeNode(node);
            this.doubleLinkedList.addHead(node);
        }else{
            if(map.size()==this.cacheSize){
                final Node last = this.doubleLinkedList.getLast();
                map.remove(last.key);
                doubleLinkedList.removeNode(last);
            }
            //新增
            Node&lt;Object,Object&gt; newNode=new Node&lt;&gt;(key,value);
            map.put(key, newNode);
            this.doubleLinkedList.addHead(newNode);
        }
    }

}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[list、set、map等集合类线程不安全的问题及解决方法]]></title>
        <id>https://tinaxiawuhao.github.io/post/GALzQf_b-/</id>
        <link href="https://tinaxiawuhao.github.io/post/GALzQf_b-/">
        </link>
        <updated>2021-09-03T08:34:53.000Z</updated>
        <content type="html"><![CDATA[<h3 id="list">List</h3>
<p>ArrayList不是线程安全类，在多线程同时写的情况下，会抛出java.util.ConcurrentModificationException异常。</p>
<pre><code class="language-java">private static void listNotSafe() {
    List&lt;String&gt; list=new ArrayList&lt;&gt;();
    for (int i = 1; i &lt;= 30; i++) {
        new Thread(() -&gt; {
            list.add(UUID.randomUUID().toString().substring(0, 8));
            System.out.println(Thread.currentThread().getName() + &quot;\t&quot; + list);
        }, String.valueOf(i)).start();
    }
}
</code></pre>
<p>解决方法：</p>
<ol>
<li>使用Vector（ArrayList所有方法加synchronized，太重）。</li>
<li>使用Collections.synchronizedList()转换成线程安全类。</li>
<li>使用java.concurrent.CopyOnWriteArrayList（推荐）。<br>
CopyOnWriteArrayList这是JUC的类，通过写时复制来实现读写分离。比如其add()方法，就是先复制一个新数组，长度为原数组长度+1，然后将新数组最后一个元素设为添加的元素。</li>
</ol>
<pre><code class="language-java">public boolean add(E e) {
    final ReentrantLock lock = this.lock;
    lock.lock();
    try {
        //得到旧数组
        Object[] elements = getArray();
        int len = elements.length;
        //复制新数组
        Object[] newElements = Arrays.copyOf(elements, len + 1);
        //设置新元素
        newElements[len] = e;
        //设置新数组
        setArray(newElements);
        return true;
    } finally {
        lock.unlock();
    }
}
</code></pre>
<h3 id="set">Set</h3>
<p>跟List类似，HashSet和TreeSet都不是线程安全的，与之对应的有CopyOnWriteSet这个线程安全类。这个类底层维护了一个CopyOnWriteArrayList数组。</p>
<pre><code class="language-java">private final CopyOnWriteArrayList&lt;E&gt; al;
public CopyOnWriteArraySet() {
    al = new CopyOnWriteArrayList&lt;E&gt;();
}
</code></pre>
<p>使用Collections.synchronizedList()转换成线程安全类。</p>
<p>HashSet和HashMap<br>
HashSet底层是用HashMap实现的。既然是用HashMap实现的，那HashMap.put()需要传两个参数，而HashSet.add()只传一个参数，这是为什么？实际上HashSet.add()就是调用的HashMap.put()，只不过Value被写死了，是一个private static final Object对象。</p>
<h3 id="map">Map</h3>
<p>HashMap不是线程安全的，Hashtable是线程安全的，但是跟Vector类似，太重量级。所以也有类似CopyOnWriteMap，只不过叫ConcurrentHashMap。</p>
<p>关于集合安全类</p>
<pre><code class="language-java">import java.util.*;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.CopyOnWriteArrayList;
import java.util.concurrent.CopyOnWriteArraySet;

public class ContainerNotSafeDemo {
    public static void main(String[] args) {
        listNotSafe();
        setNoSafe();
        mapNotSafe();
    }

    private static void mapNotSafe() {
        //Map&lt;String,String&gt; map=new HashMap&lt;&gt;();
        Map&lt;String, String&gt; map = new ConcurrentHashMap&lt;&gt;();
        for (int i = 1; i &lt;= 30; i++) {
            new Thread(() -&gt; {
                map.put(Thread.currentThread().getName(), UUID.randomUUID().toString().substring(0, 8));
                System.out.println(Thread.currentThread().getName() + &quot;\t&quot; + map);
            }, String.valueOf(i)).start();
        }
    }

    private static void setNoSafe() {
        //Set&lt;String&gt; set=new HashSet&lt;&gt;();
        Set&lt;String&gt; set = new CopyOnWriteArraySet&lt;&gt;();
        for (int i = 1; i &lt;= 30; i++) {
            new Thread(() -&gt; {
                set.add(UUID.randomUUID().toString().substring(0, 8));
                System.out.println(Thread.currentThread().getName() + &quot;\t&quot; + set);
            }, String.valueOf(i)).start();
        }
    }

    private static void listNotSafe() {
        //List&lt;String&gt; list=new ArrayList&lt;&gt;();
        List&lt;String&gt; list = new CopyOnWriteArrayList&lt;&gt;();
        for (int i = 1; i &lt;= 30; i++) {
            new Thread(() -&gt; {
                list.add(UUID.randomUUID().toString().substring(0, 8));
                System.out.println(Thread.currentThread().getName() + &quot;\t&quot; + list);
            }, String.valueOf(i)).start();
        }
    }
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[IdWorker雪花算法]]></title>
        <id>https://tinaxiawuhao.github.io/post/4WluurBt3/</id>
        <link href="https://tinaxiawuhao.github.io/post/4WluurBt3/">
        </link>
        <updated>2021-06-08T08:23:00.000Z</updated>
        <content type="html"><![CDATA[<pre><code class="language-java">package com.ihrm.common.utils;

import java.lang.management.ManagementFactory;
import java.net.InetAddress;
import java.net.NetworkInterface;

//雪花算法代码实现
public class IdWorker {
    // 时间起始标记点，作为基准，一般取系统的最近时间（一旦确定不能变动）
    private final static long twepoch = 1288834974657L;
    // 机器标识位数
    private final static long workerIdBits = 5L;
    // 数据中心标识位数
    private final static long datacenterIdBits = 5L;
    // 机器ID最大值
    private final static long maxWorkerId = -1L ^ (-1L &lt;&lt; workerIdBits);
    // 数据中心ID最大值
    private final static long maxDatacenterId = -1L ^ (-1L &lt;&lt; datacenterIdBits);
    // 毫秒内自增位
    private final static long sequenceBits = 12L;
    // 机器ID偏左移12位
    private final static long workerIdShift = sequenceBits;
    // 数据中心ID左移17位
    private final static long datacenterIdShift = sequenceBits + workerIdBits;
    // 时间毫秒左移22位
    private final static long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits;
    //毫秒内自增最大值
    private final static long sequenceMask = -1L ^ (-1L &lt;&lt; sequenceBits);
    /* 上次生产id时间戳 */
    private static long lastTimestamp = -1L;
    // 0，并发控制
    private long sequence = 0L;
    private final long workerId;
    // 数据标识id部分
    private final long datacenterId;

    public IdWorker() {
        this.datacenterId = getDatacenterId(maxDatacenterId);
       this.workerId = getMaxWorkerId(datacenterId, maxWorkerId);
    }

    /**
     * @param workerId     工作机器ID
     * @param datacenterId 序列号
     */
    public IdWorker(long workerId, long datacenterId) {
        if (workerId &gt; maxWorkerId || workerId &lt; 0) {
            throw new IllegalArgumentException(String.format(&quot;worker Id can't be greater than % d or less than 0&quot;, maxWorkerId));
        }
        if (datacenterId &gt; maxDatacenterId || datacenterId &lt; 0) {
            throw new IllegalArgumentException(String.format(&quot;datacenter Id can't be greater than % d or less than 0&quot;, maxDatacenterId));
        }
        this.workerId = workerId;
        this.datacenterId = datacenterId;
    }

    /**
     * 获取下一个ID
     *
     * @return
     */
    public synchronized long nextId() {
        long timestamp = timeGen();
        if (timestamp &lt; lastTimestamp) {
            throw new RuntimeException(String.format(&quot;Clock moved backwards. Refusing to generate id for %d milliseconds &quot;, lastTimestamp - timestamp));
        }
        if (lastTimestamp == timestamp) {
            // 当前毫秒内，则+1
            sequence = (sequence + 1) &amp; sequenceMask;
            if (sequence == 0) {
                // 当前毫秒内计数满了，则等待下一秒
                timestamp = tilNextMillis(lastTimestamp);
            }
        } else {
            sequence = 0L;
        }
        lastTimestamp = timestamp;
        // ID偏移组合生成最终的ID，并返回ID
        long nextId = ((timestamp - twepoch) &lt;&lt; timestampLeftShift)
                | (datacenterId &lt;&lt; datacenterIdShift)
                | (workerId &lt;&lt; workerIdShift) | sequence;
        return nextId;
    }

    private long tilNextMillis(final long lastTimestamp) {
        long timestamp = this.timeGen();
        while (timestamp &lt;= lastTimestamp) {
            timestamp = this.timeGen();
        }
        return timestamp;
    }

    private long timeGen() {
        return System.currentTimeMillis();
    }

    /**
     * &lt;p&gt;
     * 获取 maxWorkerId
     * &lt;/p&gt;
     */
    protected static long getMaxWorkerId(long datacenterId, long maxWorkerId) {
        StringBuffer mpid = new StringBuffer();
        mpid.append(datacenterId);
        String name = ManagementFactory.getRuntimeMXBean().getName();
        if (!name.isEmpty()) {
            /*
             * GET jvmPid
             */
            mpid.append(name.split(&quot;@&quot;)[0]);
        }
        /*
         * MAC + PID 的 hashcode 获取16个低位
         */
        return (mpid.toString().hashCode() &amp; 0xffff) % (maxWorkerId + 1);
    }

    /**
     * &lt;p&gt;
     * 数据标识id部分
     * &lt;/p&gt;
     */
    protected static long getDatacenterId(long maxDatacenterId) {
        long id = 0L;
        try {
            InetAddress ip = InetAddress.getLocalHost();
            NetworkInterface network = NetworkInterface.getByInetAddress(ip);
            if (network == null) {
                id = 1L;
            } else {
                byte[] mac = network.getHardwareAddress();
                id = ((0x000000FF &amp; (long) mac[mac.length - 1])
                        | (0x0000FF00 &amp; (((long) mac[mac.length - 2]) &lt;&lt; 8))) &gt;&gt; 6;
                id = id % (maxDatacenterId + 1);
            }
        } catch (Exception e) {
            System.out.println(&quot; getDatacenterId: &quot; + e.getMessage());
        }
        return id;
    }
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[RestTemplate]]></title>
        <id>https://tinaxiawuhao.github.io/post/fFTlwaLS_/</id>
        <link href="https://tinaxiawuhao.github.io/post/fFTlwaLS_/">
        </link>
        <updated>2021-06-07T05:34:32.000Z</updated>
        <content type="html"><![CDATA[<h3 id="spring环境下">spring环境下</h3>
<p>首先导入springboot 的 web 包</p>
<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<p>在启动类同包下创建RestTemplate.java类</p>
<pre><code class="language-java">import org.apache.http.client.HttpClient;
import org.apache.http.client.config.RequestConfig;
import org.apache.http.impl.client.DefaultHttpRequestRetryHandler;
import org.apache.http.impl.client.HttpClientBuilder;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.http.client.ClientHttpRequestFactory;
import org.springframework.http.client.HttpComponentsClientHttpRequestFactory;
import org.springframework.web.client.RestTemplate;

@Configuration
public class RestTempleConfig {

    @Bean
    public RestTemplate restTemplate() {

        //生成一个设置了连接超时时间、请求超时时间
        RequestConfig config = RequestConfig.custom()
                .setConnectionRequestTimeout(10000)
                .setConnectTimeout(10000)
                .setSocketTimeout(30000).build();

        // 设置异常重试
        HttpClientBuilder builder = HttpClientBuilder.create()
                .setDefaultRequestConfig(config)
                .setRetryHandler(new DefaultHttpRequestRetryHandler(3, false));
        HttpClient httpClient = builder.build();

        ClientHttpRequestFactory requestFactory =
                new HttpComponentsClientHttpRequestFactory(httpClient);
        RestTemplate restTemplate = new RestTemplate(requestFactory);
        // 日志拦截
        //restTemplate.setInterceptors(Collections.singletonList(new RestTemplateConsumerLogger()));

        return restTemplate;
    }
}
</code></pre>
<h3 id="非spring环境下">非spring环境下</h3>
<p>导入相关依赖包(注意版本相适应)</p>
<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;org.springframework&lt;/groupId&gt;
    &lt;artifactId&gt;spring-web&lt;/artifactId&gt;
    &lt;version&gt;5.2.16.RELEASE&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt;
    &lt;artifactId&gt;httpclient&lt;/artifactId&gt;
    &lt;version&gt;4.5.2&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;
    &lt;artifactId&gt;jackson-core&lt;/artifactId&gt;
    &lt;version&gt;2.12.1&lt;/version&gt;
    &lt;scope&gt;compile&lt;/scope&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;
    &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt;
    &lt;version&gt;2.12.1&lt;/version&gt;
    &lt;scope&gt;compile&lt;/scope&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;
    &lt;artifactId&gt;jackson-annotations&lt;/artifactId&gt;
    &lt;version&gt;2.12.1&lt;/version&gt;
    &lt;scope&gt;compile&lt;/scope&gt;
&lt;/dependency&gt;
</code></pre>
<h3 id="resttemplate">RestTemplate</h3>
<p>RestTemplate定义了36个与REST资源交互的方法，大多数都对应于HTTP的方法。 其中只有11个独立的方法，其中有十个有三种重载形式，而第十一个则重载了六次，这样一共形成了36个方法。</p>
<ol>
<li>
<p>getForEntity() 发送一个HTTP GET请求，返回的ResponseEntity包含了响应体所映射成的对象</p>
</li>
<li>
<p>getForObject() 发送一个HTTP GET请求，返回的请求体将映射为一个对象</p>
</li>
<li>
<p>postForEntity() POST 数据到一个URL，返回包含一个对象的ResponseEntity，这个对象是从响应体中映射得到的</p>
</li>
<li>
<p>postForObject() POST 数据到一个URL，返回根据响应体匹配形成的对象</p>
</li>
<li>
<p>exchange() 在URL上执行特定的HTTP方法，返回包含对象的ResponseEntity，这个对象是从响应体中映射得到的</p>
</li>
<li>
<p>execute() 在URL上执行特定的HTTP方法，返回一个从响应体映射得到的对象</p>
</li>
<li>
<p>delete() 在特定的URL上对资源执行HTTP DELETE操作</p>
</li>
<li>
<p>headForHeaders() 发送HTTP HEAD请求，返回包含特定资源URL的HTTP头</p>
</li>
<li>
<p>optionsForAllow() 发送HTTP OPTIONS请求，返回对特定URL的Allow头信息</p>
</li>
<li>
<p>postForLocation() POST 数据到一个URL，返回新创建资源的URL</p>
</li>
<li>
<p>put() PUT 资源到特定的URL</p>
</li>
</ol>
<h4 id="getforentity">getForEntity</h4>
<p>get请求就和正常在浏览器url上发送请求一样</p>
<pre><code class="language-java">RestTemplate restTemplate = new RestTemplate();
ResponseEntity&lt;String&gt; responseEntity=restTemplate.getForEntity(url+&quot;?name={1}&quot;, String.class, &quot;username&quot;);
String body = responseEntity.getBody();
</code></pre>
<pre><code class="language-java">RestTemplate restTemplate = new RestTemplate();
ResponseEntity&lt;TokenBeen&gt; responseEntity =restTemplate.getForEntity(url+&quot;?name={1}&quot;, TokenBeen.class, &quot;username&quot;);
if(responseEntity!=null){
    TokenBeen body = responseEntity.getBody();
}
</code></pre>
<pre><code class="language-java">#注意map的key要和参数中占位符相同
RestTemplate restTemplate = new RestTemplate();
Map&lt;String, String&gt; params = new HashMap&lt;&gt;();
params.put(&quot;name&quot;, &quot;username&quot;);
ResponseEntity&lt;String&gt; responseEntity = restTemplate.getForEntity(url+&quot;?name={name}&quot;, String.class, params);
String body = responseEntity.getBody();
</code></pre>
<pre><code class="language-java">RestTemplate restTemplate = new RestTemplate();
UriComponents uriConponents = UriComponentsBuilder.fromUriString(url+&quot;?name={name}&quot;).build().expand(&quot;username&quot;).encode();
URI uri = uriConponents.toUri();
ResponseEntity&lt;String&gt; responseEntity = restTemplate.getForEntity(uri, String.class);
String body = responseEntity.getBody();
</code></pre>
<pre><code class="language-java">@GetMapping(&quot;getForEntity/{id}&quot;)
public User getById(@PathVariable(name = &quot;id&quot;) String id) {
    ResponseEntity&lt;User&gt; response = restTemplate.getForEntity(&quot;http://localhost/get/{id}&quot;, User.class, id);
    User user = response.getBody();
    return user;
}
</code></pre>
<h4 id="getforobject">getForObject</h4>
<p>getForObject 和 getForEntity 用法几乎相同,getForObject函数可以看作是对getForEntity进一步封装,指示返回值返回的是响应体,省去了我们 再去 getBody()</p>
<pre><code class="language-java">RestTemplate restTemplate = new RestTemplate();
//注意参数中是uri
UriComponents uriConponents = UriComponentsBuilder.fromUriString(url+&quot;?name={name}&quot;).build().expand(&quot;username&quot;).encode();
URI uri = uriConponents.toUri();
String body = restTemplate.getForObject(uri, String.class);
</code></pre>
<pre><code class="language-java">RestTemplate restTemplate = new RestTemplate();
//注意参数中是uri
UriComponents uriConponents = UriComponentsBuilder.fromUriString(url+&quot;?name={name}&quot;).build().expand(&quot;username&quot;).encode();
URI uri = uriConponents.toUri();
TokenBeen body = restTemplate.getForObject(uri, TokenBeen.class);
</code></pre>
<pre><code class="language-java">@GetMapping(&quot;getForObject/{id}&quot;)
public User getById(@PathVariable(name = &quot;id&quot;) String id) {
    User user = restTemplate.getForObject(&quot;http://localhost/get/{id}&quot;, User.class, id);
    return user;
}
</code></pre>
<h4 id="postforentity">postForEntity</h4>
<pre><code class="language-java">public &lt;T&gt; T postForObject(String url, @Nullable Object request, Class&lt;T&gt; responseType, Object... uriVariables)throws RestClientException {} 
public &lt;T&gt; T postForObject(String url, @Nullable Object request, Class&lt;T&gt; responseType, Map&lt;String, ?&gt; uriVariables) throws RestClientException {} 
public &lt;T&gt; T postForObject(URI url, @Nullable Object request, Class&lt;T&gt; responseType) throws RestClientException {}
</code></pre>
<pre><code class="language-java">RestTemplate restTemplate = new RestTemplate();
HttpHeaders headers = new HttpHeaders();
//header参数
MediaType type = MediaType.parseMediaType(&quot;application/json; charset=UTF-8&quot;);
headers.setContentType(type);
headers.add(&quot;Accept&quot;, MediaType.APPLICATION_JSON.toString());
//body参数
JSONObject param = new JSONObject();
param.put(&quot;username&quot;, &quot;123&quot;);
HttpEntity&lt;JSONObject&gt; formEntity = new HttpEntity&lt;&gt;(param, headers);
//发送请求
String result = restTemplate.postForObject(url, formEntity, String.class);
</code></pre>
<pre><code class="language-java">@RequestMapping(&quot;saveUser&quot;)
public String save(User user) {
    ResponseEntity&lt;String&gt; response = restTemplate.postForEntity(&quot;http://localhost/save&quot;, user, String.class);
    String body = response.getBody();
    return body;
}
</code></pre>
<h4 id="postforobject">postForObject</h4>
<p>用法与 getForObject 一样</p>
<pre><code class="language-java">@RequestMapping(&quot;saveUser&quot;)
public String save(User user) {
    String body = restTemplate.postForObject(&quot;http://localhost/save&quot;, user, String.class);
    return body;
}
</code></pre>
<h4 id="exchange">exchange</h4>
<pre><code class="language-java">@PostMapping(&quot;demo&quot;)
public void demo(Integer id, String name){
 
    HttpHeaders headers = new HttpHeaders();//header参数
    headers.add(&quot;authorization&quot;,Auth);
    headers.setContentType(MediaType.APPLICATION_JSON);

    JSONObject content = new JSONObject();//放入body中的json参数
    content.put(&quot;userId&quot;, id);
    content.put(&quot;name&quot;, name);

    //post发送
    HttpEntity&lt;JSONObject&gt; request = new HttpEntity&lt;&gt;(content,headers); //组装
    ResponseEntity&lt;String&gt; response = template.exchange(&quot;http://localhost:8080/demo&quot;,HttpMethod.POST,request,String.class);
    //返回指定对象
    ParameterizedTypeReference&lt;User&gt; responseBodyType = new ParameterizedTypeReference&lt;RestBean&lt;String&gt;&gt;() {};
    User user = template.exchange(&quot;http://localhost:8080/demo&quot;,HttpMethod.POST,request,responseBodyType);
    
    
    //get发送
    HttpEntity&lt;String&gt; request = new HttpEntity&lt;&gt;(&quot;parameters&quot;,headers); //组装
    ResponseEntity&lt;String&gt; response = template.exchange(&quot;http://localhost:8080/demo&quot;,HttpMethod.GET,request,String.class);
    //返回指定对象
    ResponseEntity&lt;User&gt; response = template.exchange(&quot;http://localhost:8080/demo&quot;,HttpMethod.GET,request,User.class);
}
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1623908192461.png" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[SpringBoot  JWT实现]]></title>
        <id>https://tinaxiawuhao.github.io/post/ZsckGVdlz/</id>
        <link href="https://tinaxiawuhao.github.io/post/ZsckGVdlz/">
        </link>
        <updated>2021-06-06T08:50:36.000Z</updated>
        <content type="html"><![CDATA[<h3 id="springboot-jwt实现">SpringBoot  JWT实现</h3>
<p>（只是实现了jwt,没有生成证书,安全性得不到保障,证书安全验证查看<a href="https://tinaxiawuhao.github.io/post/wWtT_Oc9B/">Spring security JWT</a>）</p>
<pre><code class="language-java">&lt;dependency&gt;
    &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt;
    &lt;artifactId&gt;jjwt&lt;/artifactId&gt;
    &lt;version&gt;0.6.0&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<pre><code class="language-java">import io.jsonwebtoken.JwtBuilder;
import io.jsonwebtoken.Jwts;
import io.jsonwebtoken.SignatureAlgorithm;

import java.util.Date;

public class CreateJwtTest3 {
    public static void main(String[] args) {
        //为了方便测试，我们将过期时间设置为1分钟
        long now = System.currentTimeMillis();//当前时间
        long exp = now + 1000 * 60;//过期时间为1分钟
        JwtBuilder builder = Jwts.builder().setId(&quot;888&quot;)
                .setSubject(&quot;小白&quot;)
                .setIssuedAt(new Date())
                .signWith(SignatureAlgorithm.HS256, &quot;itcast&quot;)
                .setExpiration(new Date(exp))
                .claim(&quot;roles&quot;, &quot;admin&quot;) //自定义claims存储数据
                .claim(&quot;logo&quot;, &quot;logo.png&quot;);
        System.out.println(builder.compact());
    }
}
</code></pre>
<pre><code class="language-java">import io.jsonwebtoken.Claims;
import io.jsonwebtoken.Jwts;
import org.apache.commons.lang3.time.DateFormatUtils;

import java.util.Date;

public class ParseJwtTest {
    public static void main(String[] args) {
        String token = &quot;eyJhbGciOiJIUzI1NiJ9.eyJqdGkiOiI4ODgiLCJzdWIiOiLlsI_nmb0iLCJpYXQiOjE1NjExMDE3MzIsImV4cCI6MTU2MTEwMTc5MSwicm9sZXMiOiJhZG1pbiIsImxvZ28iOiJsb2dvLnBuZyJ9.5iVVdTw747L3ScHeCqle-bwj3cezK8NnE7VilQWOr8Y&quot;;
        Claims claims = Jwts.parser().setSigningKey(&quot;itcast&quot;).parseClaimsJws(token).getBody();
        System.out.println(&quot;id:&quot; + claims.getId());
        System.out.println(&quot;subject:&quot; + claims.getSubject());
        System.out.println(&quot;roles:&quot; + claims.get(&quot;roles&quot;));
        System.out.println(&quot;logo:&quot; + claims.get(&quot;logo&quot;));
        System.out.println(&quot;签发时间:&quot;+ DateFormatUtils.format(claims.getIssuedAt(),&quot;yyyy-MM-dd hh:mm:ss&quot;));
        System.out.println(&quot;过期时间:&quot;+DateFormatUtils.format(claims.getExpiration(),&quot;yyyy-MM-dd hh:mm:ss&quot;));
        System.out.println(&quot;当前时间:&quot;+DateFormatUtils.format(new Date(),&quot;yyyy-MM-dd hh:mm:ss&quot;));
    }
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[JWT介绍]]></title>
        <id>https://tinaxiawuhao.github.io/post/wWtT_Oc9B/</id>
        <link href="https://tinaxiawuhao.github.io/post/wWtT_Oc9B/">
        </link>
        <updated>2021-06-05T08:45:38.000Z</updated>
        <content type="html"><![CDATA[<h2 id="jwt介绍">JWT介绍</h2>
<p>在介绍JWT之前先看一下传统校验令牌的方法，如下图：</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1623401311518.png" alt="" loading="lazy"></figure>
<p>资源服务器授权流程如上图，客户端先去授权服务器申请令牌，申请令牌后，携带令牌访问资源服务器，资源服务器访问授权服务校验令牌的合法性，授权服务会返回校验结果，如果校验成功会返回用户信息给资源服务器，资源服务器如果接收到的校验结果通过了，则返回资源给客户端</p>
<p><strong>问题：</strong></p>
<p>传统授权方法的问题是用户每次请求资源服务，资源服务都需要携带令牌访问认证服务去校验令牌的合法性，并根据令牌获取用户的相关信息，性能低下。</p>
<p><strong>解决：</strong></p>
<p>使用JWT的思路是，用户认证通过会得到一个JWT令牌，JWT令牌中已经包括了用户相关的信息，客户端只需要携带JWT访问资源服务，资源服务根据事先约定的算法自行完成令牌校验，无需每次都请求认证服务完成授权。</p>
<p>JWT令牌授权过程如下图：</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1623401320289.png" alt="" loading="lazy"></figure>
<h3 id="什么是jwt">什么是JWT？</h3>
<p>JSON Web Token（JWT）是一个开放的行业标准（RFC 7519），它定义了一种简介的、自包含的协议格式，用于在通信双方传递json对象，传递的信息经过数字签名可以被验证和信任。JWT可以使用HMAC算法或使用RSA的公钥/私钥对来签名，防止被篡改。</p>
<blockquote>
<p>官网：https://jwt.io/</p>
<p>标准：https://tools.ietf.org/html/rfc7519</p>
</blockquote>
<h4 id="优点">优点：</h4>
<ol>
<li>
<p>jwt基于json，非常方便解析。</p>
</li>
<li>
<p>可以在令牌中自定义丰富的内容，易扩展。</p>
</li>
<li>
<p>通过非对称加密算法及数字签名技术，JWT防止篡改，安全性高。</p>
</li>
<li>
<p>资源服务使用JWT可不依赖认证服务即可完成授权。</p>
</li>
</ol>
<h4 id="缺点">缺点：</h4>
<ol>
<li>JWT令牌较长，占存储空间比较大。</li>
</ol>
<h4 id="令牌结构">令牌结构</h4>
<p>通过学习JWT令牌结构为自定义jwt令牌打好基础。</p>
<p>JWT令牌由三部分组成，每部分中间使用点（.）分隔，比如：xxxxx.yyyyy.zzzzz</p>
<p><strong>Header</strong></p>
<p>头部包括令牌的类型（即JWT）及使用的哈希算法（如HMAC SHA256或RSA）</p>
<p>一个例子如下：</p>
<p>下边是Header部分的内容</p>
<pre><code class="language-json">{
    &quot;alg&quot;: &quot;HS256&quot;,
    &quot;typ&quot;: &quot;JWT&quot;
}
</code></pre>
<p>将上边的内容使用Base64Url编码，得到一个字符串就是JWT令牌的第一部分。</p>
<p><strong>Payload</strong></p>
<p>第二部分是负载，内容也是一个json对象，它是存放有效信息的地方，它可以存放jwt提供的现成字段，比如：iss（签发者）,exp（过期时间戳）, sub（面向的用户）等，也可自定义字段。</p>
<p>此部分不建议存放敏感信息，因为此部分可以解码还原原始内容。</p>
<p>最后将第二部分负载使用Base64Url编码，得到一个字符串就是JWT令牌的第二部分。</p>
<pre><code class="language-json"> {
    &quot;sub&quot;: &quot;1234567890&quot;,
    &quot;name&quot;: &quot;456&quot;,
    &quot;admin&quot;: true
}
</code></pre>
<p><strong>Signature</strong></p>
<p>第三部分是签名，此部分用于防止jwt内容被篡改。这个部分使用base64url将前两部分进行编码，编码后使用点（.）连接组成字符串，最后使用header中声明签名算法进行签名。</p>
<pre><code class="language-java">HMACSHA256(base64UrlEncode(header) + &quot;.&quot; +base64UrlEncode(payload),secret)
</code></pre>
<p><code>base64UrlEncode(header)</code>：jwt令牌的第一部分。</p>
<p><code>base64UrlEncode(payload)</code>：jwt令牌的第二部分。</p>
<p><code>secret</code>：签名所使用的密钥。</p>
<h3 id="jwt入门">JWT入门</h3>
<p>Spring Security 提供对JWT的支持，本节我们使用Spring Security 提供的JwtHelper来创建JWT令牌，校验JWT令牌等操作。</p>
<h3 id="生成私钥和公钥">生成私钥和公钥</h3>
<p>JWT令牌生成采用非对称加密算法</p>
<ol>
<li>
<p>生成密钥证书</p>
<p>下边命令生成密钥证书，采用RSA 算法每个证书包含公钥和私钥</p>
<pre><code class="language-java">keytool -genkeypair -alias xckey -keyalg RSA -keypass xuecheng -keystore xc.keystore -storepass xuechengkeystore
</code></pre>
<blockquote>
<p>Keytool 是一个java提供的证书管理工具</p>
<p>-alias：密钥的别名</p>
<p>-keyalg：使用的hash算法</p>
<p>-keypass：密钥的访问密码</p>
<p>-keystore：密钥库文件名，xc.keystore保存了生成的证书</p>
<p>-storepass：密钥库的访问密码</p>
</blockquote>
<p><strong>查询证书信息</strong></p>
<pre><code class="language-java">keytool -list -keystore xc.keystore
</code></pre>
<p><strong>删除别名</strong></p>
<pre><code class="language-java">keytool -delete -alias xckey -keystore xc.keystore
</code></pre>
</li>
<li>
<p>导出公钥</p>
<p>openssl是一个加解密工具包，这里使用openssl来导出公钥信息。安装 openssl：http://slproweb.com/products/Win32OpenSSL.html</p>
<p>配置openssl的path环境变量，本文配置在<code>D:\OpenSSL-Win64\bin</code>  <code>cmd</code>进入<code>xc.keystore</code>文件所在目录执行如下命令：</p>
<pre><code class="language-java">keytool ‐list ‐rfc ‐‐keystore xc.keystore | openssl x509 ‐inform pem ‐pubkey
</code></pre>
<p>输入密钥库密码：</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1623908661423.png" alt="" loading="lazy"></figure>
<p>下边这一段就是公钥内容：</p>
<pre><code class="language-java">-----BEGIN PUBLIC KEY----- MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAijyxMdq4S6L1Af1rtB8SjCZHNgsQG8JTfGy55eYvzG0B/E4AudR2prSRBvF7NYPL47scRCNPgLnvbQczBHbBug6uOr78qnWsYxHlW6Aa5dI5NsmOD4DLtSw8eX0hFyK5Fj6ScYOSFBz9cd1nNTvx2+oIv0lJDcpQdQhsfgsEr1ntvWterZt/8r7xNN83gHYuZ6TM5MYvjQNBc5qC7Krs9wM7UoQuL+s0X6RlOib7/mcLn/lFLsLDdYQAZkSDx/6+t+1oHdMarChIPYT1sx9Dwj2j2mvFNDTKKKKAq0cv14Vrhz67Vjmz2yMJePDqUi0JYS2r0iIo7n8vN7s83v5uOQIDAQAB 
-----END PUBLIC KEY-----
</code></pre>
<p>将上边的公钥拷贝到文本文件中，合并为一行。</p>
</li>
</ol>
<h3 id="生成jwt令牌">生成jwt令牌</h3>
<p>在认证工程创建测试类，测试jwt令牌的生成与验证。</p>
<pre><code class="language-java">@Test
public void testCreateJwt(){
//证书文件
String key_location = &quot;xc.keystore&quot;;
//密钥库密码
String keystore_password = &quot;xuechengkeystore&quot;;
//访问证书路径
ClassPathResource resource = new ClassPathResource(key_location);
//密钥工厂
KeyStoreKeyFactory keyStoreKeyFactory = new KeyStoreKeyFactory(resource,
keystore_password.toCharArray());
//密钥的密码，此密码和别名要匹配

String keypassword = &quot;xuecheng&quot;;
//密钥别名
String alias = &quot;xckey&quot;;
//密钥对（密钥和公钥）
KeyPair keyPair = keyStoreKeyFactory.getKeyPair(alias,keypassword.toCharArray());
//私钥
RSAPrivateKey aPrivate = (RSAPrivateKey) keyPair.getPrivate();
//定义payload信息
Map&lt;String, Object&gt; tokenMap = new HashMap&lt;&gt;();
tokenMap.put(&quot;id&quot;, &quot;123&quot;);
tokenMap.put(&quot;name&quot;, &quot;mrt&quot;);
tokenMap.put(&quot;roles&quot;, &quot;r01,r02&quot;);
tokenMap.put(&quot;ext&quot;, &quot;1&quot;);
//生成jwt令牌
Jwt jwt = JwtHelper.encode(JSON.toJSONString(tokenMap), new RsaSigner(aPrivate));
//取出jwt令牌
String token = jwt.getEncoded();
System.out.println(&quot;token=&quot;+token);
} //资源服务使用公钥验证jwt的合法性，并对jwt解码
</code></pre>
<h3 id="验证jwt令牌">验证jwt令牌</h3>
<pre><code class="language-java">@Test
public void testVerify(){
//jwt令牌
String token
=&quot;eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHQiOiIxIiwicm9sZXMiOiJyMDEscjAyIiwibmFtZSI6Im1ydCIsImlkIjoiMTIzIn0.KK7_67N5d1Dthd1PgDHMsbi0UlmjGRcm_XJUUwseJ2eZyJJWoPP2IcEZgAU3tUaaKEHUf9wSRwaDgwhrwfyIcSHbs8oy3zOQEL8j5AOjzBBs7vnRmB7DbSaQD7eJiQVJOXO1QpdmEFgjhc_IBCVTJCVWgZw60IEW1_Lg5tqaLvCiIl26K48pJB5fle2zgYMzqR1L2LyTFkq39rG57VOqqSCi3dapsZQd4ctq95SJCXgGdrUDWtD52rp5o6_0uq‐mrbRdRxkrQfsa1j8C5IW2‐T4eUmiN3f9wF9JxUK1__XC1OQkOn‐ZTBCdqwWIygDFbU7sf6KzfHJTm5vfjp6NIA&quot;;
//公钥
String publickey = &quot;‐‐‐‐‐BEGIN PUBLIC KEY‐‐‐‐‐
MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAijyxMdq4S6L1Af1rtB8SjCZHNgsQG8JTfGy55eYvzG0B/E4AudR2prSRBvF7NYPL47scRCNPgLnvbQczBHbBug6uOr78qnWsYxHlW6Aa5dI5NsmOD4DLtSw8eX0hFyK5Fj6ScYOSFBz9cd1nNTvx2+oIv0lJDcpQdQhsfgsEr1ntvWterZt/8r7xNN83gHYuZ6TM5MYvjQNBc5qC7Krs9wM7UoQuL+s0X6RlOib7/mcLn/lFLsLDdYQAZkSDx/6+t+1oHdMarChIPYT1sx9Dwj2j2mvFNDTKKKKAq0cv14Vrhz67Vjmz2yMJePDqUi0JYS2r0iIo7n8vN7s83v5u
OQIDAQAB
‐‐‐‐‐END PUBLIC KEY‐‐‐‐‐&quot;;

//校验jwt
Jwt jwt = JwtHelper.decodeAndVerify(token, new RsaVerifier(publickey));
//获取jwt原始内容
String claims = jwt.getClaims();
//jwt令牌
String encoded = jwt.getEncoded();
System.out.println(encoded);
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[zookeeper概述]]></title>
        <id>https://tinaxiawuhao.github.io/post/DOckY7njv/</id>
        <link href="https://tinaxiawuhao.github.io/post/DOckY7njv/">
        </link>
        <updated>2021-06-04T06:27:35.000Z</updated>
        <content type="html"><![CDATA[<h2 id="zookeeper是什么">zookeeper是什么</h2>
<p>Zookeeper 分布式服务框架是Apache Hadoop 的一个子项目，它主要是用来解决分布式应用中经常遇到的一些数据管理问题，如：统一命名服务、状态同步服务、集群管理、分布式应用配置项的管理等。</p>
<p>简单的说，zookeeper=文件系统+通知机制。</p>
<h2 id="zookeeper提供了什么">zookeeper提供了什么</h2>
<h3 id="1-文件系统">1、 文件系统</h3>
<p>Zookeeper维护一个类似文件系统的数据结构：</p>
<p>​                            <img src="https://tinaxiawuhao.github.io/post-images/1622442641935.png" alt="" loading="lazy"></p>
<p>​    每个子目录项如 NameService 都被称作为 znode，和文件系统一样，我们能够自由的增加、删除znode，在一个znode下增加、删除子znode，唯一的不同在于znode是可以存储数据的。</p>
<p>有四种类型的znode：</p>
<ol>
<li>
<p>PERSISTENT-持久化目录节点</p>
<p>客户端与zookeeper断开连接后，该节点依旧存在</p>
</li>
<li>
<p>PERSISTENT_SEQUENTIAL-持久化顺序编号目录节点</p>
<p>客户端与zookeeper断开连接后，该节点依旧存在，只是Zookeeper给该节点名称进行顺序编号</p>
</li>
<li>
<p>EPHEMERAL-临时目录节点</p>
<p>客户端与zookeeper断开连接后，该节点被删除</p>
</li>
<li>
<p>EPHEMERAL_SEQUENTIAL-临时顺序编号目录节点</p>
<p>客户端与zookeeper断开连接后，该节点被删除，只是Zookeeper给该节点名称进行顺序编号</p>
</li>
</ol>
<h3 id="2-通知机制">2、 通知机制</h3>
<p>​    客户端注册监听它关心的目录节点，当目录节点发生变化（数据改变、被删除、子目录节点增加删除）时，zookeeper会通知客户端。</p>
<h2 id="我们能用zookeeper做什么">我们能用zookeeper做什么</h2>
<h3 id="1-命名服务">1、 命名服务</h3>
<p>​    这个似乎最简单，在zookeeper的文件系统里创建一个目录，即有唯一的path。在我们使用tborg无法确定上游程序的部署机器时即可与下游程序约定好path，通过path即能互相探索发现，不见不散了。</p>
<h3 id="2-配置管理">2、 配置管理</h3>
<p>​    程序总是需要配置的，如果程序分散部署在多台机器上，要逐个改变配置就变得困难。好吧，现在把这些配置全部放到zookeeper上去，保存在 Zookeeper 的某个目录节点中，然后所有相关应用程序对这个目录节点进行监听，一旦配置信息发生变化，每个应用程序就会收到 Zookeeper 的通知，然后从 Zookeeper 获取新的配置信息应用到系统中就好。</p>
<p>​                     <img src="https://tinaxiawuhao.github.io/post-images/1622442667808.png" alt="" loading="lazy"></p>
<h3 id="3-集群管理">3、 集群管理</h3>
<p>所谓集群管理无在乎两点：是否有机器退出和加入、选举master。</p>
<p>​    对于第一点，所有机器约定在父目录GroupMembers下创建临时目录节点，然后监听父目录节点的子节点变化消息。一旦有机器挂掉，该机器与 zookeeper的连接断开，其所创建的临时目录节点被删除，所有其他机器都收到通知：某个兄弟目录被删除，于是，所有人都知道：它下船了。新机器加入 也是类似，所有机器收到通知：新兄弟目录加入。</p>
<p>​    对于第二点，我们稍微改变一下，所有机器创建临时顺序编号目录节点，每次选取编号最小的机器作为master就好。</p>
<p>​                 <img src="https://tinaxiawuhao.github.io/post-images/1622442682095.png" alt="" loading="lazy"></p>
<h3 id="4-分布式锁">4、 分布式锁</h3>
<p>​    有了zookeeper的一致性文件系统，锁的问题变得容易。锁服务可以分为两类，一个是保持独占，另一个是控制时序。</p>
<p>​    对于第一类，我们将zookeeper上的一个znode看作是一把锁，通过createznode的方式来实现。所有客户端都去创建 /distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。厕所有言：来也冲冲，去也冲冲，用完删除掉自己创建的distribute_lock 节点就释放出锁。</p>
<p>​    对于第二类， /distribute_lock 已经预先存在，所有客户端在它下面创建临时顺序编号目录节点，和选master一样，编号最小的获得锁，用完删除，依次方便。</p>
<p>​                     <img src="https://tinaxiawuhao.github.io/post-images/1622442696117.png" alt="" loading="lazy"></p>
<h3 id="5-队列管理">5、队列管理</h3>
<p>两种类型的队列：</p>
<ol>
<li>
<p>同步队列，当一个队列的成员都聚齐时，这个队列才可用，否则一直等待所有成员到达。</p>
</li>
<li>
<p>队列按照 FIFO 方式进行入队和出队操作。</p>
<p>第一类，在约定目录下创建临时目录节点，监听节点数目是否是我们要求的数目。</p>
<p>第二类，和分布式锁服务中的控制时序场景基本原理一致，入列有编号，出列按编号。</p>
</li>
</ol>
<p>​     终于了解完我们能用zookeeper做什么了，可是作为一个程序员，我们总是想狂热了解zookeeper是如何做到这一点的，单点维护一个文件系统没有什么难度，可是如果是一个集群维护一个文件系统保持数据的一致性就非常困难了。</p>
<h3 id="6-分布式与数据复制">6、分布式与数据复制</h3>
<p>Zookeeper作为一个集群提供一致的数据服务，自然，它要在所有机器间做数据复制。数据复制的好处：</p>
<ol>
<li>
<p>容错<br>
一个节点出错，不致于让整个系统停止工作，别的节点可以接管它的工作；</p>
</li>
<li>
<p>提高系统的扩展能力<br>
把负载分布到多个节点上，或者增加节点来提高系统的负载能力；</p>
</li>
<li>
<p>提高性能<br>
让客户端本地访问就近的节点，提高用户访问速度。</p>
</li>
</ol>
<p>从客户端读写访问的透明度来看，数据复制集群系统分下面两种：</p>
<ol>
<li>
<p>写主(WriteMaster)<br>
对数据的修改提交给指定的节点。读无此限制，可以读取任何一个节点。这种情况下客户端需要对读与写进行区别，俗称读写分离；</p>
</li>
<li>
<p>写任意(Write Any)<br>
对数据的修改可提交给任意的节点，跟读一样。这种情况下，客户端对集群节点的角色与变化透明。</p>
</li>
</ol>
<p>​    对zookeeper来说，它采用的方式是写任意。通过增加机器，它的读吞吐能力和响应能力扩展性非常好，而写，随着机器的增多吞吐能力肯定下降（这 也是它建立observer的原因），而响应能力则取决于具体实现方式，是延迟复制保持最终一致性，还是立即复制快速响应。</p>
<p>我们关注的重点还是在如何保证数据在集群所有机器的一致性，这就涉及到paxos算法。</p>
<h3 id="7-数据一致性与paxos算法">7、数据一致性与paxos算法</h3>
<p>​    据说Paxos算法的难理解与算法的知名度一样令人敬仰，所以我们先看如何保持数据的一致性，这里有个原则就是：</p>
<blockquote>
<p>在一个分布式数据库系统中，如果各节点的初始状态一致，每个节点都执行相同的操作序列，那么他们最后能得到一个一致的状态。</p>
</blockquote>
<p>​    Paxos算法解决的什么问题呢，解决的就是保证每个节点执行相同的操作序列。好吧，这还不简单，master维护一个全局写队列，所有写操作都必须 放入这个队列编号，那么无论我们写多少个节点，只要写操作是按编号来的，就能保证一致性。没错，就是这样，可是如果master挂了呢。</p>
<p>​    Paxos算法通过投票来对写操作进行全局编号，同一时刻，只有一个写操作被批准，同时并发的写操作要去争取选票，只有获得过半数选票的写操作才会被 批准（所以永远只会有一个写操作得到批准），其他的写操作竞争失败只好再发起一轮投票，就这样，在日复一日年复一年的投票中，所有写操作都被严格编号排 序。编号严格递增，当一个节点接受了一个编号为100的写操作，之后又接受到编号为99的写操作（因为网络延迟等很多不可预见原因），它马上能意识到自己 数据不一致了，自动停止对外服务并重启同步过程。任何一个节点挂掉都不会影响整个集群的数据一致性（总2n+1台，除非挂掉大于n台）。</p>
<p><strong>总结</strong></p>
<p>​    Zookeeper 作为 Hadoop 项目中的一个子项目，是 Hadoop 集群管理的一个必不可少的模块，它主要用来控制集群中的数据，如它管理 Hadoop 集群中的 NameNode，还有 Hbase 中 Master Election、Server 之间状态同步等。</p>
<h1 id="zookeeper工作原理">Zookeeper工作原理</h1>
<p>​    ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，它包含一个简单的原语集，分布式应用程序可以基于它实现同步服务，配置维护和 命名服务等。Zookeeper是hadoop的一个子项目，其发展历程无需赘述。在分布式应用中，由于工程师不能很好地使用锁机制，以及基于消息的协调 机制不适合在某些应用中使用，因此需要有一种可靠的、可扩展的、分布式的、可配置的协调机制来统一系统的状态。Zookeeper的目的就在于此。</p>
<h2 id="zookeeper的基本概念">Zookeeper的基本概念</h2>
<h3 id="11-角色">1.1 角色</h3>
<p>Zookeeper中的角色主要有以下三类，如下表所示：</p>
<p>​             <img src="https://tinaxiawuhao.github.io/post-images/1622442715591.png" alt="" loading="lazy"></p>
<p>系统模型如图所示：</p>
<p>​            <img src="https://tinaxiawuhao.github.io/post-images/1622442726565.jpg" alt="" loading="lazy"></p>
<h3 id="12-设计目的">1.2 设计目的</h3>
<ol>
<li>
<p>最终一致性：client不论连接到哪个Server，展示给它都是同一个视图，这是zookeeper最重要的性能。</p>
</li>
<li>
<p>可靠性：具有简单、健壮、良好的性能，如果消息m被到一台服务器接受，那么它将被所有的服务器接受。</p>
</li>
<li>
<p>实时性：Zookeeper保证客户端将在一个时间间隔范围内获得服务器的更新信息，或者服务器失效的信息。但由于网络延时等原因，Zookeeper不能保证两个客户端能同时得到刚更新的数据，如果需要最新数据，应该在读数据之前调用sync()接口。</p>
</li>
<li>
<p>等待无关（wait-free）：慢的或者失效的client不得干预快速的client的请求，使得每个client都能有效的等待。</p>
</li>
<li>
<p>原子性：更新只能成功或者失败，没有中间状态。</p>
</li>
<li>
<p>顺序性：包括全局有序和偏序两种：全局有序是指如果在一台服务器上消息a在消息b前发布，则在所有Server上消息a都将在消息b前被发布；偏序是指如果一个消息b在消息a后被同一个发送者发布，a必将排在b前面。</p>
</li>
</ol>
<h2 id="zookeeper的流程设计">ZooKeeper的流程设计</h2>
<p>​    Zookeeper的核心是原子广播，这个机制保证了各个Server之间的同步。实现这个机制的协议叫做Zab协议。Zab协议有两种模式，它们分 别是恢复模式（选主）和广播模式（同步）。当服务启动或者在领导者崩溃后，Zab就进入了恢复模式，当领导者被选举出来，且大多数Server完成了和 leader的状态同步以后，恢复模式就结束了。状态同步保证了leader和Server具有相同的系统状态。</p>
<p>​    为了保证事务的顺序一致性，zookeeper采用了递增的事务id号（zxid）来标识事务。所有的提议（proposal）都在被提出的时候加上 了zxid。实现中zxid是一个64位的数字，它高32位是epoch用来标识leader关系是否改变，每次一个leader被选出来，它都会有一个 新的epoch，标识当前属于那个leader的统治时期。低32位用于递增计数。</p>
<p>每个Server在工作过程中有三种状态：</p>
<ul>
<li>LOOKING：当前Server不知道leader是谁，正在搜寻</li>
<li>LEADING：当前Server即为选举出来的leader</li>
<li>FOLLOWING：leader已经选举出来，当前Server与之同步</li>
</ul>
<h3 id="21-选主流程">2.1 选主流程</h3>
<p>当leader崩溃或者leader失去大多数的follower，这时候zk进入恢复模式，恢复模式需要重新选举出一个新的leader，让所有的 Server都恢复到一个正确的状态。Zk的选举算法有两种：一种是基于basic paxos实现的，另外一种是基于fast paxos算法实现的。系统默认的选举算法为fast paxos。先介绍basic paxos流程：</p>
<p>​    1 .选举线程由当前Server发起选举的线程担任，其主要功能是对投票结果进行统计，并选出推荐的Server；</p>
<p>​    2 .选举线程首先向所有Server发起一次询问(包括自己)；</p>
<p>​    3 .选举线程收到回复后，验证是否是自己发起的询问(验证zxid是否一致)，然后获取对方的id(myid)，并存储到当前询问对象列表中，最后获取对方提议的leader相关信息(    id,zxid)，并将这些信息存储到当次选举的投票记录表中；</p>
<p>​    4.  收到所有Server回复以后，就计算出zxid最大的那个Server，并将这个Server相关信息设置成下一次要投票的Server；</p>
<p>​    5.  线程将当前zxid最大的Server设置为当前Server要推荐的Leader，如果此时获胜的Server获得n/2 + 1的Server票数， 设置当前推荐的leader为获胜的Server，将根据获胜的Server相关信息设置自己的状态，否则，继续这个过程，直到leader被选举出来。</p>
<p>通过流程分析我们可以得出：要使Leader获得多数Server的支持，则Server总数必须是奇数2n+1，且存活的Server的数目不得少于n+1.</p>
<p>每个Server启动后都会重复以上流程。在恢复模式下，如果是刚从崩溃状态恢复的或者刚启动的server还会从磁盘快照中恢复数据和会话信息，zk会记录事务日志并定期进行快照，方便在恢复时进行状态恢复。选主的具体流程图如下所示：</p>
<p>​                     <img src="https://tinaxiawuhao.github.io/post-images/1622442743429.png" alt="" loading="lazy"></p>
<p>fast paxos流程是在选举过程中，某Server首先向所有Server提议自己要成为leader，当其它Server收到提议以后，解决epoch和 zxid的冲突，并接受对方的提议，然后向对方发送接受提议完成的消息，重复这个流程，最后一定能选举出Leader。其流程图如下所示：</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1622442753556.png" alt="" loading="lazy"></figure>
<h3 id="22-同步流程">2.2 同步流程</h3>
<p>选完leader以后，zk就进入状态同步过程。</p>
<p>​    1. leader等待server连接；</p>
<p>​    2 .Follower连接leader，将最大的zxid发送给leader；</p>
<p>​    3 .Leader根据follower的zxid确定同步点；</p>
<p>​    4 .完成同步后通知follower 已经成为uptodate状态；</p>
<p>​    5 .Follower收到uptodate消息后，又可以重新接受client的请求进行服务了。</p>
<p>流程图如下所示：</p>
<p>​                 <img src="https://tinaxiawuhao.github.io/post-images/1622442765596.jpg" alt="" loading="lazy"></p>
<h3 id="23-工作流程">2.3 工作流程</h3>
<h4 id="231-leader工作流程">2.3.1 Leader工作流程</h4>
<p>Leader主要有三个功能：</p>
<p>​    1 .恢复数据；</p>
<p>​    2 .维持与Learner的心跳，接收Learner请求并判断Learner的请求消息类型；</p>
<p>​    3 .Learner的消息类型主要有PING消息、REQUEST消息、ACK消息、REVALIDATE消息，根据不同的消息类型，进行不同的处理。</p>
<p>​    PING消息是指Learner的心跳信息；REQUEST消息是Follower发送的提议信息，包括写请求及同步请求；ACK消息是 Follower的对提议的回复，超过半数的Follower通过，则commit该提议；REVALIDATE消息是用来延长SESSION有效时间。<br>
Leader的工作流程简图如下所示，在实际实现中，流程要比下图复杂得多，启动了三个线程来实现功能。</p>
<p>​                <img src="https://tinaxiawuhao.github.io/post-images/1622442776052.png" alt="" loading="lazy"></p>
<h4 id="232-follower工作流程">2.3.2 Follower工作流程</h4>
<p>Follower主要有四个功能：</p>
<p>​    1. 向Leader发送请求（PING消息、REQUEST消息、ACK消息、REVALIDATE消息）；</p>
<p>​    2 .接收Leader消息并进行处理；</p>
<p>​    3 .接收Client的请求，如果为写请求，发送给Leader进行投票；</p>
<p>​    4 .返回Client结果。</p>
<p>Follower的消息循环处理如下几种来自Leader的消息：</p>
<p>​    1 .PING消息： 心跳消息；</p>
<p>​    2 .PROPOSAL消息：Leader发起的提案，要求Follower投票；</p>
<p>​    3 .COMMIT消息：服务器端最新一次提案的信息；</p>
<p>​    4 .UPTODATE消息：表明同步完成；</p>
<p>​    5 .REVALIDATE消息：根据Leader的REVALIDATE结果，关闭待revalidate的session还是允许其接受消息；</p>
<p>​    6 .SYNC消息：返回SYNC结果到客户端，这个消息最初由客户端发起，用来强制得到最新的更新。</p>
<p>Follower的工作流程简图如下所示，在实际实现中，Follower是通过5个线程来实现功能的。</p>
<p>​             <img src="https://tinaxiawuhao.github.io/post-images/1622442788398.png" alt="" loading="lazy"></p>
<p>对于observer的流程不再叙述，observer流程和Follower的唯一不同的地方就是observer不会参加leader发起的投票。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Gossip协议]]></title>
        <id>https://tinaxiawuhao.github.io/post/BmWrFaJAQ/</id>
        <link href="https://tinaxiawuhao.github.io/post/BmWrFaJAQ/">
        </link>
        <updated>2021-06-03T06:05:22.000Z</updated>
        <content type="html"><![CDATA[<h2 id="gossip">Gossip</h2>
<blockquote>
<p>Gossip协议是一个通信协议，一种传播消息的方式，灵感来自于：瘟疫、社交网络等。使用Gossip协议的有：<a href="https://tinaxiawuhao.github.io/post/FWuQD6Kxu/">Redis Cluster</a>、Consul、Apache Cassandra等。</p>
</blockquote>
<h3 id="六度分隔理论">六度分隔理论</h3>
<p>说到社交网络，就不得不提著名的六度分隔理论。1967年，哈佛大学的心理学教授Stanley Milgram想要描绘一个连结人与社区的人际连系网。做过一次连锁信实验，结果发现了“六度分隔”现象。简单地说：“你和任何一个陌生人之间所间隔的人不会超过六个，也就是说，最多通过六个人你就能够认识任何一个陌生人。</p>
<p>数学解释该理论：若每个人平均认识260人，其六度就是260↑6 =1,188,137,600,000。消除一些节点重复，那也几乎覆盖了整个地球人口若干多多倍，这也是Gossip协议的雏形。</p>
<h3 id="原理">原理</h3>
<p>Gossip协议基本思想就是：一个节点想要分享一些信息给网络中的其他的一些节点。于是，它周期性的随机选择一些节点，并把信息传递给这些节点。这些收到信息的节点接下来会做同样的事情，即把这些信息传递给其他一些随机选择的节点。一般而言，信息会周期性的传递给N个目标节点，而不只是一个。这个N被称为fanout（这个单词的本意是扇出）。</p>
<h3 id="用途">用途</h3>
<p>Gossip协议的主要用途就是信息传播和扩散：即把一些发生的事件传播到全世界。它们也被用于数据库复制，信息扩散，集群成员身份确认，故障探测等。</p>
<p>基于Gossip协议的一些有名的系统：Apache Cassandra，Redis（Cluster模式），Consul等。</p>
<h3 id="图解">图解</h3>
<p>接下来通过多张图片剖析Gossip协议是如何运行的。如下图所示，Gossip协议是周期循环执行的。图中的公式表示Gossip协议把信息传播到每一个节点需要多少次循环动作，需要说明的是，公式中的20表示整个集群有20个节点，4表示某个节点会向4个目标节点传播消息：</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1622442855693.jpg" alt="" loading="lazy"></figure>
<p>Gossip Protocol</p>
<p>如下图所示，红色的节点表示其已经“受到感染”，即接下来要传播信息的源头，连线表示这个初始化感染的节点能正常连接的节点（其不能连接的节点只能靠接下来感染的节点向其传播消息）。并且N等于4，我们假设4根较粗的线路，就是它第一次传播消息的线路：</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1622442872607.jpg" alt="" loading="lazy"></figure>
<p>first infected node</p>
<p>第一次消息完成传播后，新增了4个节点会被“感染”，即这4个节点也收到了消息。这时候，总计有5个节点变成红色：</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1622442882247.jpg" alt="" loading="lazy"></figure>
<p>infected nodes</p>
<p>那么在下一次传播周期时，总计有5个节点，且这5个节点每个节点都会向4个节点传播消息。最后，经过3次循环，20个节点全部被感染（都变成红色节点），即说明需要传播的消息已经传播给了所有节点：</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1622442890305.jpg" alt="" loading="lazy"></figure>
<p>infected all nodes</p>
<p>需要说明的是，20个节点且设置fanout=4，公式结果是2.16，这只是个近似值。真实传递时，可能需要3次甚至4次循环才能让所有节点收到消息。这是因为每个节点在传播消息的时候，是随机选择N个节点的，这样的话，就有可能某个节点会被选中2次甚至更多次。</p>
<h3 id="发送消息">发送消息</h3>
<p>由前面对Gossip协议图解分析可知，节点传播消息是周期性的，并且每个节点有它自己的周期。另外，节点发送消息时的目标节点数由参数fanout决定。至于往哪些目标节点发送，则是随机的。</p>
<p>一旦消息被发送到目标节点，那么目标节点也会被感染。一旦某个节点被感染，那么它也会向其他节点传播消息，试图感染更多的节点。最终，每一个节点都会被感染，即消息被同步给了所有节点：</p>
<h3 id="可扩展性">可扩展性</h3>
<p>Gossip协议是可扩展的，因为它只需要O(logN) 个周期就能把消息传播给所有节点。某个节点在往固定数量节点传播消息过程中，并不需要等待确认（ack），并且，即使某条消息传播过程中丢失，它也不需要做任何补偿措施。打个比方，某个节点本来需要将消息传播给4个节点，但是由于网络或者其他原因，只有3个消息接收到消息，即使这样，这对最终所有节点接收到消息是没有任何影响的。</p>
<p>如下表格所示，假定fanout=4，那么在节点数分别是20、40、80、160时，消息传播到所有节点需要的循环次数对比，在节点成倍扩大的情况下，循环次数并没有增加很多。所以，Gossip协议具备可扩展性：</p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1622442912159.jpg" alt="" loading="lazy"></figure>
<h3 id="失败容错">失败容错</h3>
<p>Gossip也具备失败容错的能力，即使网络故障等一些问题，Gossip协议依然能很好的运行。因为一个节点会多次分享某个需要传播的信息，即使不能连通某个节点，其他被感染的节点也会尝试向这个节点传播信息。</p>
<h3 id="健壮性">健壮性</h3>
<p>Gossip协议下，没有任何扮演特殊角色的节点（比如leader等）。任何一个节点无论什么时候下线或者加入，并不会破坏整个系统的服务质量。</p>
<p>然而，Gossip协议也有不完美的地方，例如，拜占庭问题（Byzantine）。即，如果有一个恶意传播消息的节点，Gossip协议的分布式系统就会出问题。</p>
<blockquote>
<p>作者：阿飞的博客<br>
原文地址：https://www.jianshu.com/p/54eab117e6ae</p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[CAP/BASE]]></title>
        <id>https://tinaxiawuhao.github.io/post/cxyiXFW2S/</id>
        <link href="https://tinaxiawuhao.github.io/post/cxyiXFW2S/">
        </link>
        <updated>2021-06-02T02:44:25.000Z</updated>
        <content type="html"><![CDATA[<h3 id="cap原则">CAP原则</h3>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1622442944478.png" alt="" loading="lazy"></figure>
<blockquote>
<p>CAP原则又称CAP定理，指的是在一个分布式系统中， Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），三者不可得兼。</p>
</blockquote>
<p><strong>CAP原则是NOSQL数据库的基石。</strong></p>
<p>分布式系统的CAP理论：理论首先把分布式系统中的三个特性进行了如下归纳：</p>
<ul>
<li>一致性（C）：在分布式系统中的所有数据备份，在同一时刻是否同样的值。（等同于所有节点访问同一份最新的数据副本）</li>
<li>可用性（A）：在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求。（对数据更新具备高可用性）</li>
<li>分区容忍性（P）：以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据正常返回，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择。</li>
</ul>
<h4 id="一致性与可用性的决择编辑">一致性与可用性的决择编辑</h4>
<p>CAP理论就是说在分布式存储系统中，最多只能实现上面的两点。而由于当前的网络硬件肯定会出现延迟丢包等问题，所以分区容忍性是我们必须需要实现的。所以我们只能在一致性和可用性之间进行权衡，没有NoSQL系统能同时保证这三点。</p>
<p>对于web2.0网站来说，关系数据库的很多主要特性却往往无用武之地</p>
<ol>
<li>
<p>数据库事务一致性需求<br>
　　很多web实时系统并不要求严格的数据库事务，对读一致性的要求很低，有些场合对写一致性要求并不高。允许实现最终一致性。</p>
</li>
<li>
<p>数据库的写实时性和读实时性需求<br>
　　对关系数据库来说，插入一条数据之后立刻查询，是肯定可以读出来这条数据的，但是对于很多web应用来说，并不要求这么高的实时性，比方说发一条消息之 后，过几秒乃至十几秒之后，我的订阅者才看到这条动态是完全可以接受的。</p>
</li>
<li>
<p>对复杂的SQL查询，特别是多表关联查询的需求<br>
　　任何大数据量的web系统，都非常忌讳多个大表的关联查询，以及复杂的数据分析类型的报表查询，特别是SNS类型的网站，从需求以及产品设计角 度，就避免了这种情况的产生。往往更多的只是单表的主键查询，以及单表的简单条件分页查询，SQL的功能被极大的弱化了。</p>
</li>
</ol>
<h4 id="cap定理的证明">CAP定理的证明</h4>
<p>现在我们就来证明一下，为什么不能同时满足三个特性？</p>
<p>假设有两台服务器，一台放着应用A和数据库V，一台放着应用B和数据库V，他们之间的网络可以互通，也就相当于分布式系统的两个部分。</p>
<p>在满足一致性的时候，两台服务器 N1和N2，一开始两台服务器的数据是一样的，DB0=DB0。在满足可用性的时候，用户不管是请求N1或者N2，都会得到立即响应。在满足分区容错性的情况下，N1和N2有任何一方宕机，或者网络不通的时候，都不会影响N1和N2彼此之间的正常运作。</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1629103855489.png" alt="" loading="lazy"></figure>
<p>当用户通过N1中的A应用请求数据更新到服务器DB0后，这时N1中的服务器DB0变为DB1，通过分布式系统的数据同步更新操作，N2服务器中的数据库V0也更新为了DB1，这时，用户通过B向数据库发起请求得到的数据就是即时更新后的数据DB1。</p>
<p>上面是正常运作的情况，但分布式系统中，最大的问题就是网络传输问题，现在假设一种极端情况，N1和N2之间的网络断开了，但我们仍要支持这种网络异常，也就是满足分区容错性，那么这样能不能同时满足一致性和可用性呢？</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1629103871249.png" alt="" loading="lazy"></figure>
<p>假设N1和N2之间通信的时候网络突然出现故障，有用户向N1发送数据更新请求，那N1中的数据DB0将被更新为DB1，由于网络是断开的，N2中的数据库仍旧是DB0；</p>
<p>如果这个时候，有用户向N2发送数据读取请求，由于数据还没有进行同步，应用程序没办法立即给用户返回最新的数据DB1，怎么办呢？有二种选择，第一，牺牲数据一致性，响应旧的数据DB0给用户；第二，牺牲可用性，阻塞等待，直到网络连接恢复，数据更新操作完成之后，再给用户响应最新的数据DB1。</p>
<p>上面的过程比较简单，但也说明了要满足分区容错性的分布式系统，只能在一致性和可用性两者中，选择其中一个。也就是说分布式系统不可能同时满足三个特性。这就需要我们在搭建系统时进行取舍了，那么，怎么取舍才是更好的策略呢?</p>
<h4 id="取舍策略">取舍策略</h4>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1622442957998.png" alt="" loading="lazy"></figure>
<p>CAP三个特性只能满足其中两个，那么取舍的策略就共有三种：</p>
<p><strong>CA without P：</strong> 如果不要求P（不允许分区），则C（强一致性）和A（可用性）是可以保证的。但放弃P的同时也就意味着放弃了系统的扩展性，也就是分布式节点受限，没办法部署子节点，这是违背分布式系统设计的初衷的。传统的关系型数据库RDBMS：Oracle、MySQL就是CA。</p>
<p><strong>CP without A：</strong> 如果不要求A（可用），相当于每个请求都需要在服务器之间保持强一致，而P（分区）会导致同步时间无限延长(也就是等待数据同步完才能正常访问服务)，一旦发生网络故障或者消息丢失等情况，就要牺牲用户的体验，等待所有数据全部一致了之后再让用户访问系统。设计成CP的系统其实不少，最典型的就是分布式数据库，如Redis、HBase等。对于这些分布式数据库来说，数据的一致性是最基本的要求，因为如果连这个标准都达不到，那么直接采用关系型数据库就好，没必要再浪费资源来部署分布式数据库。</p>
<p><strong>AP wihtout C：</strong> 要高可用并允许分区，则需放弃一致性。一旦分区发生，节点之间可能会失去联系，为了高可用，每个节点只能用本地数据提供服务，而这样会导致全局数据的不一致性。典型的应用就如某米的抢购手机场景，可能前几秒你浏览商品的时候页面提示是有库存的，当你选择完商品准备下单的时候，系统提示你下单失败，商品已售完。这其实就是先在 A（可用性）方面保证系统可以正常的服务，然后在数据的一致性方面做了些牺牲，虽然多少会影响一些用户体验，但也不至于造成用户购物流程的严重阻塞。</p>
<h3 id="base理论">BASE理论</h3>
<blockquote>
<p>BASE是Basically Available（基本可用）、Soft state（软状态）和Eventually consistent（最终一致性）三个短语的简写，BASE是对CAP中一致性和可用性权衡的结果，其来源于对大规模互联网系统分布式实践的结论，是基于CAP定理逐步演化而来的，其核心思想是即使无法做到强一致性（Strong consistency），但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性（Eventual consistency）。接下来我们着重对BASE中的三要素进行详细讲解。</p>
</blockquote>
<h4 id="基本可用">基本可用</h4>
<p>基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性——但请注意，这绝不等价于系统不可用，以下两个就是“基本可用”的典型例子。</p>
<ul>
<li>响应时间上的损失：正常情况下，一个在线搜索引擎需要0.5秒内返回给用户相应的查询结果，但由于出现异常（比如系统部分机房发生断电或断网故障），查询结果的响应时间增加到了1~2秒。</li>
<li>功能上的损失：正常情况下，在一个电子商务网站上进行购物，消费者几乎能够顺利地完成每一笔订单，但是在一些节日大促购物高峰的时候，由于消费者的购物行为激增，为了保护购物系统的稳定性，部分消费者可能会被引导到一个降级页面。</li>
</ul>
<h4 id="弱状态">弱状态</h4>
<p>弱状态也称为软状态，和硬状态相对，是指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。</p>
<h4 id="最终一致性">最终一致性</h4>
<blockquote>
<p>最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性</p>
</blockquote>
<p>亚马逊首席技术官Werner Vogels在于2008年发表的一篇文章中对最终一致性进行了非常详细的介绍。他认为最终一致性是一种特殊的弱一致性：系统能够保证在没有其他新的更新操作的情况下，数据最终一定能够达到一致的状态，因此所有客户端对系统的数据访问都能够获取到最新的值。同时，在没有发生故障的前提下，数据达到一致状态的时间延迟，取决于网络延迟，系统负载和数据复制方案设计等因素。</p>
<p>在实际工程实践中，最终一致性存在以下五类主要变种。</p>
<ol>
<li>
<p>因果一致性：</p>
<p>因果一致性是指，如果进程A在更新完某个数据项后通知了进程B，那么进程B之后对该数据项的访问都应该能够获取到进程A更新后的最新值，并且如果进程B要对该数据项进行更新操作的话，务必基于进程A更新后的最新值，即不能发生丢失更新情况。与此同时，与进程A无因果关系的进程C的数据访问则没有这样的限制。</p>
</li>
<li>
<p>读己之所写：</p>
<p>读己之所写是指，进程A更新一个数据项之后，它自己总是能够访问到更新过的最新值，而不会看到旧值。也就是说，对于单个数据获取者而言，其读取到的数据一定不会比自己上次写入的值旧。因此，读己之所写也可以看作是一种特殊的因果一致性。</p>
</li>
<li>
<p>会话一致性：</p>
<p>会话一致性将对系统数据的访问过程框定在了一个会话当中：系统能保证在同一个有效的会话中实现“读己之所写”的一致性，也就是说，执行更新操作之后，客户端能够在同一个会话中始终读取到该数据项的最新值。</p>
</li>
<li>
<p>单调读一致性：</p>
<p>单调读一致性是指如果一个进程从系统中读取出一个数据项的某个值后，那么系统对于该进程后续的任何数据访问都不应该返回更旧的值。</p>
</li>
<li>
<p>单调写一致性：</p>
<p>单调写一致性是指，一个系统需要能够保证来自同一个进程的写操作被顺序地执行。</p>
</li>
</ol>
<p>以上就是最终一致性的五类常见的变种，在时间系统实践中，可以将其中的若干个变种互相结合起来，以构建一个具有最终一致性的分布式系统。事实上，可以将其中的若干个变种相互结合起来，以构建一个具有最终一致性特性的分布式系统。事实上，最终一致性并不是只有那些大型分布式系统才设计的特性，许多现代的关系型数据库都采用了最终一致性模型。在现代关系型数据库中，大多都会采用同步和异步方式来实现主备数据复制技术。在同步方式中，数据的复制国耻鞥通常是更新事务的一部分，因此在事务完成后，主备数据库的数据就会达到一致。而在异步方式中，备库的更新往往存在延时，这取决于事务日志在主备数据库之间传输的时间长短，如果传输时间过长或者甚至在日志传输过程中出现异常导致无法及时将事务应用到备库上，那么狠显然，从备库中读取的的数据将是旧的，因此就出现了不一致的情况。当然，无论是采用多次重试还是认为数据订正，关系型数据库还是能搞保证最终数据达到一致——这就是系统提供最终一致性保证的经典案例。</p>
<p>总的来说，BASE理论面向的是大型高可用可扩展的分布式系统，和传统事务的ACID特性使相反的，它完全不同于ACID的强一致性模型，而是提出通过牺牲强一致性来获得可用性，并允许数据在一段时间内是不一致的，但最终达到一致状态。但同时，在实际的分布式场景中，不同业务单元和组件对数据一致性的要求是不同的，因此在具体的分布式系统架构设计过程中，ACID特性与BASE理论往往又会结合在一起使用。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[MyBatis 缓存详解]]></title>
        <id>https://tinaxiawuhao.github.io/post/P-yYZmx9j/</id>
        <link href="https://tinaxiawuhao.github.io/post/P-yYZmx9j/">
        </link>
        <updated>2021-06-01T08:51:37.000Z</updated>
        <content type="html"><![CDATA[<p>缓存是一般的ORM 框架都会提供的功能，目的就是提升查询的效率和减少数据库的压力。跟Hibernate 一样，MyBatis 也有一级缓存和二级缓存，并且预留了集成第三方缓存的接口。</p>
<p>缓存体系结构：</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1622193533861.png" alt="" loading="lazy"></figure>
<p>MyBatis 跟缓存相关的类都在cache 包里面，其中有一个Cache 接口，只有一个默认的实现类 <code>PerpetualCache</code>，它是用<code>HashMap</code> 实现的。</p>
<p>所有的缓存实现类总体上可分为三类：基本缓存、淘汰算法缓存、装饰器缓存。</p>
<table>
<thead>
<tr>
<th style="text-align:center">缓存实现类</th>
<th style="text-align:center">描述</th>
<th style="text-align:center">作用</th>
<th style="text-align:center">装饰条件</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">基本缓存</td>
<td style="text-align:center">缓存基本实现类</td>
<td style="text-align:center">默认是PerpetualCache，也可以自定义比如RedisCache等，具备基本功能的缓存类</td>
<td style="text-align:center">无</td>
</tr>
<tr>
<td style="text-align:center">LruCache</td>
<td style="text-align:center">LRU策略的缓存</td>
<td style="text-align:center">当缓存达到上限时，删除最近最少使用的缓存</td>
<td style="text-align:center">eviction=“LRU” （默认）</td>
</tr>
<tr>
<td style="text-align:center">FifoCache</td>
<td style="text-align:center">FIFO策略的缓存</td>
<td style="text-align:center">当缓存达到上限时，删除最先入队的缓存</td>
<td style="text-align:center">eviction=“FIFO”</td>
</tr>
<tr>
<td style="text-align:center">SoftCache/WeakCache</td>
<td style="text-align:center">带清理策略的缓存</td>
<td style="text-align:center">通过JVM的软引用和弱引用来实现缓存，当JVM内存不足时，会自动清理掉这些缓存</td>
<td style="text-align:center">eviction=“SOFT”/eviction=“WEAK”</td>
</tr>
<tr>
<td style="text-align:center">LoggingCache</td>
<td style="text-align:center">带日志功能的缓存</td>
<td style="text-align:center">比如输出缓存命中率</td>
<td style="text-align:center">基本</td>
</tr>
<tr>
<td style="text-align:center">SynchronizedCache</td>
<td style="text-align:center">同步缓存</td>
<td style="text-align:center">基于Synchronized关键字实现，解决并发问题</td>
<td style="text-align:center">基本</td>
</tr>
<tr>
<td style="text-align:center">BlockingCache</td>
<td style="text-align:center">阻塞缓存</td>
<td style="text-align:center">通过在get/put方式中加锁，保证只有一个线程操作缓存，基于Java重入锁实现</td>
<td style="text-align:center">blocking=true</td>
</tr>
<tr>
<td style="text-align:center">SerializedCache</td>
<td style="text-align:center">支持序列化的缓存</td>
<td style="text-align:center">将对象序列化以后存到缓存中，取出是反序列化</td>
<td style="text-align:center">readOnly=false(默认)</td>
</tr>
<tr>
<td style="text-align:center">ScheduledCache</td>
<td style="text-align:center">定时调度的缓存</td>
<td style="text-align:center">在进行 get/put/remove/getSize 等操作前，判断 缓存时间是否超过了设置的最长缓存时间（默认是 一小时），如果是则清空缓存–即每隔一段时间清 空一次缓存</td>
<td style="text-align:center">flushInterval不为空</td>
</tr>
<tr>
<td style="text-align:center">TransactionalCache</td>
<td style="text-align:center">事务缓存</td>
<td style="text-align:center">在二级缓存中使用，可以一次存入多个缓存，删除多个缓存</td>
<td style="text-align:center">在TransactionalCacheManager中用Map维护对应关系</td>
</tr>
</tbody>
</table>
<h3 id="一级缓存本地缓存">一级缓存（本地缓存）</h3>
<p>一级缓存也叫本地缓存，MyBatis 的一级缓存是在会话（SqlSession）层面进行缓存的。MyBatis 的一级缓存是默认开启的，不需要任何的配置。首先我们必须去弄清楚一个问题，在MyBatis 执行的流程里面，涉及到这么多的对象，那么缓存<code>PerpetualCache</code> 应该放在哪个对象里面去维护？如果要在同一个会话里面共享一级缓存，这个对象肯定是在SqlSession 里面创建的，作为SqlSession 的一个属性。</p>
<p><code>DefaultSqlSession</code> 里面只有两个属性，Configuration 是全局的，所以缓存只可能放在Executor 里面维护——<code>SimpleExecutor/ReuseExecutor/BatchExecutor</code> 的父类<code>BaseExecutor</code>的构造函数中持有了<code>PerpetualCache</code>。在同一个会话里面，多次执行相同的SQL 语句，会直接从内存取到缓存的结果，不会再发送SQL 到数据库。但是不同的会话里面，即使执行的SQL 一模一样（通过一个Mapper 的同一个方法的相同参数调用），也不能使用到一级缓存。</p>
<p>如下图所示，MyBatis会在一次会话的表示----一个SqlSession对象中创建一个本地缓存(local cache)，对于每一次查询，都会尝试根据查询的条件去本地缓存中查找是否在缓存中，如果在缓存中，就直接从缓存中取出，然后返回给用户；否则，从数据库读取数据，将查询结果存入缓存并返回给用户。</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1622193556324.png" alt="" loading="lazy"></figure>
<p>一级缓存的生命周期有多长？</p>
<ol>
<li>MyBatis在开启一个数据库会话时，会 创建一个新的<code>SqlSession</code>对象，<code>SqlSession</code>对象中会有一个新的Executor对象，Executor对象中持有一个新的<code>PerpetualCache</code>对象；当会话结束时，<code>SqlSession</code>对象及其内部的Executor对象还有<code>PerpetualCache</code>对象也一并释放掉。</li>
<li>如果<code>SqlSession</code>调用了close()方法，会释放掉一级缓存<code>PerpetualCache</code>对象，一级缓存将不可用；</li>
<li>如果<code>SqlSession</code>调用了<code>clearCache()</code>，会清空<code>PerpetualCache</code>对象中的数据，但是该对象仍可使用；</li>
<li><code>SqlSession</code>中执行了任何一个update操作(update()、delete()、insert()) ，都会清空<code>PerpetualCache</code>对象的数据，但是该对象可以继续使用；</li>
</ol>
<p>SqlSession 一级缓存的工作流程：</p>
<ol>
<li>对于某个查询，根据<code>statementId</code>,<code>params</code>,<code>rowBounds</code>来构建一个key值，根据这个key值去缓存Cache中取出对应的key值存储的缓存结果</li>
<li>判断从Cache中根据特定的key值取的数据数据是否为空，即是否命中；</li>
<li>如果命中，则直接将缓存结果返回；</li>
<li>如果没命中：</li>
</ol>
<ul>
<li>
<ol>
<li>去数据库中查询数据，得到查询结果；</li>
<li>将key和查询到的结果分别作为key,value对存储到Cache中；</li>
<li>将查询结果返回；</li>
</ol>
</li>
</ul>
<p>接下来我们来验证一下，MyBatis 的一级缓存到底是不是只能在一个会话里面共享，以及跨会话（不同session）操作相同的数据会产生什么问题。判断是否命中缓存：如果再次发送SQL 到数据库执行，说明没有命中缓存；如果直接打印对象，说明是从内存缓存中取到了结果。</p>
<ol>
<li>
<p>在同一个session 中共享（不同session 不能共享）</p>
</li>
<li>
<p>同一个会话中，update（包括delete）会导致一级缓存被清空</p>
</li>
<li>
<p>其他会话更新了数据，导致读取到脏数据（一级缓存不能跨会话共享）</p>
</li>
</ol>
<p>一级缓存的不足：</p>
<p>使用一级缓存的时候，因为缓存不能跨会话共享，不同的会话之间对于相同的数据可能有不一样的缓存。在有多个会话或者分布式环境下，会存在脏数据的问题。如果要解决这个问题，就要用到二级缓存。MyBatis 一级缓存（MyBaits 称其为 Local Cache）无法关闭，但是有两种级别可选：</p>
<ol>
<li>session 级别的缓存，在同一个 sqlSession 内，对同样的查询将不再查询数据库，直接从缓存中。</li>
<li>statement 级别的缓存，避坑： 为了避免这个问题，可以将一级缓存的级别设为 statement 级别的，这样每次查询结束都会清掉一级缓存。</li>
</ol>
<h3 id="二级缓存">二级缓存</h3>
<p>二级缓存是用来解决一级缓存不能跨会话共享的问题的，范围是<code>namespace</code> 级别的，可以被多个<code>SqlSession</code> 共享（只要是同一个接口里面的相同方法，都可以共享），生命周期和应用同步。如果你的MyBatis使用了二级缓存，并且你的Mapper和select语句也配置使用了二级缓存，那么在执行select查询的时候，MyBatis会先从二级缓存中取输入，其次才是一级缓存，即MyBatis查询数据的顺序是：二级缓存  —&gt; 一级缓存 —&gt; 数据库。</p>
<p>作为一个作用范围更广的缓存，它肯定是在SqlSession 的外层，否则不可能被多个SqlSession 共享。而一级缓存是在SqlSession 内部的，所以第一个问题，肯定是工作在一级缓存之前，也就是只有取不到二级缓存的情况下才到一个会话中去取一级缓存。第二个问题，二级缓存放在哪个对象中维护呢？ 要跨会话共享的话，SqlSession 本身和它里面的BaseExecutor 已经满足不了需求了，那我们应该在BaseExecutor 之外创建一个对象。</p>
<p>实际上MyBatis 用了一个装饰器的类来维护，就是<code>CachingExecutor</code>。如果启用了二级缓存，MyBatis 在创建Executor 对象的时候会对Executor 进行装饰。<code>CachingExecutor</code> 对于查询请求，会判断二级缓存是否有缓存结果，如果有就直接返回，如果没有委派交给真正的查询器Executor 实现类，比如<code>SimpleExecutor</code> 来执行查询，再走到一级缓存的流程。最后会把结果缓存起来，并且返回给用户。</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1622193575153.png" alt="" loading="lazy"></figure>
<p>开启二级缓存的方法</p>
<p>第一步：配置 <code>mybatis.configuration.cache-enabled=true</code>，只要没有显式地设置<code>cacheEnabled=false</code>，都会用<code>CachingExecutor</code> 装饰基本的执行器。</p>
<p>第二步：在Mapper.xml 中配置<cache/>标签：</p>
<pre><code class="language-xml">&lt;cache type=&quot;org.apache.ibatis.cache.impl.PerpetualCache&quot;
    size=&quot;1024&quot;
eviction=&quot;LRU&quot;
flushInterval=&quot;120000&quot;
readOnly=&quot;false&quot;/&gt;
</code></pre>
<p>基本上就是这样。这个简单语句的效果如下:</p>
<ul>
<li>映射语句文件中的所有 select 语句的结果将会被缓存。</li>
<li>映射语句文件中的所有 insert、update 和 delete 语句会刷新缓存。</li>
<li>缓存会使用最近最少使用算法（LRU, Least Recently Used）算法来清除不需要的缓存。</li>
<li>缓存不会定时进行刷新（也就是说，没有刷新间隔）。</li>
<li>缓存会保存列表或对象（无论查询方法返回哪种）的 1024 个引用。</li>
<li>缓存会被视为读/写缓存，这意味着获取到的对象并不是共享的，可以安全地被调用者修改，而不干扰其他调用者或线程所做的潜在修改。</li>
</ul>
<p>这个更高级的配置创建了一个 FIFO 缓存，每隔 60 秒刷新，最多可以存储结果对象或列表的 512 个引用，而且返回的对象被认为是只读的，因此对它们进行修改可能会在不同线程中的调用者产生冲突。可用的清除策略有：</p>
<ul>
<li>LRU – 最近最少使用：移除最长时间不被使用的对象。</li>
<li>FIFO – 先进先出：按对象进入缓存的顺序来移除它们。</li>
<li>SOFT – 软引用：基于垃圾回收器状态和软引用规则移除对象。</li>
<li>WEAK – 弱引用：更积极地基于垃圾收集器状态和弱引用规则移除对象。</li>
</ul>
<p>默认的清除策略是 LRU。</p>
<p><strong><code>flushInterval</code></strong>（刷新间隔）属性可以被设置为任意的正整数，设置的值应该是一个以毫秒为单位的合理时间量。 默认情况是不设置，也就是没有刷新间隔，缓存仅仅会在调用语句时刷新。</p>
<p><strong><code>size</code></strong>（引用数目）属性可以被设置为任意正整数，要注意欲缓存对象的大小和运行环境中可用的内存资源。默认值是 1024。</p>
<p><strong><code>readOnly</code></strong>（只读）属性可以被设置为 true 或 false。只读的缓存会给所有调用者返回缓存对象的相同实例。 因此这些对象不能被修改。这就提供了可观的性能提升。而可读写的缓存会（通过序列化）返回缓存对象的拷贝。 速度上会慢一些，但是更安全，因此默认值是 false。</p>
<p>注：二级缓存是事务性的。这意味着，当 SqlSession 完成并提交时，或是完成并回滚，但没有执行 <code>flushCache=true</code>的 <code>insert/delete/update</code> 语句时，缓存会获得更新。</p>
<p><code>Mapper.xml</code> 配置了<cache>之后，select()会被缓存。update()、delete()、insert()会刷新缓存。：如果<code>cacheEnabled=true</code>，<code>Mapper.xml</code> 没有配置标签，还有二级缓存吗？（没有）还会出现CachingExecutor 包装对象吗？（会）</p>
<p>只要<code>cacheEnabled=true</code> 基本执行器就会被装饰。有没有配置<cache>，决定了在启动的时候会不会创建这个mapper 的Cache 对象，只是最终会影响到<code>CachingExecutorquery</code> 方法里面的判断。如果某些查询方法对数据的实时性要求很高，不需要二级缓存，怎么办？我们可以在单个Statement ID 上显式关闭二级缓存（默认是true）：</p>
<pre><code class="language-xml">&lt;select id=&quot;selectBlog&quot; resultMap=&quot;BaseResultMap&quot; useCache=&quot;false&quot;&gt;
</code></pre>
<h4 id="第三方缓存做二级缓存">第三方缓存做二级缓存</h4>
<p>除了MyBatis 自带的二级缓存之外，我们也可以通过实现Cache 接口来自定义二级缓存。MyBatis 官方提供了一些第三方缓存集成方式，比如ehcache 和redis：https://github.com/mybatis/redis-cache ,这里就不过多介绍了。当然，我们也可以使用独立的缓存服务，不使用MyBatis 自带的二级缓存。</p>
<p>pom 文件引入依赖：</p>
<pre><code class="language-java">&lt;dependency&gt;
	&lt;groupId&gt;org.mybatis.caches&lt;/groupId&gt;
	&lt;artifactId&gt;mybatis-redis&lt;/artifactId&gt;
	&lt;version&gt;1.0.0-beta2&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<p>MybatisRedisCache</p>
<pre><code class="language-java">
import com.xxx.util.JsonUtils;
import org.apache.ibatis.cache.Cache;
import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;
import org.springframework.data.redis.core.RedisTemplate;
 
import java.util.concurrent.locks.ReadWriteLock;
import java.util.concurrent.locks.ReentrantReadWriteLock;
 
/**
 * Mybatis - redis二级缓存
 *
 */
public final class MybatisRedisCache implements Cache {
    /**
     * 日志工具类
     */
    private static final Logger logger = LogManager.getLogger(MybatisRedisCache.class);
 
    /**
     * 读写锁
     */
    private final ReadWriteLock readWriteLock = new ReentrantReadWriteLock();
    /**
     * ID
     */
    private String id;
 
    /**
     * 集成redisTemplate
     */
    private static RedisTemplate redisTemplate;
 
    public MybatisRedisCache() {
    }
 
    public MybatisRedisCache(String id) {
        if (id == null) {
            throw new IllegalArgumentException(&quot;Cache instances require an ID&quot;);
        } else {
            logger.debug(&quot;MybatisRedisCache.id={}&quot;, id);
            this.id = id;
        }
    }
 
 
    @Override
    public String getId() {
        return this.id;
    }
 
    @Override
    public int getSize() {
        try {
            Long size = redisTemplate.opsForHash().size(this.id.toString());
            logger.debug(&quot;MybatisRedisCache.getSize: {}-&gt;{}&quot;, id, size);
            return size.intValue();
        } catch (Exception e) {
            e.printStackTrace();
        }
        return 0;
    }
 
    @Override
    public void putObject(final Object key, final Object value) {
        try {
            logger.debug(&quot;MybatisRedisCache.putObject: {}-&gt;{}-&gt;{}&quot;, id, key, JsonUtils.toJson(value));
            redisTemplate.opsForHash().put(this.id.toString(), key.toString(), value);
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
 
    @Override
    public Object getObject(final Object key) {
        try {
            Object hashVal = redisTemplate.opsForHash().get(this.id.toString(), key.toString());
            logger.debug(&quot;MybatisRedisCache.getObject: {}-&gt;{}-&gt;{}&quot;, id, key, JsonUtils.toJson(hashVal));
            return hashVal;
        } catch (Exception e) {
            e.printStackTrace();
            return null;
        }
    }
 
    @Override
    public Object removeObject(final Object key) {
        try {
            redisTemplate.opsForHash().delete(this.id.toString(), key.toString());
            logger.debug(&quot;MybatisRedisCache.removeObject: {}-&gt;{}-&gt;{}&quot;, id, key);
        } catch (Exception e) {
            e.printStackTrace();
        }
        return null;
    }
 
    @Override
    public void clear() {
        try {
            redisTemplate.delete(this.id.toString());
            logger.debug(&quot;MybatisRedisCache.clear: {}&quot;, id);
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
 
    @Override
    public ReadWriteLock getReadWriteLock() {
        return this.readWriteLock;
    }
 
    @Override
    public String toString() {
        return &quot;MybatisRedisCache {&quot; + this.id + &quot;}&quot;;
    }
 
    /**
     * 设置redisTemplate
     *
     * @param redisTemplate
     */
    public void setRedisTemplate(RedisTemplate redisTemplate) {
        MybatisRedisCache.redisTemplate = redisTemplate;
    }
}
</code></pre>
<p>RedisConfig</p>
<pre><code class="language-java">import com.fasterxml.jackson.annotation.JsonAutoDetect;
import com.fasterxml.jackson.annotation.PropertyAccessor;
import com.fasterxml.jackson.databind.ObjectMapper;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.data.redis.connection.RedisConnectionFactory;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer;
import org.springframework.data.redis.serializer.StringRedisSerializer;

/**
 * Redis配置
 *
 */

@Configuration
public class RedisConfig {

    /**
     * 配置RedisTemplate
     *
     * @param factory
     * @return
     */
    @Bean
    public RedisTemplate redisTemplate(RedisConnectionFactory factory, Jackson2JsonRedisSerializer redisJsonSerializer) {
        RedisTemplate&lt;Object, Object&gt; template = new RedisTemplate&lt;&gt;();
        //redis连接工厂
        template.setConnectionFactory(factory);
        StringRedisSerializer stringRedisSerializer = new StringRedisSerializer();
        //redis.key序列化器
        template.setKeySerializer(stringRedisSerializer);
        //redis.value序列化器
        template.setValueSerializer(redisJsonSerializer);
        //redis.hash.key序列化器
        template.setHashKeySerializer(stringRedisSerializer);
        //redis.hash.value序列化器
        template.setHashValueSerializer(redisJsonSerializer);
        //调用其他初始化逻辑
        template.afterPropertiesSet();
        //这里设置redis事务一致
        template.setEnableTransactionSupport(true);
        return template;
    }

    /**
     * 配置redis Json序列化器
     *
     * @return
     */
    @Bean
    public Jackson2JsonRedisSerializer redisJsonSerializer() {
        //使用Jackson2JsonRedisSerializer来序列化和反序列化redis的value值（默认使用JDK的序列化方式）
        Jackson2JsonRedisSerializer serializer = new Jackson2JsonRedisSerializer(Object.class);
        ObjectMapper mapper = new ObjectMapper();
        mapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);
        mapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);
        serializer.setObjectMapper(mapper);
        return serializer;
    }

}
</code></pre>
<p>开启Mybatis二级缓存设置</p>
<p>方式1：mybatis-config.xml</p>
<pre><code class="language-java">&lt;configuration&gt;
    &lt;settings&gt;
        &lt;!-- 开启二级缓存 --&gt;
        &lt;setting name=&quot;cacheEnabled&quot; value=&quot;true&quot;/&gt;
    &lt;/settings&gt;
   ...
&lt;/configuration&gt;
</code></pre>
<p>方式2：Springboot - application.properties</p>
<pre><code class="language-java">#使全局的映射器启用或禁用缓存。
mybatis.configuration.cache-enabled=true
</code></pre>
<p>Mapper.xml 配置，type 使用RedisCache：</p>
<pre><code class="language-java">&lt;cache type=&quot;org.mybatis.caches.redis.RedisCache&quot;
eviction=&quot;FIFO&quot; flushInterval=&quot;60000&quot; size=&quot;512&quot; readOnly=&quot;true&quot;/&gt;
</code></pre>
<p>redis.properties 配置：</p>
<pre><code class="language-java">host=localhost
port=6379
connectionTimeout=5000
soTimeout=5000
database=0
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[springBoot概述]]></title>
        <id>https://tinaxiawuhao.github.io/post/O58auJO44/</id>
        <link href="https://tinaxiawuhao.github.io/post/O58auJO44/">
        </link>
        <updated>2021-05-31T08:29:40.000Z</updated>
        <content type="html"><![CDATA[<h2 id="spring-boot-优点">Spring Boot 优点</h2>
<ol>
<li>容易上手，提升开发效率，为 Spring 开发提供一个更快、更广泛的入门体验。</li>
<li>开箱即用，远离繁琐的配置。</li>
<li>提供了一系列大型项目通用的非业务性功能，例如：内嵌服务器、安全管理、运行数据监控、运行状况检查和外部化配置等。</li>
<li>没有代码生成，也不需要XML配置。</li>
<li>避免大量的 Maven 导入和各种版本冲突。</li>
</ol>
<h2 id="spring-boot-的核心注解是哪个它主要由哪几个注解组成的">Spring Boot 的核心注解是哪个？它主要由哪几个注解组成的？</h2>
<p>启动类上面的注解是@SpringBootApplication，它也是 Spring Boot 的核心注解，主要组合包含了以下 3 个注解：</p>
<p><code>@SpringBootConfiguration</code>：组合了 @Configuration 注解，实现配置文件的功能。</p>
<p><code>@EnableAutoConfiguration</code>：打开自动配置的功能，也可以关闭某个自动配置的选项，如关闭数据源自动配置功能： <code>@SpringBootApplication(exclude = { DataSourceAutoConfiguration.class })</code>。</p>
<p><code>@ComponentScan</code>：Spring组件扫描。</p>
<p>所有其它 Spring 组件(如Controller层、Service层、Dao层、定时器等)都必须放在应用  @SpringBootApplication 注解所在类的同包或者其子包下面，因为应用从启动类开始启动，然后会扫描启动类同包及其子包下面的组件，如果放在其它地方则会因为扫描不到而加载不了</p>
<h2 id="javaconfig">JavaConfig</h2>
<p><code>Spring JavaConfig</code> 是 Spring 社区的产品，它提供了配置 Spring IoC 容器的纯Java 方法。因此它有助于避免使用 XML 配置。使用 JavaConfig 的优点在于：</p>
<p>（1）面向对象的配置。由于配置被定义为 JavaConfig 中的类，因此用户可以充分利用 Java 中的面向对象功能。一个配置类可以继承另一个，重写它的@Bean 方法等。</p>
<p>（2）减少或消除 XML 配置。基于依赖注入原则的外化配置的好处已被证明。但是，许多开发人员不希望在 XML 和 Java 之间来回切换。JavaConfig 为开发人员提供了一种纯 Java 方法来配置与 XML 配置概念相似的 Spring 容器。从技术角度来讲，只使用 JavaConfig 配置类来配置容器是可行的，但实际上很多人认为将JavaConfig 与 XML 混合匹配是理想的。</p>
<p>（3）类型安全和重构友好。JavaConfig 提供了一种类型安全的方法来配置 Spring容器。由于 Java 5.0 对泛型的支持，现在可以按类型而不是按名称检索 bean，不需要任何强制转换或基于字符串的查找。</p>
<pre><code class="language-java">/**
 * @ConfigurationProperties 表示 告诉 SpringBoot 将本类中的所有属性和配置文件中相关的配置进行绑定；
 * prefix = &quot;user&quot; 表示 将配置文件中 key 为 user 的下面所有的属性与本类属性进行一一映射注入值，如果配置文件中
 * 不存在 &quot;user&quot; 的 key，则不会为 POJO 注入值，属性值仍然为默认值
 * @Component 将本来标识为一个 Spring 组件，因为只有是容器中的组件，容器才会为 @ConfigurationProperties 提供此注入功能
 * @PropertySource (value = { &quot; classpath : user.properties &quot; }) 指明加载类路径下的哪个配置文件来注入值
 */
@PropertySource(value = {&quot;classpath:user.properties&quot;})
@Component
@ConfigurationProperties(prefix = &quot;user&quot;)
public class User {
    private Integer id;
    private String lastName;
    private Integer age;
    private Date birthday;
    private List&lt;String&gt; colorList;
    private Map&lt;String, String&gt; cityMap;
}
/**
 * 文中的@Configuration 可以替换为@Component运行结果是一样的，但是两者是有不同的，@Configuration会为配置类生成CGLIB代理Class，@Component不会
 */
@PropertySource(value = {&quot;classpath:user.properties&quot;})
@Configuration
public class User {
    @Value(${user.id})
    private Integer id;
     @Value(${user.lastName})
    private String lastName;
     @Value(${user.age})
    private Integer age;
     @Value(${user.birthday})
    private Date birthday;
     @Value(${user.colorList})
    private List&lt;String&gt; colorList;
     @Value(${user.maps})
    private Map&lt;String, String&gt; cityMap;
}
</code></pre>
<p><strong>user.properties</strong></p>
<pre><code class="language-java">user.id=111
user.lastName=张无忌
user.age=120
user.birthday=2018/07/11
user.colorList=red,yellow,green,blacnk
user.cityMap.mapK1=长沙市
user.cityMap.mapK2=深圳市
user.maps=&quot;{mapK1: '长沙市', mapK2: '深圳市'}&quot;
</code></pre>
<h2 id="spring-boot-自动配置">Spring Boot 自动配置</h2>
<p>注解 @EnableAutoConfiguration, @Configuration, @ConditionalOnClass 就是自动配置的核心，</p>
<p>@EnableAutoConfiguration 给容器导入META-INF/spring.factories 里定义的自动配置类。</p>
<p>筛选有效的自动配置类。</p>
<p>每一个自动配置类结合对应的 xxxProperties.java 读取配置文件进行自动配置功能</p>
<h2 id="spring-boot-配置加载顺序">Spring Boot 配置加载顺序</h2>
<p>Spring Boot 支持多种外部配置方式，如下所示，从上往下加载优先级由高到低，内容相同时覆盖，不相同时累加。</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1622190707004.png" alt="" loading="lazy"></figure>
<p>如果在不同的目录中存在多个配置文件，它的读取顺序是：<br>
1、config/application.properties（项目根目录中config目录下）<br>
2、config/application.yml<br>
3、application.properties（项目根目录下）<br>
4、application.yml<br>
5、resources/config/application.properties（项目resources目录中config目录下）<br>
6、resources/config/application.yml<br>
7、resources/application.properties（项目的resources目录下）<br>
8、resources/application.yml</p>
<h2 id="yaml-配置">YAML 配置</h2>
<p>YAML 现在可以算是非常流行的一种配置文件格式了，无论是前端还是后端，都可以见到 YAML 配置。那么 YAML 配置和传统的 properties 配置相比到底有哪些优势呢？</p>
<ol>
<li>配置有序，在一些特殊的场景下，配置有序很关键</li>
<li>支持数组，数组中的元素可以是基本数据类型也可以是对象</li>
<li>简洁</li>
</ol>
<p>相比 properties 配置文件，YAML 还有一个缺点，就是不支持 <code>@PropertySource</code> 注解导入自定义的 YAML 配置。</p>
<h2 id="spring-boot-是否可以使用-xml-配置">Spring Boot 是否可以使用 XML 配置</h2>
<p>Spring Boot 推荐使用 Java 配置而非 XML 配置，但是 Spring Boot 中也可以使用 XML 配置，通过 <code>@ImportResource</code> 注解可以引入一个 XML 配置。</p>
<h2 id="spring-boot-核心配置文件bootstrapproperties和-applicationproperties-有何区别">spring boot 核心配置文件bootstrap.properties和 application.properties 有何区别</h2>
<p>单纯做 Spring Boot 开发，可能不太容易遇到 <code>bootstrap.properties</code> 配置文件，但是在结合 Spring Cloud 时，这个配置就会经常遇到了，特别是在需要加载一些远程配置文件的时侯。</p>
<p>spring boot 核心的两个配置文件：</p>
<ul>
<li>bootstrap (. yml 或者 . properties)：boostrap 由父 ApplicationContext 加载的，比 applicaton 优先加载，配置在应用程序上下文的引导阶段生效。一般来说我们在 Spring Cloud Config 或者 Nacos 中会用到它。且 boostrap 里面的属性不能被覆盖；</li>
<li>application (. yml 或者 . properties)： 由ApplicatonContext 加载，用于 spring boot 项目的自动化配置。</li>
</ul>
<h2 id="spring-profiles">Spring Profiles</h2>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1622190724869.png" alt="" loading="lazy"></figure>
<pre><code class="language-yaml">spring:
 profiles:
  active: devel #指定激活哪个环境配置，激活后，第一个文档内容失效;不指定时，以第一个文档为准
server:
 port: 8083
--- #&quot;---&quot;用于分隔不同的profiles（）文档块
spring:
 profiles: devel #指定环境标识为&quot;devel&quot;,相当于&quot;application-{profile}.properties/yml&quot;中的profile
server:
 port: 8081
---
spring:
 profiles: deploy #指定环境标识为&quot;deploy&quot;,相当于&quot;application-{profile}.properties/yml&quot;中的profile
server:
 port: 8082
</code></pre>
<h2 id="比较一下-spring-security-和-shiro-各自的优缺点">比较一下 Spring Security 和 Shiro 各自的优缺点</h2>
<p>由于 Spring Boot 官方提供了大量的非常方便的开箱即用的 Starter ，包括 Spring Security 的 Starter ，使得在 Spring Boot 中使用 Spring Security 变得更加容易，甚至只需要添加一个依赖就可以保护所有的接口，所以，如果是 Spring Boot 项目，一般选择 Spring Security 。当然这只是一个建议的组合，单纯从技术上来说，无论怎么组合，都是没有问题的。Shiro 和 Spring Security 相比，主要有如下一些特点：</p>
<ol>
<li>Spring Security 是一个重量级的安全管理框架；Shiro 则是一个轻量级的安全管理框架</li>
<li>Spring Security 概念复杂，配置繁琐；Shiro 概念简单、配置简单</li>
<li>Spring Security 功能强大；Shiro 功能简单</li>
</ol>
<h2 id="spring-boot-中如何解决跨域问题">Spring Boot 中如何解决跨域问题</h2>
<p>跨域可以在前端通过 JSONP 来解决，但是 JSONP 只可以发送 GET 请求，无法发送其他类型的请求，在 RESTful 风格的应用中，就显得非常鸡肋，因此我们推荐在后端通过 CORS，(Cross-origin resource sharing） 来解决跨域问题。这种解决方案并非 Spring Boot 特有的，在传统的 SSM 框架中，就可以通过 CORS 来解决跨域问题，只不过之前我们是在 XML 文件中配置 CORS ，现在可以通过实现WebMvcConfigurer接口然后重写addCorsMappings方法解决跨域问题。</p>
<pre><code class="language-java">@Configuration
public class CorsConfig implements WebMvcConfigurer {

    @Override
    public void addCorsMappings(CorsRegistry registry) {
        registry.addMapping(&quot;/**&quot;)
                .allowedOrigins(&quot;*&quot;)
                .allowCredentials(true)
                .allowedMethods(&quot;GET&quot;, &quot;POST&quot;, &quot;PUT&quot;, &quot;DELETE&quot;, &quot;OPTIONS&quot;)
                .maxAge(3600);
    }

}
</code></pre>
<p>项目中前后端分离部署，所以需要解决跨域的问题。</p>
<p>我们使用cookie存放用户登录的信息，在spring拦截器进行权限控制，当权限不符合时，直接返回给用户固定的json结果。</p>
<p>当用户登录以后，正常使用；当用户退出登录状态时或者token过期时，由于拦截器和跨域的顺序有问题，出现了跨域的现象。</p>
<p>我们知道一个http请求，先走filter，到达servlet后才进行拦截器的处理，如果我们把cors放在filter里，就可以优先于权限拦截器执行。</p>
<pre><code class="language-java">@Configuration
public class CorsConfig {
    @Bean
    public CorsFilter corsFilter() {
        CorsConfiguration corsConfiguration = new CorsConfiguration();
        corsConfiguration.addAllowedOrigin(&quot;*&quot;);
        corsConfiguration.addAllowedHeader(&quot;*&quot;);
        corsConfiguration.addAllowedMethod(&quot;*&quot;);
        corsConfiguration.setAllowCredentials(true);
        UrlBasedCorsConfigurationSource urlBasedCorsConfigurationSource = new UrlBasedCorsConfigurationSource();
        urlBasedCorsConfigurationSource.registerCorsConfiguration(&quot;/**&quot;, corsConfiguration);
        return new CorsFilter(urlBasedCorsConfigurationSource);
    }
}
</code></pre>
<h2 id="spring-boot-中的监视器">Spring Boot 中的监视器</h2>
<p>Spring boot actuator 是 spring 启动框架中的重要功能之一。Spring boot 监视器可帮助您访问生产环境中正在运行的应用程序的当前状态。有几个指标必须在生产环境中进行检查和监控。即使一些外部应用程序可能正在使用这些服务来向相关人员触发警报消息。监视器模块公开了一组可直接作为 HTTP URL 访问的REST 端点来检查状态。</p>
<h2 id="注册-servlet-三大组件-servlet-filter-listener">注册 Servlet 三大组件 Servlet、Filter、Listener</h2>
<h3 id="继承接口实现方式">继承，接口实现方式</h3>
<h4 id="servletregistrationbean-注册-servlet">ServletRegistrationBean 注册 Servlet</h4>
<p>1、自定义类继承 javax.servlet.http.HttpServlet，然后重写其 doGet 与 doPost 方法，在方法中编写控制代码；</p>
<p>2、第二步将 ServletRegistrationBean 组件添加到 Spring 容器中</p>
<pre><code class="language-java">import javax.servlet.ServletException;
import javax.servlet.http.HttpServlet;
import javax.servlet.http.HttpServletRequest;
import javax.servlet.http.HttpServletResponse;
import java.io.IOException;
/**
 * Created by Administrator 
 * 标准的 Servlet 实现 HttpServlet；重写其 doGet 、doPost 方法
 */
public class BookServlet extends HttpServlet {
    @Override
    protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {
        this.doPost(req, resp);
    }
    @Override
    protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {
        System.out.println(&quot;:com.lct.servlet.BookServlet:&quot; + req.getRequestURL());
        /**讲求转发到后台的 user/users 请求去，即会进入*/
        req.getRequestDispatcher(&quot;user/users&quot;).forward(req, resp);
    }
}
</code></pre>
<p>3、上面 Serlvet 转发到下面的 UserControllr 控制器中</p>
<p>4、@Configuration 配置类相当于以前的 beans.xml 中的配置，将 ServletRegistrationBean 也添加到 Spring 容器中来</p>
<pre><code class="language-java">import com.lct.component.MyLocaleResolve;
import com.lct.servlet.BookServlet;
import org.springframework.boot.web.server.WebServerFactoryCustomizer;
import org.springframework.boot.web.servlet.ServletRegistrationBean;
import org.springframework.boot.web.servlet.server.ConfigurableServletWebServerFactory;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.web.servlet.LocaleResolver;
/**
 * Created by Administrator 
 * 自定义配置类
 */
@Configuration
public class MyMvcConfig {
    /**
     * 注册 Servlet 三大组件 之  Servlet
     * 添加 ServletRegistrationBean ，就相当于以前在 web.xml 中配置的 &lt;servlet&gt;&lt;/servlet&gt;标签
     */
    @Bean
    public ServletRegistrationBean myServlet() {
        /**第二个参数是个不定参数组，可以配置映射多个请求
         * 相当于以前在 web.xml中配置的 &lt;servlet-mapptin&gt;&lt;/servlet-mapptin&gt;*/
        ServletRegistrationBean registrationBean = new ServletRegistrationBean(new
                BookServlet(), &quot;/bookServlet&quot;);
        return registrationBean;
    }
}
</code></pre>
<p>5、运行测试：</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1622190757311.gif" alt="" loading="lazy"></figure>
<h4 id="filterregistrationbean-注册-filter">FilterRegistrationBean 注册 Filter</h4>
<p>1、Filter(过滤器) 是 Servlet 技术中最实用的技术之一</p>
<p>2、Web 开发人员通过 Filter 技术，对 web 服务器管理的所有 web 资源(如动态的 Jsp、 Servlet，以及静态的 image、 html、CSS、JS 文件等) 进行过滤拦截，从而实现一些特殊的功能(如实现 URL 级别的权限访问控制、过滤敏感词汇、压缩响应信息等)</p>
<p>3、Filter 主要用于对用户请求进行预处理，也可以对 HttpServletResponse 进行后期处理(如编码设置，返回时禁用浏览器缓存等)</p>
<p>4、Filter 使用完整流程：Filter 对用户请求进行预处理，接着将请求交给 Servlet 进行处理并生成响应，最后 Filter 再对服务器响应进行后处理。</p>
<p>5、Servlet 的 Filter 经常会拿来与 Spring MVC 的 Interceptor(拦截器) 做对比</p>
<p>​	1）拦截器是基于 Java 的反射机制的，而过滤器是基于函数回调</p>
<p>​	2）拦截器不依赖与 servle t容器，过滤器依赖与 servlet 容器</p>
<p>​	3）拦截器可以访问 action 上下文、值栈里的对象，而过滤器不能访问</p>
<p>​	4）在 action 的生命周期中，拦截器可以多次被调用，而过滤器只能在容器初始化时被调用一次</p>
<p>​	5）拦截器可以获取 IOC 容器中的各个 bean，而过滤器就不行，这点很重要，在拦截器里注入一个 service，可以调用业务逻辑</p>
<p>​	6）SpringMVC 有自己的拦截器</p>
<pre><code class="language-java">import javax.servlet.*;
import javax.servlet.http.HttpServletRequest;
import java.io.IOException;
/**
 * Created by Administrator 
 * 标准 Servlet 过滤器，实现 javax.servlet.Filter 接口
 * 并重写它的 三个方法
 */
public class SystemFilter implements Filter {
    @Override
    public void init(FilterConfig filterConfig) throws ServletException {
        System.out.println(&quot;javax.servlet.Filter：：服务器启动....&quot;);
    }
    @Override
    public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException {
        /**
         * 转为 HttpServletRequest 输出请求路径 容易查看 请求地址
         */
        HttpServletRequest request = (HttpServletRequest) servletRequest;
        System.out.println(&quot;javax.servlet.Filter：：过滤器放行前....&quot; + request.getRequestURL());
        filterChain.doFilter(servletRequest, servletResponse);
        System.out.println(&quot;javax.servlet.Filter：：过滤器返回后....&quot; + request.getRequestURL());
    }
    @Override
    public void destroy() {
        System.out.println(&quot;javax.servlet.Filter：：服务器关闭....&quot;);
    }
}
</code></pre>
<p>6、使用 FilterRegistrationBean 添加 FIlter ：</p>
<pre><code class="language-java">import com.lct.component.MyLocaleResolve;
import com.lct.filter.SystemFilter;
import com.lct.servlet.BookServlet;
import org.springframework.boot.web.server.WebServerFactoryCustomizer;
import org.springframework.boot.web.servlet.FilterRegistrationBean;
import org.springframework.boot.web.servlet.ServletRegistrationBean;
import org.springframework.boot.web.servlet.server.ConfigurableServletWebServerFactory;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.web.servlet.LocaleResolver;
import javax.servlet.DispatcherType;
import java.util.Arrays;
/**
 * Created by Administrator 
 * 自定义配置类
 */
@Configuration
public class MyMvcConfig {
    /**
     * 注册 Servlet 三大组件 之  Filter (过滤器)
     * 添加 FilterRegistrationBean ，就相当于以前在 web.xml 中配置的 &lt;filter&gt;&lt;/filter&gt; 标签
     */
    @Bean
    public FilterRegistrationBean myFilter() {
        FilterRegistrationBean registrationBean = new FilterRegistrationBean();
        /**同样添加自定义的 Filter*/
        registrationBean.setFilter(new SystemFilter());
        /**然后设置过滤的路径，参数是个集合 ,相当于 web.xml中配置的 &lt;filter-mapptin&gt;&lt;/filter-mapptin&gt;
         * &quot;/*&quot;: 表示过滤所有 get 与 post 请求*/
        registrationBean.setUrlPatterns(Arrays.asList(&quot;/*&quot;));
        /**
         * setDispatcherTypes 相当于 web.xml 配置中 &lt;filter-mapptin&gt; 下的 &lt;dispatcher&gt; 标签
         * 用于过滤非常规的 get 、post 请求
         * REQUEST：默认方式，写了之后会过滤所有静态资源的请求
         * FORWARD：过滤所有的转发请求，无论是 jsp 中的 &lt;jsp:forward&lt;/&gt;、&lt;%@ page errorPage= %&gt;、还是后台的转发
         * INCLUDE：过滤 jsp 中的动态包含&lt;jsp:include 请求
         * ERROR：过滤在 web.xml 配置的全局错误页面
         * 了解即可，实际中也很少这么做
         */
        registrationBean.setDispatcherTypes(DispatcherType.REQUEST);
        return registrationBean;
    }
}
</code></pre>
<h4 id="servletlistenerregistrationbean-注册-listener">ServletListenerRegistrationBean 注册 Listener</h4>
<p>1、自定义监听器：</p>
<pre><code class="language-java">import javax.servlet.ServletContextEvent;
import javax.servlet.ServletContextListener;
/**
 * Created by Administrator on 2018/8/11 0011.
 * 标准 Servlet 监听器，实现 javax.servlet.ServletContextListener 接口
 * 然后实现方法
 * ServletContextListener：属于 Servlet 应用启动关闭监听器，监听容器初始化与销毁
 */
public class SystemListener implements ServletContextListener {
    @Override
    public void contextInitialized(ServletContextEvent servletContextEvent) {
        System.out.println(&quot;com.lct.listener.SystemListener::服务器启动.....&quot;);
    }
    @Override
    public void contextDestroyed(ServletContextEvent servletContextEvent) {
        System.out.println(&quot;com.lct.listener.SystemListener::服务器关闭.....&quot;);
    }
}
</code></pre>
<p>2、注册 ServletListenerRegistrationBean：</p>
<pre><code class="language-java">import com.lct.component.MyLocaleResolve;
import com.lct.filter.SystemFilter;
import com.lct.listener.SystemListener;
import com.lct.servlet.BookServlet;
import org.springframework.boot.web.server.WebServerFactoryCustomizer;
import org.springframework.boot.web.servlet.FilterRegistrationBean;
import org.springframework.boot.web.servlet.ServletListenerRegistrationBean;
import org.springframework.boot.web.servlet.ServletRegistrationBean;
import org.springframework.boot.web.servlet.server.ConfigurableServletWebServerFactory;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.web.servlet.LocaleResolver;
import java.util.Arrays;
/**
 * Created by Administrator 
 * 自定义配置类
 */
@Configuration
public class MyMvcConfig {
    /**
     * 注册 Servlet 三大组件 之  Listner
     * 添加 ServletListenerRegistrationBean ，就相当于以前在 web.xml 中配置的 &lt;listener&gt;&lt;/listener&gt;标签
     */
    @Bean
    public ServletListenerRegistrationBean myListener() {
        /**ServletListenerRegistrationBean&lt;T extends EventListener&gt; 属于的是泛型，可以注册常见的任意监听器
         * 将自己的监听器注册进来*/
        ServletListenerRegistrationBean registrationBean = new ServletListenerRegistrationBean(new SystemListener());
        return registrationBean;
    }
}
</code></pre>
<h3 id="注解方式">注解方式</h3>
<p>1、Servlet 三大组件 Servlet、Filter、Listener 在传统项目中需要在 web.xml 中进行相应的配置。Servlet 3.0 开始在 javax.servlet.annotation 包下提供 3 个对应</p>
<p>的 @WebServlet、@WebFilter、@WebListener 注解来简化操作。</p>
<p>2、Spring Boot 应用中这三个注解默认是不被扫描的，需要在项目启动类上添加 @ServletComponentScan 注解, 表示对 Servlet 组件扫描。</p>
<h4 id="webservlet">@WebServlet</h4>
<pre><code class="language-java">import javax.servlet.ServletException;
import javax.servlet.annotation.WebServlet;
import javax.servlet.http.HttpServlet;
import javax.servlet.http.HttpServletRequest;
import javax.servlet.http.HttpServletResponse;
import java.io.IOException;
 
/**
 * 标准的 Servlet ，实现 javax.servlet.http.HttpServlet. 重写其 doGet 、doPost 方法
 * name :表示 servlet 名称，可以不写，默认为空
 * urlPatterns: 表示请求的路径，如 http://ip:port/context-path/userServlet
 */
@WebServlet(name = &quot;UserServlet&quot;, urlPatterns = {&quot;/userServlet&quot;})
public class UserServlet extends HttpServlet {
    @Override
    protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {
        this.doPost(req, resp);
    }
 
    @Override
    protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {
        StringBuffer requestURL = req.getRequestURL();
        System.out.println(&quot;com.wmx.servlet.UserServlet -- &quot; + requestURL);
        resp.sendRedirect(&quot;/index.html&quot;);//浏览器重定向到服务器下的 index.html 页面
    }
}
</code></pre>
<h4 id="webfilter">@WebFilter</h4>
<pre><code class="language-java">import javax.servlet.*;
import javax.servlet.annotation.WebFilter;
import javax.servlet.http.HttpServletRequest;
import java.io.IOException;
 
/**
 * 标准 Servlet 过滤器，实现 javax.servlet.Filter 接口，并重现它的 3 个方法
 * filterName：表示过滤器名称，可以不写
 * value：配置请求过滤的规则，如 &quot;/*&quot; 表示过滤所有请求，包括静态资源，如 &quot;/user/*&quot; 表示 /user 开头的所有请求
 */
@WebFilter(filterName = &quot;SystemFilter&quot;, value = {&quot;/*&quot;})
public class SystemFilter implements Filter {
 
    @Override
    public void init(FilterConfig filterConfig) throws ServletException {
        System.out.println(&quot;com.wmx.servlet.SystemFilter -- 系统启动...&quot;);
    }
 
    @Override
    public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException {
        //转为 HttpServletRequest 输出请求路径
        HttpServletRequest request = (HttpServletRequest) servletRequest;
        System.out.println(&quot;com.wmx.servlet.SystemFilter -- 过滤器放行前....&quot; + request.getRequestURL());
        filterChain.doFilter(servletRequest, servletResponse);
        System.out.println(&quot;com.wmx.servlet.SystemFilter -- 过滤器返回后....&quot; + request.getRequestURL());
    }
 
    @Override
    public void destroy() {
        System.out.println(&quot;com.wmx.servlet.SystemFilter -- 系统关闭...&quot;);
    }
}
</code></pre>
<h4 id="weblistener">@WebListener</h4>
<pre><code class="language-java">import javax.servlet.ServletContextEvent;
import javax.servlet.ServletContextListener;
import javax.servlet.annotation.WebListener;
 
/**
 * 标准 Servlet 监听器，实现 javax.servlet.ServletContextListener 接口，并重写方法
 * ServletContextListener 属于 Servlet 应用启动关闭监听器，监听容器初始化与销毁。常用的监听器还有：
 * ServletRequestListener：HttpServletRequest 对象的创建和销毁监听器
 * HttpSessionListener：HttpSession 数据对象创建和销毁监听器
 * HttpSessionAttributeListener 监听HttpSession中属性变化
 * ServletRequestAttributeListener 监听ServletRequest中属性变化
 */
@WebListener
public class SystemListener implements ServletContextListener {
    @Override
    public void contextInitialized(ServletContextEvent sce) {
        System.out.println(&quot;com.wmx.servlet.SystemListener -- 服务器启动.&quot;);
    }
 
    @Override
    public void contextDestroyed(ServletContextEvent sce) {
        System.out.println(&quot;com.wmx.servlet.SystemListener -- 服务器关闭.&quot;);
    }
}
</code></pre>
<h4 id="servletcomponentscan">@ServletComponentScan</h4>
<p>Spring Boot 应用中这三个注解默认是不被扫描的，需要在项目启动类上添加 @ServletComponentScan 注解, 表示对 Servlet 组件扫描。</p>
<pre><code class="language-java">import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.boot.web.servlet.ServletComponentScan;
 
@SpringBootApplication
@ServletComponentScan //对 servlet 注解进行扫描
public class RedisStuWebApplication {
    public static void main(String[] args) {
        SpringApplication.run(RedisStuWebApplication.class, args);
    }
}
</code></pre>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1622190795511.gif" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[SpringMVC工作原理]]></title>
        <id>https://tinaxiawuhao.github.io/post/7cW_XVJ41/</id>
        <link href="https://tinaxiawuhao.github.io/post/7cW_XVJ41/">
        </link>
        <updated>2021-05-30T03:08:06.000Z</updated>
        <content type="html"><![CDATA[<p>SpringMVC的工作原理图：</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1622171698834.jpeg" alt="" loading="lazy"></figure>
<p><strong>SpringMVC流程</strong></p>
<p>1、 用户发送请求至前端控制器DispatcherServlet。</p>
<p>2、 DispatcherServlet收到请求调用HandlerMapping处理器映射器。</p>
<p>3、 处理器映射器找到具体的处理器(可以根据xml配置、注解进行查找)，生成处理器对象及处理器拦截器(如果有则生成)一并返回给DispatcherServlet。</p>
<p>4、 DispatcherServlet调用HandlerAdapter处理器适配器。</p>
<p>5、 HandlerAdapter经过适配调用具体的处理器(Controller，也叫后端控制器)。</p>
<p>6、 Controller执行完成返回ModelAndView。</p>
<p>7、 HandlerAdapter将controller执行结果ModelAndView返回给DispatcherServlet。</p>
<p>8、 DispatcherServlet将ModelAndView传给ViewReslover视图解析器。</p>
<p>9、 ViewReslover解析后返回具体View。</p>
<p>10、DispatcherServlet根据View进行渲染视图（即将模型数据填充至视图中）。</p>
<p>11、 DispatcherServlet响应用户。</p>
<p><strong>组件说明：</strong></p>
<p>以下组件通常使用框架提供实现：</p>
<p>DispatcherServlet：作为前端控制器，整个流程控制的中心，控制其它组件执行，统一调度，降低组件之间的耦合性，提高每个组件的扩展性。</p>
<p>HandlerMapping：通过扩展处理器映射器实现不同的映射方式，例如：配置文件方式，实现接口方式，注解方式等。</p>
<p>HandlAdapter：通过扩展处理器适配器，支持更多类型的处理器。</p>
<p>ViewResolver：通过扩展视图解析器，支持更多类型的视图解析，例如：jsp、freemarker、pdf、excel等。</p>
<p><strong>组件：</strong></p>
<p><strong>1、前端控制器DispatcherServlet（不需要工程师开发）,由框架提供</strong></p>
<p>作用：接收请求，响应结果，相当于转发器，中央处理器。有了dispatcherServlet减少了其它组件之间的耦合度。</p>
<p>用户请求到达前端控制器，它就相当于mvc模式中的c，dispatcherServlet是整个流程控制的中心，由它调用其它组件处理用户的请求，dispatcherServlet的存在降低了组件之间的耦合性。</p>
<p><strong>2、处理器映射器HandlerMapping(不需要工程师开发),由框架提供</strong></p>
<p>作用：根据请求的url查找Handler</p>
<p>HandlerMapping负责根据用户请求找到Handler即处理器，springmvc提供了不同的映射器实现不同的映射方式，例如：配置文件方式，实现接口方式，注解方式等。</p>
<p><strong>3、处理器适配器HandlerAdapter</strong></p>
<p>作用：按照特定规则（HandlerAdapter要求的规则）去执行Handler</p>
<p>通过HandlerAdapter对处理器进行执行，这是适配器模式的应用，通过扩展适配器可以对更多类型的处理器进行执行。</p>
<p><strong>4、处理器Handler(需要工程师开发)</strong></p>
<p><strong>注意：编写Handler时按照HandlerAdapter的要求去做，这样适配器才可以去正确执行Handler</strong></p>
<p>Handler 是继DispatcherServlet前端控制器的后端控制器，在DispatcherServlet的控制下Handler对具体的用户请求进行处理。</p>
<p>由于Handler涉及到具体的用户业务请求，所以一般情况需要工程师根据业务需求开发Handler。</p>
<p><strong>5、视图解析器View resolver(不需要工程师开发),由框架提供</strong></p>
<p>作用：进行视图解析，根据逻辑视图名解析成真正的视图（view）</p>
<p>View Resolver负责将处理结果生成View视图，View Resolver首先根据逻辑视图名解析成物理视图名即具体的页面地址，再生成View视图对象，最后对View进行渲染将处理结果通过页面展示给用户。 springmvc框架提供了很多的View视图类型，包括：jstlView、freemarkerView、pdfView等。</p>
<p>一般情况下需要通过页面标签或页面模版技术将模型数据通过页面展示给用户，需要由工程师根据业务需求开发具体的页面。</p>
<p><strong>6、视图View(需要工程师开发jsp...)</strong></p>
<p>View是一个接口，实现类支持不同的View类型（jsp、freemarker、pdf...）</p>
<p><strong>核心架构的具体流程步骤如下：</strong></p>
<p>1、首先用户发送请求——&gt;DispatcherServlet，前端控制器收到请求后自己不进行处理，而是委托给其他的解析器进行处理，作为统一访问点，进行全局的流程控制；</p>
<p>2、DispatcherServlet——&gt;HandlerMapping， HandlerMapping 将会把请求映射为HandlerExecutionChain 对象（包含一个Handler 处理器（页面控制器）对象、多个HandlerInterceptor 拦截器）对象，通过这种策略模式，很容易添加新的映射策略；</p>
<p>3、DispatcherServlet——&gt;HandlerAdapter，HandlerAdapter 将会把处理器包装为适配器，从而支持多种类型的处理器，即适配器设计模式的应用，从而很容易支持很多类型的处理器；</p>
<p>4、HandlerAdapter——&gt;处理器功能处理方法的调用，HandlerAdapter 将会根据适配的结果调用真正的处理器的功能处理方法，完成功能处理；并返回一个ModelAndView 对象（包含模型数据、逻辑视图名）；</p>
<p>5、ModelAndView的逻辑视图名——&gt; ViewResolver， ViewResolver 将把逻辑视图名解析为具体的View，通过这种策略模式，很容易更换其他视图技术；</p>
<p>6、View——&gt;渲染，View会根据传进来的Model模型数据进行渲染，此处的Model实际是一个Map数据结构，因此很容易支持其他视图技术；</p>
<p>7、返回控制权给DispatcherServlet，由DispatcherServlet返回响应给用户，到此一个流程结束。</p>
<p>下边两个组件通常情况下需要开发：</p>
<p>Handler：处理器，即后端控制器用controller表示。</p>
<p>View：视图，即展示给用户的界面，视图中通常需要标签语言展示模型数据。</p>
<p><strong>在讲SpringMVC之前我们先来看一下什么是MVC模式</strong></p>
<p>MVC：MVC是一种设计模式</p>
<p>MVC的原理图：</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1622171719747.png" alt="" loading="lazy"></figure>
<p><strong>分析：</strong></p>
<p>M-Model 模型（完成业务逻辑：有javaBean构成，service+dao+entity）</p>
<p>V-View 视图（做界面的展示  jsp，html……）</p>
<p>C-Controller 控制器（接收请求—&gt;调用模型—&gt;根据结果派发页面）</p>
<p><strong>springMVC是什么：</strong></p>
<p>springMVC是一个MVC的开源框架，springMVC=struts2+spring，springMVC就相当于是Struts2加上sring的整合，但是这里有一个疑惑就是，springMVC和spring是什么样的关系呢？这个在百度百科上有一个很好的解释：意思是说，springMVC是spring的一个后续产品，其实就是spring在原有基础上，又提供了web应用的MVC模块，可以简单的把springMVC理解为是spring的一个模块（类似AOP，IOC这样的模块），网络上经常会说springMVC和spring无缝集成，其实springMVC就是spring的一个子模块，所以根本不需要同spring进行整合。</p>
<p><strong>SpringMVC的原理图：</strong></p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1622171762295.png" alt="" loading="lazy"></figure>
<p><strong>看到这个图大家可能会有很多的疑惑，现在我们来看一下这个图的步骤：（可以对比MVC的原理图进行理解）</strong></p>
<p>第一步:用户发起请求到前端控制器（DispatcherServlet）</p>
<p>第二步：前端控制器请求处理器映射器（HandlerMappering）去查找处理器（Handle）：通过xml配置或者注解进行查找</p>
<p>第三步：找到以后处理器映射器（HandlerMappering）像前端控制器返回执行链（HandlerExecutionChain）</p>
<p>第四步：前端控制器（DispatcherServlet）调用处理器适配器（HandlerAdapter）去执行处理器（Handler）</p>
<p>第五步：处理器适配器去执行Handler</p>
<p>第六步：Handler执行完给处理器适配器返回ModelAndView</p>
<p>第七步：处理器适配器向前端控制器返回ModelAndView</p>
<p>第八步：前端控制器请求视图解析器（ViewResolver）去进行视图解析</p>
<p>第九步：视图解析器像前端控制器返回View</p>
<p>第十步：前端控制器对视图进行渲染</p>
<p>第十一步：前端控制器向用户响应结果</p>
<p><strong>看到这些步骤我相信大家很感觉非常的乱，这是正常的，但是这里主要是要大家理解springMVC中的几个组件：</strong></p>
<p>前端控制器（DispatcherServlet）：接收请求，响应结果，相当于电脑的CPU。</p>
<p>处理器映射器（HandlerMapping）：根据URL去查找处理器</p>
<p>处理器（Handler）：（需要程序员去写代码处理逻辑的）</p>
<p>处理器适配器（HandlerAdapter）：会把处理器包装成适配器，这样就可以支持多种类型的处理器，类比笔记本的适配器（适配器模式的应用）</p>
<p>视图解析器（ViewResovler）：进行视图解析，多返回的字符串，进行处理，可以解析成对应的页面</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[elasticSearch基础概念汇总]]></title>
        <id>https://tinaxiawuhao.github.io/post/w_tIMVx00/</id>
        <link href="https://tinaxiawuhao.github.io/post/w_tIMVx00/">
        </link>
        <updated>2021-05-29T07:17:08.000Z</updated>
        <content type="html"><![CDATA[<h3 id="1什么是elasticsearch">1.什么是ElasticSearch？</h3>
<p>Elasticsearch是一个基于Lucene的搜索引擎。它提供了具有HTTP Web界面和无架构JSON文档的分布式，多租户能力的全文搜索引擎。Elasticsearch是用Java开发的，根据Apache许可条款作为开源发布。它可以用于全文搜索，结构化搜索以及分析，当然你也可以将这三者进行组合。</p>
<h3 id="2为什么要使用elasticsearch">2.为什么要使用Elasticsearch?</h3>
<p>用数据库，也可以实现搜索的功能，为什么还需要搜索引擎呢？</p>
<p>就像 <a href="https://link.zhihu.com/?target=https%3A//stackoverflow.com/questions/51639166/elasticsearch-vs-relational-database">Stackoverflow</a> 的网友说的：</p>
<blockquote>
<p>A relational database can store data and also index it. A search engine can index data but also store it.</p>
</blockquote>
<p>数据库（理论上来讲，ES 也是数据库，这里的数据库，指的是关系型数据库），首先是存储，搜索只是顺便提供的功能，</p>
<p>而搜索引擎，首先是搜索，但是不把数据存下来就搜不了，所以只好存一存。</p>
<p>术业有专攻，专攻搜索的搜索引擎，自然会提供更强大的搜索能力。。</p>
<ol>
<li>Elasticsearch是分布式的。不需要其他组件，分发是实时的，被叫做”Push replication”。</li>
<li>Elasticsearch 完全支持 Apache Lucene 的接近实时的搜索。</li>
<li>处理多租户（<a href="http://en.wikipedia.org/wiki/Multitenancy">multitenancy</a>）不需要特殊配置，而Solr则需要更多的高级设置。</li>
<li>Elasticsearch 采用 Gateway 的概念，使得完备份更加简单。</li>
<li>各节点组成对等的网络结构，某些节点出现故障时会自动分配其他节点代替其进行工作。</li>
</ol>
<h3 id="3elasticsearch是如何实现master选举的">3.Elasticsearch是如何实现Master选举的？</h3>
<ul>
<li>Elasticsearch的选主是ZenDiscovery模块负责的，主要包含Ping（节点之间通过这个RPC来发现彼此）和Unicast（单播模块包含一个主机列表以控制哪些节点需要ping通）这两部分；</li>
<li>对所有可以成为master的节点（<strong>node.master: true</strong>）根据nodeId字典排序，每次选举每个节点都把自己所知道节点排一次序，然后选出第一个（第0位）节点，暂且认为它是master节点。</li>
<li>如果对某个节点的投票数达到一定的值（可以成为master节点数n/2+1）并且该节点自己也选举自己，那这个节点就是master。否则重新选举一直到满足上述条件。</li>
<li><em>补充：master节点的职责主要包括集群、节点和索引的管理，不负责文档级别的管理；data节点可以关闭http功能</em>。</li>
</ul>
<h3 id="4elasticsearch中如何避免脑裂">4.Elasticsearch中如何避免脑裂？</h3>
<p>为了避免产生脑裂，ES采用了常见的分布式系统思路，保证选举出的master被多数派(quorum)的master-eligible node认可，以此来保证只有一个master。这个quorum通过以下配置进行配置：</p>
<pre><code class="language-java">conf/elasticsearch.yml:
    discovery.zen.minimum_master_nodes: 2
</code></pre>
<h3 id="5elasticsearch中的倒排索引">5.Elasticsearch中的倒排索引</h3>
<h4 id="为什么叫倒排索引">为什么叫倒排索引</h4>
<p>在没有搜索引擎时，我们是直接输入一个网址，然后获取网站内容，这时我们的行为是：<code>document -&gt; to -&gt; words</code> 通过文章，获取里面的单词，此谓「正向索引」，forward index.后来，我们希望能够输入一个单词，找到含有这个单词，或者和这个单词有关系的文章：<code>word -&gt; to -&gt; documents</code>于是我们把这种索引，成为inverted index，直译过来，应该叫「反向索引」，国内翻译成「倒排索引」。</p>
<h4 id="倒排索引的内部结构">倒排索引的内部结构</h4>
<p>首先，在数据生成的时候，比如爬虫爬到一篇文章，这时我们需要对这篇文章进行分析，将文本拆解成一个个单词。</p>
<p>这个过程很复杂，比如“生存还是死亡”，你要如何让分词器自动将它分解为“生存”、“还是”、“死亡”三个词语，然后把“还是”这个无意义的词语干掉。这里不展开，感兴趣的同学可以查看关于「分析器」的内容。</p>
<p>接着，把这两个词语以及它对应的文档id存下来：</p>
<table>
<thead>
<tr>
<th>word</th>
<th>documentId</th>
</tr>
</thead>
<tbody>
<tr>
<td>生存</td>
<td>1</td>
</tr>
<tr>
<td>死亡</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>接着爬虫继续爬，又爬到一个含有“生存”的文档，于是索引变成：</p>
<table>
<thead>
<tr>
<th>word</th>
<th>documentId</th>
</tr>
</thead>
<tbody>
<tr>
<td>生存</td>
<td>1，2</td>
</tr>
<tr>
<td>死亡</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>下次搜索“生存”，就会返回文档ID是 1、2两份文档。然而上面这套索引的实现，给小孩子当玩具玩还行，要上生产环境，那还远着。想想看，这个世界上那么多单词，中文、英文、日文、韩文 … 你每次搜索一个单词，我都要全局遍历一遍，很明显不行。于是有了排序，我们需要对单词进行排序，像 B+ 树一样，可以在页里实现二分查找。光排序还不行，你单词都放在磁盘呢，磁盘 IO 慢的不得了，所以 Mysql 特意把索引缓存到了内存。你说好，我也学 Mysql 的，放内存，3，2，1，放，哐当，内存爆了。哪本字典，会把所有单词都贴在目录里的？</p>
<p>所以，上图：</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1622014331550.png" alt="" loading="lazy"></figure>
<p>Lucene 的倒排索，增加了最左边的一层「字典树」<code>term index</code>，它不存储所有的单词，只存储单词前缀，通过字典树找到单词所在的块，也就是单词的大概位置，再在块里二分查找，找到对应的单词，再找到单词对应的文档列表。</p>
<p>当然，内存寸土寸金，能省则省，所以 Lucene 还用了 <code>FST（Finite State Transducers）</code>对它进一步压缩。</p>
<p>最右边的 Posting List ，别看它只是存一个文档 ID 数组，但是它在设计时，遇到的问题可不少。</p>
<p><strong>Frame Of Reference</strong></p>
<p>原生的 Posting List 有两个痛点：</p>
<ul>
<li><strong>如何压缩以节省磁盘空间</strong></li>
<li><strong>如何快速求交并集（intersections and unions）</strong></li>
</ul>
<p>先来聊聊压缩。我们来简化下 Lucene 要面对的问题，假设有这样一个数组：<strong>[73, 300, 302, 332, 343, 372]</strong></p>
<p>Lucene 里，数据是按 Segment 存储的，每个 Segment 最多存 65536 个文档 ID， 所以文档 ID 的范围，从 0 到 2^16-1，所以如果不进行任何处理，那么每个元素都会占用 2 bytes ，对应上面的数组，就是 6 * 2 = 12 bytes.</p>
<p>怎么压缩呢？</p>
<p><strong>压缩，就是尽可能降低每个数据占用的空间，同时又能让信息不失真，能够还原回来。</strong></p>
<p><strong>Step 1：Delta-encode —— 增量编码</strong></p>
<p>我们只记录元素与元素之间的增量，于是数组变成了：[73, 227, 2, 30, 11, 29]</p>
<p><strong>Step 2：Split into blocks —— 分割成块</strong></p>
<p>Lucene里每个块是 256 个文档 ID，这样可以保证每个块，增量编码后，每个元素都不会超过 256（1 byte）.为了方便演示，我们假设每个块是 3 个文档 ID：</p>
<p><strong>[73, 227, 2], [30, 11, 29]</strong></p>
<p><strong>Step 3：Bit packing —— 按需分配空间</strong></p>
<p>对于第一个块，[73, 227, 2]，最大元素是227，需要 8 bits，好，那我给你这个块的每个元素，都分配 8 bits的空间。但是对于第二个块，[30, 11, 29]，最大的元素才30，只需要 5 bits，那我就给你每个元素，只分配 5 bits 的空间，足矣。这一步，可以说是把吝啬发挥到极致，精打细算，按需分配。</p>
<p>以上三个步骤，共同组成了一项编码技术，Frame Of Reference（FOR）：</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1622014347604.png" alt="" loading="lazy"></figure>
<p><strong>Roaring bitmaps</strong></p>
<p>接着来聊聊 Posting List 的第二个痛点 —— 如何快速求交并集（intersections and unions）。</p>
<p>在 Lucene 中查询，通常不只有一个查询条件，比如我们想搜索：</p>
<ul>
<li>含有“生存”相关词语的文档</li>
<li>文档发布时间在最近一个月</li>
<li>文档发布者是平台的特约作者</li>
</ul>
<p>这样就需要根据三个字段，去三棵倒排索引里去查，当然，磁盘里的数据，上一节提到过，用了 FOR 进行压缩，所以我们要把数据进行反向处理，即解压，才能还原成原始的文档 ID，然后把这三个文档 ID 数组在内存中做一个交集。</p>
<blockquote>
<p>即使没有多条件查询， Lucene 也需要频繁求并集，因为 Lucene 是分片存储的。</p>
</blockquote>
<p>同样，我们把 Lucene 遇到的问题，简化成一道算法题。</p>
<p>假设有下面三个数组：</p>
<pre><code class="language-java">[64, 300, 303, 343]

[73, 300, 302, 303, 343, 372]

[303, 311, 333, 343]
</code></pre>
<p>求它们的交集。</p>
<p><strong>Option 1: Integer 数组</strong></p>
<p>直接用原始的文档 ID ，可能你会说，那就逐个数组遍历一遍吧，遍历完就知道交集是什么了。</p>
<p>其实对于有序的数组，用跳表（skip table）可以更高效，这里就不展开了，因为不管是从性能，还是空间上考虑，Integer 数组都不靠谱，假设有100M 个文档 ID，每个文档 ID 占 2 bytes，那已经是 200 MB，而这些数据是要放到内存中进行处理的，把这么大量的数据，从磁盘解压后丢到内存，内存肯定撑不住。</p>
<p><strong>Option 2: Bitmap</strong></p>
<p>假设有这样一个数组：<strong>[3,6,7,10]</strong> 那么我们可以这样来表示：<strong>[0,0,1,0,0,1,1,0,0,1]</strong> 看出来了么，对，<strong>我们用 0 表示角标对应的数字不存在，用 1 表示存在。</strong></p>
<p>这样带来了两个好处：</p>
<ul>
<li>节省空间：既然我们只需要0和1，那每个文档 ID 就只需要 1 bit，还是假设有 100M 个文档，那只需要 100M bits = 100M * 1/8 bytes = 12.5 MB，比之前用 Integer 数组 的 200 MB，优秀太多</li>
<li>运算更快：0 和 1，天然就适合进行位运算，求交集，「与」一下，求并集，「或」一下，一切都回归到计算机的起点</li>
</ul>
<p><strong>Option 3: Roaring Bitmaps</strong></p>
<p>细心的你可能发现了，bitmap 有个硬伤，就是不管你有多少个文档，你占用的空间都是一样的，之前说过，Lucene Posting List 的每个 Segement 最多放 65536 个文档ID，举一个极端的例子，有一个数组，里面只有两个文档 ID：<strong>[0, 65535]<strong>用 Bitmap，要怎么表示？</strong>[1,0,0,0,….(超级多个0),…,0,0,1]</strong></p>
<p>你需要 65536 个 bit，也就是 65536/8 = 8192 bytes，而用 Integer 数组，你只需要 2 * 2 bytes = 4 bytes</p>
<p>呵呵，死板的 bitmap。可见在文档数量不多的时候，使用 Integer 数组更加节省内存。</p>
<p>我们来算一下临界值，很简单，无论文档数量多少，bitmap都需要 8192 bytes，而 Integer 数组则和文档数量成线性相关，每个文档 ID 占 2 bytes，所以：<code>8192 / 2 = 4096</code>当文档数量少于 4096 时，用 Integer 数组，否则，用 bitmap.</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1622014361997.png" alt="" loading="lazy"></figure>
<blockquote>
<p>这里补充一下 Roaring bitmaps 和 之前讲的 Frame Of Reference 的关系。<br>
Frame Of Reference 是压缩数据，减少磁盘占用空间，所以当我们从磁盘取数据时，也需要一个反向的过程，即解压，解压后才有我们上面看到的这样子的文档ID数组：[73, 300, 302, 303, 343, 372] ，接着我们需要对数据进行处理，求交集或者并集，这时候数据是需要放到内存进行处理的，我们有三个这样的数组，这些数组可能很大，而内存空间比磁盘还宝贵，于是需要更强有力的压缩算法，同时还要有利于快速的求交并集，于是有了Roaring Bitmaps 算法。<br>
另外，Lucene 还会把从磁盘取出来的数据，通过 Roaring bitmaps 处理后，缓存到内存中，Lucene 称之为 filter cache.</p>
</blockquote>
<h3 id="6elasticsearch中的集群-节点-索引-文档-类型是什么">6.ElasticSearch中的集群、节点、索引、文档、类型是什么？</h3>
<p><strong><code>群集</code></strong> 是一个或多个节点（服务器）的集合，它们共同保存您的整个数据，并提供跨所有节点的联合索引和搜索功能。群集由唯一名称标识，默认情况下为“elasticsearch”。此名称很重要，因为如果节点设置为按名称加入群集，则该节点只能是群集的一部分。</p>
<p><strong><code>节点</code></strong> 是属于集群一部分的单个服务器。它存储数据并参与群集索引和搜索功能。</p>
<p><strong><code>索引</code></strong> 就像关系数据库中的“数据库”。它有一个定义多种类型的映射。索引是逻辑名称空间，映射到一个或多个主分片，并且可以有零个或多个副本分片。 MySQL =&gt;数据库 　　 ElasticSearch =&gt;索引</p>
<p><strong><code>文档</code></strong> 类似于关系数据库中的一行。不同之处在于索引中的每个文档可以具有不同的结构（字段），但是对于通用字段应该具有相同的数据类型。 MySQL =&gt; Databases =&gt;Tables =&gt; Columns / Rows  ElasticSearch =&gt; Indices =&gt; Types =&gt;具有属性的文档</p>
<p><strong><code>类型</code></strong> 是索引的逻辑类别/分区，其语义完全取决于用户。</p>
<h3 id="7elasticsearch中的分片是什么">7.ElasticSearch中的分片是什么?</h3>
<p>在大多数环境中，每个节点都在单独的盒子或虚拟机上运行。</p>
<p><strong><code>索引</code></strong>  - 在Elasticsearch中，索引是文档的集合。</p>
<p><strong><code>分片</code></strong>  -因为Elasticsearch是一个分布式搜索引擎，所以索引通常被分割成分布在多个节点上的被称为分片的元素。</p>
<p><strong><code>Segment</code></strong> -每个shard（分片）包含多个segment（段），每一个segment都是一个倒排索引<br>
在查询的时，会把所有的segment查询结果汇总归并后最为最终的分片查询结果返回<br>
1.segment是不可变的，物理上你并不能从中删除信息，所以在删除文档的时候，是在文档上面打上一个删除的标记，然后在执行段合并的时候，进行删除<br>
2.索引segment段的个数越多，搜索性能越低且消耗内存更多</p>
<p>​		<strong><code>副本</code></strong>  -一个索引被分解成碎片以便于分发和扩展。副本是分片的副本。</p>
<p>​		<strong><code>分析器</code></strong>  -在ElasticSearch中索引数据时，数据由为索引定义的Analyzer在内部进行转换。 分析器由一个Tokenizer和零个或多个TokenFilter组成。编译器可以在一个或多个CharFilter之前。分析模块允许您在逻辑名称下注册分析器，然后可以在映射定义或某些API中引用它们。Elasticsearch附带了许多可以随时使用的预建分析器。或者，您可以组合内置的字符过滤器，编译器和过滤器器来创建自定义分析器。</p>
<p>​		<strong><code>编译器</code></strong>  -编译器用于将字符串分解为术语或标记流。一个简单的编译器可能会将字符串拆分为任何遇到空格或标点的地方。Elasticsearch有许多内置标记器，可用于构建自定义分析器。</p>
<h3 id="8详细描述一下elasticsearch索引文档的过程">8.详细描述一下Elasticsearch索引文档的过程。</h3>
<ul>
<li>协调节点默认使用文档ID参与计算（也支持通过routing），以便为路由提供合适的分片。</li>
</ul>
<pre><code>shard = hash(document_id) % (num_of_primary_shards)
</code></pre>
<ul>
<li>当分片所在的节点接收到来自协调节点的请求后，会将请求写入到Memory Buffer，然后定时（默认是每隔1秒）写入到Filesystem Cache，这个从Momery Buffer到Filesystem Cache的过程就叫做refresh；</li>
<li>当然在某些情况下，存在Momery Buffer和Filesystem Cache的数据可能会丢失，ES是通过translog的机制来保证数据的可靠性的。其实现机制是接收到请求后，同时也会写入到translog中，当Filesystem cache中的数据写入到磁盘中时，才会清除掉，这个过程叫做flush；</li>
<li>在flush过程中，内存中的缓冲将被清除，内容被写入一个新段，段的fsync将创建一个新的提交点，并将内容刷新到磁盘，旧的translog将被删除并开始一个新的translog。</li>
<li>flush触发的时机是定时触发（默认30分钟）或者translog变得太大（默认为512M）时；</li>
</ul>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1622018263120.jpeg" alt="" loading="lazy"></figure>
<p><em>补充：关于Lucene的Segement：</em></p>
<ul>
<li>Lucene索引是由多个段组成，段本身是一个功能齐全的倒排索引。</li>
<li>段是不可变的，允许Lucene将新的文档增量地添加到索引中，而不用从头重建索引。</li>
<li>对于每一个搜索请求而言，索引中的所有段都会被搜索，并且每个段会消耗CPU的时钟周、文件句柄和内存。这意味着段的数量越多，搜索性能会越低。</li>
<li>为了解决这个问题，Elasticsearch会合并小段到一个较大的段，提交新的合并段到磁盘，并删除那些旧的小段。</li>
</ul>
<h3 id="9详细描述一下elasticsearch更新和删除文档的过程">9.详细描述一下Elasticsearch更新和删除文档的过程</h3>
<ul>
<li>删除和更新也都是写操作，但是Elasticsearch中的文档是不可变的，因此不能被删除或者改动以展示其变更；</li>
<li>磁盘上的每个段都有一个相应的.del文件。当删除请求发送后，文档并没有真的被删除，而是在.del文件中被标记为删除。该文档依然能匹配查询，但是会在结果中被过滤掉。当段合并时，在.del文件中被标记为删除的文档将不会被写入新段。</li>
<li>在新的文档被创建时，Elasticsearch会为该文档指定一个版本号，当执行更新时，旧版本的文档在.del文件中被标记为删除，新版本的文档被索引到一个新段。旧版本的文档依然能匹配查询，但是会在结果中被过滤掉。</li>
</ul>
<h3 id="10详细描述一下elasticsearch搜索的过程">10.详细描述一下Elasticsearch搜索的过程</h3>
<ul>
<li>搜索被执行成一个两阶段过程，我们称之为 Query Then Fetch；</li>
<li>在初始<em>查询阶段</em>时，查询会广播到索引中每一个分片拷贝（主分片或者副本分片）。 每个分片在本地执行搜索并构建一个匹配文档的大小为 from + size 的优先队列。<em>PS：在搜索的时候是会查询Filesystem Cache的，但是有部分数据还在Memory Buffer，所以搜索是近实时的。</em></li>
<li>每个分片返回各自优先队列中 <strong>所有文档的 ID 和排序值</strong> 给协调节点，它合并这些值到自己的优先队列中来产生一个全局排序后的结果列表。</li>
<li>接下来就是 <em>取回阶段</em>，协调节点辨别出哪些文档需要被取回并向相关的分片提交多个 GET 请求。每个分片加载并 <em>丰富</em> 文档，如果有需要的话，接着返回文档给协调节点。一旦所有的文档都被取回了，协调节点返回结果给客户端。</li>
<li><em>补充：Query Then Fetch的搜索类型在文档相关性打分的时候参考的是本分片的数据，这样在文档数量较少的时候可能不够准确，DFS Query Then Fetch增加了一个预查询的处理，询问Term和Document frequency，这个评分更准确，但是性能会变差。</em></li>
</ul>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1622014432949.jpeg" alt="" loading="lazy"></figure>
<h3 id="11elasticsearch对于大数据量上亿量级的聚合如何实现">11.Elasticsearch对于大数据量（上亿量级）的聚合如何实现？</h3>
<ul>
<li>Elasticsearch 提供的首个近似聚合是cardinality 度量。它提供一个字段的基数，即该字段的<em>distinct</em>或者<em>unique</em>值的数目。它是基于HLL算法的。HLL 会先对我们的输入作哈希运算，然后根据哈希运算的结果中的 bits 做概率估算从而得到基数。其特点是：可配置的精度，用来控制内存的使用（更精确 ＝ 更多内存）；小的数据集精度是非常高的；我们可以通过配置参数，来设置去重需要的固定内存使用量。无论数千还是数十亿的唯一值，内存使用量只与你配置的精确度相关。</li>
</ul>
<h3 id="12在并发情况下elasticsearch如果保证读写一致">12.在并发情况下，Elasticsearch如果保证读写一致？</h3>
<ul>
<li>可以通过版本号使用乐观并发控制，以确保新版本不会被旧版本覆盖，由应用层来处理具体的冲突；</li>
<li>另外对于写操作，一致性级别支持quorum/one/all，默认为quorum，即只有当大多数分片可用时才允许写操作。但即使大多数可用，也可能存在因为网络等原因导致写入副本失败，这样该副本被认为故障，分片将会在一个不同的节点上重建。</li>
<li>对于读操作，可以设置replication为sync(默认)，这使得操作在主分片和副本分片都完成后才会返回；如果设置replication为async时，也可以通过设置搜索请求参数_preference为primary来查询主分片，确保文档是最新版本。</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[elasticSearch查询语句]]></title>
        <id>https://tinaxiawuhao.github.io/post/AdeCmc8BU/</id>
        <link href="https://tinaxiawuhao.github.io/post/AdeCmc8BU/">
        </link>
        <updated>2021-05-28T06:13:34.000Z</updated>
        <content type="html"><![CDATA[<!-- more -->
<blockquote>
<p>原文：https://distributedbytes.timojo.com/2016/07/23-useful-elasticsearch-example-queries.html<br>
作者：Tim Ojo</p>
</blockquote>
<p>为了演示不同类型的 ElasticSearch 的查询，我们将使用以下字段搜索书籍文档的集合（ title（标题）, authors（作者）, summary（摘要）, publish_date（发布日期）和 num_reviews（浏览数））。</p>
<p>在这之前，首先我们应该先创建一个新的索引（index），并批量导入一些文档：</p>
<p>创建索引：</p>
<pre><code class="language-json">PUT /bookdb_index
    { &quot;settings&quot;: { &quot;number_of_shards&quot;: 1 }} 
</code></pre>
<p>批量上传文档：</p>
<pre><code class="language-json">POST /bookdb_index/book/_bulk
    { &quot;index&quot;: { &quot;_id&quot;: 1 }}
    { &quot;title&quot;: &quot;Elasticsearch: The Definitive Guide&quot;, &quot;authors&quot;: [&quot;clinton gormley&quot;, &quot;zachary tong&quot;], &quot;summary&quot; : &quot;A distibuted real-time search and analytics engine&quot;, &quot;publish_date&quot; : &quot;2015-02-07&quot;, &quot;num_reviews&quot;: 20, &quot;publisher&quot;: &quot;oreilly&quot; }
    { &quot;index&quot;: { &quot;_id&quot;: 2 }}
    { &quot;title&quot;: &quot;Taming Text: How to Find, Organize, and Manipulate It&quot;, &quot;authors&quot;: [&quot;grant ingersoll&quot;, &quot;thomas morton&quot;, &quot;drew farris&quot;], &quot;summary&quot; : &quot;organize text using approaches such as full-text search, proper name recognition, clustering, tagging, information extraction, and summarization&quot;, &quot;publish_date&quot; : &quot;2013-01-24&quot;, &quot;num_reviews&quot;: 12, &quot;publisher&quot;: &quot;manning&quot; }
    { &quot;index&quot;: { &quot;_id&quot;: 3 }}
    { &quot;title&quot;: &quot;Elasticsearch in Action&quot;, &quot;authors&quot;: [&quot;radu gheorge&quot;, &quot;matthew lee hinman&quot;, &quot;roy russo&quot;], &quot;summary&quot; : &quot;build scalable search applications using Elasticsearch without having to do complex low-level programming or understand advanced data science algorithms&quot;, &quot;publish_date&quot; : &quot;2015-12-03&quot;, &quot;num_reviews&quot;: 18, &quot;publisher&quot;: &quot;manning&quot; }
    { &quot;index&quot;: { &quot;_id&quot;: 4 }}
    { &quot;title&quot;: &quot;Solr in Action&quot;, &quot;authors&quot;: [&quot;trey grainger&quot;, &quot;timothy potter&quot;], &quot;summary&quot; : &quot;Comprehensive guide to implementing a scalable search engine using Apache Solr&quot;, &quot;publish_date&quot; : &quot;2014-04-05&quot;, &quot;num_reviews&quot;: 23, &quot;publisher&quot;: &quot;manning&quot; }
</code></pre>
<h2 id="例子">例子</h2>
<h3 id="1基本比对查询">1.基本比对查询</h3>
<p>执行基本的全文本（匹配）查询有两种方式：使用Search Lite API（它希望所有搜索参数都作为URL的一部分传入），或使用完整的JSON请求正文（允许您使用完整的Elasticsearch DSL)。</p>
<p>这是一个基本的匹配查询，它在所有字段中搜索字符串“ guide”</p>
<pre><code class="language-json">GET /bookdb_index/book/_search?q=guide

[Results]
&quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;1&quot;,
        &quot;_score&quot;: 0.28168046,
        &quot;_source&quot;: {
          &quot;title&quot;: &quot;Elasticsearch: The Definitive Guide&quot;,
          &quot;authors&quot;: [
            &quot;clinton gormley&quot;,
            &quot;zachary tong&quot;
          ],
          &quot;summary&quot;: &quot;A distibuted real-time search and analytics engine&quot;,
          &quot;publish_date&quot;: &quot;2015-02-07&quot;,
          &quot;num_reviews&quot;: 20,
          &quot;publisher&quot;: &quot;manning&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;4&quot;,
        &quot;_score&quot;: 0.24144039,
        &quot;_source&quot;: {
          &quot;title&quot;: &quot;Solr in Action&quot;,
          &quot;authors&quot;: [
            &quot;trey grainger&quot;,
            &quot;timothy potter&quot;
          ],
          &quot;summary&quot;: &quot;Comprehensive guide to implementing a scalable search engine using Apache Solr&quot;,
          &quot;publish_date&quot;: &quot;2014-04-05&quot;,
          &quot;num_reviews&quot;: 23,
          &quot;publisher&quot;: &quot;manning&quot;
        }
      }
    ]

</code></pre>
<p>该查询的完整版本如下所示，其产生的结果与上述搜索精简版相同。</p>
<pre><code class="language-java">{
    &quot;query&quot;: {
        &quot;multi_match&quot; : {
            &quot;query&quot; : &quot;guide&quot;,
            &quot;fields&quot; : [&quot;_all&quot;]
        }
    }
}
 
</code></pre>
<p>使用<code>multi_match</code>关键字代替关键字<code>match</code>是对多个字段运行相同查询的便捷快捷方式。该<code>fields</code>属性指定要查询的字段，在这种情况下，我们要查询文档中的所有字段。<br>
这两个API均允许您指定要搜索的字段。例如，要在标题字段中搜索带有“in action”字样的图书，请执行以下操作：</p>
<pre><code class="language-java">GET /bookdb_index/book/_search?q=title:in action

[Results]
&quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;4&quot;,
        &quot;_score&quot;: 0.6259885,
        &quot;_source&quot;: {
          &quot;title&quot;: &quot;Solr in Action&quot;,
          &quot;authors&quot;: [
            &quot;trey grainger&quot;,
            &quot;timothy potter&quot;
          ],
          &quot;summary&quot;: &quot;Comprehensive guide to implementing a scalable search engine using Apache Solr&quot;,
          &quot;publish_date&quot;: &quot;2014-04-05&quot;,
          &quot;num_reviews&quot;: 23,
          &quot;publisher&quot;: &quot;manning&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;3&quot;,
        &quot;_score&quot;: 0.5975345,
        &quot;_source&quot;: {
          &quot;title&quot;: &quot;Elasticsearch in Action&quot;,
          &quot;authors&quot;: [
            &quot;radu gheorge&quot;,
            &quot;matthew lee hinman&quot;,
            &quot;roy russo&quot;
          ],
          &quot;summary&quot;: &quot;build scalable search applications using Elasticsearch without having to do complex low-level programming or understand advanced data science algorithms&quot;,
          &quot;publish_date&quot;: &quot;2015-12-03&quot;,
          &quot;num_reviews&quot;: 18,
          &quot;publisher&quot;: &quot;manning&quot;
        }
      }
    ]
 
</code></pre>
<p>但是，全身DSL在创建更复杂的查询（如我们将在后面看到）以及指定您希望如何返回结果方面给您更大的灵活性。在下面的示例中，我们指定要返回的结果数，开始的偏移量（用于分页），要返回的文档字段以及术语突出显示。</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;match&quot; : {
            &quot;title&quot; : &quot;in action&quot;
        }
    },
    &quot;size&quot;: 2,
    &quot;from&quot;: 0,
    &quot;_source&quot;: [ &quot;title&quot;, &quot;summary&quot;, &quot;publish_date&quot; ],
    &quot;highlight&quot;: {
        &quot;fields&quot; : {
            &quot;title&quot; : {}
        }
    }
}

[Results]
&quot;hits&quot;: {
    &quot;total&quot;: 2,
    &quot;max_score&quot;: 0.9105287,
    &quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;3&quot;,
        &quot;_score&quot;: 0.9105287,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;build scalable search applications using Elasticsearch without having to do complex low-level programming or understand advanced data science algorithms&quot;,
          &quot;title&quot;: &quot;Elasticsearch in Action&quot;,
          &quot;publish_date&quot;: &quot;2015-12-03&quot;
        },
        &quot;highlight&quot;: {
          &quot;title&quot;: [
            &quot;Elasticsearch &lt;em&gt;in&lt;/em&gt; &lt;em&gt;Action&lt;/em&gt;&quot;
          ]
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;4&quot;,
        &quot;_score&quot;: 0.9105287,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;Comprehensive guide to implementing a scalable search engine using Apache Solr&quot;,
          &quot;title&quot;: &quot;Solr in Action&quot;,
          &quot;publish_date&quot;: &quot;2014-04-05&quot;
        },
        &quot;highlight&quot;: {
          &quot;title&quot;: [
            &quot;Solr &lt;em&gt;in&lt;/em&gt; &lt;em&gt;Action&lt;/em&gt;&quot;
          ]
        }
      }
    ]
  }
 
</code></pre>
<p>**注意：**对于多字查询，该<code>match</code>查询使您可以指定是否使用<code>and</code>运算符而不是默认<code>or</code>运算符。您还可以指定<code>minimum_should_match</code>选项来调整返回结果的相关性。可以在<a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/match-multi-word.html">这里</a>找到详细信息。</p>
<h3 id="2多字段搜索">2.多字段搜索</h3>
<p>正如我们已经看到的，要在搜索中查询多个文档字段（例如，在标题和摘要中搜索相同的查询字符串），则可以使用该<code>multi_match</code>查询。</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;multi_match&quot; : {
            &quot;query&quot; : &quot;elasticsearch guide&quot;,
            &quot;fields&quot;: [&quot;title&quot;, &quot;summary&quot;]
        }
    }
}

[Results]
&quot;hits&quot;: {
    &quot;total&quot;: 3,
    &quot;max_score&quot;: 0.9448582,
    &quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;1&quot;,
        &quot;_score&quot;: 0.9448582,
        &quot;_source&quot;: {
          &quot;title&quot;: &quot;Elasticsearch: The Definitive Guide&quot;,
          &quot;authors&quot;: [
            &quot;clinton gormley&quot;,
            &quot;zachary tong&quot;
          ],
          &quot;summary&quot;: &quot;A distibuted real-time search and analytics engine&quot;,
          &quot;publish_date&quot;: &quot;2015-02-07&quot;,
          &quot;num_reviews&quot;: 20,
          &quot;publisher&quot;: &quot;manning&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;3&quot;,
        &quot;_score&quot;: 0.17312013,
        &quot;_source&quot;: {
          &quot;title&quot;: &quot;Elasticsearch in Action&quot;,
          &quot;authors&quot;: [
            &quot;radu gheorge&quot;,
            &quot;matthew lee hinman&quot;,
            &quot;roy russo&quot;
          ],
          &quot;summary&quot;: &quot;build scalable search applications using Elasticsearch without having to do complex low-level programming or understand advanced data science algorithms&quot;,
          &quot;publish_date&quot;: &quot;2015-12-03&quot;,
          &quot;num_reviews&quot;: 18,
          &quot;publisher&quot;: &quot;manning&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;4&quot;,
        &quot;_score&quot;: 0.14965448,
        &quot;_source&quot;: {
          &quot;title&quot;: &quot;Solr in Action&quot;,
          &quot;authors&quot;: [
            &quot;trey grainger&quot;,
            &quot;timothy potter&quot;
          ],
          &quot;summary&quot;: &quot;Comprehensive guide to implementing a scalable search engine using Apache Solr&quot;,
          &quot;publish_date&quot;: &quot;2014-04-05&quot;,
          &quot;num_reviews&quot;: 23,
          &quot;publisher&quot;: &quot;manning&quot;
        }
      }
    ]
  }
 
</code></pre>
<p>请注意，命中数字3相匹配，因为在摘要中找到了“指南”一词。</p>
<h3 id="3提高字段重要性">3.提高字段重要性</h3>
<p>由于我们正在多个字段中进行搜索，因此我们可能希望提高特定字段中的得分。在以下人为设计的示例中，我们将摘要字段的得分提高了3倍，以提高摘要字段的重要性，这反过来又会增加文档<code>_id 4</code>的相关性。</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;multi_match&quot; : {
            &quot;query&quot; : &quot;elasticsearch guide&quot;,
            &quot;fields&quot;: [&quot;title&quot;, &quot;summary^3&quot;]
        }
    },
    &quot;_source&quot;: [&quot;title&quot;, &quot;summary&quot;, &quot;publish_date&quot;]
}

[Results]
&quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;1&quot;,
        &quot;_score&quot;: 0.31495273,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;A distibuted real-time search and analytics engine&quot;,
          &quot;title&quot;: &quot;Elasticsearch: The Definitive Guide&quot;,
          &quot;publish_date&quot;: &quot;2015-02-07&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;4&quot;,
        &quot;_score&quot;: 0.14965448,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;Comprehensive guide to implementing a scalable search engine using Apache Solr&quot;,
          &quot;title&quot;: &quot;Solr in Action&quot;,
          &quot;publish_date&quot;: &quot;2014-04-05&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;3&quot;,
        &quot;_score&quot;: 0.13094766,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;build scalable search applications using Elasticsearch without having to do complex low-level programming or understand advanced data science algorithms&quot;,
          &quot;title&quot;: &quot;Elasticsearch in Action&quot;,
          &quot;publish_date&quot;: &quot;2015-12-03&quot;
        }
      }
    ]
 
</code></pre>
<p><strong>注意：</strong> Boosting不仅仅意味着计算出的分数会乘以Boosting系数。实际应用的升压值经过归一化和一些内部优化。有关增强工作原理的更多信息，请参见 <a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/query-time-boosting.html">Elasticsearch指南</a>。</p>
<h3 id="4布尔查询">4.布尔查询</h3>
<p>AND / OR / NOT运算符可用于微调我们的搜索查询，以提供更相关或更具体的结果。这是在搜索API中作为<code>bool</code>查询实现的。该<code>bool</code>查询接受一个<code>must</code>参数（等同于AND），一个<code>must_not</code>参数（等同于NOT）和一个<code>should</code>参数（等同于OR）。例如，如果我要搜索书名中带有“ Elasticsearch”或“ Solr”字样的书，则AND由“克林顿·戈姆利”（clinton gormley）创作，而不由“ radu gheorge”（radu gheorge）创作：</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;bool&quot;: {
            &quot;must&quot;: {
                &quot;bool&quot; : { &quot;should&quot;: [
                      { &quot;match&quot;: { &quot;title&quot;: &quot;Elasticsearch&quot; }},
                      { &quot;match&quot;: { &quot;title&quot;: &quot;Solr&quot; }} ] }
            },
            &quot;must&quot;: { &quot;match&quot;: { &quot;authors&quot;: &quot;clinton gormely&quot; }},
            &quot;must_not&quot;: { &quot;match&quot;: {&quot;authors&quot;: &quot;radu gheorge&quot; }}
        }
    }
}

[Results]
&quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;1&quot;,
        &quot;_score&quot;: 0.3672021,
        &quot;_source&quot;: {
          &quot;title&quot;: &quot;Elasticsearch: The Definitive Guide&quot;,
          &quot;authors&quot;: [
            &quot;clinton gormley&quot;,
            &quot;zachary tong&quot;
          ],
          &quot;summary&quot;: &quot;A distibuted real-time search and analytics engine&quot;,
          &quot;publish_date&quot;: &quot;2015-02-07&quot;,
          &quot;num_reviews&quot;: 20,
          &quot;publisher&quot;: &quot;oreilly&quot;
        }
      }
    ]
 
</code></pre>
<p>**注意：**如您所见，布尔查询可以包装任何其他查询类型，包括其他布尔查询，以创建任意复杂或深度嵌套的查询。</p>
<h3 id="5模糊查询">5.模糊查询</h3>
<p>可以在“匹配”和“多匹配”查询中启用模糊匹配，以捕获拼写错误。模糊程度是根据距原始单词的Levenshtein距离指定的。</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;multi_match&quot; : {
            &quot;query&quot; : &quot;comprihensiv guide&quot;,
            &quot;fields&quot;: [&quot;title&quot;, &quot;summary&quot;],
            &quot;fuzziness&quot;: &quot;AUTO&quot;
        }
    },
    &quot;_source&quot;: [&quot;title&quot;, &quot;summary&quot;, &quot;publish_date&quot;],
    &quot;size&quot;: 1
}

[Results]
&quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;4&quot;,
        &quot;_score&quot;: 0.5961596,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;Comprehensive guide to implementing a scalable search engine using Apache Solr&quot;,
          &quot;title&quot;: &quot;Solr in Action&quot;,
          &quot;publish_date&quot;: &quot;2014-04-05&quot;
        }
      }
    ]
 
</code></pre>
<p>**注意：**模糊度值<code>&quot;AUTO&quot;</code>等于指定<code>2</code>术语长度大于5时的值。但是，设置80％的人类拼写错误的编辑距离为<code>1</code>，并将模糊度设置为<code>1</code>可以改善整体搜索性能。有关更多信息，请参见《Elasticsearch最终指南》的“<a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/fuzziness.html">错别字和拼写错误”</a>一章。</p>
<h3 id="6通配符查询">6.通配符查询</h3>
<p>通配符查询使您可以指定要匹配的模式，而不是整个术语。<code>?</code>匹配任何字符并<code>*</code>匹配零个或多个字符。例如，要查找所有作者姓名以字母“ t”开头的记录</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;wildcard&quot; : {
            &quot;authors&quot; : &quot;t*&quot;
        }
    },
    &quot;_source&quot;: [&quot;title&quot;, &quot;authors&quot;],
    &quot;highlight&quot;: {
        &quot;fields&quot; : {
            &quot;authors&quot; : {}
        }
    }
}

[Results]
&quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;1&quot;,
        &quot;_score&quot;: 1,
        &quot;_source&quot;: {
          &quot;title&quot;: &quot;Elasticsearch: The Definitive Guide&quot;,
          &quot;authors&quot;: [
            &quot;clinton gormley&quot;,
            &quot;zachary tong&quot;
          ]
        },
        &quot;highlight&quot;: {
          &quot;authors&quot;: [
            &quot;zachary &lt;em&gt;tong&lt;/em&gt;&quot;
          ]
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;2&quot;,
        &quot;_score&quot;: 1,
        &quot;_source&quot;: {
          &quot;title&quot;: &quot;Taming Text: How to Find, Organize, and Manipulate It&quot;,
          &quot;authors&quot;: [
            &quot;grant ingersoll&quot;,
            &quot;thomas morton&quot;,
            &quot;drew farris&quot;
          ]
        },
        &quot;highlight&quot;: {
          &quot;authors&quot;: [
            &quot;&lt;em&gt;thomas&lt;/em&gt; morton&quot;
          ]
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;4&quot;,
        &quot;_score&quot;: 1,
        &quot;_source&quot;: {
          &quot;title&quot;: &quot;Solr in Action&quot;,
          &quot;authors&quot;: [
            &quot;trey grainger&quot;,
            &quot;timothy potter&quot;
          ]
        },
        &quot;highlight&quot;: {
          &quot;authors&quot;: [
            &quot;&lt;em&gt;trey&lt;/em&gt; grainger&quot;,
            &quot;&lt;em&gt;timothy&lt;/em&gt; potter&quot;
          ]
        }
      }
    ] 
 
</code></pre>
<h3 id="7正则表达式查询">7.正则表达式查询</h3>
<p>正则表达式查询使您可以指定比通配符查询更复杂的模式。</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;regexp&quot; : {
            &quot;authors&quot; : &quot;t[a-z]*y&quot;
        }
    },
    &quot;_source&quot;: [&quot;title&quot;, &quot;authors&quot;],
    &quot;highlight&quot;: {
        &quot;fields&quot; : {
            &quot;authors&quot; : {}
        }
    }
}

[Results]
&quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;4&quot;,
        &quot;_score&quot;: 1,
        &quot;_source&quot;: {
          &quot;title&quot;: &quot;Solr in Action&quot;,
          &quot;authors&quot;: [
            &quot;trey grainger&quot;,
            &quot;timothy potter&quot;
          ]
        },
        &quot;highlight&quot;: {
          &quot;authors&quot;: [
            &quot;&lt;em&gt;trey&lt;/em&gt; grainger&quot;,
            &quot;&lt;em&gt;timothy&lt;/em&gt; potter&quot;
          ]
        }
      }
    ]
 
</code></pre>
<h3 id="8匹配词组查询">8.匹配词组查询</h3>
<p>匹配词组查询要求查询字符串中的所有术语都存在于文档中，并按照查询字符串中指定的顺序并且彼此接近。默认情况下，术语必须彼此完全平行，但是您可以指定一个<code>slop</code>值，该值指示在仍将文档视为匹配项时允许相隔多远的术语。</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;multi_match&quot; : {
            &quot;query&quot;: &quot;search engine&quot;,
            &quot;fields&quot;: [&quot;title&quot;, &quot;summary&quot;],
            &quot;type&quot;: &quot;phrase&quot;,
            &quot;slop&quot;: 3
        }
    },
    &quot;_source&quot;: [ &quot;title&quot;, &quot;summary&quot;, &quot;publish_date&quot; ]
}

[Results]
&quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;4&quot;,
        &quot;_score&quot;: 0.22327082,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;Comprehensive guide to implementing a scalable search engine using Apache Solr&quot;,
          &quot;title&quot;: &quot;Solr in Action&quot;,
          &quot;publish_date&quot;: &quot;2014-04-05&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;1&quot;,
        &quot;_score&quot;: 0.16113183,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;A distibuted real-time search and analytics engine&quot;,
          &quot;title&quot;: &quot;Elasticsearch: The Definitive Guide&quot;,
          &quot;publish_date&quot;: &quot;2015-02-07&quot;
        }
      }
    ]
 
</code></pre>
<p>**注意：**在上面的示例中，对于非短语类型查询，文档的<code>_id 1</code>得分通常更高，并且<code>_id 4</code>由于其字段长度较短而出现在文档的前面。但是，在进行短语查询时，会考虑到术语的接近度，因此文档<code>_id 4</code>得分会更高。</p>
<h3 id="9匹配词组前缀">9.匹配词组前缀</h3>
<p>匹配词组前缀查询可在查询时提供“按需输入”或“穷人”版本的自动完成功能，而无需以任何方式准备数据。像match_phrase查询一样，它接受一个<code>slop</code>参数以使单词顺序和相对位置的刚性降低一些。我还接受该<code>max_expansions</code>参数来限制匹配项的数量，以降低资源强度。</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;match_phrase_prefix&quot; : {
            &quot;summary&quot;: {
                &quot;query&quot;: &quot;search en&quot;,
                &quot;slop&quot;: 3,
                &quot;max_expansions&quot;: 10
            }
        }
    },
    &quot;_source&quot;: [ &quot;title&quot;, &quot;summary&quot;, &quot;publish_date&quot; ]
}

[Results]
&quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;4&quot;,
        &quot;_score&quot;: 0.5161346,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;Comprehensive guide to implementing a scalable search engine using Apache Solr&quot;,
          &quot;title&quot;: &quot;Solr in Action&quot;,
          &quot;publish_date&quot;: &quot;2014-04-05&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;1&quot;,
        &quot;_score&quot;: 0.37248808,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;A distibuted real-time search and analytics engine&quot;,
          &quot;title&quot;: &quot;Elasticsearch: The Definitive Guide&quot;,
          &quot;publish_date&quot;: &quot;2015-02-07&quot;
        }
      }
    ]
 
</code></pre>
<p>**注意：“**按类型查询时搜索”会降低性能。更好的解决方案是按类型进行索引时间搜索。请查看<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-suggesters-completion.html">完成提示API</a>或使用<a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/_index_time_search_as_you_type.html">Edge-Ngram过滤器</a>以获取更多信息。</p>
<h3 id="10请求参数">10.请求参数</h3>
<p>该<code>query_string</code>查询提供了一种以简洁的速记语法执行多重匹配查询，布尔查询，增强查询，模糊匹配，通配符，正则表达式和范围查询的方法。在下面的示例中，我们对术语“ saerch算法”执行模糊搜索，其中作者之一是“ grant ingersoll”或“ tom morton”。我们搜索所有字段，但对摘要字段加2。</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;query_string&quot; : {
            &quot;query&quot;: &quot;(saerch~1 algorithm~1) AND (grant ingersoll)  OR (tom morton)&quot;,
            &quot;fields&quot;: [&quot;_all&quot;, &quot;summary^2&quot;]
        }
    },
    &quot;_source&quot;: [ &quot;title&quot;, &quot;summary&quot;, &quot;authors&quot; ],
    &quot;highlight&quot;: {
        &quot;fields&quot; : {
            &quot;summary&quot; : {}
        }
    }
}

[Results]
&quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;2&quot;,
        &quot;_score&quot;: 0.14558059,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;organize text using approaches such as full-text search, proper name recognition, clustering, tagging, information extraction, and summarization&quot;,
          &quot;title&quot;: &quot;Taming Text: How to Find, Organize, and Manipulate It&quot;,
          &quot;authors&quot;: [
            &quot;grant ingersoll&quot;,
            &quot;thomas morton&quot;,
            &quot;drew farris&quot;
          ]
        },
        &quot;highlight&quot;: {
          &quot;summary&quot;: [
            &quot;organize text using approaches such as full-text &lt;em&gt;search&lt;/em&gt;, proper name recognition, clustering, tagging, information extraction, and summarization&quot;
          ]
        }
      }
    ]
 
</code></pre>
<h3 id="11简单查询字符串">11.简单查询字符串</h3>
<p>该<code>simple_query_string</code>查询是该查询的一种版本<code>query_string</code>，它更适合在暴露给用户的单个搜索框中使用。它分别用+ / | /-代替了AND / OR / NOT的使用，并且丢弃了查询的无效部分，而不是在用户犯错时抛出异常。</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;simple_query_string&quot; : {
            &quot;query&quot;: &quot;(saerch~1 algorithm~1) + (grant ingersoll)  | (tom morton)&quot;,
            &quot;fields&quot;: [&quot;_all&quot;, &quot;summary^2&quot;]
        }
    },
    &quot;_source&quot;: [ &quot;title&quot;, &quot;summary&quot;, &quot;authors&quot; ],
    &quot;highlight&quot;: {
        &quot;fields&quot; : {
            &quot;summary&quot; : {}
        }
    }
} 
 
</code></pre>
<h3 id="12术语查询">12.术语查询</h3>
<p>以上示例是全文搜索的示例。有时，我们对结构化搜索更感兴趣，在结构化搜索中我们希望找到完全匹配并返回结果。在<code>term</code>与<code>terms</code>查询帮助我们在这里。在下面的示例中，我们正在搜索Manning Publications出版的索引中的所有书籍。</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;term&quot; : {
            &quot;publisher&quot;: &quot;manning&quot;
        }
    },
    &quot;_source&quot; : [&quot;title&quot;,&quot;publish_date&quot;,&quot;publisher&quot;]
}

[Results]
&quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;2&quot;,
        &quot;_score&quot;: 1.2231436,
        &quot;_source&quot;: {
          &quot;publisher&quot;: &quot;manning&quot;,
          &quot;title&quot;: &quot;Taming Text: How to Find, Organize, and Manipulate It&quot;,
          &quot;publish_date&quot;: &quot;2013-01-24&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;3&quot;,
        &quot;_score&quot;: 1.2231436,
        &quot;_source&quot;: {
          &quot;publisher&quot;: &quot;manning&quot;,
          &quot;title&quot;: &quot;Elasticsearch in Action&quot;,
          &quot;publish_date&quot;: &quot;2015-12-03&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;4&quot;,
        &quot;_score&quot;: 1.2231436,
        &quot;_source&quot;: {
          &quot;publisher&quot;: &quot;manning&quot;,
          &quot;title&quot;: &quot;Solr in Action&quot;,
          &quot;publish_date&quot;: &quot;2014-04-05&quot;
        }
      }
    ]
 
</code></pre>
<p>可以使用<code>terms</code>关键字代替并传递搜索词数组来指定多个词。</p>
<pre><code class="language-java">{
    &quot;query&quot;: {
        &quot;terms&quot; : {
            &quot;publisher&quot;: [&quot;oreilly&quot;, &quot;packt&quot;]
        }
    }
} 
 
</code></pre>
<h3 id="13字词查询-排序">13.字词查询-排序</h3>
<p>术语查询结果（与任何其他查询结果一样）可以轻松地进行排序。也允许多级排序</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;term&quot; : {
            &quot;publisher&quot;: &quot;manning&quot;
        }
    },
    &quot;_source&quot; : [&quot;title&quot;,&quot;publish_date&quot;,&quot;publisher&quot;],
    &quot;sort&quot;: [
        { &quot;publish_date&quot;: {&quot;order&quot;:&quot;desc&quot;}},
        { &quot;title&quot;: { &quot;order&quot;: &quot;desc&quot; }}
    ]
}

[Results]
&quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;3&quot;,
        &quot;_score&quot;: null,
        &quot;_source&quot;: {
          &quot;publisher&quot;: &quot;manning&quot;,
          &quot;title&quot;: &quot;Elasticsearch in Action&quot;,
          &quot;publish_date&quot;: &quot;2015-12-03&quot;
        },
        &quot;sort&quot;: [
          1449100800000,
          &quot;in&quot;
        ]
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;4&quot;,
        &quot;_score&quot;: null,
        &quot;_source&quot;: {
          &quot;publisher&quot;: &quot;manning&quot;,
          &quot;title&quot;: &quot;Solr in Action&quot;,
          &quot;publish_date&quot;: &quot;2014-04-05&quot;
        },
        &quot;sort&quot;: [
          1396656000000,
          &quot;solr&quot;
        ]
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;2&quot;,
        &quot;_score&quot;: null,
        &quot;_source&quot;: {
          &quot;publisher&quot;: &quot;manning&quot;,
          &quot;title&quot;: &quot;Taming Text: How to Find, Organize, and Manipulate It&quot;,
          &quot;publish_date&quot;: &quot;2013-01-24&quot;
        },
        &quot;sort&quot;: [
          1358985600000,
          &quot;to&quot;
        ]
      }
    ]
 
</code></pre>
<h3 id="14范围查询">14.范围查询</h3>
<p>另一个结构化查询示例是范围查询。在此示例中，我们搜索2015年出版的图书。</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;range&quot; : {
            &quot;publish_date&quot;: {
                &quot;gte&quot;: &quot;2015-01-01&quot;,
                &quot;lte&quot;: &quot;2015-12-31&quot;
            }
        }
    },
    &quot;_source&quot; : [&quot;title&quot;,&quot;publish_date&quot;,&quot;publisher&quot;]
}

[Results]
&quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;1&quot;,
        &quot;_score&quot;: 1,
        &quot;_source&quot;: {
          &quot;publisher&quot;: &quot;oreilly&quot;,
          &quot;title&quot;: &quot;Elasticsearch: The Definitive Guide&quot;,
          &quot;publish_date&quot;: &quot;2015-02-07&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;3&quot;,
        &quot;_score&quot;: 1,
        &quot;_source&quot;: {
          &quot;publisher&quot;: &quot;manning&quot;,
          &quot;title&quot;: &quot;Elasticsearch in Action&quot;,
          &quot;publish_date&quot;: &quot;2015-12-03&quot;
        }
      }
    ]
 
</code></pre>
<p>**注意：**范围查询适用于日期，数字和字符串类型字段。</p>
<h3 id="15过滤查询">15.过滤查询</h3>
<p>筛选查询允许您筛选查询结果。对于我们的示例，我们正在查询标题或摘要中带有“ Elasticsearch”一词的图书，但我们希望将搜索结果过滤为仅包含20条或更多评论的图书。</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;filtered&quot;: {
            &quot;query&quot; : {
                &quot;multi_match&quot;: {
                    &quot;query&quot;: &quot;elasticsearch&quot;,
                    &quot;fields&quot;: [&quot;title&quot;,&quot;summary&quot;]
                }
            },
            &quot;filter&quot;: {
                &quot;range&quot; : {
                    &quot;num_reviews&quot;: {
                        &quot;gte&quot;: 20
                    }
                }
            }
        }
    },
    &quot;_source&quot; : [&quot;title&quot;,&quot;summary&quot;,&quot;publisher&quot;, &quot;num_reviews&quot;]
}

[Results]
&quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;1&quot;,
        &quot;_score&quot;: 0.5955761,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;A distibuted real-time search and analytics engine&quot;,
          &quot;publisher&quot;: &quot;oreilly&quot;,
          &quot;num_reviews&quot;: 20,
          &quot;title&quot;: &quot;Elasticsearch: The Definitive Guide&quot;
        }
      }
    ]
 
</code></pre>
<p><strong>注意</strong>：筛选查询并不要求存在要对其进行筛选的查询。如果未指定<code>match_all</code>查询，则运行查询，该查询基本上返回索引中的所有文档，然后对其进行过滤。实际上，首先运行过滤器，以减少需要查询的表面积。此外，过滤器在首次使用后会被缓存，这使其性能非常好。</p>
<p><strong>更新</strong>：已过滤的查询已从即将推出的Elasticsearch 5.0中删除，以支持bool查询。这是与上面相同的示例，改写为使用bool查询。返回的结果完全相同。</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;bool&quot;: {
            &quot;must&quot; : {
                &quot;multi_match&quot;: {
                    &quot;query&quot;: &quot;elasticsearch&quot;,
                    &quot;fields&quot;: [&quot;title&quot;,&quot;summary&quot;]
                }
            },
            &quot;filter&quot;: {
                &quot;range&quot; : {
                    &quot;num_reviews&quot;: {
                        &quot;gte&quot;: 20
                    }
                }
            }
        }
    },
    &quot;_source&quot; : [&quot;title&quot;,&quot;summary&quot;,&quot;publisher&quot;, &quot;num_reviews&quot;]
}
</code></pre>
<p>在下面的示例中，这也适用于多个过滤器。</p>
<h3 id="16多个过滤器">16.多个过滤器</h3>
<p>可以通过使用过滤器来组合多个过滤<code>bool</code>器。在下一个示例中，过滤器确定返回的结果必须至少具有20条评论，不得在2015年之前发布，而应由oreilly发布。</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;filtered&quot;: {
            &quot;query&quot; : {
                &quot;multi_match&quot;: {
                    &quot;query&quot;: &quot;elasticsearch&quot;,
                    &quot;fields&quot;: [&quot;title&quot;,&quot;summary&quot;]
                }
            },
            &quot;filter&quot;: {
                &quot;bool&quot;: {
                    &quot;must&quot;: {
                        &quot;range&quot; : { &quot;num_reviews&quot;: { &quot;gte&quot;: 20 } }
                    },
                    &quot;must_not&quot;: {
                        &quot;range&quot; : { &quot;publish_date&quot;: { &quot;lte&quot;: &quot;2014-12-31&quot; } }
                    },
                    &quot;should&quot;: {
                        &quot;term&quot;: { &quot;publisher&quot;: &quot;oreilly&quot; }
                    }
                }
            }
        }
    },
    &quot;_source&quot; : [&quot;title&quot;,&quot;summary&quot;,&quot;publisher&quot;, &quot;num_reviews&quot;, &quot;publish_date&quot;]
}

[Results]
&quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;1&quot;,
        &quot;_score&quot;: 0.5955761,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;A distibuted real-time search and analytics engine&quot;,
          &quot;publisher&quot;: &quot;oreilly&quot;,
          &quot;num_reviews&quot;: 20,
          &quot;title&quot;: &quot;Elasticsearch: The Definitive Guide&quot;,
          &quot;publish_date&quot;: &quot;2015-02-07&quot;
        }
      }
    ] 
 
</code></pre>
<h3 id="17功能评分字段值因子">17.功能评分：字段值因子</h3>
<p>在某些情况下，您可能希望将文档中特定字段的值纳入相关性分数的计算中。在您希望根据文档的受欢迎程度提高其相关性的情况下，这是典型的情况。在我们的示例中，我们希望增加受欢迎的书籍（根据评论数判断）。使用<code>field_value_factor</code>功能评分可以做到这一点。</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;function_score&quot;: {
            &quot;query&quot;: {
                &quot;multi_match&quot; : {
                    &quot;query&quot; : &quot;search engine&quot;,
                    &quot;fields&quot;: [&quot;title&quot;, &quot;summary&quot;]
                }
            },
            &quot;field_value_factor&quot;: {
                &quot;field&quot; : &quot;num_reviews&quot;,
                &quot;modifier&quot;: &quot;log1p&quot;,
                &quot;factor&quot; : 2
            }
        }
    },
    &quot;_source&quot;: [&quot;title&quot;, &quot;summary&quot;, &quot;publish_date&quot;, &quot;num_reviews&quot;]
}

[Results]
&quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;1&quot;,
        &quot;_score&quot;: 0.44831306,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;A distibuted real-time search and analytics engine&quot;,
          &quot;num_reviews&quot;: 20,
          &quot;title&quot;: &quot;Elasticsearch: The Definitive Guide&quot;,
          &quot;publish_date&quot;: &quot;2015-02-07&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;4&quot;,
        &quot;_score&quot;: 0.3718407,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;Comprehensive guide to implementing a scalable search engine using Apache Solr&quot;,
          &quot;num_reviews&quot;: 23,
          &quot;title&quot;: &quot;Solr in Action&quot;,
          &quot;publish_date&quot;: &quot;2014-04-05&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;3&quot;,
        &quot;_score&quot;: 0.046479136,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;build scalable search applications using Elasticsearch without having to do complex low-level programming or understand advanced data science algorithms&quot;,
          &quot;num_reviews&quot;: 18,
          &quot;title&quot;: &quot;Elasticsearch in Action&quot;,
          &quot;publish_date&quot;: &quot;2015-12-03&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;2&quot;,
        &quot;_score&quot;: 0.041432835,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;organize text using approaches such as full-text search, proper name recognition, clustering, tagging, information extraction, and summarization&quot;,
          &quot;num_reviews&quot;: 12,
          &quot;title&quot;: &quot;Taming Text: How to Find, Organize, and Manipulate It&quot;,
          &quot;publish_date&quot;: &quot;2013-01-24&quot;
        }
      }
    ]
 
</code></pre>
<p>**注意1：**我们本来可以运行常规<code>multi_match</code>查询并按num_reviews字段进行排序，但是这样就失去了进行相关性评分的好处。<br>
**注意2：**还有许多其他参数可以调整对原始相关性得分的增强效果，例如“修饰符”，“因子”，“ boost_mode”等。这些参数在<a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/boosting-by-popularity.html">Elasticsearch指南</a>中进行了详细探讨。</p>
<h3 id="18作用分值衰减功能">18.作用分值：衰减功能</h3>
<p>假设您不想以某个字段的值递增，而希望拥有理想的目标值，并且希望该增益因子随着距离该值的增加而衰减。这通常在基于纬度/经度，价格或日期等数字字段的提升中很有用。在我们精心设计的示例中，我们正在搜索理想情况下于2014年6月左右出版的“搜索引擎”书籍。</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;function_score&quot;: {
            &quot;query&quot;: {
                &quot;multi_match&quot; : {
                    &quot;query&quot; : &quot;search engine&quot;,
                    &quot;fields&quot;: [&quot;title&quot;, &quot;summary&quot;]
                }
            },
            &quot;functions&quot;: [
                {
                    &quot;exp&quot;: {
                        &quot;publish_date&quot; : {
                            &quot;origin&quot;: &quot;2014-06-15&quot;,
                            &quot;offset&quot;: &quot;7d&quot;,
                            &quot;scale&quot; : &quot;30d&quot;
                        }
                    }
                }
            ],
            &quot;boost_mode&quot; : &quot;replace&quot;
        }
    },
    &quot;_source&quot;: [&quot;title&quot;, &quot;summary&quot;, &quot;publish_date&quot;, &quot;num_reviews&quot;]
}

[Results]
&quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;4&quot;,
        &quot;_score&quot;: 0.27420625,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;Comprehensive guide to implementing a scalable search engine using Apache Solr&quot;,
          &quot;num_reviews&quot;: 23,
          &quot;title&quot;: &quot;Solr in Action&quot;,
          &quot;publish_date&quot;: &quot;2014-04-05&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;1&quot;,
        &quot;_score&quot;: 0.005920768,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;A distibuted real-time search and analytics engine&quot;,
          &quot;num_reviews&quot;: 20,
          &quot;title&quot;: &quot;Elasticsearch: The Definitive Guide&quot;,
          &quot;publish_date&quot;: &quot;2015-02-07&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;2&quot;,
        &quot;_score&quot;: 0.000011564,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;organize text using approaches such as full-text search, proper name recognition, clustering, tagging, information extraction, and summarization&quot;,
          &quot;num_reviews&quot;: 12,
          &quot;title&quot;: &quot;Taming Text: How to Find, Organize, and Manipulate It&quot;,
          &quot;publish_date&quot;: &quot;2013-01-24&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;3&quot;,
        &quot;_score&quot;: 0.0000059171475,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;build scalable search applications using Elasticsearch without having to do complex low-level programming or understand advanced data science algorithms&quot;,
          &quot;num_reviews&quot;: 18,
          &quot;title&quot;: &quot;Elasticsearch in Action&quot;,
          &quot;publish_date&quot;: &quot;2015-12-03&quot;
        }
      }
    ]
 
</code></pre>
<h3 id="19功能评分脚本评分">19.功能评分：脚本评分</h3>
<p>如果内置的评分功能无法满足您的需求，则可以选择指定Groovy脚本进行评分。在我们的示例中，我们希望指定一个脚本，该脚本在决定要考虑评论数量的因素之前，先考虑publish_date。较新的书可能没有那么多的评论，因此不应因此受到惩罚。<br>
评分脚本如下所示：</p>
<pre><code class="language-java">publish_date = doc['publish_date'].value
num_reviews = doc['num_reviews'].value

if (publish_date &gt; Date.parse('yyyy-MM-dd', threshold).getTime()) {
  my_score = Math.log(2.5 + num_reviews)
} else {
  my_score = Math.log(1 + num_reviews)
}
return my_score
 
</code></pre>
<p>要动态使用评分脚本，我们使用<code>script_score</code>参数</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;function_score&quot;: {
            &quot;query&quot;: {
                &quot;multi_match&quot; : {
                    &quot;query&quot; : &quot;search engine&quot;,
                    &quot;fields&quot;: [&quot;title&quot;, &quot;summary&quot;]
                }
            },
            &quot;functions&quot;: [
                {
                    &quot;script_score&quot;: {
                        &quot;params&quot; : {
                            &quot;threshold&quot;: &quot;2015-07-30&quot;
                        },
                        &quot;script&quot;: &quot;publish_date = doc['publish_date'].value; num_reviews = doc['num_reviews'].value; if (publish_date &gt; Date.parse('yyyy-MM-dd', threshold).getTime()) { return log(2.5 + num_reviews) }; return log(1 + num_reviews);&quot;
                    }
                }
            ]
        }
    },
    &quot;_source&quot;: [&quot;title&quot;, &quot;summary&quot;, &quot;publish_date&quot;, &quot;num_reviews&quot;]
}

[Results]
&quot;hits&quot;: {
    &quot;total&quot;: 4,
    &quot;max_score&quot;: 0.8463001,
    &quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;1&quot;,
        &quot;_score&quot;: 0.8463001,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;A distibuted real-time search and analytics engine&quot;,
          &quot;num_reviews&quot;: 20,
          &quot;title&quot;: &quot;Elasticsearch: The Definitive Guide&quot;,
          &quot;publish_date&quot;: &quot;2015-02-07&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;4&quot;,
        &quot;_score&quot;: 0.7067348,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;Comprehensive guide to implementing a scalable search engine using Apache Solr&quot;,
          &quot;num_reviews&quot;: 23,
          &quot;title&quot;: &quot;Solr in Action&quot;,
          &quot;publish_date&quot;: &quot;2014-04-05&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;3&quot;,
        &quot;_score&quot;: 0.08952084,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;build scalable search applications using Elasticsearch without having to do complex low-level programming or understand advanced data science algorithms&quot;,
          &quot;num_reviews&quot;: 18,
          &quot;title&quot;: &quot;Elasticsearch in Action&quot;,
          &quot;publish_date&quot;: &quot;2015-12-03&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;2&quot;,
        &quot;_score&quot;: 0.07602123,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;organize text using approaches such as full-text search, proper name recognition, clustering, tagging, information extraction, and summarization&quot;,
          &quot;num_reviews&quot;: 12,
          &quot;title&quot;: &quot;Taming Text: How to Find, Organize, and Manipulate It&quot;,
          &quot;publish_date&quot;: &quot;2013-01-24&quot;
        }
      }
    ]
  }
 
</code></pre>
<p>**注意1：**要使用动态脚本，必须为<code>config/elasticsearch.yaml</code>文件中的Elasticsearch实例启用动态脚本。也可以使用存储在Elasticsearch服务器上的脚本。查阅<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-scripting.html">Elasticsearch参考文档</a>了解更多信息。</p>
<p><strong>注意2：</strong> JSON无法包含嵌入的换行符，因此分号用于分隔语句。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[docker安装ELK]]></title>
        <id>https://tinaxiawuhao.github.io/post/3D5Sr6L0c/</id>
        <link href="https://tinaxiawuhao.github.io/post/3D5Sr6L0c/">
        </link>
        <updated>2021-05-27T07:39:14.000Z</updated>
        <content type="html"><![CDATA[<h2 id="docker部署elasticsearch">Docker部署ElasticSearch</h2>
<h3 id="搜索elasticsearch镜像">搜索ElasticSearch镜像</h3>
<pre><code class="language-java">docker search elasticsearch
</code></pre>
<h3 id="拉取镜像">拉取镜像</h3>
<p>拉取镜像的时候，可以指定版本，如果不指定，默认使用latest。</p>
<pre><code class="language-java">docker pull elasticsearch:7.12.0
</code></pre>
<h3 id="查看镜像">查看镜像</h3>
<pre><code class="language-java">docker images
</code></pre>
<h3 id="docker-启动-elasticsearch">docker 启动 elasticsearch</h3>
<pre><code class="language-java"># --name : 为 elasticsearch 容器起个别名
# -e : 指定为单节点集群模式
# -i：表示运行容器
# -t：表示容器启动后会进入其命令行。加入这两个参数后，容器创建就能登录进去。即分配一个伪终端。
# -v：表示目录映射关系（前者是宿主机目录，后者是映射到宿主机上的目录），可以使用多个－v做多个目录或文件映射。注意：最好做目录映射，在宿主机上做修改，然后共享到容器上。
# -d：在run后面加上-d参数,则会创建一个守护式容器在后台运行（这样创建容器后不会自动登录容器，如果只加-i -t两个参数，创建后就会自动进去容器）。
# -p：表示端口映射，前者是宿主机端口，后者是容器内的映射端口。可以使用多个-p做多个端口映射
docker run -di --name elasticsearch -p 9200:9200 -p 9300:9300 -e &quot;discovery.type=single-node&quot; elasticsearch:7.12.0 
</code></pre>
<h3 id="elasticsearch配置">elasticsearch配置</h3>
<h4 id="创建elasticsearch滚动策略">创建elasticsearch滚动策略</h4>
<pre><code class="language-json"># 定义审计日志管理策略
curl -X PUT &quot;${host}/_ilm/policy/audit_policy&quot; -H 'Content-Type: application/json' -d'
{
  &quot;policy&quot;: {                       
    &quot;phases&quot;: {
      &quot;hot&quot;: {                      
        &quot;actions&quot;: {
          &quot;rollover&quot;: {             
            &quot;max_size&quot;: &quot;30GB&quot;,
            &quot;max_age&quot;: &quot;180d&quot;
          }
        }
      },
      &quot;delete&quot;: {
        &quot;min_age&quot;: &quot;180d&quot;,           
        &quot;actions&quot;: {
          &quot;delete&quot;: {}              
        }
      }
    }
  }
}
</code></pre>
<p>热数据最大30G,最多180天，数据最少保持180天后删除</p>
<h4 id="创建索引模板">创建索引模板</h4>
<pre><code class="language-json"># 导出日志索引模板
curl -X PUT &quot;${host}/_template/export_log_index_template&quot; -H 'Content-Type: application/json' -d'
{
  &quot;index_patterns&quot;: [
    &quot;export_log_index*&quot;
  ],
  &quot;settings&quot;: {
    &quot;number_of_shards&quot;: 1,
    &quot;number_of_replicas&quot;: 1,
    &quot;index.lifecycle.name&quot;: &quot;audit_policy&quot;,
    &quot;index.lifecycle.rollover_alias&quot;: &quot;export_log_index&quot;,
    &quot;index.max_result_window&quot;: &quot;100000&quot;
  },
  &quot;mappings&quot;: {
    &quot;properties&quot;: {
      &quot;applicationSide&quot;: {
        &quot;type&quot;: &quot;integer&quot;
      },
      &quot;exportComment&quot;: {
        &quot;type&quot;: &quot;keyword&quot;
      },
      &quot;exportFileSize&quot;: {
        &quot;type&quot;: &quot;integer&quot;
      },
      &quot;exportType&quot;: {
        &quot;type&quot;: &quot;integer&quot;
      },
      &quot;id&quot;: {
        &quot;type&quot;: &quot;keyword&quot;
      },
      &quot;operationTime&quot;: {
        &quot;type&quot;: &quot;date&quot;,
        &quot;store&quot;: true,
        &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss&quot;
      },
      &quot;operationUser&quot;: {
        &quot;type&quot;: &quot;keyword&quot;
      },
      &quot;operationUserName&quot;: {
        &quot;type&quot;: &quot;text&quot;,
        &quot;analyzer&quot;: &quot;ik_max_word&quot;,
        &quot;fields&quot;: {
          &quot;keyword&quot;: {
            &quot;type&quot;: &quot;keyword&quot;
          }
        }
      },
      &quot;remarks&quot;: {
        &quot;type&quot;: &quot;keyword&quot;
      },
      &quot;successful&quot;: {
        &quot;type&quot;: &quot;boolean&quot;
      }
    }
  }
}
</code></pre>
<h4 id="创建索引">创建索引</h4>
<pre><code class="language-json"># 创建导出日志索引，按日期命名
curl -X PUT &quot;${host}/%3Cexport_log_index-%7Bnow%2Fd%7D-1%3E&quot; -H 'Content-Type: application/json' -d'
{
  &quot;aliases&quot;: {
    &quot;export_log_index&quot;: {
      &quot;is_write_index&quot;: true
    }
  }
}
</code></pre>
<h2 id="docker-安装-kibana">docker 安装 kibana</h2>
<h3 id="拉取镜像-2">拉取镜像</h3>
<p>拉取镜像的时候，需要注意的是, <strong>kibana 的版本最好与 elasticsearch 保持一致</strong>, 避免发生不必要的错误</p>
<pre><code class="language-java">docker pull kibana:7.12.0
</code></pre>
<h3 id="查看镜像-2">查看镜像</h3>
<pre><code class="language-java">docker images
</code></pre>
<h3 id="docker-启动-kibana">docker 启动 kibana</h3>
<pre><code class="language-java"># -e : 指定环境变量配置, 提供汉化
# --like : 建立两个容器之间的关联, kibana 关联到 es
docker run -di --name kibana --link elasticsearch:elasticsearch -e &quot;I18N_LOCALE=zh-CN&quot; -p 5601:5601 kibana:7.12.0
# kibana 的汉化我感觉做的并不好
# 如果不习惯汉化, 可以把条件去除
docker run -di --name kibana --link elasticsearch:elasticsearch -p 5601:5601 kibana:7.12.0
</code></pre>
<h2 id="docker-安装-logstash">Docker 安装 Logstash</h2>
<h3 id="拉取镜像-3">拉取镜像</h3>
<p>拉取镜像的时候，需要注意的是, <strong>Logstash 的版本最好与 elasticsearch 保持一致</strong>, 避免发生不必要的错误</p>
<pre><code class="language-java">docker pull logstash:7.12.0
</code></pre>
<h3 id="查看镜像-3">查看镜像</h3>
<pre><code class="language-java">docker images
</code></pre>
<h3 id="文件映射">文件映射</h3>
<p>在本机建立配置文件和目录,用来存放所有配置的映射</p>
<pre><code class="language-java">/usr/local/logstash/config/logstash.yml
/usr/local/logstash/conf.d/
</code></pre>
<p>logstash.yml (文件内容)</p>
<pre><code class="language-java">path.config: /usr/share/logstash/conf.d/*.conf
path.logs: /var/log/logstash
</code></pre>
<p>conf.d/configuration.conf (文件内容)</p>
<p><strong>Filebeat和elasticsearch的交互</strong></p>
<pre><code class="language-json">input {
    beats {
    port =&gt; 5044
    codec =&gt; &quot;json&quot;
}
}

output {
  elasticsearch { 
    hosts =&gt; [&quot;elasticsearch:9200&quot;]，
	index =&gt; &quot;export_log_index&quot;
  }
  stdout { codec =&gt; rubydebug }
}
</code></pre>
<p><strong>mysql和elasticsearch的交互</strong></p>
<pre><code class="language-json">input {
  jdbc {
    jdbc_driver_class =&gt; &quot;com.mysql.jdbc.Driver&quot;
    jdbc_connection_string =&gt; &quot;jdbc:mysql://localhost:3306/db_example&quot;
    jdbc_user =&gt; root
    jdbc_password =&gt; ymruan123
    #启用追踪，如果为true，则需要指定tracking_column
    use_column_value =&gt; true
    #指定追踪的字段，
    tracking_column =&gt; &quot;last_updated&quot;
    #追踪字段的类型，目前只有数字(numeric)和时间类型(timestamp)，默认是数字类型
    tracking_column_type =&gt; &quot;numeric&quot;
    #记录最后一次运行的结果
    record_last_run =&gt; true
    #上面运行结果的保存位置
    last_run_metadata_path =&gt; &quot;jdbc-position.txt&quot;
    statement =&gt; &quot;SELECT * FROM user where last_updated &gt;:sql_last_value;&quot;
    schedule =&gt; &quot; * * * * * *&quot;
  }
}
output {
  elasticsearch {
    document_id =&gt; &quot;%{id}&quot;
    document_type =&gt; &quot;_doc&quot;
    index =&gt; &quot;export_log_index&quot;
    hosts =&gt; [&quot;http://localhost:9200&quot;]
  }
  stdout{
    codec =&gt; rubydebug
  }
}
</code></pre>
<p><strong>kafka和elasticsearch的交互</strong></p>
<pre><code class="language-json">input {
 kafka{
    topics =&gt; &quot;topic_export&quot;    #kafka中topic名称，记得创建该topic
    group_id =&gt; &quot;group_export&quot;     #默认为“logstash”
    codec =&gt; &quot;json&quot;    #与Shipper端output配置项一致
    consumer_threads =&gt; 1    #消费线程数，集群中所有logstash相加最好等于 topic 分区数
    bootstrap_servers =&gt; &quot;kafka:9092&quot;
    decorate_events =&gt; true    #在输出消息的时候回输出自身的信息，包括：消费消息的大小、topic来源以及consumer的group信息。
    type =&gt; &quot;topic_export&quot;  
    tags =&gt; [&quot;canal&quot;] # 标签，额外使用该参数可以在elastci中创建不同索引
  }
  
}
 
 
filter {
  # 把默认的data字段重命名为message字段，方便在elastic中显示
  mutate {
    rename =&gt; [&quot;data&quot;, &quot;message&quot;]
  }
  # 还可以使用其他的处理方式，在此就不再列出来了
}
 
output {
  elasticsearch {
    hosts =&gt; [&quot;http://172.17.107.187:9203&quot;, &quot;http://172.17.107.187:9201&quot;,&quot;http://172.17.107.187:9202&quot;]
    index =&gt; &quot;export_log_index&quot; # decorate_events=true的作用，可以使用metadata中的数据
    #user =&gt; &quot;elastic&quot;
    #password =&gt; &quot;escluter123456&quot;
  }
 }
</code></pre>
<p><strong>logback和和elasticsearch的交互</strong></p>
<p>引入依赖</p>
<pre><code class="language-xml">&lt;dependency&gt;
      &lt;groupId&gt;net.logstash.logback&lt;/groupId&gt;
      &lt;artifactId&gt;logstash-logback-encoder&lt;/artifactId&gt;
     &lt;version&gt;4.10&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<p>参数配置</p>
<pre><code class="language-json">input {
  # 应用日志
  tcp{
    type =&gt; &quot;app&quot;
    mode =&gt; &quot;server&quot;
    host =&gt; &quot;0.0.0.0&quot;
    port =&gt; 4560
    codec =&gt; json
  }
}

output {
   elasticsearch {
      hosts =&gt; &quot;http://127.0.0.1:9200&quot;
      index =&gt; &quot;export_log_index&quot;
    }
}

</code></pre>
<p>应用日志入口端口为4560，需要配置java客户端logstash入口</p>
<pre><code class="language-xml">&lt;!-- 这个是控制台日志输出格式 方便调试对比--&gt;
&lt;appender name=&quot;console&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;
    &lt;encoder&gt;
        &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss} %contextName %-5level %logger{50} -%msg%n&lt;/pattern&gt;
    &lt;/encoder&gt;
&lt;/appender&gt;
&lt;!--开启tcp格式的logstash传输，通过TCP协议连接Logstash--&gt;
&lt;appender name=&quot;STASH&quot; class=&quot;net.logstash.logback.appender.LogstashTcpSocketAppender&quot;&gt;
    &lt;destination&gt;127.0.0.1:9600&lt;/destination&gt;

    &lt;encoder class=&quot;net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder&quot;&gt;
        &lt;!--中文序列化--&gt;
        &lt;jsonFactoryDecorator class=&quot;net.logstash.logback.decorate.CharacterEscapesJsonFactoryDecorator&quot;&gt;
            &lt;escape&gt;
                &lt;targetCharacterCode&gt;10&lt;/targetCharacterCode&gt;
                &lt;escapeSequence&gt;\u2028&lt;/escapeSequence&gt;
            &lt;/escape&gt;
        &lt;/jsonFactoryDecorator&gt;
        &lt;providers&gt;
            &lt;pattern&gt;
                &lt;pattern&gt;
                    &lt;!--{
                    &quot;timestamp&quot;:&quot;%date{ISO8601}&quot;,
                    &quot;user&quot;:&quot;test&quot;,
                    &quot;message&quot;:&quot;[%d{yyyy-MM-dd HH:mm:ss.SSS}][%p][%t][%l{80}|%L]%m&quot;}%n
                    }--&gt;
                    {
                    &quot;timestamp&quot;: &quot;%date{\&quot;yyyy-MM-dd' 'HH:mm:ss,SSSZ\&quot;}&quot;,
                    &quot;level&quot;: &quot;%level&quot;,
                    &quot;thread&quot;: &quot;%thread&quot;,
                    &quot;class_name&quot;: &quot;%class&quot;,
                    &quot;line_number&quot;: &quot;%line&quot;,
                    &quot;message&quot;: &quot;%message&quot;,
                    &quot;stack_trace&quot;: &quot;%exception{5}&quot;,
                    &quot;req_id&quot;: &quot;%X{reqId}&quot;,
                    &quot;elapsed_time&quot;: &quot;#asLong{%X{elapsedTime}}&quot;
                    }
                &lt;/pattern&gt;
            &lt;/pattern&gt;
        &lt;/providers&gt;
        &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt;


    &lt;/encoder&gt;
    &lt;keepAliveDuration&gt;5 minutes&lt;/keepAliveDuration&gt;
&lt;/appender&gt;

&lt;root level=&quot;INFO&quot;&gt;
    &lt;appender-ref ref=&quot;STASH&quot;/&gt;
    &lt;appender-ref ref=&quot;console&quot;/&gt;
&lt;/root&gt;
</code></pre>
<h3 id="docker-启动-logstash">docker 启动 Logstash</h3>
<pre><code class="language-java">#docker容器互访 运行容器的时候加上参数link
docker run -id -p 5044:5044 --name logstash --link elasticsearch --link beats -v /usr/local/logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml -v /usr/local/logstash/conf.d/:/usr/share/logstash/conf.d/ logstash:7.4.1
</code></pre>
<h2 id="docker-安装-filebeat">Docker 安装 Filebeat</h2>
<h3 id="拉取镜像-4">拉取镜像</h3>
<p>拉取镜像的时候，需要注意的是, <strong>Filebeat 的版本最好与 elasticsearch 保持一致</strong>, 避免发生不必要的错误</p>
<pre><code class="language-java">docker pull store/elastic/filebeat:7.12.0
</code></pre>
<h3 id="查看镜像-4">查看镜像</h3>
<pre><code class="language-java">docker images
</code></pre>
<h3 id="文件映射-2">文件映射</h3>
<p><strong>下载默认官方配置文件</strong></p>
<pre><code class="language-http">wget https://raw.githubusercontent.com/elastic/beats/7.12/deploy/docker/filebeat.docker.yml
</code></pre>
<p>注意：文件放在宿主机/data/elk/filebeat目录下</p>
<p><strong>打开配置文件</strong><br>
<code>vim filebeat.docker.yml</code>，内容如下：</p>
<pre><code class="language-xml"># 日志输入配置
filebeat.inputs:
- type: log
  enabled: true
  paths:
  # 需要收集的日志所在的位置，可使用通配符进行配置
  #- /data/elk/*.log
  - /logs/*/*.log

#日志输出配置(采用 logstash 收集日志，5044为logstash端口)
output.logstash:
  hosts: ['192.168.12.183:5044']
</code></pre>
<h3 id="docker运行filebeat">docker运行Filebeat</h3>
<pre><code class="language-java">docker run --name filebeat --user=root -d --net somenetwork --volume=&quot;/usr/local/filebeat/log/nginx/:/var/log/nginx/&quot; --volume=&quot;/data/elk/filebeat/filebeat.docker.yml:/usr/share/filebeat/filebeat.yml&quot; --volume=&quot;/var/lib/docker/containers:/var/lib/docker/containers:ro&quot; --volume=&quot;/var/run/docker.sock:/var/run/docker.sock:ro&quot; store/elastic/filebeat:7.12.0
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[springBoot,mybatis,druid整合]]></title>
        <id>https://tinaxiawuhao.github.io/post/Ari4Sf8A0/</id>
        <link href="https://tinaxiawuhao.github.io/post/Ari4Sf8A0/">
        </link>
        <updated>2021-05-26T09:02:37.000Z</updated>
        <content type="html"><![CDATA[<h2 id="springbootmybatisdruid单数据源整合">springBoot,mybatis,druid单数据源整合</h2>
<h3 id="项目框架">项目框架</h3>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1621415131656.png" alt="" loading="lazy"></figure>
<h4 id="pomxml">pom.xml</h4>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;
    &lt;parent&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
        &lt;version&gt;2.4.5&lt;/version&gt;
        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;
    &lt;/parent&gt;
    &lt;groupId&gt;com.example&lt;/groupId&gt;
    &lt;artifactId&gt;datasources&lt;/artifactId&gt;
    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;
    &lt;name&gt;datasources&lt;/name&gt;
    &lt;description&gt;Demo project for Spring Boot&lt;/description&gt;
    &lt;properties&gt;
        &lt;java.version&gt;1.8&lt;/java.version&gt;
    &lt;/properties&gt;
    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
            &lt;optional&gt;true&lt;/optional&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;mysql&lt;/groupId&gt;
            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
            &lt;version&gt;5.1.45&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.alibaba&lt;/groupId&gt;
            &lt;artifactId&gt;druid&lt;/artifactId&gt;
            &lt;version&gt;1.1.10&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.baomidou&lt;/groupId&gt;
            &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt;
            &lt;version&gt;3.2.0&lt;/version&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

    &lt;build&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
                &lt;configuration&gt;
                    &lt;excludes&gt;
                        &lt;exclude&gt;
                            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
                            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
                        &lt;/exclude&gt;
                    &lt;/excludes&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;

&lt;/project&gt;
</code></pre>
<h4 id="applicationyml">application.yml</h4>
<pre><code class="language-yaml">spring:
  datasource:
    username: root
    password: 123456
    url: jdbc:mysql://localhost:3306/datatest?characterEncoding=utf-8&amp;useSSl=false
    driver-class-name: com.mysql.jdbc.Driver
    type: com.alibaba.druid.pool.DruidDataSource
    druid:
      initialSize: 10 # 初始化时建立物理连接的个数。初始化发生在显示调用init方法，或者第一次getConnection时
      minIdle: 10 # 最小连接池数量
      maxActive: 200 # 最大连接池数量
      maxWait: 60000 # 获取连接时最大等待时间，单位毫秒。配置了maxWait之后，缺省启用公平锁，并发效率会有所下降，如果需要可以通过配置
      timeBetweenEvictionRunsMillis: 60000 # 关闭空闲连接的检测时间间隔.Destroy线程会检测连接的间隔时间，如果连接空闲时间大于等于minEvictableIdleTimeMillis则关闭物理连接。
      minEvictableIdleTimeMillis: 300000 # 连接的最小生存时间.连接保持空闲而不被驱逐的最小时间
      validationQuery: SELECT 1 FROM DUAL # 验证数据库服务可用性的sql.用来检测连接是否有效的sql 因数据库方言而差, 例如 oracle 应该写成 SELECT 1 FROM DUAL
      testWhileIdle: true # 申请连接时检测空闲时间，根据空闲时间再检测连接是否有效.建议配置为true，不影响性能，并且保证安全性。申请连接的时候检测，如果空闲时间大于timeBetweenEvictionRun
      testOnBorrow: false # 申请连接时直接检测连接是否有效.申请连接时执行validationQuery检测连接是否有效，做了这个配置会降低性能。
      testOnReturn: false # 归还连接时检测连接是否有效.归还连接时执行validationQuery检测连接是否有效，做了这个配置会降低性能。
      poolPreparedStatements: true # 开启PSCache
      maxPoolPreparedStatementPerConnectionSize: 20 #设置PSCache值
      connectionErrorRetryAttempts: 3 # 连接出错后再尝试连接三次
      breakAfterAcquireFailure: true # 数据库服务宕机自动重连机制
      timeBetweenConnectErrorMillis: 300000 # 连接出错后重试时间间隔
      asyncInit: true # 异步初始化策略
      remove-abandoned: true # 是否自动回收超时连接
      remove-abandoned-timeout: 1800 # 超时时间(以秒数为单位)
      transaction-query-timeout: 6000 # 事务超时时间
      filters: stat,wall,log4j2
      connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=500


#mybatis是独立节点，需要单独配置
mybatis-plus:
  mapper-locations: classpath*:mapper/*.xml
  type-aliases-package: com.example.datasources.entity
  configuration:
    map-underscore-to-camel-case: true
</code></pre>
<h4 id="druidconfig">DruidConfig</h4>
<pre><code class="language-java">@Configuration
public class DruidConfig {

    @Bean
    public ServletRegistrationBean statViewServlet(){
        ServletRegistrationBean&lt;StatViewServlet&gt; bean = new ServletRegistrationBean&lt;StatViewServlet&gt;( new StatViewServlet(), &quot;/druid/*&quot; );

        Map&lt;String,String&gt; iniParms=new HashMap&lt;&gt;(  );

        iniParms.put( &quot;loginUsername&quot;,&quot;admin&quot; );//登录druid的用户名
        iniParms.put( &quot;loginPassword&quot;,&quot;123456&quot; );//登录druid的密码
        iniParms.put(&quot;allow&quot;,&quot;&quot;);//默认允许所有
        //iniParms.put( &quot;deny&quot;,&quot;192.168.***.***&quot; );//拒绝的ip地址
        bean.setInitParameters( iniParms );
        return bean;

    }

    @Bean
    public FilterRegistrationBean webStatFilter(){
        FilterRegistrationBean bean= new FilterRegistrationBean();
        bean.setFilter(new WebStatFilter());
        Map&lt;String,String&gt; iniParms=new HashMap&lt;&gt;();
        iniParms.put( &quot;excliusions&quot;, &quot;*.js,*.gif,*.jpg,*.bmp,*.png,*.css,*.ico,/druid/*&quot;);//使静态文件访问，还有/druid/* 的访问不被拦截
        bean.setInitParameters( iniParms );
        bean.setUrlPatterns( Arrays.asList(&quot;/*&quot;));
        return bean;
    }

}
</code></pre>
<h4 id="访问druid">访问Druid</h4>
<p><a href="http://localhost:8080/druid/login.html">http://localhost:8080/druid/login.html</a></p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1621415196405.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1621415233878.png" alt="" loading="lazy"></figure>
<h2 id="springbootmybatisdruid多数据源整合">springBoot,mybatis,druid多数据源整合</h2>
<h3 id="项目架构">项目架构</h3>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1621415260516.png" alt="" loading="lazy"></figure>
<h4 id="pomxml-2">pom.xml</h4>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;
    &lt;parent&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
        &lt;version&gt;2.4.5&lt;/version&gt;
        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;
    &lt;/parent&gt;
    &lt;groupId&gt;com.example&lt;/groupId&gt;
    &lt;artifactId&gt;datasources&lt;/artifactId&gt;
    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;
    &lt;name&gt;datasources&lt;/name&gt;
    &lt;description&gt;Demo project for Spring Boot&lt;/description&gt;
    &lt;properties&gt;
        &lt;java.version&gt;1.8&lt;/java.version&gt;
    &lt;/properties&gt;
    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
            &lt;optional&gt;true&lt;/optional&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;mysql&lt;/groupId&gt;
            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
            &lt;version&gt;5.1.45&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.alibaba&lt;/groupId&gt;
            &lt;artifactId&gt;druid&lt;/artifactId&gt;
            &lt;version&gt;1.1.10&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt;
            &lt;optional&gt;true&lt;/optional&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.baomidou&lt;/groupId&gt;
            &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt;
            &lt;version&gt;3.2.0&lt;/version&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

    &lt;build&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
                &lt;configuration&gt;
                    &lt;excludes&gt;
                        &lt;exclude&gt;
                            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
                            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
                        &lt;/exclude&gt;
                    &lt;/excludes&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;

&lt;/project&gt;
</code></pre>
<h4 id="applicationyml-2">application.yml</h4>
<pre><code class="language-yaml">spring:
  datasource:
    #使用druid连接池
    type: com.alibaba.druid.pool.DruidDataSource

# 自定义的主数据源配置信息
primary:
  datasource:
    #druid相关配置
    druid:
      #监控统计拦截的filters
      filters: stat
      driverClassName: com.mysql.jdbc.Driver
      #配置基本属性
      url: jdbc:mysql://127.0.0.1:3306/primary_database?useUnicode=true&amp;characterEncoding=UTF-8&amp;allowMultiQueries=true&amp;autoReconnect=true&amp;useSSL=false
      username: root
      password: 123456
      #配置初始化大小/最小/最大
      initialSize: 1
      minIdle: 1
      maxActive: 20
      #获取连接等待超时时间
      maxWait: 60000
      #间隔多久进行一次检测，检测需要关闭的空闲连接
      timeBetweenEvictionRunsMillis: 60000
      #一个连接在池中最小生存的时间
      minEvictableIdleTimeMillis: 300000
      validationQuery: SELECT 'x'
      testWhileIdle: true
      testOnBorrow: false
      testOnReturn: false
      #打开PSCache，并指定每个连接上PSCache的大小。oracle设为true，mysql设为false。分库分表较多推荐设置为false
      poolPreparedStatements: false
      maxPoolPreparedStatementPerConnectionSize: 20

# 自定义的从数据源配置信息
back:
  datasource:
    #druid相关配置
    druid:
      #监控统计拦截的filters
      filters: stat
      driverClassName: com.mysql.jdbc.Driver
      #配置基本属性
      url: jdbc:mysql://127.0.0.1:3306/back_database?useUnicode=true&amp;characterEncoding=UTF-8&amp;allowMultiQueries=true&amp;autoReconnect=true&amp;useSSL=false
      username: root
      password: 123456
      #配置初始化大小/最小/最大
      initialSize: 1
      minIdle: 1
      maxActive: 20
      #获取连接等待超时时间
      maxWait: 60000
      #间隔多久进行一次检测，检测需要关闭的空闲连接
      timeBetweenEvictionRunsMillis: 60000
      #一个连接在池中最小生存的时间
      minEvictableIdleTimeMillis: 300000
      validationQuery: SELECT 'x'
      testWhileIdle: true
      testOnBorrow: false
      testOnReturn: false
      #打开PSCache，并指定每个连接上PSCache的大小。oracle设为true，mysql设为false。分库分表较多推荐设置为false
      poolPreparedStatements: false
      maxPoolPreparedStatementPerConnectionSize: 20
</code></pre>
<h4 id="druidconfig-2">DruidConfig</h4>
<pre><code class="language-java">@Configuration
public class DruidConfig {

    @Bean
    public ServletRegistrationBean statViewServlet(){
        ServletRegistrationBean&lt;StatViewServlet&gt; bean = new ServletRegistrationBean&lt;StatViewServlet&gt;( new StatViewServlet(), &quot;/druid/*&quot; );

        Map&lt;String,String&gt; iniParms=new HashMap&lt;&gt;(  );

        iniParms.put( &quot;loginUsername&quot;,&quot;admin&quot; );//登录druid的用户名
        iniParms.put( &quot;loginPassword&quot;,&quot;123456&quot; );//登录druid的密码
        iniParms.put(&quot;allow&quot;,&quot;&quot;);//默认允许所有
        //iniParms.put( &quot;deny&quot;,&quot;192.168.***.***&quot; );//拒绝的ip地址
        bean.setInitParameters( iniParms );
        return bean;

    }

    @Bean
    public FilterRegistrationBean webStatFilter(){
        FilterRegistrationBean bean= new FilterRegistrationBean();
        bean.setFilter(new WebStatFilter());
        Map&lt;String,String&gt; iniParms=new HashMap&lt;&gt;();
        iniParms.put( &quot;excliusions&quot;, &quot;*.js,*.gif,*.jpg,*.bmp,*.png,*.css,*.ico,/druid/*&quot;);//使静态文件访问，还有/druid/* 的访问不被拦截
        bean.setInitParameters( iniParms );
        bean.setUrlPatterns( Arrays.asList(&quot;/*&quot;));
        return bean;
    }

}
</code></pre>
<h4 id="primarydatabaseconfig">PrimaryDataBaseConfig</h4>
<pre><code class="language-java">/**
 * @Description: 主数据源配置类
 */
@Data
@Configuration
// 前缀为primary.datasource.druid的配置信息
@ConfigurationProperties(prefix = &quot;primary.datasource.druid&quot;)
@MapperScan(basePackages = PrimaryDataBaseConfig.PACKAGE, sqlSessionFactoryRef = &quot;primarySqlSessionFactory&quot;)
public class PrimaryDataBaseConfig {
 
    /**
     * dao层的包路径
     */
    static final String PACKAGE = &quot;com.example.datasources.dao.primary&quot;;
 
    /**
     * mapper文件的相对路径
     */
    private static final String MAPPER_LOCATION = &quot;classpath:mapper/primary/*.xml&quot;;
 
    private String filters;
    private String url;
    private String username;
    private String password;
    private String driverClassName;
    private int initialSize;
    private int minIdle;
    private int maxActive;
    private long maxWait;
    private long timeBetweenEvictionRunsMillis;
    private long minEvictableIdleTimeMillis;
    private String validationQuery;
    private boolean testWhileIdle;
    private boolean testOnBorrow;
    private boolean testOnReturn;
    private boolean poolPreparedStatements;
    private int maxPoolPreparedStatementPerConnectionSize;
 
    // 主数据源使用@Primary注解进行标识
    @Primary
    @Bean(name = &quot;primaryDataSource&quot;)
    public DataSource primaryDataSource() throws SQLException {
        DruidDataSource druid = new DruidDataSource();
        // 监控统计拦截的filters
        druid.setFilters(filters);
 
        // 配置基本属性
        druid.setDriverClassName(driverClassName);
        druid.setUsername(username);
        druid.setPassword(password);
        druid.setUrl(url);
 
        //初始化时建立物理连接的个数
        druid.setInitialSize(initialSize);
        //最大连接池数量
        druid.setMaxActive(maxActive);
        //最小连接池数量
        druid.setMinIdle(minIdle);
        //获取连接时最大等待时间，单位毫秒。
        druid.setMaxWait(maxWait);
        //间隔多久进行一次检测，检测需要关闭的空闲连接
        druid.setTimeBetweenEvictionRunsMillis(timeBetweenEvictionRunsMillis);
        //一个连接在池中最小生存的时间
        druid.setMinEvictableIdleTimeMillis(minEvictableIdleTimeMillis);
        //用来检测连接是否有效的sql
        druid.setValidationQuery(validationQuery);
        //建议配置为true，不影响性能，并且保证安全性。
        druid.setTestWhileIdle(testWhileIdle);
        //申请连接时执行validationQuery检测连接是否有效
        druid.setTestOnBorrow(testOnBorrow);
        druid.setTestOnReturn(testOnReturn);
        //是否缓存preparedStatement，也就是PSCache，oracle设为true，mysql设为false。分库分表较多推荐设置为false
        druid.setPoolPreparedStatements(poolPreparedStatements);
        // 打开PSCache时，指定每个连接上PSCache的大小
        druid.setMaxPoolPreparedStatementPerConnectionSize(maxPoolPreparedStatementPerConnectionSize);
 
        return druid;
    }
 
    // 创建该数据源的事务管理
    @Primary
    @Bean(name = &quot;primaryTransactionManager&quot;)
    public DataSourceTransactionManager primaryTransactionManager() throws SQLException {
        return new DataSourceTransactionManager(primaryDataSource());
    }
 
    // 创建Mybatis的连接会话工厂实例
    @Primary
    @Bean(name = &quot;primarySqlSessionFactory&quot;)
    public SqlSessionFactory primarySqlSessionFactory(@Qualifier(&quot;primaryDataSource&quot;) DataSource primaryDataSource) throws Exception {
        final SqlSessionFactoryBean sessionFactory = new SqlSessionFactoryBean();
        sessionFactory.setDataSource(primaryDataSource);  // 设置数据源bean
        sessionFactory.setMapperLocations(new PathMatchingResourcePatternResolver()
                .getResources(PrimaryDataBaseConfig.MAPPER_LOCATION));  // 设置mapper文件路径
 
        return sessionFactory.getObject();
    }
}
</code></pre>
<h4 id="backdatabaseconfig">BackDataBaseConfig</h4>
<pre><code class="language-java">/**
 * @Description: 从数据源配置类
 */
@Data
@Configuration
@ConfigurationProperties(prefix = &quot;back.datasource.druid&quot;)
@MapperScan(basePackages = BackDataBaseConfig.PACKAGE, sqlSessionFactoryRef = &quot;backSqlSessionFactory&quot;)
public class BackDataBaseConfig {
 
    /**
     * dao层的包路径
     */
    static final String PACKAGE = &quot;com.example.datasources.dao.back&quot;;
 
    /**
     * mapper文件的相对路径
     */
    private static final String MAPPER_LOCATION = &quot;classpath:mapper/back/*.xml&quot;;
 
    private String filters;
    private String url;
    private String username;
    private String password;
    private String driverClassName;
    private int initialSize;
    private int minIdle;
    private int maxActive;
    private long maxWait;
    private long timeBetweenEvictionRunsMillis;
    private long minEvictableIdleTimeMillis;
    private String validationQuery;
    private boolean testWhileIdle;
    private boolean testOnBorrow;
    private boolean testOnReturn;
    private boolean poolPreparedStatements;
    private int maxPoolPreparedStatementPerConnectionSize;
 
    @Bean(name = &quot;backDataSource&quot;)
    public DataSource backDataSource() throws SQLException {
        DruidDataSource druid = new DruidDataSource();
        // 监控统计拦截的filters
        druid.setFilters(filters);
 
        // 配置基本属性
        druid.setDriverClassName(driverClassName);
        druid.setUsername(username);
        druid.setPassword(password);
        druid.setUrl(url);
 
        //初始化时建立物理连接的个数
        druid.setInitialSize(initialSize);
        //最大连接池数量
        druid.setMaxActive(maxActive);
        //最小连接池数量
        druid.setMinIdle(minIdle);
        //获取连接时最大等待时间，单位毫秒。
        druid.setMaxWait(maxWait);
        //间隔多久进行一次检测，检测需要关闭的空闲连接
        druid.setTimeBetweenEvictionRunsMillis(timeBetweenEvictionRunsMillis);
        //一个连接在池中最小生存的时间
        druid.setMinEvictableIdleTimeMillis(minEvictableIdleTimeMillis);
        //用来检测连接是否有效的sql
        druid.setValidationQuery(validationQuery);
        //建议配置为true，不影响性能，并且保证安全性。
        druid.setTestWhileIdle(testWhileIdle);
        //申请连接时执行validationQuery检测连接是否有效
        druid.setTestOnBorrow(testOnBorrow);
        druid.setTestOnReturn(testOnReturn);
        //是否缓存preparedStatement，也就是PSCache，oracle设为true，mysql设为false。分库分表较多推荐设置为false
        druid.setPoolPreparedStatements(poolPreparedStatements);
        // 打开PSCache时，指定每个连接上PSCache的大小
        druid.setMaxPoolPreparedStatementPerConnectionSize(maxPoolPreparedStatementPerConnectionSize);
 
        return druid;
    }
 
    @Bean(name = &quot;backTransactionManager&quot;)
    public DataSourceTransactionManager backTransactionManager() throws SQLException {
        return new DataSourceTransactionManager(backDataSource());
    }
 
    @Bean(name = &quot;backSqlSessionFactory&quot;)
    public SqlSessionFactory backSqlSessionFactory(@Qualifier(&quot;backDataSource&quot;) DataSource backDataSource) throws Exception {
        final SqlSessionFactoryBean sessionFactory = new SqlSessionFactoryBean();
        sessionFactory.setDataSource(backDataSource);
        sessionFactory.setMapperLocations(new PathMatchingResourcePatternResolver()
                .getResources(BackDataBaseConfig.MAPPER_LOCATION));
 
        return sessionFactory.getObject();
    }
}
</code></pre>
<h4 id="访问druid-2">访问Druid</h4>
<p><a href="http://localhost:8080/druid/login.html">http://localhost:8080/druid/login.html</a></p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1621415300791.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1621415336496.png" alt="" loading="lazy"></figure>
<h2 id="springbootmybatisdruid主从备份">springBoot,mybatis,druid主从备份</h2>
<h3 id="项目架构-2">项目架构</h3>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1621481203900.png" alt="" loading="lazy"></figure>
<h4 id="pomxml-3">pom.xml</h4>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;
    &lt;parent&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
        &lt;version&gt;2.4.5&lt;/version&gt;
        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;
    &lt;/parent&gt;
    &lt;groupId&gt;com.example&lt;/groupId&gt;
    &lt;artifactId&gt;datasources&lt;/artifactId&gt;
    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;
    &lt;name&gt;datasources&lt;/name&gt;
    &lt;description&gt;Demo project for Spring Boot&lt;/description&gt;
    &lt;properties&gt;
        &lt;java.version&gt;1.8&lt;/java.version&gt;
    &lt;/properties&gt;
    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
            &lt;optional&gt;true&lt;/optional&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;mysql&lt;/groupId&gt;
            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
            &lt;version&gt;5.1.45&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.alibaba&lt;/groupId&gt;
            &lt;artifactId&gt;druid&lt;/artifactId&gt;
            &lt;version&gt;1.1.10&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt;
            &lt;optional&gt;true&lt;/optional&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.baomidou&lt;/groupId&gt;
            &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt;
            &lt;version&gt;3.2.0&lt;/version&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

    &lt;build&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
                &lt;configuration&gt;
                    &lt;excludes&gt;
                        &lt;exclude&gt;
                            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
                            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
                        &lt;/exclude&gt;
                    &lt;/excludes&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;

&lt;/project&gt;

</code></pre>
<h4 id="applicationyml-3">application.yml</h4>
<pre><code class="language-yaml">spring:
  datasource:
    #使用druid连接池
    type: com.alibaba.druid.pool.DruidDataSource

# 自定义的主数据源配置信息
primary:
  datasource:
    #druid相关配置
    druid:
      #监控统计拦截的filters
      filters: stat
      driverClassName: com.mysql.jdbc.Driver
      #配置基本属性
      url: jdbc:mysql://127.0.0.1:3306/primary_database?useUnicode=true&amp;characterEncoding=UTF-8&amp;allowMultiQueries=true&amp;autoReconnect=true&amp;useSSL=false
      username: root
      password: 123456
      #配置初始化大小/最小/最大
      initialSize: 1
      minIdle: 1
      maxActive: 20
      #获取连接等待超时时间
      maxWait: 60000
      #间隔多久进行一次检测，检测需要关闭的空闲连接
      timeBetweenEvictionRunsMillis: 60000
      #一个连接在池中最小生存的时间
      minEvictableIdleTimeMillis: 300000
      validationQuery: SELECT 'x'
      testWhileIdle: true
      testOnBorrow: false
      testOnReturn: false
      #打开PSCache，并指定每个连接上PSCache的大小。oracle设为true，mysql设为false。分库分表较多推荐设置为false
      poolPreparedStatements: false
      maxPoolPreparedStatementPerConnectionSize: 20

# 自定义的从数据源配置信息
back:
  datasource:
    #druid相关配置
    druid:
      #监控统计拦截的filters
      filters: stat
      driverClassName: com.mysql.jdbc.Driver
      #配置基本属性
      url: jdbc:mysql://127.0.0.1:3306/back_database?useUnicode=true&amp;characterEncoding=UTF-8&amp;allowMultiQueries=true&amp;autoReconnect=true&amp;useSSL=false
      username: root
      password: 123456
      #配置初始化大小/最小/最大
      initialSize: 1
      minIdle: 1
      maxActive: 20
      #获取连接等待超时时间
      maxWait: 60000
      #间隔多久进行一次检测，检测需要关闭的空闲连接
      timeBetweenEvictionRunsMillis: 60000
      #一个连接在池中最小生存的时间
      minEvictableIdleTimeMillis: 300000
      validationQuery: SELECT 'x'
      testWhileIdle: true
      testOnBorrow: false
      testOnReturn: false
      #打开PSCache，并指定每个连接上PSCache的大小。oracle设为true，mysql设为false。分库分表较多推荐设置为false
      poolPreparedStatements: false
      maxPoolPreparedStatementPerConnectionSize: 20
</code></pre>
<h4 id="druidconfig-3">DruidConfig</h4>
<pre><code class="language-java">@Configuration
public class DruidConfig {
 
    public final static String MAPPER_XML_PATH = &quot;classpath:mapper/*.xml&quot;;
 
    @ConfigurationProperties(prefix = &quot;master.datasource.druid&quot;)
    @Bean(name = &quot;masterDataSource&quot;)
    public DataSource masterDataSource() {
        return new DruidDataSource();
    }
 
 
    @Bean
    public PlatformTransactionManager txManager(DataSource dynamicDataSource) {
        return new DataSourceTransactionManager(dynamicDataSource);
    }
 
 
    @ConfigurationProperties(prefix = &quot;slave.datasource.druid&quot;)
    @Bean
    public DataSource slaveDataSource(){
        return  new DruidDataSource();
    }
 
 
    @Bean
    public DynamicDataSource dynamicDataSource(){
        DynamicDataSource dynamicDataSource=new DynamicDataSource();
        Map&lt;Object,Object&gt; map=new HashMap&lt;&gt;();
        map.put(DbUtil.master,masterDataSource());
        map.put(DbUtil.slave,slaveDataSource());
        dynamicDataSource.setDefaultTargetDataSource(masterDataSource());
        dynamicDataSource.setTargetDataSources(map);
        return dynamicDataSource;
    }
 
    @Bean
    public SqlSessionFactoryBean sqlSessionFactoryBean(DataSource dynamicDataSource) throws IOException {
        SqlSessionFactoryBean sqlSessionFactory = new SqlSessionFactoryBean();
        sqlSessionFactory.setDataSource(dynamicDataSource);
        sqlSessionFactory.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(MAPPER_XML_PATH));
        return sqlSessionFactory;
    }
 
    @Bean
    public SqlSessionTemplate sqlSessionTemplate(SqlSessionFactoryBean sqlSessionFactoryBean) throws Exception {
        SqlSessionTemplate sqlSessionTemplate = new SqlSessionTemplate(sqlSessionFactoryBean.getObject());
        return sqlSessionTemplate;
    }

    @Bean
    public ServletRegistrationBean statViewServlet(){
        ServletRegistrationBean&lt;StatViewServlet&gt; bean = new ServletRegistrationBean&lt;StatViewServlet&gt;( new StatViewServlet(), &quot;/druid/*&quot; );

        Map&lt;String,String&gt; iniParms=new HashMap&lt;&gt;(  );

        iniParms.put( &quot;loginUsername&quot;,&quot;admin&quot; );//登录druid的用户名
        iniParms.put( &quot;loginPassword&quot;,&quot;123456&quot; );//登录druid的密码
        iniParms.put(&quot;allow&quot;,&quot;&quot;);//默认允许所有
        //iniParms.put( &quot;deny&quot;,&quot;192.168.***.***&quot; );//拒绝的ip地址
        bean.setInitParameters( iniParms );
        return bean;

    }

    @Bean
    public FilterRegistrationBean webStatFilter(){
        FilterRegistrationBean bean= new FilterRegistrationBean();
        bean.setFilter(new WebStatFilter());
        Map&lt;String,String&gt; iniParms=new HashMap&lt;&gt;();
        iniParms.put( &quot;excliusions&quot;, &quot;*.js,*.gif,*.jpg,*.bmp,*.png,*.css,*.ico,/druid/*&quot;);//使静态文件访问，还有/druid/* 的访问不被拦截
        bean.setInitParameters( iniParms );
        bean.setUrlPatterns( Arrays.asList(&quot;/*&quot;));
        return bean;
    }
}@Configuration
public class DruidConfig {

    @Bean
    public ServletRegistrationBean statViewServlet(){
        ServletRegistrationBean&lt;StatViewServlet&gt; bean = new ServletRegistrationBean&lt;StatViewServlet&gt;( new StatViewServlet(), &quot;/druid/*&quot; );

        Map&lt;String,String&gt; iniParms=new HashMap&lt;&gt;(  );

        iniParms.put( &quot;loginUsername&quot;,&quot;admin&quot; );//登录druid的用户名
        iniParms.put( &quot;loginPassword&quot;,&quot;123456&quot; );//登录druid的密码
        iniParms.put(&quot;allow&quot;,&quot;&quot;);//默认允许所有
        //iniParms.put( &quot;deny&quot;,&quot;192.168.***.***&quot; );//拒绝的ip地址
        bean.setInitParameters( iniParms );
        return bean;

    }

    @Bean
    public FilterRegistrationBean webStatFilter(){
        FilterRegistrationBean bean= new FilterRegistrationBean();
        bean.setFilter(new WebStatFilter());
        Map&lt;String,String&gt; iniParms=new HashMap&lt;&gt;();
        iniParms.put( &quot;excliusions&quot;, &quot;*.js,*.gif,*.jpg,*.bmp,*.png,*.css,*.ico,/druid/*&quot;);//使静态文件访问，还有/druid/* 的访问不被拦截
        bean.setInitParameters( iniParms );
        bean.setUrlPatterns( Arrays.asList(&quot;/*&quot;));
        return bean;
    }

}
</code></pre>
<h4 id="masterdatasource">MasterDataSource</h4>
<pre><code class="language-java">/**
 * 自定义主数据库注解
 */
@Target(ElementType.METHOD)
@Retention(RetentionPolicy.RUNTIME)
public @interface MasterDataSource {
    String value() default &quot;&quot;;
}
</code></pre>
<h4 id="databaseaop">DatabaseAOP</h4>
<pre><code class="language-java">/**
 * aop从dao层判断使用哪个数据库
 * @MasterDataSource标识使用主数据库
 * 不标识使用从数据库
 */
@Aspect
@Component
public class DatabaseAOP {
    @Pointcut(value = &quot;execution(* com.example.datasources.dao..*.*(..))&quot;)
    public void pointCut() {
 
    }
 
    @Before(&quot;pointCut()&quot;)
    public void before(JoinPoint joinPoint) {
        MethodSignature methodSignature = (MethodSignature) joinPoint.getSignature();
        Method method = methodSignature.getMethod();
        boolean isExist = method.isAnnotationPresent(MasterDataSource.class);
        if (!isExist) {
            DbUtil.setDb(DbUtil.slave);
            return;
        }
        DbUtil.setDb(DbUtil.master);
    }
}
</code></pre>
<h4 id="dbutil">DbUtil</h4>
<pre><code class="language-java">/**
 * 存储当前线程使用数据库标识
 */
public class DbUtil {
    public static String master=&quot;master&quot;;
    public static String slave=&quot;slave&quot;;
 
    private static final ThreadLocal&lt;String&gt; threadLocal=new ThreadLocal();
 
 
    public static void setDb(String db){
        threadLocal.set(db);
    }
 
    public static String getDb(){
        return threadLocal.get();
    }
 
}
</code></pre>
<h4 id="dynamicdatasource">DynamicDataSource</h4>
<pre><code class="language-java">/**
 * spring的jdbc提供了动态数据源的入口
 * 继承AbstractRoutingDataSource覆盖determineCurrentLookupKey()方法 返回当前使用数据库
 */
@Slf4j
public class DynamicDataSource extends AbstractRoutingDataSource {

    @Override
    protected Object determineCurrentLookupKey() {
        log.info(&quot;当前使用数据库：{}&quot;, DbUtil.getDb());
        return DbUtil.getDb();
    }
}
</code></pre>
<h4 id="citymapper">CityMapper</h4>
<pre><code class="language-java">/**
  * springBoot启动入口DatasourcesApplication注解@MapperScan(basePackages = &quot;com.example.datasources.dao&quot;)
  * 起到和@Mapper一样的作用
  * 添加了@Mapper注解之后这个接口在编译时会生成相应的实现类，不再需要写mapper映射文件，可以按下方@Select(&quot;select * from city where city_name like CONCAT('%', #{cityName},'%')&quot;)实现功能，@Autowired注解也需要通过@Mapper注解实现接口的动态代理实现类
  */
@Mapper
@Component
public interface CityMapper {
	/**
     * @MasterDataSource指定使用主数据库新增
     * 不指定默认使用从数据库
     */
    @MasterDataSource
    void insertCity(City city);
    /**
     * 根据城市名称，查询城市信息
     *
     * @param cityName 城市名
     * 默认使用从数据库
     */
    //@Select(&quot;select * from city where city_name like CONCAT('%', #{cityName},'%')&quot;)
    List&lt;City&gt; selectByName(@Param(&quot;cityName&quot;) String cityName);
}
</code></pre>
<h4 id="citymapperxml">CityMapper.xml</h4>
<pre><code class="language-java">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;
&lt;mapper namespace=&quot;com.example.datasources.dao.CityMapper&quot;&gt;
    &lt;resultMap id=&quot;BaseResultMap&quot; type=&quot;com.example.datasources.entity.City&quot;&gt;
        &lt;id column=&quot;id&quot; jdbcType=&quot;INTEGER&quot; property=&quot;id&quot;/&gt;
        &lt;result column=&quot;city_name&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;cityName&quot;/&gt;
    &lt;/resultMap&gt;
    &lt;sql id=&quot;Base_Column_List&quot;&gt;
        id,city_name
    &lt;/sql&gt;
    &lt;insert id=&quot;insertCity&quot; parameterType=&quot;com.example.datasources.entity.City&quot;&gt;
        INSERT into city (id,city_name) VALUES (#{id,jdbcType=INTEGER}, #{cityName,jdbcType=VARCHAR});
    &lt;/insert&gt;
    &lt;select id=&quot;selectByName&quot; resultMap=&quot;BaseResultMap&quot;&gt;
        select
        &lt;include refid=&quot;Base_Column_List&quot;/&gt;
        from city
        where city_name like CONCAT('%', #{cityName},'%')
    &lt;/select&gt;
&lt;/mapper&gt;
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[SpringBoot基础]]></title>
        <id>https://tinaxiawuhao.github.io/post/RosSxJXYD/</id>
        <link href="https://tinaxiawuhao.github.io/post/RosSxJXYD/">
        </link>
        <updated>2021-05-25T08:17:25.000Z</updated>
        <content type="html"><![CDATA[<h1 id="一-springboot简介">一、SpringBoot简介</h1>
<h2 id="11-原有spring优缺点分析">1.1  原有Spring优缺点分析</h2>
<p><strong>1.1.1 Spring的优点分析</strong></p>
<p>Spring是Java企业版（Java Enterprise Edition，JEE，也称J2EE）的轻量级代替品。无需开发重量级的Enterprise JavaBean（EJB），Spring为企业级Java开发提供了一种相对简单的方法，通过依赖注入和面向切面编程，用简单的Java对象（Plain Old Java Object，POJO）实现了EJB的功能。</p>
<p><strong>1.1.2 Spring的缺点分析</strong></p>
<p>虽然Spring的组件代码是轻量级的，但它的配置却是重量级的。一开始，Spring用XML配置，而且是很多XML配置。Spring 2.5引入了基于注解的组件扫描，这消除了大量针对应用程序自身组件的显式XML配置。Spring 3.0引入了基于Java的配置，这是一种类型安全的可重构配置方式，可以代替XML。</p>
<p>所有这些配置都代表了开发时的损耗。因为在思考Spring特性配置和解决业务问题之间需要进行思维切换，所以编写配置挤占了编写应用程序逻辑的时间。和所有框架一样，Spring实用，但与此同时它要求的回报也不少。</p>
<p>除此之外，项目的依赖管理也是一件耗时耗力的事情。在环境搭建时，需要分析要导入哪些库的坐标，而且还需要分析导入与之有依赖关系的其他库的坐标，一旦选错了依赖的版本，随之而来的不兼容问题就会严重阻碍项目的开发进度。</p>
<h2 id="12-springboot的概述">1.2 SpringBoot的概述</h2>
<p><strong>1.2.1 SpringBoot解决上述Spring的缺点</strong></p>
<p>SpringBoot对上述Spring的缺点进行的改善和优化，基于约定优于配置的思想，可以让开发人员不必在配置与逻辑业务之间进行思维的切换，全身心的投入到逻辑业务的代码编写中，从而大大提高了开发的效率，一定程度上缩短了项目周期。</p>
<p><strong>1.2.2 SpringBoot的特点</strong></p>
<ul>
<li>为基于Spring的开发提供更快的入门体验</li>
<li>开箱即用，没有代码生成，也无需XML配置。同时也可以修改默认值来满足特定的需求</li>
<li>提供了一些大型项目中常见的非功能性特性，如嵌入式服务器、安全、指标，健康检测、外部配置等</li>
<li>SpringBoot不是对Spring功能上的增强，而是提供了一种快速使用Spring的方式</li>
</ul>
<p><strong>1.2.3 SpringBoot的核心功能</strong></p>
<ul>
<li>
<p>起步依赖</p>
<p>起步依赖本质上是一个Maven项目对象模型（Project Object Model，POM），定义了对其他库的传递依赖，这些东西加在一起即支持某项功能。</p>
<p>简单的说，起步依赖就是将具备某种功能的坐标打包到一起，并提供一些默认的功能。</p>
</li>
<li>
<p>自动配置</p>
<p>Spring Boot的自动配置是一个运行时（更准确地说，是应用程序启动时）的过程，考虑了众多因素，才决定Spring配置应该用哪个，不该用哪个。该过程是Spring自动完成的。</p>
</li>
</ul>
<p>​	注意：起步依赖和自动配置的原理剖析会在第三章《SpringBoot原理分析》进行详细讲解</p>
<h1 id="二-springboot快速入门">二、SpringBoot快速入门</h1>
<h2 id="21-代码实现">2.1 代码实现</h2>
<h3 id="211-创建maven工程">2.1.1 创建Maven工程</h3>
<p>使用idea工具创建一个maven工程，该工程为普通的java工程即可</p>
<p><img src="https://tinaxiawuhao.github.io/post-images/1621326186879.png" alt="" loading="lazy"><br>
<img src="https://tinaxiawuhao.github.io/post-images/1621326245811.png" alt="" loading="lazy"><br>
<img src="https://tinaxiawuhao.github.io/post-images/1621326301646.png" alt="" loading="lazy"><br>
<img src="https://tinaxiawuhao.github.io/post-images/1621326307461.png" alt="" loading="lazy"></p>
<h3 id="212-添加springboot的起步依赖">2.1.2 添加SpringBoot的起步依赖</h3>
<p>SpringBoot要求，项目要继承SpringBoot的起步依赖spring-boot-starter-parent</p>
<pre><code class="language-xml">&lt;parent&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
    &lt;version&gt;2.0.1.RELEASE&lt;/version&gt;
&lt;/parent&gt;
</code></pre>
<p>SpringBoot要集成SpringMVC进行Controller的开发，所以项目要导入web的启动依赖</p>
<pre><code class="language-xml">&lt;dependencies&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
    &lt;/dependency&gt;
&lt;/dependencies&gt;
</code></pre>
<h3 id="213-编写springboot引导类">2.1.3 编写SpringBoot引导类</h3>
<p>要通过SpringBoot提供的引导类起步SpringBoot才可以进行访问</p>
<pre><code class="language-java">package com.itheima;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;

@SpringBootApplication
public class MySpringBootApplication {

    public static void main(String[] args) {
        SpringApplication.run(MySpringBootApplication.class);
    }

}
</code></pre>
<h3 id="214-编写controller">2.1.4 编写Controller</h3>
<p>在引导类MySpringBootApplication同级包或者子级包中创建QuickStartController</p>
<pre><code class="language-java">package com.itheima.controller;

import org.springframework.stereotype.Controller;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.ResponseBody;

@Controller
public class QuickStartController {
    
    @RequestMapping(&quot;/quick&quot;)
    @ResponseBody
    public String quick(){
        return &quot;springboot 访问成功!&quot;;
    }
    
}
</code></pre>
<h3 id="215-测试">2.1.5 测试</h3>
<p>执行SpringBoot起步类的主方法，控制台打印日志如下：</p>
<pre><code>.   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::        (v2.0.1.RELEASE)

2018-05-08 14:29:59.714  INFO 5672 --- [           main] com.itheima.MySpringBootApplication      : Starting MySpringBootApplication on DESKTOP-RRUNFUH with PID 5672 (C:\Users\muzimoo\IdeaProjects\IdeaTest\springboot_quick\target\classes started by muzimoo in C:\Users\muzimoo\IdeaProjects\IdeaTest)
... ... ...
o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-08 14:30:03.126  INFO 5672 --- [           main] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup
2018-05-08 14:30:03.196  INFO 5672 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 8080 (http) with context path ''
2018-05-08 14:30:03.206  INFO 5672 --- [           main] com.itheima.MySpringBootApplication      : Started MySpringBootApplication in 4.252 seconds (JVM running for 5.583)
</code></pre>
<p>通过日志发现，Tomcat started on port(s): 8080 (http) with context path ''</p>
<p>tomcat已经起步，端口监听8080，web应用的虚拟工程名称为空</p>
<p>打开浏览器访问url地址为：http://localhost:8080/quick</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1621326470668.png" alt="" loading="lazy"></figure>
<h2 id="22-快速入门解析">2.2 快速入门解析</h2>
<h3 id="222-springboot代码解析">2.2.2 SpringBoot代码解析</h3>
<ul>
<li>@SpringBootApplication：标注SpringBoot的启动类，该注解具备多种功能（后面详细剖析）</li>
<li>SpringApplication.run(MySpringBootApplication.class) 代表运行SpringBoot的启动类，参数为SpringBoot启动类的字节码对象</li>
</ul>
<h3 id="223-springboot工程热部署">2.2.3 SpringBoot工程热部署</h3>
<p>我们在开发中反复修改类、页面等资源，每次修改后都是需要重新启动才生效，这样每次启动都很麻烦，浪费了大量的时间，我们可以在修改代码后不重启就能生效，在 pom.xml 中添加如下配置就可以实现这样的功能，我们称之为热部署。</p>
<pre><code class="language-xml">&lt;!--热部署配置--&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<p>注意：IDEA进行SpringBoot热部署失败原因</p>
<p>出现这种情况，并不是热部署配置问题，其根本原因是因为Intellij IEDA默认情况下不会自动编译，需要对IDEA进行自动编译的设置，如下：</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1621326573533.png" alt="" loading="lazy"></figure>
<p>然后 Shift+Ctrl+Alt+/，选择Registry</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1621326585849.png" alt="" loading="lazy"></figure>
<h3 id="224-使用idea快速创建springboot项目">2.2.4 使用idea快速创建SpringBoot项目</h3>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1621326603385.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1621326620200.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1621326640049.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1621326656407.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1621326697642.png" alt="" loading="lazy"></figure>
<p>通过idea快速创建的SpringBoot项目的pom.xml中已经导入了我们选择的web的起步依赖的坐标</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
	xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
	&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

	&lt;groupId&gt;com.itheima&lt;/groupId&gt;
	&lt;artifactId&gt;springboot_quick2&lt;/artifactId&gt;
	&lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;
	&lt;packaging&gt;jar&lt;/packaging&gt;

	&lt;name&gt;springboot_quick2&lt;/name&gt;
	&lt;description&gt;Demo project for Spring Boot&lt;/description&gt;

	&lt;parent&gt;
		&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
		&lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
		&lt;version&gt;2.0.1.RELEASE&lt;/version&gt;
		&lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;
	&lt;/parent&gt;

	&lt;properties&gt;
		&lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
		&lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;
		&lt;java.version&gt;9&lt;/java.version&gt;
	&lt;/properties&gt;

	&lt;dependencies&gt;
		&lt;dependency&gt;
			&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
			&lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
		&lt;/dependency&gt;

		&lt;dependency&gt;
			&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
			&lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;
			&lt;scope&gt;test&lt;/scope&gt;
		&lt;/dependency&gt;
	&lt;/dependencies&gt;

	&lt;build&gt;
		&lt;plugins&gt;
			&lt;plugin&gt;
				&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
				&lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
			&lt;/plugin&gt;
		&lt;/plugins&gt;
	&lt;/build&gt;


&lt;/project&gt;

</code></pre>
<p>可以使用快速入门的方式创建Controller进行访问，此处不再赘述</p>
<h1 id="三-springboot原理分析">三、SpringBoot原理分析</h1>
<h2 id="31-起步依赖原理分析">3.1 起步依赖原理分析</h2>
<p><strong>3.1.1 分析spring-boot-starter-parent</strong></p>
<p>按住Ctrl点击pom.xml中的spring-boot-starter-parent，跳转到了spring-boot-starter-parent的pom.xml，xml配置如下（只摘抄了部分重点配置）：</p>
<pre><code class="language-xml">&lt;parent&gt;
  &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
  &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt;
  &lt;version&gt;2.0.1.RELEASE&lt;/version&gt;
  &lt;relativePath&gt;../../spring-boot-dependencies&lt;/relativePath&gt;
&lt;/parent&gt;
</code></pre>
<p>按住Ctrl点击pom.xml中的spring-boot-starter-dependencies，跳转到了spring-boot-starter-dependencies的pom.xml，xml配置如下（只摘抄了部分重点配置）：</p>
<pre><code class="language-xml">&lt;properties&gt;
  	&lt;activemq.version&gt;5.15.3&lt;/activemq.version&gt;
  	&lt;antlr2.version&gt;2.7.7&lt;/antlr2.version&gt;
  	&lt;appengine-sdk.version&gt;1.9.63&lt;/appengine-sdk.version&gt;
  	&lt;artemis.version&gt;2.4.0&lt;/artemis.version&gt;
  	&lt;aspectj.version&gt;1.8.13&lt;/aspectj.version&gt;
  	&lt;assertj.version&gt;3.9.1&lt;/assertj.version&gt;
  	&lt;atomikos.version&gt;4.0.6&lt;/atomikos.version&gt;
  	&lt;bitronix.version&gt;2.1.4&lt;/bitronix.version&gt;
  	&lt;build-helper-maven-plugin.version&gt;3.0.0&lt;/build-helper-maven-plugin.version&gt;
  	&lt;byte-buddy.version&gt;1.7.11&lt;/byte-buddy.version&gt;
  	... ... ...
&lt;/properties&gt;
&lt;dependencyManagement&gt;
  	&lt;dependencies&gt;
      	&lt;dependency&gt;
        	&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        	&lt;artifactId&gt;spring-boot&lt;/artifactId&gt;
        	&lt;version&gt;2.0.1.RELEASE&lt;/version&gt;
      	&lt;/dependency&gt;
      	&lt;dependency&gt;
        	&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        	&lt;artifactId&gt;spring-boot-test&lt;/artifactId&gt;
        	&lt;version&gt;2.0.1.RELEASE&lt;/version&gt;
      	&lt;/dependency&gt;
      	... ... ...
	&lt;/dependencies&gt;
&lt;/dependencyManagement&gt;
&lt;build&gt;
  	&lt;pluginManagement&gt;
    	&lt;plugins&gt;
      		&lt;plugin&gt;
        		&lt;groupId&gt;org.jetbrains.kotlin&lt;/groupId&gt;
        		&lt;artifactId&gt;kotlin-maven-plugin&lt;/artifactId&gt;
        		&lt;version&gt;${kotlin.version}&lt;/version&gt;
      		&lt;/plugin&gt;
      		&lt;plugin&gt;
        		&lt;groupId&gt;org.jooq&lt;/groupId&gt;
        		&lt;artifactId&gt;jooq-codegen-maven&lt;/artifactId&gt;
        		&lt;version&gt;${jooq.version}&lt;/version&gt;
      		&lt;/plugin&gt;
      		&lt;plugin&gt;
        		&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        		&lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
        		&lt;version&gt;2.0.1.RELEASE&lt;/version&gt;
      		&lt;/plugin&gt;
          	... ... ...
    	&lt;/plugins&gt;
  	&lt;/pluginManagement&gt;
&lt;/build&gt;
</code></pre>
<p>从上面的spring-boot-starter-dependencies的pom.xml中我们可以发现，一部分坐标的版本、依赖管理、插件管理已经定义好，所以我们的SpringBoot工程继承spring-boot-starter-parent后已经具备版本锁定等配置了。所以起步依赖的作用就是进行依赖的传递。</p>
<p><strong>3.1.2 分析spring-boot-starter-web</strong></p>
<p>按住Ctrl点击pom.xml中的spring-boot-starter-web，跳转到了spring-boot-starter-web的pom.xml，xml配置如下（只摘抄了部分重点配置）：</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;project xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot; xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;
    xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;&gt;
  	&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;
  	&lt;parent&gt;
    	&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    	&lt;artifactId&gt;spring-boot-starters&lt;/artifactId&gt;
    	&lt;version&gt;2.0.1.RELEASE&lt;/version&gt;
  	&lt;/parent&gt;
  	&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
  	&lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
  	&lt;version&gt;2.0.1.RELEASE&lt;/version&gt;
  	&lt;name&gt;Spring Boot Web Starter&lt;/name&gt;
  
  	&lt;dependencies&gt;
    	&lt;dependency&gt;
      		&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
      		&lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;
      		&lt;version&gt;2.0.1.RELEASE&lt;/version&gt;
      		&lt;scope&gt;compile&lt;/scope&gt;
    	&lt;/dependency&gt;
    	&lt;dependency&gt;
      		&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
      		&lt;artifactId&gt;spring-boot-starter-json&lt;/artifactId&gt;
      		&lt;version&gt;2.0.1.RELEASE&lt;/version&gt;
      		&lt;scope&gt;compile&lt;/scope&gt;
    	&lt;/dependency&gt;
    	&lt;dependency&gt;
      		&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
      		&lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt;
      		&lt;version&gt;2.0.1.RELEASE&lt;/version&gt;
      		&lt;scope&gt;compile&lt;/scope&gt;
    	&lt;/dependency&gt;
    	&lt;dependency&gt;
      		&lt;groupId&gt;org.hibernate.validator&lt;/groupId&gt;
      		&lt;artifactId&gt;hibernate-validator&lt;/artifactId&gt;
      		&lt;version&gt;6.0.9.Final&lt;/version&gt;
      		&lt;scope&gt;compile&lt;/scope&gt;
    	&lt;/dependency&gt;
    	&lt;dependency&gt;
      		&lt;groupId&gt;org.springframework&lt;/groupId&gt;
      		&lt;artifactId&gt;spring-web&lt;/artifactId&gt;
      		&lt;version&gt;5.0.5.RELEASE&lt;/version&gt;
      		&lt;scope&gt;compile&lt;/scope&gt;
    	&lt;/dependency&gt;
    	&lt;dependency&gt;
      		&lt;groupId&gt;org.springframework&lt;/groupId&gt;
      		&lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt;
      		&lt;version&gt;5.0.5.RELEASE&lt;/version&gt;
      		&lt;scope&gt;compile&lt;/scope&gt;
    	&lt;/dependency&gt;
  	&lt;/dependencies&gt;
&lt;/project&gt;

</code></pre>
<p>从上面的spring-boot-starter-web的pom.xml中我们可以发现，spring-boot-starter-web就是将web开发要使用的spring-web、spring-webmvc等坐标进行了“打包”，这样我们的工程只要引入spring-boot-starter-web起步依赖的坐标就可以进行web开发了，同样体现了依赖传递的作用。</p>
<h2 id="32-自动配置原理解析">3.2 自动配置原理解析</h2>
<p>按住Ctrl点击查看启动类MySpringBootApplication上的注解@SpringBootApplication</p>
<pre><code class="language-java">@SpringBootApplication
public class MySpringBootApplication {
    public static void main(String[] args) {
        SpringApplication.run(MySpringBootApplication.class);
    }
}
</code></pre>
<p>注解@SpringBootApplication的源码</p>
<pre><code class="language-java">@Target(ElementType.TYPE)
@Retention(RetentionPolicy.RUNTIME)
@Documented
@Inherited
@SpringBootConfiguration
@EnableAutoConfiguration
@ComponentScan(excludeFilters = {
		@Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class),
		@Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) })
public @interface SpringBootApplication {

	/**
	 * Exclude specific auto-configuration classes such that they will never be applied.
	 * @return the classes to exclude
	 */
	@AliasFor(annotation = EnableAutoConfiguration.class)
	Class&lt;?&gt;[] exclude() default {};

	... ... ...

}
</code></pre>
<p>@SpringBootConfiguration：等同与@Configuration，既标注该类是Spring的一个配置类</p>
<p>@EnableAutoConfiguration：SpringBoot自动配置功能开启</p>
<p>按住Ctrl点击查看注解@EnableAutoConfiguration</p>
<pre><code class="language-java">@Target(ElementType.TYPE)
@Retention(RetentionPolicy.RUNTIME)
@Documented
@Inherited
@AutoConfigurationPackage
@Import(AutoConfigurationImportSelector.class)
public @interface EnableAutoConfiguration {
	... ... ...
}
</code></pre>
<p>@Import(AutoConfigurationImportSelector.class) 导入了AutoConfigurationImportSelector类</p>
<p>按住Ctrl点击查看AutoConfigurationImportSelector源码</p>
<pre><code class="language-java">public String[] selectImports(AnnotationMetadata annotationMetadata) {
        ... ... ...
        List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata,
                                                                   attributes);
        configurations = removeDuplicates(configurations);
        Set&lt;String&gt; exclusions = getExclusions(annotationMetadata, attributes);
        checkExcludedClasses(configurations, exclusions);
        configurations.removeAll(exclusions);
        configurations = filter(configurations, autoConfigurationMetadata);
        fireAutoConfigurationImportEvents(configurations, exclusions);
        return StringUtils.toStringArray(configurations);
}


protected List&lt;String&gt; getCandidateConfigurations(AnnotationMetadata metadata,
			AnnotationAttributes attributes) {
		List&lt;String&gt; configurations = SpringFactoriesLoader.loadFactoryNames(
				getSpringFactoriesLoaderFactoryClass(), getBeanClassLoader());
		
		return configurations;
}

</code></pre>
<p>SpringFactoriesLoader.loadFactoryNames 方法的作用就是从META-INF/spring.factories文件中读取指定类对应的类名称列表</p>
<figure data-type="image" tabindex="9"><img src="https://tinaxiawuhao.github.io/post-images/1621326779183.png" alt="" loading="lazy"></figure>
<p>spring.factories 文件中有关自动配置的配置信息如下：</p>
<pre><code>... ... ...

org.springframework.boot.autoconfigure.web.reactive.function.client.WebClientAutoConfiguration,\
org.springframework.boot.autoconfigure.web.servlet.DispatcherServletAutoConfiguration,\
org.springframework.boot.autoconfigure.web.servlet.ServletWebServerFactoryAutoConfiguration,\
org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration,\
org.springframework.boot.autoconfigure.web.servlet.HttpEncodingAutoConfiguration,\
org.springframework.boot.autoconfigure.web.servlet.MultipartAutoConfiguration,\

... ... ...
</code></pre>
<p>上面配置文件存在大量的以Configuration为结尾的类名称，这些类就是存有自动配置信息的类，而SpringApplication在获取这些类名后再加载</p>
<p>我们以ServletWebServerFactoryAutoConfiguration为例来分析源码：</p>
<pre><code class="language-java">@Configuration
@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE)
@ConditionalOnClass(ServletRequest.class)
@ConditionalOnWebApplication(type = Type.SERVLET)
@EnableConfigurationProperties(ServerProperties.class)
@Import({ ServletWebServerFactoryAutoConfiguration.BeanPostProcessorsRegistrar.class,
		ServletWebServerFactoryConfiguration.EmbeddedTomcat.class,
		ServletWebServerFactoryConfiguration.EmbeddedJetty.class,
		ServletWebServerFactoryConfiguration.EmbeddedUndertow.class })
public class ServletWebServerFactoryAutoConfiguration {
	... ... ...
}

</code></pre>
<p>@EnableConfigurationProperties(ServerProperties.class) 代表加载ServerProperties服务器配置属性类</p>
<p>进入ServerProperties.class源码如下：</p>
<pre><code class="language-java">@ConfigurationProperties(prefix = &quot;server&quot;, ignoreUnknownFields = true)
public class ServerProperties {

	/**
	 * Server HTTP port.
	 */
	private Integer port;

	/**
	 * Network address to which the server should bind.
	 */
	private InetAddress address;
  
  	... ... ...
  
}
</code></pre>
<p>prefix = &quot;server&quot; 表示SpringBoot配置文件中的前缀，SpringBoot会将配置文件中以server开始的属性映射到该类的字段中。映射关系如下：</p>
<figure data-type="image" tabindex="10"><img src="https://tinaxiawuhao.github.io/post-images/1621326800187.png" alt="" loading="lazy"></figure>
<h1 id="四-springboot的配置文件">四、SpringBoot的配置文件</h1>
<h2 id="41-springboot配置文件类型">4.1 SpringBoot配置文件类型</h2>
<h3 id="411-springboot配置文件类型和作用">4.1.1 SpringBoot配置文件类型和作用</h3>
<p>SpringBoot是基于约定的，所以很多配置都有默认值，但如果想使用自己的配置替换默认配置的话，就可以使用application.properties或者application.yml（application.yaml）进行配置。</p>
<p>SpringBoot默认会从Resources目录下加载application.properties或application.yml（application.yaml）文件</p>
<p>其中，application.properties文件是键值对类型的文件，之前一直在使用，所以此处不在对properties文件的格式进行阐述。除了properties文件外，SpringBoot还可以使用yml文件进行配置，下面对yml文件进行讲解。</p>
<h3 id="412-applicationyml配置文件">4.1.2 application.yml配置文件</h3>
<p><strong>4.1.2.1 yml配置文件简介</strong></p>
<p>YML文件格式是YAML (YAML Aint Markup Language)编写的文件格式，YAML是一种直观的能够被电脑识别的的数据数据序列化格式，并且容易被人类阅读，容易和脚本语言交互的，可以被支持YAML库的不同的编程语言程序导入，比如： C/C++, Ruby, Python, Java, Perl, C#, PHP等。YML文件是以数据为核心的，比传统的xml方式更加简洁。</p>
<p>YML文件的扩展名可以使用.yml或者.yaml。</p>
<p><strong>4.1.2.2 yml配置文件的语法</strong></p>
<p><strong>4.1.2.2.1 配置普通数据</strong></p>
<ul>
<li>
<p>语法： key: value</p>
</li>
<li>
<p>示例代码：</p>
</li>
<li>
<pre><code class="language-yaml">name: haohao
</code></pre>
</li>
<li>
<p>注意：value之前有一个空格</p>
</li>
</ul>
<p><strong>4.1.2.2.2 配置对象数据</strong></p>
<ul>
<li>
<p>语法：</p>
<p>​	key:</p>
<p>​		key1: value1</p>
<p>​		key2: value2</p>
<p>​	或者：</p>
<p>​	key: {key1: value1,key2: value2}</p>
</li>
<li>
<p>示例代码：</p>
</li>
<li>
<pre><code class="language-yaml">person:
  name: haohao
  age: 31
  addr: beijing

#或者

person: {name: haohao,age: 31,addr: beijing}
</code></pre>
</li>
<li>
<p>注意：key1前面的空格个数不限定，在yml语法中，相同缩进代表同一个级别</p>
</li>
</ul>
<p><strong>4.1.2.2.3 配置数组（List、Set）数据</strong></p>
<ul>
<li>
<p>语法：</p>
<p>​	key:</p>
<p>​		- value1</p>
<p>​		- value2</p>
<p>或者：</p>
<p>​	key: [value1,value2]</p>
</li>
<li>
<p>示例代码：</p>
</li>
<li>
<pre><code class="language-yaml">city:
  - beijing
  - tianjin
  - shanghai
  - chongqing
  
#或者

city: [beijing,tianjin,shanghai,chongqing]

#集合中的元素是对象形式
student:
  - name: zhangsan
    age: 18
    score: 100
  - name: lisi
    age: 28
    score: 88
  - name: wangwu
    age: 38
    score: 90
</code></pre>
</li>
<li>
<p>注意：value1与之间的 - 之间存在一个空格</p>
</li>
</ul>
<h3 id="413-springboot配置信息的查询">4.1.3 SpringBoot配置信息的查询</h3>
<p>上面提及过，SpringBoot的配置文件，主要的目的就是对配置信息进行修改的，但在配置时的key从哪里去查询呢？我们可以查阅SpringBoot的官方文档,文档URL：https://docs.spring.io/spring-boot/docs/2.0.1.RELEASE/reference/htmlsingle/#common-application-properties</p>
<p>常用的配置摘抄如下：</p>
<pre><code class="language-xml"># QUARTZ SCHEDULER (QuartzProperties)
spring.quartz.jdbc.initialize-schema=embedded # Database schema initialization mode.
spring.quartz.jdbc.schema=classpath:org/quartz/impl/jdbcjobstore/tables_@@platform@@.sql # Path to the SQL file to use to initialize the database schema.
spring.quartz.job-store-type=memory # Quartz job store type.
spring.quartz.properties.*= # Additional Quartz Scheduler properties.

# ----------------------------------------
# WEB PROPERTIES
# ----------------------------------------

# EMBEDDED SERVER CONFIGURATION (ServerProperties)
server.port=8080 # Server HTTP port.
server.servlet.context-path= # Context path of the application.
server.servlet.path=/ # Path of the main dispatcher servlet.

# HTTP encoding (HttpEncodingProperties)
spring.http.encoding.charset=UTF-8 # Charset of HTTP requests and responses. Added to the &quot;Content-Type&quot; header if not set explicitly.

# JACKSON (JacksonProperties)
spring.jackson.date-format= # Date format string or a fully-qualified date format class name. For instance, `yyyy-MM-dd HH:mm:ss`.

# SPRING MVC (WebMvcProperties)
spring.mvc.servlet.load-on-startup=-1 # Load on startup priority of the dispatcher servlet.
spring.mvc.static-path-pattern=/** # Path pattern used for static resources.
spring.mvc.view.prefix= # Spring MVC view prefix.
spring.mvc.view.suffix= # Spring MVC view suffix.

# DATASOURCE (DataSourceAutoConfiguration &amp; DataSourceProperties)
spring.datasource.driver-class-name= # Fully qualified name of the JDBC driver. Auto-detected based on the URL by default.
spring.datasource.password= # Login password of the database.
spring.datasource.url= # JDBC URL of the database.
spring.datasource.username= # Login username of the database.

# JEST (Elasticsearch HTTP client) (JestProperties)
spring.elasticsearch.jest.password= # Login password.
spring.elasticsearch.jest.proxy.host= # Proxy host the HTTP client should use.
spring.elasticsearch.jest.proxy.port= # Proxy port the HTTP client should use.
spring.elasticsearch.jest.read-timeout=3s # Read timeout.
spring.elasticsearch.jest.username= # Login username.

</code></pre>
<p>我们可以通过配置application.poperties 或者 application.yml 来修改SpringBoot的默认配置</p>
<p>例如：</p>
<p>application.properties文件</p>
<pre><code class="language-java">server.port=8888
server.servlet.context-path=demo
</code></pre>
<p>application.yml文件</p>
<pre><code class="language-yaml">server:
  port: 8888
  servlet:
    context-path: /demo
</code></pre>
<h2 id="42-配置文件与配置类的属性映射方式">4.2 配置文件与配置类的属性映射方式</h2>
<h3 id="421-使用注解value映射">4.2.1 使用注解@Value映射</h3>
<p>我们可以通过@Value注解将配置文件中的值映射到一个Spring管理的Bean的字段上</p>
<p>例如：</p>
<p>application.properties配置如下：</p>
<pre><code class="language-yaml">person:
  name: zhangsan
  age: 18
</code></pre>
<p>或者，application.yml配置如下：</p>
<pre><code class="language-yaml">person:
  name: zhangsan
  age: 18
</code></pre>
<p>实体Bean代码如下：</p>
<pre><code class="language-java">@Controller
public class QuickStartController {

    @Value(&quot;${person.name}&quot;)
    private String name;
    @Value(&quot;${person.age}&quot;)
    private Integer age;


    @RequestMapping(&quot;/quick&quot;)
    @ResponseBody
    public String quick(){
        return &quot;springboot 访问成功! name=&quot;+name+&quot;,age=&quot;+age;
    }

}
</code></pre>
<p>浏览器访问地址：http://localhost:8080/quick 结果如下：</p>
<figure data-type="image" tabindex="11"><img src="https://tinaxiawuhao.github.io/post-images/1621326747717.png" alt="" loading="lazy"></figure>
<h3 id="422-使用注解configurationproperties映射">4.2.2 使用注解@ConfigurationProperties映射</h3>
<p>通过注解@ConfigurationProperties(prefix=&quot;配置文件中的key的前缀&quot;)可以将配置文件中的配置自动与实体进行映射</p>
<p>application.properties配置如下：</p>
<pre><code class="language-yaml">person:
  name: zhangsan
  age: 18
</code></pre>
<p>或者，application.yml配置如下：</p>
<pre><code class="language-yaml">person:
  name: zhangsan
  age: 18
</code></pre>
<p>实体Bean代码如下：</p>
<pre><code class="language-java">@Controller
@ConfigurationProperties(prefix = &quot;person&quot;)
public class QuickStartController {

    private String name;
    private Integer age;

    @RequestMapping(&quot;/quick&quot;)
    @ResponseBody
    public String quick(){
        return &quot;springboot 访问成功! name=&quot;+name+&quot;,age=&quot;+age;
    }

    public void setName(String name) {
        this.name = name;
    }

    public void setAge(Integer age) {
        this.age = age;
    }
}
</code></pre>
<p>浏览器访问地址：http://localhost:8080/quick 结果如下：</p>
<figure data-type="image" tabindex="12"><img src="https://tinaxiawuhao.github.io/post-images/1621326821666.png" alt="" loading="lazy"></figure>
<p>注意：使用@ConfigurationProperties方式可以进行配置文件与实体字段的自动映射，但需要字段必须提供set方法才可以，而使用@Value注解修饰的字段不需要提供set方法</p>
<h1 id="五-springboot与整合其他技术">五、SpringBoot与整合其他技术</h1>
<h2 id="51-springboot整合mybatis">5.1 SpringBoot整合Mybatis</h2>
<p><strong>5.1.1 添加Mybatis的起步依赖</strong></p>
<pre><code class="language-xml">&lt;!--mybatis起步依赖--&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt;
    &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;
    &lt;version&gt;1.1.1&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<p><strong>5.1.2 添加数据库驱动坐标</strong></p>
<pre><code class="language-xml">&lt;!-- MySQL连接驱动 --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;mysql&lt;/groupId&gt;
    &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<p><strong>5.1.3 添加数据库连接信息</strong></p>
<p>在application.properties中添加数据量的连接信息</p>
<pre><code class="language-yaml">#DB Configuration:
spring.datasource.driverClassName=com.mysql.jdbc.Driver
spring.datasource.url=jdbc:mysql://127.0.0.1:3306/test?useUnicode=true&amp;characterEncoding=utf8
spring.datasource.username=root
spring.datasource.password=root
</code></pre>
<p><strong>5.1.4 创建user表</strong></p>
<p>在test数据库中创建user表</p>
<pre><code class="language-sql">-- ----------------------------
-- Table structure for `user`
-- ----------------------------
DROP TABLE IF EXISTS `user`;
CREATE TABLE `user` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `username` varchar(50) DEFAULT NULL,
  `password` varchar(50) DEFAULT NULL,
  `name` varchar(50) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=10 DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of user
-- ----------------------------
INSERT INTO `user` VALUES ('1', 'zhangsan', '123', '张三');
INSERT INTO `user` VALUES ('2', 'lisi', '123', '李四');
</code></pre>
<p><strong>5.1.5 创建实体Bean</strong></p>
<pre><code class="language-java">public class User {
    // 主键
    private Long id;
    // 用户名
    private String username;
    // 密码
    private String password;
    // 姓名
    private String name;
  
    //此处省略getter和setter方法 .. ..
    
}
</code></pre>
<p><strong>5.1.6 编写Mapper</strong></p>
<pre><code class="language-java">@Mapper
public interface UserMapper {
	public List&lt;User&gt; queryUserList();
}
</code></pre>
<p>注意：@Mapper标记该类是一个mybatis的mapper接口，可以被spring boot自动扫描到spring上下文中</p>
<p><strong>5.1.7 配置Mapper映射文件</strong></p>
<p>在src\main\resources\mapper路径下加入UserMapper.xml配置文件&quot;</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot; ?&gt;
&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot; &gt;
&lt;mapper namespace=&quot;com.itheima.mapper.UserMapper&quot;&gt;
    &lt;select id=&quot;queryUserList&quot; resultType=&quot;user&quot;&gt;
        select * from user
    &lt;/select&gt;
&lt;/mapper&gt;
</code></pre>
<p><strong>5.1.8 在application.properties中添加mybatis的信息</strong></p>
<pre><code class="language-yaml">#spring集成Mybatis环境
#pojo别名扫描包
mybatis.type-aliases-package=com.itheima.domain
#加载Mybatis映射文件
mybatis.mapper-locations=classpath:mapper/*Mapper.xml
</code></pre>
<p><strong>5.1.9 编写测试Controller</strong></p>
<pre><code class="language-java">@Controller
public class MapperController {

    @Autowired
    private UserMapper userMapper;

    @RequestMapping(&quot;/queryUser&quot;)
    @ResponseBody
    public List&lt;User&gt; queryUser(){
        List&lt;User&gt; users = userMapper.queryUserList();
        return users;
    }

}
</code></pre>
<p><strong>5.1.10 测试</strong></p>
<figure data-type="image" tabindex="13"><img src="https://tinaxiawuhao.github.io/post-images/1621326842189.png" alt="" loading="lazy"></figure>
<h2 id="52-springboot整合junit">5.2 SpringBoot整合Junit</h2>
<p><strong>5.2.1 添加Junit的起步依赖</strong></p>
<pre><code class="language-xml">&lt;!--测试的起步依赖--&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;
    &lt;scope&gt;test&lt;/scope&gt;
&lt;/dependency&gt;
</code></pre>
<p><strong>5.2.2 编写测试类</strong></p>
<pre><code class="language-java">package com.itheima.test;

import com.itheima.MySpringBootApplication;
import com.itheima.domain.User;
import com.itheima.mapper.UserMapper;
import org.junit.Test;
import org.junit.runner.RunWith;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.test.context.junit4.SpringRunner;

import java.util.List;

@RunWith(SpringRunner.class)
@SpringBootTest(classes = MySpringBootApplication.class)
public class MapperTest {

    @Autowired
    private UserMapper userMapper;

    @Test
    public void test() {
        List&lt;User&gt; users = userMapper.queryUserList();
        System.out.println(users);
    }

}
</code></pre>
<p>其中，</p>
<p>SpringRunner继承自SpringJUnit4ClassRunner，使用哪一个Spring提供的测试测试引擎都可以</p>
<pre><code class="language-java">public final class SpringRunner extends SpringJUnit4ClassRunner 
</code></pre>
<p>@SpringBootTest的属性指定的是引导类的字节码对象</p>
<p><strong>5.2.3 控制台打印信息</strong></p>
<figure data-type="image" tabindex="14"><img src="https://tinaxiawuhao.github.io/post-images/1621326860451.png" alt="" loading="lazy"></figure>
<h2 id="53-springboot整合spring-data-jpa">5.3 SpringBoot整合Spring Data JPA</h2>
<p><strong>5.3.1 添加Spring Data JPA的起步依赖</strong></p>
<pre><code class="language-xml">&lt;!-- springBoot JPA的起步依赖 --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<p><strong>5.3.2 添加数据库驱动依赖</strong></p>
<pre><code class="language-xml">&lt;!-- MySQL连接驱动 --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;mysql&lt;/groupId&gt;
    &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<p><strong>5.3.3 在application.properties中配置数据库和jpa的相关属性</strong></p>
<pre><code class="language-yaml">#DB Configuration:
spring.datasource.driverClassName=com.mysql.jdbc.Driver
spring.datasource.url=jdbc:mysql://127.0.0.1:3306/test?useUnicode=true&amp;characterEncoding=utf8
spring.datasource.username=root
spring.datasource.password=root

#JPA Configuration:
spring.jpa.database=MySQL
spring.jpa.show-sql=true
spring.jpa.generate-ddl=true
spring.jpa.hibernate.ddl-auto=update
spring.jpa.hibernate.naming_strategy=org.hibernate.cfg.ImprovedNamingStrategy
</code></pre>
<p><strong>5.3.4 创建实体配置实体</strong></p>
<pre><code class="language-java">@Entity
public class User {
    // 主键
    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;
    // 用户名
    private String username;
    // 密码
    private String password;
    // 姓名
    private String name;
 
    //此处省略setter和getter方法... ...
}
</code></pre>
<p><strong>5.3.5 编写UserRepository</strong></p>
<pre><code class="language-java">public interface UserRepository extends JpaRepository&lt;User,Long&gt;{
    public List&lt;User&gt; findAll();
}
</code></pre>
<p><strong>5.3.6 编写测试类</strong></p>
<pre><code class="language-java">@RunWith(SpringRunner.class)
@SpringBootTest(classes=MySpringBootApplication.class)
public class JpaTest {

    @Autowired
    private UserRepository userRepository;

    @Test
    public void test(){
        List&lt;User&gt; users = userRepository.findAll();
        System.out.println(users);
    }

}
</code></pre>
<p><strong>5.3.7 控制台打印信息</strong></p>
<figure data-type="image" tabindex="15"><img src="https://tinaxiawuhao.github.io/post-images/1621326882957.png" alt="" loading="lazy"></figure>
<p>注意：如果是jdk9，执行报错如下：</p>
<figure data-type="image" tabindex="16"><img src="https://tinaxiawuhao.github.io/post-images/1621326901468.png" alt="" loading="lazy"></figure>
<p>原因：jdk缺少相应的jar</p>
<p>解决方案：手动导入对应的maven坐标，如下：</p>
<pre><code class="language-xml">&lt;!--jdk9需要导入如下坐标--&gt;
&lt;dependency&gt;
    &lt;groupId&gt;javax.xml.bind&lt;/groupId&gt;
    &lt;artifactId&gt;jaxb-api&lt;/artifactId&gt;
    &lt;version&gt;2.3.0&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<h2 id="54-springboot整合redis">5.4 SpringBoot整合Redis</h2>
<p><strong>5.4.1 添加redis的起步依赖</strong></p>
<pre><code class="language-xml">&lt;!-- 配置使用redis启动器 --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<p><strong>5.4.2 配置redis的连接信息</strong></p>
<pre><code class="language-yaml">#Redis
spring.redis.host=127.0.0.1
spring.redis.port=6379
</code></pre>
<p><strong>5.4.3 注入RedisTemplate测试redis操作</strong></p>
<pre><code class="language-java">@RunWith(SpringRunner.class)
@SpringBootTest(classes = SpringbootJpaApplication.class)
public class RedisTest {

    @Autowired
    private UserRepository userRepository;

    @Autowired
    private RedisTemplate&lt;String, String&gt; redisTemplate;

    @Test
    public void test() throws JsonProcessingException {
        //从redis缓存中获得指定的数据
        String userListData = redisTemplate.boundValueOps(&quot;user.findAll&quot;).get();
        //如果redis中没有数据的话
        if(null==userListData){
            //查询数据库获得数据
            List&lt;User&gt; all = userRepository.findAll();
            //转换成json格式字符串
            ObjectMapper om = new ObjectMapper();
            userListData = om.writeValueAsString(all);
            //将数据存储到redis中，下次在查询直接从redis中获得数据，不用在查询数据库
            redisTemplate.boundValueOps(&quot;user.findAll&quot;).set(userListData);
            System.out.println(&quot;===============从数据库获得数据===============&quot;);
        }else{
            System.out.println(&quot;===============从redis缓存中获得数据===============&quot;);
        }

        System.out.println(userListData);

    }

}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[SpringBoot自动装配原理]]></title>
        <id>https://tinaxiawuhao.github.io/post/YkvDN4zR3/</id>
        <link href="https://tinaxiawuhao.github.io/post/YkvDN4zR3/">
        </link>
        <updated>2021-05-24T02:37:39.000Z</updated>
        <content type="html"><![CDATA[<h3 id="springboot自动配置">SpringBoot自动配置</h3>
<p>从代码里看项目SpringBoot的项目启动类只有一个注解@SpringBootApplication和一个run方法。</p>
<pre><code class="language-java">@SpringBootApplication
public class Application {
    public static void main(String[] args) {
        SpringApplication.run(Application.class, args);
    }
}
</code></pre>
<p>直接看<code>@SpringBootApplication</code>的代码：</p>
<pre><code class="language-java">@Target({ElementType.TYPE})
@Retention(RetentionPolicy.RUNTIME)
@Documented
@Inherited
@SpringBootConfiguration
@EnableAutoConfiguration
@ComponentScan(
    excludeFilters = {@Filter(
    type = FilterType.CUSTOM,
    classes = {TypeExcludeFilter.class}
), @Filter(
    type = FilterType.CUSTOM,
    classes = {AutoConfigurationExcludeFilter.class}
)}
)
public @interface SpringBootApplication {
    @AliasFor(
        annotation = EnableAutoConfiguration.class,
        attribute = &quot;exclude&quot;
    )
    Class&lt;?&gt;[] exclude() default {};

    @AliasFor(
        annotation = EnableAutoConfiguration.class,
        attribute = &quot;excludeName&quot;
    )
    String[] excludeName() default {};

    @AliasFor(
        annotation = ComponentScan.class,
        attribute = &quot;basePackages&quot;
    )
    String[] scanBasePackages() default {};

    @AliasFor(
        annotation = ComponentScan.class,
        attribute = &quot;basePackageClasses&quot;
    )
    Class&lt;?&gt;[] scanBasePackageClasses() default {};
}
</code></pre>
<p><code>@SpringBootApplication</code>：包含了<code>@SpringBootConfiguration</code>（打开是<code>@Configuration</code>），<code>@EnableAutoConfiguration</code>，<code>@ComponentScan</code>注解。<br>
<strong>@Configuration</strong><br>
JavaConfig形式的Spring Ioc容器的配置类使用的那个<code>@Configuration</code>，SpringBoot社区推荐使用基于JavaConfig的配置形式，所以，这里的启动类标注了@Configuration之后，本身其实也是一个IoC容器的配置类。<br>
对比一下传统XML方式和config配置方式的区别：<br>
XML声明和定义配置方式：</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;
	xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot;
	xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot;
	xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans 
						http://www.springframework.org/schema/beans/spring-beans-3.0.xsd
						http://www.springframework.org/schema/aop 
						http://www.springframework.org/schema/aop/spring-aop-3.0.xsd
						http://www.springframework.org/schema/context 
						http://www.springframework.org/schema/context/spring-context-3.0.xsd
						http://www.springframework.org/schema/tx 
						http://www.springframework.org/schema/tx/spring-tx-3.0.xsd
	&quot;&gt;
	&lt;bean id=&quot;app&quot; class=&quot;com...&quot; /&gt;
</code></pre>
<p>用一个过滤器举例，JavaConfig的配置方式是这样：</p>
<pre><code class="language-java">@Configuration
public class DruidConfiguration {    
    @Bean
    public FilterRegistrationBean statFilter(){
        //创建过滤器
        FilterRegistrationBean filterRegistrationBean = new FilterRegistrationBean(new WebStatFilter());
        //设置过滤器过滤路径
        filterRegistrationBean.addUrlPatterns(&quot;/*&quot;);
        //忽略过滤的形式
        filterRegistrationBean.addInitParameter(&quot;exclusions&quot;,&quot;*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*&quot;);
        return filterRegistrationBean;
    }
}
</code></pre>
<p>任何一个标注了<code>@Configuration</code>的Java类定义都是一个JavaConfig配置类。<br>
任何一个标注了<code>@Bean</code>的方法，其返回值将作为一个bean定义注册到Spring的IoC容器，方法名将默认成该bean定义的id。<br>
<strong>@ComponentScan</strong><br>
<code>@ComponentScan</code>对应XML配置中的元素，<code>@ComponentScan</code>的功能其实就是自动扫描并加载符合条件的组件（比如<code>@Component</code>和<code>@Repository</code>等）或者bean定义，最终将这些bean定义加载到IoC容器中。<br>
我们可以通过basePackages等属性来细粒度的定制<code>@ComponentScan</code>自动扫描的范围，如果不指定，则默认Spring框架实现会从声明@ComponentScan所在类的package进行扫描。<br>
注：所以SpringBoot的启动类最好是放在root package下，因为默认不指定basePackages。<br>
<strong>@EnableAutoConfiguration</strong><br>
（核心内容）看英文意思就是自动配置，概括一下就是，借助@Import的帮助，将所有符合自动配置条件的bean定义加载到IoC容器。</p>
<pre><code class="language-java">@Target({ElementType.TYPE})
@Retention(RetentionPolicy.RUNTIME)
@Documented
@Inherited
@AutoConfigurationPackage
@Import({EnableAutoConfigurationImportSelector.class})
public @interface EnableAutoConfiguration {
    String ENABLED_OVERRIDE_PROPERTY = &quot;spring.boot.enableautoconfiguration&quot;;

    Class&lt;?&gt;[] exclude() default {};

    String[] excludeName() default {};
}
</code></pre>
<p>里面最关键的是<code>@Import(EnableAutoConfigurationImportSelector.class)</code>，借助EnableAutoConfigurationImportSelector，<code>@EnableAutoConfiguration</code>可以帮助SpringBoot应用将所有符合条件的<code>@Configuration</code>配置都加载到当前SpringBoot创建并使用的IoC容器。该配置模块的主要使用到了SpringFactoriesLoader。</p>
<h4 id="springfactoriesloader详解">SpringFactoriesLoader详解</h4>
<p>SpringFactoriesLoader为Spring工厂加载器，该对象提供了loadFactoryNames方法，入参为factoryClass和classLoader即需要传入工厂类名称和对应的类加载器，方法会根据指定的classLoader，加载该类加器搜索路径下的指定文件，即spring.factories文件，传入的工厂类为接口，而文件中对应的类则是接口的实现类，或最终作为实现类。</p>
<pre><code class="language-java">public abstract class SpringFactoriesLoader {
    private static final Log logger = LogFactory.getLog(SpringFactoriesLoader.class);
    public static final String FACTORIES_RESOURCE_LOCATION = &quot;META-INF/spring.factories&quot;;

    public SpringFactoriesLoader() {
    }

    public static &lt;T&gt; List&lt;T&gt; loadFactories(Class&lt;T&gt; factoryClass, ClassLoader classLoader) {
        Assert.notNull(factoryClass, &quot;'factoryClass' must not be null&quot;);
        ClassLoader classLoaderToUse = classLoader;
        if (classLoader == null) {
            classLoaderToUse = SpringFactoriesLoader.class.getClassLoader();
        }

        List&lt;String&gt; factoryNames = loadFactoryNames(factoryClass, classLoaderToUse);
        if (logger.isTraceEnabled()) {
            logger.trace(&quot;Loaded [&quot; + factoryClass.getName() + &quot;] names: &quot; + factoryNames);
        }

        List&lt;T&gt; result = new ArrayList(factoryNames.size());
        Iterator var5 = factoryNames.iterator();

        while(var5.hasNext()) {
            String factoryName = (String)var5.next();
            result.add(instantiateFactory(factoryName, factoryClass, classLoaderToUse));
        }

        AnnotationAwareOrderComparator.sort(result);
        return result;
    }

    public static List&lt;String&gt; loadFactoryNames(Class&lt;?&gt; factoryClass, ClassLoader classLoader) {
        String factoryClassName = factoryClass.getName();

        try {
            Enumeration&lt;URL&gt; urls = classLoader != null ? classLoader.getResources(&quot;META-INF/spring.factories&quot;) : ClassLoader.getSystemResources(&quot;META-INF/spring.factories&quot;);
            ArrayList result = new ArrayList();

            while(urls.hasMoreElements()) {
                URL url = (URL)urls.nextElement();
                Properties properties = PropertiesLoaderUtils.loadProperties(new UrlResource(url));
                String factoryClassNames = properties.getProperty(factoryClassName);
                result.addAll(Arrays.asList(StringUtils.commaDelimitedListToStringArray(factoryClassNames)));
            }

            return result;
        } catch (IOException var8) {
            throw new IllegalArgumentException(&quot;Unable to load [&quot; + factoryClass.getName() + &quot;] factories from location [&quot; + &quot;META-INF/spring.factories&quot; + &quot;]&quot;, var8);
        }
    }

    private static &lt;T&gt; T instantiateFactory(String instanceClassName, Class&lt;T&gt; factoryClass, ClassLoader classLoader) {
        try {
            Class&lt;?&gt; instanceClass = ClassUtils.forName(instanceClassName, classLoader);
            if (!factoryClass.isAssignableFrom(instanceClass)) {
                throw new IllegalArgumentException(&quot;Class [&quot; + instanceClassName + &quot;] is not assignable to [&quot; + factoryClass.getName() + &quot;]&quot;);
            } else {
                Constructor&lt;?&gt; constructor = instanceClass.getDeclaredConstructor();
                ReflectionUtils.makeAccessible(constructor);
                return constructor.newInstance();
            }
        } catch (Throwable var5) {
            throw new IllegalArgumentException(&quot;Unable to instantiate factory class: &quot; + factoryClass.getName(), var5);
        }
    }
}
</code></pre>
<p>所以文件中一般为如下图这种一对多的类名集合，获取到这些实现类的类名后，loadFactoryNames方法返回类名集合，方法调用方得到这些集合后，再通过反射获取这些类的类对象、构造方法，最终生成实例。</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1621306254228.webp" alt="" loading="lazy"></figure>
<p>下图有助于我们形象理解自动配置流程（盗个图）</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1621306269634.webp" alt="" loading="lazy"></figure>
<h4 id="autoconfigurationimportselector">AutoConfigurationImportSelector</h4>
<p>继续上面讲的AutoConfigurationImportSelector.class。该类主要关注selectImports方法</p>
<pre><code class="language-java">public String[] selectImports(AnnotationMetadata annotationMetadata) {
    if (!this.isEnabled(annotationMetadata)) {
        return NO_IMPORTS;
    } else {
        try {
            AutoConfigurationMetadata autoConfigurationMetadata = AutoConfigurationMetadataLoader.loadMetadata(this.beanClassLoader);
            AnnotationAttributes attributes = this.getAttributes(annotationMetadata);
            List&lt;String&gt; configurations = this.getCandidateConfigurations(annotationMetadata, attributes);
            configurations = this.removeDuplicates(configurations);
            configurations = this.sort(configurations, autoConfigurationMetadata);
            Set&lt;String&gt; exclusions = this.getExclusions(annotationMetadata, attributes);
            this.checkExcludedClasses(configurations, exclusions);
            configurations.removeAll(exclusions);
            configurations = this.filter(configurations, autoConfigurationMetadata);
            this.fireAutoConfigurationImportEvents(configurations, exclusions);
            return (String[])configurations.toArray(new String[configurations.size()]);
        } catch (IOException var6) {
            throw new IllegalStateException(var6);
        }
    }
}
</code></pre>
<p>该方法在springboot启动流程——bean实例化前被执行，返回要实例化的类信息列表。如果获取到类信息，spring可以通过类加载器将类加载到jvm中，现在我们已经通过spring-boot的starter依赖方式依赖了我们需要的组件，那么这些组件的类信息在select方法中就可以被获取到。</p>
<pre><code class="language-java">protected List&lt;String&gt; getCandidateConfigurations(AnnotationMetadata metadata, AnnotationAttributes attributes) {
    List&lt;String&gt; configurations = SpringFactoriesLoader.loadFactoryNames(this.getSpringFactoriesLoaderFactoryClass(), this.getBeanClassLoader());
    Assert.notEmpty(configurations, &quot;No auto configuration classes found in META-INF/spring.factories. If you are using a custom packaging, make sure that file is correct.&quot;);
    return configurations;
}
</code></pre>
<p>方法中的getCandidateConfigurations方法，其返回一个自动配置类的类名列表，方法调用了loadFactoryNames方法，查看该方法</p>
<pre><code class="language-java">public static List&lt;String&gt; loadFactoryNames(Class&lt;?&gt; factoryClass, ClassLoader classLoader) {
    String factoryClassName = factoryClass.getName();

    try {
        Enumeration&lt;URL&gt; urls = classLoader != null ? classLoader.getResources(&quot;META-INF/spring.factories&quot;) : ClassLoader.getSystemResources(&quot;META-INF/spring.factories&quot;);
        ArrayList result = new ArrayList();

        while(urls.hasMoreElements()) {
            URL url = (URL)urls.nextElement();
            Properties properties = PropertiesLoaderUtils.loadProperties(new UrlResource(url));
            String factoryClassNames = properties.getProperty(factoryClassName);
            result.addAll(Arrays.asList(StringUtils.commaDelimitedListToStringArray(factoryClassNames)));
        }

        return result;
    } catch (IOException var8) {
        throw new IllegalArgumentException(&quot;Unable to load [&quot; + factoryClass.getName() + &quot;] factories from location [&quot; + &quot;META-INF/spring.factories&quot; + &quot;]&quot;, var8);
    }
}
</code></pre>
<p>自动配置器会跟根据传入的factoryClass.getName()到项目系统路径下所有的spring.factories文件中找到相应的key，从而加载里面的类。我们就选取这个mybatis-spring-boot-autoconfigure下的spring.factories文件</p>
<h4 id="auto-configure">Auto Configure</h4>
<p>org.springframework.boot.autoconfigure.EnableAutoConfiguration=<br>
org.mybatis.spring.boot.autoconfigure.MybatisAutoConfiguration<br>
进入org.mybatis.spring.boot.autoconfigure.MybatisAutoConfiguration中，又是一堆注解</p>
<pre><code class="language-java">@org.springframework.context.annotation.Configuration
@ConditionalOnClass({SqlSessionFactory.class, SqlSessionFactoryBean.class})
@ConditionalOnBean({DataSource.class})
@EnableConfigurationProperties({MybatisProperties.class})
@AutoConfigureAfter({DataSourceAutoConfiguration.class})
public class MybatisAutoConfiguration
{
  private static final Logger logger = LoggerFactory.getLogger(MybatisAutoConfiguration.class);
  private final MybatisProperties properties;
  private final Interceptor[] interceptors;
  private final ResourceLoader resourceLoader;
  private final DatabaseIdProvider databaseIdProvider;
  private final List&lt;ConfigurationCustomizer&gt; configurationCustomizers;
</code></pre>
<ol>
<li><code>@Configuration</code>是一个通过注解标注的springBean，</li>
<li><code>@ConditionalOnClass({ SqlSessionFactory.class, SqlSessionFactoryBean.class})</code>这个注解的意思是：当存在SqlSessionFactory.class, SqlSessionFactoryBean.class这两个类时才解析MybatisAutoConfiguration配置类,否则不解析这一个配置类。我们需要mybatis为我们返回会话对象，就必须有会话工厂相关类</li>
<li><code>@CondtionalOnBean(DataSource.class)</code>只处理已经被声明为bean的dataSource</li>
<li><code>@ConditionalOnMissingBean(MapperFactoryBean.class)</code>这个注解的意思是如果容器中不存在name指定的bean则创建bean注入，否则不执行以上配置可以保证sqlSessionFactory、sqlSessionTemplate、dataSource等mybatis所需的组件均可被自动配置，<code>@Configuration</code>注解已经提供了Spring的上下文环境，所以以上组件的配置方式与Spring启动时通过mybatis.xml文件进行配置起到一个效果。</li>
</ol>
<p>只要一个基于SpringBoot项目的类路径下存在SqlSessionFactory.class, SqlSessionFactoryBean.class，并且容器中已经注册了dataSourceBean，就可以触发自动化配置，意思说我们只要在maven的项目中加入了mybatis所需要的若干依赖，就可以触发自动配置，但引入mybatis原生依赖的话，每集成一个功能都要去修改其自动化配置类，那就得不到开箱即用的效果了。所以Spring-boot为我们提供了统一的starter可以直接配置好相关的类，触发自动配置所需的依赖(mybatis)如下：</p>
<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt;
    &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<p>因为maven依赖的传递性，我们只要依赖starter就可以依赖到所有需要自动配置的类，实现开箱即用的功能。也体现出Springboot简化了Spring框架带来的大量XML配置以及复杂的依赖管理，让开发人员可以更加关注业务逻辑的开发。<br>
再贴个盗的图SpringBoot的启动结构图</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1621306299869.webp" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[mysql概述六]]></title>
        <id>https://tinaxiawuhao.github.io/post/jytwMqgV3/</id>
        <link href="https://tinaxiawuhao.github.io/post/jytwMqgV3/">
        </link>
        <updated>2021-05-23T06:24:05.000Z</updated>
        <content type="html"><![CDATA[<h3 id="数据库优化">数据库优化</h3>
<h4 id="为什么要优化">为什么要优化</h4>
<ul>
<li>系统的吞吐量瓶颈往往出现在数据库的访问速度上</li>
<li>随着应用程序的运行，数据库的中的数据会越来越多，处理时间会相应变慢</li>
<li>数据是存放在磁盘上的，读写速度无法和内存相比</li>
</ul>
<p>优化原则：减少系统瓶颈，减少资源占用，增加系统的反应速度。</p>
<h3 id="数据库结构优化">数据库结构优化</h3>
<p>一个好的数据库设计方案对于数据库的性能往往会起到事半功倍的效果。需要考虑数据冗余、查询和更新的速度、字段的数据类型是否合理等多方面的内容。</p>
<h4 id="将字段很多的表分解成多个表">将字段很多的表分解成多个表</h4>
<p>对于字段较多的表，如果有些字段的使用频率很低，可以将这些字段分离出来形成新表。因为当一个表的数据量很大时，会由于使用频率低的字段的存在而变慢。</p>
<h4 id="增加中间表">增加中间表</h4>
<p>对于需要经常联合查询的表，可以建立中间表以提高查询效率。通过建立中间表，将需要通过联合查询的数据插入到中间表中，然后将原来的联合查询改为对中间表的查询。</p>
<h4 id="增加冗余字段">增加冗余字段</h4>
<p>设计数据表时应尽量遵循范式理论的规约，尽可能的减少冗余字段，让数据库设计看起来精致、优雅。但是，合理的加入冗余字段可以提高查询速度。表的规范化程度越高，表和表之间的关系越多，需要连接查询的情况也就越多，性能也就越差。</p>
<p><strong>注意：冗余字段的值在一个表中修改了，就要想办法在其他表中更新，否则就会导致数据不一致的问题。</strong></p>
<h3 id="mysql数据库cpu飙满的话怎么处理">MySQL数据库cpu飙满的话怎么处理</h3>
<p>当 cpu 飙满时，先用操作系统命令 top 命令观察是不是 <code>mysqld</code> 占用导致的，如果不是，找出占用高的进程，并进行相关处理。</p>
<p>如果是 <code>mysqld</code> 造成的， <code>show processlist</code>，看看里面跑的 session 情况，是不是有消耗资源的 sql 在运行。找出消耗高的 sql，看看执行计划是否准确， index 是否缺失，或者实在是数据量太大造成。</p>
<p>一般来说，肯定要 kill 掉这些线程(同时观察 cpu 使用率是否下降)，等进行相应的调整(比如说加索引、改 sql、改内存参数)之后，再重新跑这些 SQL。</p>
<p>也有可能是每个 sql 消耗资源并不多，但是突然之间，有大量的 session 连进来导致 cpu 飙升，这种情况就需要跟应用一起来分析为何连接数会激增，再做出相应的调整，比如说限制连接数等</p>
<h3 id="大表优化">大表优化</h3>
<p>当MySQL单表记录数过大时，数据库的CRUD性能会明显下降，一些常见的优化措施如下：</p>
<ol>
<li><strong>限定数据的范围：</strong> 务必禁止不带任何限制数据范围条件的查询语句。比如：我们当用户在查询订单历史的时候，我们可以控制在一个月的范围内。；</li>
<li><strong>读/写分离：</strong> 经典的数据库拆分方案，主库负责写，从库负责读；</li>
<li><strong>缓存：</strong> 使用MySQL的缓存，另外对重量级、更新少的数据可以考虑使用应用级别的缓存；</li>
</ol>
<p>还有就是通过分库分表的方式进行优化，主要有垂直分表和水平分表</p>
<ol>
<li>
<p><strong>垂直分表：</strong></p>
<blockquote>
<p><strong>根据数据库里面数据表的相关性进行拆分。</strong> 例如，用户表中既有用户的登录信息又有用户的基本信息，可以将用户表拆分成两个单独的表，甚至放到单独的库做分库。</p>
</blockquote>
<p><strong>简单来说垂直拆分是指数据表列的拆分，把一张列比较多的表拆分为多张表。</strong> 如下图所示，这样来说大家应该就更容易理解了。</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1620975369610.jpeg" alt="" loading="lazy"></figure>
<p><strong>垂直拆分的优点：</strong> 可以使得行数据变小，在查询时减少读取的Block数，减少I/O次数。此外，垂直分区可以简化表的结构，易于维护。</p>
<p><strong>垂直拆分的缺点：</strong> 主键会出现冗余，需要管理冗余列，并会引起Join操作，可以通过在应用层进行Join来解决。此外，垂直分区会让事务变得更加复杂；</p>
<p><strong>适用场景</strong></p>
<ul>
<li>
<ul>
<li>1、如果一个表中某些列常用，另外一些列不常用</li>
<li>2、可以使数据行变小，一个数据页能存储更多数据，查询时减少I/O次数</li>
</ul>
</li>
</ul>
<p><strong>缺点</strong></p>
<ul>
<li>
<ul>
<li>有些分表的策略基于应用层的逻辑算法，一旦逻辑算法改变，整个分表逻辑都会改变，扩展性较差</li>
<li>对于应用层来说，逻辑算法增加开发成本</li>
<li>管理冗余列，查询所有数据需要join操作</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>水平分表：</strong></p>
<p><strong>保持数据表结构不变，通过某种策略存储数据分片。这样每一片数据分散到不同的表或者库中，达到了分布式的目的。 水平拆分可以支撑非常大的数据量。</strong></p>
<p>水平拆分是指数据表行的拆分，表的行数超过200万行时，就会变慢，这时可以把一张的表的数据拆成多张表来存放。举个例子：我们可以将用户信息表拆分成多个用户信息表，这样就可以避免单一表数据量过大对性能造成影响。</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1620975354396.jpeg" alt="" loading="lazy"></figure>
<p>水品拆分可以支持非常大的数据量。需要注意的一点是:分表仅仅是解决了单一表数据过大的问题，但由于表的数据还是在同一台机器上，其实对于提升MySQL并发能力没有什么意义，所以 <strong>水平拆分最好分库</strong> 。</p>
<p>水平拆分能够 <strong>支持非常大的数据量存储，应用端改造也少</strong>，但 <strong>分片事务难以解决</strong> ，跨界点Join性能较差，逻辑复杂。</p>
<p>《Java工程师修炼之道》的作者推荐 <strong>尽量不要对数据进行分片，因为拆分会带来逻辑、部署、运维的各种复杂度</strong> ，一般的数据表在优化得当的情况下支撑千万以下的数据量是没有太大问题的。如果实在要分片，尽量选择客户端分片架构，这样可以减少一次和中间件的网络I/O。</p>
<p><strong>适用场景</strong></p>
<ul>
<li>
<ul>
<li>1、表中的数据本身就有独立性，例如表中分表记录各个地区的数据或者不同时期的数据，特别是有些数据常用，有些不常用。</li>
<li>2、需要把数据存放在多个介质上。</li>
</ul>
</li>
</ul>
<p><strong>水平切分的缺点</strong></p>
<ul>
<li>
<ul>
<li>1、给应用增加复杂度，通常查询时需要多个表名，查询所有数据都需UNION操作</li>
<li>2、在许多数据库应用中，这种复杂度会超过它带来的优点，查询时会增加读一个索引层的磁盘次数</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="数据库分片两种常见方案">数据库分片两种常见方案</h4>
<ul>
<li>
<ul>
<li><strong>客户端代理：</strong> <strong>分片逻辑在应用端，封装在jar包中，通过修改或者封装JDBC层来实现。</strong> 当当网的 <strong>Sharding-JDBC</strong> 、阿里的TDDL是两种比较常用的实现。</li>
<li><strong>中间件代理：</strong> <strong>在应用和数据中间加了一个代理层。分片逻辑统一维护在中间件服务中。</strong> 我们现在谈的 <strong>Mycat</strong> 、360的Atlas、网易的DDB等等都是这种架构的实现。</li>
</ul>
</li>
</ul>
<h4 id="分库分表后面临的问题">分库分表后面临的问题</h4>
<ul>
<li>
<p><strong>事务支持</strong> 分库分表后，就成了分布式事务了。如果依赖数据库本身的分布式事务管理功能去执行事务，将付出高昂的性能代价； 如果由应用程序去协助控制，形成程序逻辑上的事务，又会造成编程方面的负担。</p>
</li>
<li>
<p><strong>跨库join</strong></p>
<p>只要是进行切分，跨节点Join的问题是不可避免的。但是良好的设计和切分却可以减少此类情况的发生。解决这一问题的普遍做法是分两次查询实现。在第一次查询的结果集中找出关联数据的id,根据这些id发起第二次请求得到关联数据。 分库分表方案产品</p>
</li>
<li>
<p><strong>跨节点的count,order by,group by以及聚合函数问题</strong> 这些是一类问题，因为它们都需要基于全部数据集合进行计算。多数的代理都不会自动处理合并工作。解决方案：与解决跨节点join问题的类似，分别在各个节点上得到结果后在应用程序端进行合并。和join不同的是每个结点的查询可以并行执行，因此很多时候它的速度要比单一大表快很多。但如果结果集很大，对应用程序内存的消耗是一个问题。</p>
</li>
<li>
<p><strong>数据迁移，容量规划，扩容等问题</strong> 来自淘宝综合业务平台团队，它利用对2的倍数取余具有向前兼容的特性（如对4取余得1的数对2取余也是1）来分配数据，避免了行级别的数据迁移，但是依然需要进行表级别的迁移，同时对扩容规模和分表数量都有限制。总得来说，这些方案都不是十分的理想，多多少少都存在一些缺点，这也从一个侧面反映出了Sharding扩容的难度。</p>
</li>
<li>
<p><strong>ID问题</strong></p>
</li>
<li>
<p>一旦数据库被切分到多个物理结点上，我们将不能再依赖数据库自身的主键生成机制。一方面，某个分区数据库自生成的ID无法保证在全局上是唯一的；另一方面，应用程序在插入数据之前需要先获得ID,以便进行SQL路由. 一些常见的主键生成策略</p>
<p><strong>UUID</strong> 使用UUID作主键是最简单的方案，但是缺点也是非常明显的。由于UUID非常的长，除占用大量存储空间外，最主要的问题是在索引上，在建立索引和基于索引进行查询时都存在性能问题。 <strong>Twitter的分布式自增ID算法Snowflake</strong> 在分布式系统中，需要生成全局UID的场合还是比较多的，twitter的snowflake解决了这种需求，实现也还是很简单的，除去配置信息，核心代码就是毫秒级时间41位 机器ID 10位 毫秒内序列12位。</p>
</li>
<li>
<p>跨分片的排序分页</p>
<p>般来讲，分页时需要按照指定字段进行排序。当排序字段就是分片字段的时候，我们通过分片规则可以比较容易定位到指定的分片，而当排序字段非分片字段的时候，情况就会变得比较复杂了。为了最终结果的准确性，我们需要在不同的分片节点中将数据进行排序并返回，并将不同分片返回的结果集进行汇总和再次排序，最后再返回给用户。如下图所示：</p>
</li>
</ul>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1620975324802.png" alt="" loading="lazy"></figure>
<h3 id="mysql复制原理以及流程">MySQL复制原理以及流程</h3>
<p>主从复制：将主数据库中的DDL和DML操作通过二进制日志（BINLOG）传输到从数据库上，然后将这些日志重新执行（重做）；从而使得从数据库的数据与主数据库保持一致。</p>
<h4 id="主从复制的作用">主从复制的作用</h4>
<ol>
<li>主数据库出现问题，可以切换到从数据库。</li>
<li>可以进行数据库层面的读写分离。</li>
<li>可以在从数据库上进行日常备份。</li>
</ol>
<h4 id="mysql主从复制解决的问题">MySQL主从复制解决的问题</h4>
<ul>
<li>数据分布：随意开始或停止复制，并在不同地理位置分布数据备份</li>
<li>负载均衡：降低单个服务器的压力</li>
<li>高可用和故障切换：帮助应用程序避免单点失败</li>
<li>升级测试：可以用更高版本的MySQL作为从库</li>
</ul>
<h4 id="mysql主从复制工作原理">MySQL主从复制工作原理</h4>
<ul>
<li>在主库上把数据更高记录到二进制日志</li>
<li>从库将主库的日志复制到自己的中继日志</li>
<li>从库读取中继日志的事件，将其重放到从库数据中</li>
</ul>
<h4 id="基本原理流程3个线程以及之间的关联">基本原理流程，3个线程以及之间的关联</h4>
<p><strong>主</strong>：<code>binlog</code>线程——记录下所有改变了数据库数据的语句，放进master上的<code>binlog</code>中；</p>
<p><strong>从</strong>：io线程——在使用start slave 之后，负责从master上拉取 <code>binlog</code> 内容，放进自己的<code>relay log</code>中；</p>
<p><strong>从</strong>：sql执行线程——执行<code>relay log</code>中的语句；</p>
<h4 id="复制过程">复制过程</h4>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1620975307300.jpeg" alt="" loading="lazy"></figure>
<p>Binary log：主数据库的二进制日志</p>
<p>Relay log：从服务器的中继日志</p>
<p>第一步：master在每个事务更新数据完成之前，将该操作记录串行地写入到binlog文件中。</p>
<p>第二步：salve开启一个I/O Thread，该线程在master打开一个普通连接，主要工作是binlog dump process。如果读取的进度已经跟上了master，就进入睡眠状态并等待master产生新的事件。I/O线程最终的目的是将这些事件写入到中继日志中。</p>
<p>第三步：SQL Thread会读取中继日志，并顺序执行该日志中的SQL事件，从而与主数据库中的数据保持一致。</p>
<h3 id="读写分离解决方案">读写分离解决方案</h3>
<p>读写分离是依赖于主从复制，而主从复制又是为读写分离服务的。因为主从复制要求slave不能写只能读（如果对slave执行写操作，那么show slave status将会呈现Slave_SQL_Running=NO，此时你需要按照前面提到的手动同步一下slave）。</p>
<ol>
<li>
<p><strong>方案一</strong></p>
<p>使用mysql-proxy代理</p>
<p>优点：直接实现读写分离和负载均衡，不用修改代码，master和slave用一样的帐号，mysql官方不建议实际生产中使用</p>
<p>缺点：降低性能， 不支持事务</p>
</li>
<li>
<p><strong>方案二</strong></p>
<p>使用AbstractRoutingDataSource+aop+annotation在dao层决定数据源。</p>
<p>如果采用了mybatis， 可以将读写分离放在ORM层，比如mybatis可以通过mybatis plugin拦截sql语句，所有的insert/update/delete都访问master库，所有的select 都访问salve库，这样对于dao层都是透明。 plugin实现时可以通过注解或者分析语句是读写方法来选定主从库。不过这样依然有一个问题， 也就是不支持事务， 所以我们还需要重写一下DataSourceTransactionManager， 将read-only的事务扔进读库， 其余的有读有写的扔进写库。</p>
</li>
<li>
<p><strong>方案三</strong></p>
<p>使用AbstractRoutingDataSource+aop+annotation在service层决定数据源，可以支持事务.</p>
<p>缺点：类内部方法通过this.xx()方式相互调用时，aop不会进行拦截，需进行特殊处理。</p>
</li>
</ol>
<h3 id="备份计划mysqldump以及xtranbackup的实现原理">备份计划，mysqldump以及xtranbackup的实现原理</h3>
<h4 id="1备份计划">(1)备份计划</h4>
<p>视库的大小来定，一般来说 100G 内的库，可以考虑使用 mysqldump 来做，因为 mysqldump更加轻巧灵活，备份时间选在业务低峰期，可以每天进行都进行全量备份(mysqldump 备份出来的文件比较小，压缩之后更小)。</p>
<p>100G 以上的库，可以考虑用 xtranbackup 来做，备份速度明显要比 mysqldump 要快。一般是选择一周一个全备，其余每天进行增量备份，备份时间为业务低峰期。</p>
<h4 id="2备份恢复时间">(2)备份恢复时间</h4>
<p>物理备份恢复快，逻辑备份恢复慢</p>
<p>这里跟机器，尤其是硬盘的速率有关系，以下列举几个仅供参考</p>
<pre><code class="language-java">20G的2分钟（mysqldump）

80G的30分钟(mysqldump)

111G的30分钟（mysqldump)

288G的3小时（xtra)

3T的4小时（xtra)
</code></pre>
<p>逻辑导入时间一般是备份时间的5倍以上</p>
<h4 id="3备份恢复失败如何处理">(3)备份恢复失败如何处理</h4>
<p>首先在恢复之前就应该做足准备工作，避免恢复的时候出错。比如说备份之后的有效性检查、权限检查、空间检查等。如果万一报错，再根据报错的提示来进行相应的调整。</p>
<h4 id="4mysqldump和xtrabackup实现原理">(4)mysqldump和xtrabackup实现原理</h4>
<p><strong>mysqldump</strong></p>
<blockquote>
<p><code>mysqldump</code> 属于逻辑备份。加入<code>–single-transaction</code> 选项可以进行一致性备份。后台进程会先设置 session 的事务隔离级别为 <code>RR(SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ)</code>，之后显式开启一个事务<code>(START TRANSACTION /*!40100 WITH CONSISTENTSNAPSHOT */)</code>，这样就保证了该事务里读到的数据都是事务事务时候的快照。之后再把表的数据读取出来。如果加上<code>–master-data=1</code> 的话，在刚开始的时候还会加一个数据库的读锁<code>(FLUSH TABLES WITH READ LOCK)</code>,等开启事务后，再记录下数据库此时 <code>binlog</code> 的位置<code>(showmaster status)</code>，马上解锁，再读取表的数据。等所有的数据都已经导完，就可以结束事务</p>
</blockquote>
<p><strong>Xtrabackup</strong></p>
<blockquote>
<p><code>xtrabackup</code> 属于物理备份，直接拷贝表空间文件，同时不断扫描产生的 redo 日志并保存下来。最后完成<code>innodb</code> 的备份后，会做一个 <code>flush engine logs</code>的操作(老版本在有 bug，在5.6 上不做此操作会丢数据)，确保所有的<code>redo log</code> 都已经落盘(涉及到事务的两阶段提交概念，因为 <code>xtrabackup</code> 并不拷贝 <code>binlog</code>，所以必须保证所有的 <code>redo log</code> 都落盘，否则可能会丢最后一组提交事务的数据)。这个时间点就是 <code>innodb</code> 完成备份的时间点，数据文件虽然不是一致性的，但是有这段时间的 redo 就可以让数据文件达到一致性(恢复的时候做的事情)。然后还需要<code>flush tables with read lock</code>，把 <code>myisam</code> 等其他引擎的表给备份出来，备份完后解锁。这样就做到了完美的热备。</p>
</blockquote>
<h3 id="数据表损坏的修复方式">数据表损坏的修复方式</h3>
<p>使用 <code>myisamchk</code> 来修复，具体步骤：</p>
<ul>
<li>1）修复前将mysql服务停止。</li>
<li>2）打开命令行方式，然后进入到mysql的/bin目录。</li>
<li>3）执行<code>myisamchk –recover</code> 数据库所在路径/*.MYI</li>
</ul>
<p>使用<code>repair table</code> 或者 <code>OPTIMIZE table</code>命令来修复，<code>REPAIR TABLE table_name</code> 修复表<code>OPTIMIZE TABLE table_name</code> 优化表 <code>REPAIR TABLE</code> 用于修复被破坏的表。 <code>OPTIMIZE TABLE</code> 用于回收闲置的数据库空间，当表上的数据行被删除时，所占据的磁盘空间并没有立即被回收，使用了<code>OPTIMIZE TABLE</code>命令后这些空间将被回收，并且对磁盘上的数据行进行重排（注意：是磁盘上，而非数据库）</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[mysql概述五]]></title>
        <id>https://tinaxiawuhao.github.io/post/lbX34toJL/</id>
        <link href="https://tinaxiawuhao.github.io/post/lbX34toJL/">
        </link>
        <updated>2021-05-22T05:09:05.000Z</updated>
        <content type="html"><![CDATA[<h3 id="sql优化">SQL优化</h3>
<p>对于低性能的SQL语句的定位，最重要也是最有效的方法就是使用执行计划，MySQL提供了explain命令来查看语句的执行计划。 我们知道，不管是哪种数据库，或者是哪种数据库引擎，在对一条SQL语句进行执行的过程中都会做很多相关的优化，<strong>对于查询语句，最重要的优化方式就是使用索引</strong>。 而<strong>执行计划，就是显示数据库引擎对于SQL语句的执行的详细情况，其中包含了是否使用索引，使用什么索引，使用的索引的相关信息等</strong>。</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1620973419410.png" alt="" loading="lazy"></figure>
<p>执行计划包含的信息 <strong>id</strong> 有一组数字组成。表示一个查询中各个子查询的执行顺序;</p>
<ul>
<li>id相同执行顺序由上至下。</li>
<li>id不同，id值越大优先级越高，越先被执行。</li>
<li>id为null时表示一个结果集，不需要使用它查询，常出现在包含union等查询语句中。</li>
</ul>
<p><strong>select_type</strong> 每个子查询的查询类型，一些常见的查询类型。</p>
<table>
<thead>
<tr>
<th>id</th>
<th>select_type</th>
<th>description</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>SIMPLE</td>
<td>不包含任何子查询或union等查询</td>
</tr>
<tr>
<td>2</td>
<td>PRIMARY</td>
<td>包含子查询最外层查询就显示为 PRIMARY</td>
</tr>
<tr>
<td>3</td>
<td>SUBQUERY</td>
<td>在select或 where字句中包含的查询</td>
</tr>
<tr>
<td>4</td>
<td>DERIVED</td>
<td>from字句中包含的查询</td>
</tr>
<tr>
<td>5</td>
<td>UNION</td>
<td>出现在union后的查询语句中</td>
</tr>
<tr>
<td>6</td>
<td>UNION RESULT</td>
<td>从UNION中获取结果集，例如上文的第三个例子</td>
</tr>
</tbody>
</table>
<p><strong>type</strong>(非常重要，可以看到有没有走索引) 访问类型</p>
<ul>
<li><code>ALL</code> 扫描全表数据</li>
<li><code>index</code> 遍历索引</li>
<li><code>range</code> 索引范围查找</li>
<li><code>index_subquery</code> 在子查询中使用 <code>ref</code></li>
<li><code>unique_subquery</code> 在子查询中使用 <code>eq_ref</code></li>
<li><code>ref_or_null</code> 对Null进行索引的优化的 <code>ref</code></li>
<li><code>fulltext</code> 使用全文索引</li>
<li><code>ref</code> 使用非唯一索引查找数据</li>
<li><code>eq_ref</code> 在join查询中使用<code>PRIMARY KEY</code>  or  <code>UNIQUE NOT NULL</code>索引关联。</li>
</ul>
<p><strong>possible_keys</strong> 可能使用的索引，注意不一定会使用。查询涉及到的字段上若存在索引，则该索引将被列出来。当该列为 NULL时就要考虑当前的SQL是否需要优化了。</p>
<p><strong>key</strong> 显示MySQL在查询中实际使用的索引，若没有使用索引，显示为NULL。</p>
<p><strong>TIPS</strong>:查询中若使用了覆盖索引(覆盖索引：索引的数据覆盖了需要查询的所有数据)，则该索引仅出现在key列表中</p>
<p><strong>key_length</strong> 索引长度</p>
<p><strong>ref</strong> 表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值</p>
<p><strong>rows</strong> 返回估算的结果集数目，并不是一个准确的值。</p>
<p><strong>extra</strong> 的信息非常丰富，常见的有：</p>
<ol>
<li>Using index 使用覆盖索引</li>
<li>Using where 使用了用where子句来过滤结果集</li>
<li>Using filesort 使用文件排序，使用非索引列进行排序时出现，非常消耗性能，尽量优化。</li>
<li>Using temporary 使用了临时表 sql优化的目标可以参考阿里开发手册</li>
</ol>
<p>【推荐】SQL性能优化的目标：至少要达到 range 级别，要求是ref级别，如果可以是consts最好。</p>
<p>说明：</p>
<p>1） consts 单表中最多只有一个匹配行（主键或者唯一索引），在优化阶段即可读取到数据。</p>
<p>2） ref 指的是使用普通的索引（normal index）。</p>
<p>3） range 对索引进行范围检索。  反例：explain表的结果，type=index，索引物理文件全扫描，速度非常慢，这个index级别比较range还低，与全表扫描是小巫见大巫。</p>
<h3 id="sql执行顺序">SQL执行顺序</h3>
<p>mysql执行sql的顺序从 From 开始，以下是执行的顺序流程</p>
<ol>
<li>
<p>FROM  <code>FROM table1 left join table2 on</code> 将table1和table2中的数据产生笛卡尔积，生成Temp1</p>
</li>
<li>
<p>JOIN <code>JOIN table2</code>  所以先是确定表，再确定关联条件</p>
</li>
<li>
<p>ON <code>ON table1.column = table2.columu</code> 确定表的绑定条件 由Temp1产生中间表Temp2</p>
</li>
<li>
<p>WHERE  对中间表Temp2产生的结果进行过滤  产生中间表Temp3</p>
</li>
<li>
<p>GROUP BY 对中间表Temp3进行分组，产生中间表Temp4</p>
</li>
<li>
<p>HAVING  对分组后的记录进行聚合 产生中间表Temp5</p>
</li>
<li>
<p>SELECT  对中间表Temp5进行列筛选，产生中间表 Temp6</p>
</li>
<li>
<p>DISTINCT 对中间表 Temp6进行去重，产生中间表 Temp7</p>
</li>
<li>
<p>ORDER BY 对Temp7中的数据进行排序，产生中间表Temp8</p>
</li>
<li>
<p>LIMIT 对中间表Temp8进行分页，产生中间表Temp9</p>
</li>
</ol>
<h3 id="sql的生命周期">SQL的生命周期</h3>
<ol>
<li>与服务器建立连接，客户端发送一条查询给服务器</li>
<li>服务器先检查查询缓存，如果命中了缓存则立刻返回存储在缓存中的结果，否则执行下一步</li>
<li>服务端进行sql解析，预处理，再由查询优化器生成对应的查询执行计划</li>
<li>mysql根据优化器提供的执行计划，调用存储引擎的api来执行查询</li>
<li>通过步骤一的连接，发送结果到客户端</li>
<li>关掉连接，释放资源</li>
</ol>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1620973396577.png" alt="" loading="lazy"></figure>
<h3 id="优化大表数据查询">优化大表数据查询</h3>
<ol>
<li>优化shema、sql语句+索引；</li>
<li>加缓存，<code>memcached</code>, <code>redis</code>；</li>
<li>主从复制，读写分离；</li>
<li>垂直拆分，根据你模块的耦合度，将一个大的系统分为多个小的系统，也就是分布式系统；</li>
<li>水平切分，针对数据量大的表，这一步最麻烦，最能考验技术水平，要选择一个合理的sharding key, 为了有好的查询效率，表结构也要改动，做一定的冗余，应用也要改，sql中尽量带sharding key，将数据定位到限定的表上去查，而不是扫描全部的表；</li>
</ol>
<h3 id="超大分页怎么处理">超大分页怎么处理</h3>
<p>超大的分页一般从两个方向上来解决.</p>
<ul>
<li>数据库层面,这也是我们主要集中关注的(虽然收效没那么大),类似于<code>select * from table where age &gt; 20 limit 1000000,10</code>这种查询其实也是有可以优化的余地的. 这条语句需要<code>load1000000</code>数据然后基本上全部丢弃,只取10条当然比较慢. 当时我们可以修改为<code>select * from table where id in (select id from table where age &gt; 20 limit 1000000,10)</code>.这样虽然也load了一百万的数据,但是由于索引覆盖,要查询的所有字段都在索引中,所以速度会很快. 同时如果ID连续的好,我们还可以<code>select * from table where id &gt; 1000000 limit 10</code>,效率也是不错的,优化的可能性有许多种,但是核心思想都一样,就是减少load的数据.</li>
<li>从需求的角度减少这种请求…主要是不做类似的需求(直接跳转到几百万页之后的具体某一页.只允许逐页查看或者按照给定的路线走,这样可预测,可缓存)以及防止ID泄漏且连续被人恶意攻击.</li>
</ul>
<p>解决超大分页,其实主要是靠缓存,可预测性的提前查到内容,缓存至<code>redis</code>等k-V数据库中,直接返回即可.</p>
<p>在阿里巴巴《Java开发手册》中,对超大分页的解决办法是类似于上面提到的第一种.</p>
<p>【推荐】利用延迟关联或者子查询优化超多分页场景。  说明：MySQL并不是跳过offset行，而是取offset+N行，然后返回放弃前offset行，返回N行，那当offset特别大的时候，效率就非常的低下，要么控制返回的总页数，要么对超过特定阈值的页数进行SQL改写。  正例：先快速定位需要获取的id段，然后再关联：  <code>SELECT a.* FROM 表1 a, (select id from 表1 where 条件 LIMIT 100000,20 ) b where a.id=b.id</code></p>
<h3 id="mysql-分页">mysql 分页</h3>
<p>LIMIT 子句可以被用于强制 SELECT 语句返回指定的记录数。LIMIT 接受一个或两个数字参数。参数必须是一个整数常量。如果给定两个参数，第一个参数指定第一个返回记录行的偏移量，第二个参数指定返回记录行的最大数目。初始记录行的偏移量是 0(而不是 1)</p>
<pre><code class="language-mysql">mysql&gt; SELECT * FROM table LIMIT 5,10; // 检索记录行 6-15 
</code></pre>
<p>为了检索从某一个偏移量到记录集的结束所有的记录行，可以指定第二个参数为 -1：</p>
<pre><code class="language-mysql">mysql&gt; SELECT * FROM table LIMIT 95,-1; // 检索记录行 96-last. 
</code></pre>
<p>如果只给定一个参数，它表示返回最大的记录行数目：</p>
<pre><code class="language-mysql">mysql&gt; SELECT * FROM table LIMIT 5; //检索前 5 个记录行 
</code></pre>
<p>换句话说，LIMIT n 等价于 LIMIT 0,n。</p>
<h3 id="慢查询日志">慢查询日志</h3>
<p>用于记录执行时间超过某个临界值的SQL日志，用于快速定位慢查询，为我们的优化做参考。</p>
<p><strong>开启慢查询日志</strong></p>
<p>配置项：<code>slow_query_log</code></p>
<p>可以使用<code>show variables like ‘slov_query_log’</code>查看是否开启，如果状态值为OFF，可以使用<code>set GLOBAL slow_query_log = on</code>来开启，它会在<code>datadir</code>下产生一个<code>xxx-slow.log</code>的文件。</p>
<p><strong>设置临界时间</strong></p>
<p>配置项：<code>long_query_time</code></p>
<p>查看：<code>show VARIABLES like 'long_query_time'</code>，单位秒</p>
<p>设置：<code>set long_query_time=0.5</code></p>
<p>实操时应该从长时间设置到短的时间，即将最慢的SQL优化掉</p>
<p>查看日志，一旦SQL超过了我们设置的临界时间就会被记录到<code>xxx-slow.log</code>中</p>
<h4 id="慢查询处理">慢查询处理</h4>
<p>在业务系统中，除了使用主键进行的查询，其他的会在测试库上测试其耗时，慢查询的统计主要由运维在做，会定期将业务中的慢查询反馈给我们。</p>
<p>慢查询的优化首先要搞明白慢的原因是什么？ 是查询条件没有命中索引？是load了不需要的数据列？还是数据量太大？</p>
<p>所以优化也是针对这三个方向来的，</p>
<ul>
<li>首先分析语句，看看是否load了额外的数据，可能是查询了多余的行并且抛弃掉了，可能是加载了许多结果中并不需要的列，对语句进行分析以及重写。</li>
<li>分析语句的执行计划，然后获得其使用索引的情况，之后修改语句或者修改索引，使得语句可以尽可能的命中索引。</li>
<li>如果对语句的优化已经无法进行，可以考虑表中的数据量是否太大，如果是的话可以进行横向或者纵向的分表。</li>
</ul>
<h3 id="主键必要性">主键必要性</h3>
<p>主键是数据库确保数据行在整张表唯一性的保障，即使业务上本张表没有主键，也建议添加一个自增长的ID列作为主键。设定了主键之后，在后续的删改查的时候可能更加快速以及确保操作数据范围安全。</p>
<h4 id="主键使用自增id还是uuid">主键使用自增ID还是UUID</h4>
<p>推荐使用自增ID，不要使用UUID。</p>
<p>因为在InnoDB存储引擎中，主键索引是作为聚簇索引存在的，也就是说，主键索引的B+树叶子节点上存储了主键索引以及全部的数据(按照顺序)，如果主键索引是自增ID，那么只需要不断向后排列即可，如果是UUID，由于到来的ID与原来的大小不确定，会造成非常多的数据插入，数据移动，然后导致产生很多的内存碎片，进而造成插入性能的下降。</p>
<p>总之，在数据量大一些的情况下，用自增主键性能会好一些。</p>
<p>由于主键是聚簇索引，如果没有主键，InnoDB会选择一个唯一键来作为聚簇索引，如果没有唯一键，会生成一个隐式的主键。</p>
<p><strong>字段为什么要求定义为not null</strong></p>
<p>null值会占用更多的字节，且会在程序中造成很多与预期不符的情况。</p>
<p><strong>如果要存储用户的密码散列，应该使用什么字段进行存储？</strong></p>
<p>密码散列，盐，用户身份证号等固定长度的字符串应该使用char而不是varchar来存储，这样可以节省空间且提高检索效率。</p>
<h3 id="优化查询过程中的数据访问">优化查询过程中的数据访问</h3>
<ul>
<li>访问数据太多导致查询性能下降</li>
<li>确定应用程序是否在检索大量超过需要的数据，可能是太多行或列</li>
<li>确认MySQL服务器是否在分析大量不必要的数据行</li>
<li>避免犯如下SQL语句错误
<ul>
<li>查询不需要的数据。解决办法：使用limit解决</li>
<li>多表关联返回全部列。解决办法：指定列名</li>
<li>总是返回全部列。解决办法：避免使用SELECT *</li>
<li>重复查询相同的数据。解决办法：可以缓存数据，下次直接读取缓存</li>
<li>是否在扫描额外的记录。解决办法：
<ul>
<li>使用explain进行分析，如果发现查询需要扫描大量的数据，但只返回少数的行，可以通过如下技巧去优化：
<ul>
<li>使用索引覆盖扫描，把所有的列都放到索引中，这样存储引擎不需要回表获取对应行就可以返回结果。</li>
<li>改变数据库和表的结构，修改数据表范式</li>
<li>重写SQL语句，让优化器可以以更优的方式执行查询。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="优化长难的查询语句">优化长难的查询语句</h3>
<ul>
<li>一个复杂查询还是多个简单查询</li>
<li>MySQL内部每秒能扫描内存中上百万行数据，相比之下，响应数据给客户端就要慢得多</li>
<li>使用尽可能小的查询是好的，但是有时将一个大的查询分解为多个小的查询是很有必要的。</li>
<li>切分查询</li>
<li>将一个大的查询分为多个小的相同的查询</li>
<li>一次性删除1000万的数据要比一次删除1万，暂停一会的方案更加损耗服务器开销。</li>
<li>分解关联查询，让缓存的效率更高。</li>
<li>执行单个查询可以减少锁的竞争。</li>
<li>在应用层做关联更容易对数据库进行拆分。</li>
<li>查询效率会有大幅提升。</li>
<li>较少冗余记录的查询。</li>
</ul>
<h3 id="优化特定类型的查询语句">优化特定类型的查询语句</h3>
<ul>
<li>count(*)会忽略所有的列，直接统计所有列数，不要使用count(列名)</li>
<li>MyISAM中，没有任何where条件的count(*)非常快。</li>
<li>当有where条件时，MyISAM的count统计不一定比其它引擎快。</li>
<li>可以使用explain查询近似值，用近似值替代count(*)</li>
<li>增加汇总表</li>
<li>使用缓存</li>
</ul>
<h3 id="优化关联查询">优化关联查询</h3>
<ul>
<li>确定ON或者USING子句中是否有索引。</li>
<li>确保GROUP BY和ORDER BY只有一个表中的列，这样MySQL才有可能使用索引。</li>
</ul>
<h3 id="优化子查询">优化子查询</h3>
<ul>
<li>用关联查询替代</li>
<li>优化GROUP BY和DISTINCT
<ul>
<li>这两种查询可以使用索引来优化，是最有效的优化方法</li>
</ul>
</li>
<li>关联查询中，使用标识列分组的效率更高</li>
<li>如果不需要ORDER BY，进行GROUP BY时加ORDER BY NULL，MySQL不会再进行文件排序。</li>
<li>WITH ROLLUP超级聚合，可以挪到应用程序处理</li>
</ul>
<h3 id="优化limit分页">优化LIMIT分页</h3>
<ul>
<li>LIMIT偏移量大的时候，查询效率较低</li>
<li>可以记录上次查询的最大ID，下次查询时直接根据该ID来查询</li>
</ul>
<h3 id="优化union查询">优化UNION查询</h3>
<ul>
<li>UNION ALL的效率高于UNION</li>
</ul>
<h3 id="优化where子句">优化WHERE子句</h3>
<p>对于此类问题，先说明如何定位低效SQL语句，然后根据SQL语句可能低效的原因做排查，先从索引着手，如果索引没有问题，考虑以上几个方面，数据访问的问题，长难查询句的问题还是一些特定类型优化的问题，逐一回答。</p>
<p>SQL语句优化的一些方法？</p>
<ul>
<li>
<p>1.对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。</p>
</li>
<li>
<p>2.应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描，如：</p>
<pre><code class="language-mysql">select id from t where num is null 
-- 可以在num上设置默认值0，确保表中num列没有null值，然后这样查询： 
select id from t where num=0
</code></pre>
</li>
<li>
<p>3.应尽量避免在 where 子句中使用!=或&lt;&gt;操作符，否则引擎将放弃使用索引而进行全表扫描。</p>
</li>
<li>
<p>4.应尽量避免在 where 子句中使用or 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描，如：</p>
<pre><code class="language-mysql">select id from t where num=10 or num=20 
-- 可以这样查询： 
select id from t where num=10 union all select id from t where num=20
</code></pre>
</li>
<li>
<p>5.in 和 not in 也要慎用，否则会导致全表扫描，如：</p>
<pre><code class="language-mysql">select id from t where num in(1,2,3)  
-- 对于连续的数值，能用 between 就不要用 in 了： 
select id from t where num between 1 and 3
</code></pre>
</li>
<li>
<p>6.下面的查询也将导致全表扫描：</p>
<pre><code class="language-mysql">select id from t where name like ‘%李%’ -- 若要提高效率，可以考虑全文检索。
</code></pre>
</li>
<li>
<p>7.如果在 where 子句中使用参数，也会导致全表扫描。因为SQL只有在运行时才会解析局部变量，但优化程序不能将访问计划的选择推迟到运行时；它必须在编译时进行选择。然 而，如果在编译时建立访问计划，变量的值还是未知的，因而无法作为索引选择的输入项。如下面语句将进行全表扫描：</p>
<pre><code class="language-mysql">select id from t where num=@num 
-- 可以改为强制查询使用索引： 
select id from t with(index(索引名)) where num=@num
</code></pre>
</li>
<li>
<p>8.应尽量避免在 where 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描。如：</p>
<pre><code class="language-mysql">select id from t where num/2=100 
-- 应改为: 
select id from t where num=100*2
</code></pre>
</li>
<li>
<p>9.应尽量避免在where子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描。如：</p>
<pre><code class="language-mysql">select id from t where substring(name,1,3)=’abc’ 
-- name以abc开头的id应改为: 
select id from t where name like ‘abc%’
</code></pre>
</li>
<li>
<p>10.不要在 where 子句中的“=”左边进行函数、算术运算或其他表达式运算，否则系统将可能无法正确使用索引。</p>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[mysql概述四]]></title>
        <id>https://tinaxiawuhao.github.io/post/QKdNIC7pG/</id>
        <link href="https://tinaxiawuhao.github.io/post/QKdNIC7pG/">
        </link>
        <updated>2021-05-21T03:23:06.000Z</updated>
        <content type="html"><![CDATA[<h3 id="视图">视图</h3>
<blockquote>
<p>为了提高复杂SQL语句的复用性和表操作的安全性，MySQL数据库管理系统提供了视图特性。所谓视图，本质上是一种虚拟表，在物理上是不存在的，其内容与真实的表相似，包含一系列带有名称的列和行数据。但是，视图并不在数据库中以储存的数据值形式存在。行和列数据来自定义视图的查询所引用基本表，并且在具体引用视图时动态生成。</p>
</blockquote>
<p>视图使开发者只关心感兴趣的某些特定数据和所负责的特定任务，只能看到视图中所定义的数据，而不是视图所引用表中的数据，从而提高了数据库中数据的安全性。</p>
<h4 id="特点">特点</h4>
<p>视图的特点如下:</p>
<ul>
<li>视图的列可以来自不同的表，是表的抽象和在逻辑意义上建立的新关系。</li>
<li>视图是由基本表(实表)产生的表(虚表)。</li>
<li>视图的建立和删除不影响基本表。</li>
<li>对视图内容的更新(添加，删除和修改)直接影响基本表。</li>
<li>当视图来自多个基本表时，不允许添加和删除数据。</li>
</ul>
<p>视图的操作包括创建视图，查看视图，删除视图和修改视图。</p>
<h4 id="使用场景">使用场景</h4>
<p>视图根本用途：简化sql查询，提高开发效率。如果说还有另外一个用途那就是兼容老的表结构。</p>
<p>下面是视图的常见使用场景：</p>
<ul>
<li>重用SQL语句；</li>
<li>简化复杂的SQL操作。在编写查询后，可以方便的重用它而不必知道它的基本查询细节；</li>
<li>使用表的组成部分而不是整个表；</li>
<li>保护数据。可以给用户授予表的特定部分的访问权限而不是整个表的访问权限；</li>
<li>更改数据格式和表示。视图可返回与底层表的表示和格式不同的数据。</li>
</ul>
<h4 id="优点">优点</h4>
<ol>
<li>查询简单化。视图能简化用户的操作</li>
<li>数据安全性。视图使用户能以多种角度看待同一数据，能够对机密数据提供安全保护</li>
<li>逻辑数据独立性。视图对重构数据库提供了一定程度的逻辑独立性</li>
</ol>
<h4 id="缺点">缺点</h4>
<ol>
<li>性能。数据库必须把视图的查询转化成对基本表的查询，如果这个视图是由一个复杂的多表查询所定义，那么，即使是视图的一个简单查询，数据库也把它变成一个复杂的结合体，需要花费一定的时间。</li>
<li>修改限制。当用户试图修改视图的某些行时，数据库必须把它转化为对基本表的某些行的修改。事实上，当从视图中插入或者删除时，情况也是这样。对于简单视图来说，这是很方便的，但是，对于比较复杂的视图，可能是不可修改的</li>
</ol>
<p>这些视图有如下特征：</p>
<ol>
<li>
<p>有UNIQUE等集合操作符的视图。</p>
</li>
<li>
<p>有GROUP BY子句的视图。</p>
</li>
<li>
<p>有诸如AVG\SUM\MAX等聚合函数的视图。</p>
</li>
<li>
<p>使用DISTINCT关键字的视图。</p>
</li>
<li>
<p>连接表的视图（其中有些例外）</p>
</li>
</ol>
<h3 id="游标">游标</h3>
<blockquote>
<p>游标是系统为用户开设的一个数据缓冲区，存放SQL语句的执行结果，每个游标区都有一个名字。用户可以通过游标逐一获取记录并赋给主变量，交由主语言进一步处理。</p>
</blockquote>
<h3 id="存储过程与函数">存储过程与函数</h3>
<blockquote>
<p>存储过程是一个预编译的SQL语句，优点是允许模块化的设计，就是说只需要创建一次，以后在该程序中就可以调用多次。如果某次操作需要执行多次SQL，使用存储过程比单纯SQL语句执行要快。</p>
</blockquote>
<h4 id="优点-2">优点</h4>
<ol>
<li>
<p>存储过程是预编译过的，执行效率高。</p>
</li>
<li>
<p>存储过程的代码直接存放于数据库中，通过存储过程名直接调用，减少网络通讯。</p>
</li>
<li>
<p>安全性高，执行存储过程需要有一定权限的用户。</p>
</li>
<li>
<p>存储过程可以重复使用，减少数据库开发人员的工作量。</p>
</li>
</ol>
<h4 id="缺点-2">缺点</h4>
<p>1）调试麻烦，但是用 PL/SQL Developer 调试很方便！弥补这个缺点。</p>
<p>2）移植问题，数据库端代码当然是与数据库相关的。但是如果是做工程型项目，基本不存在移植问题。</p>
<p>3）重新编译问题，因为后端代码是运行前编译的，如果带有引用关系的对象发生改变时，受影响的存储过程、包将需要重新编译（不过也可以设置成运行时刻自动编译）。</p>
<p>4）如果在一个程序系统中大量的使用存储过程，到程序交付使用的时候随着用户需求的增加会导致数据结构的变化，接着就是系统的相关问题了，最后如果用户想维护该系统可以说是很难很难、而且代价是空前的，维护起来更麻烦。</p>
<h3 id="触发器">触发器</h3>
<blockquote>
<p>触发器是用户定义在关系表上的一类由事件驱动的特殊的存储过程。触发器是指一段代码，当触发某个事件时，自动执行这些代码。</p>
</blockquote>
<p>使用场景</p>
<ul>
<li>可以通过数据库中的相关表实现级联更改。</li>
<li>实时监控某张表中的某个字段的更改而需要做出相应的处理。</li>
<li>例如可以生成某些业务的编号。</li>
<li>注意不要滥用，否则会造成数据库及应用程序的维护困难。</li>
<li>大家需要牢记以上基础知识点，重点是理解数据类型CHAR和VARCHAR的差异，表存储引擎InnoDB和MyISAM的区别。</li>
</ul>
<h4 id="mysql中都有哪些触发器">MySQL中都有哪些触发器</h4>
<p>在MySQL数据库中有如下六种触发器：</p>
<ul>
<li>Before Insert</li>
<li>After Insert</li>
<li>Before Update</li>
<li>After Update</li>
<li>Before Delete</li>
<li>After Delete</li>
</ul>
<h3 id="sql语句">SQL语句</h3>
<p><strong>SQL语句分类</strong></p>
<ol>
<li>
<p>数据定义语言DDL（Data Ddefinition Language）CREATE，DROP，ALTER 主要为以上操作 即对逻辑结构等有操作的，其中包括表结构，视图和索引。</p>
</li>
<li>
<p>数据查询语言DQL（Data Query Language）SELECT 这个较为好理解 即查询操作，以select关键字。各种简单查询，连接查询等 都属于DQL。</p>
</li>
<li>
<p>数据操纵语言DML（Data Manipulation Language）INSERT，UPDATE，DELETE 主要为以上操作 即对数据进行操作的，对应上面所说的查询操作 DQL与DML共同构建了多数初级程序员常用的增删改查操作。而查询是较为特殊的一种 被划分到DQL中。</p>
</li>
<li>
<p>数据控制功能DCL（Data Control Language）GRANT，REVOKE，COMMIT，ROLLBACK 主要为以上操作 即对数据库安全性完整性等有操作的，可以简单的理解为权限控制等。</p>
</li>
</ol>
<h4 id="超键-候选键-主键-外键">超键、候选键、主键、外键</h4>
<ul>
<li>超键：在关系中能唯一标识元组的属性集称为关系模式的超键。一个属性可以为作为一个超键，多个属性组合在一起也可以作为一个超键。超键包含候选键和主键。</li>
<li>候选键：是最小超键，即没有冗余元素的超键。</li>
<li>主键：数据库表中对储存数据对象予以唯一和完整标识的数据列或属性的组合。一个数据列只能有一个主键，且主键的取值不能缺失，即不能为空值（Null）。</li>
<li>外键：在一个表中存在的另一个表的主键称此表的外键。</li>
</ul>
<h4 id="sql-约束">SQL 约束</h4>
<ul>
<li><code>NOT NULL</code>: 用于控制字段的内容一定不能为空（NULL）。</li>
<li><code>UNIQUE</code>: 控件字段内容不能重复，一个表允许有多个 Unique 约束。</li>
<li><code>PRIMARY KEY</code>: 也是用于控件字段内容不能重复，但它在一个表只允许出现一个。</li>
<li><code>FOREIGN KEY</code>: 用于预防破坏表之间连接的动作，也能防止非法数据插入外键列，因为它必须是它指向的那个表中的值之一。</li>
<li><code>CHECK</code>: 用于控制字段的值范围。</li>
</ul>
<h4 id="六种关联查询">六种关联查询</h4>
<ul>
<li>交叉连接（CROSS JOIN）</li>
<li>内连接（INNER JOIN）</li>
<li>外连接（LEFT JOIN/RIGHT JOIN）</li>
<li>联合查询（UNION与UNION ALL）</li>
<li>全连接（FULL JOIN）</li>
<li>交叉连接（CROSS JOIN）</li>
</ul>
<p><code>SELECT * FROM A,B(,C)</code>或者<code>SELECT * FROM A CROSS JOIN B (CROSS JOIN C)</code>#没有任何关联条件，结果是笛卡尔积，结果集会很大，没有意义，很少使用内连接（INNER JOIN）<code>SELECT * FROM A,B WHERE A.id=B.id</code>或者<code>SELECT * FROM A INNER JOIN B ON A.id=B.id</code>多表中同时符合某种条件的数据记录的集合，INNER JOIN可以缩写为JOIN</p>
<p>内连接分为三类</p>
<ul>
<li>等值连接：ON A.id=B.id</li>
<li>不等值连接：ON A.id &gt; B.id</li>
<li>自连接：SELECT * FROM A T1 INNER JOIN A T2 ON T1.id=T2.pid</li>
</ul>
<p>外连接（LEFT JOIN/RIGHT JOIN）</p>
<ul>
<li>左外连接：LEFT OUTER JOIN, 以左表为主，先查询出左表，按照ON后的关联条件匹配右表，没有匹配到的用NULL填充，可以简写成LEFT JOIN</li>
<li>右外连接：RIGHT OUTER JOIN, 以右表为主，先查询出右表，按照ON后的关联条件匹配左表，没有匹配到的用NULL填充，可以简写成RIGHT JOIN</li>
</ul>
<p>联合查询（UNION与UNION ALL）</p>
<pre><code class="language-mysql">SELECT * FROM A UNION SELECT * FROM B UNION ...
</code></pre>
<ul>
<li>就是把多个结果集集中在一起，UNION前的结果为基准，需要注意的是联合查询的列数要相等，相同的记录行会合并</li>
<li>如果使用UNION ALL，不会合并重复的记录行</li>
<li>效率 UNION ALL 高于 UNION</li>
</ul>
<p>全连接（FULL JOIN）</p>
<ul>
<li>
<p>MySQL不支持全连接</p>
</li>
<li>
<p>可以使用LEFT JOIN 和UNION和RIGHT JOIN联合使用</p>
<pre><code class="language-mysql">SELECT * FROM A LEFT JOIN B ON A.id=B.id UNIONSELECT * FROM A RIGHT JOIN B ON A.id=B.id
</code></pre>
</li>
</ul>
<p><strong>表连接展示</strong></p>
<p>有2张表，1张R、1张S，R表有ABC三列，S表有CD两列，表中各有三条记录。</p>
<p>R表</p>
<table>
<thead>
<tr>
<th>A</th>
<th>B</th>
<th>C</th>
</tr>
</thead>
<tbody>
<tr>
<td>a1</td>
<td>b1</td>
<td>c1</td>
</tr>
<tr>
<td>a2</td>
<td>b2</td>
<td>c2</td>
</tr>
<tr>
<td>a3</td>
<td>b3</td>
<td>c3</td>
</tr>
</tbody>
</table>
<p>S表</p>
<table>
<thead>
<tr>
<th>C</th>
<th>D</th>
</tr>
</thead>
<tbody>
<tr>
<td>c1</td>
<td>d1</td>
</tr>
<tr>
<td>c2</td>
<td>d2</td>
</tr>
<tr>
<td>c4</td>
<td>d3</td>
</tr>
</tbody>
</table>
<ol>
<li>交叉连接(笛卡尔积):</li>
</ol>
<pre><code class="language-mysql">select r.*,s.* from r,s
</code></pre>
<table>
<thead>
<tr>
<th>A</th>
<th>B</th>
<th>C</th>
<th>C</th>
<th>D</th>
</tr>
</thead>
<tbody>
<tr>
<td>a1</td>
<td>b1</td>
<td>c1</td>
<td>c1</td>
<td>d1</td>
</tr>
<tr>
<td>a2</td>
<td>b2</td>
<td>c2</td>
<td>c1</td>
<td>d1</td>
</tr>
<tr>
<td>a3</td>
<td>b3</td>
<td>c3</td>
<td>c1</td>
<td>d1</td>
</tr>
<tr>
<td>a1</td>
<td>b1</td>
<td>c1</td>
<td>c2</td>
<td>d2</td>
</tr>
<tr>
<td>a2</td>
<td>b2</td>
<td>c2</td>
<td>c2</td>
<td>d2</td>
</tr>
<tr>
<td>a3</td>
<td>b3</td>
<td>c3</td>
<td>c2</td>
<td>d2</td>
</tr>
<tr>
<td>a1</td>
<td>b1</td>
<td>c1</td>
<td>c4</td>
<td>d3</td>
</tr>
<tr>
<td>a2</td>
<td>b2</td>
<td>c2</td>
<td>c4</td>
<td>d3</td>
</tr>
<tr>
<td>a3</td>
<td>b3</td>
<td>c3</td>
<td>c4</td>
<td>d3</td>
</tr>
</tbody>
</table>
<ol>
<li>内连接结果：</li>
</ol>
<pre><code class="language-mysql">select r.*,s.* from r inner join s on r.c=s.c
</code></pre>
<table>
<thead>
<tr>
<th>A</th>
<th>B</th>
<th>C</th>
<th>C</th>
<th>D</th>
</tr>
</thead>
<tbody>
<tr>
<td>a1</td>
<td>b1</td>
<td>c1</td>
<td>c1</td>
<td>d1</td>
</tr>
<tr>
<td>a2</td>
<td>b2</td>
<td>c2</td>
<td>c2</td>
<td>d2</td>
</tr>
</tbody>
</table>
<ol>
<li>左连接结果：</li>
</ol>
<pre><code class="language-mysql">select r.*,s.* from r left join s on r.c=s.c
</code></pre>
<table>
<thead>
<tr>
<th>A</th>
<th>B</th>
<th>C</th>
<th>C</th>
<th>D</th>
</tr>
</thead>
<tbody>
<tr>
<td>a1</td>
<td>b1</td>
<td>c1</td>
<td>c1</td>
<td>d1</td>
</tr>
<tr>
<td>a2</td>
<td>b2</td>
<td>c2</td>
<td>c2</td>
<td>d2</td>
</tr>
<tr>
<td>a3</td>
<td>b3</td>
<td>c3</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<ol>
<li>右连接结果：</li>
</ol>
<pre><code class="language-mysql">select r.*,s.* from r right join s on r.c=s.c
</code></pre>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>A</td>
<td>B</td>
<td>C</td>
<td>C</td>
<td>D</td>
</tr>
<tr>
<td>a1</td>
<td>b1</td>
<td>c1</td>
<td>c1</td>
<td>d1</td>
</tr>
<tr>
<td>a2</td>
<td>b2</td>
<td>c2</td>
<td>c2</td>
<td>d2</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td>c4</td>
<td>d3</td>
</tr>
</tbody>
</table>
<ol>
<li>全表连接的结果（MySql不支持，Oracle支持）：</li>
</ol>
<pre><code class="language-mysql">select r.*,s.* from r full join s on r.c=s.c
</code></pre>
<table>
<thead>
<tr>
<th>A</th>
<th>B</th>
<th>C</th>
<th>C</th>
<th>D</th>
</tr>
</thead>
<tbody>
<tr>
<td>a1</td>
<td>b1</td>
<td>c1</td>
<td>c1</td>
<td>d1</td>
</tr>
<tr>
<td>a2</td>
<td>b2</td>
<td>c2</td>
<td>c2</td>
<td>d2</td>
</tr>
<tr>
<td>a3</td>
<td>b3</td>
<td>c3</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td>c4</td>
<td>d3</td>
</tr>
</tbody>
</table>
<h3 id="子查询">子查询</h3>
<ol>
<li>条件：一条SQL语句的查询结果做为另一条查询语句的条件或查询结果</li>
<li>嵌套：多条SQL语句嵌套使用，内部的SQL查询语句称为子查询。</li>
</ol>
<h4 id="子查询的三种情况">子查询的三种情况</h4>
<ol>
<li>
<p>子查询是单行单列的情况：结果集是一个值，父查询使用：=、 &lt;、 &gt; 等运算符</p>
<p>-- 查询工资最高的员工是谁？  <code>select * from employee where salary=(select max(salary) from employee);</code></p>
</li>
<li>
<p>子查询是多行单列的情况：结果集类似于一个数组，父查询使用：in 运算符</p>
<p>-- 查询工资最高的员工是谁？  <code>select * from employee where salary=(select max(salary) from employee);</code></p>
</li>
<li>
<p>子查询是多行多列的情况：结果集类似于一张虚拟表，不能用于where条件，用于select子句中做为子表</p>
<p>-- 1) 查询出2011年以后入职的员工信息 -- 2) 查询所有的部门信息，与上面的虚拟表中的信息比对，找出所有部门ID相等的员工。</p>
<pre><code class="language-mysql">SELECT
	* 
FROM
	dept d,
	( SELECT * FROM employee WHERE join_date &gt; '2011-1-1' ) e 
WHERE
	e.dept_id = d.id;
	
-- 使用表连接：
SELECT
	d.*,
	e.* 
FROM
	dept d
	INNER JOIN employee e ON d.id = e.dept_id 
WHERE
	e.join_date &gt; '2011-1-1'
</code></pre>
</li>
</ol>
<h4 id="mysql中-in-和-exists-区别">mysql中 in 和 exists 区别</h4>
<p>mysql中的in语句是把外表和内表作hash 连接，而exists语句是对外表作loop循环，每次loop循环再对内表进行查询。一直大家都认为exists比in语句的效率要高，这种说法其实是不准确的。这个是要区分环境的。</p>
<ol>
<li>如果查询的两个表大小相当，那么用in和exists差别不大。</li>
<li>如果两个表中一个较小，一个是大表，则子查询表大的用exists，子查询表小的用in。</li>
<li>not in 和not exists：如果查询语句使用了not in，那么内外表都进行全表扫描，没有用到索引；而not extsts的子查询依然能用到表上的索引。所以无论那个表大，用not exists都比not in要快。</li>
</ol>
<h4 id="varchar与char的区别">varchar与char的区别</h4>
<p><strong>char的特点</strong></p>
<ul>
<li>char表示定长字符串，长度是固定的；</li>
<li>如果插入数据的长度小于char的固定长度时，则用空格填充；</li>
<li>因为长度固定，所以存取速度要比varchar快很多，甚至能快50%，但正因为其长度固定，所以会占据多余的空间，是空间换时间的做法；</li>
<li>对于char来说，最多能存放的字符个数为255，和编码无关</li>
</ul>
<p><strong>varchar的特点</strong></p>
<ul>
<li>varchar表示可变长字符串，长度是可变的；</li>
<li>插入的数据是多长，就按照多长来存储；</li>
<li>varchar在存取方面与char相反，它存取慢，因为长度不固定，但正因如此，不占据多余的空间，是时间换空间的做法；</li>
<li>对于varchar来说，最多能存放的字符个数为65532</li>
</ul>
<p>总之，结合性能角度（char更快）和节省磁盘空间角度（varchar更小），具体情况还需具体来设计数据库才是妥当的做法。</p>
<h4 id="varchar50中50的涵义">varchar(50)中50的涵义</h4>
<p>最多存放50个字符，varchar(50)和(200)存储hello所占空间一样，但后者在排序时会消耗更多内存，因为order by col采用fixed_length计算col长度(memory引擎也一样)。在早期 MySQL 版本中， 50 代表字节数，现在代表字符数。</p>
<h4 id="int20中20的涵义">int(20)中20的涵义</h4>
<p>是指显示字符的长度。20表示最大显示宽度为20，但仍占4字节存储，存储范围不变；不影响内部存储，只是影响带 zerofill 定义的 int 时，前面补多少个 0，易于报表展示</p>
<h4 id="mysql为什么这么设计字段">mysql为什么这么设计字段</h4>
<p>对大多数应用没有意义，只是规定一些工具用来显示字符的个数；int(1)和int(20)存储和计算均一样；</p>
<h4 id="mysql中int10和char10以及varchar10的区别">mysql中int(10)和char(10)以及varchar(10)的区别</h4>
<ul>
<li>
<p>int(10)的10表示显示的数据的长度，不是存储数据的大小；chart(10)和varchar(10)的10表示存储数据的大小，即表示存储多少个字符。</p>
<p>int(10) 10位的数据长度 9999999999，占32个字节，int型4位</p>
<p>char(10) 10位固定字符串，不足补空格 最多10个字符</p>
<p>varchar(10) 10位可变字符串，不足补空格 最多10个字符</p>
</li>
<li>
<p>char(10)表示存储定长的10个字符，不足10个就用空格补齐，占用更多的存储空间</p>
</li>
<li>
<p>varchar(10)表示存储10个变长的字符，存储多少个就是多少个，空格也按一个字符存储，这一点是和char(10)的空格不同的，char(10)的空格表示占位不算一个字符</p>
</li>
</ul>
<h4 id="float和double的区别">FLOAT和DOUBLE的区别</h4>
<ul>
<li>FLOAT类型数据可以存储至多8位十进制数，并在内存中占4字节。</li>
<li>DOUBLE类型数据可以存储至多18位十进制数，并在内存中占8字节。</li>
</ul>
<h4 id="drop-delete与truncate的区别">drop、delete与truncate的区别</h4>
<p>三者都表示删除，但是三者有一些差别：</p>
<table>
<thead>
<tr>
<th></th>
<th>Delete</th>
<th>Truncate</th>
<th>Drop</th>
</tr>
</thead>
<tbody>
<tr>
<td>类型</td>
<td>属于DML</td>
<td>属于DDL</td>
<td>属于DDL</td>
</tr>
<tr>
<td>回滚</td>
<td>可回滚</td>
<td>不可回滚</td>
<td>不可回滚</td>
</tr>
<tr>
<td>删除内容</td>
<td>表结构还在，删除表的全部或者一部分数据行</td>
<td>表结构还在，删除表中的所有数据</td>
<td>从数据库中删除表，所有的数据行，索引和权限也会被删除</td>
</tr>
<tr>
<td>删除速度</td>
<td>删除速度慢，需要逐行删除</td>
<td>删除速度快</td>
<td>删除速度最快</td>
</tr>
</tbody>
</table>
<p>因此，在不再需要一张表的时候，用drop；在想删除部分数据行时候，用delete；在保留表而删除所有数据的时候用truncate。</p>
<h4 id="union与union-all的区别">UNION与UNION ALL的区别</h4>
<ul>
<li>如果使用UNION ALL，不会合并重复的记录行</li>
<li>效率 UNION 高于 UNION ALL</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[mysql概述三]]></title>
        <id>https://tinaxiawuhao.github.io/post/5ppmKteEb/</id>
        <link href="https://tinaxiawuhao.github.io/post/5ppmKteEb/">
        </link>
        <updated>2021-05-20T02:47:42.000Z</updated>
        <content type="html"><![CDATA[<h3 id="事务">事务</h3>
<p>事务是一个不可分割的数据库操作序列，也是数据库并发控制的基本单位，其执行的结果必须使数据库从一种一致性状态变到另一种一致性状态。事务是逻辑上的一组操作，要么都执行，要么都不执行。</p>
<p>事务最经典也经常被拿出来说例子就是转账了。</p>
<p>假如小明要给小红转账1000元，这个转账会涉及到两个关键操作就是：将小明的余额减少1000元，将小红的余额增加1000元。万一在这两个操作之间突然出现错误比如银行系统崩溃，导致小明余额减少而小红的余额没有增加，这样就不对了。事务就是保证这两个关键操作要么都成功，要么都要失败。</p>
<h4 id="事物的四大特性acid">事物的四大特性(ACID)</h4>
<p>关系性数据库需要遵循ACID规则，具体内容如下：</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1620962508572.png" alt="" loading="lazy"></figure>
<ol>
<li><strong>原子性：</strong> 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；</li>
<li><strong>一致性：</strong> 执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的；</li>
<li><strong>隔离性：</strong> 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；</li>
<li><strong>持久性：</strong> 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。</li>
</ol>
<h4 id="脏读幻读不可重复读">脏读？幻读？不可重复读？</h4>
<ul>
<li>脏读(Drity Read)：某个事务已更新一份数据，另一个事务在此时读取了同一份数据，由于某些原因，前一个RollBack了操作，则后一个事务所读取的数据就会是不正确的。</li>
<li>不可重复读(Non-repeatable read):在一个事务的两次查询之中数据不一致，这可能是两次查询过程中间插入了一个事务更新了原有的数据。</li>
<li>幻读(Phantom Read):在一个事务的两次查询中数据笔数不一致，例如有一个事务查询了几列(Row)数据，而另一个事务却在此时插入了新的几列数据，先前的事务在接下来的查询中，就会发现有几列数据是它先前所没有的。</li>
</ul>
<h4 id="事务的隔离级别">事务的隔离级别</h4>
<p>为了达到事务的四大特性，数据库定义了4种不同的事务隔离级别，由低到高依次为<code>Read uncommitted</code>、<code>Read committed</code>、<code>Repeatable read</code>、<code>Serializable</code>，这四个级别可以逐个解决脏读、不可重复读、幻读这几类问题。</p>
<table>
<thead>
<tr>
<th>隔离级别</th>
<th>脏读</th>
<th>不可重复读</th>
<th>幻影读</th>
</tr>
</thead>
<tbody>
<tr>
<td>READ-UNCOMMITTED</td>
<td>√</td>
<td>√</td>
<td>√</td>
</tr>
<tr>
<td>READ-COMMITTED</td>
<td>×</td>
<td>√</td>
<td>√</td>
</tr>
<tr>
<td>REPEATABLE-READ</td>
<td>×</td>
<td>×</td>
<td>√</td>
</tr>
<tr>
<td>SERIALIZABLE</td>
<td>×</td>
<td>×</td>
<td>×</td>
</tr>
</tbody>
</table>
<p><strong>SQL 标准定义了四个隔离级别：</strong></p>
<ul>
<li><strong>READ-UNCOMMITTED(读未提交)：</strong> 最低的隔离级别，允许读取尚未提交的数据变更，<strong>可能会导致脏读、幻读或不可重复读</strong>。</li>
<li><strong>READ-COMMITTED(读已提交)：</strong> 允许读取并发事务已经提交的数据，<strong>可以阻止脏读，但是幻读或不可重复读仍有可能发生</strong>。</li>
<li><strong>REPEATABLE-READ(可重复读)：</strong> 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，<strong>可以阻止脏读和不可重复读，但幻读仍有可能发生</strong>。</li>
<li><strong>SERIALIZABLE(串行化)：</strong> 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，<strong>该级别可以防止脏读、不可重复读以及幻读</strong>。</li>
</ul>
<p>这里需要注意的是：Mysql 默认采用的 <code>REPEATABLE_READ(可重复读)</code>隔离级别 Oracle 默认采用的 <code>READ_COMMITTED(读已提交)</code>隔离级别</p>
<p>事务隔离机制的实现基于锁机制和并发调度。其中并发调度使用的是MVVC（多版本并发控制），通过保存修改的旧版本信息来支持并发一致性读和回滚等特性。</p>
<p>因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是<strong>READ-COMMITTED(读已提交):</strong>，但是你要知道的是InnoDB 存储引擎默认使用 **REPEATABLE-READ(可重读)**并不会有任何性能损失。</p>
<p>InnoDB 存储引擎在 <strong>分布式事务</strong> 的情况下一般会用到**SERIALIZABLE(可串行化)**隔离级别。</p>
<h3 id="锁">锁</h3>
<p>当数据库有并发事务的时候，可能会产生数据的不一致，这时候需要一些机制来保证访问的次序，锁机制就是这样的一个机制。</p>
<p>就像酒店的房间，如果大家随意进出，就会出现多人抢夺同一个房间的情况，而在房间上装上锁，申请到钥匙的人才可以入住并且将房间锁起来，其他人只有等他使用完毕才可以再次使用。</p>
<h4 id="隔离级别与锁的关系">隔离级别与锁的关系</h4>
<p>在<code>Read Uncommitted</code>级别下，读取数据不需要加共享锁，这样就不会跟被修改的数据上的排他锁冲突</p>
<p>在<code>Read Committed</code>级别下，读操作需要加共享锁，但是在语句执行完以后释放共享锁；</p>
<p>在<code>Repeatable Read</code>级别下，读操作需要加共享锁，但是在事务提交之前并不释放共享锁，也就是必须等待事务执行完毕以后才释放共享锁。</p>
<p><code>SERIALIZABLE</code> 是限制性最强的隔离级别，因为该级别<strong>锁定整个范围的键</strong>，并一直持有锁，直到事务完成。</p>
<h4 id="按照锁的粒度分数据库锁">按照锁的粒度分数据库锁</h4>
<p>在关系型数据库中，可以<strong>按照锁的粒度把数据库锁分</strong>为行级锁(INNODB引擎)、表级锁(MYISAM引擎)和页级锁(BDB引擎 )。</p>
<h5 id="myisam和innodb存储引擎使用的锁">MyISAM和InnoDB存储引擎使用的锁</h5>
<ul>
<li>MyISAM采用表级锁(table-level locking)。</li>
<li>InnoDB支持行级锁(row-level locking)和表级锁，默认为行级锁</li>
</ul>
<p>行级锁，表级锁和页级锁对比</p>
<blockquote>
<p><strong>行级锁</strong> 行级锁是Mysql中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，但加锁的开销也最大。行级锁分为共享锁 和 排他锁。</p>
</blockquote>
<p>特点：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。</p>
<blockquote>
<p><strong>表级锁</strong> 表级锁是MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。最常使用的MYISAM与INNODB都支持表级锁定。表级锁定分为表共享读锁（共享锁）与表独占写锁（排他锁）。</p>
</blockquote>
<p>特点：开销小，加锁快；不会出现死锁；锁定粒度大，发出锁冲突的概率最高，并发度最低。</p>
<blockquote>
<p><strong>页级锁</strong> 页级锁是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折中的页级，一次锁定相邻的一组记录。</p>
</blockquote>
<p>特点：开销和加锁时间介于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般</p>
<h3 id="按照锁的类别分数据库锁">按照锁的类别分数据库锁</h3>
<p><strong>从锁的类别上来讲</strong>，有共享锁和排他锁。</p>
<blockquote>
<p>共享锁: 又叫做读锁。 当用户要进行数据的读取时，对数据加上共享锁。共享锁可以同时加上多个。</p>
</blockquote>
<blockquote>
<p>排他锁: 又叫做写锁。 当用户要进行数据的写入时，对数据加上排他锁。排他锁只可以加一个，他和其他的排他锁，共享锁都相斥。</p>
</blockquote>
<p>用上面的例子来说就是用户的行为有两种，一种是来看房，多个用户一起看房是可以接受的。 一种是真正的入住一晚，在这期间，无论是想入住的还是想看房的都不可以。</p>
<p>锁的粒度取决于具体的存储引擎，InnoDB实现了行级锁，页级锁，表级锁。</p>
<p>他们的加锁开销从大到小，并发能力也是从大到小。</p>
<h3 id="mysql中innodb引擎的行锁实现">MySQL中InnoDB引擎的行锁实现</h3>
<p>答：InnoDB是基于索引来完成行锁</p>
<p>例: <code>select * from tab_with_index where id = 1 for update;</code></p>
<p>for update 可以根据条件来完成行锁锁定，并且 id 是有索引键的列，如果 id 不是索引键那么InnoDB将完成表锁，并发将无从谈起</p>
<p><strong>InnoDB存储引擎的锁的算法有三种</strong></p>
<ul>
<li><code>Record lock</code>：单个行记录上的锁</li>
<li><code>Gap lock</code>：间隙锁，锁定一个范围，不包括记录本身</li>
<li><code>Next-key lock</code>：<code>record+gap</code> 锁定一个范围，包含记录本身</li>
</ul>
<h4 id="相关知识点">相关知识点：</h4>
<ol>
<li>
<p>innodb对于行的查询使用<code>next-key lock</code></p>
</li>
<li>
<p><code>Next-locking keying</code>为了解决<code>Phantom Problem</code>幻读问题</p>
</li>
<li>
<p>当查询的索引含有唯一属性时，将<code>next-key lock</code>降级为<code>record key</code></p>
</li>
<li>
<p>Gap锁设计的目的是为了阻止多个事务将记录插入到同一范围内，而这会导致幻读问题的产生</p>
</li>
<li>
<p>有两种方式显式关闭gap锁：（除了外键约束和唯一性检查外，其余情况仅使用<code>record lock</code>）</p>
<p>A. 将事务隔离级别设置为RC</p>
<p>B. 将参数innodb_locks_unsafe_for_binlog设置为1</p>
</li>
</ol>
<h3 id="死锁">死锁</h3>
<p>死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方的资源，从而导致恶性循环的现象。</p>
<p>常见的解决死锁的方法</p>
<ol>
<li>
<p>如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会。</p>
</li>
<li>
<p>在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率；</p>
</li>
<li>
<p>对于非常容易产生死锁的业务部分，可以尝试使用升级锁定颗粒度，通过表级锁定来减少死锁产生的概率；</p>
</li>
</ol>
<p>如果业务处理不好可以用分布式事务锁或者使用乐观锁</p>
<h3 id="数据库的乐观锁和悲观锁">数据库的乐观锁和悲观锁</h3>
<p>数据库管理系统（DBMS）中的并发控制的任务是确保在多个事务同时存取数据库中同一数据时不破坏事务的隔离性和统一性以及数据库的统一性。乐观并发控制（乐观锁）和悲观并发控制（悲观锁）是并发控制主要采用的技术手段。</p>
<blockquote>
<p><strong>悲观锁</strong>：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。在查询完数据的时候就把事务锁起来，直到提交事务。实现方式：使用数据库中的锁机制</p>
</blockquote>
<blockquote>
<p><strong>乐观锁</strong>：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。在修改数据的时候把事务锁起来，通过version的方式来进行锁定。实现方式：乐一般会使用版本号机制或CAS算法实现。</p>
</blockquote>
<h4 id="两种锁的使用场景">两种锁的使用场景</h4>
<p>从上面对两种锁的介绍，我们知道两种锁各有优缺点，不可认为一种好于另一种，像<strong>乐观锁适用于写比较少的情况下（多读场景）</strong>，即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。</p>
<p>但如果是多写的情况，一般会经常产生冲突，这就会导致上层应用会不断的进行retry，这样反倒是降低了性能，所以<strong>一般多写的场景下用悲观锁就比较合适。</strong></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[mysql概述二]]></title>
        <id>https://tinaxiawuhao.github.io/post/QzFPAEzVT/</id>
        <link href="https://tinaxiawuhao.github.io/post/QzFPAEzVT/">
        </link>
        <updated>2021-05-19T09:20:46.000Z</updated>
        <content type="html"><![CDATA[<h3 id="索引">索引</h3>
<blockquote>
<p>索引是一种特殊的文件(InnoDB数据表上的索引是表空间的一个组成部分)，它们包含着对数据表里所有记录的引用指针。</p>
</blockquote>
<blockquote>
<p>索引是一种数据结构。数据库索引，是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据。索引的实现通常使用B树及其变种B+树。</p>
</blockquote>
<p>更通俗的说，索引就相当于目录。为了方便查找书中的内容，通过对内容建立索引形成目录。索引是一个文件，它是要占据物理空间的。</p>
<h3 id="索引的基本原理">索引的基本原理</h3>
<p>索引用来快速地寻找那些具有特定值的记录。如果没有索引，一般来说执行查询时遍历整张表。</p>
<p>索引的原理很简单，就是把无序的数据变成有序的查询</p>
<ol>
<li>把创建了索引的列的内容进行排序</li>
<li>对排序结果生成倒排表</li>
<li>在倒排表内容上拼上数据地址链</li>
<li>在查询的时候，先拿到倒排表内容，再取出数据地址链，从而拿到具体数据</li>
</ol>
<h3 id="索引优缺点">索引优缺点</h3>
<h4 id="优点">优点</h4>
<ul>
<li>可以大大加快数据的检索速度，这也是创建索引的最主要的原因。</li>
<li>通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能。</li>
</ul>
<h4 id="缺点">缺点</h4>
<ul>
<li>时间方面：创建索引和维护索引要耗费时间，具体地，当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，会降低增/改/删的执行效率；</li>
<li>空间方面：索引需要占物理空间。</li>
</ul>
<h3 id="使用场景重点">使用场景（重点）</h3>
<h4 id="where">where</h4>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1620897817779.png" alt="" loading="lazy"></figure>
<p>上图中，根据id查询记录，因为id字段仅建立了主键索引，因此此SQL执行可选的索引只有主键索引，如果有多个，最终会选一个较优的作为检索的依据。</p>
<p>-- 增加一个没有建立索引的字段 <code>alter table innodb1 add sex char(1);</code></p>
<p>-- 按sex检索时可选的索引为null <code>EXPLAIN SELECT * from innodb1 where sex='男';</code></p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1620897795644.png" alt="" loading="lazy"></figure>
<p>可以尝试在一个字段未建立索引时，根据该字段查询的效率，然后对该字段建立索引<code>alter table 表名 add index(字段名)</code>，同样的SQL执行的效率，你会发现查询效率会有明显的提升（数据量越大越明显）。</p>
<h4 id="order-by">order by</h4>
<p>当我们使用order by将查询结果按照某个字段排序时，如果该字段没有建立索引，那么执行计划会将查询出的所有数据使用外部排序（将数据从硬盘分批读取到内存使用内部排序，最后合并排序结果），这个操作是很影响性能的，因为需要将查询涉及到的所有数据从磁盘中读到内存（如果单条数据过大或者数据量过多都会降低效率），更无论读到内存之后的排序了。</p>
<p>但是如果我们对该字段建立索引<code>alter table 表名 add index(字段名)</code>，那么由于索引本身是有序的，因此直接按照索引的顺序和映射关系逐条取出数据即可。而且如果分页的，那么只用<strong>取出索引表某个范围内的索引对应的数据</strong>，而不用像上述那<strong>取出所有数据</strong>进行排序再返回某个范围内的数据。（从磁盘取数据是最影响性能的）</p>
<h4 id="join">join</h4>
<p>对join语句匹配关系（on）涉及的字段建立索引能够提高效率</p>
<h4 id="索引覆盖">索引覆盖</h4>
<p>如果要查询的字段都建立过索引，那么引擎会直接在索引表中查询而不会访问原始数据（否则只要有一个字段没有建立索引就会做全表扫描），这叫索引覆盖。因此我们需要尽可能的在select后只写必要的查询字段，以增加索引覆盖的几率。</p>
<p>这里值得注意的是不要想着为每个字段建立索引，因为优先使用索引的优势就在于其体积小。</p>
<h3 id="索引类型">索引类型</h3>
<p><strong>主键索引:</strong> 数据列不允许重复，不允许为NULL，一个表只能有一个主键。</p>
<p><strong>唯一索引:</strong> 数据列不允许重复，允许为NULL值，一个表允许多个列创建唯一索引。</p>
<ul>
<li>可以通过 <code>ALTER TABLE table_name ADD UNIQUE (column);</code> 创建唯一索引</li>
<li>可以通过 <code>ALTER TABLE table_name ADD UNIQUE (column1,column2);</code> 创建唯一组合索引</li>
</ul>
<p><strong>普通索引:</strong> 基本的索引类型，没有唯一性的限制，允许为NULL值。</p>
<ul>
<li>可以通过<code>ALTER TABLE table_name ADD INDEX index_name (column);</code>创建普通索引</li>
<li>可以通过<code>ALTER TABLE table_name ADD INDEX index_name(column1, column2, column3);</code>创建组合索引</li>
</ul>
<p><strong>全文索引：</strong> 是目前搜索引擎使用的一种关键技术。</p>
<ul>
<li>可以通过<code>ALTER TABLE table_name ADD FULLTEXT (column);</code>创建全文索引</li>
</ul>
<h3 id="索引设计的原则">索引设计的原则</h3>
<ol>
<li>适合索引的列是出现在where子句中的列，或者连接子句中指定的列</li>
<li>基数较小的类，索引效果较差，没有必要在此列建立索引</li>
<li>使用短索引，如果对长字符串列进行索引，应该指定一个前缀长度，这样能够节省大量索引空间</li>
<li>不要过度索引。索引需要额外的磁盘空间，并降低写操作的性能。在修改表内容的时候，索引会进行更新甚至重构，索引列越多，这个时间就会越长。所以只保持需要的索引有利于查询即可。</li>
</ol>
<h3 id="创建索引的原则重中之重">创建索引的原则（重中之重）</h3>
<p>索引虽好，但也不是无限制的使用，最好符合一下几个原则</p>
<p>1） 最左前缀匹配原则，组合索引非常重要的原则，mysql会一直向右匹配直到遇到范围查询<code>(&gt;、&lt;、between、like)</code>就停止匹配，比如<code>a = 1 and b = 2 and c &gt; 3 and d = 4</code> 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。</p>
<p>2）较频繁作为查询条件的字段才去创建索引</p>
<p>3）更新频繁字段不适合创建索引</p>
<p>4）若是不能有效区分数据的列不适合做索引列(如性别，男女未知，最多也就三种，区分度实在太低)</p>
<p>5）尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。</p>
<p>6）定义有外键的数据列一定要建立索引。</p>
<p>7）对于那些查询中很少涉及的列，重复值比较多的列不要建立索引。</p>
<p>8）对于定义为text、image和bit的数据类型的列不要建立索引。</p>
<h3 id="创建索引的三种方式">创建索引的三种方式</h3>
<ol>
<li>
<p>第一种方式：在执行CREATE TABLE时创建索引</p>
<pre><code class="language-mysql">CREATE TABLE user_index2 (
	id INT auto_increment PRIMARY KEY,
	first_name VARCHAR ( 16 ),
	last_name VARCHAR ( 16 ),
	id_card VARCHAR ( 18 ),
	information text,
	KEY NAME ( first_name, last_name ),
	FULLTEXT KEY ( information ),
UNIQUE KEY ( id_card ) 
);
</code></pre>
</li>
<li>
<p>第二种方式：使用ALTER TABLE命令去增加索引</p>
<pre><code class="language-mysql">//ALTER TABLE用来创建普通索引、UNIQUE索引或PRIMARY KEY索引。
ALTER TABLE table_name ADD INDEX index_name (column_list);
</code></pre>
<p>其中table_name是要增加索引的表名，column_list指出对哪些列进行索引，多列时各列之间用逗号分隔。</p>
<p>索引名index_name可自己命名，缺省时，MySQL将根据第一个索引列赋一个名称。另外，ALTER TABLE允许在单个语句中更改多个表，因此可以在同时创建多个索引。</p>
</li>
<li>
<p>第三种方式：使用CREATE INDEX命令创建</p>
<pre><code class="language-mysql">//CREATE INDEX可对表增加普通索引或UNIQUE索引。（但是，不能创建PRIMARY KEY索引）
CREATE INDEX index_name ON table_name (column_list);
</code></pre>
</li>
</ol>
<h3 id="删除索引">删除索引</h3>
<p>根据索引名删除普通索引、唯一索引、全文索引：<code>alter table 表名 drop KEY 索引名</code></p>
<pre><code class="language-mysql">ALTER TABLE user_index DROP KEY NAME;
ALTER TABLE user_index DROP KEY id_card;
ALTER TABLE user_index DROP KEY information;
</code></pre>
<p>删除主键索引：alter table 表名 drop primary key（因为主键只有一个）。这里值得注意的是，如果主键自增长，那么不能直接执行此操作（自增长依赖于主键索引）：</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1620897774703.png" alt="" loading="lazy"></figure>
<p>需要取消自增长再行删除：</p>
<pre><code class="language-mysql">alter table user_index
-- 重新定义字段
MODIFY id int,
drop PRIMARY KEY
</code></pre>
<p>但通常不会删除主键，因为设计主键一定与业务逻辑无关。</p>
<h3 id="创建索引时需要注意什么">创建索引时需要注意什么？</h3>
<ul>
<li>非空字段：应该指定列为NOT NULL，除非你想存储NULL。在mysql中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。你应该用0、一个特殊的值或者一个空串代替空值；</li>
<li>取值离散大的字段：（变量各个取值之间的差异程度）的列放到联合索引的前面，可以通过count()函数查看字段的差异值，返回值越大说明字段的唯一值越多字段的离散程度高；</li>
<li>索引字段越小越好：数据库的数据存储以页为单位一页存储的数据越多一次IO操作获取的数据越大效率越高。</li>
</ul>
<h3 id="使用索引查询一定能提高查询的性能吗为什么">使用索引查询一定能提高查询的性能吗？为什么</h3>
<p>通常，通过索引查询数据比全表扫描要快。但是我们也必须注意到它的代价。</p>
<ul>
<li>索引需要空间来存储，也需要定期维护， 每当有记录在表中增减或索引列被修改时，索引本身也会被修改。 这意味着每条记录的INSERT，DELETE，UPDATE将为此多付出4，5 次的磁盘I/O。 因为索引需要额外的存储空间和处理，那些不必要的索引反而会使查询反应时间变慢。使用索引查询不一定能提高查询性能，索引范围查询(INDEX RANGE SCAN)适用于两种情况:</li>
<li>基于一个范围的检索，一般查询返回结果集小于表中记录数的30%</li>
<li>基于非唯一性索引的检索</li>
</ul>
<h3 id="百万级别或以上的数据如何删除">百万级别或以上的数据如何删除</h3>
<p>关于索引：由于索引需要额外的维护成本，因为索引文件是单独存在的文件,所以当我们对数据的增加,修改,删除,都会产生额外的对索引文件的操作,这些操作需要消耗额外的IO,会降低增/改/删的执行效率。所以，在我们删除数据库百万级别数据的时候，查询MySQL官方手册得知删除数据的速度和创建的索引数量是成正比的。</p>
<ol>
<li>所以我们想要删除百万数据的时候可以先删除索引（此时大概耗时三分多钟）</li>
<li>然后删除其中无用数据（此过程需要不到两分钟）</li>
<li>删除完成后重新创建索引(此时数据较少了)创建索引也非常快，约十分钟左右。</li>
<li>与之前的直接删除绝对是要快速很多，更别说万一删除中断,一切删除会回滚。那更是坑了。</li>
</ol>
<h3 id="前缀索引">前缀索引</h3>
<p>语法：<code>index(field(10))</code>，使用字段值的前10个字符建立索引，默认是使用字段的全部内容建立索引。</p>
<p>前提：前缀的标识度高。比如密码就适合建立前缀索引，因为密码几乎各不相同。</p>
<p>实操的难度：在于前缀截取的长度。</p>
<p>我们可以利用<code>select count(*)/count(distinct left(password,prefixLen));</code>，通过从调整prefixLen的值（从1自增）查看不同前缀长度的一个平均匹配度，接近1时就可以了（表示一个密码的前prefixLen个字符几乎能确定唯一一条记录）</p>
<h3 id="什么是最左前缀原则什么是最左匹配原则">什么是最左前缀原则？什么是最左匹配原则</h3>
<ul>
<li>顾名思义，就是最左优先，在创建多列索引时，要根据业务需求，where子句中使用最频繁的一列放在最左边。</li>
<li>最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询<code>(&gt;、&lt;、between、like)</code>就停止匹配，比如a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。</li>
<li>=和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式</li>
</ul>
<h3 id="索引算法">索引算法</h3>
<p>索引算法有 BTree算法和Hash算法</p>
<h4 id="btree算法">BTree算法</h4>
<p>BTree是最常用的mysql数据库索引算法，也是mysql默认的算法。因为它不仅可以被用在<code>=</code>,<code>&gt;</code>,<code>&gt;=</code>,<code>&lt;</code>,<code>&lt;=</code>和<code>between</code>这些比较操作符上，而且还可以用于<code>like</code>操作符，只要它的查询条件是一个不以通配符开头的常量， 例如：</p>
<p>-- 只要它的查询条件是一个不以通配符开头的常量 <code>select * from user where name like 'jack%';</code></p>
<p>-- 如果一通配符开头，或者没有使用常量，则不会使用索引，例如： <code>select * from user where name like '%jack';</code></p>
<h4 id="hash算法">Hash算法</h4>
<p>Hash Hash索引只能用于对等比较，例如<code>=</code>,<code>&lt;=&gt;（相当于=）</code>操作符。由于是一次定位数据，不像BTree索引需要从根节点到枝节点，最后才能访问到页节点这样多次IO访问，所以检索效率远高于BTree索引。</p>
<h3 id="索引的数据结构b树hash">索引的数据结构（b树，hash）</h3>
<p>索引的数据结构和具体存储引擎的实现有关，在MySQL中使用较多的索引有<strong>Hash索引</strong>，<strong>B+树索引</strong>等，而我们经常使用的InnoDB存储引擎的默认索引实现为：B+树索引。对于哈希索引来说，底层的数据结构就是哈希表，因此在绝大多数需求为单条记录查询的时候，可以选择哈希索引，查询性能最快；其余大部分场景，建议选择BTree索引。</p>
<ol>
<li>
<p>B树索引</p>
<p>mysql通过存储引擎取数据，基本上90%的人用的就是InnoDB了，按照实现方式分，InnoDB的索引类型目前只有两种：BTREE（B树）索引和HASH索引。B树索引是Mysql数据库中使用最频繁的索引类型，基本所有存储引擎都支持BTree索引。通常我们说的索引不出意外指的就是（B树）索引（实际是用B+树实现的，因为在查看表索引时<code>SHOW INDEX FROM &lt;表名&gt; [ FROM &lt;数据库名&gt;]</code>，mysql一律打印BTREE，所以简称为B树索引）</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1620984450233.png" alt="" loading="lazy"></figure>
<p><strong>查询方式：</strong></p>
<p>主键索引区:PI(关联保存的数据的地址)按主键查询,</p>
<p>普通索引区:si(关联的id的地址,然后再到达上面的地址)。所以按主键查询,速度最快</p>
<p><strong>B+tree性质：</strong></p>
<p>1.）n棵子tree的节点包含n个关键字，不用来保存数据而是保存数据的索引。</p>
<p>2.）所有的叶子结点中包含了全部关键字的信息，及指向含这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。</p>
<p>3.）所有的非终端结点可以看成是索引部分，结点中仅含其子树中的最大（或最小）关键字。</p>
<p>4.）B+ 树中，数据对象的插入和删除仅在叶节点上进行。</p>
<p>5.）B+树有2个头指针，一个是树的根节点，一个是最小关键码的叶节点。</p>
</li>
<li>
<p>哈希索引</p>
<p>简要说下，类似于数据结构中简单实现的HASH表（散列表）一样，当我们在mysql中用哈希索引时，主要就是通过Hash算法（常见的Hash算法有直接定址法、平方取中法、折叠法、除数取余法、随机数法），将数据库字段数据转换成定长的Hash值，与这条数据的行指针一并存入Hash表的对应位置；如果发生Hash碰撞（两个不同关键字的Hash值相同），则在对应Hash键下以链表形式存储。当然这只是简略模拟图。</p>
</li>
</ol>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1620897738341.webp" alt="" loading="lazy"></figure>
<h3 id="b树和b树的区别">B树和B+树的区别</h3>
<ul>
<li>在B树中，你可以将键和值存放在内部节点和叶子节点；但在B+树中，内部节点都是键，没有值，叶子节点同时存放键和值。</li>
<li>B+树的叶子节点有一条链相连，而B树的叶子节点各自独立。</li>
</ul>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1620897723431.jpeg" alt="" loading="lazy"></figure>
<h4 id="使用b树的好处">使用B树的好处</h4>
<p>B树可以在内部节点同时存储键和值，因此，把频繁访问的数据放在靠近根节点的地方将会大大提高热点数据的查询效率。这种特性使得B树在特定数据重复多次查询的场景中更加高效。</p>
<h4 id="使用b树的好处-2">使用B+树的好处</h4>
<p>由于B+树的内部节点只存放键，不存放值，因此，一次读取，可以在内存页中获取更多的键，有利于更快地缩小查找范围。 B+树的叶节点由一条链相连，因此，当需要进行一次全数据遍历的时候，B+树只需要使用O(logN)时间找到最小的一个节点，然后通过链进行O(N)的顺序遍历即可。而B树则需要对树的每一层进行遍历，这会需要更多的内存置换次数，因此也就需要花费更多的时间</p>
<h3 id="hash索引和b树对比">Hash索引和B+树对比</h3>
<p>首先要知道Hash索引和B+树索引的底层实现原理：</p>
<p>hash索引底层就是hash表，进行查找时，调用一次hash函数就可以获取到相应的键值，之后进行回表查询获得实际数据。B+树底层实现是多路平衡查找树。对于每一次的查询都是从根节点出发，查找到叶子节点方可以获得所查键值，然后根据查询判断是否需要回表查询数据。</p>
<p>那么可以看出他们有以下的不同：</p>
<ul>
<li>hash索引进行等值查询更快(一般情况下)，但是却无法进行范围查询。</li>
</ul>
<p>因为在hash索引中经过hash函数建立索引之后，索引的顺序与原顺序无法保持一致，不能支持范围查询。而B+树的的所有节点皆遵循(左节点小于父节点，右节点大于父节点，多叉树也类似)，天然支持范围。</p>
<ul>
<li>hash索引不支持使用索引进行排序，原理同上。</li>
<li>hash索引不支持模糊查询以及多列索引的最左前缀匹配。原理也是因为hash函数的不可预测。AAAA和AAAAB的索引没有相关性。</li>
<li>hash索引任何时候都避免不了回表查询数据，而B+树在符合某些条件(聚簇索引，覆盖索引等)的时候可以只通过索引完成查询。</li>
<li>hash索引虽然在等值查询上较快，但是不稳定。性能不可预测，当某个键值存在大量重复的时候，发生hash碰撞，此时效率可能极差。而B+树的查询效率比较稳定，对于所有的查询都是从根节点到叶子节点，且树的高度较低。</li>
</ul>
<p>因此，在大多数情况下，直接选择B+树索引可以获得稳定且较好的查询速度。而不需要使用hash索引。</p>
<h3 id="数据库为什么使用b树而不是b树">数据库为什么使用B+树而不是B树</h3>
<ul>
<li>B树只适合随机检索，而B+树同时支持随机检索和顺序检索；</li>
<li>B+树空间利用率更高，可减少I/O次数，磁盘读写代价更低。一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘I/O消耗。B+树的内部结点并没有指向关键字具体信息的指针，只是作为索引使用，其内部结点比B树小，盘块能容纳的结点中关键字数量更多，一次性读入内存中可以查找的关键字也就越多，相对的，IO读写次数也就降低了。而IO读写次数是影响索引检索效率的最大因素；</li>
<li>B+树的查询效率更加稳定。B树搜索有可能会在非叶子结点结束，越靠近根节点的记录查找时间越短，只要找到关键字即可确定记录的存在，其性能等价于在关键字全集内做一次二分查找。而在B+树中，顺序检索比较明显，随机检索时，任何关键字的查找都必须走一条从根节点到叶节点的路，所有关键字的查找路径长度相同，导致每一个关键字的查询效率相当。</li>
<li>B-树在提高了磁盘IO性能的同时并没有解决元素遍历的效率低下的问题。B+树的叶子节点使用指针顺序连接在一起，只要遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作。</li>
<li>增删文件（节点）时，效率更高。因为B+树的叶子节点包含所有关键字，并以有序的链表结构存储，这样可很好提高增删效率。</li>
</ul>
<h3 id="b树在满足聚簇索引和覆盖索引的时候不需要回表查询数据">B+树在满足聚簇索引和覆盖索引的时候不需要回表查询数据</h3>
<p>在B+树的索引中，叶子节点可能存储了当前的key值，也可能存储了当前的key值以及整行的数据，这就是聚簇索引和非聚簇索引。 在InnoDB中，只有主键索引是聚簇索引，如果没有主键，则挑选一个唯一键建立聚簇索引。如果没有唯一键，则隐式的生成一个键来建立聚簇索引。</p>
<p>当查询使用聚簇索引时，在对应的叶子节点，可以获取到整行数据，因此不用再次进行回表查询。</p>
<h3 id="什么是聚簇索引何时使用聚簇索引与非聚簇索引">什么是聚簇索引？何时使用聚簇索引与非聚簇索引</h3>
<ul>
<li>聚簇索引：将数据存储与索引放到了一块，找到索引也就找到了数据</li>
<li>非聚簇索引：将数据存储于索引分开结构，索引结构的叶子节点指向了数据的对应行，myisam通过key_buffer把索引先缓存到内存中，当需要访问数据时（通过索引访问数据），在内存中直接搜索索引，然后通过索引找到磁盘相应数据，这也就是为什么索引不在key buffer命中时，速度慢的原因</li>
</ul>
<p>澄清一个概念：innodb中，在聚簇索引之上创建的索引称之为辅助索引，辅助索引访问数据总是需要二次查找，非聚簇索引都是辅助索引，像复合索引、前缀索引、唯一索引，辅助索引叶子节点存储的不再是行的物理位置，而是主键值</p>
<p>何时使用聚簇索引与非聚簇索引</p>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1620897704953.png" alt="" loading="lazy"></figure>
<h3 id="非聚簇索引一定会回表查询吗">非聚簇索引一定会回表查询吗？</h3>
<p>不一定，这涉及到查询语句所要求的字段是否全部命中了索引，如果全部命中了索引，那么就不必再进行回表查询。</p>
<p>举个简单的例子，假设我们在员工表的年龄上建立了索引，那么当进行<code>select age from employee where age &lt; 20</code>的查询时，在索引的叶子节点上，已经包含了age信息，不会再次进行回表查询。</p>
<h3 id="联合索引">联合索引</h3>
<blockquote>
<p>MySQL可以使用多个字段同时建立一个索引，叫做联合索引。</p>
</blockquote>
<p>在联合索引中，如果想要命中索引，需要按照建立索引时的字段顺序挨个使用，否则无法命中索引。</p>
<p>具体原因为:</p>
<p>MySQL使用索引时需要索引有序，假设现在建立了<code>&quot;name，age，school&quot;</code>的联合索引，那么索引的排序为: 先按照name排序，如果name相同，则按照age排序，如果age的值也相等，则按照school进行排序。</p>
<p>当进行查询时，此时索引仅仅按照name严格有序，因此必须首先使用name字段进行等值查询，之后对于匹配到的列而言，其按照age字段严格有序，此时可以使用age字段用做索引查找，以此类推。因此在建立联合索引的时候应该注意索引列的顺序，一般情况下，将查询需求频繁或者字段选择性高的列放在前面。此外可以根据特例的查询或者表结构进行单独的调整。</p>
<blockquote>
<p>漫画：什么是B-树？https://tinaxiawuhao.github.io/post/LhRxiTagh/<br>
漫画：什么是B+树？https://tinaxiawuhao.github.io/post/jVTlR3ljT/</p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[mysql概述一]]></title>
        <id>https://tinaxiawuhao.github.io/post/Nq-4WaiGL/</id>
        <link href="https://tinaxiawuhao.github.io/post/Nq-4WaiGL/">
        </link>
        <updated>2021-05-18T07:31:08.000Z</updated>
        <content type="html"><![CDATA[<h3 id="为什么要使用数据库">为什么要使用数据库</h3>
<ol>
<li>
<p><strong>数据保存在内存</strong></p>
<p>优点： 存取速度快</p>
<p>缺点： 数据不能永久保存</p>
</li>
<li>
<p><strong>数据保存在文件</strong></p>
<p>优点： 数据永久保存</p>
<p>缺点：1）速度比内存操作慢，频繁的IO操作。</p>
<p>​			2）查询数据不方便</p>
</li>
<li>
<p><strong>数据保存在数据库</strong></p>
<p>1）数据永久保存</p>
<p>2）使用SQL语句，查询方便效率高。</p>
<p>3）管理数据方便</p>
</li>
</ol>
<h3 id="sql">SQL</h3>
<blockquote>
<p>结构化查询语言(Structured Query Language)简称SQL，是一种数据库查询语言。</p>
</blockquote>
<p>作用：用于存取数据、查询、更新和管理关系数据库系统。</p>
<h3 id="mysql">MySQL</h3>
<blockquote>
<p>MySQL是一个关系型数据库管理系统，由瑞典MySQL AB 公司开发，属于 Oracle 旗下产品。MySQL 是最流行的关系型数据库管理系统之一，在 WEB 应用方面，MySQL是最好的 RDBMS (Relational Database Management System，关系数据库管理系统) 应用软件之一。在Java企业级开发中非常常用，因为 MySQL 是开源免费的，并且方便扩展。</p>
</blockquote>
<h3 id="数据库三大范式是什么">数据库三大范式是什么</h3>
<ol>
<li>
<p>第一范式：每个列都不可以再拆分。</p>
</li>
<li>
<p>第二范式：在第一范式的基础上，非主键列完全依赖于主键，而不能是依赖于主键的一部分。</p>
</li>
<li>
<p>第三范式：在第二范式的基础上，非主键列只依赖于主键，不依赖于其他非主键。</p>
</li>
</ol>
<p>在设计数据库结构的时候，要尽量遵守三范式，如果不遵守，必须有足够的理由。比如性能。事实上我们经常会为了性能而妥协数据库的设计。</p>
<h3 id="mysql有关权限的表">mysql有关权限的表</h3>
<p>MySQL服务器通过权限表来控制用户对数据库的访问，权限表存放在mysql数据库里，由mysql_install_db脚本初始化。这些权限表分别user，db，table_priv，columns_priv和host。下面分别介绍一下这些表的结构和内容：</p>
<ul>
<li>user权限表：记录允许连接到服务器的用户帐号信息，里面的权限是全局级的。</li>
<li>db权限表：记录各个帐号在各个数据库上的操作权限。</li>
<li>table_priv权限表：记录数据表级的操作权限。</li>
<li>columns_priv权限表：记录数据列级的操作权限。</li>
<li>host权限表：配合db权限表对给定主机上数据库级操作权限作更细致的控制。这个权限表不受GRANT和REVOKE语句的影响。</li>
</ul>
<h3 id="mysql的binlog有几种录入格式分别有什么区别">MySQL的binlog有几种录入格式？分别有什么区别？</h3>
<p>有三种格式，statement，row和mixed。</p>
<ul>
<li>statement模式下，每一条会修改数据的sql都会记录在binlog中。不需要记录每一行的变化，减少了binlog日志量，节约了IO，提高性能。由于sql的执行是有上下文的，因此在保存的时候需要保存相关的信息，同时还有一些使用了函数之类的语句无法被记录复制。</li>
<li>row级别下，不记录sql语句上下文相关信息，仅保存哪条记录被修改。记录单元为每一行的改动，基本是可以全部记下来但是由于很多操作，会导致大量行的改动(比如alter table)，因此这种模式的文件保存的信息太多，日志量太大。</li>
<li>mixed，一种折中的方案，普通操作使用statement记录，当无法使用statement的时候使用row。</li>
</ul>
<p>此外，新版的MySQL中对row级别也做了一些优化，当表结构发生变化的时候，会记录语句而不是逐行记录。</p>
<h3 id="数据类型">数据类型</h3>
<table>
<thead>
<tr>
<th><strong>分类</strong></th>
<th><strong>类型名称</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>整数类型</strong></td>
<td>tinyInt</td>
<td>很小的整数(8位二进制)</td>
</tr>
<tr>
<td></td>
<td>smallint</td>
<td>小的整数(16位二进制)</td>
</tr>
<tr>
<td></td>
<td>mediumint</td>
<td>中等大小的整数(24位二进制)</td>
</tr>
<tr>
<td></td>
<td>int(integer)</td>
<td>普通大小的整数(32位二进制)</td>
</tr>
<tr>
<td><strong>小数类型</strong></td>
<td>float</td>
<td>单精度浮点数</td>
</tr>
<tr>
<td></td>
<td>double</td>
<td>双精度浮点数</td>
</tr>
<tr>
<td></td>
<td>decimal(m,d)</td>
<td>压缩严格的定点数</td>
</tr>
<tr>
<td><strong>日期类型</strong></td>
<td>year</td>
<td>YYYY 1901~2155</td>
</tr>
<tr>
<td></td>
<td>time</td>
<td>HH:MM:SS -838:59:59~838:59:59</td>
</tr>
<tr>
<td></td>
<td>date</td>
<td>YYYY-MM-DD 1000-01-01~9999-12-3</td>
</tr>
<tr>
<td></td>
<td>datetime</td>
<td>YYYY-MM-DD HH:MM:SS 1000-01-01 00:00:00~ 9999-12-31 23:59:59</td>
</tr>
<tr>
<td></td>
<td>timestamp</td>
<td>YYYY-MM-DD HH:MM:SS 19700101 00:00:01 UTC~2038-01-19 03:14:07UTC</td>
</tr>
<tr>
<td><strong>文本、二进制类型</strong></td>
<td>CHAR(M)</td>
<td>M为0~255之间的整数</td>
</tr>
<tr>
<td></td>
<td>VARCHAR(M)</td>
<td>M为0~65535之间的整数</td>
</tr>
<tr>
<td></td>
<td>TINYBLOB</td>
<td>允许长度0~255字节</td>
</tr>
<tr>
<td></td>
<td>BLOB</td>
<td>允许长度0~65535字节</td>
</tr>
<tr>
<td></td>
<td>MEDIUMBLOB</td>
<td>允许长度0~167772150字节</td>
</tr>
<tr>
<td></td>
<td>LONGBLOB</td>
<td>允许长度0~4294967295字节</td>
</tr>
<tr>
<td></td>
<td>TINYTEXT</td>
<td>允许长度0~255字节</td>
</tr>
<tr>
<td></td>
<td>TEXT</td>
<td>允许长度0~65535字节</td>
</tr>
<tr>
<td></td>
<td>MEDIUMTEXT</td>
<td>允许长度0~167772150字节</td>
</tr>
<tr>
<td></td>
<td>LONGTEXT</td>
<td>允许长度0~4294967295字节</td>
</tr>
<tr>
<td></td>
<td>VARBINARY(M)</td>
<td>允许长度0~M个字节的变长字节字符串</td>
</tr>
<tr>
<td></td>
<td>BINARY(M)</td>
<td>允许长度0~M个字节的定长字节字符串</td>
</tr>
</tbody>
</table>
<ul>
<li>
<p>1、整数类型，包括TINYINT、SMALLINT、MEDIUMINT、INT、BIGINT，分别表示1字节、2字节、3字节、4字节、8字节整数。任何整数类型都可以加上UNSIGNED属性，表示数据是无符号的，即非负整数。</p>
<p>长度：整数类型可以被指定长度，例如：INT(11)表示长度为11的INT类型。长度在大多数场景是没有意义的，它不会限制值的合法范围，只会影响显示字符的个数，而且需要和UNSIGNED ZEROFILL属性配合使用才有意义。</p>
<p>例子，假定类型设定为INT(5)，属性为UNSIGNED ZEROFILL，如果用户插入的数据为12的话，那么数据库实际存储数据为00012。</p>
</li>
<li>
<p>2、实数类型，包括FLOAT、DOUBLE、DECIMAL。</p>
<p>DECIMAL可以用于存储比BIGINT还大的整型，能存储精确的小数。</p>
<p>而FLOAT和DOUBLE是有取值范围的，并支持使用标准的浮点进行近似计算。</p>
<p>计算时FLOAT和DOUBLE相比DECIMAL效率更高一些，DECIMAL你可以理解成是用字符串进行处理。</p>
</li>
<li>
<p>3、字符串类型，包括VARCHAR、CHAR、TEXT、BLOB</p>
<p>VARCHAR用于存储可变长字符串，它比定长类型更节省空间。</p>
<p>VARCHAR使用额外1或2个字节存储字符串长度。列长度小于255字节时，使用1字节表示，否则使用2字节表示。</p>
<p>VARCHAR存储的内容超出设置的长度时，内容会被截断。</p>
<p>CHAR是定长的，根据定义的字符串长度分配足够的空间。</p>
<p>CHAR会根据需要使用空格进行填充方便比较。</p>
<p>CHAR适合存储很短的字符串，或者所有值都接近同一个长度。</p>
<p>CHAR存储的内容超出设置的长度时，内容同样会被截断。</p>
<p><strong>使用策略：</strong></p>
<p>对于经常变更的数据来说，CHAR比VARCHAR更好，因为CHAR不容易产生碎片。</p>
<p>对于非常短的列，CHAR比VARCHAR在存储空间上更有效率。</p>
<p>使用时要注意只分配需要的空间，更长的列排序时会消耗更多内存。</p>
<p>尽量避免使用TEXT/BLOB类型，查询时会使用临时表，导致严重的性能开销。</p>
</li>
<li>
<p>4、枚举类型（ENUM），把不重复的数据存储为一个预定义的集合。</p>
<p>有时可以使用ENUM代替常用的字符串类型。</p>
<p>ENUM存储非常紧凑，会把列表值压缩到一个或两个字节。</p>
<p>ENUM在内部存储时，其实存的是整数。</p>
<p>尽量避免使用数字作为ENUM枚举的常量，因为容易混乱。</p>
<p>排序是按照内部存储的整数</p>
</li>
<li>
<p>5、日期和时间类型，尽量使用timestamp，空间效率高于datetime，</p>
<p>用整数保存时间戳通常不方便处理。</p>
<p>如果需要存储微妙，可以使用bigint存储。</p>
</li>
</ul>
<h3 id="mysql存储引擎">MySQL存储引擎</h3>
<blockquote>
<p>存储引擎Storage engine：MySQL中的数据、索引以及其他对象是如何存储的，是一套文件系统的实现。</p>
</blockquote>
<p>常用的存储引擎有以下：</p>
<ul>
<li><strong>Innodb引擎</strong>：Innodb引擎提供了对数据库ACID事务的支持。并且还提供了行级锁和外键的约束。它的设计的目标就是处理大数据容量的数据库系统。</li>
<li><strong>MyIASM引擎</strong>(原本Mysql的默认引擎)：不提供事务的支持，也不支持行级锁和外键。</li>
<li><strong>MEMORY引擎</strong>：所有的数据都在内存中，数据的处理速度快，但是安全性不高。</li>
</ul>
<h4 id="myisam与innodb区别">MyISAM与InnoDB区别</h4>
<table>
<thead>
<tr>
<th></th>
<th>MyISAM</th>
<th>Innodb</th>
</tr>
</thead>
<tbody>
<tr>
<td>存储结构</td>
<td>每张表被存放在三个文件：frm-表格定义、MYD(MYData)-数据文件、MYI(MYIndex)-索引文件</td>
<td>所有的表都保存在同一个数据文件中（也可能是多个文件，或者是独立的表空间文件），InnoDB表的大小只受限于操作系统文件的大小，一般为2GB</td>
</tr>
<tr>
<td>存储空间</td>
<td>MyISAM可被压缩，存储空间较小</td>
<td>InnoDB的表需要更多的内存和存储，它会在主内存中建立其专用的缓冲池用于高速缓冲数据和索引</td>
</tr>
<tr>
<td>可移植性、备份及恢复</td>
<td>由于MyISAM的数据是以文件的形式存储，所以在跨平台的数据转移中会很方便。在备份和恢复时可单独针对某个表进行操作</td>
<td>免费的方案可以是拷贝数据文件、备份 binlog，或者用 mysqldump，在数据量达到几十G的时候就相对痛苦了</td>
</tr>
<tr>
<td>文件格式</td>
<td>数据和索引是分别存储的，数据.MYD，索引.MYI</td>
<td>数据和索引是集中存储的，.ibd</td>
</tr>
<tr>
<td>记录存储顺序</td>
<td>按记录插入顺序保存</td>
<td>按主键大小有序插入</td>
</tr>
<tr>
<td>外键</td>
<td>不支持</td>
<td>支持</td>
</tr>
<tr>
<td>事务</td>
<td>不支持</td>
<td>支持</td>
</tr>
<tr>
<td>锁支持（锁是避免资源争用的一个机制，MySQL锁对用户几乎是透明的）</td>
<td>表级锁定</td>
<td>行级锁定、表级锁定，锁定力度小并发能力高</td>
</tr>
<tr>
<td>SELECT</td>
<td>MyISAM更优</td>
<td></td>
</tr>
<tr>
<td>INSERT、UPDATE、DELETE</td>
<td></td>
<td>InnoDB更优</td>
</tr>
<tr>
<td>select count(*)</td>
<td>myisam更快，因为myisam内部维护了一个计数器，可以直接调取。</td>
<td></td>
</tr>
<tr>
<td>索引的实现方式</td>
<td>B+树索引，myisam 是堆表</td>
<td>B+树索引，Innodb 是索引组织表</td>
</tr>
<tr>
<td>哈希索引</td>
<td>不支持</td>
<td>支持</td>
</tr>
<tr>
<td>全文索引</td>
<td>支持</td>
<td>不支持</td>
</tr>
</tbody>
</table>
<h4 id="myisam索引与innodb索引的区别">MyISAM索引与InnoDB索引的区别？</h4>
<ul>
<li>InnoDB索引是聚簇索引，MyISAM索引是非聚簇索引。</li>
<li>InnoDB的主键索引的叶子节点存储着行数据，因此主键索引非常高效。</li>
<li>MyISAM索引的叶子节点存储的是行数据地址，需要再寻址一次才能得到数据。</li>
<li>InnoDB非主键索引的叶子节点存储的是主键和其他带索引的列数据，因此查询时做到覆盖索引会非常高效。</li>
</ul>
<h4 id="innodb引擎的4大特性">InnoDB引擎的4大特性</h4>
<ul>
<li>
<p>插入缓冲（Insert Buffer/Change Buffer)</p>
<p>提升插入性能，change buffering是insert buffer的加强，insert buffer只针对insert有效，change buffering对insert、delete、update(delete+insert)、purge都有效</p>
<p>只对于非聚集索引（非唯一）的插入和更新有效，对于每一次的插入不是写到索引页中，而是先判断插入的非聚集索引页是否在缓冲池中，如果在则直接插入；若不在，则先放到Insert Buffer 中，再按照一定的频率进行合并操作，再写回disk。这样通常能将多个插入合并到一个操作中，目的还是为了减少随机IO带来性能损耗。</p>
<p>使用插入缓冲的条件：<br>
* 非聚集索引<br>
* 非唯一索引</p>
<p>Change buffer是作为buffer pool中的一部分存在。<em>Innodb_change_buffering参数缓存所对应的操作：(update会被认为是delete+insert)</em></p>
<p>innodb_change_buffering，设置的值有：inserts、deletes、purges、changes（inserts和deletes）、all（默认）、none。</p>
<ul>
<li>all: 默认值，缓存insert, delete, purges操作</li>
<li>none: 不缓存</li>
<li>inserts: 缓存insert操作</li>
<li>deletes: 缓存delete操作</li>
<li>changes: 缓存insert和delete操作</li>
<li>purges: 缓存后台执行的物理删除操作</li>
</ul>
<p>可以通过参数控制其使用的大小：<br>
innodb_change_buffer_max_size，默认是25%，即缓冲池的1/4。最大可设置为50%。<em>当MySQL实例中有大量的修改操作时，要考虑增大</em><strong>innodb_change_buffer_max_size</strong></p>
<p>上面提过在一定频率下进行合并，那所谓的频率是什么条件？</p>
<ul>
<li>1）辅助索引页被读取到缓冲池中。正常的select先检查Insert Buffer是否有该非聚集索引页存在，若有则合并插入。</li>
<li>2）辅助索引页没有可用空间。空间小于1/32页的大小，则会强制合并操作。</li>
<li>3）Master Thread 每秒和每10秒的合并操作。</li>
</ul>
</li>
<li>
<p>二次写(double write)</p>
<p>Doublewrite缓存是位于系统表空间的存储区域，用来缓存InnoDB的数据页从innodb buffer pool中flush之后并写入到数据文件之前，所以当操作系统或者数据库进程在数据页写磁盘的过程中崩溃，Innodb可以在doublewrite缓存中找到数据页的备份而用来执行crash恢复。数据页写入到doublewrite缓存的动作所需要的IO消耗要小于写入到数据文件的消耗，因为此写入操作会以一次大的连续块的方式写入</p>
<p>在应用（apply）重做日志前，用户需要一个页的副本，当写入失效发生时，先通过页的副本来还原该页，再进行重做，这就是double write</p>
<p><strong>doublewrite组成：</strong><br>
内存中的doublewrite buffer,大小2M。<br>
物理磁盘上共享表空间中连续的128个页，即2个区（extend），大小同样为2M。</p>
<p>对缓冲池的脏页进行刷新时，不是直接写磁盘，而是会通过memcpy()函数将脏页先复制到内存中的doublewrite buffer，之后通过doublewrite 再分两次，每次1M顺序地写入共享表空间的物理磁盘上，在这个过程中，因为doublewrite页是连续的，因此这个过程是顺序写的，开销并不是很大。在完成doublewrite页的写入后，再将doublewrite buffer 中的页写入各个 表空间文件中，此时的写入则是离散的。如果操作系统在将页写入磁盘的过程中发生了崩溃，在恢复过程中，innodb可以从共享表空间中的doublewrite中找到该页的一个副本，将其复制到表空间文件，再应用重做日志。</p>
<figure data-type="image" tabindex="1"><img src="https://img2018.cnblogs.com/blog/1626822/201903/1626822-20190314095034387-1992982436.png" alt="img" loading="lazy"></figure>
</li>
<li>
<p>自适应哈希索引(ahi)</p>
<p>Adaptive Hash index属性使得InnoDB更像是内存数据库。该属性通过innodb_adapitve_hash_index开启，也可以通过—skip-innodb_adaptive_hash_index参数</p>
<p>Innodb存储引擎会监控对表上二级索引的查找，如果发现某二级索引被频繁访问，二级索引成为热数据，建立哈希索引可以带来速度的提升</p>
<p>经常访问的二级索引数据会自动被生成到hash索引里面去(最近连续被访问三次的数据)，自适应哈希索引通过缓冲池的B+树构造而来，因此建立的速度很快。<br>
哈希（hash）是一种非常快的等值查找方法，在一般情况下这种查找的时间复杂度为O(1),即一般仅需要一次查找就能定位数据。而B+树的查找次数，取决于B+树的高度，在生产环境中，B+树的高度一般3-4层，故需要3-4次的查询。</p>
<p>innodb会监控对表上个索引页的查询。如果观察到建立哈希索引可以带来速度提升，则自动建立哈希索引，称之为自适应哈希索引（Adaptive Hash Index，AHI）。<br>
AHI有一个要求，就是对这个页的连续访问模式必须是一样的。<br>
例如对于（a,b）访问模式情况：</p>
<pre><code class="language-sh">where a = xxx
where a = xxx and b = xxx
</code></pre>
<p><strong>特点</strong><br>
　　1、无序，没有树高<br>
　　2、降低对二级索引树的频繁访问资源，索引树高&lt;=4，访问索引：访问树、根节点、叶子节点<br>
　　3、自适应<br>
<strong>缺陷</strong><br>
　　1、hash自适应索引会占用innodb buffer pool；<br>
　   2、自适应hash索引只适合搜索等值的查询，如select * from table where index_col='xxx'，而对于其他查找类型，如范围查找，是不能使用的；<br>
　　3、极端情况下，自适应hash索引才有比较大的意义，可以降低逻辑读。</p>
</li>
<li>
<p>预读(read ahead)</p>
<p>InnoDB使用两种预读算法来提高I/O性能：线性预读（linear read-ahead）和随机预读（randomread-ahead）<br>
为了区分这两种预读的方式，我们可以把线性预读放到以extent为单位，而随机预读放到以extent中的page为单位。线性预读着眼于将下一个extent提前读取到buffer pool中，而随机预读着眼于将当前extent中的剩余的page提前读取到buffer pool中。</p>
<p><strong>线性预读（linear read-ahead）</strong></p>
<p>线性预读方式有一个很重要的变量控制是否将下一个extent预读到buffer pool中，通过使用配置参数innodb_read_ahead_threshold，可以控制Innodb执行预读操作的时间。如果一个extent中的被顺序读取的page超过或者等于该参数变量时，Innodb将会异步的将下一个extent读取到buffer pool中，innodb_read_ahead_threshold可以设置为0-64的任何值，默认值为56，值越高，访问模式检查越严格<br>
例如，如果将值设置为48，则InnoDB只有在顺序访问当前extent中的48个pages时才触发线性预读请求，将下一个extent读到内存中。如果值为8，InnoDB触发异步预读，即使程序段中只有8页被顺序访问。你可以在MySQL配置文件中设置此参数的值，或者使用SET GLOBAL需要该SUPER权限的命令动态更改该参数。<br>
在没有该变量之前，当访问到extent的最后一个page的时候，Innodb会决定是否将下一个extent放入到buffer pool中。</p>
<p><strong>随机预读（randomread-ahead）</strong></p>
<p>随机预读方式则是表示当同一个extent中的一些page在buffer pool中发现时，Innodb会将该extent中的剩余page一并读到buffer pool中，由于随机预读方式给Innodb code带来了一些不必要的复杂性，同时在性能也存在不稳定性，在5.5中已经将这种预读方式废弃。要启用此功能，请将配置变量设置innodb_random_read_ahead为ON。</p>
</li>
</ul>
<h4 id="存储引擎选择">存储引擎选择</h4>
<p>如果没有特别的需求，使用默认的Innodb即可。</p>
<p>MyISAM：以读写插入为主的应用程序，比如博客系统、新闻门户网站。</p>
<p>Innodb：更新（删除）操作频率也高，或者要保证数据的完整性；并发量高，支持事务和外键。比如OA自动化办公系统。</p>
<h3 id="mysql查询过程">MySQL查询过程</h3>
<p>​       MySQL查询优化实质说白了就是遵循一些原则让MySQL的优化器能够按照预想的合理方式运行，从而达到不同的业务目标需要实现的效果。下图展示了MySQL的查询过程。<br>
<img src="https://tinaxiawuhao.github.io/post-images/1636082387664.png" alt="" loading="lazy"></p>
<h4 id="客户端服务端通信协议">客户端/服务端通信协议</h4>
<p>MySQL客户端/服务端通信协议是&quot;半双工&quot;的：在任意时刻，要么是服务器向客户端发送数据，要么是客户端向服务器发送数据，这两个动作不能同时发生。一旦一端开始发送消息，另一端要接收完整个消息才能响应它，所以我们无法也无须将一个消息切成小块独立发送，也没有办法进行流量控制。</p>
<p>客户端用一个单独的数据包将查询请求发送给服务器，所以当查询语句很长的时候，需要设置max_allowed_packet参数。但是需要注意的是，如果查询实在是太大，服务端会拒绝接收更多数据并抛出异常。</p>
<p>与之相反的是，服务器响应给用户的数据通常会很多，由多个数据包组成。但是当服务器响应客户端请求时，客户端必须完整的接收整个返回结果，而不能简单的只取前面几条结果，然后让服务器停止发送。因而在实际开发中，尽量保持查询简单且只返回必需的数据，减小通信间数据包的大小和数量是一个非常好的习惯，这也是查询中尽量避免使用SELECT *以及加上LIMIT限制的原因之一。</p>
<h4 id="查询缓存">查询缓存</h4>
<p>在解析一个查询语句前，如果查询缓存是打开的，那么MySQL会检查这个查询语句是否命中查询缓存中的数据。如果当前查询恰好命中查询缓存，在检查一次用户权限后直接返回缓存中的结果。这种情况下，查询不会被解析，也不会生成执行计划，更不会执行。</p>
<p>MySQL将缓存存放在一个引用表（类似于HashMap的数据结构）中，通过哈希值索引，这个哈希值通过查询本身、当前要查询的数据库、客户端协议版本号等一些可能影响结果的信息计算得来。所以两个查询在任何字符上的不同（例如：空格、注释），都会导致缓存不会命中。</p>
<p>如果查询中包含任何用户自定义函数、存储函数、用户变量、临时表、mysql库中的系统表，其查询结果都不会被缓存。比如函数NOW()或者CURRENT_DATE()会因为不同的查询时间，返回不同的查询结果，再比如包含CURRENT_USER或者CONNECION_ID()的查询语句会因为不同的用户而返回不同的结果，将这样的查询结果缓存起来没有任何的意义。</p>
<p>MySQL的查询缓存系统会跟踪查询中涉及的每个表，如果这些表（数据或结构）发生变化，那么和这张表相关的所有缓存数据都将失效。正因为如此，在任何的写操作时，MySQL必须将对应表的所有缓存都设置为失效。如果查询缓存非常大或者碎片很多，这个操作就可能带来很大的系统消耗，甚至导致系统僵死一会儿。而且查询缓存对系统的额外消耗也不仅仅在写操作，读操作也不例外。如果查询结果被缓存，那么执行完成后，会将结果存入缓存，也会带来额外的系统消耗。基于此，我们知道并不是什么情况下查询缓存都会提高系统性能，缓存和失效都会带来额外消耗，只有当缓存带来的资源节约大于其本身消耗的资源时，才会给系统带来性能提升。如果系统确实存在一些性能问题，可以尝试打开查询缓存，并在数据库设计上做一些优化，比如：</p>
<p>1）多个小表代替一个大表（注意不要过度设计）</p>
<p>2）批量插入代替循环单条插入，降低磁盘IO次数</p>
<p>3）合理控制缓存空间大小，一般来说其大小设置为几十兆比较合适</p>
<p>4）可以通过SQL_CACHE和SQL_NO_CACHE来控制某个查询语句是否需要进行缓存</p>
<h4 id="语法解析和预处理">语法解析和预处理</h4>
<p>MySQL通过关键字将SQL语句进行解析并生成一颗对应的解析树。这个过程解析器主要通过语法规则来验证和解析，比如SQL中是否使用了错误的关键字或者关键字的顺序是否正确等等。预处理则会根据MySQL规则进一步检查解析树是否合法，比如检查要查询的数据表和数据列是否存在等等。</p>
<h4 id="查询优化">查询优化</h4>
<p>经过前面的步骤生成的语法树被认为是合法的了，并且由优化器将其转化成查询计划。多数情况下一条查询可以有很多种执行方式，最后都返回相应的结果。优化器的作用就是找到这其中最好的执行计划。MySQL使用基于成本的优化器，它尝试预测一个查询使用某种执行计划时的成本，并选择其中成本最小的一个。在MySQL可以通过查询当前会话的last_query_cost的值来得到其计算当前查询的成本。 有非常多的原因会导致MySQL选择错误的执行计划，比如统计信息不准确、不会考虑不受其控制的操作成本（用户自定义函数、存储过程）、MySQL认为的最优跟我们想的不一样，我们希望执行时间尽可能短，但MySQL只选择它认为成本小的，但成本小有的时候并不是我们的预期。</p>
<h4 id="查询执行引擎">查询执行引擎</h4>
<p>在完成解析和优化阶段以后，MySQL会生成对应的执行计划，查询执行引擎根据执行计划给出的指令逐步执行得出结果。整个执行过程的大部分操作均是通过调用存储引擎实现的接口来完成，这些接口被称为handler API。查询过程中的每一张表由一个handler实例表示。实际上，MySQL在查询优化阶段就为每一张表创建了一个handler实例，优化器可以根据这些实例的接口来获取表的相关信息，包括表的所有列名、索引统计信息等。存储引擎接口提供了非常丰富的功能，但其底层仅有几十个接口，这些接口像搭积木一样完成了一次查询的大部分操作。</p>
<h4 id="返回结果给客户端">返回结果给客户端</h4>
<p>查询执行的最后一个阶段就是将结果返回给客户端。即使查询不到数据，MySQL仍然会返回这个查询的相关信息，比如该查询影响到的行数以及执行时间等等。如果查询缓存被打开且这个查询可以被缓存，MySQL也会将结果存放到缓存中。结果集返回客户端是一个增量且逐步返回的过程。有可能MySQL在生成第一条结果时，就开始向客户端逐步返回结果集了。这样服务端就无须存储太多结果而消耗过多内存，也可以让客户端第一时间获得返回结果。需要注意的是，结果集中的每一行都会以一个满足客户端/服务器通信协议的数据包发送，再通过TCP协议进行传输，在传输过程中，可能对MySQL的数据包进行缓存然后批量发送。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[redis概述五]]></title>
        <id>https://tinaxiawuhao.github.io/post/Sjb64Uy0k/</id>
        <link href="https://tinaxiawuhao.github.io/post/Sjb64Uy0k/">
        </link>
        <updated>2021-05-17T07:38:52.000Z</updated>
        <content type="html"><![CDATA[<h3 id="分布式问题">分布式问题</h3>
<h4 id="redis实现分布式锁">Redis实现分布式锁</h4>
<p>Redis为单进程单线程模式，采用队列模式将并发访问变成串行访问，且多客户端对Redis的连接并不存在竞争关系Redis中可以使用SETNX命令实现分布式锁。</p>
<p>当且仅当 key 不存在，将 key 的值设为 value。 若给定的 key 已经存在，则 SETNX 不做任何动作</p>
<p>SETNX 是『SET if Not eXists』(如果不存在，则 SET)的简写。</p>
<p>返回值：设置成功，返回 1 。设置失败，返回 0 。</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1620719853455.png" alt="" loading="lazy"></figure>
<p>使用SETNX完成同步锁的流程及事项如下：</p>
<p>使用SETNX命令获取锁，若返回0（key已存在，锁已存在）则获取失败，反之获取成功</p>
<p>为了防止获取锁后程序出现异常，导致其他线程/进程调用SETNX命令总是返回0而进入死锁状态，需要为该key设置一个“合理”的过期时间</p>
<p>释放锁，使用DEL命令将锁数据删除</p>
<pre><code class="language-java">package com.example.redisstudy.template;

import org.apache.commons.lang3.StringUtils;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.data.redis.core.StringRedisTemplate;
import org.springframework.stereotype.Component;

import java.util.concurrent.TimeUnit;

/**
* @Description //直接使用Redis进行分布式锁 
* 这是简易版本  如果要使用Redis原生锁记得加过期时间，防止死锁 最好使用Redisson操作简单更加方便
* @Date
* @Author wuhao
**/
 
@Component
public class RedisLockCommon {
    @Autowired
    private StringRedisTemplate stringRedisTemplate;

    private Integer EXPIRE_TIME=3000;
    /**
     * Redis加锁的操作
     *
     * @param key
     * @param value
     * @return
     */
    public Boolean tryLock(String key, String value) {
        if (stringRedisTemplate.opsForValue().setIfAbsent(key, value, EXPIRE_TIME, TimeUnit.SECONDS)) {
            return true;
        }
        return false;
    }
 
 
    /**
     * Redis解锁的操作
     *
     * @param key
     * @param value
     */
    public void unlock(String key, String value) {
        String currentValue = stringRedisTemplate.opsForValue().get(key);
        try {
            if (StringUtils.isNotEmpty(currentValue) &amp;&amp; currentValue.equals(value)) {
                stringRedisTemplate.opsForValue().getOperations().delete(key);
            }
        } catch (Exception e) {
        }
    }
}
</code></pre>
<h4 id="如何解决-redis-的并发竞争-key-问题">如何解决 Redis 的并发竞争 Key 问题</h4>
<p>所谓 Redis 的并发竞争 Key 的问题也就是多个系统同时对一个 key 进行操作，但是最后执行的顺序和我们期望的顺序不同，这样也就导致了结果的不同！</p>
<p>推荐一种方案：分布式锁（zookeeper 和 redis 都可以实现分布式锁）。（如果不存在 Redis 的并发竞争 Key 问题，不要使用分布式锁，这样会影响性能）</p>
<p>基于zookeeper临时有序节点可以实现的分布式锁。大致思想为：每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。 判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。 当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。完成业务流程后，删除对应的子节点释放锁。</p>
<p>在实践中，当然是从以可靠性为主。所以首推Zookeeper。</p>
<p>参考：https://www.jianshu.com/p/8bddd381de06</p>
<h4 id="分布式redis是前期做还是后期规模上来了再做好为什么">分布式Redis是前期做还是后期规模上来了再做好？为什么？</h4>
<p>既然Redis是如此的轻量（单实例只使用1M内存），为防止以后的扩容，最好的办法就是一开始就启动较多实例。即便你只有一台服务器，你也可以一开始就让Redis以分布式的方式运行，使用分区，在同一台服务器上启动多个实例。</p>
<p>一开始就多设置几个Redis实例，例如32或者64个实例，对大多数用户来说这操作起来可能比较麻烦，但是从长久来看做这点牺牲是值得的。</p>
<p>这样的话，当你的数据不断增长，需要更多的Redis服务器时，你需要做的就是仅仅将Redis实例从一台服务迁移到另外一台服务器而已（而不用考虑重新分区的问题）。一旦你添加了另一台服务器，你需要将你一半的Redis实例从第一台机器迁移到第二台机器。</p>
<h4 id="什么是-redlock">什么是 RedLock</h4>
<p>Redis 官方站提出了一种权威的基于 Redis 实现分布式锁的方式名叫 <em>Redlock</em>，此种方式比原先的单节点的方法更安全。它可以保证以下特性：</p>
<ol>
<li>安全特性：互斥访问，即永远只有一个 client 能拿到锁</li>
<li>避免死锁：最终 client 都可能拿到锁，不会出现死锁的情况，即使原本锁住某资源的 client crash 了或者出现了网络分区</li>
<li>容错性：只要大部分 Redis 节点存活就可以正常提供服务</li>
</ol>
<pre><code class="language-java">package com.example.redisstudy.template;

import org.springframework.data.redis.connection.RedisConnection;
import org.springframework.data.redis.connection.RedisConnectionFactory;
import org.springframework.data.redis.connection.ReturnType;
import org.springframework.data.redis.core.RedisConnectionUtils;
import org.springframework.data.redis.core.StringRedisTemplate;
import org.springframework.stereotype.Repository;

import java.nio.charset.Charset;
import java.util.UUID;
import java.util.concurrent.TimeUnit;


@Repository
public class RedisLock {

    /**
     * 解锁脚本，原子操作
     */
    private static final String unlockScript =
            &quot;if redis.call(\&quot;get\&quot;,KEYS[1]) == ARGV[1]\n&quot;
                    + &quot;then\n&quot;
                    + &quot;    return redis.call(\&quot;del\&quot;,KEYS[1])\n&quot;
                    + &quot;else\n&quot;
                    + &quot;    return 0\n&quot;
                    + &quot;end&quot;;

    private StringRedisTemplate redisTemplate;

    public RedisLock(StringRedisTemplate redisTemplate) {
        this.redisTemplate = redisTemplate;
    }

    /**
     * 加锁，有阻塞
     * @param name
     * @param expire
     * @param timeout
     * @return
     */
    public String lock(String name, long expire, long timeout){
        long startTime = System.currentTimeMillis();
        String token;
        do{
            token = tryLock(name, expire);
            if(token == null) {
                if((System.currentTimeMillis()-startTime) &gt; (timeout-50))
                    break;
                try {
                    Thread.sleep(50); //try 50 per sec
                } catch (InterruptedException e) {
                    e.printStackTrace();
                    return null;
                }
            }
        }while(token==null);

        return token;
    }

    /**
     * 加锁，无阻塞
     * @param name
     * @param expire
     * @return
     */
    public String tryLock(String name, long expire) {
        String token = UUID.randomUUID().toString();
        if (redisTemplate.opsForValue().setIfAbsent(name, token, expire, TimeUnit.SECONDS)) {
            return token;
        }
        return null;
    }

    /**
     * 解锁
     * @param name
     * @param token
     * @return
     */
    public boolean unlock(String name, String token) {
        byte[][] keysAndArgs = new byte[2][];
        keysAndArgs[0] = name.getBytes(Charset.forName(&quot;UTF-8&quot;));
        keysAndArgs[1] = token.getBytes(Charset.forName(&quot;UTF-8&quot;));
        RedisConnectionFactory factory = redisTemplate.getConnectionFactory();
        RedisConnection conn = factory.getConnection();
        try {
            Long result = (Long)conn.scriptingCommands().eval(unlockScript.getBytes(Charset.forName(&quot;UTF-8&quot;)), ReturnType.INTEGER, 1, keysAndArgs);
            if(result!=null &amp;&amp; result&gt;0)
                return true;
        }finally {
            RedisConnectionUtils.releaseConnection(conn, factory);
        }

        return false;
    }
}
</code></pre>
<h4 id="缓存雪崩">缓存雪崩</h4>
<blockquote>
<p><strong>缓存雪崩</strong>是指缓存同一时间大面积的失效，所以，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。</p>
</blockquote>
<p><strong>解决方案</strong></p>
<ol>
<li>缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。</li>
<li>一般并发量不是特别多的时候，使用最多的解决方案是加锁排队。</li>
<li>给每一个缓存数据增加相应的缓存标记，记录缓存的是否失效，如果缓存标记失效，则更新数据缓存。</li>
</ol>
<h4 id="缓存穿透">缓存穿透</h4>
<blockquote>
<p><strong>缓存穿透</strong>是指缓存和数据库中都没有的数据，导致所有的请求都落到数据库上，造成数据库短时间内承受大量请求而崩掉。</p>
</blockquote>
<p><strong>解决方案</strong></p>
<ol>
<li>接口层增加校验，如用户鉴权校验，id做基础校验，id&lt;=0的直接拦截；</li>
<li>从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击</li>
<li>采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的 bitmap 中，一个一定不存在的数据会被这个 bitmap 拦截掉，从而避免了对底层存储系统的查询压力</li>
</ol>
<p><strong>附加</strong></p>
<p>对于空间的利用到达了一种极致，那就是Bitmap和布隆过滤器(Bloom Filter)。</p>
<p>Bitmap： 典型的就是哈希表</p>
<p>缺点是，Bitmap对于每个元素只能记录1bit信息，如果还想完成额外的功能，恐怕只能靠牺牲更多的空间、时间来完成了。</p>
<p><strong>布隆过滤器</strong>（推荐）</p>
<p>就是引入了k(k&gt;1)个相互独立的哈希函数，保证在给定的空间、误判率下，完成元素判重的过程。</p>
<p>它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。</p>
<p>Bloom-Filter算法的核心思想就是利用多个不同的Hash函数来解决“冲突”。</p>
<p>Hash存在一个冲突（碰撞）的问题，用同一个Hash得到的两个URL的值有可能相同。为了减少冲突，我们可以多引入几个Hash，如果通过其中的一个Hash值我们得出某元素不在集合中，那么该元素肯定不在集合中。只有在所有的Hash函数告诉我们该元素在集合中时，才能确定该元素存在于集合中。这便是Bloom-Filter的基本思想。</p>
<p>Bloom-Filter一般用于在大数据量的集合中判定某元素是否存在。</p>
<h4 id="缓存击穿">缓存击穿</h4>
<blockquote>
<p><strong>缓存击穿</strong>是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。和缓存雪崩不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。</p>
</blockquote>
<p><strong>解决方案</strong></p>
<ol>
<li>设置热点数据永远不过期。</li>
<li>加互斥锁，互斥锁</li>
</ol>
<h4 id="缓存预热">缓存预热</h4>
<blockquote>
<p><strong>缓存预热</strong>就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！</p>
</blockquote>
<p><strong>解决方案</strong></p>
<ol>
<li>直接写个缓存刷新页面，上线时手工操作一下；</li>
<li>数据量不大，可以在项目启动的时候自动进行加载；</li>
<li>定时刷新缓存；</li>
</ol>
<h4 id="缓存降级">缓存降级</h4>
<blockquote>
<p>当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。</p>
</blockquote>
<p><strong>缓存降级</strong>的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如加入购物车、结算）。</p>
<p>在进行降级之前要对系统进行梳理，看看系统是不是可以丢卒保帅；从而梳理出哪些必须誓死保护，哪些可降级；比如可以参考日志级别设置预案：</p>
<ol>
<li>一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级；</li>
<li>警告：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警；</li>
<li>错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级；</li>
<li>严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。</li>
</ol>
<p>服务降级的目的，是为了防止Redis服务故障，导致数据库跟着一起发生雪崩问题。因此，对于不重要的缓存数据，可以采取服务降级策略，例如一个比较常见的做法就是，Redis出现问题，不去数据库查询，而是直接返回默认值给用户。</p>
<h4 id="热点数据和冷数据">热点数据和冷数据</h4>
<p>热点数据，缓存才有价值</p>
<p>对于冷数据而言，大部分数据可能还没有再次访问到就已经被挤出内存，不仅占用内存，而且价值不大。频繁修改的数据，看情况考虑使用缓存</p>
<p>对于热点数据，比如我们的某IM产品，生日祝福模块，当天的寿星列表，缓存以后可能读取数十万次。再举个例子，某导航产品，我们将导航信息，缓存以后可能读取数百万次。</p>
<p>数据更新前至少读取两次，缓存才有意义。这个是最基本的策略，如果缓存还没有起作用就失效了，那就没有太大价值了。</p>
<p>那存不存在，修改频率很高，但是又不得不考虑缓存的场景呢？有！比如，这个读取接口对数据库的压力很大，但是又是热点数据，这个时候就需要考虑通过缓存手段，减少数据库的压力，比如我们的某助手产品的，点赞数，收藏数，分享数等是非常典型的热点数据，但是又不断变化，此时就需要将数据同步保存到Redis缓存，减少数据库压力。</p>
<h4 id="缓存热点key">缓存热点key</h4>
<p>缓存中的一个Key(比如一个促销商品)，在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。</p>
<p><strong>解决方案</strong></p>
<p>对缓存查询加锁，如果KEY不存在，就加锁，然后查DB入缓存，然后解锁；其他进程如果发现有锁就等待，然后等解锁后返回数据或者进入DB查询</p>
<h3 id="常用工具">常用工具</h3>
<h4 id="redis支持的java客户端都有哪些官方推荐用哪个">Redis支持的Java客户端都有哪些？官方推荐用哪个？</h4>
<p>Redisson、Jedis、lettuce等等，官方推荐使用Redisson。</p>
<h4 id="redis和redisson有什么关系">Redis和Redisson有什么关系？</h4>
<p>Redisson是一个高级的分布式协调Redis客服端，能帮助用户在分布式环境中轻松实现一些Java的对象 (Bloom filter, BitSet, Set, SetMultimap, ScoredSortedSet, SortedSet, Map, ConcurrentMap, List, ListMultimap, Queue, BlockingQueue, Deque, BlockingDeque, Semaphore, Lock, ReadWriteLock, AtomicLong, CountDownLatch, Publish / Subscribe, HyperLogLog)。</p>
<h4 id="jedis与redisson对比有什么优缺点">Jedis与Redisson对比有什么优缺点？</h4>
<p>Jedis是Redis的Java实现的客户端，其API提供了比较全面的Redis命令的支持；Redisson实现了分布式和可扩展的Java数据结构，和Jedis相比，功能较为简单，不支持字符串操作，不支持排序、事务、管道、分区等Redis特性。Redisson的宗旨是促进使用者对Redis的关注分离，从而让使用者能够将精力更集中地放在处理业务逻辑上。</p>
<p>Redisson实现分布式锁</p>
<pre><code class="language-java">package com.example.redisstudy.template;

import org.redisson.Redisson;
import org.redisson.api.RLock;
import org.redisson.api.RedissonClient;
import org.redisson.config.Config;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.stereotype.Component;

/**
 * @author wuhao
 * @desc ...
 * @date 2020-12-09 14:57:30
 */
@Component
public class RedissonLock {
    @Value(&quot;${spring.redis.address}&quot;)
    public String address;

    public RLock lock(){
        Config config = new Config();
        config.useSingleServer().setAddress(address);
//        config.useSingleServer().setPassword(&quot;redis1234&quot;);
        final RedissonClient client = Redisson.create(config);
        RLock lock = client.getLock(&quot;redis:lock&quot;);
        return lock;
    }
}

</code></pre>
<h4 id="如何保证缓存与数据库双写时的数据一致性">如何保证缓存与数据库双写时的数据一致性？</h4>
<p>你只要用缓存，就可能会涉及到缓存与数据库双存储双写，你只要是双写，就一定会有数据一致性的问题，那么你如何解决一致性问题？</p>
<p>一般来说，就是如果你的系统不是严格要求缓存+数据库必须一致性的话，缓存可以稍微的跟数据库偶尔有不一致的情况，最好不要做这个方案，读请求和写请求串行化，串到一个内存队列里去，这样就可以保证一定不会出现不一致的情况</p>
<p>串行化之后，就会导致系统的吞吐量会大幅度的降低，用比正常情况下多几倍的机器去支撑线上的一个请求。</p>
<p>还有一种方式就是可能会暂时产生不一致的情况，但是发生的几率特别小，就是<strong>先更新数据库，然后再删除缓存。</strong></p>
<table>
<thead>
<tr>
<th>问题场景</th>
<th>描述</th>
<th>解决</th>
</tr>
</thead>
<tbody>
<tr>
<td>先写缓存，再写数据库，缓存写成功，数据库写失败</td>
<td>缓存写成功，但写数据库失败或者响应延迟，则下次读取（并发读）缓存时，就出现脏读</td>
<td>这个写缓存的方式，本身就是错误的，需要改为先写数据库，把旧缓存置为失效；读取数据的时候，如果缓存不存在，则读取数据库再写缓存</td>
</tr>
<tr>
<td>先写数据库，再写缓存，数据库写成功，缓存写失败</td>
<td>写数据库成功，但写缓存失败，则下次读取（并发读）缓存时，则读不到数据</td>
<td>缓存使用时，假如读缓存失败，先读数据库，再回写缓存的方式实现</td>
</tr>
<tr>
<td>需要缓存异步刷新</td>
<td>指数据库操作和写缓存不在一个操作步骤中，比如在分布式场景下，无法做到同时写缓存或需要异步刷新（补救措施）时候</td>
<td>确定哪些数据适合此类场景，根据经验值确定合理的数据不一致时间，用户数据刷新的时间间隔</td>
</tr>
</tbody>
</table>
<h4 id="redis常见性能问题和解决方案">Redis常见性能问题和解决方案？</h4>
<ol>
<li>Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化。如果采用了主从架构，那么建议必须开启 master node 的持久化，不建议用 slave node 作为 master node 的数据热备，因为那样的话，如果你关掉 master 的持久化，可能在 master 宕机重启的时候数据是空的，然后可能一经过复制， slave node 的数据也丢了。另外，master 的各种备份方案，也需要做。万一本地的所有文件丢失了，从备份中挑选一份 rdb 去恢复 master，这样才能确保启动的时候，是有数据的，即使采用了后续讲解的高可用机制，slave node 可以自动接管 master node，但也可能 sentinel 还没检测到 master failure，master node 就自动重启了，还是可能导致上面所有的 slave node 数据被清空。</li>
<li>如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。</li>
<li>为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内。</li>
<li>尽量避免在压力较大的主库上增加从库</li>
<li>Master调用BGREWRITEAOF重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂服务暂停现象。</li>
<li>为了Master的稳定性，主从复制不要用图状结构，用单向链表结构更稳定，即主从关系为：Master&lt;–Slave1&lt;–Slave2&lt;–Slave3…，这样的结构也方便解决单点故障问题，实现Slave对Master的替换，也即，如果Master挂了，可以立马启用Slave1做Master，其他不变。</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[redis概述四]]></title>
        <id>https://tinaxiawuhao.github.io/post/FWuQD6Kxu/</id>
        <link href="https://tinaxiawuhao.github.io/post/FWuQD6Kxu/">
        </link>
        <updated>2021-05-16T06:21:49.000Z</updated>
        <content type="html"><![CDATA[<h3 id="集群方案">集群方案</h3>
<h4 id="1redis-主从架构">1，Redis 主从架构</h4>
<p>单机的 redis，能够承载的 QPS 大概就在上万到几万不等。对于缓存来说，一般都是用来支撑<strong>读高并发</strong>的。因此架构做成主从(master-slave)架构，一主多从，主负责写，并且将数据复制到其它的 slave 节点，从节点负责读。所有的<strong>读请求全部走从节点</strong>。这样也可以很轻松实现水平扩容，<strong>支撑读高并发</strong>。</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1620717339756.png" alt="" loading="lazy"></figure>
<p>redis replication -&gt; 主从架构 -&gt; 读写分离 -&gt; 水平扩容支撑读高并发</p>
<p><strong>redis replication 的核心机制</strong></p>
<ul>
<li>redis 采用<strong>异步方式</strong>复制数据到 slave 节点，不过 redis2.8 开始，slave node 会周期性地确认自己每次复制的数据量；</li>
<li>一个 master node 是可以配置多个 slave node 的；</li>
<li>slave node 也可以连接其他的 slave node；</li>
<li>slave node 做复制的时候，不会 block master node 的正常工作；</li>
<li>slave node 在做复制的时候，也不会 block 对自己的查询操作，它会用旧的数据集来提供服务；但是复制完成的时候，需要删除旧数据集，加载新数据集，这个时候就会暂停对外服务了；</li>
<li>slave node 主要用来进行横向扩容，做读写分离，扩容的 slave node 可以提高读的吞吐量。</li>
</ul>
<p>注意，如果采用了主从架构，那么建议必须<strong>开启</strong> master node 的持久化，不建议用 slave node 作为 master node 的数据热备，因为那样的话，如果你关掉 master 的持久化，可能在 master 宕机重启的时候数据是空的，然后可能一经过复制， slave node 的数据也丢了。</p>
<p>另外，master 的各种备份方案，也需要做。万一本地的所有文件丢失了，从备份中挑选一份 rdb 去恢复 master，这样才能<strong>确保启动的时候，是有数据的</strong>，即使采用了后续讲解的高可用机制，slave node 可以自动接管 master node，但也可能 sentinel 还没检测到 master failure，master node 就自动重启了，还是可能导致上面所有的 slave node 数据被清空。</p>
<p><strong>redis 主从复制的核心原理</strong></p>
<p>当启动一个 slave node 的时候，它会发送一个 PSYNC 命令给 master node。</p>
<p>如果这是 slave node 初次连接到 master node，那么会触发一次 full resynchronization 全量复制。此时 master 会启动一个后台线程，开始生成一份 RDB 快照文件，</p>
<p>同时还会将从客户端 client 新收到的所有写命令缓存在内存中。RDB 文件生成完毕后， master 会将这个 RDB 发送给 slave，slave 会先<strong>写入本地磁盘，然后再从本地磁盘加载到内存</strong>中，</p>
<p>接着 master 会将内存中缓存的写命令发送到 slave，slave 也会同步这些数据。</p>
<p>slave node 如果跟 master node 有网络故障，断开了连接，会自动重连，连接之后 master node 仅会复制给 slave 部分缺少的数据。</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1620717355448.png" alt="" loading="lazy"></figure>
<p><strong>过程原理</strong></p>
<ol>
<li>当从库和主库建立MS关系后，会向主数据库发送SYNC命令</li>
<li>主库接收到SYNC命令后会开始在后台保存快照(RDB持久化过程)，并将期间接收到的写命令缓存起来</li>
<li>当快照完成后，主Redis会将快照文件和所有缓存的写命令发送给从Redis</li>
<li>从Redis接收到后，会载入快照文件并且执行收到的缓存的命令</li>
<li>之后，主Redis每当接收到写命令时就会将命令发送从Redis，从而保证数据的一致</li>
</ol>
<p><strong>缺点</strong></p>
<p>所有的slave节点数据的复制和同步都由master节点来处理，会照成master节点压力太大，使用主从从结构来解决</p>
<h4 id="2哨兵模式">2，哨兵模式</h4>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1620716695309.png" alt="" loading="lazy"></figure>
<p><strong>哨兵的介绍</strong></p>
<p>sentinel，中文名是哨兵。哨兵是 redis 集群机构中非常重要的一个组件，主要有以下功能：</p>
<ul>
<li>集群监控：负责监控 redis master 和 slave 进程是否正常工作。</li>
<li>消息通知：如果某个 redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员。</li>
<li>故障转移：如果 master node 挂掉了，会自动转移到 slave node 上。</li>
<li>配置中心：如果故障转移发生了，通知 client 客户端新的 master 地址。</li>
</ul>
<p><strong>哨兵用于实现 redis 集群的高可用</strong>，本身也是分布式的，作为一个哨兵集群去运行，互相协同工作。</p>
<ul>
<li>故障转移时，判断一个 master node 是否宕机了，需要大部分的哨兵都同意才行，涉及到了分布式选举的问题。</li>
<li>即使部分哨兵节点挂掉了，哨兵集群还是能正常工作的，因为如果一个作为高可用机制重要组成部分的故障转移系统本身是单点的，那就很坑爹了。</li>
</ul>
<p><strong>哨兵的核心知识</strong></p>
<ul>
<li>哨兵至少需要 3 个实例，来保证自己的健壮性。</li>
<li>哨兵 + redis 主从的部署架构，是<strong>不保证数据零丢失</strong>的，只能保证 redis 集群的高可用性。</li>
<li>对于哨兵 + redis 主从这种复杂的部署架构，尽量在测试环境和生产环境，都进行充足的测试和演练。<br>
<img src="https://tinaxiawuhao.github.io/post-images/1620717166180.png" alt="" loading="lazy"></li>
</ul>
<h4 id="分布式和哨兵">分布式和哨兵</h4>
<p>Redis主从复制模式下， 一旦主节点出现了故障不可达， 需要人工干预进行故障转移， 无论对于Redis的应用方还是运维方都带来了很大的不便。对于应用方来说无法及时感知到主节点的变化， 必然会造成一定的写数据丢失和读数据错误， 甚至可能造成应用方服务不可用。 对于Redis的运维方来说， 整个故障转移的过程是需要人工来介入的， 故障转移实时性和准确性上都无法得到保障。考虑到这点， 有些公司把上述流程自动化了， 但是仍然存在如下问题： 第一， 判断节点不可达的机制是否健全和标准。 第二， 如果有多个从节点， 怎样保证只有一个被晋升为主节点。 第三，通知客户端新的主节点机制是否足够健壮。 Redis Sentinel正是用于解决这些问题<br>
<img src="https://tinaxiawuhao.github.io/post-images/1620716970068.png" alt="" loading="lazy"><br>
Redis Sentinel是一个分布式架构， 其中包含若干个Sentinel节点和Redis数据节点， 每个Sentinel节点会对数据节点和其余Sentinel节点进行监控， 当它发现节点不可达时， 会对节点做下线标识。 如果被标识的是主节点， 它还会和其他Sentinel节点进行“协商”， 当大多数Sentinel节点都认为主节点不可达时， 它们会选举出一个Sentinel节点来完成自动故障转移的工作， 同时会将这个变化实时通知给Redis应用方。 整个过程完全是自动的， 不需要人工来介入， 所以这套方案很有效地解决了Redis的高可用问题<br>
<img src="https://tinaxiawuhao.github.io/post-images/1620716982305.png" alt="" loading="lazy"></p>
<h4 id="哨兵的监控与选举">哨兵的监控与选举</h4>
<h5 id="哨兵的定时监控">哨兵的定时监控</h5>
<p>任务1：每个哨兵节点每10秒会向主节点和从节点发送info命令获取最拓扑结构图，哨兵配置时只要配置对主节点的监控即可，通过向主节点发送info，获取从节点的信息，并当有新的从节点加入时可以马上感知到</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1634888807687.png" alt="" loading="lazy"></figure>
<p>任务2：每个哨兵节点每隔2秒会向redis数据节点的指定频道上发送该哨兵节点对于主节点的判断以及当前哨兵节点的信息，同时每个哨兵节点也会订阅该频道，来了解其它哨兵节点的信息及对主节点的判断，其实就是通过消息publish和subscribe来完成的</p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1634888824561.png" alt="" loading="lazy"></figure>
<p>任务3：每隔1秒每个哨兵会向主节点、从节点及其余哨兵节点发送一次ping命令做一次心跳检测，这个也是哨兵用来判断节点是否正常的重要依据</p>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1634888834049.png" alt="" loading="lazy"></figure>
<p><strong>主观下线</strong>：所谓主观下线，就是单个sentinel认为某个服务下线（有可能是接收不到订阅，之间的网络不通等等原因）。</p>
<p>sentinel会以每秒一次的频率向所有与其建立了命令连接的实例（master，从服务，其他sentinel）发ping命令，通过判断ping回复是有效回复，还是无效回复来判断实例时候在线（对该sentinel来说是“主观在线”）。</p>
<p>sentinel配置文件中的down-after-milliseconds设置了判断主观下线的时间长度，如果实例在down-after-milliseconds毫秒内，返回的都是无效回复，那么sentinel回认为该实例已（主观）下线，修改其flags状态为SRI_S_DOWN。如果多个sentinel监视一个服务，有可能存在多个sentinel的down-after-milliseconds配置不同，这个在实际生产中要注意。</p>
<p><strong>客观下线</strong>：当主观下线的节点是主节点时，此时该哨兵3节点会通过指令sentinel is-masterdown-by-addr寻求其它哨兵节点对主节点的判断，如果其他的哨兵也认为主节点主观线下了，则当认为主观下线的票数超过了quorum（选举）个数，此时哨兵节点则认为该主节点确实有问题，这样就客观下线了，大部分哨兵节点都同意下线操作，也就说是客观下线</p>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1634888843652.png" alt="" loading="lazy"></figure>
<h5 id="哨兵lerder选举流程">哨兵lerder选举流程</h5>
<p>如果主节点被判定为客观下线之后，就要选取一个哨兵节点来完成后面的故障转移工作，选举出一个leader的流程如下:</p>
<p>a)每个在线的哨兵节点都可以成为领导者，当它确认（比如哨兵3）主节点下线时，会向其它哨兵发is-master-down-by-addr命令，征求判断并要求将自己设置为领导者，由领导者处理故障转移；<br>
b)当其它哨兵收到此命令时，可以同意或者拒绝它成为领导者；<br>
c)如果哨兵3发现自己在选举的票数大于等于num(sentinels)/2+1时，将成为领导者，如果没有超过，继续选举…………</p>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1634888851210.png" alt="" loading="lazy"></figure>
<h5 id="自动故障转移机制">自动故障转移机制</h5>
<h6 id="在从节点中选择新的主节点">在从节点中选择新的主节点</h6>
<p>sentinel状态数据结构中保存了主服务的所有从服务信息，领头sentinel按照如下的规则从从服务列表中挑选出新的主服务</p>
<ol>
<li>过滤掉主观下线的节点</li>
<li>选择slave-priority最高的节点，如果由则返回没有就继续选择</li>
<li>选择出复制偏移量最大的系节点，因为复制便宜量越大则数据复制的越完整，如果由就返回了，没有就继续</li>
<li>选择run_id最小的节点</li>
</ol>
<figure data-type="image" tabindex="9"><img src="https://tinaxiawuhao.github.io/post-images/1634889047008.png" alt="" loading="lazy"></figure>
<h6 id="更新主从状态">更新主从状态</h6>
<p>通过slaveof no one命令，让选出来的从节点成为主节点；并通过slaveof命令让其他节点成为其从节点。</p>
<p><strong>将已下线的主节点设置成新的主节点的从节点，当其回复正常时，复制新的主节点，变成新的主节点的从节点</strong></p>
<p>同理，当已下线的服务重新上线时，sentinel会向其发送slaveof命令，让其成为新主的从</p>
<h4 id="3官方redis-cluster-方案服务端路由查询">3，官方Redis Cluster 方案(服务端路由查询)</h4>
<figure data-type="image" tabindex="10"><img src="https://tinaxiawuhao.github.io/post-images/1620717452848.png" alt="" loading="lazy"></figure>
<p><strong>简介</strong></p>
<p>Redis Cluster是一种服务端Sharding技术，3.0版本开始正式提供。Redis Cluster并没有使用一致性hash，而是采用slot(槽)的概念，一共分成16384个槽。将请求发送到任意节点，接收到请求的节点会将查询请求发送到正确的节点上执行</p>
<p><strong>方案说明</strong></p>
<ol>
<li>通过哈希的方式，将数据分片，每个节点均分存储一定哈希槽(哈希值)区间的数据，默认分配了16384 个槽位</li>
<li>每份数据分片会存储在多个互为主从的多节点上</li>
<li>数据写入先写主节点，再同步到从节点(支持配置为阻塞同步)</li>
<li>同一分片多个节点间的数据不保持一致性</li>
<li>读取数据时，当客户端操作的key没有分配在该节点上时，redis会返回转向指令，指向正确的节点</li>
<li>扩容时时需要需要把旧节点的数据迁移一部分到新节点</li>
</ol>
<p>在 redis cluster 架构下，每个 redis 要放开两个端口号，比如一个是 6379，另外一个就是 加1w 的端口号，比如 16379。</p>
<p>16379 端口号是用来进行节点间通信的，也就是 cluster bus 的东西，cluster bus 的通信，用来进行故障检测、配置更新、故障转移授权。cluster bus 用了另外一种二进制的协议，gossip 协议，用于节点间进行高效的数据交换，占用更少的网络带宽和处理时间。</p>
<p><strong>节点间的内部通信机制</strong></p>
<p>基本通信原理</p>
<p>集群元数据的维护有两种方式：集中式、Gossip 协议。redis cluster 节点间采用 gossip 协议进行通信。</p>
<h5 id="分布式寻址算法">分布式寻址算法</h5>
<ul>
<li>
<p>hash 算法（大量缓存重建）</p>
<p>使用特定的数据， 如Redis的键或用户ID， 再根据节点数量N使用公式：hash（key） %N计算出哈希值， 用来决定数据映射到哪一个节点上。 这种方案存在一个问题： 当节点数量变化时， 如扩容或收缩节点， 数据节点映射关系需要重新计算， 会导致数据的重新迁移。<br>
这种方式的突出优点是简单性， 常用于数据库的分库分表规则， 一般采用预分区的方式， 提前根据数据量规划好分区数， 比如划分为512或1024张表， 保证可支撑未来一段时间的数据量， 再根据负载情况将表迁移到其他数据库中。 扩容时通常采用翻倍扩容， 避免数据映射全部被打乱导致全量迁移的情况， 如图所示。<br>
<img src="https://tinaxiawuhao.github.io/post-images/1620717081847.png" alt="" loading="lazy"></p>
</li>
<li>
<p>一致性 hash 算法（自动缓存迁移）+ 虚拟节点（自动负载均衡）</p>
<p>一致性哈希分区（Distributed Hash Table） 实现思路是为系统中每个节点分配一个token， 范围一般在0~232， 这些token构成一个哈希环。 数据读写执行节点查找操作时， 先根据key计算hash值， 然后顺时针找到第一个大于等于该哈希值的token节点， 如图所示。<br>
<img src="https://tinaxiawuhao.github.io/post-images/1620717088124.png" alt="" loading="lazy"><br>
这种方式相比节点取余最大的好处在于加入和删除节点只影响哈希环中相邻的节点， 对其他节点无影响。 但一致性哈希分区存在几个问题：</p>
<ol>
<li>
<p>加减节点会造成哈希环中部分数据无法命中， 需要手动处理或者忽略这部分数据， 因此一致性哈希常用于缓存场景。</p>
</li>
<li>
<p>当使用少量节点时， 节点变化将大范围影响哈希环中数据映射， 因此这种方式不适合少量数据节点的分布式方案。</p>
</li>
<li>
<p>普通的一致性哈希分区在增减节点时需要增加一倍或减去一半节点才能保证数据和负载的均衡。</p>
</li>
</ol>
</li>
<li>
<p>redis cluster 的 hash slot 算法</p>
<p>虚拟槽分区巧妙地使用了哈希空间， 使用分散度良好的哈希函数把所有数据映射到一个固定范围的整数集合中， 整数定义为槽（slot）。 这个范围一般远远大于节点数， 比如Redis Cluster槽范围是0~16383。 槽是集群内数据管理和迁移的基本单位。 采用大范围槽的主要目的是为了方便数据拆分和集群扩展。 每个节点会负责一定数量的槽， 如图所示。<br>
<img src="https://tinaxiawuhao.github.io/post-images/1620717095963.png" alt="" loading="lazy"><br>
Redis Cluser采用虚拟槽分区， 所有的键根据哈希函数映射到0~16383整数槽内， 计算公式： slot=CRC16（key） &amp;16383。 每一个节点负责维护一部分槽以及槽所映射的键值数据， 如图所示<br>
<img src="https://tinaxiawuhao.github.io/post-images/1620717101176.png" alt="" loading="lazy"><br>
Redis虚拟槽分区的特点：</p>
<ol>
<li>
<p>解耦数据和节点之间的关系， 简化了节点扩容和收缩难度。</p>
</li>
<li>
<p>节点自身维护槽的映射关系， 不需要客户端或者代理服务维护槽分区元数据。</p>
</li>
<li>
<p>支持节点、 槽、 键之间的映射查询， 用于数据路由、 在线伸缩等场景</p>
</li>
</ol>
</li>
</ul>
<p><strong>优点</strong></p>
<ul>
<li>无中心架构，支持动态扩容，对业务透明</li>
<li>具备Sentinel的监控和自动Failover(故障转移)能力</li>
<li>客户端不需要连接集群所有节点，连接集群中任何一个可用节点即可</li>
<li>高性能，客户端直连redis服务，免去了proxy代理的损耗</li>
</ul>
<p><strong>缺点</strong></p>
<ul>
<li>运维也很复杂，数据迁移需要人工干预</li>
<li>只能使用0号数据库</li>
<li>不支持批量操作(pipeline管道操作)</li>
<li>分布式逻辑和存储模块耦合等</li>
</ul>
<h3 id="集群相关提问">集群相关提问</h3>
<h4 id="redis集群的主从复制模型是怎样的">Redis集群的主从复制模型是怎样的？</h4>
<p>为了使在部分节点失败或者大部分节点无法通信的情况下集群仍然可用，所以集群使用了主从复制模型，每个节点都会有N-1个复制品</p>
<h4 id="生产环境中的-redis-是怎么部署的">生产环境中的 redis 是怎么部署的？</h4>
<p>redis cluster，10 台机器，5 台机器部署了 redis 主实例，另外 5 台机器部署了 redis 的从实例，每个主实例挂了一个从实例，5 个节点对外提供读写服务，每个节点的读写高峰qps可能可以达到每秒 5 万，5 台机器最多是 25 万读写请求/s。</p>
<p>机器是什么配置？32G 内存+ 8 核 CPU + 1T 磁盘，但是分配给 redis 进程的是10g内存，一般线上生产环境，redis 的内存尽量不要超过 10g，超过 10g 可能会有问题。</p>
<p>5 台机器对外提供读写，一共有 50g 内存。</p>
<p>因为每个主实例都挂了一个从实例，所以是高可用的，任何一个主实例宕机，都会自动故障迁移，redis 从实例会自动变成主实例继续提供读写服务。</p>
<p>你往内存里写的是什么数据？每条数据的大小是多少？商品数据，每条数据是 10kb。100 条数据是 1mb，10 万条数据是 1g。常驻内存的是 200 万条商品数据，占用内存是 20g，仅仅不到总内存的 50%。目前高峰期每秒就是 3500 左右的请求量。</p>
<p>其实大型的公司，会有基础架构的 team 负责缓存集群的运维。</p>
<h4 id="说说redis哈希槽的概念">说说Redis哈希槽的概念？</h4>
<p>Redis集群没有使用一致性hash,而是引入了哈希槽的概念，Redis集群有16384个哈希槽，每个key通过CRC16校验后对16384取模来决定放置哪个槽，slot=CRC16（key） &amp;16383，集群的每个节点负责一部分hash槽。</p>
<h4 id="redis集群会有写操作丢失吗为什么">Redis集群会有写操作丢失吗？为什么？</h4>
<p>Redis并不能保证数据的强一致性，这意味这在实际中集群在特定的条件下可能会丢失写操作。</p>
<p>以下情况可能导致写操作丢失：</p>
<ul>
<li>过期 key 被清理</li>
<li>最大内存不足，导致 Redis 自动清理部分 key 以节省空间</li>
<li>主库故障后自动重启，从库自动同步</li>
<li>单独的主备方案，网络不稳定触发哨兵的自动切换主从节点，切换期间会有数据丢失</li>
</ul>
<h4 id="redis集群之间是如何复制的">Redis集群之间是如何复制的？</h4>
<p>在从节点执行slaveof命令后， 复制过程便开始运作， 下面详细介绍建立复制的完整流程， 如图所示。<br>
从图中可以看出复制过程大致分为6个过程：<br>
<img src="https://tinaxiawuhao.github.io/post-images/1620717243838.png" alt="" loading="lazy"></p>
<ol>
<li>
<p>保存主节点（master） 信息。执行slaveof后从节点只保存主节点的地址信息便直接返回， 这时建立复制流程还没有开始， 在从节点6380执行info replication可以看到如下信息：</p>
<pre><code class="language-sh">master_host:127.0.0.1
master_port:6379
master_link_status:down
</code></pre>
<p>从统计信息可以看出， 主节点的ip和port被保存下来， 但是主节点的连接状态（master_link_status） 是下线状态。 执行slaveof后Redis会打印如下日志：</p>
<pre><code class="language-sh">SLAVE OF 127.0.0.1:6379 enabled (user request from 'id=65 addr=127.0.0.1:58090 fd=5 name= age=11 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=32768 obl=0 oll=0 omem=0 events=r cmd=slaveof')
</code></pre>
<p>通过该日志可以帮助运维人员定位发送slaveof命令的客户端， 方便追踪和发现问题。</p>
</li>
<li>
<p>从节点（slave） 内部通过每秒运行的定时任务维护复制相关逻辑，当定时任务发现存在新的主节点后， 会尝试与该节点建立网络连接， 如图所示。<br>
<img src="https://tinaxiawuhao.github.io/post-images/1620717266049.png" alt="" loading="lazy"><br>
从节点会建立一个socket套接字， 例如图6-8中从节点建立了一个端口为24555的套接字， 专门用于接受主节点发送的复制命令。 从节点连接成功后<br>
打印如下日志：</p>
<pre><code class="language-sh">\* Connecting to MASTER 127.0.0.1:6379
\* MASTER &lt;-&gt; SLAVE sync started
</code></pre>
<p>如果从节点无法建立连接， 定时任务会无限重试直到连接成功或者执行slaveof no one取消复制， 如图所示。<br>
<img src="https://tinaxiawuhao.github.io/post-images/1620717276476.png" alt="" loading="lazy"><br>
关于连接失败， 可以在从节点执行info replication查看master_link_down_since_seconds指标， 它会记录与主节点连接失败的系统时<br>
间。 从节点连接主节点失败时也会每秒打印如下日志， 方便运维人员发现问题：</p>
<pre><code class="language-sh">\# Error condition on socket for SYNC: {socket_error_reason}
</code></pre>
</li>
<li>
<p>发送ping命令。<br>
连接建立成功后从节点发送ping请求进行首次通信， ping请求主要目的如下：<br>
·检测主从之间网络套接字是否可用。<br>
·检测主节点当前是否可接受处理命令。<br>
如果发送ping命令后， 从节点没有收到主节点的pong回复或者超时， 比如网络超时或者主节点正在阻塞无法响应命令， 从节点会断开复制连接， 下<br>
次定时任务会发起重连， 如图所示。<br>
<img src="https://tinaxiawuhao.github.io/post-images/1620717286026.png" alt="" loading="lazy"><br>
从节点发送的ping命令成功返回， Redis打印如下日志， 并继续后续复制流程：</p>
<pre><code class="language-sh">Master replied to PING, replication can continue...
</code></pre>
</li>
<li>
<p>权限验证。 如果主节点设置了requirepass参数， 则需要密码验证，从节点必须配置masterauth参数保证与主节点相同的密码才能通过验证； 如果验证失败复制将终止， 从节点重新发起复制流程。</p>
</li>
<li>
<p>同步数据集。 主从复制连接正常通信后， 对于首次建立复制的场景， 主节点会把持有的数据全部发送给从节点， 这部分操作是耗时最长的步骤。 Redis在2.8版本以后采用新复制命令psync进行数据同步， 原来的sync命令依然支持， 保证新旧版本的兼容性。 新版同步划分两种情况： 全量同步和部分同步.</p>
</li>
<li>
<p>命令持续复制。 当主节点把当前的数据同步给从节点后， 便完成了复制的建立流程。 接下来主节点会持续地把写命令发送给从节点， 保证主从数据一致性。</p>
</li>
</ol>
<h4 id="redis集群最大节点个数是多少">Redis集群最大节点个数是多少？</h4>
<p>16384个</p>
<h4 id="redis集群如何选择数据库">Redis集群如何选择数据库？</h4>
<p>Redis集群目前无法做数据库选择，默认在0数据库。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[redis概述三]]></title>
        <id>https://tinaxiawuhao.github.io/post/WAG-fYk_l/</id>
        <link href="https://tinaxiawuhao.github.io/post/WAG-fYk_l/">
        </link>
        <updated>2021-05-15T06:15:23.000Z</updated>
        <content type="html"><![CDATA[<h3 id="redis持久化">Redis持久化</h3>
<p>持久化就是把内存的数据写到磁盘中去，防止服务宕机了内存数据丢失。</p>
<h3 id="redis-的持久化机制是什么各自的优缺点">Redis 的持久化机制是什么？各自的优缺点？</h3>
<p>Redis 提供两种持久化机制 RDB（默认） 和 AOF 机制:</p>
<h4 id="rdb">RDB：</h4>
<p>RDB是Redis DataBase缩写快照</p>
<p>RDB是Redis默认的持久化方式。按照一定的时间将内存的数据以快照的形式保存到硬盘中，对应产生的数据文件为dump.rdb。通过配置文件中的save参数来定义快照的周期。<br>
<img src="https://tinaxiawuhao.github.io/post-images/1620713915376.png" alt="" loading="lazy"></p>
<p>bgsave是主流的触发RDB持久化方式， 根据下图了解它的运作流程<br>
<img src="https://tinaxiawuhao.github.io/post-images/1620718308347.png" alt="" loading="lazy"></p>
<ol>
<li>执行bgsave命令， Redis父进程判断当前是否存在正在执行的子进程， 如RDB/AOF子进程， 如果存在bgsave命令直接返回。</li>
<li>父进程执行fork操作创建子进程， fork操作过程中父进程会阻塞， 通过info stats命令查看latest_fork_usec选项， 可以获取最近一个fork操作的耗时， 单位为微秒。</li>
<li>父进程fork完成后， bgsave命令返回“Background saving started”信息并不再阻塞父进程， 可以继续响应其他命令。</li>
<li>子进程创建RDB文件， 根据父进程内存生成临时快照文件， 完成后对原有文件进行原子替换。 执行lastsave命令可以获取最后一次生成RDB的时间， 对应info统计的rdb_last_save_time选项。</li>
<li>进程发送信号给父进程表示完成， 父进程更新统计信息， 具体见info Persistence下的rdb_*相关选</li>
</ol>
<p><strong>优点：</strong></p>
<ul>
<li>1、只有一个文件 dump.rdb，方便持久化。</li>
<li>2、容灾性好，一个文件可以保存到安全的磁盘。</li>
<li>3、性能最大化，fork 子进程来完成写操作，让主进程继续处理命令，所以是 IO 最大化。使用单独子进程来进行持久化，主进程不会进行任何 IO 操作，保证了 redis 的高性能</li>
<li>4.相对于数据集大时，比 AOF 的启动效率更高。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>1、数据安全性低。RDB 是间隔一段时间进行持久化，如果持久化之间 redis 发生故障，会发生数据丢失。所以这种方式更适合数据要求不严谨的时候</li>
<li>2、AOF（Append-only file)持久化方式： 是指所有的命令行记录以 redis 命令请 求协议的格式完全持久化存储)保存为 aof 文件。</li>
</ul>
<h4 id="aof">AOF：</h4>
<p>AOF持久化(即Append Only File持久化)，则是将Redis执行的每次写命令记录到单独的日志文件中，当重启Redis会重新将持久化的日志中文件恢复数据。</p>
<p>当两种方式同时开启时，数据恢复Redis会优先选择AOF恢复。</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1620713929324.png" alt="" loading="lazy"></figure>
<p>开启AOF功能需要设置配置： appendonly yes， 默认不开启。 AOF文件名通过appendfilename配置设置， 默认文件名是appendonly.aof。 保存路径同RDB持久化方式一致， 通过dir配置指定。 AOF的工作流程操作： 命令写入（append） 、 文件同步（sync） 、 文件重写（rewrite） 、 重启加载<br>
（load） ， 如图所示<br>
<img src="https://tinaxiawuhao.github.io/post-images/1620718403610.png" alt="" loading="lazy"><br>
流程如下：</p>
<ol>
<li>所有的写入命令会追加到aof_buf（ 缓冲区） 中。</li>
<li>AOF缓冲区根据对应的策略向硬盘做同步操作。</li>
<li>随着AOF文件越来越大， 需要定期对AOF文件进行重写， 达到压缩的目的。</li>
<li>当Redis服务器重启时， 可以加载AOF文件进行数据恢复。</li>
</ol>
<p><strong>aof重写</strong><br>
<img src="https://tinaxiawuhao.github.io/post-images/1620718497901.png" alt="" loading="lazy"><br>
AOF重新运作流程<br>
流程说明：</p>
<ol>
<li>执行AOF重写请求。<br>
如果当前进程正在执行AOF重写， 请求不执行并返回如下响应：<pre><code class="language-java">ERR Background append only file rewriting already in progress
</code></pre>
如果当前进程正在执行bgsave操作， 重写命令延迟到bgsave完成之后再执行， 返回如下响应：<pre><code class="language-sh">Background append only file rewriting scheduled
</code></pre>
</li>
<li>父进程执行fork创建子进程， 开销等同于bgsave过程。</li>
<li>3.1.  主进程fork操作完成后， 继续响应其他命令。 所有修改命令依然写入AOF缓冲区并根据appendfsync策略同步到硬盘， 保证原有AOF机制正确性。<br>
3.2.  由于fork操作运用写时复制技术， 子进程只能共享fork操作时的内存数据。 由于父进程依然响应命令， Redis使用“AOF重写缓冲区”保存这部分新数据， 防止新AOF文件生成期间丢失这部分数据。</li>
<li>子进程根据内存快照， 按照命令合并规则写入到新的AOF文件。 每次批量写入硬盘数据量由配置aof-rewrite-incremental-fsync控制， 默认为32MB， 防止单次刷盘数据过多造成硬盘阻塞。</li>
<li>5.1.  新AOF文件写入完成后， 子进程发送信号给父进程， 父进程更新统计信息， 具体见info persistence下的aof_*相关统计。<br>
5.2. 父进程把AOF重写缓冲区的数据写入到新的AOF文件。<br>
5.3.  使用新AOF文件替换老文件， 完成AOF重写。</li>
</ol>
<h4 id="aof追加阻塞">AOF追加阻塞</h4>
<p>当开启AOF持久化时， 常用的同步硬盘的策略是everysec， 用于平衡性能和数据安全性。 对于这种方式， Redis使用另一条线程每秒执行fsync同步硬盘。 当系统硬盘资源繁忙时， 会造成Redis主线程阻塞， 如图所示。<br>
<img src="https://tinaxiawuhao.github.io/post-images/1620808951472.png" alt="" loading="lazy"><br>
使用everysec做刷盘策略的流程</p>
<h5 id="阻塞流程分析">阻塞流程分析：</h5>
<p>1） 主线程负责写入AOF缓冲区。<br>
2） AOF线程负责每秒执行一次同步磁盘操作， 并记录最近一次同步时间。<br>
3） 主线程负责对比上次AOF同步时间：<br>
·如果距上次同步成功时间在2秒内， 主线程直接返回。<br>
·如果距上次同步成功时间超过2秒， 主线程将会阻塞， 直到同步操作完成。</p>
<p><strong>通过对AOF阻塞流程可以发现两个问题：</strong><br>
1） everysec配置最多可能丢失2秒数据， 不是1秒。<br>
2） 如果系统fsync缓慢， 将会导致Redis主线程阻塞影响效率。</p>
<h5 id="aof阻塞问题定位">AOF阻塞问题定位：</h5>
<p>1） 发生AOF阻塞时， Redis输出如下日志， 用于记录AOF fsync阻塞导致拖慢Redis服务的行为：</p>
<pre><code class="language-sh">Asynchronous AOF fsync is taking too long (disk is busy). Writing the AOF buffer without waiting for fsync to complete, this may slow down Redis
</code></pre>
<p>2） 每当发生AOF追加阻塞事件发生时， 在info Persistence统计中，aof_delayed_fsync指标会累加， 查看这个指标方便定位AOF阻塞问题。<br>
3） AOF同步最多允许2秒的延迟， 当延迟发生时说明硬盘存在高负载问题， 可以通过监控工具如iotop， 定位消耗硬盘IO资源的进程。优化AOF追加阻塞问题主要是优化系统硬盘负载</p>
<p><strong>优点：</strong></p>
<ul>
<li>1、数据安全，aof 持久化可以配置 appendfsync 属性。<br>
配置为always时， 每次写入都要同步AOF文件， 在一般的SATA硬盘上， Redis只能支持大约几百TPS写入， 显然跟Redis高性能特性背道而驰，不建议配置。<br>
配置为no， 由于操作系统每次同步AOF文件的周期不可控， 而且会加大每次同步硬盘的数据量， 虽然提升了性能， 但数据安全性无法保证。<br>
配置为everysec， 是建议的同步策略， 也是默认配置， 做到兼顾性能和数据安全性。 理论上只有在系统突然宕机的情况下丢失1秒的数据<br>
<img src="https://tinaxiawuhao.github.io/post-images/1620808300719.png" alt="" loading="lazy"></li>
<li>2、通过 append 模式写文件，即使中途服务器宕机，可以通过 redis-check-aof 工具解决数据一致性问题。</li>
<li>3、AOF 机制的 rewrite 模式。AOF 文件没被 rewrite 之前（文件过大时会对命令 进行合并重写），可以删除其中的某些命令（比如误操作的 flushall）)</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>1、AOF 文件比 RDB 文件大，且恢复速度慢。</li>
<li>2、数据集大的时候，比 rdb 启动效率低。</li>
</ul>
<h4 id="比较">比较</h4>
<ul>
<li>AOF文件比RDB更新频率高，优先使用AOF还原数据。</li>
<li>AOF比RDB更安全也更大</li>
<li>RDB性能比AOF好</li>
<li>如果两个都配了优先加载AOF<br>
<img src="https://tinaxiawuhao.github.io/post-images/1620718547797.png" alt="" loading="lazy"></li>
</ul>
<h3 id="如何选择合适的持久化方式">如何选择合适的持久化方式</h3>
<ul>
<li>一般来说， 如果想达到足以媲美PostgreSQL的数据安全性，你应该同时使用两种持久化功能。在这种情况下，当 Redis 重启的时候会优先载入AOF文件来恢复原始的数据，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整。</li>
<li>如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失，那么你可以只使用RDB持久化。</li>
<li>有很多用户都只使用AOF持久化，但并不推荐这种方式，因为定时生成RDB快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比AOF恢复的速度要快，除此之外，使用RDB还可以避免AOF程序的bug。</li>
<li>如果你只希望你的数据在服务器运行的时候存在，你也可以不使用任何持久化方式。</li>
</ul>
<h3 id="redis持久化数据和缓存怎么做扩容">Redis持久化数据和缓存怎么做扩容？</h3>
<ul>
<li>如果Redis被当做缓存使用，使用一致性哈希实现动态扩容缩容。</li>
<li>如果Redis被当做一个持久化存储使用，必须使用固定的keys-to-nodes映射关系，节点的数量一旦确定不能变化。否则的话(即Redis节点需要动态变化的情况），必须使用可以在运行时进行数据再平衡的一套系统，而当前只有Redis集群可以做到这样。</li>
</ul>
<h3 id="redis的过期键的删除策略">Redis的过期键的删除策略</h3>
<p>我们都知道，Redis是key-value数据库，我们可以设置Redis中缓存的key的过期时间。Redis的过期策略就是指当Redis中缓存的key过期了，Redis如何处理。</p>
<p>过期策略通常有以下三种：</p>
<ul>
<li>定时过期：每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即清除。该策略可以立即清除过期的数据，对内存很友好；但是会占用大量的CPU资源去处理过期的数据，从而影响缓存的响应时间和吞吐量。</li>
<li>惰性过期：只有当访问一个key时，才会判断该key是否已过期，过期则清除。该策略可以最大化地节省CPU资源，却对内存非常不友好。极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。</li>
<li>定期过期：每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。该策略是前两者的一个折中方案。通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得CPU和内存资源达到最优的平衡效果。</li>
</ul>
<p>(expires字典会保存所有设置了过期时间的key的过期时间数据，其中，key是指向键空间中的某个键的指针，value是该键的毫秒精度的UNIX时间戳表示的过期时间。键空间是指该Redis集群中保存的所有键。)</p>
<p>Redis中同时使用了惰性过期和定期过期两种过期策略。</p>
<h3 id="redis-key的过期时间和永久有效分别怎么设置">Redis key的过期时间和永久有效分别怎么设置？</h3>
<p>EXPIRE和PERSIST命令。</p>
<p><strong>我们知道通过expire来设置key 的过期时间，那么对过期的数据怎么处理呢?</strong></p>
<p>除了缓存服务器自带的缓存失效策略之外（Redis默认的有6种策略可供选择），我们还可以根据具体的业务需求进行自定义的缓存淘汰，常见的策略有两种：</p>
<ol>
<li>定时去清理过期的缓存；</li>
<li>当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。</li>
</ol>
<p>两者各有优劣，第一种的缺点是维护大量缓存的key是比较麻烦的，第二种的缺点就是每次用户请求过来都要判断缓存失效，逻辑相对比较复杂！具体用哪种方案，大家可以根据自己的应用场景来权衡。</p>
<h3 id="redis内存">redis内存</h3>
<p>redis内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。</p>
<h4 id="redis的内存淘汰策略有哪些">Redis的内存淘汰策略有哪些</h4>
<p>Redis的内存淘汰策略是指在Redis的用于缓存的内存不足时，怎么处理需要新写入且需要申请额外空间的数据。</p>
<p><strong>全局的键空间选择性移除</strong></p>
<ul>
<li>noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。</li>
<li>allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。（这个是<strong>最常用</strong>的）</li>
<li>allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。</li>
<li>allkeys-lfu：从所有键中驱逐使用频率最少的键</li>
</ul>
<p><strong>设置过期时间的键空间选择性移除</strong></p>
<ul>
<li>volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。</li>
<li>volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。</li>
<li>volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。</li>
<li>volatile-lfu：从所有配置了过期时间的键中驱逐使用频率最少的键</li>
</ul>
<h4 id="总结">总结</h4>
<p>Redis的内存淘汰策略的选取并不会影响过期的key的处理。内存淘汰策略用于处理内存不足时的需要申请额外空间的数据；过期策略用于处理过期的缓存数据。</p>
<h4 id="redis主要消耗什么物理资源">Redis主要消耗什么物理资源？</h4>
<p>内存。</p>
<h4 id="redis的内存用完了会发生什么">Redis的内存用完了会发生什么？</h4>
<p>如果达到设置的上限，Redis的写命令会返回错误信息（但是读命令还可以正常返回。）或者你可以配置内存淘汰机制，当Redis达到内存上限时会冲刷掉旧的内容。</p>
<h4 id="redis如何做内存优化">Redis如何做内存优化？</h4>
<p>可以好好利用Hash,list,sorted set,set等集合类型数据，因为通常情况下很多小的Key-Value可以用更紧凑的方式存放到一起。尽可能使用散列表（hashes），散列表（是说散列表里面存储的数少）使用的内存非常小，所以你应该尽可能的将你的数据模型抽象到一个散列表里面。比如你的web系统中有一个用户对象，不要为这个用户的名称，姓氏，邮箱，密码设置单独的key，而是应该把这个用户的所有信息存储到一张散列表里面</p>
<h3 id="redis线程模型">Redis线程模型</h3>
<p>Redis基于Reactor模式开发了网络事件处理器，这个处理器被称为文件事件处理器（file event handler）。它的组成结构为4部分：多个套接字、IO多路复用程序、文件事件分派器、事件处理器。因为文件事件分派器队列的消费是单线程的，所以Redis才叫单线程模型。</p>
<ul>
<li>文件事件处理器使用 I/O 多路复用（multiplexing）程序来同时监听多个套接字， 并根据套接字目前执行的任务来为套接字关联不同的事件处理器。</li>
<li>当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关闭（close）等操作时， 与操作相对应的文件事件就会产生， 这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。</li>
</ul>
<p>虽然文件事件处理器以单线程方式运行， 但通过使用 I/O 多路复用程序来监听多个套接字， 文件事件处理器既实现了高性能的网络通信模型， 又可以很好地与 redis 服务器中其他同样以单线程方式运行的模块进行对接， 这保持了 Redis 内部单线程设计的简单性。</p>
<p>参考：https://www.cnblogs.com/barrywxx/p/8570821.html</p>
<h3 id="事务">事务</h3>
<blockquote>
<p>事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断.事务是一个原子操作：事务中的命令要么全部被执行，要么全部都不执行。</p>
</blockquote>
<h4 id="redis事务的概念">Redis事务的概念</h4>
<p>Redis 事务的本质是通过MULTI、EXEC、DISCARD、WATCH等一组命令的集合。事务支持一次执行多个命令，一个事务中所有命令都会被序列化。在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。</p>
<p>总结说：redis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令。</p>
<h4 id="redis事务的三个阶段">Redis事务的三个阶段</h4>
<ol>
<li>事务开始 MULTI</li>
<li>命令入队</li>
<li>事务执行 EXEC</li>
</ol>
<p>事务执行过程中，如果服务端收到有EXEC、DISCARD、WATCH、MULTI之外的请求，将会把请求放入队列中排队</p>
<h4 id="redis事务相关命令">Redis事务相关命令</h4>
<p>Redis事务功能是通过MULTI、EXEC、DISCARD和WATCH 四个原语实现的</p>
<p>Redis会将一个事务中的所有命令序列化，然后按顺序执行。</p>
<ol>
<li><strong>redis 不支持回滚</strong>，“Redis 在事务失败时不进行回滚，而是继续执行余下的命令”， 所以 Redis 的内部可以保持简单且快速。</li>
<li><strong>如果在一个事务中的命令出现错误，那么所有的命令都不会执行</strong>；</li>
<li><strong>如果在一个事务中出现运行错误，那么正确的命令会被执行</strong>。</li>
</ol>
<ul>
<li>WATCH 命令是一个乐观锁，可以为 Redis 事务提供 check-and-set （CAS）行为。 可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行，监控一直持续到EXEC命令。</li>
<li>MULTI命令用于开启一个事务，它总是返回OK。 MULTI执行之后，客户端可以继续向服务器发送任意多条命令，这些命令不会立即被执行，而是被放到一个队列中，当EXEC命令被调用时，所有队列中的命令才会被执行。</li>
<li>EXEC：执行所有事务块内的命令。返回事务块内所有命令的返回值，按命令执行的先后顺序排列。 当操作被打断时，返回空值 nil 。</li>
<li>通过调用DISCARD，客户端可以清空事务队列，并放弃执行事务， 并且客户端会从事务状态中退出。</li>
<li>UNWATCH命令可以取消watch对所有key的监控。</li>
</ul>
<h4 id="事务管理acid概述">事务管理（ACID）概述</h4>
<ol>
<li>
<p>原子性（Atomicity）</p>
<p>原子性是指事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。</p>
</li>
<li>
<p>一致性（Consistency）</p>
<p>事务前后数据的完整性必须保持一致。</p>
</li>
<li>
<p>隔离性（Isolation）</p>
<p>多个事务并发执行时，一个事务的执行不应影响其他事务的执行</p>
</li>
<li>
<p>持久性（Durability）</p>
<p>持久性是指一个事务一旦被提交，它对数据库中数据的改变就是永久性的，接下来即使数据库发生故障也不应该对其有任何影响</p>
</li>
</ol>
<p><strong>Redis的事务总是具有ACID中的隔离性，不具有隔离级别</strong>，其他特性是不支持的。当服务器运行在<em>AOF</em>持久化模式下，并且appendfsync选项的值为always时，事务也具有持久性。</p>
<h4 id="redis事务支持隔离性吗">Redis事务支持隔离性吗</h4>
<p>Redis 是单进程程序，并且它保证在执行事务时，不会对事务进行中断，事务可以运行直到执行完所有事务队列中的命令为止。因此，<strong>Redis 的事务是总是带有隔离性的，因为是单线程不具有隔离级别</strong>。</p>
<h4 id="redis事务保证原子性吗支持回滚吗">Redis事务保证原子性吗，支持回滚吗</h4>
<p>Redis中，单条命令是原子性执行的，但<strong>事务不保证原子性，且没有回滚</strong>。事务中任意命令执行失败，其余的命令仍会被执行。</p>
<h4 id="redis事务其他实现">Redis事务其他实现</h4>
<ul>
<li>基于Lua脚本，Redis可以保证脚本内的命令一次性、按顺序地执行，</li>
</ul>
<p>其同时也不提供事务运行错误的回滚，执行过程中如果部分命令运行错误，剩下的命令还是会继续运行完</p>
<ul>
<li>基于中间标记变量，通过另外的标记变量来标识事务是否执行完成，读取数据时先读取该标记变量判断是否事务执行完成。但这样会需要额外写代码实现，比较繁琐</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[redis概述二]]></title>
        <id>https://tinaxiawuhao.github.io/post/YNIBE7Yaj/</id>
        <link href="https://tinaxiawuhao.github.io/post/YNIBE7Yaj/">
        </link>
        <updated>2021-05-14T08:43:43.000Z</updated>
        <content type="html"><![CDATA[<h3 id="redis有哪些数据类型">Redis有哪些数据类型</h3>
<p>Redis主要有5种数据类型，包括String，List，Set，Zset，Hash，满足大部分的使用要求</p>
<table>
<thead>
<tr>
<th style="text-align:left">数据类型</th>
<th style="text-align:left">可以存储的值</th>
<th style="text-align:left">操作</th>
<th style="text-align:left">应用场景</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">STRING</td>
<td style="text-align:left">字符串、整数或者浮点数</td>
<td style="text-align:left">对整个字符串或者字符串的其中一部分执行操作对整数和浮点数执行自增或者自减操作</td>
<td style="text-align:left">做简单的键值对缓存</td>
</tr>
<tr>
<td style="text-align:left">LIST</td>
<td style="text-align:left">列表</td>
<td style="text-align:left">从两端压入或者弹出元素对单个或者多个元素进行修剪，只保留一个范围内的元素</td>
<td style="text-align:left">存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的数据</td>
</tr>
<tr>
<td style="text-align:left">SET</td>
<td style="text-align:left">无序集合</td>
<td style="text-align:left">添加、获取、移除单个元素检查一个元素是否存在于集合中计算交集、并集、差集从集合里面随机获取元素</td>
<td style="text-align:left">交集、并集、差集的操作，比如交集，可以把两个人的粉丝列表整一个交集</td>
</tr>
<tr>
<td style="text-align:left">HASH</td>
<td style="text-align:left">包含键值对的无序散列表</td>
<td style="text-align:left">添加、获取、移除单个键值对获取所有键值对检查某个键是否存在</td>
<td style="text-align:left">结构化的数据，比如一个对象</td>
</tr>
<tr>
<td style="text-align:left">ZSET</td>
<td style="text-align:left">有序集合</td>
<td style="text-align:left">添加、获取、删除元素根据分值范围或者成员来获取元素计算一个键的排名</td>
<td style="text-align:left">去重但可以排序，如获取排名前几名的用户</td>
</tr>
</tbody>
</table>
<h3 id="redis数据详解">Redis数据详解</h3>
<h4 id="string">String</h4>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1620702855667.png" alt="img" loading="lazy"></figure>
<ol>
<li>
<p>设置值</p>
<pre><code class="language-java">//设置值
set key value [ex seconds] [px milliseconds] [nx|xx]

127.0.0.1:6379&gt; set hello world
</code></pre>
<blockquote>
<p>set命令有几个选项：<br>
·ex seconds： 为键设置秒级过期时间。<br>
·px milliseconds： 为键设置毫秒级过期时间。<br>
·nx： 键必须不存在， 才可以设置成功， 用于添加。<br>
·xx： 与nx相反， 键必须存在， 才可以设置成功， 用于更新。</p>
</blockquote>
<pre><code class="language-java">// 因为键hello已存在， 所以setnx失败， 返回结果为0
127.0.0.1:6379&gt; setnx hello redis
(integer) 0
//因为键hello已存在， 所以set xx成功， 返回结果为OK：
127.0.0.1:6379&gt; set hello jedis xx
OK
</code></pre>
<p>setnx和setxx在实际使用中有什么应用场景吗？ 以setnx命令为例子， 由于Redis的单线程命令处理机制， 如果有多个客户端同时执行setnx key value，根据setnx的特性只有一个客户端能设置成功， setnx可以作为分布式锁的一种实现方案， Redis官方给出了使用setnx实现分布式锁的方法： http://redis.io/topics/distlock。</p>
</li>
<li>
<p>获取值</p>
<pre><code class="language-java">get key
//下面操作获取键hello的值：
127.0.0.1:6379&gt; get hello
&quot;world&quot;
//如果要获取的键不存在， 则返回nil（空） ：
127.0.0.1:6379&gt; get not_exist_key
(nil)
</code></pre>
</li>
<li>
<p>批量设置值</p>
<pre><code class="language-java">mset key value [key value ...]
//下面操作通过mset命令一次性设置4个键值对：
127.0.0.1:6379&gt; mset a 1 b 2 c 3 d 4
OK
</code></pre>
</li>
<li>
<p>批量获取值</p>
<pre><code class="language-java">mget key [key ...]
//下面操作批量获取了键a、 b、 c、 d的值：
127.0.0.1:6379&gt; mget a b c d
1) &quot;1&quot;
2) &quot;2&quot;
3) &quot;3&quot;
4) &quot;4&quot;
如果有些键不存在， 那么它的值为nil（空） ， 结果是按照传入键的顺序返回：
127.0.0.1:6379&gt; mget a b c f
1) &quot;1&quot;
2) &quot;2&quot;
3) &quot;3&quot;
4) (nil)
</code></pre>
</li>
<li>
<p>计数</p>
<pre><code class="language-java">incr key
//incr命令用于对值做自增操作， 返回结果分为三种情况：
//·值不是整数， 返回错误。
//·值是整数， 返回自增后的结果。
//·键不存在， 按照值为0自增， 返回结果为1。
//例如对一个不存在的键执行incr操作后， 返回结果是1：
127.0.0.1:6379&gt; exists key
(integer) 0
127.0.0.1:6379&gt; incr key
(integer) 1
//再次对键执行incr命令， 返回结果是2：
127.0.0.1:6379&gt; incr key
(integer) 2
//如果值不是整数， 那么会返回错误：
127.0.0.1:6379&gt; set hello world
OK
127.0.0.1:6379&gt; incr hello
(error) ERR value is not an integer or out of range
//除了incr命令， Redis提供了decr(自减)、incrby(自增指定数字)、decrby(自减指定数字)、incrbyfloat(自增浮点数)：
decr key
incrby key increment
decrby key decrement
incrbyfloat key increment
//很多存储系统和编程语言内部使用CAS机制实现计数功能， 会有一定的CPU开销， 但在Redis中完全不存在这个问题， 因为Redis是单线程架构， 任何命令到了Redis服务端都要顺序执行
</code></pre>
</li>
</ol>
<h4 id="string使用场景">String使用场景</h4>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1620702881825.png" alt="img" loading="lazy"></figure>
<ol>
<li>缓存功能</li>
<li>计数</li>
<li>共享Session</li>
<li>限速</li>
</ol>
<h4 id="list">List</h4>
<p><img src="https://tinaxiawuhao.github.io/post-images/1620702898919.png" alt="img" loading="lazy"><br>
<img src="https://tinaxiawuhao.github.io/post-images/1620702909739.png" alt="img" loading="lazy"><br>
<img src="https://tinaxiawuhao.github.io/post-images/1620702922813.png" alt="img" loading="lazy"></p>
<ol>
<li>
<p>添加</p>
<pre><code class="language-java">//从右边插入元素
rpush key value [value ...]
//下面代码从右向左插入元素c、 b、 a：
127.0.0. 1:6379&gt; rpush listkey c b a
(integer) 3
//lrange0-1命令可以从左到右获取列表的所有元素：
127.0.0.1:6379&gt; lrange listkey 0 -1
1) &quot;c&quot;
2) &quot;b&quot;
3) &quot;a&quot;
</code></pre>
<pre><code class="language-java">//从左边插入元素
lpush key value [value ...]
使用方法和rpush相同， 只不过从左侧插入。
</code></pre>
<pre><code class="language-java">//向某个元素前或者后插入元素
linsert key before|after pivot value
//linsert命令会从列表中找到等于pivot的元素， 在其前(before)或者后(after)插入一个新的元素value， 例如下面操作会在列表的元素b前插入java：
127.0.0.1:6379&gt; linsert listkey before b java
(integer) 4
//返回结果为4， 代表当前命令的长度， 当前列表变为：
127.0.0.1:6379&gt; lrange listkey 0 -1
1) &quot;c&quot;
2) &quot;java&quot;
3) &quot;b&quot;
4) &quot;a&quot;
</code></pre>
</li>
<li>
<p>查找</p>
<pre><code class="language-java">//获取指定范围内的元素列表
lrange key start end
//lrange操作会获取列表指定索引范围所有的元素。 索引下标有两个特点： 第一， 索引下标从左到右分别是0到N-1， 但是从右到左分别是-1到-N。
//第二， lrange中的end选项包含了自身， 这个和很多编程语言不包含end不太相同， 例如想获取列表的第2到第4个元素， 可以执行如下操作：
127.0.0.1:6379&gt; lrange listkey 1 3
1) &quot;java&quot;
2) &quot;b&quot;
3) &quot;a&quot;
</code></pre>
<pre><code class="language-java">//获取列表指定索引下标的元素
lindex key index
//例如当前列表最后一个元素为a：
127.0.0.1:6379&gt; lindex listkey -1
&quot;a&quot;
</code></pre>
<pre><code class="language-java">// 获取列表长度
llen key
//例如， 下面示例当前列表长度为4：
127.0.0.1:6379&gt; llen listkey
(integer) 4
</code></pre>
</li>
<li>
<p>删除</p>
<pre><code class="language-java">//从列表左侧弹出元素
lpop key
//如下操作将列表最左侧的元素c会被弹出， 弹出后列表变为java、 b、a：
127.0.0.1:6379&gt;t lpop listkey
&quot;c&quot;
127.0.0.1:6379&gt; lrange listkey 0 -1
1) &quot;java&quot;
2) &quot;b&quot;
3) &quot;a&quot;
</code></pre>
<pre><code class="language-java">//从列表右侧弹出
rpop key
它的使用方法和lpop是一样的， 只不过从列表右侧弹出
</code></pre>
<pre><code class="language-java">//删除指定元素
lrem key count value
//lrem命令会从列表中找到等于value的元素进行删除， 根据count的不同分为三种情况：
//·count&gt;0， 从左到右， 删除最多count个元素。
//·count&lt;0， 从右到左， 删除最多count绝对值个元素。
//·count=0， 删除所有。
//例如向列表从左向右插入5个a， 那么当前列表变为“a a a a a java b a”，
//下面操作将从列表左边开始删除4个为a的元素：
127.0.0.1:6379&gt; lrem listkey 4 a
(integer) 4
127.0.0.1:6379&gt; lrange listkey 0 -1
1) &quot;a&quot;
2) &quot;java&quot;
3) &quot;b&quot;
4) &quot;a&quot;
</code></pre>
<pre><code class="language-java">//按照索引范围修剪列表
ltrim key start end
//例如， 下面操作会只保留列表listkey第2个到第4个元素：
127.0.0.1:6379&gt; ltrim listkey 1 3
OK
127.0.0.1:6379&gt; lrange listkey 0 -1
1) &quot;java&quot;
2) &quot;b&quot;
3) &quot;a&quot;
</code></pre>
</li>
<li>
<p>修改</p>
<pre><code class="language-java">//修改指定索引下标的元素：
lset key index newValue
//下面操作会将列表listkey中的第3个元素设置为python：
127.0.0.1:6379&gt; lset listkey 2 python
OK
127.0.0.1:6379&gt; lrange listkey 0 -1
1) &quot;java&quot;
2) &quot;b&quot;
3) &quot;python&quot;
</code></pre>
</li>
<li>
<p>阻塞操作</p>
<pre><code class="language-java">//阻塞式弹出如下：
blpop key [key ...] timeout
brpop key [key ...] timeout
//blpop和brpop是lpop和rpop的阻塞版本， 它们除了弹出方向不同， 使用方法基本相同， 所以下面以brpop命令进行说明， brpop命令包含两个参数：
//·key[key...]： 多个列表的键。
//·timeout： 阻塞时间（单位： 秒） 。
    
//列表为空： 如果timeout=3， 那么客户端要等到3秒后返回， 如果timeout=0， 那么客户端一直阻塞等下去：
127.0.0.1:6379&gt; brpop list:test 3
(nil)
(3.10s)
127.0.0.1:6379&gt; brpop list:test 0
//...阻塞...
//如果此期间添加了数据element1， 客户端立即返回：
127.0.0.1:6379&gt; brpop list:test 3
1) &quot;list:test&quot;
2) &quot;element1&quot;
(2.06s)
    
//列表不为空： 客户端会立即返回。
127.0.0.1:6379&gt; brpop list:test 0
1) &quot;list:test&quot;
2) &quot;element1&quot;

//在使用brpop时， 有两点需要注意。
//第一点， 如果是多个键， 那么brpop会从左至右遍历键， 一旦有一个键能弹出元素， 客户端立即返回：
127.0.0.1:6379&gt; brpop list:1 list:2 list:3 0
//..阻塞..
//此时另一个客户端分别向list： 2和list： 3插入元素：
client-lpush&gt; lpush list:2 element2
(integer) 1
client-lpush&gt; lpush list:3 element3
(integer) 1
//客户端会立即返回list： 2中的element2， 因为list： 2最先有可以弹出的元素：
127.0.0.1:6379&gt; brpop list:1 list:2 list:3 0
1) &quot;list:2&quot;
2) &quot;element2_1&quot;
//第二点， 如果多个客户端对同一个键执行brpop， 那么最先执行brpop命令的客户端可以获取到弹出的值。
//客户端1：
client-1&gt; brpop list:test 0
//...阻塞...
//客户端2：
client-2&gt; brpop list:test 0
//...阻塞...
//客户端3：
client-3&gt; brpop list:test 0
//...阻塞...
//此时另一个客户端lpush一个元素到list： test列表中：
client-lpush&gt; lpush list:test element
(integer) 1
//那么客户端1最会获取到元素， 因为客户端1最先执行brpop， 而客户端2和客户端3继续阻塞：
client&gt; brpop list:test 0
1) &quot;list:test&quot;
2) &quot;element&quot;
</code></pre>
</li>
</ol>
<h4 id="list使用场景">List使用场景</h4>
<blockquote>
<p>lpush+lpop=Stack（ 栈）<br>
lpush+rpop=Queue（ 队列）<br>
lpush+ltrim=Capped Collection（ 有限集合）<br>
lpush+brpop=Message Queue（ 消息队列）</p>
</blockquote>
<h4 id="set">Set</h4>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1620711808145.png" alt="img" loading="lazy"></figure>
<ul>
<li>
<p>集合内操作</p>
<ol>
<li>
<p>添加元素</p>
<pre><code class="language-java">//sadd key element [element ...]
//返回结果为添加成功的元素个数， 例如：
127.0.0.1:6379&gt; exists myset
(integer) 0
127.0.0.1:6379&gt; sadd myset a b c
(integer) 3
127.0.0.1:6379&gt; sadd myset a b
(integer) 0
</code></pre>
</li>
<li>
<p>删除元素</p>
<pre><code class="language-java">//srem key element [element ...]
//返回结果为成功删除元素个数， 例如：
127.0.0.1:6379&gt; srem myset a b
(integer) 2
127.0.0.1:6379&gt; srem myset hello
(integer) 0
</code></pre>
</li>
<li>
<p>计算元素个数</p>
<pre><code class="language-java">//scard key
//scard的时间复杂度为O（1） ， 它不会遍历集合所有元素， 而是直接用Redis内部的变量， 例如：
127.0.0.1:6379&gt; scard myset
(integer) 1
</code></pre>
</li>
<li>
<p>判断元素是否在集合中</p>
<pre><code class="language-java">//sismember key element
//如果给定元素element在集合内返回1， 反之返回0， 例如：
127.0.0.1:6379&gt; sismember myset c
(integer) 1
</code></pre>
</li>
<li>
<p>随机从集合返回指定个数元素</p>
<pre><code class="language-java">//srandmember key [count]
//[count]是可选参数， 如果不写默认为1， 例如：
127.0.0.1:6379&gt; srandmember myset 2
1) &quot;a&quot;
2) &quot;c&quot;
127.0.0.1:6379&gt; srandmember myset
&quot;d&quot;
</code></pre>
</li>
<li>
<p>从集合随机弹出元素</p>
<pre><code class="language-java">//spop key
//spop操作可以从集合中随机弹出一个元素， 例如下面代码是一次spop后， 集合元素变为&quot;d b a&quot;：
123
127.0.0.1:6379&gt; spop myset
&quot;c&quot;
127.0.0.1:6379&gt; smembers myset
1) &quot;d&quot;
2) &quot;b&quot;
3) &quot;a&quot;
//需要注意的是Redis从3.2版本开始， spop也支持[count]参数。
//srandmember和spop都是随机从集合选出元素， 两者不同的是spop命令执行后， 元素会从集合中删除， 而srandmember不会。
</code></pre>
</li>
<li>
<p>获取所有元素</p>
<pre><code class="language-java">//smembers key
//下面代码获取集合myset所有元素， 并且返回结果是无序的：
127.0.0.1:6379&gt; smembers myset
1) &quot;d&quot;
2) &quot;b&quot;
3) &quot;a&quot;
//smembers和lrange、 hgetall都属于比较重的命令， 如果元素过多存在阻塞Redis的可能性， 这时候可以使用sscan来完成， 有关sscan命令2.7节会介绍。
</code></pre>
</li>
</ol>
</li>
<li>
<p>集合间操作</p>
<pre><code class="language-java">//现在有两个集合， 它们分别是user： 1： follow和user： 2： follow：
127.0.0.1:6379&gt; sadd user:1:follow it music his sports
(integer) 4
127.0.0.1:6379&gt; sadd user:2:follow it news ent sports
(integer) 4
124
</code></pre>
<ol>
<li>
<p>求多个集合的交集</p>
<pre><code class="language-java">//sinter key [key ...]
//例如下面代码是求user： 1： follow和user： 2： follow两个集合的交集，返回结果是sports、 it：
127.0.0.1:6379&gt; sinter user:1:follow user:2:follow
1) &quot;sports&quot;
2) &quot;it&quot;
</code></pre>
</li>
<li>
<p>求多个集合的并集</p>
<pre><code class="language-java">//suinon key [key ...]
//例如下面代码是求user： 1： follow和user： 2： follow两个集合的并集，返回结果是sports、 it、 his、 news、 music、 ent：
127.0.0.1:6379&gt; sunion user:1:follow user:2:follow
1) &quot;sports&quot;
2) &quot;it&quot;
3) &quot;his&quot;
4) &quot;news&quot;
5) &quot;music&quot;
6) &quot;ent&quot;
</code></pre>
</li>
<li>
<p>求多个集合的差集</p>
<pre><code class="language-java">//sdiff key [key ...]
//例如下面代码是求user： 1： follow和user： 2： follow两个集合的差集，返回结果是music和his：
127.0.0.1:6379&gt; sdiff user:1:follow user:2:follow
1) &quot;music&quot;
2) &quot;his&quot;
</code></pre>
<p>前面三个命令如图所示<br>
<img src="https://tinaxiawuhao.github.io/post-images/1620711875701.png" alt="img" loading="lazy"></p>
</li>
<li>
<p>将交集、 并集、 差集的结果保存</p>
<pre><code class="language-java">sinterstore destination key [key ...]
suionstore destination key [key ...]
sdiffstore destination key [key ...]
</code></pre>
<p>集合间的运算在元素较多的情况下会比较耗时， 所以Redis提供了上面三个命令（原命令+store） 将集合间交集、 并集、 差集的结果保存在destination key中， 例如下面操作将user： 1： follow和user： 2： follow两个集合的交集结果保存在user： 1_2： inter中， user： 1_2： inter本身也是集合类<br>
型：</p>
<pre><code class="language-java">127.0.0.1:6379&gt; sinterstore user:1_2:inter user:1:follow user:2:follow
(integer) 2
127.0.0.1:6379&gt; type user:1_2:inter
set
127.0.0.1:6379&gt; smembers user:1_2:inter
1) &quot;it&quot;
2) &quot;sports&quot;
</code></pre>
</li>
</ol>
</li>
</ul>
<h4 id="set使用场景">Set使用场景</h4>
<blockquote>
<p>sadd=Tagging（标签）<br>
spop/srandmember=Random item（生成随机数， 比如抽奖）<br>
sadd+sinter=Social Graph（社交需求）</p>
</blockquote>
<h4 id="zset">Zset</h4>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1620711899603.png" alt="img" loading="lazy"></figure>
<ul>
<li>
<p>集合内操作</p>
<ol>
<li>
<p>添加成员</p>
<pre><code class="language-java">//zadd key score member [score member ...]
//下面操作向有序集合user： ranking添加用户tom和他的分数251：
127.0.0.1:6379&gt; zadd user:ranking 251 tom
(integer) 1
//返回结果代表成功添加成员的个数：
127.0.0.1:6379&gt; zadd user:ranking 1 kris 91 mike 200 frank 220 tim 250 martin
(integer) 5
</code></pre>
<p>有关zadd命令有两点需要注意：<br>
Redis3.2为zadd命令添加了nx、 xx、 ch、 incr四个选项：<br>
nx： member必须不存在， 才可以设置成功， 用于添加。<br>
xx： member必须存在， 才可以设置成功， 用于更新。<br>
ch： 返回此次操作后， 有序集合元素和分数发生变化的个数<br>
incr： 对score做增加， 相当于后面介绍的zincrby。<br>
有序集合相比集合提供了排序字段， 但是也产生了代价， zadd的时间复杂度为O（log（n） ） ， sadd的时间复杂度为O（1） 。</p>
</li>
<li>
<p>计算成员个数</p>
<pre><code class="language-java">//zcard key
//例如下面操作返回有序集合user： ranking的成员数为5， 和集合类型的scard命令一样， zcard的时间复杂度为O（1） 。
127.0.0.1:6379&gt; zcard user:ranking
(integer) 5
</code></pre>
</li>
<li>
<p>计算某个成员的分数</p>
<pre><code class="language-java">//zscore key member
//tom的分数为251， 如果成员不存在则返回nil：
127.0.0.1:6379&gt; zscore user:ranking tom
&quot;251&quot;
127.0.0.1:6379&gt; zscore user:ranking test
(nil)
</code></pre>
</li>
<li>
<p>计算成员的排名</p>
<pre><code class="language-java">//zrank key member
//zrevrank key member
//zrank是从分数从低到高返回排名， zrevrank反之。 例如下面操作中， tom在zrank和zrevrank分别排名第5和第0（排名从0开始计算） 。
127.0.0.1:6379&gt; zrank user:ranking tom
(integer) 5
127.0.0.1:6379&gt; zrevrank user:ranking tom
(integer) 0
</code></pre>
</li>
<li>
<p>删除成员</p>
<pre><code class="language-java">//zrem key member [member ...]
//下面操作将成员mike从有序集合user： ranking中删除。
127.0.0.1:6379&gt; zrem user:ranking mike
(integer) 1
//返回结果为成功删除的个数。
</code></pre>
</li>
<li>
<p>增加成员的分数</p>
<pre><code class="language-java">//zincrby key increment member
//下面操作给tom增加了9分， 分数变为了260分：
127.0.0.1:6379&gt; zincrby user:ranking 9 tom
&quot;260&quot;
</code></pre>
</li>
<li>
<p>返回指定排名范围的成员</p>
<pre><code class="language-java">//zrange key start end [withscores]
//zrevrange key start end [withscores]
//有序集合是按照分值排名的， zrange是从低到高返回， zrevrange反之。
//下面代码返回排名最低的是三个成员， 如果加上withscores选项， 同时会返回成员的分数：
127.0.0.1:6379&gt; zrange user:ranking 0 2 withscores
1) &quot;kris&quot;
2) &quot;1&quot;
3) &quot;frank&quot;
4) &quot;200&quot;
5) &quot;tim&quot;
6) &quot;220&quot;
127.0.0.1:6379&gt; zrevrange user:ranking 0 2 withscores
1) &quot;tom&quot;
2) &quot;260&quot;
3) &quot;martin&quot;
4) &quot;250&quot;
5) &quot;tim&quot;
6) &quot;220&quot;
</code></pre>
</li>
<li>
<p>返回指定分数范围的成员</p>
<pre><code class="language-java">//zrangebyscore key min max [withscores] [limit offset count]
//zrevrangebyscore key max min [withscores] [limit offset count]
//其中zrangebyscore按照分数从低到高返回， zrevrangebyscore反之。 例如下面操作从低到高返回200到221分的成员， withscores选项会同时返回每个成员的分数。 [limit offset count]选项可以限制输出的起始位置和个数：
127.0.0.1:6379&gt; zrangebyscore user:ranking 200 tinf withscores
1) &quot;frank&quot;
2) &quot;200&quot;
3) &quot;tim&quot;
4) &quot;220&quot;
127.0.0.1:6379&gt; zrevrangebyscore user:ranking 221 200 withscores
1) &quot;tim&quot;
2) &quot;220&quot;
3) &quot;frank&quot;
4) &quot;200&quot;
//同时min和max还支持开区间（ 小括号） 和闭区间（ 中括号） ， -inf和+inf分别代表无限小和无限大：
127.0.0.1:6379&gt; zrangebyscore user:ranking (200 +inf withscores
1) &quot;tim&quot;
2) &quot;220&quot;
3) &quot;martin&quot;
4) &quot;250&quot;
5) &quot;tom&quot;
6) &quot;260&quot;
</code></pre>
</li>
<li>
<p>返回指定分数范围成员个数</p>
<pre><code class="language-java">//zcount key min max
//下面操作返回200到221分的成员的个数：
127.0.0.1:6379&gt; zcount user:ranking 200 221
(integer) 2
</code></pre>
</li>
<li>
<p>删除指定排名内的升序元素</p>
<pre><code class="language-java">//zremrangebyrank key start end
//下面操作删除第start到第end名的成员：
127.0.0.1:6379&gt; zremrangebyrank user:ranking 0 2
(integer) 3
</code></pre>
</li>
<li>
<p>删除指定分数范围的成员</p>
<pre><code class="language-java">//zremrangebyscore key min max
//下面操作将250分以上的成员全部删除， 返回结果为成功删除的个数：
127.0.0.1:6379&gt; zremrangebyscore user:ranking (250 +inf
(integer) 2
</code></pre>
</li>
</ol>
</li>
<li>
<p>集合间操作</p>
<p>将图中的两个有序集合导入到Redis中。<br>
<img src="https://tinaxiawuhao.github.io/post-images/1620711939016.png" alt="img" loading="lazy"></p>
<pre><code class="language-java">127.0.0.1:6379&gt; zadd user:ranking:1 1 kris 91 mike 200 frank 220 tim 250 martin
251 tom
(integer) 6
127.0.0.1:6379&gt; zadd user:ranking:2 8 james 77 mike 625 martin 888 tom
(integer) 4
</code></pre>
<ol>
<li>
<p>交集</p>
<pre><code class="language-java">//zinterstore destination numkeys key [key ...] [weights weight [weight ...]][aggregate sum|min|max]
//这个命令参数较多， 下面分别进行说明：
//·destination： 交集计算结果保存到这个键。
//·numkeys： 需要做交集计算键的个数。
//·key[key...]： 需要做交集计算的键。
//·weights weight[weight...]： 每个键的权重， 在做交集计算时， 每个键中的每个member会将自己分数乘以这个权重， 每个键的权重默认是1。
//·aggregate sum|min|max： 计算成员交集后， 分值可以按照sum（ 和） 、min（ 最小值） 、 max（ 最大值） 做汇总， 默认值是sum。
//下面操作对user： ranking： 1和user： ranking： 2做交集， weights和aggregate使用了默认配置， 可以看到目标键user： ranking： 1_inter_2对分值做了sum操作：
127.0.0.1:6379&gt; zinterstore user:ranking:1_inter_2 2 user:ranking:1
user:ranking:2
(integer) 3
127.0.0.1:6379&gt; zrange user:ranking:1_inter_2 0 -1 withscores
1) &quot;mike&quot;
2) &quot;168&quot;
3) &quot;martin&quot;
4) &quot;875&quot;
5) &quot;tom&quot;
6) &quot;1139&quot;
//如果想让user： ranking： 2的权重变为0.5， 并且聚合效果使用max， 可以执行如下操作：
127.0.0.1:6379&gt; zinterstore user:ranking:1_inter_2 2 user:ranking:1
user:ranking:2 weights 1 0.5 aggregate max
(integer) 3
127.0.0.1:6379&gt; zrange user:ranking:1_inter_2 0 -1 withscores
1) &quot;mike&quot;
2) &quot;91&quot;
3) &quot;martin&quot;
4) &quot;312.5&quot;
5) &quot;tom&quot;
6) &quot;444&quot;
</code></pre>
</li>
<li>
<p>并集</p>
<pre><code class="language-java">//zunionstore destination numkeys key [key ...] [weights weight [weight ...]][aggregate sum|min|max]
//该命令的所有参数和zinterstore是一致的， 只不过是做并集计算， 例如下面操作是计算user： ranking： 1和user： ranking： 2的并集， weights和
//aggregate使用了默认配置， 可以看到目标键user： ranking： 1_union_2对分值做了sum操作：
127.0.0.1:6379&gt; zunionstore user:ranking:1_union_2 2 user:ranking:1
user:ranking:2
(integer) 7
127.0.0.1:6379&gt; zrange user:ranking:1_union_2 0 -1 withscores
1) &quot;kris&quot;
2) &quot;1&quot;
3) &quot;james&quot;
4) &quot;8&quot;
5) &quot;mike&quot;
6) &quot;168&quot;
7) &quot;frank&quot;
8) &quot;200&quot;
9) &quot;tim&quot;
10) &quot;220&quot;
11) &quot;martin&quot;
12) &quot;875&quot;
13) &quot;tom&quot;
14) &quot;1139&quot;
</code></pre>
</li>
</ol>
</li>
</ul>
<h4 id="zset使用场景">Zset使用场景</h4>
<p>有序集合比较典型的使用场景就是排行榜系统。 例如视频网站需要对用户上传的视频做排行榜， 榜单的维度可能是多个方面的： 按照时间、 按照播<br>
放数量、 按照获得的赞数。 本节使用赞数这个维度， 记录每天用户上传视频的排行榜。 主要需要实现以下4个功能。</p>
<ol>
<li>
<p>添加用户赞数<br>
例如用户mike上传了一个视频， 并获得了3个赞， 可以使用有序集合的zadd和zincrby功能：</p>
<pre><code class="language-sh">zadd user:ranking:2016_03_15 mike 3
</code></pre>
<p>如果之后再获得一个赞， 可以使用zincrby：</p>
<pre><code class="language-sh">zincrby user:ranking:2016_03_15 mike 1
</code></pre>
</li>
<li>
<p>取消用户赞数<br>
由于各种原因（例如用户注销、 用户作弊） 需要将用户删除， 此时需要将用户从榜单中删除掉， 可以使用zrem。 例如删除成员tom：</p>
<pre><code class="language-sh">zrem user:ranking:2016_03_15 mike
</code></pre>
</li>
<li>
<p>展示获取赞数最多的十个用户<br>
此功能使用zrevrange命令实现：</p>
<pre><code class="language-sh">zrevrangebyrank user:ranking:2016_03_15 0 9
</code></pre>
</li>
<li>
<p>展示用户信息以及用户分数<br>
此功能将用户名作为键后缀， 将用户信息保存在哈希类型中， 至于用户的分数和排名可以使用zscore和zrank两个功能：</p>
<pre><code class="language-sh">hgetall user:info:tom
zscore user:ranking:2016_03_15 mike
zrank user:ranking:2016_03_15 mik  
</code></pre>
</li>
</ol>
<h4 id="hash">Hash</h4>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1620711973275.png" alt="img" loading="lazy"></figure>
<ol>
<li>
<p>设置值</p>
<pre><code class="language-java">//hset key field value
//下面为user： 1添加一对field-value：
127.0.0.1:6379&gt; hset user:1 name tom
(integer) 1
//如果设置成功会返回1， 反之会返回0。 此外Redis提供了hsetnx命令， 它们的关系就像set和setnx命令一样， 只不过作用域由键变为field。
</code></pre>
</li>
<li>
<p>获取值</p>
<pre><code class="language-java">//hget key field
//例如， 下面操作获取user： 1的name域（属性） 对应的值：
127.0.0.1:6379&gt; hget user:1 name
&quot;tom&quot;
//如果键或field不存在， 会返回nil：
127.0.0.1:6379&gt; hget user:2 name
(nil)
127.0.0.1:6379&gt; hget user:1 age
(nil)
</code></pre>
</li>
<li>
<p>删除field</p>
<pre><code class="language-java">//hdel key field [field ...]
//hdel会删除一个或多个field， 返回结果为成功删除field的个数， 例如：
127.0.0.1:6379&gt; hdel user:1 name
(integer) 1
127.0.0.1:6379&gt; hdel user:1 age
(integer) 0
</code></pre>
</li>
<li>
<p>计算field个数</p>
<pre><code class="language-java">//hlen key
//例如user： 1有3个field：
127.0.0.1:6379&gt; hset user:1 name tom
(integer) 1
127.0.0.1:6379&gt; hset user:1 age 23
(integer) 1
127.0.0.1:6379&gt; hset user:1 city tianjin
(integer) 1
127.0.0.1:6379&gt; hlen user:1
(integer) 3
</code></pre>
</li>
<li>
<p>批量设置或获取field-value</p>
<pre><code class="language-java">//hmget key field [field ...]
//hmset key field value [field value ...]
//hmset和hmget分别是批量设置和获取field-value， hmset需要的参数是key和多对field-value， hmget需要的参数是key和多个field。 例如：
127.0.0.1:6379&gt; hmset user:1 name mike age 12 city tianjin
OK
127.0.0.1:6379&gt; hmget user:1 name city
1) &quot;mike&quot;
2) &quot;tianjin&quot;
</code></pre>
</li>
<li>
<p>判断field是否存在</p>
<pre><code class="language-java">//hexists key field
//例如， user： 1包含name域， 所以返回结果为1， 不包含时返回0：
127.0.0.1:6379&gt; hexists user:1 name
(integer) 1
</code></pre>
</li>
<li>
<p>获取所有field</p>
<pre><code class="language-java">//hkeys key
//hkeys命令应该叫hfields更为恰当， 它返回指定哈希键所有的field， 例如：
127.0.0.1:6379&gt; hkeys user:1
1) &quot;name&quot;
2) &quot;age&quot;
3) &quot;city&quot;
</code></pre>
</li>
<li>
<p>获取所有value</p>
<pre><code class="language-java">//hvals key
下面操作获取user： 1全部value：
127.0.0.1:6379&gt; hvals user:1
1) &quot;mike&quot;
2) &quot;12&quot;
3) &quot;tianjin&quot;
</code></pre>
</li>
<li>
<p>获取所有的field-value</p>
<pre><code class="language-java">//hgetall key
//下面操作获取user： 1所有的field-value：
127.0.0.1:6379&gt; hgetall user:1
1) &quot;name&quot;
2) &quot;mike&quot;
3) &quot;age&quot;
4) &quot;12&quot;
5) &quot;city&quot;
6) &quot;tianjin&quot;
</code></pre>
<p>在使用hgetall时， 如果哈希元素个数比较多， 会存在阻塞Redis的可能。<br>
如果开发人员只需要获取部分field， 可以使用hmget， 如果一定要获取全部field-value， 可以使用hscan命令， 该命令会渐进式遍历哈希类型.</p>
</li>
<li>
<p>hincrby hincrbyfloat</p>
<pre><code class="language-java">//hincrby key field
//hincrbyfloat key field
//hincrby和hincrbyfloat， 就像incrby和incrbyfloat命令一样， 但是它们的作用域是filed。
</code></pre>
</li>
<li>
<p>计算value的字符串长度（需要Redis3.2以上）</p>
<pre><code class="language-java">//hstrlen key field
//例如hget user： 1name的value是tom， 那么hstrlen的返回结果是3：
127.0.0.1:6379&gt; hstrlen user:1 name
(integer) 3
</code></pre>
</li>
</ol>
<h4 id="hash使用场景">Hash使用场景</h4>
<p>保存对象信息<br>
<img src="https://tinaxiawuhao.github.io/post-images/1620712022434.png" alt="img" loading="lazy"></p>
<h3 id="redis-发布订阅">Redis 发布订阅</h3>
<p>Redis 发布订阅 (pub/sub) 是一种消息通信模式：发送者 (pub) 发送消息，订阅者 (sub) 接收消息。</p>
<p>Redis 客户端可以订阅任意数量的频道。</p>
<p>下图展示了频道 channel1 ， 以及订阅这个频道的三个客户端 —— client2 、 client5 和 client1 之间的关系：</p>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1634545852554.png" alt="" loading="lazy"></figure>
<p>当有新消息通过 PUBLISH 命令发送给频道 channel1 时， 这个消息就会被发送给订阅它的三个客户端：</p>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1634545878403.png" alt="" loading="lazy"></figure>
<hr>
<h4 id="实例">实例</h4>
<p>以下实例演示了发布订阅是如何工作的，需要开启两个 redis-cli 客户端。</p>
<p>在我们实例中我们创建了订阅频道名为 <strong>runoobChat</strong>:</p>
<h5 id="第一个-redis-cli-客户端">第一个 redis-cli 客户端</h5>
<blockquote>
<p>redis 127.0.0.1:6379&gt; SUBSCRIBE runoobChat</p>
<p>Reading messages... (press Ctrl-C to quit)</p>
<ol>
<li>&quot;subscribe&quot;</li>
<li>&quot;redisChat&quot;</li>
<li>(integer) 1</li>
</ol>
</blockquote>
<p>现在，我们先重新开启个 redis 客户端，然后在同一个频道 runoobChat 发布两次消息，订阅者就能接收到消息。</p>
<h5 id="第二个-redis-cli-客户端">第二个 redis-cli 客户端</h5>
<blockquote>
<p>redis 127.0.0.1:6379&gt; PUBLISH runoobChat &quot;Redis PUBLISH test&quot;</p>
<p>(integer) 1</p>
<p>redis 127.0.0.1:6379&gt; PUBLISH runoobChat &quot;Learn redis by runoob.com&quot;</p>
<p>(integer) 1</p>
<p># 订阅者的客户端会显示如下消息</p>
<ol>
<li>&quot;message&quot;</li>
<li>&quot;runoobChat&quot;</li>
<li>&quot;Redis PUBLISH test&quot;</li>
<li>&quot;message&quot;</li>
<li>&quot;runoobChat&quot;</li>
<li>&quot;Learn redis by runoob.com&quot;</li>
</ol>
</blockquote>
<h3 id="springboot中实现">springboot中实现</h3>
<p><strong>一.配置文件</strong></p>
<pre><code class="language-yaml">spring:
  redis:
     host: 192.168.0.200
     port: 6379
     password:
     database: 1
     pool.max-active: 8
     pool.max-wait: -1
     pool.max-idle: 8
     pool.min-idle: 0
     timeout: 5000
</code></pre>
<p><strong>二.maven坐标</strong></p>
<pre><code>&lt;dependencies&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;
        &lt;scope&gt;test&lt;/scope&gt;
    &lt;/dependency&gt;
&lt;/dependencies&gt;
</code></pre>
<p><strong>三.redis消息监听器容器以及redis监听器注入IOC容器</strong></p>
<pre><code class="language-java">package com.example.demo;

import org.springframework.cache.annotation.EnableCaching;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.context.annotation.Scope;
import org.springframework.data.redis.connection.RedisConnectionFactory;
import org.springframework.data.redis.listener.PatternTopic;
import org.springframework.data.redis.listener.RedisMessageListenerContainer;
import org.springframework.data.redis.listener.adapter.MessageListenerAdapter;

@Configuration
@EnableCaching
public class RedisConfig{
    /**
	  * Redis消息监听器容器
      * @param connectionFactory
      * @return
    **/
    @Bean
    RedisMessageListenerContainer container(RedisConnectionFactory connectionFactory) {
        RedisMessageListenerContainer container = new RedisMessageListenerContainer();
        container.setConnectionFactory(connectionFactory);
        //订阅了一个叫pmp和channel 的通道，多通道
        container.addMessageListener(listenerAdapter(new RedisPmpSub()),new PatternTopic(&quot;pmp&quot;));
        container.addMessageListener(listenerAdapter(new RedisChannelSub()),new PatternTopic(&quot;channel&quot;));
        //这个container 可以添加多个 messageListener
        return container;
    }
    
    /**
     * 配置消息接收处理类
     * @param redisMsg  自定义消息接收类
     * @return
     */
    @Bean()
    @Scope(&quot;prototype&quot;)
    MessageListenerAdapter listenerAdapter(RedisMsg redisMsg) {
        //这个地方 是给messageListenerAdapter 传入一个消息接受的处理器，利用反射的方法调用“receiveMessage”
        //也有好几个重载方法，这边默认调用处理器的方法 叫handleMessage 可以自己到源码里面看
        return new MessageListenerAdapter(redisMsg, &quot;receiveMessage&quot;);//注意2个通道调用的方法都要为receiveMessage
    }

}
</code></pre>
<p><strong>四.普通的消息处理器接口</strong></p>
<pre><code class="language-java">package com.example.demo;

import org.springframework.stereotype.Component;


@Component
public interface RedisMsg {

    public void receiveMessage(String message);

}
</code></pre>
<p><strong>五.普通的消息处理器POJO</strong></p>
<pre><code class="language-java">package com.example.demo;

/**

 * @Auther: Administrator
 * @Date: 2018/7/9 11:01
 * @Description:
   */
    public class RedisChannelSub implements RedisMsg {
   @Override
   public void receiveMessage(String message) {
       //注意通道调用的方法名要和RedisConfig的listenerAdapter的MessageListenerAdapter参数2相同
       System.out.println(&quot;这是RedisChannelSub&quot;+&quot;-----&quot;+message);
   }
    }
    package com.example.demo;


public class RedisPmpSub implements RedisMsg{

    /**
     * 接收消息的方法
     * @param message 订阅消息
     */
    public void receiveMessage(String message){
        //注意通道调用的方法名要和RedisConfig的listenerAdapter的MessageListenerAdapter参数2相同
        System.out.println(message);
    }

}
</code></pre>
<p><strong>六.消息发布者</strong></p>
<pre><code class="language-java">package com.example.demo;

import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.data.redis.core.StringRedisTemplate;
import org.springframework.scheduling.annotation.EnableScheduling;
import org.springframework.scheduling.annotation.Scheduled;
import org.springframework.stereotype.Component;

//定时器
@EnableScheduling
@Component
public class TestSenderController {
    @Autowired
    private StringRedisTemplate stringRedisTemplate;

    //向redis消息队列index通道发布消息
    @Scheduled(fixedRate = 2000)
    public void sendMessage(){
        stringRedisTemplate.convertAndSend(&quot;pmp&quot;,String.valueOf(Math.random()));
        stringRedisTemplate.convertAndSend(&quot;channel&quot;,String.valueOf(Math.random()));
    }

}
</code></pre>
<p><strong>七.启动类</strong></p>
<pre><code class="language-java">package com.example.demo;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;

@SpringBootApplication
public class DemoApplication {

    public static void main(String[] args) {
        SpringApplication.run(DemoApplication.class, args);
    }

}
</code></pre>
<h3 id="3种高级数据结构">3种高级数据结构</h3>
<h4 id="bitmap">BitMap</h4>
<p>BitMap，即位图，其实也就是 byte 数组，用二进制表示，只有 0 和 1 两个数字。</p>
<p>如图所示：</p>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1634546661392.webp" alt="" loading="lazy"></figure>
<p><strong>重要 API</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">命令</th>
<th style="text-align:center">含义</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">getbit key offset</td>
<td style="text-align:center">对key所存储的字符串值，获取指定偏移量上的位（bit）</td>
</tr>
<tr>
<td style="text-align:center">setbit key offset value</td>
<td style="text-align:center">对key所存储的字符串值，设置或清除指定偏移量上的位（bit） 1. 返回值为该位在setbit之前的值 2. value只能取0或1 3. offset从0开始，即使原位图只能10位，offset可以取1000</td>
</tr>
<tr>
<td style="text-align:center">bitcount key [start end]</td>
<td style="text-align:center">获取位图指定范围中位值为1的个数 如果不指定start与end，则取所有</td>
</tr>
<tr>
<td style="text-align:center">bitop op destKey key1 [key2...]</td>
<td style="text-align:center">做多个BitMap的and（交集）、or（并集）、not（非）、xor（异或）操作并将结果保存在destKey中</td>
</tr>
<tr>
<td style="text-align:center">bitpos key tartgetBit [start end]</td>
<td style="text-align:center">计算位图指定范围第一个偏移量对应的的值等于targetBit的位置 1. 找不到返回-1 2. start与end没有设置，则取全部 3. targetBit只能取0或者1</td>
</tr>
</tbody>
</table>
<p><strong>演示</strong></p>
<figure data-type="image" tabindex="9"><img src="https://tinaxiawuhao.github.io/post-images/1634546673051.webp" alt="" loading="lazy"></figure>
<p><strong>应用场景</strong></p>
<p>统计每日用户的登录数。每一位标识一个用户ID，当某个用户访问我们的网页或执行了某个操作，就在bitmap中把标识此用户的位设置为1。</p>
<p>这里做了一个 使用 set 和 BitMap 存储的对比。</p>
<p><strong>场景1：1 亿用户，5千万独立</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">数据类型</th>
<th style="text-align:center">每个 userid 占用空间</th>
<th style="text-align:center">需要存储的用户量</th>
<th style="text-align:center">全部内存量</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">set</td>
<td style="text-align:center">32位（假设userid用的是整型，实际很多网站用的是长整型）</td>
<td style="text-align:center">50,000,000</td>
<td style="text-align:center">32位 * 50,000,000 = 200 MB</td>
</tr>
<tr>
<td style="text-align:center">BitMap</td>
<td style="text-align:center">1 位</td>
<td style="text-align:center">100,000,000</td>
<td style="text-align:center">1 位 * 100,000,000 = 12.5 MB</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">一天</th>
<th style="text-align:center">一个月</th>
<th style="text-align:center">一年</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">set</td>
<td style="text-align:center">200M</td>
<td style="text-align:center">6G</td>
<td style="text-align:center">72G</td>
</tr>
<tr>
<td style="text-align:center">BitMap</td>
<td style="text-align:center">12.5M</td>
<td style="text-align:center">375M</td>
<td style="text-align:center">4.5G</td>
</tr>
</tbody>
</table>
<p><strong>场景2：只有 10 万独立用户</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">数据类型</th>
<th style="text-align:center">每个 userid 占用空间</th>
<th style="text-align:center">需要存储的用户量</th>
<th style="text-align:center">全部内存量</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">set</td>
<td style="text-align:center">32位（假设userid用的是整型，实际很多网站用的是长整型）</td>
<td style="text-align:center">1,000,000</td>
<td style="text-align:center">32位 * 1,000,000 = 4 MB</td>
</tr>
<tr>
<td style="text-align:center">BitMap</td>
<td style="text-align:center">1 位</td>
<td style="text-align:center">100,000,000</td>
<td style="text-align:center">1 位 * 100,000,000 = 12.5 MB</td>
</tr>
</tbody>
</table>
<p>通过上面的对比，我们可以看到，如果独立用户数量很多，使用 BitMap 明显更有优势，能节省大量的内存。但如果独立用户数量较少，还是建议使用 set 存储，BitMap 会产生多余的存储开销。</p>
<p><strong>使用经验</strong></p>
<ol>
<li>type = string，BitMap 是 sting 类型，最大 512 MB。</li>
<li>注意 setbit 时的偏移量，可能有较大耗时</li>
<li>位图不是绝对好。</li>
</ol>
<h4 id="hyperloglog">HyperLogLog</h4>
<p>HyperLogLog 是基于 HyperLogLog 算法的一种数据结构，该算法可以在极小空间完成独立数量统计。</p>
<p>在本质上还是字符串类型。</p>
<figure data-type="image" tabindex="10"><img src="https://tinaxiawuhao.github.io/post-images/1634546953753.webp" alt="" loading="lazy"></figure>
<p><strong>重要 API</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">命令</th>
<th style="text-align:center">含义</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">pfadd key element1 [element2...]</td>
<td style="text-align:center">向HyperLogLog中添加元素</td>
</tr>
<tr>
<td style="text-align:center">pfcount key1 [key2...]</td>
<td style="text-align:center">计算HyperLogLog的独立总数</td>
</tr>
<tr>
<td style="text-align:center">pfmerge destKey key1 [key2...]</td>
<td style="text-align:center">合并多个hyperLogLog到destKey中</td>
</tr>
</tbody>
</table>
<p><strong>演示</strong></p>
<figure data-type="image" tabindex="11"><img src="https://tinaxiawuhao.github.io/post-images/1634546964179.webp" alt="" loading="lazy"></figure>
<p><strong>内存消耗</strong></p>
<p>以百万独立用户为例</p>
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">内存消耗</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1 天</td>
<td style="text-align:center">15 KB</td>
</tr>
<tr>
<td style="text-align:center">1 个月</td>
<td style="text-align:center">450 KB</td>
</tr>
<tr>
<td style="text-align:center">1 年</td>
<td style="text-align:center">15KB * 365 = 5 MB</td>
</tr>
</tbody>
</table>
<p>可以看到内存消耗是非常低的，比我们之前学过的 BitMap 还要低得多。</p>
<p><strong>使用经验</strong></p>
<blockquote>
<p>Q：既然 HyperLogLog 那么好，那么是不是以后用这个来存储数据就行了呢？</p>
<p>A：这里要考虑两个因素：</p>
<ol>
<li>hyperloglog 的错误率为：0.81%，存储的数据不能百分百准确。</li>
<li>hyperloglog 不能取出单条数据。api 中也没有相关操作。</li>
</ol>
</blockquote>
<p>如果你没有这两个方面的顾虑，那么用 HyperLogLog 来存储大规模数据，还是非常不错的。</p>
<h4 id="geo">GEO</h4>
<ul>
<li>Redis 3.2添加新特性</li>
<li>功能：存储经纬度、计算两地距离、范围计算等</li>
<li>基于ZSet实现</li>
<li>删除操作使用 <code>zrem key member</code></li>
</ul>
<p><strong>GEO 相关命令</strong></p>
<p><strong>1. geoadd key longitude latitude member [lon lat member...]</strong></p>
<ul>
<li>含义：增加地理位置信息
<ul>
<li>longitude ：经度</li>
<li>latitude     :  纬度</li>
<li>member   :  标识信息</li>
</ul>
</li>
</ul>
<p><strong>2. geopos key member1 [member2...]</strong></p>
<ul>
<li>含义：获取地理位置信息</li>
</ul>
<p><strong>3. geodist key member1 member2 [unit]</strong></p>
<ul>
<li>含义：获取两个地理位置的距离</li>
<li>unit取值范围
<ul>
<li>m（米，默认）</li>
<li>km（千米）</li>
<li>mi（英里）</li>
<li>ft（英尺）</li>
</ul>
</li>
</ul>
<p><strong>4. georadius key longitude latitude unit [withcoord] [withdist] [withhash] [COUNT count] [sort] [store key] [storedist key]</strong></p>
<ul>
<li>含义：以给定的经纬度为中心，返回包含的位置元素当中，与中心距离不超过给定最大距离的所有位置元素。</li>
<li>unit取值范围
<ul>
<li>m（米）</li>
<li>km（千米）</li>
<li>mi（英里）</li>
<li>ft（英尺）</li>
</ul>
</li>
<li>withcoord：将位置元素的经度与纬度也一并返回</li>
<li>withdist：在返回位置元素的同时，将距离也一并返回。距离的单位和用户给定的范围单位保持一致</li>
<li>withhash：以52位的符号整数形式，返回位置元素经过geohash编码的有序集合分值。用于底层应用或调试，实际作用不大。</li>
<li>sort取值范围
<ul>
<li>asc：根据中心位置，按照从近到远的方式返回位置元素</li>
<li>desc：根据中心位置，按照从远到近的方式返回位置元素</li>
</ul>
</li>
<li>store key：将返回结果而的地理位置信息保存到指定键</li>
<li>storedist key：将返回结果距离中心节点的距离保存到指定键</li>
</ul>
<p><strong>5. georadiusbymember key member radius unit [withcoord][withdist][withhash][COUNT count][sort][store key][storedist key]</strong></p>
<ul>
<li>含义：以给定的元素为中心，返回包含的位置元素当中，与中心距离不超过给定最大距离的所有位置元素。</li>
<li>unit取值范围
<ul>
<li>m（米）</li>
<li>km（千米）</li>
<li>mi（英里）</li>
<li>ft（英尺）</li>
</ul>
</li>
<li>withcoord：将位置元素的经度与纬度也一并返回</li>
<li>withdist：在返回位置元素的同时，将距离也一并返回。距离的单位和用户给定的范围单位保持一致</li>
<li>withhash：以52位的符号整数形式，返回位置元素经过geohash编码的有序集合分值。用于底层应用或调试，实际作用不大。</li>
<li>sort取值范围
<ul>
<li>asc：根据中心位置，按照从近到远的方式返回位置元素</li>
<li>desc：根据中心位置，按照从远到近的方式返回位置元素</li>
</ul>
</li>
<li>store key：将返回结果而的地理位置信息保存到指定键</li>
<li>storedist key：将返回结果距离中心节点的距离保存到指定键</li>
</ul>
<p><strong>演示</strong></p>
<p>geo 功能是在 redis-3.2 后引入的</p>
<pre><code class="language-java">127.0.0.1:6381&gt; geoadd cities:locations 116.28 39.55 beijing
(integer) 1
127.0.0.1:6381&gt; geoadd cities:locations 117.12 39.08 tianjin 114.29 38.02 shijiazhuang 118.01 39.38 tangshan 115.29 38.51 baoding
(integer) 4
127.0.0.1:6381&gt; geopos cities:locations tianjin
1) 1) &quot;117.12000042200088501&quot;
   2) &quot;39.0800000535766543&quot;
127.0.0.1:6381&gt; geodist cities:locations tianjin beijing km
&quot;89.2061&quot;
127.0.0.1:6379&gt; georadiusbymember cities:locations beijing 150 km
1) &quot;beijing&quot;
2) &quot;tianjin&quot;
3) &quot;tangshan&quot;
4) &quot;baoding&quot;。
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[redis概述一]]></title>
        <id>https://tinaxiawuhao.github.io/post/7i0HRwy0e/</id>
        <link href="https://tinaxiawuhao.github.io/post/7i0HRwy0e/">
        </link>
        <updated>2021-05-13T08:35:43.000Z</updated>
        <content type="html"><![CDATA[<h3 id="什么是redis">什么是Redis</h3>
<p>Redis(Remote Dictionary Server) 是一个使用 C 语言编写的，开源的（BSD许可）高性能非关系型（NoSQL）的键值对数据库。</p>
<p>Redis 可以存储键和五种不同类型的值之间的映射。键的类型只能为字符串，值支持五种数据类型：字符串、列表、集合、散列表、有序集合。</p>
<p>与传统数据库不同的是 Redis 的数据是存在内存中的，所以读写速度非常快，因此 redis 被广泛应用于缓存方向，每秒可以处理超过 10万次读写操作，是已知性能最快的Key-Value DB。另外，Redis 也经常用来做分布式锁。除此之外，Redis 支持事务 、持久化、LUA脚本、LRU驱动事件、多种集群方案。</p>
<h3 id="redis有哪些优缺点">Redis有哪些优缺点</h3>
<p>优点</p>
<ul>
<li>读写性能优异， Redis能读的速度是110000次/s，写的速度是81000次/s。</li>
<li>支持数据持久化，支持AOF和RDB两种持久化方式。</li>
<li>支持事务，Redis的所有操作都是原子性的，同时Redis还支持对几个操作合并后的原子性执行。</li>
<li>数据结构丰富，除了支持string类型的value外还支持hash、set、zset、list等数据结构。</li>
<li>支持主从复制，主机会自动将数据同步到从机，可以进行读写分离。</li>
</ul>
<p>缺点</p>
<ul>
<li>数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。</li>
<li>Redis 不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复。</li>
<li>主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性。</li>
<li>Redis 较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。为避免这一问题，运维人员在系统上线时必须确保有足够的空间，这对资源造成了很大的浪费。</li>
</ul>
<h3 id="为什么要用-redis-为什么要用缓存">为什么要用 Redis /为什么要用缓存</h3>
<p>主要从“高性能”和“高并发”这两点来看待这个问题。</p>
<p><strong>高性能：</strong></p>
<p>假如用户第一次访问数据库中的某些数据。这个过程会比较慢，因为是从硬盘上读取的。将该用户访问的数据存在缓存中，这样下一次再访问这些数据的时候就可以直接从缓存中获取了。操作缓存就是直接操作内存，所以速度相当快。如果数据库中的对应数据改变的之后，同步改变缓存中相应的数据即可！</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1620635891817.png" alt="" loading="lazy"></figure>
<p><strong>高并发：</strong></p>
<p>直接操作缓存能够承受的请求是远远大于直接访问数据库的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1620635909701.png" alt="" loading="lazy"></figure>
<h3 id="为什么要用-redis-而不用-mapguava-做缓存">为什么要用 Redis 而不用 map/guava 做缓存?</h3>
<p>缓存分为本地缓存和分布式缓存。以 Java 为例，使用自带的 map 或者 guava 实现的是本地缓存，最主要的特点是轻量以及快速，生命周期随着 jvm 的销毁而结束，并且在多实例的情况下，每个实例都需要各自保存一份缓存，缓存不具有一致性。</p>
<p>使用 redis 或 memcached 之类的称为分布式缓存，在多实例的情况下，各实例共用一份缓存数据，缓存具有一致性。缺点是需要保持 redis 或 memcached服务的高可用，整个程序架构上较为复杂。</p>
<h3 id="redis为什么这么快">Redis为什么这么快</h3>
<p>1、完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于 HashMap，HashMap 的优势就是查找和操作的时间复杂度都是O(1)；</p>
<p>2、数据结构简单，对数据操作也简单，Redis 中的数据结构是专门进行设计的；</p>
<p>3、采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；</p>
<p>4、使用多路 I/O 复用模型，非阻塞 IO；</p>
<p>5、使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis 直接自己构建了 VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[多线程基础概念四]]></title>
        <id>https://tinaxiawuhao.github.io/post/b7Jq-wpXZ/</id>
        <link href="https://tinaxiawuhao.github.io/post/b7Jq-wpXZ/">
        </link>
        <updated>2021-05-12T06:59:14.000Z</updated>
        <content type="html"><![CDATA[<h3 id="lock-接口lock-interface简介">Lock 接口(Lock interface)简介</h3>
<blockquote>
<p>Lock 接口比同步方法和同步块提供了更具扩展性的锁操作。他们允许更灵活的结构，可以具有完全不同的性质，并且可以支持多个相关类的条件对象。</p>
</blockquote>
<p><strong>优势</strong><br>
它的优势有：</p>
<p>（1）可以使锁更公平</p>
<p>（2）可以使线程在等待锁的时候响应中断</p>
<p>（3）可以让线程尝试获取锁，并在无法获取锁的时候立即返回或者等待一段时间</p>
<p>（4）可以在不同的范围，以不同的顺序获取和释放锁</p>
<p>整体上来说 Lock 是 synchronized 的扩展版，Lock 提供了无条件的、可轮询的(tryLock 方法)、定时的(tryLock 带参方法)、可中断的(lockInterruptibly)、可多条件队列的(newCondition 方法)锁操作。另外 Lock 的实现类基本都支持非公平锁(默认)和公平锁，synchronized 只支持非公平锁，当然，在大部分情况下，非公平锁是高效的选择。</p>
<h4 id="乐观锁和悲观锁">乐观锁和悲观锁</h4>
<p>悲观锁：总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。再比如 Java 里面的同步原语 <code>synchronized</code> 关键字的实现也是悲观锁。</p>
<p>乐观锁：顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库提供的类似于 write_condition 机制，其实都是提供的乐观锁。在 Java中 <code>java.util.concurrent.atomic</code> 包下面的原子变量类就是使用了乐观锁的一种实现方式 <code>CAS</code> 实现的。</p>
<h5 id="乐观锁的实现方式">乐观锁的实现方式：</h5>
<p>1、使用版本标识来确定读到的数据与提交时的数据是否一致。提交后修改版本标识，不一致时可以采取丢弃和再次尝试的策略。</p>
<p>2、java 中的 Compare and Swap 即 CAS ，当多个线程尝试使用 CAS 同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。 CAS 操作中包含三个操作数 —— 需要读写的内存位置（V），进行比较的预期原值（A）和拟写入的新值(B)。如果内存位置 V 的值与预期原值 A 相匹配，那么处理器会自动将该位置值更新为新值 B。否则处理器不做任何操作。</p>
<h5 id="cas">CAS</h5>
<p>CAS 是 compare and swap 的缩写，即我们所说的比较交换。</p>
<p>CAS 是一种基于锁的操作，而且是乐观锁。在 java 中锁分为乐观锁和悲观锁。悲观锁是将资源锁住，等一个之前获得锁的线程释放锁之后，下一个线程才可以访问。而乐观锁采取了一种宽泛的态度，通过某种方式不加锁来处理资源，比如通过给记录加 version 来获取数据，性能较悲观锁有很大的提高。</p>
<p>CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。如果内存地址里面的值和 A 的值是一样的，那么就将内存里面的值更新成 B。CAS是通过无限循环来获取数据的，若果在第一轮循环中，a 线程获取地址里面的值被b 线程修改了，那么 a 线程需要自旋，到下次循环才有可能机会执行。</p>
<p><code>java.util.concurrent.atomic</code> 包下的类大多是使用 CAS 操作来实现的(<code>AtomicInteger</code>,<code>AtomicBoolean</code>,<code>AtomicLong</code>)。</p>
<h6 id="cas产生的问题">CAS产生的问题</h6>
<ol>
<li>
<p>ABA 问题：</p>
<p>比如说一个线程 one 从内存位置 V 中取出 A，这时候另一个线程 two 也从内存中取出 A，并且 two 进行了一些操作变成了 B，然后 two 又将 V 位置的数据变成 A，这时候线程 one 进行 CAS 操作发现内存中仍然是 A，然后 one 操作成功。尽管线程 one 的 CAS 操作成功，但可能存在潜藏的问题。从 Java1.5 开始 JDK 的 atomic包里提供了一个类<code>AtomicStampedReference</code> 来解决 ABA 问题。</p>
</li>
<li>
<p>循环时间长开销大：</p>
<p>对于资源竞争严重（线程冲突严重）的情况，CAS 自旋的概率会比较大，从而浪费更多的 CPU 资源，效率低于 synchronized。</p>
</li>
<li>
<p>只能保证一个共享变量的原子操作：</p>
<p>当对一个共享变量执行操作时，我们可以使用循环 CAS 的方式来保证原子操作，但是对多个共享变量操作时，循环 CAS 就无法保证操作的原子性，这个时候就可以用锁。</p>
</li>
</ol>
<h4 id="公平锁锁和非公平锁">公平锁锁和非公平锁</h4>
<p>公平锁：多个线程按照申请锁的顺序去获得锁，线程会直接进入队列去排队，永远都是队列的第一位才能得到锁。</p>
<ul>
<li>优点：所有的线程都能得到资源，不会饿死在队列中。</li>
<li>缺点：吞吐量会下降很多，队列里面除了第一个线程，其他的线程都会阻塞，cpu唤醒阻塞线程的开销会很大。</li>
</ul>
<p>非公平锁：多个线程去获取锁的时候，会直接去尝试获取，获取不到，再去进入等待队列，如果能获取到，就直接获取到锁。</p>
<ul>
<li>优点：可以减少CPU唤醒线程的开销，整体的吞吐效率会高点，CPU也不必取唤醒所有线程，会减少唤起线程的数量。</li>
<li>缺点：你们可能也发现了，这样可能导致队列中间的线程一直获取不到锁或者长时间获取不到锁，导致饿死。</li>
</ul>
<h4 id="伪共享">伪共享</h4>
<p><strong>一、伪共享的定义：</strong></p>
<blockquote>
<p>缓存系统中是以缓存行（cache line）为单位存储的，当多线程修改互相独立的变量时，如果这些变量共享同一个缓存行，就会无意中影响彼此的性能，这就是伪共享。</p>
</blockquote>
<p><strong>二、CPU缓存机制</strong></p>
<blockquote>
<p>CPU 缓存（Cache Memory）是位于 CPU 与内存之间的临时存储器，它的容量比内存小的多但是交换速度却比内存要快得多。<br>
高速缓存的出现主要是为了解决 CPU 运算速度与内存读写速度不匹配的矛盾，因为 CPU 运算速度要比内存读写速度快很多，这样会使 CPU 花费很长时间等待数据到来或把数据写入内存。<br>
在缓存中的数据是内存中的一小部分，但这一小部分是短时间内 CPU 即将访问的，当 CPU 调用大量数据时，就可避开内存直接从缓存中调用，从而加快读取速度。</p>
</blockquote>
<p>CPU 和主内存之间有好几层缓存，因为即使直接访问主内存也是非常慢的。如果你正在多次对一块数据做相同的运算，那么在执行运算的时候把它加载到离 CPU 很近的地方就有意义了。</p>
<p>按照数据读取顺序和与 CPU 结合的紧密程度，CPU 缓存可以分为一级缓存，二级缓存，部分高端 CPU 还具有三级缓存。每一级缓存中所储存的全部数据都是下一级缓存的一部分，越靠近 CPU 的缓存越快也越小。所以 L1 缓存很小但很快(译注：L1 表示一级缓存)，并且紧靠着在使用它的 CPU 内核。L2 大一些，也慢一些，并且仍然只能被一个单独的 CPU 核使用。L3 在现代多核机器中更普遍，仍然更大，更慢，并且被单个插槽上的所有 CPU 核共享。最后，你拥有一块主存，由全部插槽上的所有 CPU 核共享。拥有三级缓存的的 CPU，到三级缓存时能够达到 95% 的命中率，只有不到 5% 的数据需要从内存中查询。</p>
<p>多核机器的存储结构如下图所示：</p>
<figure data-type="image" tabindex="1"><img src="https://images2015.cnblogs.com/blog/897247/201608/897247-20160823201221667-1059026925.png" alt="img" loading="lazy"></figure>
<p>当 CPU 执行运算的时候，它先去 L1 查找所需的数据，再去 L2，然后是 L3，最后如果这些缓存中都没有，所需的数据就要去主内存拿。走得越远，运算耗费的时间就越长。所以如果你在做一些很频繁的事，你要确保数据在 L1 缓存中。</p>
<p>Martin Thompson 给出了一些缓存未命中的消耗数据，如下所示：</p>
<figure data-type="image" tabindex="2"><img src="https://images2015.cnblogs.com/blog/897247/201608/897247-20160823201305464-895015043.png" alt="img" loading="lazy"></figure>
<p><strong>三、缓存行</strong></p>
<p>缓存系统中是以缓存行（cache line）为单位存储的。缓存行通常是 64 字节（译注：本文基于 64 字节，其他长度的如 32 字节等不适本文讨论的重点），并且它有效地引用主内存中的一块地址。例如一个 的 long 类型是 8 字节，因此在一个缓存行中可以存 8 个 long 类型的变量。所以，如果你访问一个 long 数组，当数组中的一个值被加载到缓存中，它会额外加载另外 7 个，以致你能非常快地遍历这个数组。事实上，你可以非常快速的遍历在连续的内存块中分配的任意数据结构。而如果你在数据结构中的项在内存中不是彼此相邻的（如链表），你将得不到免费缓存加载所带来的优势，并且在这些数据结构中的每一个项都可能会出现缓存未命中。</p>
<p>如果存在这样的场景，有多个线程操作不同的成员变量，但是相同的缓存行，这个时候会发生什么？。没错，伪共享（False Sharing）问题就发生了！有张 Disruptor 项目的经典示例图，如下：</p>
<figure data-type="image" tabindex="3"><img src="https://images2015.cnblogs.com/blog/897247/201608/897247-20160823202002573-736704844.png" alt="img" loading="lazy"></figure>
<p>上图中，一个运行在处理器 core1上的线程想要更新变量 X 的值，同时另外一个运行在处理器 core2 上的线程想要更新变量 Y 的值。但是，这两个频繁改动的变量都处于同一条缓存行。两个线程就会轮番发送 RFO 消息，占得此缓存行的拥有权。当 core1 取得了拥有权开始更新 X，则 core2 对应的缓存行需要设为 I 状态。当 core2 取得了拥有权开始更新 Y，则 core1 对应的缓存行需要设为 I 状态(失效态)。轮番夺取拥有权不但带来大量的 RFO 消息，而且如果某个线程需要读此行数据时，L1 和 L2 缓存上都是失效数据，只有 L3 缓存上是同步好的数据。从前一篇我们知道，读 L3 的数据非常影响性能。更坏的情况是跨槽读取，L3 都要 miss，只能从内存上加载。</p>
<p>表面上 X 和 Y 都是被独立线程操作的，而且两操作之间也没有任何关系。只不过它们共享了一个缓存行，但所有竞争冲突都是来源于共享。</p>
<p>因此，当两个以上CPU都要访问同一个缓存行大小的内存区域时，就会引起冲突，这种情况就叫“共享”。但是，这种情况里面又包含了“其实不是共享”的“伪共享”情况。比如，两个处理器各要访问一个word，这两个word却存在于同一个cache line大小的区域里，这时，从应用逻辑层面说，这两个处理器并没有共享内存，因为他们访问的是不同的内容（不同的word）。但是因为cache line的存在和限制，这两个CPU要访问这两个不同的word时，却一定要访问同一个cache line块，产生了事实上的“共享”。显然，由于cache line大小限制带来的这种“伪共享”是我们不想要的，会浪费系统资源。</p>
<p><strong>四、如何避免伪共享</strong>？</p>
<p>1）让不同线程操作的对象处于不同的缓存行。</p>
<p>可以进行缓存行填充（Padding） 。例如，如果一条缓存行有 64 字节，而 Java 程序的对象头固定占 8 字节(32位系统)或 12 字节( 64 位系统默认开启压缩, 不开压缩为 16 字节)，所以我们只需要填 6 个无用的长整型补上6*8=48字节，让不同的 VolatileLong 对象处于不同的缓存行，就避免了伪共享( 64 位系统超过缓存行的 64 字节也无所谓，只要保证不同线程不操作同一缓存行就可以)。</p>
<p>2）使用编译指示，强制使每一个变量对齐。</p>
<p>强制使对象按照缓存行的边界对齐。例如可以使数据按64位对齐，那么一个缓存行只有一个可操作对象，这样发生伪共享之后，也只是对应缓存行的数据变化，并不影响其他的对象。</p>
<h4 id="无锁队列">无锁队列</h4>
<pre><code class="language-java">import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicReferenceArray;
 
 
/**
 * 用数组实现无锁有界队列
 */
 
public class LockFreeQueue {
 
    private AtomicReferenceArray atomicReferenceArray;
    //代表为空，没有元素
    private static final  Integer EMPTY = null;
    //头指针,尾指针
    AtomicInteger head,tail;
 
 
    public LockFreeQueue(int size){
        atomicReferenceArray = new AtomicReferenceArray(new Integer[size + 1]);
        head = new AtomicInteger(0);
        tail = new AtomicInteger(0);
    }
 
    /**
     * 入队
     * @param element
     * @return
     */
    public boolean add(Integer element){
        int index = (tail.get() + 1) % atomicReferenceArray.length();
        if( index == head.get() % atomicReferenceArray.length()){
            System.out.println(&quot;当前队列已满,&quot;+ element+&quot;无法入队!&quot;);
            return false;
        }
        while(!atomicReferenceArray.compareAndSet(index,EMPTY,element)){
            return add(element);
        }
        tail.incrementAndGet(); //移动尾指针
        System.out.println(&quot;入队成功!&quot; + element);
        return true;
    }
 
    /**
     * 出队
     * @return
     */
    public Integer poll(){
        if(head.get() == tail.get()){
            System.out.println(&quot;当前队列为空&quot;);
            return null;
        }
        int index = (head.get() + 1) % atomicReferenceArray.length();
        Integer ele = (Integer) atomicReferenceArray.get(index);
        if(ele == null){ //有可能其它线程也在出队
            return poll();
        }
        while(!atomicReferenceArray.compareAndSet(index,ele,EMPTY)){
            return poll();
        }
        head.incrementAndGet();
        System.out.println(&quot;出队成功!&quot; + ele);
        return ele;
    }
 
    public void print(){
       StringBuffer buffer = new StringBuffer(&quot;[&quot;);
       for(int i = 0; i &lt; atomicReferenceArray.length() ; i++){
           if(i == head.get() || atomicReferenceArray.get(i) == null){
               continue;
           }
           buffer.append(atomicReferenceArray.get(i) + &quot;,&quot;);
       }
       buffer.deleteCharAt(buffer.length() - 1);
       buffer.append(&quot;]&quot;);
       System.out.println(&quot;队列内容:&quot;    +buffer.toString());
 
    }
 
}
</code></pre>
<h4 id="死锁">死锁</h4>
<p>当线程 A 持有独占锁a，并尝试去获取独占锁 b 的同时，线程 B 持有独占锁 b，并尝试获取独占锁 a 的情况下，就会发生 AB 两个线程由于互相持有对方需要的锁，而发生的阻塞现象，我们称为死锁。</p>
<h5 id="1-产生死锁的条件和防止死锁">1. 产生死锁的条件和防止死锁</h5>
<p>**互斥 请求与保持 不可剥夺 循环等待 **</p>
<p>产生死锁的必要条件：</p>
<ol>
<li>
<p>互斥条件：所谓互斥就是进程在某一时间内独占资源。</p>
</li>
<li>
<p>请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。</p>
</li>
<li>
<p>不可剥夺条件：进程已获得资源，在末使用完之前，不能强行剥夺。</p>
</li>
<li>
<p>循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。</p>
</li>
</ol>
<p>这四个条件是死锁的必要条件，只要系统发生死锁，这些条件必然成立，而只要上述条件之 一不满足，就不会发生死锁。</p>
<p>理解了死锁的原因，尤其是产生死锁的四个必要条件，就可以最大可能地避免、预防和 解除死锁。</p>
<p>防止死锁可以采用以下的方法：</p>
<ul>
<li>尽量使用 <code>tryLock(long timeout, TimeUnit unit)</code>的方法<code>(ReentrantLock、ReentrantReadWriteLock)</code>，设置超时时间，超时可以退出防止死锁。</li>
<li>尽量使用 <code>Java. util. concurrent</code> 并发类代替自己手写锁。</li>
<li>尽量降低锁的使用粒度，尽量不要几个功能用同一把锁。</li>
<li>尽量减少同步的代码块。</li>
</ul>
<pre><code class="language-java">import lombok.SneakyThrows;
import java.util.concurrent.TimeUnit;

class HoldLockThread implements Runnable{
    private String lockOne;
    private String lockTwo;

    public HoldLockThread(String lockOne, String lockTwo) {
        this.lockOne = lockOne;
        this.lockTwo = lockTwo;
    }

    @Override
    @SneakyThrows
    public void run(){
        synchronized (lockOne){
            System.out.println(Thread.currentThread().getName()+&quot;自己获取&quot;+lockOne+&quot;尝试获取&quot;+lockTwo);
            TimeUnit.SECONDS.sleep(2L);
            synchronized (lockTwo){
                System.out.println(Thread.currentThread().getName()+&quot;自己获取&quot;+lockTwo+&quot;尝试获取&quot;+lockOne);
            }
        }
    }
}
public class DeadLockDemo {
    public static void main(String[] args) {
        String lockA=&quot;lockA&quot;;
        String lockB=&quot;lockB&quot;;

        new Thread(new HoldLockThread(lockA,lockB),&quot;ThreadAAA&quot;).start();
        new Thread(new HoldLockThread(lockB,lockA),&quot;ThreadBBB&quot;).start();
    }
}
</code></pre>
<h5 id="2-死锁与活锁与饥饿的区别">2. 死锁与活锁与饥饿的区别</h5>
<p>死锁：是指两个或两个以上的进程（或线程）在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。</p>
<p>活锁：任务或者执行者没有被阻塞，由于某些条件没有满足，导致一直重复尝试，失败，尝试，失败。</p>
<p>活锁和死锁的区别在于，处于活锁的实体是在不断的改变状态，这就是所谓的“活”， 而处于死锁的实体表现为等待；活锁有可能自行解开，死锁则不能。</p>
<p>饥饿：一个或者多个线程因为种种原因无法获得所需要的资源，导致一直无法执行的状态。</p>
<p>Java 中导致饥饿的原因：</p>
<p>1、高优先级线程吞噬所有的低优先级线程的 CPU 时间。</p>
<p>2、线程被永久堵塞在一个等待进入同步块的状态，因为其他线程总是能在它之前持续地对该同步块进行访问。</p>
<p>3、线程在等待一个本身也处于永久等待完成的对象(比如调用这个对象的 wait 方法)，因为其他线程总是被持续地获得唤醒。</p>
<h3 id="reentrantlock重入锁">ReentrantLock(重入锁)</h3>
<p><code>ReentrantLock</code>重入锁，是实现Lock接口的一个类，也是在实际编程中使用频率很高的一个锁，支持重入性，表示能够对共享资源能够重复加锁，即当前线程获取该锁再次获取不会被阻塞。</p>
<p>在java关键字synchronized隐式支持重入性，synchronized通过获取自增，释放自减的方式实现重入。与此同时，ReentrantLock还支持公平锁和非公平锁两种方式。那么，要想完完全全的弄懂ReentrantLock的话，主要也就是ReentrantLock同步语义的学习：</p>
<ol>
<li>重入性的实现原理；</li>
<li>公平锁和非公平锁</li>
</ol>
<h4 id="1-重入性的实现原理">1. 重入性的实现原理</h4>
<p>要想支持重入性，就要解决两个问题：</p>
<p><strong>1. 在线程获取锁的时候，如果已经获取锁的线程是当前线程的话则直接再次获取成功；</strong></p>
<p><strong>2. 由于锁会被获取n次，那么只有锁在被释放同样的n次之后，该锁才算是完全释放成功</strong>。</p>
<p>ReentrantLock支持两种锁：<strong>公平锁</strong>和<strong>非公平锁</strong>。<strong>何谓公平性，是针对获取锁而言的，如果一个锁是公平的，那么锁的获取顺序就应该符合请求上的绝对时间顺序，满足FIFO</strong>。</p>
<h4 id="2-reentrantlock使用">2. ReentrantLock使用</h4>
<pre><code class="language-java">class Bank{
      /**
       * volatile实现
       */
      private  int count=0;
      /**
       * 使用可重入锁
       */
      private Lock lock=new ReentrantLock();

      public void getCount(){
            System.out.println(&quot;账户余额为：&quot;+count);
      }
      /**
       * 同步方法实现存钱
       * @param money
       */
      public void save(int money){
            lock.lock();
            try {
                  count+=money;
                  System.out.println(System.currentTimeMillis()+&quot;存进：&quot;+money);
            } catch (Exception e) {
                  // TODO Auto-generated catch block
                  e.printStackTrace();
            }finally {
                  lock.unlock();//释放锁
            }
      }
      /**
       * 同步代码块实现取钱
       * @param money
       */
      public  void remove(int money){
            if (count-money&lt;0) {
                  System.err.println(&quot;余额不足。&quot;);
                  return;
            }
                lock.lock();
                  try {
                        count-=money;
                        System.err.println(System.currentTimeMillis()+&quot;取出：&quot;+money);
                  } catch (Exception e) {
                        // TODO Auto-generated catch block
                        e.printStackTrace();
                  }finally {
                        lock.unlock();
                  }

      }
}
</code></pre>
<h4 id="读写锁reentrantreadwritelock">读写锁ReentrantReadWriteLock</h4>
<p>首先明确一下，不是说 ReentrantLock 不好，只是 ReentrantLock 某些时候有局限。如果使用 ReentrantLock，可能本身是为了防止线程 A 在写数据、线程 B 在读数据造成的数据不一致，但这样，如果线程 C 在读数据、线程 D 也在读数据，读数据是不会改变数据的，没有必要加锁，但是还是加锁了，降低了程序的性能。因为这个，才诞生了读写锁 ReadWriteLock。</p>
<p>ReadWriteLock 是一个读写锁接口，读写锁是用来提升并发程序性能的锁分离技术，ReentrantReadWriteLock 是 ReadWriteLock 接口的一个具体实现，实现了读写的分离，读锁是共享的，写锁是独占的，读和读之间不会互斥，读和写、写和读、写和写之间才会互斥，提升了读写的性能。</p>
<p>而读写锁有以下三个重要的特性：</p>
<p>（1）公平选择性：支持非公平（默认）和公平的锁获取方式，吞吐量还是非公平优于公平。</p>
<p>（2）重进入：读锁和写锁都支持线程重进入。</p>
<h3 id="并发容器">并发容器</h3>
<h4 id="1-concurrenthashmap">1. ConcurrentHashMap</h4>
<p><code>ConcurrentHashMap</code>是Java中的一个<strong>线程安全且高效的HashMap实现</strong>。平时涉及高并发如果要用map结构，那第一时间想到的就是它。相对于hashmap来说，<code>ConcurrentHashMap</code>就是线程安全的map，其中利用了锁分段的思想提高了并发度。</p>
<p>那么它到底是如何实现线程安全的？</p>
<p>JDK 1.6版本关键要素：</p>
<ul>
<li>segment继承了<code>ReentrantLock</code>充当锁的角色，为每一个segment提供了线程安全的保障；</li>
<li>segment维护了哈希散列表的若干个桶，每个桶由<code>HashEntry</code>构成的链表。</li>
</ul>
<p>JDK1.8后，<code>ConcurrentHashMap</code>抛弃了原有的<strong>Segment 分段锁，而采用了 CAS + synchronized 来保证并发安全性</strong>。</p>
<h5 id="11-concurrenthashmap-的并发度">1.1 ConcurrentHashMap 的并发度</h5>
<p><code>ConcurrentHashMap</code> 把实际 map 划分成若干部分来实现它的可扩展性和线程安全。这种划分是使用并发度获得的，它是 <code>ConcurrentHashMap</code> 类构造函数的一个可选参数，默认值为 16，这样在多线程情况下就能避免争用。</p>
<p>在 JDK8 后，它摒弃了 Segment（锁段）的概念，而是启用了一种全新的方式实现,利用 CAS 算法。同时加入了更多的辅助变量来提高并发度，</p>
<h5 id="12-并发容器的实现">1.2 并发容器的实现</h5>
<p>何为同步容器：可以简单地理解为通过 synchronized 来实现同步的容器，如果有多个线程调用同步容器的方法，它们将会串行执行。比如<code>Vector</code>，<code>Hashtable</code>，以及 <code>Collections.synchronizedSet</code>，<code>synchronizedList</code> 等方法返回的容器。可以通过查看 <code>Vector</code>，<code>Hashtable</code>等这些同步容器的实现代码，可以看到这些容器实现线程安全的方式就是将它们的状态封装起来，并在需要同步的方法上加上关键字 synchronized。</p>
<p>并发容器使用了与同步容器完全不同的加锁策略来提供更高的并发性和伸缩性，例如在 <code>ConcurrentHashMap</code> 中采用了一种粒度更细的加锁机制，可以称为分段锁，在这种锁机制下，允许任意数量的读线程并发地访问 map，并且执行读操作的线程和写操作的线程也可以并发的访问 map，同时允许一定数量的写操作线程并发地修改 map，所以它可以在并发环境下实现更高的吞吐量。</p>
<h5 id="13-同步集合与并发集合区别">1.3 同步集合与并发集合区别</h5>
<p>同步集合与并发集合都为多线程和并发提供了合适的线程安全的集合，不过并发集合的可扩展性更高。在 Java1.5 之前程序员们只有同步集合来用且在多线程并发的时候会导致争用，阻碍了系统的扩展性。Java5 介绍了并发集合像<code>ConcurrentHashMap</code>，不仅提供线程安全还用锁分离和内部分区等现代技术提高了可扩展性。</p>
<h5 id="14-synchronizedmap-和-concurrenthashmap-比较">1.4 SynchronizedMap 和 ConcurrentHashMap 比较</h5>
<p><code>SynchronizedMap</code> 一次锁住整张表来保证线程安全，所以每次只能有一个线程来访为 map。</p>
<p><code>ConcurrentHashMap</code> 使用分段锁来保证在多线程下的性能。</p>
<p><code>ConcurrentHashMap</code> 中则是一次锁住一个桶。<code>ConcurrentHashMap</code> 默认将hash 表分为 16 个桶，诸如 get，put，remove 等常用操作只锁当前需要用到的桶。</p>
<p>这样，原来只能一个线程进入，现在却能同时有 16 个写线程执行，并发性能的提升是显而易见的。</p>
<p>另外 <code>ConcurrentHashMap</code> 使用了一种不同的迭代方式。在这种迭代方式中，当iterator 被创建后集合再发生改变就不再是抛出<code>ConcurrentModificationException</code>，取而代之的是在改变时 new 新的数据从而不影响原有的数据，iterator 完成后再将头指针替换为新的数据 ，这样 iterator线程可以使用原来老的数据，而写线程也可以并发的完成改变。</p>
<h4 id="2-copyonwritearraylist">2. CopyOnWriteArrayList</h4>
<p><code>CopyOnWriteArrayList</code> 是一个并发容器。有很多人称它是线程安全的，我认为这句话不严谨，缺少一个前提条件，那就是非复合场景下操作它是线程安全的。</p>
<p><code>CopyOnWriteArrayList</code>(免锁容器)的好处之一是当多个迭代器同时遍历和修改这个列表时，不会抛出<code>ConcurrentModificationException</code>。在<code>CopyOnWriteArrayList</code> 中，写入将导致创建整个底层数组的副本，而源数组将保留在原地，使得复制的数组在被修改时，读取操作可以安全地执行。</p>
<p><code>CopyOnWriteArrayList</code> 的使用场景</p>
<p>通过源码分析，我们看出它的优缺点比较明显，所以使用场景也就比较明显。就是合适读多写少的场景。</p>
<p><code>CopyOnWriteArrayList</code> 的缺点</p>
<ol>
<li>由于写操作的时候，需要拷贝数组，会消耗内存，如果原数组的内容比较多的情况下，可能导致 young gc 或者 full gc。</li>
<li>不能用于实时读的场景，像拷贝数组、新增元素都需要时间，所以调用一个 set 操作后，读取到数据可能还是旧的，虽然<code>CopyOnWriteArrayList</code> 能做到最终一致性,但是还是没法满足实时性要求。</li>
<li>由于实际使用中可能没法保证 <code>CopyOnWriteArrayList</code> 到底要放置多少数据，万一数据稍微有点多，每次 add/set 都要重新复制数组，这个代价实在太高昂了。在高性能的互联网应用中，这种操作分分钟引起故障。</li>
</ol>
<p><code>CopyOnWriteArrayList</code> 的设计思想</p>
<ol>
<li>读写分离，读和写分开</li>
<li>最终一致性</li>
<li>使用另外开辟空间的思路，来解决并发冲突</li>
</ol>
<h4 id="3-threadlocal">3. ThreadLocal</h4>
<p>ThreadLocal 是一个本地线程副本变量工具类，在每个线程中都创建了一个 ThreadLocalMap 对象，简单说 ThreadLocal 就是一种以空间换时间的做法，每个线程可以访问自己内部 ThreadLocalMap 对象内的 value。通过这种方式，避免资源在多线程间共享。</p>
<p>原理：线程局部变量是局限于线程内部的变量，属于线程自身所有，不在多个线程间共享。Java提供ThreadLocal类来支持线程局部变量，是一种实现线程安全的方式。但是在管理环境下（如 web 服务器）使用线程局部变量的时候要特别小心，在这种情况下，工作线程的生命周期比任何应用变量的生命周期都要长。任何线程局部变量一旦在工作完成后没有释放，Java 应用就存在内存泄露的风险。</p>
<p>经典的使用场景是为每个线程分配一个 JDBC 连接 Connection。这样就可以保证每个线程的都在各自的 Connection 上进行数据库的操作，不会出现 A 线程关了 B线程正在使用的 Connection； 还有 Session 管理 等问题。</p>
<p>ThreadLocal 使用例子：</p>
<pre><code class="language-java">public class TestThreadLocal {
    
    //线程本地存储变量
    private static final ThreadLocal&lt;Integer&gt; THREAD_LOCAL_NUM 
        = new ThreadLocal&lt;Integer&gt;() {
        @Override
        protected Integer initialValue() {
            return 0;
        }
    };
 
    public static void main(String[] args) {
        for (int i = 0; i &lt;3; i++) {//启动三个线程
            Thread t = new Thread() {
                @Override
                public void run() {
                    add10ByThreadLocal();
                }
            };
            t.start();
        }
    }
    
    /**
     * 线程本地存储变量加 5
     */
    private static void add10ByThreadLocal() {
        for (int i = 0; i &lt;5; i++) {
            Integer n = THREAD_LOCAL_NUM.get();
            n += 1;
            THREAD_LOCAL_NUM.set(n);
            System.out.println(Thread.currentThread().getName() + &quot; : ThreadLocal num=&quot; + n);
        }
    }
    
}
</code></pre>
<p>打印结果：启动了 3 个线程，每个线程最后都打印到 “ThreadLocal num=5”，而不是 num 一直在累加直到值等于 15</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1620459942353.png" alt="" loading="lazy"></figure>
<h5 id="31什么是线程局部变量">3.1什么是线程局部变量？</h5>
<p>线程局部变量是局限于线程内部的变量，属于线程自身所有，不在多个线程间共享。Java 提供 ThreadLocal 类来支持线程局部变量，是一种实现线程安全的方式。但是在管理环境下（如 web 服务器）使用线程局部变量的时候要特别小心，在这种情况下，工作线程的生命周期比任何应用变量的生命周期都要长。任何线程局部变量一旦在工作完成后没有释放，Java 应用就存在内存泄露的风险。</p>
<h5 id="32-threadlocal内存泄漏分析与解决方案">3.2 ThreadLocal内存泄漏分析与解决方案</h5>
<p><strong>ThreadLocal造成内存泄漏的原因？</strong></p>
<p>ThreadLocalMap 中使用的 key 为 ThreadLocal 的弱引用,而 value 是强引用。所以，如果 ThreadLocal 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。这样一来，ThreadLocalMap 中就会出现key为null的Entry。假如我们不做任何措施的话，value 永远无法被GC 回收，这个时候就可能会产生内存泄露。ThreadLocalMap实现中已经考虑了这种情况，在调用 set()、get()、remove() 方法的时候，会清理掉 key 为 null 的记录。使用完 ThreadLocal方法后 最好手动调用remove()方法</p>
<p><strong>ThreadLocal内存泄漏解决方案？</strong></p>
<ul>
<li>每次使用完ThreadLocal，都调用它的remove()方法，清除数据。</li>
<li>在使用线程池的情况下，没有及时清理ThreadLocal，不仅是内存泄漏的问题，更严重的是可能导致业务逻辑出现问题。所以，使用ThreadLocal就跟加锁完要解锁一样，用完就清理。</li>
</ul>
<h4 id="4-blockingqueue">4. BlockingQueue</h4>
<p><code>阻塞队列（BlockingQueue）</code>是一个支持两个附加操作的队列。</p>
<p>这两个附加的操作是：在队列为空时，获取元素的线程会等待队列变为非空。当队列满时，存储元素的线程会等待队列可用。</p>
<p>阻塞队列常用于生产者和消费者的场景，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。阻塞队列就是生产者存放元素的容器，而消费者也只从容器里拿元素。</p>
<p>JDK7 提供了 7 个阻塞队列。分别是：</p>
<p><code>ArrayBlockingQueue</code> ：一个由数组结构组成的有界阻塞队列。</p>
<p><code>LinkedBlockingQueue</code> ：一个由链表结构组成的有界阻塞队列。</p>
<p><code>PriorityBlockingQueue</code> ：一个支持优先级排序的无界阻塞队列。</p>
<p><code>DelayQueue</code>：一个使用优先级队列实现的无界阻塞队列。</p>
<p><code>SynchronousQueue</code>：一个不存储元素的阻塞队列。</p>
<p><code>LinkedTransferQueue</code>：一个由链表结构组成的无界阻塞队列。</p>
<p><code>LinkedBlockingDeque</code>：一个由链表结构组成的双向阻塞队列。</p>
<p>Java 5 之前实现同步存取时，可以使用普通的一个集合，然后在使用线程的协作和线程同步可以实现生产者，消费者模式，主要的技术就是用好，<code>wait</code>,<code>notify</code>,<code>notifyAll</code>,<code>sychronized</code> 这些关键字。而在 java 5 之后，可以使用阻塞队列来实现，此方式大大简少了代码量，使得多线程编程更加容易，安全方面也有保障。</p>
<p><code>BlockingQueue</code> 接口是 Queue 的子接口，它的主要用途并不是作为容器，而是作为线程同步的的工具，因此他具有一个很明显的特性，当生产者线程试图向 <code>BlockingQueue</code> 放入元素时，如果队列已满，则线程被阻塞，当消费者线程试图从中取出一个元素时，如果队列为空，则该线程会被阻塞，正是因为它所具有这个特性，所以在程序中多个线程交替向 BlockingQueue 中放入元素，取出元素，它可以很好的控制线程之间的通信。</p>
<p>阻塞队列使用最经典的场景就是 socket 客户端数据的读取和解析，读取数据的线程不断将数据放入队列，然后解析线程不断从队列取数据解析。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[多线程基础概念三]]></title>
        <id>https://tinaxiawuhao.github.io/post/c-lkdzfwM/</id>
        <link href="https://tinaxiawuhao.github.io/post/c-lkdzfwM/">
        </link>
        <updated>2021-05-11T06:13:04.000Z</updated>
        <content type="html"><![CDATA[<h3 id="java内存模型和线程相关">Java内存模型和线程相关</h3>
<p><strong>Java中垃圾回收有什么目的？什么时候进行垃圾回收？</strong></p>
<p>垃圾回收的目的是识别并且丢弃应用不再使用的对象来释放和重用资源。</p>
<p><strong>如果对象的引用被置为null，垃圾收集器是否会立即释放对象占用的内存？</strong></p>
<p>不会，在本次垃圾回收周期中，这个对象将被标记为可回收的。也就是说并不会立即被垃圾收集器立刻回收，而是在下一次垃圾回收时对象依旧不可达才会释放其占用的内存。</p>
<p><strong>finalize()方法什么时候被调用？析构函数(finalization)的目的是什么？</strong></p>
<p>1）垃圾回收器（garbage colector）决定回收某对象时，就会运行该对象的finalize()方法；</p>
<p>finalize是Object类的一个方法，该方法在Object类中的声明<code>protected void finalize() throws Throwable { }</code></p>
<p>在垃圾回收器执行时会调用被回收对象的finalize()方法，可以覆盖此方法来实现对其资源的回收。注意：一旦垃圾回收器准备释放对象占用的内存，将首先调用该对象的finalize()方法，并且下一次垃圾回收动作发生时，才真正回收对象占用的内存空间</p>
<p>2）GC本来就是内存回收了，应用还需要在finalization做什么呢？ 答案是大部分时候，什么都不用做(也就是不需要重载)。只有在某些很特殊的情况下，比如你调用了一些native的方法(一般是C写的)，可以要在finaliztion里去调用C的释放函数。</p>
<h4 id="重排序与数据依赖性">重排序与数据依赖性</h4>
<h5 id="为什么代码会重排序">为什么代码会重排序？</h5>
<p>在执行程序时，为了提供性能，处理器和编译器常常会对指令进行重排序，但是不能随意重排序，不是你想怎么排序就怎么排序，它需要满足以下两个条件：</p>
<ul>
<li>在单线程环境下不能改变程序运行的结果；</li>
<li>存在数据依赖关系的不允许重排序</li>
</ul>
<p>需要注意的是：重排序不会影响单线程环境的执行结果，但是会破坏多线程的执行语义。</p>
<h5 id="as-if-serial规则和happens-before规则的区别">as-if-serial规则和happens-before规则的区别</h5>
<ul>
<li>as-if-serial语义保证单线程内程序的执行结果不被改变，happens-before关系保证正确同步的多线程程序的执行结果不被改变。</li>
<li>as-if-serial语义给编写单线程程序的程序员创造了一个幻境：单线程程序是按程序的顺序来执行的。happens-before关系给编写正确同步的多线程程序的程序员创造了一个幻境：正确同步的多线程程序是按happens-before指定的顺序来执行的。</li>
<li>as-if-serial语义和happens-before这么做的目的，都是为了在不改变程序执行结果的前提下，尽可能地提高程序执行的并行度。</li>
</ul>
<h4 id="synchronized">synchronized</h4>
<p>在 Java 中,synchronized 关键字是用来控制线程同步的,就是在多线程的环境下,控制synchronized 代码段不被多个线程同时执行。synchronized 可以修饰类、方法、变量。</p>
<p>另外，在 Java 早期版本中，synchronized属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的 Mutex Lock 来实现的，Java 的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，这也是为什么早期的 synchronized 效率低的原因。庆幸的是在 Java 6 之后 Java 官方对从 JVM 层面对synchronized 较大优化，所以现在的 synchronized 锁效率也优化得很不错了。JDK1.6对锁的实现引入了大量的优化，如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。</p>
<h5 id="synchronized关键字最主要的三种使用方式">synchronized关键字最主要的三种使用方式：</h5>
<ul>
<li><strong>修饰实例方法:</strong> 作用于当前对象实例加锁，进入同步代码前要获得当前对象实例的锁</li>
<li><strong>修饰静态方法:</strong> 也就是给当前类加锁，会作用于类的所有对象实例，因为静态成员不属于任何一个实例对象，是类成员（ static 表明这是该类的一个静态资源，不管new了多少个对象，只有一份）。所以如果一个线程A调用一个实例对象的非静态 synchronized 方法，而线程B需要调用这个实例对象所属类的静态 synchronized 方法，是允许的，不会发生互斥现象，<strong>因为访问静态 synchronized 方法占用的锁是当前类的锁，而访问非静态 synchronized 方法占用的锁是当前实例对象锁</strong>。</li>
<li><strong>修饰代码块:</strong> 指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。</li>
</ul>
<p><strong>总结：</strong> synchronized 关键字加到 static 静态方法和 synchronized(class)代码块上都是是给 Class 类上锁。synchronized 关键字加到实例方法上是给对象实例上锁。尽量不要使用 synchronized(String a) 因为JVM中，字符串常量池具有缓存功能！</p>
<p>下面我以一个常见的面试题为例讲解一下 synchronized 关键字的具体使用。</p>
<p>面试中面试官经常会说：“单例模式了解吗？来给我手写一下！给我解释一下双重检验锁方式实现单例模式的原理呗！”</p>
<p><strong>双重校验锁实现对象单例（线程安全）</strong></p>
<pre><code class="language-java">public class Singleton {

    private volatile static Singleton uniqueInstance;

    private Singleton() {
    }

    public static Singleton getUniqueInstance() {
       //先判断对象是否已经实例过，没有实例化过才进入加锁代码
        if (uniqueInstance == null) {
            //类对象加锁
            synchronized (Singleton.class) {
                if (uniqueInstance == null) {
                    uniqueInstance = new Singleton();
                }
            }
        }
        return uniqueInstance;
    }
}
</code></pre>
<p>另外，需要注意<code>uniqueInstance</code> 采用 volatile 关键字修饰也是很有必要。</p>
<p><code>uniqueInstance</code> 采用 volatile 关键字修饰也是很有必要的， <code>uniqueInstance = new Singleton();</code> 这段代码其实是分为三步执行：</p>
<ol>
<li>为 uniqueInstance 分配内存空间</li>
<li>初始化 uniqueInstance</li>
<li>将 uniqueInstance 指向分配的内存地址</li>
</ol>
<p>使用 volatile 可以禁止 JVM 的指令重排，保证在多线程环境下也能正常运行。</p>
<h5 id="说一下-synchronized-底层实现原理">说一下 synchronized 底层实现原理？</h5>
<p>synchronized是Java中的一个关键字，在使用的过程中并没有看到显示的加锁和解锁过程。因此有必要通过javap命令，查看相应的字节码文件。</p>
<p>synchronized 同步语句块的情况</p>
<pre><code class="language-java">public class SynchronizedDemo {
    public void method() {
        synchronized (this) {
            System.out.println(&quot;synchronized 代码块&quot;);
        }
    }
}
</code></pre>
<p>通过JDK 反汇编指令 javap -c -v SynchronizedDemo</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1620456899828.png" alt="" loading="lazy"></figure>
<p>可以看出在执行同步代码块之前之后都有一个monitor字样，其中前面的是<code>monitorenter</code>，后面的是离开<code>monitorexit</code>，不难想象一个线程也执行同步代码块，首先要获取锁，而获取锁的过程就是<code>monitorenter</code> ，在执行完代码块之后，要释放锁，释放锁就是执行<code>monitorexit</code>指令。</p>
<p>为什么会有两个<code>monitorexit</code>呢？</p>
<p>这个主要是防止在同步代码块中线程因异常退出，而锁没有得到释放，这必然会造成死锁（等待的线程永远获取不到锁）。因此最后一个<code>monitorexit</code>是保证在异常情况下，锁也可以得到释放，避免死锁。</p>
<p>仅有ACC_SYNCHRONIZED这么一个标志，该标记表明线程进入该方法时，需要<code>monitorenter</code>，退出该方法时需要<code>monitorexit</code>。</p>
<p>synchronized可重入的原理</p>
<p>重入锁是指一个线程获取到该锁之后，该线程可以继续获得该锁。底层原理维护一个计数器，当线程获取该锁时，计数器加一，再次获得该锁时继续加一，释放锁时，计数器减一，当计数器值为0时，表明该锁未被任何线程所持有，其它线程可以竞争获取锁。</p>
<h5 id="什么是自旋">什么是自旋</h5>
<p>很多 synchronized 里面的代码只是一些很简单的代码，执行时间非常快，此时等待的线程都加锁可能是一种不太值得的操作，因为线程阻塞涉及到用户态和内核态切换的问题。既然 synchronized 里面的代码执行得非常快，不妨让等待锁的线程不要被阻塞，而是在 synchronized 的边界做忙循环，这就是自旋。如果做了多次循环发现还没有获得锁，再阻塞，这样可能是一种更好的策略。</p>
<h5 id="锁状态">锁状态</h5>
<p>锁的状态总共有四种：无锁状态、偏向锁、轻量级锁和重量级锁。随着锁的竞争，锁可以从偏向锁升级到轻量级锁，再升级的重量级锁（但是锁的升级是单向的，也就是说只能从低到高升级，不会出现锁的降级）。JDK 1.6中默认是开启偏向锁和轻量级锁的，我们也可以通过-XX:-UseBiasedLocking来禁用偏向锁。锁的状态保存在对象的头文件中，以32位的JDK为例：</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1620463288509.png" alt="" loading="lazy"></figure>
<p>“轻量级”是相对于使用操作系统互斥量来实现的传统锁而言的。但是，首先需要强调一点的是，轻量级锁并不是用来代替重量级锁的，它的本意是在没有多线程竞争的前提下，减少传统的重量级锁使用产生的性能消耗。在解释轻量级锁的执行过程之前，先明白一点，轻量级锁所适应的场景是线程交替执行同步块的情况，如果存在同一时间访问同一锁的情况，就会导致轻量级锁膨胀为重量级锁。</p>
<h5 id="多线程中-synchronized-锁升级的原理是什么">多线程中 synchronized 锁升级的原理是什么？</h5>
<p>synchronized 锁升级原理：在锁对象的对象头里面有一个 <code>threadid</code> 字段，在第一次访问的时候<code>threadid</code> 为空，jvm 让其持有偏向锁，并将 <code>threadid</code> 设置为其线程 id，再次进入的时候会先判断 <code>threadid</code> 是否与其线程 id 一致，如果一致则可以直接使用此对象，如果不一致，则升级偏向锁为轻量级锁，通过自旋循环一定次数来获取锁，执行一定次数之后，如果还没有正常获取到要使用的对象，此时就会把锁从轻量级升级为重量级锁，此过程就构成了 synchronized 锁的升级。</p>
<p>锁的升级的目的：锁升级是为了减低了锁带来的性能消耗。在 Java 6 之后优化 synchronized 的实现方式，使用了偏向锁升级为轻量级锁再升级到重量级锁的方式，从而减低了锁带来的性能消耗。</p>
<figure data-type="image" tabindex="3"><img src="https://images2015.cnblogs.com/blog/820406/201604/820406-20160424163618101-624122079.png" alt="img" loading="lazy"></figure>
<p>重量级锁、轻量级锁和偏向锁之间转换图</p>
<h5 id="线程-b-怎么知道线程-a-修改了变量">线程 B 怎么知道线程 A 修改了变量</h5>
<p>（1）volatile 修饰变量</p>
<p>（2）synchronized 修饰修改变量的方法</p>
<p>（3）wait/notify</p>
<p>（4）while 轮询</p>
<p><strong>当一个线程进入一个对象的 synchronized 方法 A 之后，其它线程是否可进入此对象的 synchronized 方法 B？</strong></p>
<p>不能。其它线程只能访问该对象的非同步方法，同步方法则不能进入。因为非静态方法上的 synchronized 修饰符要求执行方法时要获得对象的锁，如果已经进入A 方法说明对象锁已经被取走，那么试图进入 B 方法的线程就只能在等锁池（注意不是等待池哦）中等待对象的锁。</p>
<h5 id="synchronized-volatile-cas-比较">synchronized、volatile、CAS 比较</h5>
<p>（1）synchronized 是悲观锁，属于抢占式，会引起其他线程阻塞。</p>
<p>（2）volatile 提供多线程共享变量可见性和禁止指令重排序优化。</p>
<p>（3）CAS 是基于冲突检测的乐观锁（非阻塞）</p>
<h5 id="synchronized-和-lock-有什么区别">synchronized 和 Lock 有什么区别？</h5>
<ul>
<li>首先synchronized是Java内置关键字，在JVM层面，Lock是个Java类；</li>
<li>synchronized 可以给类、方法、代码块加锁；而 lock 只能给代码块加锁。</li>
<li>synchronized 不需要手动获取锁和释放锁，使用简单，发生异常会自动释放锁，不会造成死锁；而 lock 需要自己加锁和释放锁，如果使用不当没有 unLock()去释放锁就会造成死锁。</li>
<li>通过 Lock 可以知道有没有成功获取锁，而 synchronized 却无法办到。</li>
</ul>
<h5 id="synchronized-和-reentrantlock-区别是什么">synchronized 和 ReentrantLock 区别是什么？</h5>
<p>synchronized 是和 if、else、for、while 一样的关键字，ReentrantLock 是类，这是二者的本质区别。既然 ReentrantLock 是类，那么它就提供了比synchronized 更多更灵活的特性，可以被继承、可以有方法、可以有各种各样的类变量</p>
<p>synchronized 早期的实现比较低效，对比 ReentrantLock，大多数场景性能都相差较大，但是在 Java 6 中对 synchronized 进行了非常多的改进。</p>
<p>相同点：两者都是可重入锁</p>
<p>两者都是可重入锁。“可重入锁”概念是：自己可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果不可锁重入的话，就会造成死锁。同一个线程每次获取锁，锁的计数器都自增1，所以要等到锁的计数器下降为0时才能释放锁。</p>
<p>主要区别如下：</p>
<ul>
<li>ReentrantLock 使用起来比较灵活，但是必须有释放锁的配合动作；</li>
<li>ReentrantLock 必须手动获取与释放锁，而 synchronized 不需要手动释放和开启锁；</li>
<li>ReentrantLock 只适用于代码块锁，而 synchronized 可以修饰类、方法、变量等。</li>
<li>二者的锁机制其实也是不一样的。ReentrantLock 底层调用的是 Unsafe 的park 方法加锁，synchronized 操作的应该是对象头中 mark word</li>
</ul>
<p>Java中每一个对象都可以作为锁，这是synchronized实现同步的基础：</p>
<ul>
<li>普通同步方法，锁是当前实例对象</li>
<li>静态同步方法，锁是当前类的class对象</li>
<li>同步方法块，锁是括号里面的对象</li>
</ul>
<h4 id="尽可能去使用synchronized而不要去使用lock">尽可能去使用synchronized而不要去使用LOCK</h4>
<p>什么概念呢？我和大家打个比方：你叫jdk，你生了一个孩子叫synchronized，后来呢，你领养了一个孩子叫LOCK。起初，LOCK刚来到新家的时候，它很乖，很懂事，各个方面都表现的比synchronized好。你很开心，但是你内心深处又有一点淡淡的忧伤，你不希望你自己亲生的孩子竟然还不如一个领养的孩子乖巧。这个时候，你对亲生的孩子教育更加深刻了，你想证明，你的亲生孩子synchronized并不会比领养的孩子LOCK差。<br>
那如何教育呢？<br>
在jdk1.6~jdk1.7的时候，你作为爸爸，你给他优化了，具体优化在哪里呢：</p>
<ol>
<li>
<p>线程自旋和适应性自旋<br>
我们知道，java’线程其实是映射在内核之上的，线程的挂起和恢复会极大的影响开销。并且jdk官方人员发现，很多线程在等待锁的时候，在很短的一段时间就获得了锁，所以它们在线程等待的时候，并不需要把线程挂起，而是让他无目的的循环，一般设置10次。这样就避免了线程切换的开销，极大的提升了性能。<br>
而适应性自旋，是赋予了自旋一种学习能力，它并不固定自旋10次一下。他可以根据它前面线程的自旋情况，从而调整它的自旋，甚至是不经过自旋而直接挂起。</p>
</li>
<li>
<p>锁消除<br>
什么叫锁消除呢？就是把不必要的同步在编译阶段进行移除。<br>
那么有的小伙伴又迷糊了，我自己写的代码我会不知道这里要不要加锁？我加了锁就是表示这边会有同步呀？<br>
并不是这样，这里所说的锁消除并不一定指代是你写的代码的锁消除，我打一个比方：<br>
在jdk1.5以前，我们的String字符串拼接操作其实底层是StringBuffer来实现的（写一个简单的demo，然后查看class文件中的字节码指令就清楚了），而在jdk1.5之后，那么是用StringBuilder来拼接的。我们考虑前面的情况，比如如下代码：</p>
<pre><code class="language-java">String str1=&quot;qwe&quot;;
String str2=&quot;asd&quot;;
String str3=str1+str2;
</code></pre>
<p>底层实现会变成这样：</p>
<pre><code class="language-java">StringBuffer sb = new StringBuffer();
sb.append(&quot;qwe&quot;);
sb.append(&quot;asd&quot;);
</code></pre>
<p>我们知道，StringBuffer是一个线程安全的类，也就是说两个append方法都会同步，通过指针逃逸分析（就是变量不会外泄），我们发现在这段代码并不存在线程安全问题，这个时候就会把这个同步锁消除。</p>
</li>
<li>
<p>锁粗化<br>
在用synchronized的时候，我们都讲究为了避免大开销，尽量同步代码块要小。那么为什么还要加粗呢？<br>
我们继续以上面的字符串拼接为例，我们知道在这一段代码中，每一个append都需要同步一次，那么我可以把锁粗化到第一个append和最后一个append（这里不要去纠结前面的锁消除，我只是打个比方）</p>
</li>
<li>
<p>轻量级锁</p>
<p><strong>轻量级锁的加锁过程</strong></p>
<p>（1）在代码进入同步块的时候，如果同步对象锁状态为无锁状态（锁标志位为“01”状态，是否为偏向锁为“0”），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝，官方称之为 Displaced Mark Word。这时候线程堆栈与对象头的状态如图2.1所示。</p>
<p>（2）拷贝对象头中的Mark Word复制到锁记录中。</p>
<p>（3）拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，并将Lock record里的owner指针指向object mark word。如果更新成功，则执行步骤（3），否则执行步骤（4）。</p>
<p>（4）如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为“00”，即表示此对象处于轻量级锁定状态，这时候线程堆栈与对象头的状态如图2.2所示。</p>
<p>（5）如果这个更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行。否则说明多个线程竞争锁，轻量级锁就要膨胀为重量级锁，锁标志的状态值变为“10”，Mark Word中存储的就是指向重量级锁（互斥量）的指针，后面等待锁的线程也要进入阻塞状态。 而当前线程便尝试使用自旋来获取锁，自旋就是为了不让线程阻塞，而采用循环去获取锁的过程。</p>
<figure data-type="image" tabindex="4"><img src="https://images2015.cnblogs.com/blog/820406/201604/820406-20160424105442866-2111954866.png" alt="img" loading="lazy"></figure>
<p>​           图2.1 轻量级锁CAS操作之前堆栈与对象的状态</p>
<figure data-type="image" tabindex="5"><img src="https://images2015.cnblogs.com/blog/820406/201604/820406-20160424105540163-1019388398.png" alt="img" loading="lazy"></figure>
<p>​           图2.2 轻量级锁CAS操作之后堆栈与对象的状态</p>
<p><strong>轻量级锁的解锁过程：</strong></p>
<p>（1）通过CAS操作尝试把线程中复制的Displaced Mark Word对象替换当前的Mark Word。</p>
<p>（2）如果替换成功，整个同步过程就完成了。</p>
<p>（3）如果替换失败，说明有其他线程尝试过获取该锁（此时锁已膨胀），那就要在释放锁的同时，唤醒被挂起的线程。</p>
</li>
<li>
<p>偏向锁</p>
<p>引入偏向锁是为了在无多线程竞争的情况下尽量减少不必要的轻量级锁执行路径，因为轻量级锁的获取及释放依赖多次CAS原子指令，而偏向锁只需要在置换ThreadID的时候依赖一次CAS原子指令（由于一旦出现多线程竞争的情况就必须撤销偏向锁，所以偏向锁的撤销操作的性能损耗必须小于节省下来的CAS原子指令的性能消耗）。上面说过，轻量级锁是为了在线程交替执行同步块时提高性能，而偏向锁则是在只有一个线程执行同步块时进一步提高性能。</p>
<p><strong>1、偏向锁获取过程：</strong></p>
<p>（1）访问Mark Word中偏向锁的标识是否设置成1，锁标志位是否为01——确认为可偏向状态。</p>
<p>（2）如果为可偏向状态，则测试线程ID是否指向当前线程，如果是，进入步骤（5），否则进入步骤（3）。</p>
<p>（3）如果线程ID并未指向当前线程，则通过CAS操作竞争锁。如果竞争成功，则将Mark Word中线程ID设置为当前线程ID，然后执行（5）；如果竞争失败，执行（4）。</p>
<p>（4）如果CAS获取偏向锁失败，则表示有竞争。当到达全局安全点（safepoint）时获得偏向锁的线程被挂起，偏向锁升级为轻量级锁，然后被阻塞在安全点的线程继续往下执行同步代码。</p>
<p>（5）执行同步代码。</p>
<p><strong>2、偏向锁的释放：</strong></p>
<p>偏向锁的撤销在上述第四步骤中有提到**。**偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动去释放偏向锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态，撤销偏向锁后恢复到未锁定（标志位为“01”）或轻量级锁（标志位为“00”）的状态。</p>
</li>
</ol>
<h4 id="volatile">volatile</h4>
<p>对于可见性，Java 提供了 volatile 关键字来保证可见性和禁止指令重排。 volatile 提供 happens-before 的保证，确保一个线程的修改能对其他线程是可见的。当一个共享变量被 volatile 修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。</p>
<p>从实践角度而言，volatile 的一个重要作用就是和 CAS 结合，保证了原子性，详细的可以参见 java.util.concurrent.atomic 包下的类，比如 AtomicInteger。</p>
<p>volatile 常用于多线程环境下的单次操作(单次读或者单次写)。</p>
<h5 id="java-中能创建-volatile-数组吗">Java 中能创建 volatile 数组吗？</h5>
<p>能，Java 中可以创建 volatile 类型数组，不过只是一个指向数组的引用，而不是整个数组。意思是，如果改变引用指向的数组，将会受到 volatile 的保护，但是如果多个线程同时改变数组的元素，volatile 标示符就不能起到之前的保护作用了。</p>
<h5 id="volatile-变量和-atomic-变量有什么不同">volatile 变量和 atomic 变量有什么不同？</h5>
<p>volatile 变量可以确保先行关系，即写操作会发生在后续的读操作之前, 但它并不能保证原子性。例如用 volatile 修饰 count 变量，那么 count++ 操作就不是原子性的。</p>
<p>而 AtomicInteger 类提供的 atomic 方法可以让这种操作具有原子性如getAndIncrement()方法会原子性的进行增量操作把当前值加一，其它数据类型和引用变量也可以进行相似操作。</p>
<h5 id="volatile-能使得一个非原子操作变成原子操作吗">volatile 能使得一个非原子操作变成原子操作吗？</h5>
<p>关键字volatile的主要作用是使变量在多个线程间可见，但无法保证原子性，对于多个线程访问同一个实例变量需要加锁进行同步。</p>
<p>虽然volatile只能保证可见性不能保证原子性，但用volatile修饰long和double可以保证其操作原子性。</p>
<p>所以从Oracle Java Spec里面可以看到：</p>
<ul>
<li>对于64位的long和double，如果没有被volatile修饰，那么对其操作可以不是原子的。在操作的时候，可以分成两步，每次对32位操作。</li>
<li>如果使用volatile修饰long和double，那么其读写都是原子操作</li>
<li>对于64位的引用地址的读写，都是原子操作</li>
<li>在实现JVM时，可以自由选择是否把读写long和double作为原子操作</li>
<li>推荐JVM实现为原子操作</li>
</ul>
<h5 id="volatile-修饰符的有过什么实践">volatile 修饰符的有过什么实践？</h5>
<p>单例模式</p>
<p>是否 Lazy 初始化：是</p>
<p>是否多线程安全：是</p>
<p>实现难度：较复杂</p>
<p>描述：对于Double-Check这种可能出现的问题（当然这种概率已经非常小了，但毕竟还是有的嘛~），解决方案是：只需要给instance的声明加上volatile关键字即可volatile关键字的一个作用是禁止指令重排，把instance声明为volatile之后，对它的写操作就会有一个内存屏障（什么是内存屏障？），这样，在它的赋值完成之前，就不用会调用读操作。注意：volatile阻止的不是singleton = newSingleton()这句话内部[1-2-3]的指令重排，而是保证了在一个写操作（[1-2-3]）完成之前，不会调用读操作（if (instance == null)）。</p>
<pre><code class="language-java">public class Singleton7 {

    private static volatile Singleton7 instance = null;

    private Singleton7() {}

    public static Singleton7 getInstance() {
        if (instance == null) {
            synchronized (Singleton7.class) {
                if (instance == null) {
                    instance = new Singleton7();
                }
            }
        }

        return instance;
    }

}
</code></pre>
<h5 id="synchronized-和-volatile-的区别是什么">synchronized 和 volatile 的区别是什么？</h5>
<p>synchronized 表示只有一个线程可以获取作用对象的锁，执行代码，阻塞其他线程。</p>
<p>volatile 表示变量在 CPU 的寄存器中是不确定的，必须从主存中读取。保证多线程环境下变量的可见性；禁止指令重排序。</p>
<p><strong>区别</strong></p>
<ul>
<li>volatile 是变量修饰符；synchronized 可以修饰类、方法、变量。</li>
<li>volatile 仅能实现变量的修改可见性，不能保证原子性；而 synchronized 则可以保证变量的修改可见性和原子性。</li>
<li>volatile 不会造成线程的阻塞；synchronized 可能会造成线程的阻塞。</li>
<li>volatile标记的变量不会被编译器优化；synchronized标记的变量可以被编译器优化。</li>
<li><strong>volatile关键字</strong>是线程同步的<strong>轻量级实现</strong>，所以<strong>volatile性能肯定比synchronized关键字要好</strong>。但是<strong>volatile关键字只能用于变量而synchronized关键字可以修饰方法以及代码块</strong>。synchronized关键字在JavaSE1.6之后进行了主要包括为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁以及其它各种优化之后执行效率有了显著提升，<strong>实际开发中使用 synchronized 关键字的场景还是更多一些</strong>。</li>
</ul>
<table>
<thead>
<tr>
<th>类别</th>
<th>synchronized</th>
<th>Lock</th>
</tr>
</thead>
<tbody>
<tr>
<td>存在层次</td>
<td>Java的关键字，在jvm层面上</td>
<td>是一个类</td>
</tr>
<tr>
<td>锁的释放</td>
<td>1、已获取锁的线程执行完同步代码，释放锁 2、线程执行发生异常，jvm会让线程释放锁</td>
<td>在finally中必须释放锁，不然容易造成线程死锁</td>
</tr>
<tr>
<td>锁的获取</td>
<td>假设A线程获得锁，B线程等待。如果A线程阻塞，B线程会一直等待</td>
<td>分情况而定，Lock有多个锁获取的方式，具体下面会说道，大致就是可以尝试获得锁，线程可以不用一直等待</td>
</tr>
<tr>
<td>锁状态</td>
<td>无法判断</td>
<td>可以判断</td>
</tr>
<tr>
<td>锁类型</td>
<td>可重入 不可中断 非公平</td>
<td>可重入 可判断 可公平（两者皆可）</td>
</tr>
<tr>
<td>性能</td>
<td>少量同步</td>
<td>大量同步</td>
</tr>
</tbody>
</table>
<h4 id="final">final</h4>
<p>不可变对象(Immutable Objects)即对象一旦被创建它的状态（对象的数据，也即对象属性值）就不能改变，反之即为可变对象(Mutable Objects)。</p>
<p>不可变对象的类即为不可变类(Immutable Class)。Java 平台类库中包含许多不可变类，如 String、基本类型的包装类、BigInteger 和 BigDecimal 等。</p>
<p>只有满足如下状态，一个对象才是不可变的；</p>
<ul>
<li>它的状态不能在创建后再被修改；</li>
<li>所有域都是 final 类型；并且，它被正确创建（创建期间没有发生 this 引用的逸出）。</li>
</ul>
<p>不可变对象保证了对象的内存可见性，对不可变对象的读取不需要进行额外的同步手段，提升了代码执行效率。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[多线程基础概念二]]></title>
        <id>https://tinaxiawuhao.github.io/post/h9DSVN_A0/</id>
        <link href="https://tinaxiawuhao.github.io/post/h9DSVN_A0/">
        </link>
        <updated>2021-05-10T05:50:50.000Z</updated>
        <content type="html"><![CDATA[<h3 id="线程的状态和基本操作">线程的状态和基本操作</h3>
<p><strong>线程的生命周期及五种基本状态</strong></p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1620454342415.png" alt="" loading="lazy"></figure>
<ol>
<li>
<p><strong>新建(new)</strong>：新创建了一个线程对象。</p>
</li>
<li>
<p><strong>可运行(runnable)</strong>：线程对象创建后，当调用线程对象的 start()方法，该线程处于就绪状态，等待被线程调度选中，获取cpu的使用权。</p>
</li>
<li>
<p><strong>运行(running)</strong>：可运行状态(runnable)的线程获得了cpu时间片（timeslice），执行程序代码。注：就绪状态是进入到运行状态的唯一入口，也就是说，线程要想进入运行状态执行，首先必须处于就绪状态中；</p>
</li>
<li>
<p><strong>阻塞(block)</strong>：处于运行状态中的线程由于某种原因，暂时放弃对 CPU的使用权，停止执行，此时进入阻塞状态，直到其进入到就绪状态，才 有机会再次被 CPU 调用以进入到运行状态。</p>
<p>阻塞的情况分三种：</p>
<p>(一). 等待阻塞：运行状态中的线程执行 wait()方法，JVM会把该线程放入等待队列(waitting queue)中，使本线程进入到等待阻塞状态；</p>
<p>(二). 同步阻塞：线程在获取 synchronized 同步锁失败(因为锁被其它线程所占用)，，则JVM会把该线程放入锁池(lock pool)中，线程会进入同步阻塞状态；</p>
<p>(三). 其他阻塞: 通过调用线程的 sleep()或 join()或发出了 I/O 请求时，线程会进入到阻塞状态。当 sleep()状态超时、join()等待线程终止或者超时、或者 I/O 处理完毕时，线程重新转入就绪状态。</p>
</li>
<li>
<p><strong>死亡(dead)</strong>：线程run()、main()方法执行结束，或者因异常退出了run()方法，则该线程结束生命周期。死亡的线程不可再次复生。</p>
</li>
</ol>
<h4 id="java-中用到的线程调度算法是什么">Java 中用到的线程调度算法是什么？</h4>
<p>计算机通常只有一个 CPU，在任意时刻只能执行一条机器指令，每个线程只有获得CPU 的使用权才能执行指令。所谓多线程的并发运行，其实是指从宏观上看，各个线程轮流获得 CPU 的使用权，分别执行各自的任务。在运行池中，会有多个处于就绪状态的线程在等待 CPU，JAVA 虚拟机的一项任务就是负责线程的调度，线程调度是指按照特定机制为多个线程分配 CPU 的使用权。</p>
<p>有两种调度模型：分时调度模型和抢占式调度模型。</p>
<p>分时调度模型是指让所有的线程轮流获得 cpu 的使用权，并且平均分配每个线程占用的 CPU 的时间片这个也比较好理解。</p>
<p>Java虚拟机采用抢占式调度模型，是指优先让可运行池中优先级高的线程占用CPU，如果可运行池中的线程优先级相同，那么就随机选择一个线程，使其占用CPU。处于运行状态的线程会一直运行，直至它不得不放弃 CPU。</p>
<h5 id="线程的调度策略">线程的调度策略</h5>
<p>线程调度器选择优先级最高的线程运行，但是，如果发生以下情况，就会终止线程的运行：</p>
<p>（1）线程体中调用了 yield 方法让出了对 cpu 的占用权利</p>
<p>（2）线程体中调用了 sleep 方法使线程进入睡眠状态</p>
<p>（3）线程由于 IO 操作受到阻塞</p>
<p>（4）另外一个更高优先级线程出现</p>
<p>（5）在支持时间片的系统中，该线程的时间片用完</p>
<h5 id="什么是线程调度器thread-scheduler和时间分片time-slicing">什么是线程调度器(Thread Scheduler)和时间分片(Time Slicing )？</h5>
<p>线程调度器是一个操作系统服务，它负责为 Runnable 状态的线程分配 CPU 时间。一旦我们创建一个线程并启动它，它的执行便依赖于线程调度器的实现。</p>
<p>时间分片是指将可用的 CPU 时间分配给可用的 Runnable 线程的过程。分配 CPU 时间可以基于线程优先级或者线程等待的时间。</p>
<p>线程调度并不受到 Java 虚拟机控制，所以由应用程序来控制它是更好的选择（也就是说不要让你的程序依赖于线程的优先级）。</p>
<h5 id="请说出与线程同步以及线程调度相关的方法">请说出与线程同步以及线程调度相关的方法。</h5>
<p>（1） wait()：使一个线程处于等待（阻塞）状态，并且释放所持有的对象的锁；</p>
<p>（2）sleep()：使一个正在运行的线程处于睡眠状态，是一个静态方法，调用此方法要处理 <code>InterruptedException</code> 异常；</p>
<p>（3）notify()：唤醒一个处于等待状态的线程，当然在调用此方法的时候，并不能确切的唤醒某一个等待状态的线程，而是由 JVM 确定唤醒哪个线程，而且与优先级无关；</p>
<p>（4）notityAll()：唤醒所有处于等待状态的线程，该方法并不是将对象的锁给所有线程，而是让它们竞争，只有获得锁的线程才能进入就绪状态；</p>
<h5 id="sleep-和-wait-有什么区别">sleep() 和 wait() 有什么区别？</h5>
<p>两者都可以暂停线程的执行</p>
<ul>
<li>类的不同：sleep() 是 Thread线程类的静态方法，wait() 是 Object类的方法。</li>
<li>是否释放锁：sleep() 不释放锁；wait() 释放锁。</li>
<li>用途不同：Wait 通常被用于线程间交互/通信，sleep 通常被用于暂停执行。</li>
<li>用法不同：wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者 notifyAll() 方法。sleep() 方法执行完成后，线程会自动苏醒。或者可以使用wait(long timeout)超时后线程会自动苏醒。</li>
</ul>
<h5 id="你是如何调用-wait-方法的使用-if-块还是循环为什么">你是如何调用 wait() 方法的？使用 if 块还是循环？为什么？</h5>
<p>处于等待状态的线程可能会收到错误警报和伪唤醒，如果不在循环中检查等待条件，程序就会在没有满足结束条件的情况下退出。</p>
<p>wait() 方法应该在循环调用，因为当线程获取到 CPU 开始执行的时候，其他条件可能还没有满足，所以在处理前，循环检测条件是否满足会更好。下面是一段标准的使用 wait 和 notify 方法的代码：</p>
<pre><code class="language-java">synchronized (monitor) {
    //  判断条件谓词是否得到满足
    while(!locked) {
        //  等待唤醒
        monitor.wait();
    }
    //  处理其他的业务逻辑
}
</code></pre>
<h5 id="为什么线程通信的方法-wait-notify和-notifyall被定义在-object-类里">为什么线程通信的方法 wait(), notify()和 notifyAll()被定义在 Object 类里？</h5>
<p>Java中，任何对象都可以作为锁，并且 wait()，notify()等方法用于等待对象的锁或者唤醒线程，在 Java 的线程中并没有可供任何对象使用的锁，所以任意对象调用方法一定要定义在Object类中。</p>
<p>wait(), notify()和 notifyAll()这些方法在同步代码块中调用</p>
<p>有的人会说，既然是线程放弃对象锁，那也可以把wait()定义在Thread类里面啊，新定义的线程继承于Thread类，也不需要重新定义wait()方法的实现。然而，这样做有一个非常大的问题，一个线程完全可以持有很多锁，你一个线程放弃锁的时候，到底要放弃哪个锁？当然了，这种设计并不是不能实现，只是管理起来更加复杂。</p>
<p>综上所述，wait()、notify()和notifyAll()方法要定义在Object类中。</p>
<h5 id="为什么-wait-notify和-notifyall必须在同步方法或者同步块中被调用">为什么 wait(), notify()和 notifyAll()必须在同步方法或者同步块中被调用？</h5>
<p>当一个线程需要调用对象的 wait()方法的时候，这个线程必须拥有该对象的锁，接着它就会释放这个对象锁并进入等待状态直到其他线程调用这个对象上的 notify()方法。同样的，当一个线程需要调用对象的 notify()方法时，它会释放这个对象的锁，以便其他在等待的线程就可以得到这个对象锁。由于所有的这些方法都需要线程持有对象的锁，这样就只能通过同步来实现，所以他们只能在同步方法或者同步块中被调用。</p>
<h5 id="thread-类中的-yield-方法有什么作用">Thread 类中的 yield 方法有什么作用？</h5>
<p>使当前线程从执行状态（运行状态）变为可执行态（就绪状态）。</p>
<p>当前线程到了就绪状态，那么接下来哪个线程会从就绪状态变成执行状态呢？可能是当前线程，也可能是其他线程，看系统的分配了。</p>
<h5 id="为什么-thread-类的-sleep和-yield-方法是静态的">为什么 Thread 类的 sleep()和 yield ()方法是静态的？</h5>
<p>Thread 类的 sleep()和 yield()方法将在当前正在执行的线程上运行。所以在其他处于等待状态的线程上调用这些方法是没有意义的。这就是为什么这些方法是静态的。它们可以在当前正在执行的线程中工作，并避免程序员错误的认为可以在其他非运行线程调用这些方法。</p>
<h5 id="线程的-sleep方法和-yield方法有什么区别">线程的 sleep()方法和 yield()方法有什么区别？</h5>
<p>（1） sleep()方法给其他线程运行机会时不考虑线程的优先级，因此会给低优先级的线程以运行的机会；yield()方法只会给相同优先级或更高优先级的线程以运行的机会；</p>
<p>（2） 线程执行 sleep()方法后转入阻塞（blocked）状态，而执行 yield()方法后转入就绪（ready）状态；</p>
<p>（3）sleep()方法声明抛出 InterruptedException，而 yield()方法没有声明任何异常；</p>
<p>（4）sleep()方法比 yield()方法（跟操作系统 CPU 调度相关）具有更好的可移植性，通常不建议使用yield()方法来控制并发线程的执行。</p>
<h5 id="如何停止一个正在运行的线程">如何停止一个正在运行的线程？</h5>
<p>在java中有以下3种方法可以终止正在运行的线程：</p>
<ol>
<li>使用退出标志，使线程正常退出，也就是当run方法完成后线程终止。</li>
<li>使用stop方法强行终止，但是不推荐这个方法，因为stop和suspend及resume一样都是过期作废的方法。</li>
<li>使用interrupt方法中断线程。</li>
</ol>
<h5 id="java-中-interrupted-和-isinterrupted-方法的区别">Java 中 interrupted 和 isInterrupted 方法的区别？</h5>
<p>interrupt：用于中断线程。调用该方法的线程的状态为将被置为”中断”状态。</p>
<p>注意：线程中断仅仅是置线程的中断状态位，不会停止线程。需要用户自己去监视线程的状态为并做处理。支持线程中断的方法（也就是线程中断后会抛出interruptedException 的方法）就是在监视线程的中断状态，一旦线程的中断状态被置为“中断状态”，就会抛出中断异常。</p>
<p>interrupted：是静态方法，查看当前中断信号是true还是false并且清除中断信号。如果一个线程被中断了，第一次调用 interrupted 则返回 true，第二次和后面的就返回 false 了。</p>
<p>isInterrupted：查看当前中断信号是true还是false</p>
<h5 id="什么是阻塞式方法">什么是阻塞式方法？</h5>
<p>阻塞式方法是指程序会一直等待该方法完成期间不做其他事情，ServerSocket 的accept()方法就是一直等待客户端连接。这里的阻塞是指调用结果返回之前，当前线程会被挂起，直到得到结果之后才会返回。此外，还有异步和非阻塞式方法在任务完成前就返回。</p>
<h5 id="java-中你怎样唤醒一个阻塞的线程">Java 中你怎样唤醒一个阻塞的线程？</h5>
<p>首先 ，wait()、notify() 方法是针对对象的，调用任意对象的 wait()方法都将导致线程阻塞，阻塞的同时也将释放该对象的锁，相应地，调用任意对象的 notify()方法则将随机解除该对象阻塞的线程，但它需要重新获取该对象的锁，直到获取成功才能往下执行；</p>
<p>其次，wait、notify 方法必须在 synchronized 块或方法中被调用，并且要保证同步块或方法的锁对象与调用 wait、notify 方法的对象是同一个，如此一来在调用 wait 之前当前线程就已经成功获取某对象的锁，执行 wait 阻塞后当前线程就将之前获取的对象锁释放。</p>
<h5 id="notify-和-notifyall-有什么区别">notify() 和 notifyAll() 有什么区别？</h5>
<p>如果线程调用了对象的 wait()方法，那么线程便会处于该对象的等待池中，等待池中的线程不会去竞争该对象的锁。</p>
<p>notifyAll() 会唤醒所有的线程，notify() 只会唤醒一个线程。</p>
<p>notifyAll() 调用后，会将全部线程由等待池移到锁池，然后参与锁的竞争，竞争成功则继续执行，如果不成功则留在锁池等待锁被释放后再次参与竞争。而 notify()只会唤醒一个线程，具体唤醒哪一个线程由虚拟机控制。</p>
<h4 id="如何在两个线程间共享数据">如何在两个线程间共享数据？</h4>
<p>在两个线程间共享变量即可实现共享。</p>
<p>一般来说，共享变量要求变量本身是线程安全的，然后在线程内使用的时候，如果有对共享变量的复合操作，那么也得保证复合操作的线程安全性。</p>
<p>可以通过中断 和 共享变量的方式实现线程间的通讯和协作</p>
<p>比如说最经典的生产者-消费者模型：当队列满时，生产者需要等待队列有空间才能继续往里面放入商品，而<strong>在等待的期间内，生产者必须释放对临界资源（即队列）的占用权</strong>。因为生产者如果不释放对临界资源的占用权，那么<strong>消费者就无法消费队列中的商品</strong>，就不会让队列有空间，那么生产者就会一直无限等待下去。因此，一般情况下，当队列满时，会让生产者交出对临界资源的占用权，并进入挂起状态。然后等待消费者消费了商品，然后消费者通知生产者队列有空间了。同样地，当队列空时，消费者也必须等待，等待生产者通知它队列中有商品了。这种互相通信的过程就是线程间的协作。</p>
<p>Java中线程通信协作的最常见的两种方式：</p>
<ol>
<li>
<p>syncrhoized加锁的线程的<strong>Object类</strong>的wait()/notify()/notifyAll()</p>
</li>
<li>
<p>ReentrantLock类加锁的线程的<strong>Condition类的</strong>await()/signal()/signalAll()</p>
</li>
</ol>
<p>线程间直接的数据交换：</p>
<ol start="3">
<li>通过管道进行线程间通信：1）字节流；2）字符流</li>
</ol>
<h4 id="同步方法和同步块哪个是更好的选择">同步方法和同步块，哪个是更好的选择？</h4>
<pre><code class="language-java">Lock lock = new ReentrantLock();
lock. lock();
try {
    System. out. println(&quot;获得锁&quot;);
} catch (Exception e) {
    // TODO: handle exception
} finally {
    System. out. println(&quot;释放锁&quot;);
    lock. unlock();
}
</code></pre>
<p>同步块更要符合开放调用的原则，只在需要锁住的代码块锁住相应的对象，这样从侧面来说也可以避免死锁。</p>
<p>请知道一条原则：同步的范围越小越好。</p>
<h5 id="什么是线程同步和线程互斥有哪几种实现方式">什么是线程同步和线程互斥，有哪几种实现方式？</h5>
<p>当一个线程对共享的数据进行操作时，应使之成为一个&quot;原子操作&quot;，即在没有完成相关操作之前，不允许其他线程打断它，否则，就会破坏数据的完整性，必然会得到错误的处理结果，这就是线程的同步。</p>
<p>在多线程应用中，考虑不同线程之间的数据同步和防止死锁。当两个或多个线程之间同时等待对方释放资源的时候就会形成线程之间的死锁。为了防止死锁的发生，需要通过同步来实现线程安全。</p>
<p>线程互斥是指对于共享的进程系统资源，在各单个线程访问时的排它性。当有若干个线程都要使用某一共享资源时，任何时刻最多只允许一个线程去使用，其它要使用该资源的线程必须等待，直到占用资源者释放该资源。线程互斥可以看成是一种特殊的线程同步。</p>
<p>线程间的同步方法大体可分为两类：用户模式和内核模式。顾名思义，内核模式就是指利用系统内核对象的单一性来进行同步，使用时需要切换内核态与用户态，而用户模式就是不需要切换到内核态，只在用户态完成操作。</p>
<p>用户模式下的方法有：原子操作（例如一个单一的全局变量），临界区。<br>
内核模式下的方法有：事件，信号量，互斥量。</p>
<p>实现线程同步的方法</p>
<ul>
<li>同步代码方法：sychronized 关键字修饰的方法</li>
<li>同步代码块：sychronized 关键字修饰的代码块</li>
<li>使用特殊变量域volatile实现线程同步：volatile关键字为域变量的访问提供了一种免锁机制</li>
<li>使用重入锁实现线程同步：reentrantlock类是可重入、互斥、实现了lock接口的锁，它与sychronized方法具有相同的基本行为和语义</li>
</ul>
<h5 id="在监视器monitor内部是如何做线程同步的程序应该做哪种级别的同步">在监视器(Monitor)内部，是如何做线程同步的？程序应该做哪种级别的同步？</h5>
<p>在 java 虚拟机中，每个对象( Object 和 class )通过某种逻辑关联监视器,每个监视器和一个对象引用相关联，为了实现监视器的互斥功能，每个对象都关联着一把锁。</p>
<p>一旦方法或者代码块被 <strong>synchronized</strong> 修饰，那么这个部分就放入了监视器的监视区域，<strong>确保一次只能有一个线程执行该部分的代码</strong>，线程在获取锁之前不允许执行该部分的代码</p>
<p>另外 java 还提供了显式监视器( Lock )和隐式监视器( synchronized )两种锁方案</p>
<h4 id="如果你提交任务时线程池队列已满这时会发生什么">如果你提交任务时，线程池队列已满，这时会发生什么</h4>
<p>这里区分一下：</p>
<p>（1）如果使用的是无界队列 LinkedBlockingQueue，也就是无界队列的话，没关系，继续添加任务到阻塞队列中等待执行，因为 LinkedBlockingQueue 可以近乎认为是一个无穷大的队列，可以无限存放任务</p>
<p>（2）如果使用的是有界队列比如 ArrayBlockingQueue，任务首先会被添加到ArrayBlockingQueue 中，ArrayBlockingQueue 满了，会根据maximumPoolSize 的值增加线程数量，如果增加了线程数量还是处理不过来，ArrayBlockingQueue 继续满，那么则会使用拒绝策略RejectedExecutionHandler 处理满了的任务，默认是 AbortPolicy</p>
<h4 id="什么叫线程安全servlet-是线程安全吗">什么叫线程安全？servlet 是线程安全吗?</h4>
<p>线程安全是编程中的术语，指某个方法在多线程环境中被调用时，能够正确地处理多个线程之间的共享变量，使程序功能正确完成。</p>
<p>Servlet 不是线程安全的，servlet 是单实例多线程的，当多个线程同时访问同一个方法，是不能保证共享变量的线程安全性的。</p>
<p>Struts2 的 action 是多实例多线程的，是线程安全的，每个请求过来都会 new 一个新的 action 分配给这个请求，请求完成后销毁。</p>
<p>SpringMVC 的 Controller 是线程安全的吗？不是的，和 Servlet 类似的处理流程。</p>
<p>Struts2 好处是不用考虑线程安全问题；Servlet 和 SpringMVC 需要考虑线程安全问题，但是性能可以提升不用处理太多的 gc，可以使用 ThreadLocal 来处理多线程的问题。</p>
<h4 id="在-java-程序中怎么保证多线程的运行安全">在 Java 程序中怎么保证多线程的运行安全？</h4>
<ul>
<li>方法一：使用安全类，比如 java.util.concurrent 下的类，使用原子类AtomicInteger</li>
<li>方法二：使用自动锁 synchronized。</li>
<li>方法三：使用手动锁 Lock。</li>
</ul>
<p>手动锁 Java 示例代码如下：</p>
<pre><code class="language-java">Lock lock = new ReentrantLock();
lock. lock();
try {
    System. out. println(&quot;获得锁&quot;);
} catch (Exception e) {
    // TODO: handle exception
} finally {
    System. out. println(&quot;释放锁&quot;);
    lock. unlock();
}
</code></pre>
<h4 id="你对线程优先级的理解是什么">你对线程优先级的理解是什么？</h4>
<p>每一个线程都是有优先级的，一般来说，高优先级的线程在运行时会具有优先权，但这依赖于线程调度的实现，这个实现是和操作系统相关的(OS dependent)。我们可以定义线程的优先级，但是这并不能保证高优先级的线程会在低优先级的线程前执行。线程优先级是一个 int 变量(从 1-10)，1 代表最低优先级，10 代表最高优先级。</p>
<p>Java 的线程优先级调度会委托给操作系统去处理，所以与具体的操作系统优先级有关，如非特别需要，一般无需设置线程优先级。</p>
<h4 id="线程类的构造方法-静态块是被哪个线程调用的">线程类的构造方法、静态块是被哪个线程调用的</h4>
<p>这是一个非常刁钻和狡猾的问题。请记住：线程类的构造方法、静态块是被 new这个线程类所在的线程所调用的，而 run 方法里面的代码才是被线程自身所调用的。</p>
<p>如果说上面的说法让你感到困惑，那么我举个例子，假设 Thread2 中 new 了Thread1，main 函数中 new 了 Thread2，那么：</p>
<p>（1）Thread2 的构造方法、静态块是 main 线程调用的，Thread2 的 run()方法是Thread2 自己调用的</p>
<p>（2）Thread1 的构造方法、静态块是 Thread2 调用的，Thread1 的 run()方法是Thread1 自己调用的</p>
<h4 id="一个线程运行时发生异常会怎样">一个线程运行时发生异常会怎样？</h4>
<p>如果异常没有被捕获该线程将会停止执行。<code>Thread.UncaughtExceptionHandler</code>是用于处理未捕获异常造成线程突然中断情况的一个内嵌接口。当一个未捕获异常将造成线程中断的时候，JVM 会使用 <code>Thread.getUncaughtExceptionHandler()</code>来查询线程的 <code>UncaughtExceptionHandler</code>并将线程和异常作为参数传递给 handler 的 <code>uncaughtException()</code>方法进行处理。</p>
<h4 id="java-线程数过多会造成什么异常">Java 线程数过多会造成什么异常？</h4>
<ul>
<li>线程的生命周期开销非常高</li>
<li>消耗过多的 CPU</li>
</ul>
<p>资源如果可运行的线程数量多于可用处理器的数量，那么有线程将会被闲置。大量空闲的线程会占用许多内存，给垃圾回收器带来压力，而且大量的线程在竞争 CPU资源时还将产生其他性能的开销。</p>
<ul>
<li>降低JVM稳定性</li>
</ul>
<p>在可创建线程的数量上存在一个限制，这个限制值将随着平台的不同而不同，并且承受着多个因素制约，包括 JVM 的启动参数、Thread 构造函数中请求栈的大小，以及底层操作系统对线程的限制等。如果破坏了这些限制，那么可能抛出<code>OutOfMemoryError</code> 异常。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ 多线程基础概念]]></title>
        <id>https://tinaxiawuhao.github.io/post/ddmZREDcW/</id>
        <link href="https://tinaxiawuhao.github.io/post/ddmZREDcW/">
        </link>
        <updated>2021-05-09T05:18:21.000Z</updated>
        <content type="html"><![CDATA[<h2 id="什么是线程">什么是线程</h2>
<blockquote>
<p>是操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程中的实际运作单位。</p>
</blockquote>
<h3 id="线程安全的问题">线程安全的问题</h3>
<p><strong>并发编程三要素是什么？在 Java 程序中怎么保证多线程的运行安全？</strong></p>
<p>并发编程三要素（线程的安全性问题体现在）：</p>
<p>原子性：原子，即一个不可再被分割的颗粒。原子性指的是一个或多个操作要么全部执行成功要么全部执行失败。(<code>synchronized</code>,<code>lock</code>,<code>unlock</code>)</p>
<p>可见性：一个线程对共享变量的修改,另一个线程能够立刻看到。（<code>synchronized</code>,<code>volatile</code>,<code>final</code>）</p>
<p>有序性：程序执行的顺序按照代码的先后顺序执行。（处理器可能会对指令进行重排序）（<code>synchronized</code>,<code>volatile</code>）</p>
<p>出现线程安全问题的原因：</p>
<ul>
<li>线程切换带来的原子性问题</li>
<li>缓存导致的可见性问题</li>
<li>编译优化带来的有序性问题</li>
</ul>
<p>解决办法：</p>
<ul>
<li>JDK Atomic开头的原子类、synchronized、LOCK，可以解决原子性问题</li>
<li>synchronized、volatile、LOCK，可以解决可见性问题</li>
<li>Happens-Before 规则可以解决有序性问题</li>
</ul>
<h3 id="并发与并行">并发与并行</h3>
<ul>
<li>并发：多个任务在同一个 CPU 核上，按细分的时间片轮流(交替)执行，从逻辑上来看那些任务是同时执行。</li>
<li>并行：单位时间内，多个处理器或多核处理器同时处理多个任务，是真正意义上的“同时进行”。</li>
<li>串行：有n个任务，由一个线程按顺序执行。由于任务、方法都在一个线程执行所以不存在线程不安全情况，也就不存在临界区的问题。</li>
</ul>
<h3 id="并发编程多线程的优点">并发编程（多线程）的优点</h3>
<ol>
<li>
<p>早期的CPU是单核的，为了提升计算能力，将多个计算单元整合到一起。形成了多核CPU。<strong>多线程就是为了将多核CPU发挥到极致，一边提高性能</strong>。</p>
</li>
<li>
<p>方便进行业务拆分，提升系统并发能力和性能：在特殊的业务场景下，先天的就适合于并发编程。现在的系统动不动就要求百万级甚至千万级的并发量，而多线程并发编程正是开发高并发系统的基础，利用好多线程机制可以大大提高系统整体的并发能力以及性能。面对复杂业务模型，并行程序会比串行程序更适应业务需求，而并发编程更能吻合这种业务拆分</p>
</li>
</ol>
<h3 id="并发编程多线程的缺点">并发编程（多线程）的缺点</h3>
<p>上面说了多线程的优点是：为了提高计算性能。那么一定会提高？答案是不一定的。有时候多线程不一定比单线程计算快</p>
<p>多线程会带来额外的开销和复杂的问题</p>
<ul>
<li>上下文切换</li>
<li>死锁</li>
<li>内存泄漏</li>
</ul>
<h4 id="上下文切换">上下文切换</h4>
<p>时间片是CPU分配给各个线程的时间，因为时间非常短，所以CPU不断通过切换线程，让我们觉得多个线程是同时执行的，时间片一般是几十毫秒。而每次切换时，需要保存当前的状态起来，以便能够进行恢复先前状态，而这个切换时非常损耗性能，过于频繁反而无法发挥出多线程编程的优势。<br>
减少上下文切换可以采用无锁并发编程，CAS算法，使用最少的线程和使用协程。</p>
<ul>
<li>
<p>无锁并发编程：可以参照concurrentHashMap锁分段的思想，不同的线程处理不同段的数据，这样在多线程竞争的条件下，可以减少上下文切换的时间。</p>
</li>
<li>
<p>CAS算法，利用Atomic下使用CAS算法来更新数据，使用了乐观锁，可以有效的减少一部分不必要的锁竞争带来的上下文切换</p>
</li>
<li>
<p>使用最少线程：避免创建不需要的线程，比如任务很少，但是创建了很多的线程，这样会造成大量的线程都处于等待状态</p>
</li>
<li>
<p>协程：在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换</p>
</li>
</ul>
<h4 id="线程死锁">线程死锁</h4>
<blockquote>
<p>死锁是指两个或两个以上的进程（线程）在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程（线程）称为死锁进程（线程）。</p>
</blockquote>
<p>多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。由于线程被无限期地阻塞，因此程序不可能正常终止。</p>
<p>如下图所示，线程 A 持有资源 2，线程 B 持有资源 1，他们同时都想申请对方的资源，所以这两个线程就会互相等待而进入死锁状态。</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1620451228802.png" alt="" loading="lazy"></figure>
<p>下面通过一个例子来说明线程死锁：</p>
<pre><code class="language-java">public class DeadLockDemo {
    private static Object resource1 = new Object();//资源 1
    private static Object resource2 = new Object();//资源 2

    public static void main(String[] args) {
        new Thread(() -&gt; {
            synchronized (resource1) {
                System.out.println(Thread.currentThread() + &quot;get resource1&quot;);
                try {
                    Thread.sleep(1000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println(Thread.currentThread() + &quot;waiting get resource2&quot;);
                synchronized (resource2) {
                    System.out.println(Thread.currentThread() + &quot;get resource2&quot;);
                }
            }
        }, &quot;线程 1&quot;).start();

        new Thread(() -&gt; {
            synchronized (resource2) {
                System.out.println(Thread.currentThread() + &quot;get resource2&quot;);
                try {
                    Thread.sleep(1000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println(Thread.currentThread() + &quot;waiting get resource1&quot;);
                synchronized (resource1) {
                    System.out.println(Thread.currentThread() + &quot;get resource1&quot;);
                }
            }
        }, &quot;线程 2&quot;).start();
    }
}
</code></pre>
<p>输出结果</p>
<pre><code class="language-java">Thread[线程 1,5,main]get resource1
Thread[线程 2,5,main]get resource2
Thread[线程 1,5,main]waiting get resource2
Thread[线程 2,5,main]waiting get resource1
</code></pre>
<p>线程 A 通过 synchronized (resource1) 获得 resource1 的监视器锁，然后通过Thread.sleep(1000)；让线程 A 休眠 1s 为的是让线程 B 得到CPU执行权，然后获取到 resource2 的监视器锁。线程 A 和线程 B 休眠结束了都开始企图请求获取对方的资源，然后这两个线程就会陷入互相等待的状态，这也就产生了死锁。上面的例子符合产生死锁的四个必要条件。</p>
<p><strong>形成死锁的四个必要条件是什么</strong></p>
<ol>
<li>互斥条件：线程(进程)对于所分配到的资源具有排它性，即一个资源只能被一个线程(进程)占用，直到被该线程(进程)释放</li>
<li>请求与保持条件：一个线程(进程)因请求被占用资源而发生阻塞时，对已获得的资源保持不放。</li>
<li>不剥夺条件：线程(进程)已获得的资源在末使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。</li>
<li>循环等待条件：当发生死锁时，所等待的线程(进程)必定会形成一个环路（类似于死循环），造成永久阻塞</li>
</ol>
<p><strong>如何避免线程死锁</strong></p>
<p>我们只要破坏产生死锁的四个条件中的其中一个就可以了。</p>
<ol>
<li>
<p><strong>破坏互斥条件</strong></p>
<p>这个条件我们没有办法破坏，因为我们用锁本来就是想让他们互斥的（临界资源需要互斥访问）。</p>
</li>
<li>
<p><strong>破坏请求与保持条件</strong></p>
<p>一次性申请所有的资源。</p>
</li>
<li>
<p><strong>破坏不剥夺条件</strong></p>
<p>占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。</p>
</li>
<li>
<p><strong>破坏循环等待条件</strong></p>
<p>靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。</p>
</li>
</ol>
<h3 id="创建线程的四种方式">创建线程的四种方式</h3>
<p>创建线程有四种方式：</p>
<ul>
<li>继承 Thread 类；</li>
<li>实现 Runnable 接口；</li>
<li>实现 Callable 接口；</li>
<li>使用 Executors 工具类创建线程池</li>
</ul>
<h4 id="继承-thread-类">继承 Thread 类</h4>
<p>步骤</p>
<ol>
<li>定义Thread 类的子类，并重写该类的run() 方法，该run() 方法的方法体就代表类线程需要完成的任务。因此把run() 方法称为线程执行体。</li>
<li>创建 Thread 子类的实例，即创建线程对象</li>
<li>调用子类实例的star()方法来启动线程</li>
</ol>
<pre><code class="language-java">/**
   * 继承 thread 的内部类，以买票例子
   */
public class FirstThread extends Thread{
    private int i;
    private int ticket = 10;

    @Override
    public void run() {
        for (;i&lt;20;i++) {
			//当继承thread 时，直接使用this 可以获取当前的线程,getName()获取当前线程的名字
            if(this.ticket&gt;0){
               	Log.e(TAG, getName() + &quot;, 卖票：ticket=&quot; + ticket--);
            }
        }

    }
}

private void starTicketThread(){
    Log.d(TAG,&quot;starTicketThread, &quot;+Thread.currentThread().getName());

    FirstThread thread1 = new FirstThread();
    FirstThread thread2 = new FirstThread();
    FirstThread thread3 = new FirstThread();

    thread1.start();
    thread2.start();
    thread3.start();

    //开启3个线程进行买票，每个线程都卖了10张，总共就30张票

}
</code></pre>
<p>运行结果</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1620451264035.png" alt="" loading="lazy"></figure>
<p><strong>注意</strong> ：可以看到 3 个线程输入的 票数变量不连续，注意：ticket 是 FirstThread 的实例属性，而不是局部变量，但是因为程序每次创建线程对象都需要创建一个FirstThread 的对象，所有多个线程不共享该实例的属性。</p>
<pre><code class="language-java">//使用Lambda表达式，实现多线程
  new Thread(() -&gt; {
    System.out.println(Thread.currentThread().getName() + &quot;新线程创建了！&quot;);
  }
  ).start();
</code></pre>
<h4 id="实现-runnable-接口">实现 Runnable 接口</h4>
<p>步骤</p>
<ol>
<li>定义Runnable接口实现类SecondThread，并重写run()方法</li>
<li>创建SecondThread实例secondThread，以secondThread作为target创建Thead对象，<strong>该Thread对象才是真正的线程对象</strong></li>
<li>调用线程对象的start()方法</li>
</ol>
<pre><code class="language-java">/**
   * 实现 runnable 接口，创建线程类
   */
public class SecondThread implements Runnable{

    private int i;
    private int ticket = 100;

    @Override
    public void run() {
        for (;i&lt;20;i++) {
            //如果线程类实现 runnable 接口
            //获取当前的线程，只能用 Thread.currentThread() 获取当前的线程名
            Log.d(TAG,Thread.currentThread().getName()+&quot; &quot;+i);

            if(this.ticket&gt;0){
                Log.e(TAG, Thread.currentThread().getName() + &quot;, 卖票：ticket=&quot; + ticket--);
            }
        }
    }
}


private void starTicketThread2(){
    Log.d(TAG,&quot;starTicketThread2, &quot;+Thread.currentThread().getName());

    SecondThread secondThread = new SecondThread();

    //通过new Thread(target,name)创建新的线程
    new Thread(secondThread,&quot;买票人1&quot;).start();
    new Thread(secondThread,&quot;买票人2&quot;).start();
    new Thread(secondThread,&quot;买票人3&quot;).start();

    //虽然是开启了3个线程，但是一共只买了100张票
}
</code></pre>
<p>执行结果</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1620451273746.png" alt="" loading="lazy"></figure>
<p><strong>注意</strong>：可以看到 3 个线程输入的 票数变量是连续的，采用 Runnable 接口的方式创建多个线程可以共享线程类的实例的属性。这是因为在这种方式下，程序所创建的Runnable 对象只是线程的 target ,而多个线程可以共享同一个 target,所以多个线程可以共享同一个线程类（实际上应该是该线程的target 类）的实例属性。</p>
<pre><code class="language-java">//使用匿名内部类的方式，实现多线程
  new Thread(new Runnable() {
    @Override
    public void run() {
      System.out.println(Thread.currentThread().getName() + &quot;新线程创建了！&quot;);
    }
  }).start();
</code></pre>
<h4 id="实现-callable-接口">实现 Callable 接口</h4>
<p>步骤</p>
<ol>
<li>创建callable接口的实现类，并实现call() 方法，该call() 方法将作为线程的执行体，且该call() 方法是有返回值的。</li>
<li>创建 callable实现类的实例，使用 FutureTask 类来包装Callable对象，该FutureTask 对象封装 call() 方法的返回值。</li>
<li>使用FutureTask 对象作为Thread对象的target创建并启动新线程。</li>
<li>调用FutureTask对象的get()方法来获取子线程执行结束后的返回值。</li>
</ol>
<pre><code class="language-java">/**
       * 使用callable 来实现线程类
       */
public class ThirdThread implements Callable&lt;Integer&gt;{

    private int ticket = 20;

    @Override
    public Integer call(){

        for ( int i = 0;i&lt;10;i++) {
            //获取当前的线程，只能用 Thread.currentThread() 获取当前的线程名
            //        Log.d(TAG,Thread.currentThread().getName()+&quot; &quot;+i);

            if(this.ticket&gt;0){
                Log.e(TAG, Thread.currentThread().getName() + &quot;, 卖票：ticket=&quot; + ticket--);
            }
        }


        return ticket;
    }
}

private void starCallableThread(){
    ThirdThread thirdThread = new ThirdThread();
    FutureTask&lt;Integer&gt; task = new FutureTask&lt;Integer&gt;(thirdThread);

    new Thread(task,&quot;有返回值的线程&quot;).start();

    try {
        Integer integer = task.get();
        Log.d(TAG,&quot;starCallableThread, 子线程的返回值=&quot;+integer);

    } catch (InterruptedException e) {
        e.printStackTrace();
    } catch (ExecutionException e) {
        e.printStackTrace();
    }

}
</code></pre>
<p>执行结果</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1620451283904.png" alt="" loading="lazy"></figure>
<p><strong>注意</strong>：注意：Callable的call() 方法允许声明抛出异常，并且允许带有返回值。</p>
<p>程序最后调用FutureTask 对象的get()方法来返回Call(）方法的返回值，导致主线程被阻塞，直到call()方法结束并返回为止。</p>
<h4 id="使用-executors-工具类创建线程池">使用 Executors 工具类创建线程池</h4>
<p>Executors提供了一系列工厂方法用于创先线程池，返回的线程池都实现了<code>ExecutorService</code>接口。</p>
<p>主要有<code>newFixedThreadPool</code>，<code>newCachedThreadPool</code>，<code>newSingleThreadExecutor</code>，<code>newScheduledThreadPool</code>，后续详细介绍这四种线程池</p>
<pre><code class="language-java">public class MyRunnable implements Runnable {

    @Override
    public void run() {
        System.out.println(Thread.currentThread().getName() + &quot; run()方法执行中...&quot;);
    }

}
public class SingleThreadExecutorTest {
    
    public static void main(String[] args) {
        ExecutorService executorService = Executors.newSingleThreadExecutor();
        MyRunnable runnableTest = new MyRunnable();
        for (int i = 0; i &lt; 5; i++) {
            executorService.execute(runnableTest);
        }

        System.out.println(&quot;线程任务开始执行&quot;);
        executorService.shutdown();
    }

}
</code></pre>
<p>执行结果</p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1620451292701.png" alt="" loading="lazy"></figure>
<h4 id="说一下-runnable-和-callable-有什么区别">说一下 runnable 和 callable 有什么区别？</h4>
<p>相同点</p>
<ul>
<li>都是接口</li>
<li>都可以编写多线程程序</li>
<li>都采用Thread.start()启动线程</li>
</ul>
<p>主要区别</p>
<ul>
<li>Runnable 接口 run 方法无返回值；Callable 接口 call 方法有返回值，是个泛型，和Future、FutureTask配合可以用来获取异步执行的结果</li>
<li>Runnable 接口 run 方法只能抛出运行时异常，且无法捕获处理；Callable 接口 call 方法允许抛出异常，可以获取异常信息</li>
</ul>
<p><strong>注</strong>：Callalbe接口支持返回执行结果，需要调用FutureTask.get()得到，此方法会阻塞主进程的继续往下执行，如果不调用不会阻塞。</p>
<h4 id="线程的-run和-start有什么区别">线程的 run()和 start()有什么区别？</h4>
<p>每个线程都是通过某个特定Thread对象所对应的方法run()来完成其操作的，run()方法称为线程体。通过调用Thread类的start()方法来启动一个线程。</p>
<p>start() 方法用于启动线程，run() 方法用于执行线程的运行时代码。run() 可以重复调用，而 start() 只能调用一次。</p>
<h4 id="为什么我们调用-start-方法时会执行-run-方法为什么我们不能直接调用-run-方法">为什么我们调用 start() 方法时会执行 run() 方法，为什么我们不能直接调用 run() 方法？</h4>
<p>new 一个 Thread，线程进入了新建状态。调用 start() 方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 start() 会执行线程的相应准备工作，然后自动执行 run() 方法的内容，这是真正的多线程工作。</p>
<p>而直接执行 run() 方法，会把 run 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。</p>
<p>总结： 调用 start 方法方可启动线程并使线程进入就绪状态，而 run 方法只是 thread 的一个普通方法调用，还是在主线程里执行。</p>
<h4 id="什么是-callable-和-future">什么是 Callable 和 Future?</h4>
<p>Callable 接口类似于 Runnable，从名字就可以看出来了，但是 Runnable 不会返回结果，并且无法抛出返回结果的异常，而 Callable 功能更强大一些，被线程执行后，可以返回值，这个返回值可以被 Future 拿到，也就是说，Future 可以拿到异步执行任务的返回值。</p>
<p>Future 接口表示异步任务，是一个可能还没有完成的异步任务的结果。所以说 Callable用于产生结果，Future 用于获取结果。</p>
<h4 id="什么是-futuretask">什么是 FutureTask</h4>
<p>FutureTask 表示一个异步运算的任务。FutureTask 里面可以传入一个 Callable 的具体实现类，可以对这个异步运算的任务的结果进行等待获取、判断是否已经完成、取消任务等操作。只有当运算完成的时候结果才能取回，如果运算尚未完成 get 方法将会阻塞。一个 FutureTask 对象可以对调用了 Callable 和 Runnable 的对象进行包装，由于 FutureTask 也是Runnable 接口的实现类，所以 FutureTask 也可以放入线程池中。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[java基础之一文件操作]]></title>
        <id>https://tinaxiawuhao.github.io/post/FNm9kw7nn/</id>
        <link href="https://tinaxiawuhao.github.io/post/FNm9kw7nn/">
        </link>
        <updated>2021-05-08T06:57:30.000Z</updated>
        <content type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1620370686314.png" alt="" loading="lazy"></figure>
<h3 id="一-抽象类">一、抽象类：</h3>
<p>字节流： <code>InputStream</code>（读入流） <code>OutputStream</code>(写出流）<br>
字符流：<code>Reader</code>（字符 读入流） <code>Writer</code> （字符写出流）</p>
<h3 id="字节流读取字符数据的问题">字节流读取字符数据的问题 :</h3>
<p>汉字等字符,往往有多个字节组成,那么到底哪几个字节应该组成一个汉字呢? 字节流不知道.如果我们自己用字节流读取字节数据,然后手动自己转字符,就有可能对规则不了解.从而造成错误. Java中的字符流恰好就可以帮助我们解决这个问题.</p>
<p>Java提供的字符流的底层，它自己会根据读取到的字节数据的特点，然后自动的帮助我们把字节转成字符，最后我们就会自然的得到想要的字符数据。</p>
<p><strong>字符流怎么解决这个问题呢?</strong></p>
<p>​    <strong>字符流 =</strong> <strong>字节流 +</strong> <strong>编码表</strong></p>
<p>编码表其实里面定义了字节与字符的转换规则.</p>
<p>字符流在读取数据的时候,底层还是字节流在读取数据,字符流会自动根据编码规则把字节数据转为字符数据,就不会造成错误!</p>
<h3 id="编码表的介绍">编码表的介绍 :</h3>
<p><strong>说明 :</strong>  计算机中保存的数据都是二进制（1010100101001），我们要把生活中的数据保存到计算机中，需要把生活中的数据转成二进制数据，然后才能让计算机来识别生活中的数据，进而对这些数据进行处理。 &quot;补充 :&quot; 要把生活中的数据转成计算机能够识别的数据，就需要定义一个固定的转换关系： 老美他们为了把自己的生活中的数据保存到计算机中，他们发明了一张表，然后在这张表中规定了生活中所有的字符和二进制之间的对应关系：老美的文字和计算机中的二进制的对应关系表：ASCII。</p>
<p><strong>ASCII码表：</strong> 它采用的是一个字节表示所有的文字（标点符号，英文字母，其他的特殊符号，数字等）。</p>
<table>
<thead>
<tr>
<th>生活中的字符</th>
<th>十进制</th>
<th>二进制</th>
</tr>
</thead>
<tbody>
<tr>
<td>A</td>
<td>65</td>
<td>01000001</td>
</tr>
<tr>
<td>B</td>
<td>66</td>
<td>01000010</td>
</tr>
</tbody>
</table>
<p>欧洲也定义一张拉丁码表：ISO-8859-1 这个表码表兼容ASCII码表。也采用的一个字节表示字符数据。</p>
<p><strong>ASCII：</strong>  一个字节表示一个字符： <code>0xxx xxxx</code>  规定二进制的最高位是0，其他的7位表示某个字符的编码值。</p>
<p><strong>ISO-8859-1：</strong>  一个字节表示一个字符：把整个字节表示字符，<code>xxxx xxxx</code> 全部用来表示字符数据</p>
<p><strong>中国的编码表：</strong> GBK编码表采用2个字节表示一个汉字。<br>
<strong>GB2312 ：</strong> 它识别六七千的文字。兼容ASCII编码表。</p>
<p><strong>GBK：</strong> 识别两万多字符。目前主流的编码表.</p>
<p><strong>GB18030：</strong> 识别更多。</p>
<p>世界计算机协会也制定了一个张国际通用的编码表：</p>
<p>​       <strong>Unicode编码表：</strong> 它也采用2个字节表示一个字符。</p>
<p>Unicode编码表升级：<strong>UTF-8</strong>。</p>
<p>​	 <strong>UTF-8：</strong>  它对字符的编码规律可以使用一个字节表示的字符就使用一个字节。 可以使用两个字节表示的字符就使用两个字节。 可以使用三个字节表示的字符就使用三个字节（基本汉字都使用三个字节）。</p>
<p>可以识别汉字的编码表：      <code>GB2312</code>、<code>GBK</code>、<code>Unicode</code>、<code>UTF-8</code></p>
<h3 id="二-文件操作流">二、文件操作流</h3>
<p>字节流： <code>FileInputStream</code> ，<code>FileOutputStream</code><br>
字符流： <code>FileReader</code>, <code>FileWriter</code></p>
<pre><code class="language-java">File file = new File(&quot;D:/test/testIO.java&quot;);
InputStream in = new FileInputStream(file);
InputStream in = new FileInputStream(&quot;D:/test/testIO.java&quot;);
OutputStream out = new FileOutputStream(file);
OutputStream out = new FileOutputStream(&quot;D:/test/testIO.java&quot;);
</code></pre>
<pre><code class="language-java">Reader reader = new FileReader(&quot;demo01.txt&quot;);
FileWriter writer = new FileWriter(&quot;demo02.txt&quot;);
Writer writer = new OutputStreamWriter(new FileOutputStream(&quot;demo03_utf8.txt&quot;), &quot;UTF-8&quot;);
Reader reader = new InputStreamReader(new FileInputStream(&quot;demo03_utf8.txt&quot;), &quot;UTF-8&quot;);

</code></pre>
<pre><code class="language-java">//1.指定要读 的文件目录及名称
File file =new File(&quot;文件路径&quot;);
//2.创建文件读入流对象
FileInputStream fis =new FileInputStream(file);
//3.定义结束标志,可用字节数组读取
int i =0 ;
while((i = fis.read())!=-1){ 
    //i 就是从文件中读取的字节，读完后返回-1
}
//4.关闭流
fis.close();
//5.处理异常
</code></pre>
<pre><code class="language-java">//1.指定要写到的文件目录及名称
File file =new File(&quot;文件路径&quot;);
//2.创建文件读入流对象
FileOutputStream fos =new FileOutputStream(file);
//3.定义结束标志
fos.write(要写出的字节或者字节数组);
//4.刷新和关闭流
fos.flush();
fos.close();
//5.处理异常
</code></pre>
<h3 id="三-缓冲流">三、缓冲流：</h3>
<p>​    字节缓冲流：<code>BufferedInputStream</code>,<code>BufferedOutputStream</code><br>
​    字符缓冲流：<code>BufferedReader</code> ,<code>BufferedWriter</code><br>
​    缓冲流是对流的操作的功能的加强，提高了数据的读写效率。既然缓冲流是对流的功能和读写效率的加强和提高，所以在创建缓冲流的对象时应该要传入要加强的流对象。</p>
<pre><code class="language-java">//保存其参数，即输入流 in，以便将来使用。创建一个内部缓冲区数组并将
//其存储在 buf 中,该buf的大小默认为8192。
public BufferedInputStream(InputStream in);

 
//创建具有指定缓冲区大小的 BufferedInputStream 并保存其参数，
//即输入流 in，以便将来使用。创建一个长度为 size 的内部缓冲区数组并
//将其存储在 buf 中。
public BufferedInputStream(InputStream in,int size);


//创建一个新的缓冲输出流，以将数据写入指定的底层输出流。
public BufferedOutputStream(OutputStream out);

 
//创建一个新的缓冲输出流，以将具有指定缓冲区大小的数据写入指定的底层输出流。
public BufferedOutputStream(OutputStream out,int size);
</code></pre>
<pre><code class="language-java">BufferedWriter bw = new BufferedWriter(new OutputStreamWriter(new FileOutputStream(&quot;demo08_utf8.txt&quot;), &quot;UTF-8&quot;));

BufferedReader br = new BufferedReader(new InputStreamReader(new FileInputStream(&quot;demo08_utf8.txt&quot;), &quot;UTF-8&quot;));
</code></pre>
<pre><code class="language-java">//1.指定要读 的文件目录及名称
File file =new File(&quot;文件路径&quot;);
//2.创建文件读入流对象
FileInputStream fis =new FileInputStream(file);
//3.创建缓冲流对象加强fis功能
BufferedInputStream bis =new BufferedInputStream(fis); 
//4.定义结束标志,可用字节数组读取
int i =0 ;
while((i = bis.read())!=-1){ 
    //i 就是从文件中读取的字节，读完后返回-1
}
//5.关闭流
bis.close();
//6.处理异常
</code></pre>
<pre><code class="language-java">//1.指定要写到的文件目录及名称
File file =new File(&quot;文件路径&quot;);
//2.创建文件读入流对象
FileOutputStream fos =new FileOutputStream(file);
//3.创建缓冲流对象加强fos功能
BufferedOutputStream bos=new BufferedOutputStream(fos);
//4.向流中写入数据
bos.write(要写出的字节或者字节数组);
//5.刷新和关闭流
bos.flush();
bos.close();
//6.处理异常
</code></pre>
<p>由以上看出流的操作基本相同，此流与文件流操作是几乎一样的只是将文件流作为参数传入缓冲流的构造方法中堆文件流读写文件的功能进行加强<br>
注1：在字符读入缓冲流<code>BufferedReade</code>r 中还提供了读一行的方法 <code>readLine()</code>可以读取一行文本<br>
在字符写出缓冲流<code>BufferedWriter</code> 中还提供了写入一个行分隔符的方法<code>writeLine()</code>,用于写出时换行<br>
注2：此处用到的是设计模式中的装饰模式</p>
<pre><code class="language-java">//装饰的对象只要是抽象类的子类即可
BufferedInputStream bis =new BufferedInputStream(new FileInputStream(new File(&quot;文件路径&quot;)));   
</code></pre>
<h3 id="四-转换流">四、转换流：</h3>
<p>这类流是用于将字符转换为字节输入输出，用于操作字符文件，属于字符流的子类，所以后缀为<code>reader</code>，<code>writer</code>；前缀<code>inputstream</code>，<code>outputstream</code>；</p>
<p>注 ：要传入字节流作为参赛<br>
<code>InputStreamReade</code>r: 字符转换输出流<br>
<code>OutputStreamWriter</code>：字符转换输入流</p>
<pre><code class="language-java">需求：读取键盘输入的一行文本,再将输入的写到本地磁盘上
//1.获取键盘输入的字节流对象in
InputStream in =Stream.in; 
/*2.用转换流将字节流对象转换为字符流对象，方便调用字符缓冲流的readeLine()方法*/
InputStreamReader isr =new InputStreamReader(in);
/*5.创建字符转换输出流对象osw，方便把输入的字符流转换为字节输出到本地文件。*/
OutputStreamWriter osw =new OutputStreamWriter(new FileOutputStream(new File(&quot;文件名&quot;))); 
/*3.现在isr是字符流，可以作为参数传入字符缓冲流中*/
BufferedReader br =new BufferedReader(isr);
/*4.可以调用字符缓冲流br的readLine()方法度一行输入文本*/
String line =null;
while((line =br.readLine()){
    osw.write(line);//osw是字符流对象，可以直接操作字符串
}
//刷新此缓冲的输出流，保证数据全部都能写出
osw.flush();
br.close();
osw.close();
</code></pre>
<h3 id="读取数据">读取数据</h3>
<pre><code class="language-java">//读取方式一 : 效率低!
int content = -1;
while ((content = reader.read()) != -1) {
    System.out.print((char)content);
}


//读取方式二 : 数组之后的无用数据都会被读取!
int len = -1;
char[] cbuf = new char[1024];
while ((len = reader.read(cbuf)) != -1) {
    System.out.println(cbuf);
}


// 读取方式三 : 将读取的数据内容转换为 `字符串`
int len = -1;
char[] cbuf = new char[1024];
while ((len = reader.read(cbuf)) != -1) {
    String str = new String(cbuf, 0, len);
    System.out.println(str);
}
</code></pre>
<pre><code class="language-java">&quot;转换流 和 操作流 之间的关系 :&quot;
&quot;转换流 :&quot;
1. OutputStreamWriter = OutputStream + 任意编码表
2. InputStreamReader = InputStream + 任意编码表
&quot;操作流 :&quot;
1. FileWriter = OutputStreamWriter + 默认编码表 (GBK)
2. FileReader = InputStreamReader + 默认编码表(GBK)

&quot;总结 : 一般我们都使用操作流,当需要指定编码表的时候,才会使用转换流&quot;
</code></pre>
<h3 id="拆分文件及还原">拆分文件及还原</h3>
<pre><code class="language-java">public class Test {
     public static void main(String[] args) throws IOException {
           int count = judge();
           System.out.println(count);
           BufferedInputStream bis = new BufferedInputStream(new FileInputStream(
                     &quot;somethings\\test.flv&quot;));
           incision(count, bis, 6);
           BufferedOutputStream bos = new BufferedOutputStream(
                     new FileOutputStream(&quot;somethings\\jzc.flv&quot;));
           joint(bos,6);
           bos.close();
           bis.close();
     }
     public static void joint( BufferedOutputStream bos,int n)
                throws FileNotFoundException, IOException {
           for (int i = 1; i &lt;= n; i++) {
                BufferedInputStream bis = new BufferedInputStream(
                           new FileInputStream(&quot;somethings\\jzc&quot; + i + &quot;.flv&quot;));
                byte[] bys = new byte[1024];
                int len = -1;
                while ((len = bis.read(bys)) != -1) {
                     bos.write(bys, 0, len);
                }
                bis.close();
           }
           bos.close();
           System.out.println(&quot;拼接完了&quot;);
     }
     public static void incision(int count, BufferedInputStream bis, int n)
                throws FileNotFoundException, IOException {
           byte[] bys = new byte[1024];
           int len = -1;
           
           for (int i = 1; i &lt;= n; i++) {
                int count2 = 0;
                BufferedOutputStream bos = new BufferedOutputStream(
                           new FileOutputStream(&quot;somethings\\jzc&quot; + i + &quot;.flv&quot;));
                while ((len = bis.read(bys)) != -1) {
                     count2 += 1024;
                     System.out.println(count2);
                     if (count2 &lt; (count / n)+1024&amp;&amp;count2 &gt; (count / n)-1024) {
                           break;
                     } else {
                           bos.write(bys, 0, len);
                     }
                }
                bos.close();
           }
           System.out.println(&quot;切割完了&quot;);
     }
     public static int judge() throws FileNotFoundException, IOException {
           BufferedInputStream bis = new BufferedInputStream(new FileInputStream(
                     &quot;somethings\\test.flv&quot;));
           byte[] bys = new byte[1024];
           int len = -1;
           int count = 0;
           while ((len = bis.read(bys)) != -1) {
                count += 1024;
           }
           bis.close();
           return count;
     }
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[java基础之一lambda]]></title>
        <id>https://tinaxiawuhao.github.io/post/7BfPpY68W/</id>
        <link href="https://tinaxiawuhao.github.io/post/7BfPpY68W/">
        </link>
        <updated>2021-05-07T08:14:58.000Z</updated>
        <content type="html"><![CDATA[<h3 id="一-引言">一、引言</h3>
<p>java8最大的特性就是引入Lambda表达式，即函数式编程，可以将行为进行传递。<strong>总结就是：使用不可变值与函数，函数对不可变值进行处理，映射成另一个值。</strong></p>
<h3 id="二-java重要的函数式接口">二、java重要的函数式接口</h3>
<h4 id="1-什么是函数式接口">1、什么是函数式接口</h4>
<p><strong>函数接口是只有一个抽象方法的接口，用作 Lambda 表达式的类型。使用@FunctionalInterface注解修饰的类，编译器会检测该类是否只有一个抽象方法或接口，否则，会报错。可以有多个默认方法，静态方法。</strong></p>
<h5 id="11-java8自带的常用函数式接口">1.1 java8自带的常用函数式接口。</h5>
<table>
<thead>
<tr>
<th>函数接口</th>
<th>抽象方法</th>
<th>功能</th>
<th>参数</th>
<th>返回类型</th>
<th>示例</th>
</tr>
</thead>
<tbody>
<tr>
<td>Predicate</td>
<td>test(T t)</td>
<td>判断真假</td>
<td>T</td>
<td>boolean</td>
<td>金刚的身高大于185cm吗？</td>
</tr>
<tr>
<td>Consumer</td>
<td>accept(T t)</td>
<td>消费消息</td>
<td>T</td>
<td>void</td>
<td>输出一个值</td>
</tr>
<tr>
<td>Function</td>
<td>R apply(T t)</td>
<td>将T映射为R（转换功能）</td>
<td>T</td>
<td>R</td>
<td>获得student对象的名字</td>
</tr>
<tr>
<td>Supplier</td>
<td>T get()</td>
<td>生产消息</td>
<td>None</td>
<td>T</td>
<td>工厂方法</td>
</tr>
<tr>
<td>UnaryOperator</td>
<td>T apply(T t)</td>
<td>一元操作</td>
<td>T</td>
<td>T</td>
<td>逻辑非（!）</td>
</tr>
<tr>
<td>BinaryOperator</td>
<td>apply(T t, U u)</td>
<td>二元操作</td>
<td>(T，T)</td>
<td>(T)</td>
<td>求两个数的乘积（*）</td>
</tr>
</tbody>
</table>
<pre><code>public class Test {
    public static void main(String[] args) {
        Predicate&lt;Integer&gt; predicate = x -&gt; x &gt; 185;
        Student student = new Student(&quot;金刚&quot;, 23, 175);
        System.out.println(&quot;金刚的身高高于185吗？：&quot; + predicate.test(student.getStature()));

        Consumer&lt;String&gt; consumer = System.out::println;
        consumer.accept(&quot;消费消息，输出一个值&quot;);

        Function&lt;Student, String&gt; function = Student::getName;
        String name = function.apply(student);
        System.out.println(name);

        Supplier&lt;Integer&gt; supplier = () -&gt; Integer.valueOf(BigDecimal.TEN.toString());
        System.out.println(supplier.get());

        UnaryOperator&lt;Boolean&gt; unaryOperator = uglily -&gt; !uglily;
        Boolean apply2 = unaryOperator.apply(true);
        System.out.println(apply2);

        BinaryOperator&lt;Integer&gt; operator = (x, y) -&gt; x * y;
        Integer integer = operator.apply(2, 3);
        System.out.println(integer);

        test(() -&gt; &quot;我是一个演示的函数式接口&quot;);
    }

    /**
     * 演示自定义函数式接口使用
     *
     * @param worker
     */
    public static void test(Worker worker) {
        String work = worker.work();
        System.out.println(work);
    }

    public interface Worker {
        String work();
    }
}
//金刚的身高高于185吗？：false
//消费消息，输出一个值
//金刚
//10
//false
//6
//我是一个演示的函数式接口
</code></pre>
<p>以上演示了lambda接口的使用及自定义一个函数式接口并使用。下面，我们看看java8将函数式接口封装到流中如何高效的帮助我们处理集合。</p>
<p><strong>注意：Student::getName</strong>例子中这种编写lambda表达式的方式称为<strong>方法引用。<strong>格式为</strong>ClassName::methodName</strong>。</p>
<p><strong>示例：本篇所有示例都基于以下三个类。OutstandingClass：班级；Student：学生；SpecialityEnum：特长。</strong></p>
<figure data-type="image" tabindex="1"><img src="https://user-gold-cdn.xitu.io/2019/5/23/16ae40638d420acd?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt="img" loading="lazy"></figure>
<h5 id="12-惰性求值与及早求值">1.2 惰性求值与及早求值</h5>
<p><strong>惰性求值：只描述Stream，操作的结果也是Stream，这样的操作称为惰性求值</strong>。 惰性求值可以像建造者模式一样链式使用，最后再使用及早求值得到最终结果。</p>
<p><strong>及早求值：得到最终的结果而不是Stream，这样的操作称为及早求值。</strong></p>
<h4 id="2-常用的流">2、常用的流</h4>
<h5 id="21-collectcollectorstolist">2.1 collect(Collectors.toList())</h5>
<p><strong>将流转换为list。还有toSet()，toMap()等。及早求值</strong>。</p>
<pre><code class="language-java">public class TestCase {
    public static void main(String[] args) {
        List&lt;Student&gt; studentList = Stream.of(new Student(&quot;路飞&quot;, 22, 175),
                new Student(&quot;红发&quot;, 40, 180),
                new Student(&quot;白胡子&quot;, 50, 185)).collect(Collectors.toList());
        System.out.println(studentList);
    }
}
//输出结果
//[Student{name='路飞', age=22, stature=175, specialities=null}, 
//Student{name='红发', age=40, stature=180, specialities=null}, 
//Student{name='白胡子', age=50, stature=185, specialities=null}]
</code></pre>
<pre><code class="language-java">//转成map
public Map&lt;Long, String&gt; getIdNameMap(List&lt;Account&gt; accounts) {
    return accounts.stream().collect(Collectors.toMap(Account::getId, Account::getUsername));
}
//收集成实体本身map
public Map&lt;Long, Account&gt; getIdAccountMap(List&lt;Account&gt; accounts) {
    return accounts.stream().collect(Collectors.toMap(Account::getId, account -&gt; account));
}
//account -&gt; account是一个返回本身的lambda表达式，其实还可以使用Function接口中的一个默认方法代替，使整个方法更简洁优雅：
public Map&lt;Long, Account&gt; getIdAccountMap(List&lt;Account&gt; accounts) {
    return accounts.stream().collect(Collectors.toMap(Account::getId, Function.identity()));
}
//重复key的情况，下面name可能重复
public Map&lt;String, Account&gt; getNameAccountMap(List&lt;Account&gt; accounts) {
    return accounts.stream().collect(Collectors.toMap(Account::getUsername, Function.identity()));
}
//toMap有个重载方法，可以传入一个合并的函数来解决key冲突问题
public Map&lt;String, Account&gt; getNameAccountMap(List&lt;Account&gt; accounts) {
    return accounts.stream().collect(Collectors.toMap(Account::getUsername, Function.identity(), (key1, key2) -&gt; key2));
}
//按id分组
Map&lt;Long, List&lt;Account&gt;&gt; map = accounts.stream().collect(Collectors.groupingBy(Account::getId));
//指定具体收集的map
public Map&lt;String, Account&gt; getNameAccountMap(List&lt;Account&gt; accounts) {
    return accounts.stream().collect(Collectors.toMap(Account::getUsername, Function.identity(), (key1, key2) -&gt; key2, LinkedHashMap::new));
}
</code></pre>
<h5 id="22-filter">2.2 filter</h5>
<p>顾名思义，起<strong>过滤筛选</strong>的作用。<strong>内部就是Predicate接口。惰性求值。</strong></p>
<figure data-type="image" tabindex="2"><img src="https://user-gold-cdn.xitu.io/2019/5/23/16ae40638d2c0a51?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt="img" loading="lazy"></figure>
<p>比如我们筛选出出身高小于180的同学。</p>
<pre><code class="language-java">public class TestCase {
    public static void main(String[] args) {
        List&lt;Student&gt; students = new ArrayList&lt;&gt;(3);
        students.add(new Student(&quot;路飞&quot;, 22, 175));
        students.add(new Student(&quot;红发&quot;, 40, 180));
        students.add(new Student(&quot;白胡子&quot;, 50, 185));

        List&lt;Student&gt; list = students.stream()
            .filter(stu -&gt; stu.getStature() &lt; 180)
            .collect(Collectors.toList());
        System.out.println(list);
    }
}
//输出结果
//[Student{name='路飞', age=22, stature=175, specialities=null}]
</code></pre>
<h5 id="23-map">2.3 map</h5>
<p><strong>转换功能，内部就是Function接口。惰性求值</strong></p>
<figure data-type="image" tabindex="3"><img src="https://user-gold-cdn.xitu.io/2019/5/23/16ae40638d1c6610?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt="img" loading="lazy"></figure>
<pre><code class="language-java">public class TestCase {
    public static void main(String[] args) {
        List&lt;Student&gt; students = new ArrayList&lt;&gt;(3);
        students.add(new Student(&quot;路飞&quot;, 22, 175));
        students.add(new Student(&quot;红发&quot;, 40, 180));
        students.add(new Student(&quot;白胡子&quot;, 50, 185));

        List&lt;String&gt; names = students.stream().map(student -&gt; student.getName())
                .collect(Collectors.toList());
        System.out.println(names);
    }
}
//输出结果
//[路飞, 红发, 白胡子]
</code></pre>
<p>例子中将student对象转换为String对象，获取student的名字。</p>
<h5 id="24-flatmap">2.4 flatMap</h5>
<p><strong>将多个Stream合并为一个Stream。惰性求值</strong></p>
<figure data-type="image" tabindex="4"><img src="https://user-gold-cdn.xitu.io/2019/5/23/16ae40638c4cca86?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt="img" loading="lazy"></figure>
<pre><code class="language-java">public class TestCase {
    public static void main(String[] args) {
        List&lt;Student&gt; students = new ArrayList&lt;&gt;(3);
        students.add(new Student(&quot;路飞&quot;, 22, 175));
        students.add(new Student(&quot;红发&quot;, 40, 180));
        students.add(new Student(&quot;白胡子&quot;, 50, 185));

        List&lt;Student&gt; studentList = Stream.of(students,
                asList(new Student(&quot;艾斯&quot;, 25, 183),
                        new Student(&quot;雷利&quot;, 48, 176)))
                .flatMap(students1 -&gt; students1.stream()).collect(Collectors.toList());
        System.out.println(studentList);
    }
}
//输出结果
//[Student{name='路飞', age=22, stature=175, specialities=null}, 
//Student{name='红发', age=40, stature=180, specialities=null}, 
//Student{name='白胡子', age=50, stature=185, specialities=null}, 
//Student{name='艾斯', age=25, stature=183, specialities=null},
//Student{name='雷利', age=48, stature=176, specialities=null}]
</code></pre>
<p>调用Stream.of的静态方法将两个list转换为Stream，再通过flatMap将两个流合并为一个。</p>
<h5 id="25-max和min">2.5 max和min</h5>
<p>我们经常会在集合中<strong>求最大或最小值</strong>，使用流就很方便。<strong>及早求值。</strong></p>
<pre><code class="language-java">public class TestCase {
    public static void main(String[] args) {
        List&lt;Student&gt; students = new ArrayList&lt;&gt;(3);
        students.add(new Student(&quot;路飞&quot;, 22, 175));
        students.add(new Student(&quot;红发&quot;, 40, 180));
        students.add(new Student(&quot;白胡子&quot;, 50, 185));

        Optional&lt;Student&gt; max = students.stream()
            .max(Comparator.comparing(stu -&gt; stu.getAge()));
        Optional&lt;Student&gt; min = students.stream()
            .min(Comparator.comparing(stu -&gt; stu.getAge()));
        //判断是否有值
        if (max.isPresent()) {
            System.out.println(max.get());
        }
        if (min.isPresent()) {
            System.out.println(min.get());
        }
    }
}
//输出结果
//Student{name='白胡子', age=50, stature=185, specialities=null}
//Student{name='路飞', age=22, stature=175, specialities=null}
</code></pre>
<p><strong>max、min接收一个Comparator</strong>（例子中使用java8自带的静态函数，只需要传进需要比较值即可。）并且返回一个Optional对象，该对象是java8新增的类，专门为了防止null引发的空指针异常。可以使用max.isPresent()判断是否有值；可以使用max.orElse(new Student())，当值为null时就使用给定值；也可以使用max.orElseGet(() -&gt; new Student());这需要传入一个Supplier的lambda表达式。</p>
<h5 id="26-count">2.6 count</h5>
<p><strong>统计功能，一般都是结合filter使用，因为先筛选出我们需要的再统计即可。及早求值</strong></p>
<pre><code class="language-java">public class TestCase {
    public static void main(String[] args) {
        List&lt;Student&gt; students = new ArrayList&lt;&gt;(3);
        students.add(new Student(&quot;路飞&quot;, 22, 175));
        students.add(new Student(&quot;红发&quot;, 40, 180));
        students.add(new Student(&quot;白胡子&quot;, 50, 185));

        long count = students.stream().filter(s1 -&gt; s1.getAge() &lt; 45).count();
        System.out.println(&quot;年龄小于45岁的人数是：&quot; + count);
    }
}
//输出结果
//年龄小于45岁的人数是：2
</code></pre>
<h5 id="27-reduce">2.7 reduce</h5>
<p><strong>reduce 操作可以实现从一组值中生成一个值</strong>。在上述例子中用到的 count 、 min 和 max 方<br>
法，因为常用而被纳入标准库中。事实上，这些方法都是 reduce 操作。<strong>及早求值。</strong></p>
<figure data-type="image" tabindex="5"><img src="https://user-gold-cdn.xitu.io/2019/5/23/16ae40638c52397b?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt="img" loading="lazy"></figure>
<pre><code class="language-java">public class TestCase {
    public static void main(String[] args) {
        Integer reduce = Stream.of(1, 2, 3, 4).reduce(0, (acc, x) -&gt; acc+ x);
        System.out.println(reduce);
    }
}
//输出结果
//10
</code></pre>
<p>我们看得reduce接收了一个初始值为0的累加器，依次取出值与累加器相加，最后累加器的值就是最终的结果。</p>
<h3 id="三-高级集合类及收集器">三、高级集合类及收集器</h3>
<h4 id="31-转换成值">3.1 转换成值</h4>
<p>**收集器，一种通用的、从流生成复杂值的结构。**只要将它传给 collect 方法，所有<br>
的流就都可以使用它了。标准类库已经提供了一些有用的收集器，<strong>以下示例代码中的收集器都是从 java.util.stream.Collectors 类中静态导入的。</strong></p>
<pre><code class="language-java">public class CollectorsTest {
    public static void main(String[] args) {
        List&lt;Student&gt; students1 = new ArrayList&lt;&gt;(3);
        students1.add(new Student(&quot;路飞&quot;, 23, 175));
        students1.add(new Student(&quot;红发&quot;, 40, 180));
        students1.add(new Student(&quot;白胡子&quot;, 50, 185));

        OutstandingClass ostClass1 = new OutstandingClass(&quot;一班&quot;, students1);
        //复制students1，并移除一个学生
        List&lt;Student&gt; students2 = new ArrayList&lt;&gt;(students1);
        students2.remove(1);
        OutstandingClass ostClass2 = new OutstandingClass(&quot;二班&quot;, students2);
        //将ostClass1、ostClass2转换为Stream
        Stream&lt;OutstandingClass&gt; classStream = Stream.of(ostClass1, ostClass2);
        OutstandingClass outstandingClass = biggestGroup(classStream);
        System.out.println(&quot;人数最多的班级是：&quot; + outstandingClass.getName());

        System.out.println(&quot;一班平均年龄是：&quot; + averageNumberOfStudent(students1));
    }

    /**
     * 获取人数最多的班级
     */
    private static OutstandingClass biggestGroup(Stream&lt;OutstandingClass&gt; outstandingClasses) {
        return outstandingClasses.collect(
                maxBy(comparing(ostClass -&gt; ostClass.getStudents().size())))
                .orElseGet(OutstandingClass::new);
    }

    /**
     * 计算平均年龄
     */
    private static double averageNumberOfStudent(List&lt;Student&gt; students) {
        return students.stream().collect(averagingInt(Student::getAge));
    }
}
//输出结果
//人数最多的班级是：一班
//一班平均年龄是：37.666666666666664
</code></pre>
<p>maxBy或者minBy就是求最大值与最小值。</p>
<h4 id="32-转换成块">3.2 转换成块</h4>
<p><strong>常用的流操作是将其分解成两个集合，Collectors.partitioningBy帮我们实现了，接收一个Predicate函数式接口。</strong></p>
<figure data-type="image" tabindex="6"><img src="https://user-gold-cdn.xitu.io/2019/5/23/16ae4063943b9487?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt="img" loading="lazy"></figure>
<p>将示例学生分为会唱歌与不会唱歌的两个集合。</p>
<pre><code class="language-java">public class PartitioningByTest {
    public static void main(String[] args) {
        //省略List&lt;student&gt; students的初始化
        Map&lt;Boolean, List&lt;Student&gt;&gt; listMap = students.stream().collect(
            Collectors.partitioningBy(student -&gt; student.getSpecialities().
                                      contains(SpecialityEnum.SING)));
    }
}
</code></pre>
<h4 id="33-数据分组">3.3 数据分组</h4>
<p>数据分组是一种更自然的分割数据操作，与将数据分成 ture 和 false 两部分不同，<strong>可以使</strong><br>
<strong>用任意值对数据分组。Collectors.groupingBy接收一个Function做转换。</strong></p>
<figure data-type="image" tabindex="7"><img src="https://user-gold-cdn.xitu.io/2019/5/23/16ae4063f5d78c78?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt="img" loading="lazy"></figure>
<p><strong>如图，我们使用groupingBy将根据进行分组为圆形一组，三角形一组，正方形一组。</strong></p>
<p>例子：根据学生第一个特长进行分组</p>
<pre><code class="language-java">public class GroupingByTest {
    public static void main(String[] args) {
        //省略List&lt;student&gt; students的初始化
         Map&lt;SpecialityEnum, List&lt;Student&gt;&gt; listMap = 
             students.stream().collect(
             Collectors.groupingBy(student -&gt; student.getSpecialities().get(0)));
    }
}
</code></pre>
<p><strong>Collectors.groupingBy与SQL 中的 group by 操作是一样的。</strong></p>
<h4 id="34-字符串拼接">3.4 字符串拼接</h4>
<p>如果将所有学生的名字拼接起来，怎么做呢？通常只能创建一个StringBuilder，循环拼接。使用Stream，使用Collectors.joining()简单容易。</p>
<pre><code class="language-java">public class JoiningTest {
    public static void main(String[] args) {
        List&lt;Student&gt; students = new ArrayList&lt;&gt;(3);
        students.add(new Student(&quot;路飞&quot;, 22, 175));
        students.add(new Student(&quot;红发&quot;, 40, 180));
        students.add(new Student(&quot;白胡子&quot;, 50, 185));

         String names = students.stream()
             .map(Student::getName).collect(Collectors.joining(&quot;,&quot;,&quot;[&quot;,&quot;]&quot;));
        System.out.println(names);
    }
}
//输出结果
//[路飞,红发,白胡子]
</code></pre>
<p><strong>joining接收三个参数，第一个是分界符，第二个是前缀符，第三个是结束符。也可以不传入参数Collectors.joining()，这样就是直接拼接。</strong></p>
<blockquote>
<p>原文地址：https://juejin.cn/post/6844903849753329678#hjava</p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java基础之—反射]]></title>
        <id>https://tinaxiawuhao.github.io/post/NjXzyw7sR/</id>
        <link href="https://tinaxiawuhao.github.io/post/NjXzyw7sR/">
        </link>
        <updated>2021-05-06T05:43:10.000Z</updated>
        <content type="html"><![CDATA[<p>反射是框架设计的灵魂（使用的前提条件：必须先得到代表的字节码的Class，Class类用于表示.class文件（字节码））</p>
<h2 id="反射的概述">反射的概述</h2>
<blockquote>
<p>JAVA反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性；这种动态获取的信息以及动态调用对象的方法的功能称为java语言的反射机制。<br>
要想解剖一个类,必须先要获取到该类的字节码文件对象。而解剖使用的就是Class类中的方法.所以先要获取到每一个字节码文件对应的Class类型的对象.</p>
</blockquote>
<blockquote>
<p>反射就是把java类中的各种成分映射成一个个的Java对象<br>
例如：一个类有：成员变量、方法、构造方法、包等等信息，利用反射技术可以对一个类进行解剖，把个个组成部分映射成一个个对象。（其实：一个类中这些成员方法、构造方法、在加入类中都有一个类来描述）</p>
</blockquote>
<p>如图是类的正常加载过程：Class对象的由来是将class文件读入内存，并为之创建一个Class对象。</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1619675125967.png" alt="" loading="lazy"></figure>
<p>其中这个Class对象很特殊。我们先了解一下这个Class类</p>
<h3 id="查看class类在java中的api详解">查看Class类在java中的api详解</h3>
<p>Class 类的实例表示正在运行的 Java 应用程序中的类和接口。也就是jvm中有N多的实例每个类都有该Class对象。（包括基本数据类型）<br>
Class 没有公共构造方法。Class 对象是在加载类时由 Java 虚拟机以及通过调用类加载器中的defineClass 方法自动构造的。也就是这不需要我们自己去处理创建，JVM已经帮我们创建好了。</p>
<p>没有公共的构造方法，方法共有64个。<br>
<img src="https://tinaxiawuhao.github.io/post-images/1619675067633.png" alt="" loading="lazy"></p>
<h3 id="反射的使用">反射的使用</h3>
<h4 id="获取class对象的三种方式">获取Class对象的三种方式</h4>
<p>1.1 Object ——&gt; getClass();<br>
1.2 任何数据类型（包括基本数据类型）都有一个“静态”的class属性<br>
1.3 通过Class类的静态方法：forName（String  className）(常用)</p>
<p>其中1.1是因为Object类中的getClass方法、因为所有类都继承Object类。从而调用Object类来获取</p>
<pre><code class="language-java">package fanshe;
/**
 * 获取Class对象的三种方式
 * 1 Object ——&gt; getClass();
 * 2 任何数据类型（包括基本数据类型）都有一个“静态”的class属性
 * 3 通过Class类的静态方法：forName（String  className）(常用)
 *
 */
public class Fanshe {
	public static void main(String[] args) {
		//第一种方式获取Class对象  
		Student stu1 = new Student();//这一new 产生一个Student对象，一个Class对象。
		Class stuClass = stu1.getClass();//获取Class对象
		System.out.println(stuClass.getName());
		
		//第二种方式获取Class对象
		Class stuClass2 = Student.class;
		System.out.println(stuClass == stuClass2);//判断第一种方式获取的Class对象和第二种方式获取的是否是同一个
		
		//第三种方式获取Class对象
		try {
			Class stuClass3 = Class.forName(&quot;fanshe.Student&quot;);//注意此字符串必须是真实路径，就是带包名的类路径，包名.类名
			System.out.println(stuClass3 == stuClass2);//判断三种方式是否获取的是同一个Class对象
		} catch (ClassNotFoundException e) {
			e.printStackTrace();
		}
		
	}
}
</code></pre>
<p>注意：在运行期间，一个类，只有一个Class对象产生。<br>
三种方式常用第三种，第一种对象都有了还要反射干什么。第二种需要导入类的包，依赖太强，不导包就抛编译错误。一般都第三种，一个字符串可以传入也可写在配置文件中等多种方法。</p>
<h4 id="通过反射获取构造方法并使用">通过反射获取构造方法并使用：</h4>
<pre><code class="language-java">package fanshe;
 
public class Student {
	
	//---------------构造方法-------------------
	//（默认的构造方法）
	Student(String str){
		System.out.println(&quot;(默认)的构造方法 s = &quot; + str);
	}
	
	//无参构造方法
	public Student(){
		System.out.println(&quot;调用了公有、无参构造方法执行了。。。&quot;);
	}
	
	//有一个参数的构造方法
	public Student(char name){
		System.out.println(&quot;姓名：&quot; + name);
	}
	
	//有多个参数的构造方法
	public Student(String name ,int age){
		System.out.println(&quot;姓名：&quot;+name+&quot;年龄：&quot;+ age);//这的执行效率有问题，以后解决。
	}
	
	//受保护的构造方法
	protected Student(boolean n){
		System.out.println(&quot;受保护的构造方法 n = &quot; + n);
	}
	
	//私有构造方法
	private Student(int age){
		System.out.println(&quot;私有的构造方法   年龄：&quot;+ age);
	}
 
}
</code></pre>
<p>共有6个构造方法；</p>
<pre><code class="language-java">/*
 * 通过Class对象可以获取某个类中的：构造方法、成员变量、成员方法；并访问成员；
 * 
 * 1.获取构造方法：
 * 	1).批量的方法：
 * 	public Constructor[] getConstructors()：所有&quot;公有的&quot;构造方法
 *  public Constructor[] getDeclaredConstructors()：获取所有的构造方法(包括私有、受保护、默认、公有)
 *
 * 2).获取单个的方法，并调用：
 * 	public Constructor getConstructor(Class... parameterTypes):获取单个的&quot;公有的&quot;构造方法：
 * 	public Constructor getDeclaredConstructor(Class... parameterTypes):获取&quot;某个构造方法&quot;可以是私有的，或受保护、默认、公有；
 * 		
 *调用构造方法：
 * 	Constructor--&gt;newInstance(Object... initargs)
 *	 使用此 Constructor 对象表示的构造方法来创建该构造方法的声明类的新实例，并用指定的初始化参数初始化该实例。
 * 它的返回值是T类型，所以newInstance是创建了一个构造方法的声明类的新实例对象。并为之调用
 */
package fanshe;
 
import java.lang.reflect.Constructor;
 
public class Constructors {
 
	public static void main(String[] args) throws Exception {
		//1.加载Class对象
		Class clazz = Class.forName(&quot;fanshe.Student&quot;);
		
		
		//2.获取所有公有构造方法
		System.out.println(&quot;**********************所有公有构造方法*********************************&quot;);
		Constructor[] conArray = clazz.getConstructors();
		for(Constructor c : conArray){
			System.out.println(c);
		}
		
		
		System.out.println(&quot;************所有的构造方法(包括：私有、受保护、默认、公有)***************&quot;);
		conArray = clazz.getDeclaredConstructors();
		for(Constructor c : conArray){
			System.out.println(c);
		}
		
		System.out.println(&quot;*****************获取公有、无参的构造方法*******************************&quot;);
		Constructor con = clazz.getConstructor(null);
		//1&gt;、因为是无参的构造方法所以类型是一个null,不写也可以：这里需要的是一个参数的类型，切记是类型
		//2&gt;、返回的是描述这个无参构造函数的类对象。
	
		System.out.println(&quot;con = &quot; + con);
		//调用构造方法
		Object obj = con.newInstance();
	//	System.out.println(&quot;obj = &quot; + obj);
	//	Student stu = (Student)obj;
		
		System.out.println(&quot;******************获取私有构造方法，并调用*******************************&quot;);
		con = clazz.getDeclaredConstructor(char.class);
		System.out.println(con);
		//调用构造方法
		con.setAccessible(true);//暴力访问(忽略掉访问修饰符)
		obj = con.newInstance('男');
	}
	
}
</code></pre>
<p>后台输出：</p>
<pre><code class="language-java">**********************所有公有构造方法*********************************
public fanshe.Student(java.lang.String,int)
public fanshe.Student(char)
public fanshe.Student()
************所有的构造方法(包括：私有、受保护、默认、公有)***************
private fanshe.Student(int)
protected fanshe.Student(boolean)
public fanshe.Student(java.lang.String,int)
public fanshe.Student(char)
public fanshe.Student()
fanshe.Student(java.lang.String)
*****************获取公有、无参的构造方法*******************************
con = public fanshe.Student()
调用了公有、无参构造方法执行了。。。
******************获取私有构造方法，并调用*******************************
public fanshe.Student(char)
姓名：男
</code></pre>
<h4 id="获取成员变量并调用">获取成员变量并调用：</h4>
<pre><code class="language-java">package fanshe.field;
 
public class Student {
	public Student(){
		
	}
	//**********字段*************//
	public String name;
	protected int age;
	char sex;
	private String phoneNum;
	
	@Override
	public String toString() {
		return &quot;Student [name=&quot; + name + &quot;, age=&quot; + age + &quot;, sex=&quot; + sex
				+ &quot;, phoneNum=&quot; + phoneNum + &quot;]&quot;;
	}
}
</code></pre>
<p>测试类：</p>
<pre><code class="language-java">/*
 * 获取成员变量并调用：
 * 
 * 1.批量的
 * 		1).Field[] getFields():获取所有的&quot;公有字段&quot;
 * 		2).Field[] getDeclaredFields():获取所有字段，包括：私有、受保护、默认、公有；
 * 2.获取单个的：
 * 		1).public Field getField(String fieldName):获取某个&quot;公有的&quot;字段；
 * 		2).public Field getDeclaredField(String fieldName):获取某个字段(可以是私有的)
 * 
 * 	 设置字段的值：
 * 		Field --&gt; public void set(Object obj,Object value):
 * 					参数说明：
 * 					1.obj:要设置的字段所在的对象；
 * 					2.value:要为字段设置的值；
 * 
 */
package fanshe.field;
import java.lang.reflect.Field;
public class Fields {
 
		public static void main(String[] args) throws Exception {
			//1.获取Class对象
			Class stuClass = Class.forName(&quot;fanshe.field.Student&quot;);
			//2.获取字段
			System.out.println(&quot;************获取所有公有的字段********************&quot;);
			Field[] fieldArray = stuClass.getFields();
			for(Field f : fieldArray){
				System.out.println(f);
			}
			System.out.println(&quot;************获取所有的字段(包括私有、受保护、默认的)********************&quot;);
			fieldArray = stuClass.getDeclaredFields();
			for(Field f : fieldArray){
				System.out.println(f);
			}
			System.out.println(&quot;*************获取公有字段**并调用***********************************&quot;);
			Field f = stuClass.getField(&quot;name&quot;);
			System.out.println(f);
			//获取一个对象
			Object obj = stuClass.getConstructor().newInstance();//产生Student对象--》Student stu = new Student();
			//为字段设置值
			f.set(obj, &quot;刘德华&quot;);//为Student对象中的name属性赋值--》stu.name = &quot;刘德华&quot;
			//验证
			Student stu = (Student)obj;
			System.out.println(&quot;验证姓名：&quot; + stu.name);
			
			
			System.out.println(&quot;**************获取私有字段****并调用********************************&quot;);
			f = stuClass.getDeclaredField(&quot;phoneNum&quot;);
			System.out.println(f);
			f.setAccessible(true);//暴力反射，解除私有限定
			f.set(obj, &quot;18888889999&quot;);
			System.out.println(&quot;验证电话：&quot; + stu);
			
		}
	}
</code></pre>
<p>后台输出：</p>
<pre><code class="language-java">************获取所有公有的字段********************
public java.lang.String fanshe.field.Student.name
************获取所有的字段(包括私有、受保护、默认的)********************
public java.lang.String fanshe.field.Student.name
protected int fanshe.field.Student.age
char fanshe.field.Student.sex
private java.lang.String fanshe.field.Student.phoneNum
*************获取公有字段**并调用***********************************
public java.lang.String fanshe.field.Student.name
验证姓名：刘德华
**************获取私有字段****并调用********************************
private java.lang.String fanshe.field.Student.phoneNum
验证电话：Student [name=刘德华, age=0, sex=，phoneNum=18888889999]
</code></pre>
<h4 id="获取成员方法并调用">获取成员方法并调用</h4>
<pre><code class="language-java">package fanshe.method;
 
public class Student {
	//**************成员方法***************//
	public void show1(String s){
		System.out.println(&quot;调用了：公有的，String参数的show1(): s = &quot; + s);
	}
	protected void show2(){
		System.out.println(&quot;调用了：受保护的，无参的show2()&quot;);
	}
	void show3(){
		System.out.println(&quot;调用了：默认的，无参的show3()&quot;);
	}
	private String show4(int age){
		System.out.println(&quot;调用了，私有的，并且有返回值的，int参数的show4(): age = &quot; + age);
		return &quot;abcd&quot;;
	}
}
</code></pre>
<p>测试类：</p>
<pre><code class="language-java">/*
 * 获取成员方法并调用：
 * 
 * 1.批量的：
 * 		public Method[] getMethods():获取所有&quot;公有方法&quot;；（包含了父类的方法也包含Object类）
 * 		public Method[] getDeclaredMethods():获取所有的成员方法，包括私有的(不包括继承的)
 * 2.获取单个的：
 * 		public Method getMethod(String name,Class&lt;?&gt;... parameterTypes):
 * 					参数：
 * 						name : 方法名；
 * 						Class ... : 形参的Class类型对象
 * 		public Method getDeclaredMethod(String name,Class&lt;?&gt;... parameterTypes)
 * 
 * 	 调用方法：
 * 		Method --&gt; public Object invoke(Object obj,Object... args):
 * 					参数说明：
 * 					obj : 要调用方法的对象；
 * 					args:调用方式时所传递的实参；
):
 */
package fanshe.method;
 
import java.lang.reflect.Method;
 
public class MethodClass {
 
	public static void main(String[] args) throws Exception {
		//1.获取Class对象
		Class stuClass = Class.forName(&quot;fanshe.method.Student&quot;);
		//2.获取所有公有方法
		System.out.println(&quot;***************获取所有的”公有“方法*******************&quot;);
		stuClass.getMethods();
		Method[] methodArray = stuClass.getMethods();
		for(Method m : methodArray){
			System.out.println(m);
		}
		System.out.println(&quot;***************获取所有的方法，包括私有的*******************&quot;);
		methodArray = stuClass.getDeclaredMethods();
		for(Method m : methodArray){
			System.out.println(m);
		}
		System.out.println(&quot;***************获取公有的show1()方法*******************&quot;);
		Method m = stuClass.getMethod(&quot;show1&quot;, String.class);
		System.out.println(m);
		//实例化一个Student对象
		Object obj = stuClass.getConstructor().newInstance();
		m.invoke(obj, &quot;刘德华&quot;);
		
		System.out.println(&quot;***************获取私有的show4()方法******************&quot;);
		m = stuClass.getDeclaredMethod(&quot;show4&quot;, int.class);
		System.out.println(m);
		m.setAccessible(true);//解除私有限定
		Object result = m.invoke(obj, 20);//需要两个参数，一个是要调用的对象（获取有反射），一个是实参
		System.out.println(&quot;返回值：&quot; + result);
		
		
	}
}
</code></pre>
<p>控制台输出：</p>
<pre><code class="language-java">***************获取所有的”公有“方法*******************
public void fanshe.method.Student.show1(java.lang.String)
public final void java.lang.Object.wait(long,int) throws java.lang.InterruptedException
public final native void java.lang.Object.wait(long) throws java.lang.InterruptedException
public final void java.lang.Object.wait() throws java.lang.InterruptedException
public boolean java.lang.Object.equals(java.lang.Object)
public java.lang.String java.lang.Object.toString()
public native int java.lang.Object.hashCode()
public final native java.lang.Class java.lang.Object.getClass()
public final native void java.lang.Object.notify()
public final native void java.lang.Object.notifyAll()
***************获取所有的方法，包括私有的*******************
public void fanshe.method.Student.show1(java.lang.String)
private java.lang.String fanshe.method.Student.show4(int)
protected void fanshe.method.Student.show2()
void fanshe.method.Student.show3()
***************获取公有的show1()方法*******************
public void fanshe.method.Student.show1(java.lang.String)
调用了：公有的，String参数的show1(): s = 刘德华
***************获取私有的show4()方法******************
private java.lang.String fanshe.method.Student.show4(int)
调用了，私有的，并且有返回值的，int参数的show4(): age = 20
返回值：abcd
</code></pre>
<h4 id="反射main方法">反射main方法</h4>
<pre><code class="language-java">package fanshe.main;
 
public class Student {
 
	public static void main(String[] args) {
		System.out.println(&quot;main方法执行了。。。&quot;);
	}
}
</code></pre>
<p>测试类：</p>
<pre><code class="language-java">package fanshe.main;
 
import java.lang.reflect.Method;
 
/**
 * 获取Student类的main方法、不要与当前的main方法搞混了
 */
public class Main {
	
	public static void main(String[] args) {
		try {
			//1、获取Student对象的字节码
			Class clazz = Class.forName(&quot;fanshe.main.Student&quot;);
			
			//2、获取main方法
			 Method methodMain = clazz.getMethod(&quot;main&quot;, String[].class);//第一个参数：方法名称，第二个参数：方法形参的类型，
			//3、调用main方法
			// methodMain.invoke(null, new String[]{&quot;a&quot;,&quot;b&quot;,&quot;c&quot;});
			 //第一个参数，对象类型，因为方法是static静态的，所以为null可以，第二个参数是String数组，这里要注意在jdk1.4时是数组，jdk1.5之后是可变参数
			 //这里拆的时候将  new String[]{&quot;a&quot;,&quot;b&quot;,&quot;c&quot;} 拆成3个对象。。。所以需要将它强转。
			 methodMain.invoke(null, (Object)new String[]{&quot;a&quot;,&quot;b&quot;,&quot;c&quot;});//方式一
			// methodMain.invoke(null, new Object[]{new String[]{&quot;a&quot;,&quot;b&quot;,&quot;c&quot;}});//方式二
			
		} catch (Exception e) {
			e.printStackTrace();
		}
		
		
	}
}
</code></pre>
<p>控制台输出：</p>
<pre><code class="language-java">main方法执行了。。。
</code></pre>
<h4 id="反射方法的其它使用之-通过反射运行配置文件内容">反射方法的其它使用之---通过反射运行配置文件内容</h4>
<pre><code class="language-java">public class Student {
	public void show(){
		System.out.println(&quot;is show()&quot;);
	}
}
</code></pre>
<p>配置文件以txt文件为例子（pro.txt）：</p>
<pre><code class="language-java">className = cn.fanshe.Student
methodName = show
</code></pre>
<p>测试类：</p>
<pre><code class="language-java">import java.io.FileNotFoundException;
import java.io.FileReader;
import java.io.IOException;
import java.lang.reflect.Method;
import java.util.Properties;
 
/*
 * 我们利用反射和配置文件，可以使：应用程序更新时，对源码无需进行任何修改
 * 我们只需要将新类发送给客户端，并修改配置文件即可
 */
public class Demo {
	public static void main(String[] args) throws Exception {
		//通过反射获取Class对象
		Class stuClass = Class.forName(getValue(&quot;className&quot;));//&quot;cn.fanshe.Student&quot;
		//2获取show()方法
		Method m = stuClass.getMethod(getValue(&quot;methodName&quot;));//show
		//3.调用show()方法
		m.invoke(stuClass.getConstructor().newInstance());
		
	}
	
	//此方法接收一个key，在配置文件中获取相应的value
	public static String getValue(String key) throws IOException{
		Properties pro = new Properties();//获取配置文件的对象
		FileReader in = new FileReader(&quot;pro.txt&quot;);//获取输入流
		pro.load(in);//将流加载到配置文件对象中
		in.close();
		return pro.getProperty(key);//返回根据key获取的value值
	}
}
</code></pre>
<p>控制台输出：</p>
<pre><code class="language-java">is show()
</code></pre>
<h5 id="需求">需求：</h5>
<p>当我们升级这个系统时，不要Student类，而需要新写一个Student2的类时，这时只需要更改pro.txt的文件内容就可以了。代码就一点不用改动</p>
<p>要替换的student2类：</p>
<pre><code class="language-java">public class Student2 {
	public void show2(){
		System.out.println(&quot;is show2()&quot;);
	}
}
</code></pre>
<p>配置文件更改为：</p>
<pre><code class="language-java">className = cn.fanshe.Student2
methodName = show2
</code></pre>
<p>控制台输出：</p>
<pre><code class="language-java">is show2();
</code></pre>
<h4 id="反射方法的其它使用之-通过反射越过泛型检查">反射方法的其它使用之---通过反射越过泛型检查</h4>
<p>泛型用在编译期，编译过后泛型擦除（消失掉）。所以是可以通过反射越过泛型检查的</p>
<pre><code class="language-java">import java.lang.reflect.Method;
import java.util.ArrayList;
 
/*
 * 通过反射越过泛型检查
 * 
 * 例如：有一个String泛型的集合，怎样能向这个集合中添加一个Integer类型的值？
 */
public class Demo {
	public static void main(String[] args) throws Exception{
		ArrayList&lt;String&gt; strList = new ArrayList&lt;&gt;();
		strList.add(&quot;aaa&quot;);
		strList.add(&quot;bbb&quot;);
		
	//	strList.add(100);
		//获取ArrayList的Class对象，反向的调用add()方法，添加数据
		Class listClass = strList.getClass(); //得到 strList 对象的字节码 对象
		//获取add()方法
		Method m = listClass.getMethod(&quot;add&quot;, Object.class);
		//调用add()方法
		m.invoke(listClass , 100);
		
		//遍历集合
		for(Object obj : strList){
			System.out.println(obj);
		}
	}
}
</code></pre>
<p>控制台输出：</p>
<pre><code class="language-java">aaa
bbb
100
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[java基础之一集合]]></title>
        <id>https://tinaxiawuhao.github.io/post/FRRzAbqMV/</id>
        <link href="https://tinaxiawuhao.github.io/post/FRRzAbqMV/">
        </link>
        <updated>2021-05-05T06:41:04.000Z</updated>
        <content type="html"><![CDATA[<h2 id="基础数据结构说明">基础数据结构说明</h2>
<p>​		<strong>数组</strong>：采用一段连续的存储单元来存储数据。对于指定下标的查找，时间复杂度为O(1)；通过给定值进行查找，需要遍历数组，逐一比对给定关键字和数组元素，时间复杂度为O(n)，当然，对于有序数组，则可采用二分查找，插值查找，斐波那契查找等方式，可将查找复杂度提高为O(logn)；对于一般的插入删除操作，涉及到数组元素的移动，其平均复杂度也为O(n)</p>
<p><strong>线性链表</strong>：对于链表的新增，删除等操作（在找到指定操作位置后），仅需处理结点间的引用即可，时间复杂度为O(1)，而查找操作需要遍历链表逐一进行比对，复杂度为O(n)</p>
<p><strong>二叉树</strong>：对一棵相对平衡的有序二叉树，对其进行插入，查找，删除等操作，平均复杂度均为O(logn)。</p>
<p><strong>哈希表</strong>：相比上述几种数据结构，在哈希表中进行添加，删除，查找等操作，性能十分之高，不考虑哈希冲突的情况下，仅需一次定位即可完成，时间复杂度为O(1)，接下来我们就来看看哈希表是如何实现达到惊艳的常数阶O(1)的。</p>
<h3 id="哈希表具体说明">哈希表具体说明</h3>
<p>我们知道，数据结构的物理存储结构只有两种：<strong>顺序存储结构</strong>和<strong>链式存储结构</strong>（像栈，队列，树，图等是从逻辑结构去抽象的，映射到内存中，也是这两种物理组织形式），而在上面我们提到过，在数组中根据下标查找某个元素，一次定位就可以达到，哈希表利用了这种特性，<strong>哈希表的主干就是数组</strong>。</p>
<p>比如我们要新增或查找某个元素，我们通过把当前元素的关键字 通过某个函数映射到数组中的某个位置，通过数组下标一次定位就可完成操作。</p>
<p><strong>存储位置 = f(关键字)</strong></p>
<p>其中，这个函数f一般称为<strong>哈希函数</strong>，这个函数的设计好坏会直接影响到哈希表的优劣。举个例子，比如我们要在哈希表中执行插入操作：</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1619592366553.png" alt="" loading="lazy"></figure>
<p>查找操作同理，先通过哈希函数计算出实际存储地址，然后从数组中对应地址取出即可。</p>
<p><strong>哈希冲突</strong></p>
<p>然而万事无完美，如果两个不同的元素，通过哈希函数得出的实际存储地址相同怎么办？也就是说，当我们对某个元素进行哈希运算，得到一个存储地址，然后要进行插入的时候，发现已经被其他元素占用了，其实这就是所谓的<strong>哈希冲突</strong>，也叫哈希碰撞。前面我们提到过，哈希函数的设计至关重要，好的哈希函数会尽可能地保证 <strong>计算简单</strong>和<strong>散列地址分布均匀</strong>但是，我们需要清楚的是，数组是一块连续的固定长度的内存空间，再好的哈希函数也不能保证得到的存储地址绝对不发生冲突。那么哈希冲突如何解决呢？哈希冲突的解决方案有多种:<code>开放定址法（线性探测）</code>（发生冲突，继续寻找下一块未被占用的存储地址），<code>再散列函数法</code>，<code>链地址法</code>。</p>
<h3 id="r-b-tree简介">R-B Tree简介</h3>
<p>R-B Tree，全称是Red-Black Tree，又称为“红黑树”，它一种特殊的二叉查找树。红黑树的每个节点上都有存储位表示节点的颜色，可以是红(Red)或黑(Black)。</p>
<p><strong>红黑树的特性</strong>:<br>
<strong>（1）每个节点或者是黑色，或者是红色。</strong><br>
<strong>（2）根节点是黑色。</strong><br>
<strong>（3）每个叶子节点（NIL）是黑色。 [注意：这里叶子节点，是指为空(NIL或NULL)的叶子节点！]</strong><br>
<strong>（4）如果一个节点是红色的，则它的子节点必须是黑色的。</strong><br>
<strong>（5）从一个节点到该节点的子孙节点的所有路径上包含相同数目的黑节点。</strong></p>
<p><strong>注意</strong>：<br>
(01) 特性(3)中的叶子节点，是只为空(NIL或null)的节点。<br>
(02) 特性(5)，确保没有一条路径会比其他路径长出俩倍。因而，红黑树是相对是接近平衡的二叉树。</p>
<p>红黑树示意图如下：</p>
<figure data-type="image" tabindex="2"><a href="https://images0.cnblogs.com/i/497634/201403/251730074203156.jpg"><img src="https://images0.cnblogs.com/i/497634/201403/251730074203156.jpg" alt="img" loading="lazy"></a></figure>
<p><strong>性质</strong><br>
红黑树是每个节点都带有颜色属性的二叉查找树，颜色或红色或黑色。在二叉查找树强制一般要求以外，对于任何有效的红黑树我们增加了如下的额外要求：<br>
【1】性质1. 节点是红色或黑色。<br>
【2】性质2. 根节点是黑色。<br>
【3】性质3 每个叶节点是黑色的。<br>
【4】性质4 每个红色节点的两个子节点都是黑色。(从每个叶子到根的所有路径上不能有两个连续的红色节点)<br>
【5】性质5. 从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点。</p>
<p><strong>用途和好处</strong><br>
红黑树和AVL树一样都对插入时间、删除时间和查找时间提供了最好可能的最坏情况担保。这不只是使它们在时间敏感的应用如即时应用(real time application)中有价值，而且使它们有在提供最坏情况担保的其他数据结构中作为建造板块的价值；例如，在计算几何中使用的很多数据结构都可以基于红黑树。</p>
<p>​	红黑树在函数式编程中也特别有用，在这里它们是最常用的持久数据结构之一，它们用来构造关联数组和集合，在突变之后它们能保持为以前的版本。除了O(log n)的时间之外，红黑树的持久版本对每次插入或删除需要O(log n)的空间。</p>
<p>​	红黑树是 2-3-4树的一种等同。换句话说，对于每个 2-3-4 树，都存在至少一个数据元素是同样次序的红黑树。在 2-3-4 树上的插入和删除操作也等同于在红黑树中颜色翻转和旋转。这使得 2-3-4 树成为理解红黑树背后的逻辑的重要工具，这也是很多介绍算法的教科书在红黑树之前介绍 2-3-4 树的原因，尽管 2-3-4 树在实践中不经常使用。</p>
<p><strong>红黑树的数据结构</strong></p>
<pre><code class="language-java">public class RBTree&lt;T extends Comparable&lt;T&gt;&gt; {

    private RBTNode&lt;T&gt; mRoot;    // 根结点

    private static final boolean RED   = false;
    private static final boolean BLACK = true;

    public class RBTNode&lt;T extends Comparable&lt;T&gt;&gt; {
        boolean color;        // 颜色
        T key;                // 关键字(键值)
        RBTNode&lt;T&gt; left;    // 左孩子
        RBTNode&lt;T&gt; right;    // 右孩子
        RBTNode&lt;T&gt; parent;    // 父结点

        public RBTNode(T key, boolean color, RBTNode&lt;T&gt; parent, RBTNode&lt;T&gt; left, RBTNode&lt;T&gt; right) {
            this.key = key;
            this.color = color;
            this.parent = parent;
            this.left = left;
            this.right = right;
        }

    }

    ...
}

</code></pre>
<h2 id="集合说明">集合说明</h2>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1619592387947.png" alt="" loading="lazy"></figure>
<h3 id="arraylist实现原理要点概括">ArrayList实现原理要点概括</h3>
<ol>
<li>
<p>ArrayList是List接口的可变数组非同步实现，并允许包括null在内的所有元素。</p>
</li>
<li>
<p>ArrayList的数据结构如下：</p>
<p></p>
</li>
</ol>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1619592476277.png" alt="" loading="lazy"></figure>
<p>说明：底层的数据结构就是数组，数组元素类型为Object类型，即可以存放所有类型数据。我们对ArrayList类的实例的所有的操作底层都是基于数组的。</p>
<ol start="3">
<li>
<p>该集合是可变长度数组，数组扩容时，会将老数组中的元素重新拷贝一份到新的数组中，每次数组容量增长大约是其容量的1.5倍，这种操作的代价很高。</p>
<pre><code class="language-java">newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1)
</code></pre>
</li>
<li>
<p>采用了Fail-Fast机制，面对并发的修改时，迭代器很快就会完全失败，而不是冒着在将来某个不确定时间发生任意不确定行为的风险</p>
</li>
<li>
<p>remove方法会让下标到数组末尾的元素向前移动一个单位，并把最后一位的值置空，方便GC</p>
</li>
</ol>
<h3 id="linkedlist实现原理要点概括">LinkedList实现原理要点概括</h3>
<ol>
<li>
<p>LinkedList是List接口的双向链表非同步实现，并允许包括null在内的所有元素。从JDK1.7开始，LinkedList 由双向循环链表改为双向链表</p>
</li>
<li>
<p>LinkedList数据结构如下</p>
</li>
</ol>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1619592485724.png" alt="" loading="lazy"></figure>
<p>说明：如上图所示，LinkedList底层使用的双向链表结构，有一个头结点和一个尾结点，双向链表意味着我们可以从头开始正向遍历，或者是从尾开始逆向遍历，并且可以针对头部和尾部进行相应的操作。</p>
<ol start="3">
<li>
<p>双向链表节点对应的类Node的实例，Node中包含成员变量：prev，next，item。其中，prev是该节点的上一个节点，next是该节点的下一个节点，item是该节点所包含的值。</p>
<pre><code class="language-java">public class LinkedList&lt;E&gt;
    extends AbstractSequentialList&lt;E&gt;
    implements List&lt;E&gt;, Deque&lt;E&gt;, Cloneable, java.io.Serializable
{
    transient int size = 0;

    /**
     * Pointer to first node.
     * Invariant: (first == null &amp;&amp; last == null) ||
     *            (first.prev == null &amp;&amp; first.item != null)
     */
    transient Node&lt;E&gt; first;

    /**
     * Pointer to last node.
     * Invariant: (first == null &amp;&amp; last == null) ||
     *            (last.next == null &amp;&amp; last.item != null)
     */
    transient Node&lt;E&gt; last;
    
     /**
     *  节点结构
     */
    private static class Node&lt;E&gt; {
        E item;
        Node&lt;E&gt; next;
        Node&lt;E&gt; prev;

        Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) {
            this.item = element;
            this.next = next;
            this.prev = prev;
        }
    }

}

</code></pre>
<p>说明：LinkedList的属性非常简单，一个头结点、一个尾结点、一个表示链表中实际元素个数的变量。注意，头结点、尾结点都有transient关键字修饰，这也意味着在序列化时该域是不会序列化的。</p>
</li>
<li>
<p>它的查找是分两半查找，先判断index是在链表的哪一半，然后再去对应区域查找，这样最多只要遍历链表的一半节点即可找到</p>
</li>
</ol>
<h3 id="hashmap实现原理要点概括">HashMap实现原理要点概括</h3>
<ol>
<li>
<p>HashMap是基于哈希表的Map接口的非同步实现，允许使用null值和null键，但不保证映射的顺序。</p>
</li>
<li>
<p>底层使用数组实现，数组中每一项是个单向链表，即数组和链表的结合体；当链表长度大于8时，链表转换为红黑树，这样减少链表查询时间。</p>
</li>
</ol>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1619592496628.png" alt="" loading="lazy"></figure>
<ol start="3">
<li>
<p>HashMap在底层将key-value当成一个整体进行处理，这个整体就是一个Node对象。HashMap底层采用一个Node[]数组来保存所有的key-value对，当需要存储一个Node对象时，会根据key的hash算法来决定其在数组中的存储位置，再根据equals方法决定其在该数组位置上的链表中的存储位置；当需要取出一个Node时，也会根据key的hash算法找到其在数组中的存储位置，再根据equals方法从该位置上的链表中取出该Node。</p>
</li>
<li>
<p>HashMap解决hash冲突是采用了<code>链地址</code>法，也就是<strong>数组+链表</strong>的方式，</p>
</li>
<li>
<p>HashMap进行数组扩容需要重新计算扩容后每个元素在数组中的位置，很耗性能</p>
</li>
<li>
<p>采用了Fail-Fast机制，通过一个modCount值记录修改次数，对HashMap内容的修改都将增加这个值。迭代器初始化过程中会将这个值赋给迭代器的expectedModCount，在迭代过程中，判断modCount跟expectedModCount是否相等，如果不相等就表示已经有其他线程修改了Map，马上抛出异常</p>
</li>
</ol>
<h4 id="重写equals方法需同时重写hashcode方法">重写equals方法需同时重写hashCode方法</h4>
<pre><code class="language-java">public static void main(String []args){
    HashMap&lt;Person,String&gt; map = new HashMap&lt;Person, String&gt;();
    Person person = new Person(1234,&quot;乔峰&quot;);
    //put到hashmap中去
    map.put(person,&quot;天龙八部&quot;);
    //get取出，从逻辑上讲应该能输出“天龙八部”
    System.out.println(&quot;结果:&quot;+map.get(new Person(1234,&quot;乔峰&quot;)));
}
</code></pre>
<p>​		如果我们已经对HashMap的原理有了一定了解，这个结果就不难理解了。尽管我们在进行get和put操作的时候，使用的key从逻辑上讲是等值的（通过equals比较是相等的），但由于没有重写hashCode方法，所以put操作时，key(hashcode1)--&gt;hash--&gt;indexFor--&gt;最终索引位置 ，而通过key取出value的时候 key(hashcode2)--&gt;hash--&gt;indexFor--&gt;最终索引位置，由于hashcode1不等于hashcode2，导致没有定位到一个数组位置而返回逻辑上错误的值null（也有可能碰巧定位到一个数组位置，但是也会判断其entry的hash值是否相等。）</p>
<p>所以，在重写equals的方法的时候，必须注意重写hashCode方法，同时还要保证通过equals判断相等的两个对象，调用hashCode方法要返回同样的整数值。而如果equals判断不相等的两个对象，其hashCode可以相同（只不过会发生哈希冲突，应尽量避免）。</p>
<h3 id="hashtable实现原理要点概括">Hashtable实现原理要点概括</h3>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1619592758082.jfif" alt="" loading="lazy"></figure>
<ol>
<li>Hashtable是基于哈希表的Map接口的同步实现，不允许使用null值和null键，Hashtable中的映射不是有序的</li>
<li>底层使用数组实现，数组中每一项是个单链表，即数组和链表的结合体</li>
<li>Hashtable在底层将key-value当成一个整体进行处理，这个整体就是一个Entry对象。Hashtable底层采用一个Entry[]数组来保存所有的key-value对，当需要存储一个Entry对象时，会根据key的hash算法来决定其在数组中的存储位置，在根据equals方法决定其在该数组位置上的链表中的存储位置；当需要取出一个Entry时，也会根据key的hash算法找到其在数组中的存储位置，再根据equals方法从该位置上的链表中取出该Entry。</li>
<li>synchronized是针对整张Hash表的，即每次锁住整张表让线程独占</li>
</ol>
<h3 id="concurrenthashmap实现原理要点概括">ConcurrentHashMap实现原理要点概括</h3>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1619592765108.jpeg" alt="" loading="lazy"></figure>
<ol>
<li>
<p>ConcurrentHashMap允许多个修改操作并发进行，其关键在于使用了锁分离技术。</p>
</li>
<li>
<p>它使用了多个锁来控制对hash表的不同段进行的修改，每个段其实就是一个小的hashtable，它们有自己的锁。只要多个并发发生在不同的段上，它们就可以并发进行。</p>
</li>
<li>
<p>ConcurrentHashMap在底层将key-value当成一个整体进行处理，这个整体就是一个Entry对象。Hashtable底层采用一个Entry[]数组来保存所有的key-value对，当需要存储一个Entry对象时，会根据key的hash算法来决定其在数组中的存储位置，在根据equals方法决定其在该数组位置上的链表中的存储位置；当需要取出一个Entry时，也会根据key的hash算法找到其在数组中的存储位置，再根据equals方法从该位置上的链表中取出该Entry。</p>
</li>
<li>
<p>与HashMap不同的是，ConcurrentHashMap使用多个子Hash表，也就是段(Segment)</p>
</li>
<li>
<p>ConcurrentHashMap完全允许多个读操作并发进行，读操作并不需要加锁。如果使用传统的技术，如HashMap中的实现，如果允许可以在hash链的中间添加或删除元素，读操作不加锁将得到不一致的数据。</p>
</li>
</ol>
<p><strong>ConcurrentHashMap 1.8为什么要使用CAS+Synchronized取代Segment+ReentrantLock</strong></p>
<p>​	大家应该都知道ConcurrentHashMap在1.8的时候有了很大的改动,当然,我这里要说的改动不是指链表长度大于8就转为红黑树这种常识,我要说的是ConcurrentHashMap在1.8为什么用CAS+Synchronized取代Segment+ReentrantLock了</p>
<p>​	首先,我假设你对CAS,Synchronized,ReentrantLock这些知识很了解,并且知道AQS,自旋锁,偏向锁,轻量级锁,重量级锁这些知识,也知道Synchronized和ReentrantLock在唤醒被挂起线程竞争的时候有什么区别</p>
<p>​	首先我们说下1.8以前的ConcurrentHashMap是怎么保证线程并发的,首先在初始化ConcurrentHashMap的时候,会初始化一个Segment数组,容量为16,而每个Segment呢,都继承了ReentrantLock类,也就是说每个Segment类本身就是一个锁,之后Segment内部又有一个table数组,而每个table数组里的索引数据呢,又对应着一个Node链表.</p>
<p>​	那么这样的好处是什么呢?我先从老版本的添加流程说起吧,由于电脑里没有JDK1.7及以下的版本我没法给你看代码,所以使用文字描述的方式,首先,当我们使用put方法的时候,是对我们的key进行hash拿到一个整型,然后将整型对16取模,拿到对应的Segment,之后调用Segment的put方法,然后上锁,请注意,这里lock()的时候其实是this.lock(),也就是说,每个Segment的锁是分开的</p>
<p>​	其中一个上锁不会影响另一个,此时也就代表了我可以有十六个线程进来,而ReentrantLock上锁的时候如果只有一个线程进来,是不会有线程挂起的操作的,也就是说只需要在AQS里使用CAS改变一个state的值为1,此时就能对代码进行操作,这样一来,我们等于将并发量/16了.</p>
<p>好,说完了老版本的ConcurrentHashMap,我们再说说新版本的,请看下面的图:</p>
<figure data-type="image" tabindex="9"><img src="https://tinaxiawuhao.github.io/post-images/1629875978754.png" alt="" loading="lazy"></figure>
<p>​	请注意Synchronized上锁的对象,请记住,Synchronized是靠对象的对象头和此对象对应的monitor来保证上锁的,也就是对象头里的重量级锁标志指向了monitor,而monitor呢,内部则保存了一个当前线程,也就是抢到了锁的线程.</p>
<p>​	那么这里的这个f是什么呢?它是Node链表里的每一个Node,也就是说,Synchronized是将每一个Node对象作为了一个锁,这样做的好处是什么呢?将锁细化了,也就是说,除非两个线程同时操作一个Node,注意,是一个Node而不是一个Node链表哦,那么才会争抢同一把锁.</p>
<p>​	如果使用ReentrantLock其实也可以将锁细化成这样的,只要让Node类继承ReentrantLock就行了,这样的话调用f.lock()就能做到和Synchronized(f)同样的效果,但为什么不这样做呢?</p>
<p>​	请大家试想一下,锁已经被细化到这种程度了,那么出现并发争抢的可能性还高吗?还有就是,哪怕出现争抢了,只要线程可以在30到50次自旋里拿到锁,那么Synchronized就不会升级为重量级锁,而等待的线程也就不用被挂起,我们也就少了挂起和唤醒这个上下文切换的过程开销.</p>
<p>​	但如果是ReentrantLock呢?它则只有在线程没有抢到锁,然后新建Node节点后再尝试一次而已,不会自旋,而是直接被挂起,这样一来,我们就很容易会多出线程上下文开销的代价.当然,你也可以使用tryLock(),但是这样又出现了一个问题,你怎么知道tryLock的时间呢?在时间范围里还好,假如超过了呢?</p>
<p>​	所以,在锁被细化到如此程度上,使用Synchronized是最好的选择了.这里再补充一句,Synchronized和ReentrantLock他们的开销差距是在释放锁时唤醒线程的数量,Synchronized是唤醒锁池里所有的线程+刚好来访问的线程,而ReentrantLock则是当前线程后进来的第一个线程+刚好来访问的线程.</p>
<p>​	如果是线程并发量不大的情况下,那么Synchronized因为自旋锁,偏向锁,轻量级锁的原因,不用将等待线程挂起,偏向锁甚至不用自旋,所以在这种情况下要比ReentrantLock高效</p>
<p><strong>1.8弃用分段锁的原因由以下几点：</strong><br>
1. 加入多个分段锁浪费内存空间。<br>
2. 生产环境中， map 在放入时竞争同一个锁的概率非常小，分段锁反而会造成更新等操作的长时间等待。<br>
3. 为了提高 GC 的效率</p>
<h3 id="hashset实现原理要点概括">HashSet实现原理要点概括</h3>
<ol>
<li>HashSet由哈希表(实际上是一个HashMap实例)支持，不保证set的迭代顺序，并允许使用null元素。</li>
<li>对于HashSet而言，它是基于HashMap实现的，HashSet底层使用HashMap来保存所有元素，因此HashSet 的实现比较简单，相关HashSet的操作，基本上都是直接调用底层HashMap的相关方法来完成，API也是对HashMap的行为进行了封装，可参考HashMap</li>
</ol>
<h3 id="linkedhashmap实现原理要点概括">LinkedHashMap实现原理要点概括</h3>
<figure data-type="image" tabindex="10"><img src="https://tinaxiawuhao.github.io/post-images/1619593405140.png" alt="" loading="lazy"></figure>
<ol>
<li>LinkedHashMap继承于HashMap，底层使用哈希表和双向链表来保存所有元素，并且它是非同步，允许使用null值和null键。</li>
<li>基本操作与父类HashMap相似，通过重写HashMap相关方法，重新定义了数组中保存的元素Entry，来实现自己的链接列表特性。该Entry除了保存当前对象的引用外，还保存了其上一个元素before和下一个元素after的引用，从而构成了双向链接列表。</li>
</ol>
<h3 id="linkedhashset实现原理要点概括">LinkedHashSet实现原理要点概括</h3>
<ol>
<li>对于LinkedHashSet而言，它继承与HashSet、又基于LinkedHashMap来实现的。LinkedHashSet底层使用LinkedHashMap来保存所有元素，它继承与HashSet，其所有的方法操作上又与HashSet相同。</li>
</ol>
<h2 id="java集合遍历的几种方式总结及比较">java集合遍历的几种方式总结及比较</h2>
<h3 id="集合类的通用遍历方式-用迭代器迭代">集合类的通用遍历方式, 用迭代器迭代:</h3>
<pre><code class="language-java">Iterator it = list.iterator();

while(it.hasNext()) {

　　Object obj = it.next();

}
</code></pre>
<h3 id="map遍历方式">Map遍历方式：</h3>
<p><strong>1、通过获取所有的key按照key来遍历</strong></p>
<pre><code class="language-java">//Set&lt;Integer&gt; set = map.keySet(); //得到所有key的集合
for (Integer in : map.keySet()) {
    String str = map.get(in);//得到每个key多对用value的值
}
</code></pre>
<p><strong>2、通过Map.entrySet使用iterator遍历key和value</strong></p>
<pre><code class="language-java">Iterator&lt;Map.Entry&lt;Integer, String&gt;&gt; it = map.entrySet().iterator();
while (it.hasNext()) {
     Map.Entry&lt;Integer, String&gt; entry = it.next();
       System.out.println(&quot;key= &quot; + entry.getKey() + &quot; and value= &quot; + entry.getValue());
}
</code></pre>
<p><strong>3、通过Map.entrySet遍历key和value，推荐，尤其是容量大时</strong></p>
<pre><code class="language-java">for (Map.Entry&lt;Integer, String&gt; entry : map.entrySet()) {
    //Map.entry&lt;Integer,String&gt; 映射项（键-值对）  有几个方法：用上面的名字entry
    //entry.getKey() ;entry.getValue(); entry.setValue();
    //map.entrySet()  返回此映射中包含的映射关系的 Set视图。
    System.out.println(&quot;key= &quot; + entry.getKey() + &quot; and value= &quot; + entry.getValue());
}
</code></pre>
<p>4、通过Map.values()遍历所有的value，但不能遍历key</p>
<pre><code class="language-java">for (String v : map.values()) {
    System.out.println(&quot;value= &quot; + v);
}
</code></pre>
<h3 id="list遍历方式">List遍历方式：</h3>
<p><strong>第一种：</strong></p>
<pre><code class="language-java">Iterator iterator = list.iterator();
while(iterator.hasNext()){
    int i = (Integer) iterator.next();
    System.out.println(i);
}
</code></pre>
<p><strong>第二种：</strong></p>
<pre><code class="language-java">for (Object object : list) { 
    System.out.println(object); 
}
</code></pre>
<p><strong>第三种：</strong></p>
<pre><code class="language-java">for(int i = 0 ;i&lt;list.size();i++) {  
    int j= (Integer) list.get(i);
    System.out.println(j);  
}
</code></pre>
<h3 id="每个遍历方法的实现原理是什么">每个遍历方法的实现原理是什么？</h3>
<ol>
<li>传统的for循环遍历，基于计数器的：</li>
</ol>
<p>​    遍历者自己在集合外部维护一个计数器，然后依次读取每一个位置的元素，当读取到最后一个元素后，停止。主要就是需要按元素的位置来读取元素。</p>
<ol start="2">
<li>迭代器遍历，Iterator：</li>
</ol>
<p>​    每一个具体实现的数据集合，一般都需要提供相应的Iterator。相比于传统for循环，Iterator取缔了显式的遍历计数器。所以基于顺序存储集合的Iterator可以直接按位置访问数据。而基于链式存储集合的Iterator，正常的实现，都是需要保存当前遍历的位置。然后根据当前位置来向前或者向后移动指针。</p>
<ol start="3">
<li>foreach循环遍历：</li>
</ol>
<p>​    根据反编译的字节码可以发现，foreach内部也是采用了Iterator的方式实现，只不过Java编译器帮我们生成了这些代码。</p>
<h3 id="各遍历方式对于不同的存储方式性能如何">各遍历方式对于不同的存储方式，性能如何？</h3>
<p><strong>1、传统的for循环遍历，基于计数器的：</strong></p>
<p>​    因为是基于元素的位置，按位置读取。所以我们可以知道，对于顺序存储，因为读取特定位置元素的平均时间复杂度是O(1)，所以遍历整个集合的平均时间复杂度为O(n)。而对于链式存储，因为读取特定位置元素的平均时间复杂度是O(n)，所以遍历整个集合的平均时间复杂度为O(n2)（n的平方）。</p>
<p>ArrayList按位置读取的代码：直接按元素位置读取。</p>
<pre><code class="language-java">transient Object[] elementData;

public E get(int index) {
    rangeCheck(index);
    return elementData(index);
}

E elementData(int index) {
    return (E) elementData[index];
}
</code></pre>
<p>LinkedList按位置读取的代码：每次都需要从第0个元素开始向后读取。其实它内部也做了小小的优化。</p>
<pre><code class="language-java">transient int size = 0;
transient Node&lt;E&gt; first;
transient Node&lt;E&gt; last;

public E get(int index) {
    checkElementIndex(index);
    return node(index).item;
}

Node&lt;E&gt; node(int index) {
    if (index &lt; (size &gt;&gt; 1)) {   //查询位置在链表前半部分，从链表头开始查找
        Node&lt;E&gt; x = first;
        for (int i = 0; i &lt; index; i++)
            x = x.next;
        return x;
    } else {                     //查询位置在链表后半部分，从链表尾开始查找
        Node&lt;E&gt; x = last;
        for (int i = size - 1; i &gt; index; i--)
            x = x.prev;
        return x;
    }
}
</code></pre>
<p><strong>2、迭代器遍历，Iterator：</strong></p>
<p>​    那么对于RandomAccess类型的集合来说，没有太多意义，反而因为一些额外的操作，还会增加额外的运行时间。但是对于Sequential Access的集合来说，就有很重大的意义了，因为Iterator内部维护了当前遍历的位置，所以每次遍历，读取下一个位置并不需要从集合的第一个元素开始查找，只要把指针向后移一位就行了，这样一来，遍历整个集合的时间复杂度就降低为O(n)；</p>
<p>（这里只用LinkedList做例子）LinkedList的迭代器，内部实现，就是维护当前遍历的位置，然后操作指针移动就可以了：</p>
<pre><code class="language-java">public E next() {
    checkForComodification();
    if (!hasNext())
        throw new NoSuchElementException();

    lastReturned = next;
    next = next.next;
    nextIndex++;
    return lastReturned.item;
}

public E previous() {
    checkForComodification();
    if (!hasPrevious())
        throw new NoSuchElementException();

    lastReturned = next = (next == null) ? last : next.prev;
    nextIndex--;
    return lastReturned.item;
}
</code></pre>
<p><strong>3、foreach循环遍历：</strong></p>
<p>​    分析Java字节码可知，foreach内部实现原理，也是通过Iterator实现的，只不过这个Iterator是Java编译器帮我们生成的，所以我们不需要再手动去编写。但是因为每次都要做类型转换检查，所以花费的时间比Iterator略长。时间复杂度和Iterator一样。</p>
<p>Iterator和foreach字节码如下：</p>
<pre><code class="language-java">//使用Iterator的字节码：
    Code:
       0: new           #16                 // class java/util/ArrayList
       3: dup
       4: invokespecial #18                 // Method java/util/ArrayList.&quot;&lt;init&gt;&quot;:()V
       7: astore_1
       8: aload_1
       9: invokeinterface #19,  1           // InterfaceMethod java/util/List.iterator:()Ljava/util/Iterator;
      14: astore_2
      15: goto          25
      18: aload_2
      19: invokeinterface #25,  1           // InterfaceMethod java/util/Iterator.next:()Ljava/lang/Object;
      24: pop
      25: aload_2
      26: invokeinterface #31,  1           // InterfaceMethod java/util/Iterator.hasNext:()Z
      31: ifne          18
      34: return
 
 
//使用foreach的字节码：
    Code:
       0: new           #16                 // class java/util/ArrayList
       3: dup
       4: invokespecial #18                 // Method java/util/ArrayList.&quot;&lt;init&gt;&quot;:()V
       7: astore_1
       8: aload_1
       9: invokeinterface #19,  1           // InterfaceMethod java/util/List.iterator:()Ljava/util/Iterator;
      14: astore_3
      15: goto          28
      18: aload_3
      19: invokeinterface #25,  1           // InterfaceMethod java/util/Iterator.next:()Ljava/lang/Object;
      24: checkcast     #31                 // class loop/Model
      27: astore_2
      28: aload_3
      29: invokeinterface #33,  1           // InterfaceMethod java/util/Iterator.hasNext:()Z
      34: ifne          18
      37: return
</code></pre>
<h3 id="各遍历方式的适用于什么场合">各遍历方式的适用于什么场合？</h3>
<ol>
<li>
<p>传统的for循环遍历，基于计数器的：</p>
<p>​    顺序存储：读取性能比较高。适用于遍历顺序存储集合。</p>
<p>​    链式存储：时间复杂度太大，不适用于遍历链式存储的集合。</p>
</li>
<li>
<p>迭代器遍历，Iterator：</p>
<p>​    顺序存储：如果不是太在意时间，推荐选择此方式，毕竟代码更加简洁，也防止了Off-By-One的问题。</p>
<p>​    链式存储：意义就重大了，平均时间复杂度降为O(n)，还是挺诱人的，所以推荐此种遍历方式。</p>
</li>
<li>
<p>foreach循环遍历：</p>
<p>​    foreach只是让代码更加简洁了，但是他有一些缺点，就是遍历过程中不能操作数据集合（删除等），所以有些场合不使用。而且它本身就是基于Iterator实现的，但是由于类型转换的问题，所以会比直接使用Iterator慢一点，但是还好，时间复杂度都是一样的。所以怎么选择，参考上面两种方式，做一个折中的选择。</p>
</li>
</ol>
<h3 id="randomaccess接口标记">RandomAccess接口标记</h3>
<p>Java数据集合框架中，提供了一个RandomAccess接口，该接口没有方法，只是一个标记。通常被List接口的实现使用，用来标记该List的实现是否支持Random Access。</p>
<p>一个数据集合实现了该接口，就意味着它支持Random Access，按位置读取元素的平均时间复杂度为O(1)。比如ArrayList。</p>
<p>而没有实现该接口的，就表示不支持Random Access。比如LinkedList。</p>
<p>所以看来JDK开发者也是注意到这个问题的，那么推荐的做法就是，如果想要遍历一个List，那么先判断是否支持Random Access，也就是 list instanceof RandomAccess。</p>
<p>比如：</p>
<pre><code class="language-java">if (list instanceof RandomAccess) {
    //使用传统的for循环遍历。
} else {
    //使用Iterator或者foreach。
}
</code></pre>
<h2 id="array-list-set互转">Array、List、Set互转</h2>
<h3 id="array-list互转">Array、List互转</h3>
<ol>
<li>Array 转List</li>
</ol>
<pre><code class="language-java">String[] s = new String[]{&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;,&quot;E&quot;};
List&lt;String&gt; list = Arrays.asList(s);
# 注意这里list里面的元素直接是s里面的元素( list backed by the specified array)，换句话就是说：对s的修改，直接影响list。
s[0] =&quot;AA&quot;;
System.out.println(&quot;list: &quot; + list);
# 输出结果
list: [AA, B, C, D, E]
</code></pre>
<ol start="2">
<li>List转Array</li>
</ol>
<pre><code class="language-java">String[] dest = list.toArray(new String[0]);//new String[0]是指定返回数组的类型
System.out.println(&quot;dest: &quot; + Arrays.toString(dest));
# 输出结果
dest: [AA, B, C, D, E]
# 注意这里的dest里面的元素不是list里面的元素，换句话就是说：对list中关于元素的修改，不会影响dest。
list.set(0, &quot;Z&quot;);
System.out.println(&quot;modified list: &quot; + list);
System.out.println(&quot;dest: &quot; + Arrays.toString(dest));
# 输出结果
modified list: [Z, B, C, D, E]
dest: [AA, B, C, D, E]
# 可以看到list虽然被修改了，但是dest数组没有没修改。
</code></pre>
<h3 id="list-set互转">List、Set互转</h3>
<p>因为List和Set都实现了Collection接口，且addAll(Collection&lt;? extends E&gt; c);方法，因此可以采用addAll()方法将List和Set互相转换；另外，List和Set也提供了Collection&lt;? extends E&gt; c作为参数的构造函数，因此通常采用构造函数的形式完成互相转化。</p>
<pre><code class="language-java">//List转Set
Set&lt;String&gt; set = new HashSet&lt;&gt;(list);
System.out.println(&quot;set: &quot; + set);
//Set转List
List&lt;String&gt; list_1 = new ArrayList&lt;&gt;(set);
System.out.println(&quot;list_1: &quot; + list_1);
# 和toArray()一样，被转换的List(Set)的修改不会对被转化后的Set（List）造成影响。
</code></pre>
<h3 id="array-set互转">Array、Set互转</h3>
<pre><code class="language-java">//array转set
s = new String[]{&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;,&quot;E&quot;};
set = new HashSet&lt;&gt;(Arrays.asList(s));
System.out.println(&quot;set: &quot; + set);
//set转array
dest = set.toArray(new String[0]);
System.out.println(&quot;dest: &quot; + Arrays.toString(dest));
</code></pre>
<h2 id="java-中初始化-list-集合的-6-种方式">Java 中初始化 List 集合的 6 种方式!</h2>
<ol>
<li>
<p>常规方式</p>
<pre><code class="language-java"> # 后面缺失的泛型类型在 JDK 7 之后就可以不用写具体的类型了，改进后会自动推断类型
 List&lt;String&gt; list = new ArrayList&lt;&gt;();
 list.add(&quot;1&quot;);
 list.add(&quot;2&quot;);
 list.add(&quot;3&quot;);
</code></pre>
</li>
<li>
<p>Arrays 工具类</p>
<pre><code class="language-java">import static java.util.Arrays.asList;
 List&lt;String&gt; list = asList(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;);
 # 注意，上面的 asList 是 Arrays 的静态方法，这里使用了静态导入。这种方式添加的是不可变的 List, 即不能添加、删除等操作，需要警惕。。
 # 如果要可变，那就使用 ArrayList 再包装一下，如下面所示。
 List&lt;String&gt; numbers = new ArrayList&lt;&gt;(Arrays.asList(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;));
 numbers.add(&quot;4&quot;);
</code></pre>
</li>
<li>
<p>Collections 工具类</p>
<pre><code class="language-java">List&lt;String&gt; list = Collections.nCopies(3, &quot;list&quot;);
 # 这种方式添加的是不可变的、复制某个元素N遍的工具类，以上程序输出：
 # [list, list, list]
 # 老规则，如果要可变，使用 ArrayList 包装一遍。
 List&lt;String&gt; list = new ArrayList&lt;&gt;(Collections.nCopies(3, &quot;list&quot;));
 list.add(&quot;list&quot;);

 # 还有初始化单个对象的 List 工具类，这种方式也是不可变的，集合内只能有一个元素，这种也用得很少啊。
 List&lt;String&gt; list = Collections.singletonList(&quot;list&quot;);

 # 还有一个创建空 List 的工具类，没有默认容量，节省空间，但不知道实际工作中没有用。
 List&lt;String&gt; list = Collections.emptyList(&quot;list&quot;);
</code></pre>
</li>
<li>
<p>匿名内部类</p>
<pre><code class="language-java">List&lt;String&gt; list = new ArrayList&lt;&gt;() {{
 add(&quot;1&quot;);
 add(&quot;2&quot;);
 add(&quot;3&quot;);
 }};
</code></pre>
<p>这种其实有效率和内存泄漏的问题，参考：</p>
<p>https://blog.csdn.net/xukun5137/article/details/78275201</p>
<p>https://www.cnblogs.com/wenbronk/p/7000643.html</p>
</li>
<li>
<p>JDK8 Stream</p>
<pre><code class="language-java">import static java.util.stream.Collectors.toList;
 List&lt;String&gt; list = Stream.of(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;).collect(toList());
</code></pre>
</li>
<li>
<p>JDK 9 List.of</p>
<pre><code class="language-java">List&lt;String&gt; list = List.of(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;);
</code></pre>
<p>这是 JDK 9 里面新增的 List 接口里面的静态方法，同样也是不可变的。</p>
</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java线程同步五种方法]]></title>
        <id>https://tinaxiawuhao.github.io/post/fE1AHZqDl/</id>
        <link href="https://tinaxiawuhao.github.io/post/fE1AHZqDl/">
        </link>
        <updated>2021-05-04T09:16:26.000Z</updated>
        <content type="html"><![CDATA[<h2 id="线程同步">线程同步</h2>
<p>即当有一个线程在对内存进行操作时，其他线程都不可以对这个内存地址进行操作，直到该线程完成操作， 其他线程才能对该内存地址进行操作，而其他线程又处于等待状态，实现线程同步的方法有很多，下面介绍java线程同步的五种方法。</p>
<h3 id="同步方法">同步方法</h3>
<p>使用synchronized关键字修饰的方法。由于java的每个对象都有一个内置锁，当用关键字修饰此方法时，内置锁会保护整个方法。在调用该方法前，需要获得内置锁，否则该线程就处于阻塞状态。</p>
<pre><code class="language-java">public synchronized void method(){} 
# synchronized关键字也可以修饰静态方法，此时如果调用该静态方法，将会锁住整个类。
public static synchronized void method(){} 
</code></pre>
<h3 id="同步代码块">同步代码块</h3>
<p>即有synchronized关键字修饰的语句块。被关键字修饰的的语句块会自动加上内置锁，从而实现同步。</p>
<pre><code class="language-java">synchronized(object){ 
	# 代码
} 
</code></pre>
<p><strong>注：同步是一种高开销的操作，因此应该尽量减少同步的内容。通常没有必要去同步整个方法，使用关键字synchronized修饰关键代码即可。</strong></p>
<h3 id="使用特殊域变量修饰符volatile实现线程同步">使用特殊域变量修饰符volatile实现线程同步</h3>
<p>（1）volatile关键字是非锁，比synchronized稍弱的同步机制</p>
<p>（2）保证此变量对所有的线程的可见性，当一个线程修改了这个变量的值，volatile 保证了新值能立即同步到主内存，以及每次使用前立即从主内存刷新。</p>
<p>（3）volatile不会提供原子操作，并不能保证线程安全，也不能用来修饰final类型的变量。</p>
<p>（4）禁止指令重排序优化。有volatile修饰的变量，赋值后多执行了一个添加<strong>内存屏障</strong>操作（指令重排序时不能把后面的指令重排序到内存屏障之前的位置）</p>
<pre><code class="language-java">public class Test extends Thread  {
    volatile int x = 0; //此处可以将volatile去除 或者 替换为 static，经过对比可看出volatile的作用
    
    private void write() {
        x = 5;
    }
    
    private void read() {
        while (x != 5) {}
        if(x == 5){
            System.out.println(&quot;------stoped&quot;);
        }
    }
    
    public static void main(String[] args) throws Exception {
        Test example = new Test();
        
        Thread writeThread = new Thread(new Runnable() {
            public void run() {
                example.write();
            }
        });

        Thread readThread = new Thread(new Runnable() {
            public void run() {
                example.read();
            }
        });

        readThread.start();
        TimeUnit.SECONDS.sleep(5); //记住此处一定要暂停5秒，以保证writeThread一定会在readThread中执行
        System.out.println(&quot;------&quot;);
        writeThread.start();
    }
}
</code></pre>
<p>注：多线程中的非同步问题主要出现在对域的读写上，如果域自身避免这个问题，那么就不需要修改操作该域的方法。用final域，有锁保护的域可以避免非同步的问题。</p>
<h3 id="使用重入锁reentrantlock实现线程同步">使用重入锁ReentrantLock实现线程同步</h3>
<p>jdk1.5中java.util.concurrent包下ReentrantLock类是可重入、互斥、实现了Lock接口的锁。它与synchronized修饰的方法具有相同的基本行为与语义，并且扩展了其能力。</p>
<p>ReentrantLock类的常用方法有：</p>
<p>（1）ReentrantLock()：创建一个ReentrantLock实例。</p>
<p>（2）lock():获得锁</p>
<p>（3）unlock()：释放锁</p>
<p>上述代码可以修改为：</p>
<pre><code class="language-java">public class Test extends Thread  {
    private int x = 0; 
    
    /**
      * 使用可重入锁
      */
    private Lock lock=new ReentrantLock();
    
    private void write() {
     lock.lock();
        try {
            x = 5;
        } catch (Exception e) {
            // TODO Auto-generated catch block
            e.printStackTrace();
        }finally {
            lock.unlock();//释放锁
        }
    }
    
    private void read() {
     lock.lock();
        try {
            while (x != 5) {}
            if(x == 5){
                System.out.println(&quot;------stoped&quot;);
            }
        } catch (Exception e) {
            // TODO Auto-generated catch block
            e.printStackTrace();
        }finally {
            lock.unlock();//释放锁
        }
        
    }
    
    public static void main(String[] args) throws Exception {
        Test example = new Test();
        
        Thread writeThread = new Thread(new Runnable() {
            public void run() {
                example.write();
            }
        });

        Thread readThread = new Thread(new Runnable() {
            public void run() {
                example.read();
            }
        });

        readThread.start();
        TimeUnit.SECONDS.sleep(5); //记住此处一定要暂停5秒，以保证writeThread一定会在readThread中执行
        System.out.println(&quot;------&quot;);
        writeThread.start();
    }
}
</code></pre>
<p>注：</p>
<ol>
<li>
<p>ReentrantLock()还可以通过public ReentrantLock(boolean fair)构造方法创建公平锁，即，优先运行等待时间最长的线程，这样大幅度降低程序运行效率。</p>
</li>
<li>
<p>关于Lock对象和synchronized关键字的选择：</p>
<p>（1）最好两个都不用，使用一种java.util.concurrent包提供的机制，能够帮助用户处理所有与锁相关的代码。</p>
<p>（2）如果synchronized关键字能够满足用户的需求，就用synchronized，他能简化代码。</p>
<p>（3）如果需要使用更高级的功能，就用ReentrantLock类，此时要注意及时释放锁，否则会出现死锁，通常在finally中释放锁。</p>
</li>
</ol>
<h3 id="使用threadlocal管理局部变量实现线程同步">使用ThreadLocal管理局部变量实现线程同步</h3>
<p>ThreadLocal管理变量，则每一个使用该变量的线程都获得一个该变量的副本，副本之间相互独立，这样每一个线程都可以随意修改自己的副本，而不会对其他线程产生影响。</p>
<p>ThreadLocal类常用的方法：</p>
<ol>
<li>
<p>get()：返回该线程局部变量的当前线程副本中的值。</p>
</li>
<li>
<p>initialValue()：返回此线程局部变量的当前线程的”初始值“。</p>
</li>
<li>
<p>remove()：移除此线程局部变量当前线程的值。</p>
</li>
<li>
<p>set(T value)：将此线程局部变量的当前线程副本中的值设置为指定值value。</p>
</li>
</ol>
<p>上述代码修改为：</p>
<pre><code class="language-java"> 
public class Test extends Thread  {
    private static ThreadLocal&lt;Integer&gt; count=new ThreadLocal&lt;Integer&gt;(){
            @Override
            protected Integer initialValue() {
                  // TODO Auto-generated method stub
                  return 0;
            }
      };
    
    private void write() {
        count.set(count.get()+5);
    }
    
    private void read() {
        while (count.get() != 5) {}
        if(count.get() == 5){
            System.out.println(&quot;------stoped&quot;);
        }
    }
    
    public static void main(String[] args) throws Exception {
        Test example = new Test();
        
        Thread writeThread = new Thread(new Runnable() {
            public void run() {
                example.write();
            }
        });

        Thread readThread = new Thread(new Runnable() {
            public void run() {
                example.read();
            }
        });

        readThread.start();
        TimeUnit.SECONDS.sleep(5); //记住此处一定要暂停5秒，以保证writeThread一定会在readThread中执行
        System.out.println(&quot;------&quot;);
        writeThread.start();
    }
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ThreadLocal是什么]]></title>
        <id>https://tinaxiawuhao.github.io/post/cQAJ3QFSZ/</id>
        <link href="https://tinaxiawuhao.github.io/post/cQAJ3QFSZ/">
        </link>
        <updated>2021-05-03T08:38:38.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>ThreadLocal是一个本地线程副本变量工具类。主要用于将私有线程和该线程存放的副本对象做一个映射，各个线程之间的变量互不干扰，在高并发场景下，可以实现无状态的调用，特别适用于各个线程依赖不通的变量值完成操作的场景。</p>
</blockquote>
<h3 id="数据结构">数据结构</h3>
<p>下图为ThreadLocal的内部结构图<br>
<img src="https://tinaxiawuhao.github.io/post-images/1619599257027.png" alt="" loading="lazy"></p>
<h3 id="threadlocal结构内部核心机制">ThreadLocal结构内部核心机制:</h3>
<ol>
<li>
<p>每个Thread线程内部都有一个Map。</p>
</li>
<li>
<p>Map里面存储线程本地对象（key）和线程的变量副本（value）</p>
</li>
<li>
<p>Thread内部的Map是由ThreadLocal维护的，由ThreadLocal负责向map获取和设置线程的变量值。<br>
所以对于不同的线程，每次获取副本值时，别的线程并不能获取到当前线程的副本值，形成了副本的隔离，互不干扰。</p>
</li>
</ol>
<p>Thread线程内部的Map在类中描述如下：</p>
<pre><code class="language-java"> public class Thread implements Runnable {
        /* ThreadLocal values pertaining to this thread. This map is maintained
         * by the ThreadLocal class. 
         */
        ThreadLocal.ThreadLocalMap threadLocals = null;
    }
</code></pre>
<h2 id="深入解析threadlocal">深入解析ThreadLocal</h2>
<p>ThreadLocal类提供如下几个核心方法：</p>
<pre><code class="language-java">public T get()
public void set(T value)
public void remove()
# get()方法用于获取当前线程的副本变量值。
# set()方法用于保存当前线程的副本变量值。
# initialValue()为当前线程初始副本变量值。
# remove()方法移除当前前程的副本变量值。
</code></pre>
<h3 id="get方法">get()方法</h3>
<pre><code class="language-java">/**
 * Returns the value in the current thread's copy of this
 * thread-local variable.  If the variable has no value for the
 * current thread, it is first initialized to the value returned
 * by an invocation of the {@link #initialValue} method.
 *
 * @return the current thread's value of this thread-local
 */
public T get() {
    Thread t = Thread.currentThread();
    ThreadLocalMap map = getMap(t);
    if (map != null) {
        ThreadLocalMap.Entry e = map.getEntry(this);
        if (e != null)
            return (T)e.value;
    }
    return setInitialValue();
}

ThreadLocalMap getMap(Thread t) {
    return t.threadLocals;
}

private T setInitialValue() {
    T value = initialValue();
    Thread t = Thread.currentThread();
    ThreadLocalMap map = getMap(t);
    if (map != null)
        map.set(this, value);
    else
        createMap(t, value);
    return value;
}

protected T initialValue() {
    return null;
}
</code></pre>
<h4 id="步骤">步骤：</h4>
<ol>
<li>获取当前线程的ThreadLocalMap对象threadLocals</li>
<li>从map中获取线程存储的K-V Entry节点。</li>
<li>从Entry节点获取存储的Value副本值返回。</li>
<li>map为空的话返回初始值null，即线程变量副本为null，在使用时需要注意判断NullPointerException。</li>
</ol>
<h3 id="set方法">set()方法</h3>
<pre><code class="language-java">/**
 * Sets the current thread's copy of this thread-local variable
 * to the specified value.  Most subclasses will have no need to
 * override this method, relying solely on the {@link #initialValue}
 * method to set the values of thread-locals.
 *
 * @param value the value to be stored in the current thread's copy of
 *        this thread-local.
 */
public void set(T value) {
    Thread t = Thread.currentThread();
    ThreadLocalMap map = getMap(t);
    if (map != null)
        map.set(this, value);
    else
        createMap(t, value);
}

ThreadLocalMap getMap(Thread t) {
    return t.threadLocals;
}

void createMap(Thread t, T firstValue) {
    t.threadLocals = new ThreadLocalMap(this, firstValue);
}
</code></pre>
<h4 id="步骤-2">步骤：</h4>
<ol>
<li>获取当前线程的成员变量map</li>
<li>map非空，则重新将ThreadLocal和新的value副本放入到map中。</li>
<li>map空，则对线程的成员变量ThreadLocalMap进行初始化创建，并将ThreadLocal和value副本放入map中。</li>
</ol>
<h3 id="remove方法">remove()方法</h3>
<p>remove方法比较简单，不做赘述。</p>
<h3 id="threadlocalmap">ThreadLocalMap</h3>
<p>ThreadLocalMap是ThreadLocal的内部类，没有实现Map接口，用独立的方式实现了Map的功能，其内部的Entry也独立实现。</p>
<p>ThreadLocalMap类图<br>
<img src="https://tinaxiawuhao.github.io/post-images/1619599268344.png" alt="" loading="lazy"></p>
<p>在ThreadLocalMap中，也是用Entry来保存K-V结构数据的。但是Entry中key只能是ThreadLocal对象，这点被Entry的构造方法已经限定死了。</p>
<pre><code class="language-java">static class Entry extends WeakReference&lt;ThreadLocal&gt; {
    /** The value associated with this ThreadLocal. */
    Object value;

    Entry(ThreadLocal k, Object v) {
        super(k);
        value = v;
    }
}
</code></pre>
<p>Entry继承自WeakReference（弱引用，生命周期只能存活到下次GC前），但只有Key是弱引用类型的，Value并非弱引用。<br>
ThreadLocalMap的成员变量：</p>
<pre><code class="language-java">static class ThreadLocalMap {
    /**
     * The initial capacity -- MUST be a power of two.
     */
    private static final int INITIAL_CAPACITY = 16;

    /**
     * The table, resized as necessary.
     * table.length MUST always be a power of two.
     */
    private Entry[] table;

    /**
     * The number of entries in the table.
     */
    private int size = 0;

    /**
     * The next size value at which to resize.
     */
    private int threshold; // Default to 0
}
</code></pre>
<h3 id="hash冲突怎么解决">Hash冲突怎么解决</h3>
<p>和HashMap的最大的不同在于，ThreadLocalMap结构非常简单，没有next引用，也就是说ThreadLocalMap中解决Hash冲突的方式并非链表的方式，而是采用线性探测的方式，所谓线性探测，就是根据初始key的hashcode值确定元素在table数组中的位置，如果发现这个位置上已经有其他key值的元素被占用，则利用固定的算法寻找一定步长的下个位置，依次判断，直至找到能够存放的位置。<br>
ThreadLocalMap解决Hash冲突的方式就是简单的步长加1或减1，寻找下一个相邻的位置。</p>
<pre><code class="language-java">/**
 * Increment i modulo len.
 */
private static int nextIndex(int i, int len) {
    return ((i + 1 &lt; len) ? i + 1 : 0);
}

/**
 * Decrement i modulo len.
 */
private static int prevIndex(int i, int len) {
    return ((i - 1 &gt;= 0) ? i - 1 : len - 1);
}
</code></pre>
<p>显然ThreadLocalMap采用线性探测的方式解决Hash冲突的效率很低，如果有大量不同的ThreadLocal对象放入map中时发送冲突，或者发生二次冲突，则效率很低。<br>
<code>所以这里引出的良好建议是：每个线程只存一个变量，这样的话所有的线程存放到map中的Key都是相同的ThreadLocal，如果一个线程要保存多个变量，就需要创建多个ThreadLocal，多个ThreadLocal放入Map中时会极大的增加Hash冲突的可能。 ThreadLocalMap的问题</code><br>
由于ThreadLocalMap的key是弱引用，而Value是强引用。这就导致了一个问题，ThreadLocal在没有外部对象强引用时，发生GC时弱引用Key会被回收，而Value不会回收，如果创建ThreadLocal的线程一直持续运行，那么这个Entry对象中的value就有可能一直得不到回收，发生内存泄露。</p>
<h3 id="如何避免泄漏">如何避免泄漏</h3>
<p>既然Key是弱引用，那么我们要做的事，就是在调用ThreadLocal的get()、set()方法时完成后再调用remove方法，将Entry节点和Map的引用关系移除，这样整个Entry对象在GC Roots分析后就变成不可达了，下次GC的时候就可以被回收。<br>
如果使用ThreadLocal的set方法之后，没有显示的调用remove方法，就有可能发生内存泄露，所以养成良好的编程习惯十分重要，使用完ThreadLocal之后，记得调用remove方法。</p>
<pre><code class="language-java">ThreadLocal&lt;Session&gt; threadLocal = new ThreadLocal&lt;Session&gt;();
try {
    threadLocal.set(new Session(1, &quot;Misout的博客&quot;));
    // 其它业务逻辑
} finally {
    threadLocal.remove();
}
</code></pre>
<h3 id="应用场景">应用场景</h3>
<p>还记得Hibernate的session获取场景吗？</p>
<pre><code class="language-java">private static final ThreadLocal&lt;Session&gt; threadLocal = new ThreadLocal&lt;Session&gt;();

//获取Session
public static Session getCurrentSession(){
    Session session =  threadLocal.get();
    //判断Session是否为空，如果为空，将创建一个session，并设置到本地线程变量中
    try {
        if(session ==null&amp;&amp;!session.isOpen()){
            if(sessionFactory==null){
                rbuildSessionFactory();// 创建Hibernate的SessionFactory
            }else{
                session = sessionFactory.openSession();
            }
        }
        threadLocal.set(session);
    } catch (Exception e) {
        // TODO: handle exception
    }

    return session;
}
</code></pre>
<p>为什么？每个线程访问数据库都应当是一个独立的Session会话，如果多个线程共享同一个Session会话，有可能其他线程关闭连接了，当前线程再执行提交时就会出现会话已关闭的异常，导致系统异常。此方式能避免线程争抢Session，提高并发下的安全性。<br>
使用ThreadLocal的典型场景正如上面的数据库连接管理，线程会话管理等场景，只适用于独立变量副本的情况，如果变量为全局共享的，则不适用在高并发下使用。</p>
<h2 id="总结">总结</h2>
<ol>
<li>每个ThreadLocal只能保存一个变量副本，如果想要上线一个线程能够保存多个副本以上，就需要创建多个ThreadLocal。</li>
<li>ThreadLocal内部的ThreadLocalMap键为弱引用，会有内存泄漏的风险。</li>
<li>适用于无状态，副本变量独立后不影响业务逻辑的高并发场景。如果如果业务逻辑强依赖于副本变量，则不适合用ThreadLocal解决，需要另寻解决方案。</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[HashMap负载因子为什么是0.75，链表转红黑树阈值为什么是8]]></title>
        <id>https://tinaxiawuhao.github.io/post/mdZO-HjSu/</id>
        <link href="https://tinaxiawuhao.github.io/post/mdZO-HjSu/">
        </link>
        <updated>2021-05-02T13:04:40.000Z</updated>
        <content type="html"><![CDATA[<h3 id="1hashmap负载因子为什么是075">1.HashMap负载因子为什么是0.75</h3>
<p>这是时间与空间成本上的折中。</p>
<h4 id="11时间成本">1.1时间成本</h4>
<p>假设负载因子是1时，虽然空间利用率高了，但是随之提高的是哈希碰撞的概率。<br>
而Hashmap中哈希碰撞的解决方法采用的拉链法，哈希冲突高了会导致链表越来越长（虽然后面会转换成红黑树），我们知道链表的查询效率是比较低的，所以负载因子太高会导致时间成本上升。</p>
<h4 id="12空间成本">1.2空间成本</h4>
<p>那么为了减少哈希冲突，提高查询效率，负载因子是不是越低越好呢？答案显然是否定的。<br>
假设负载因子为0.5时，那么空间利用率只有50%。例如大小为64时，至少有32没有被利用，大小为1024时，就有512没有被利用。扩容后的空间越大，空出的空间也就越大。<br>
所以Java开发人员经过权衡，负载因子不能太大也不能太小，折中选择为0.75。</p>
<h3 id="2链表转红黑树阈值为什么是8">2.链表转红黑树阈值为什么是8</h3>
<p>当负载因子是0.75的情况下，哈希碰撞的概率遵循参数约为0.5的泊松分布<br>
这是概率论的范畴，不知道的同学只需要记住当负载因子是0.75的情况下，我们能够计算出哈希碰撞的概率</p>
<pre><code class="language-java">Because TreeNodes are about twice the size of regular nodes, we
use them only when bins contain enough nodes to warrant use
(see TREEIFY_THRESHOLD). And when they become too small (due to
removal or resizing) they are converted back to plain bins.  In
usages with well-distributed user hashCodes, tree bins are
rarely used.  Ideally, under random hashCodes, the frequency of
nodes in bins follows a Poisson distribution
(http://en.wikipedia.org/wiki/Poisson_distribution) with a
parameter of about 0.5 on average for the default resizing
threshold of 0.75, although with a large variance because of
resizing granularity. Ignoring variance, the expected
occurrences of list size k are (exp(-0.5)*pow(0.5, k)/factorial(k)). 
The first values are:
0:    0.60653066
1:    0.30326533
2:    0.07581633
3:    0.01263606
4:    0.00157952
5:    0.00015795
6:    0.00001316
7:    0.00000094
8:    0.00000006
more: less than 1 in ten million
</code></pre>
<p>在HashMap源码中，给出了计算出的哈希碰撞的概率。<br>
我们看到碰撞8次(链表长度达到8)的概率为0.00000006,几乎是一个不可能事件。<br>
所以Java开发人员将链表转红黑树阈值默认设为8，是为了避免链表转红黑树这种耗时操作的事件发生。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[java中静态代码块，非静态代码块，构造函数之间的执行顺序]]></title>
        <id>https://tinaxiawuhao.github.io/post/8H8sHTUTf/</id>
        <link href="https://tinaxiawuhao.github.io/post/8H8sHTUTf/">
        </link>
        <updated>2021-05-01T08:34:46.000Z</updated>
        <content type="html"><![CDATA[<p>它们之间的执行顺序为：静态代码块—&gt;非静态代码块—&gt;构造方法。<br>
静态代码块只在第一次加载类的时候执行一次，之后不再执行；而非静态代码块和构造函数都是在每new一次就执行一次，只不过非静态代码块在构造函数之前执行而已。<br>
如果存在子类，则加载顺序为先父类后子类。<br>
看如下的代码：</p>
<pre><code class="language-java">package com.ykp.test;
 
class ClassA {
    public ClassA() {
        System.out.println(&quot;父类构造函数&quot;);
    }
 
    {
        System.out.println(&quot;父类非静态代码块1&quot;);
    }
    {
        System.out.println(&quot;父类非静态代码块2&quot;);
    }
    static {
        System.out.println(&quot;父类静态代码块 1&quot;);
    }
    static {
        System.out.println(&quot;父类静态代码块 2&quot;);
    }
}
 
public class ClassB extends ClassA {
    public ClassB() {
        System.out.println(&quot;子类构造函数&quot;);
    }
 
    {
        System.out.println(&quot;子类非静态代码块2&quot;);
    }
    {
        System.out.println(&quot;子类非静态代码块1&quot;);
    }
    static {
        System.out.println(&quot;子类静态代码块 2&quot;);
    }
    static {
        System.out.println(&quot;子类静态代码块 1&quot;);
    }
 
    public static void main(String[] args) {
        System.out.println(&quot;....主方法开始....&quot;);
        new ClassB();
        System.out.println(&quot;************&quot;);
        new ClassB();
        System.out.println(&quot;....主方法结束....&quot;);
    }
}
</code></pre>
<p>执行结果：</p>
<pre><code class="language-java">父类静态代码块 1
父类静态代码块 2
子类静态代码块 2
子类静态代码块 1
....主方法开始....
父类非静态代码块1
父类非静态代码块2
父类构造函数
子类非静态代码块2
子类非静态代码块1
子类构造函数
************
父类非静态代码块1
父类非静态代码块2
父类构造函数
子类非静态代码块2
子类非静态代码块1
子类构造函数
....主方法结束....
</code></pre>
<p>从结果可以看出，首先加载类，加载的时候先加载父类，然后子类，类加载的时候就执行静态代码快，也就是说静态代码块是在类加载的时候就加载的，而且只加载一次。如果存在多个执行顺序按照代码的先后来。<br>
对于非静态代码块，是在new的时候加载的，只是在构造函数之前加载而已。如果存在多个执行顺序按照代码的先后来。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[指令重排序]]></title>
        <id>https://tinaxiawuhao.github.io/post/J4bdQ7uDb/</id>
        <link href="https://tinaxiawuhao.github.io/post/J4bdQ7uDb/">
        </link>
        <updated>2021-04-30T06:23:15.000Z</updated>
        <content type="html"><![CDATA[<h3 id="数据依赖性">数据依赖性</h3>
<p>如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在数据依赖性。数据依赖分下列三种类型：</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>代码示例</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>写后读</td>
<td>a = 1;b = a;</td>
<td>写一个变量之后，再读这个位置。</td>
</tr>
<tr>
<td>写后写</td>
<td>a = 1;a = 2;</td>
<td>写一个变量之后，再写这个变量。</td>
</tr>
<tr>
<td>读后写</td>
<td>a = b;b = 1;</td>
<td>读一个变量之后，再写这个变量。</td>
</tr>
</tbody>
</table>
<p>上面三种情况，只要重排序两个操作的执行顺序，程序的执行结果将会被改变。</p>
<p>前面提到过，编译器和处理器可能会对操作做重排序。编译器和处理器在重排序时，会遵守数据依赖性，编译器和处理器不会改变存在数据依赖关系的两个操作的执行顺序。</p>
<p>注意，这里所说的数据依赖性仅针对单个处理器中执行的指令序列和单个线程中执行的操作，不同处理器之间和不同线程之间的数据依赖性不被编译器和处理器考虑。</p>
<h3 id="as-if-serial-语义">as-if-serial 语义</h3>
<p>as-if-serial 语义的意思指：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器，runtime 和处理器都必须遵守 as-if-serial 语义。</p>
<p>为了遵守 as-if-serial 语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。但是，如果操作之间不存在数据依赖关系，这些操作可能被编译器和处理器重排序。为了具体说明，请看下面计算圆面积的代码示例：</p>
<pre><code class="language-java">double pi  = 3.14;    //A
double r   = 1.0;     //B
double area = pi * r * r; //C  
</code></pre>
<p>上面三个操作的数据依赖关系如下图所示：</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1619332089100.png" alt="" loading="lazy"></figure>
<p>如上图所示，A 和 C 之间存在数据依赖关系，同时 B 和 C 之间也存在数据依赖关系。因此在最终执行的指令序列中，C 不能被重排序到 A 和 B 的前面（C 排到 A 和 B 的前面，程序的结果将会被改变）。但 A 和 B 之间没有数据依赖关系，编译器和处理器可以重排序 A 和 B 之间的执行顺序。下图是该程序的两种执行顺序：</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1619332096691.webp" alt="" loading="lazy"></figure>
<p>as-if-serial 语义把单线程程序保护了起来，遵守 as-if-serial 语义的编译器，runtime 和处理器共同为编写单线程程序的程序员创建了一个幻觉：单线程程序是按程序的顺序来执行的。as-if-serial 语义使单线程程序员无需担心重排序会干扰他们，也无需担心内存可见性问题。</p>
<h3 id="程序顺序规则">程序顺序规则</h3>
<p>根据 happens- before 的程序顺序规则，上面计算圆的面积的示例代码存在三个 happens- before 关系：</p>
<ol>
<li>A happens- before B；</li>
<li>B happens- before C；</li>
<li>A happens- before C；</li>
</ol>
<p>这里的第3个 happens- before 关系，是根据 happens- before 的传递性推导出来的。</p>
<p>这里 A happens- before B，但实际执行时 B 却可以排在 A 之前执行（看上面的重排序后的执行顺序）。在第一章提到过，如果 A happens- before B，JMM 并不要求 A 一定要在 B 之前执行。JMM 仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前。这里操作 A 的执行结果不需要对操作 B 可见；而且重排序操作 A 和操作 B 后的执行结果，与操作 A 和操作 B 按 happens- before 顺序执行的结果一致。在这种情况下，JMM 会认为这种重排序并不非法（not illegal），JMM 允许这种重排序。</p>
<p>在计算机中，软件技术和硬件技术有一个共同的目标：在不改变程序执行结果的前提下，尽可能的开发并行度。编译器和处理器遵从这一目标，从 happens- before 的定义我们可以看出，JMM 同样遵从这一目标。</p>
<h3 id="重排序对多线程的影响">重排序对多线程的影响</h3>
<p>现在让我们来看看，重排序是否会改变多线程程序的执行结果。请看下面的示例代码：</p>
<pre><code class="language-java">class ReorderExample {
    int a = 0;
    boolean flag = false;

    public void writer() {
        a = 1;                   //1
        flag = true;             //2
    }

    Public void reader() {
        if (flag) {                //3
            int i =  a * a;        //4
            ……
        }
    }
}  
</code></pre>
<p>flag 变量是个标记，用来标识变量 a 是否已被写入。这里假设有两个线程 A 和 B，A 首先执行writer() 方法，随后 B 线程接着执行 reader() 方法。线程B在执行操作4时，能否看到线程 A 在操作1对共享变量 a 的写入？</p>
<p>答案是：不一定能看到。</p>
<p>由于操作1和操作2没有数据依赖关系，编译器和处理器可以对这两个操作重排序；同样，操作3和操作4没有数据依赖关系，编译器和处理器也可以对这两个操作重排序。让我们先来看看，当操作1和操作2重排序时，可能会产生什么效果？请看下面的程序执行时序图：<br>
<img src="https://tinaxiawuhao.github.io/post-images/1619332109512.webp" alt="" loading="lazy"></p>
<p>如上图所示，操作1和操作2做了重排序。程序执行时，线程A首先写标记变量 flag，随后线程 B 读这个变量。由于条件判断为真，线程 B 将读取变量a。此时，变量 a 还根本没有被线程 A 写入，在这里多线程程序的语义被重排序破坏了！</p>
<p>※注：本文统一用红色的虚箭线表示错误的读操作，用绿色的虚箭线表示正确的读操作。</p>
<p>下面再让我们看看，当操作3和操作4重排序时会产生什么效果（借助这个重排序，可以顺便说明控制依赖性）。下面是操作3和操作4重排序后，程序的执行时序图：</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1619332116836.webp" alt="" loading="lazy"></figure>
<p>在程序中，操作3和操作4存在控制依赖关系。当代码中存在控制依赖性时，会影响指令序列执行的并行度。为此，编译器和处理器会采用猜测（Speculation）执行来克服控制相关性对并行度的影响。以处理器的猜测执行为例，执行线程 B 的处理器可以提前读取并计算 a*a，然后把计算结果临时保存到一个名为重排序缓冲（reorder buffer ROB）的硬件缓存中。当接下来操作3的条件判断为真时，就把该计算结果写入变量i中。</p>
<p>从图中我们可以看出，猜测执行实质上对操作3和4做了重排序。重排序在这里破坏了多线程程序的语义！</p>
<p>在单线程程序中，对存在控制依赖的操作重排序，不会改变执行结果（这也是 as-if-serial 语义允许对存在控制依赖的操作做重排序的原因）；但在多线程程序中，对存在控制依赖的操作重排序，可能会改变程序的执行结果。</p>
<h3 id="编译器指令重排">编译器指令重排</h3>
<p>下面我们简单看一个编译器重排的例子：</p>
<p>线程 1 线程 2</p>
<pre><code class="language-bash">1：x2 = a ; 3: x1 = b ;

2: b = 1; 4: a = 2 ;
</code></pre>
<p>两个线程同时执行，分别有1、2、3、4四段执行代码，其中1、2属于线程1 ， 3、4属于线程2 ，从程序的执行顺序上看，似乎不太可能出现x1 = 1 和x2 = 2 的情况，但实际上这种情况是有可能发现的，因为如果编译器对这段程序代码执行重排优化后，可能出现下列情况</p>
<p>线程 1 线程 2</p>
<pre><code class="language-bash">2: b = 1; 4: a = 2 ;

1：x2 = a ; 3: x1 = b ;
</code></pre>
<p>这种执行顺序下就有可能出现<code>x1 = 1</code> 和<code>x2 = 2</code> 的情况，这也就说明在多线程环境下，由于编译器优化重排的存在，两个线程中使用的变量能否保证一致性是无法确定的。</p>
<p>源代码和Runtime时执行的代码很可能不一样，这是因为编译器、处理器常常会为了追求性能对改变执行顺序。然而改变顺序执行很危险，很有可能使得运行结果和预想的不一样，特别是当重排序共享变量时。</p>
<p>从源代码到Runtime需要经过三步的重排序：</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1619515556691.png" alt="" loading="lazy"></figure>
<h2 id="编译器重排序">编译器重排序</h2>
<p>为了提高性能，在不改变单线程的执行结果下，可以改变语句执行顺序。</p>
<p>比如尽可能的减少寄存器的读写次数，充分利用局部性。像下面这段代码这样，交替的读x、y，会导致寄存器频繁的交替存储x和y，最糟的情况下寄存器要存储3次x和3次y。如果能让x的一系列操作一块做完，y的一块做完，理想情况下寄存器只需要存储1次x和1次y。</p>
<pre><code class="language-javascript">//优化前
int x = 1;
int y = 2;
int a1 = x * 1;
int b1 = y * 1;
int a2 = x * 2;
int b2 = y * 2;
int a3 = x * 3;
int b3 = y * 3;

//优化后
int x = 1;
int y = 2;
int a1 = x * 1;
int a2 = x * 2;
int a3 = x * 3;
int b1 = y * 1;
int b2 = y * 2;
int b3 = y * 3;
</code></pre>
<h2 id="指令重排序">指令重排序</h2>
<p>指令重排序是处理器层面做的优化。处理器在执行时往往会因为一些限制而等待，如访存的地址不在cache中发生miss，这时就需要到内存甚至外存去取，然而内存和外区的读取速度比CPU执行速度慢得多。</p>
<p>早期处理器是顺序执行(in-order execution)的，在内存、外存读取数据这段时间，处理器就一直处于等待状态。现在处理器一般都是乱序执行(out-of-order execution)，处理器会在等待数据的时候去<strong>执行其他已准备好的操作</strong>，不会让处理器一直等待。</p>
<p>满足乱序执行的条件：</p>
<ol>
<li>该缓存的操作数缓存好</li>
<li>有空闲的执行单元</li>
</ol>
<p>对于下面这段汇编代码，操作1如果发生cache miss，则需要等待读取内存外存。看看有没有能优先执行的指令，操作2依赖于操作1，不能被优先执行，操作3不依赖1和2，所以能优先执行操作3。 所以实际执行顺序是3&gt;1&gt;2</p>
<pre><code class="language-javascript">LDR R1, [R0];//操作1
ADD R2, R1, R1;//操作2
ADD R3, R4, R4;//操作3
</code></pre>
<h2 id="内存系统重排序">内存系统重排序</h2>
<p>由于处理器有读、写缓存区，<em>写缓存区没有及时刷新到内存</em>，造成其他处理器读到的值不是最新的，使得<strong>处理器执行的读写操作与内存上反应出的顺序不一致</strong>。</p>
<p>如下面这个例子，可能造成处理器A读到的b=0，处理器B读到的a=0。A1写a=1先写到处理器A的写缓存区中，此时内存中a=0。如果这时处理器B从内存中读a，读到的将是0。</p>
<p>以处理器A来说，处理器A执行的顺序是A1&gt;A2&gt;A3，但是由于写缓存区没有及时刷新到内存，所以实际顺序为A2&gt;A1&gt;A3。</p>
<pre><code class="language-javascript">初始化：
a = 0;
b = 0;

处理器A执行
a = 1; //A1
read(b); //A2

处理器B执行
b = 2; //B1
read(a); //B2
</code></pre>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1619515566926.png" alt="" loading="lazy"></figure>
<h2 id="阻止重排序">阻止重排序</h2>
<p>不论哪种重排序都可能造成共享变量中线程间不可见，这会改变程序运行结果。所以需要禁止对那些要求可见的共享变量重排序。</p>
<ul>
<li>阻止编译重排序：禁止编译器在某些时候重排序。</li>
<li>阻止指令重排序和内存系统重排序：使用内存屏障或Lock前缀指令</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[happens-before原则和volatile]]></title>
        <id>https://tinaxiawuhao.github.io/post/67CnuNlVA/</id>
        <link href="https://tinaxiawuhao.github.io/post/67CnuNlVA/">
        </link>
        <updated>2021-04-29T05:38:32.000Z</updated>
        <content type="html"><![CDATA[<h2 id="基本概念">基本概念</h2>
<p><strong>先补充一下概念：Java 内存模型中的可见性、原子性和有序性。</strong></p>
<h3 id="可见性">可见性：</h3>
<p>可见性是一种复杂的属性，因为可见性中的错误总是会违背我们的直觉。通常，我们无法确保执行读操作的线程能适时地看到其他线程写入的值，有时甚至是根本不可能的事情。为了确保多个线程之间对内存写入操作的可见性，必须使用同步机制。</p>
<p><strong>可见性，是指线程之间的可见性，一个线程修改的状态对另一个线程是可见的</strong>也就是一个线程修改的结果。另一个线程马上就能看到。比如：用volatile修饰的变量，就会具有可见性。volatile修饰的变量不允许线程内部缓存和重排序，即直接修改内存。所以对其他线程是可见的。但是这里需要注意一个问题，volatile只能让被他修饰内容具有可见性，但不能保证它具有原子性。比如 volatile int a = 0；之后有一个操作 a++；这个变量a具有可见性，但是a++ 依然是一个非原子操作，也就是这个操作同样存在线程安全问题。</p>
<p>在 Java 中 <code>volatile</code>、<code>synchronized</code> 和<code>final</code> 实现可见性。</p>
<h3 id="原子性">原子性：</h3>
<p><strong>原子是世界上的最小单位，具有不可分割性</strong>，比如 a=0；（a非long和double类型） 这个操作是不可分割的，那么我们说这个操作是原子操作。再比如：a++； 这个操作实际是a = a + 1；是可分割的，所以他不是一个原子操作。非原子操作都会存在线程安全问题，需要我们使用同步技术（sychronized）来让它变成一个原子操作。一个操作是原子操作，那么我们称它具有原子性。java的concurrent包下提供了一些原子类，我们可以通过阅读API来了解这些原子类的用法。比如：<code>AtomicInteger</code>、<code>AtomicLong</code>、<code>AtomicReference</code>等。</p>
<p>在 Java 中 <code>synchronized</code> 和在 <code>lock</code>、<code>unlock</code> 中操作保证原子性。</p>
<h3 id="有序性">有序性：</h3>
<p>Java 语言提供了 volatile 和 synchronized 两个关键字来保证线程之间操作的有序性，volatile 是因为其本身包含“禁止指令重排序”的语义，synchronized 是由“一个变量在同一个时刻只允许一条线程对其进行 lock 操作”这条规则获得的，此规则决定了持有同一个对象锁的两个同步块只能串行执行。</p>
<h2 id="happens-before">happens-before</h2>
<p>在学习<code>Java内存模型(JMM, Java Memory Model)</code>时，关于线程、主存(main memory)、工作内存(working memory)，这些概念都有着实体的相互对应，线程可能对应着一个内核线程，主存对应着内存，而工作内存则涵盖了写缓冲区、缓存(cache)、寄存器等一系列为了提高数据存取效率的<strong>暂存区域</strong>。但是，一提到<strong>happens-before原则</strong>，就让人有点“丈二和尚摸不着头脑”。这个涵盖了整个<code>JMM</code>中可见性原则的规则，究竟如何理解？</p>
<p>两个操作间具有happens-before关系，并不意味着前一个操作必须要在后一个操作之前执行。happens-before仅仅要求前一个操作对后一个操作可见。happens-before原则和一般意义上的<strong>时间先后</strong>是不同的</p>
<h2 id="有哪些happens-before规则">有哪些happens-before规则</h2>
<p><code>程序次序规则</code>：在一个线程内一段代码的执行结果是有序的。就是还会指令重排，但是随便它怎么排，结果是按照我们代码的顺序生成的不会变。<br>
<code>管程锁定规则</code>：就是无论是在单线程环境还是多线程环境，对于同一个锁来说，一个线程对这个锁解锁之后，另一个线程获取了这个锁都能看到前一个线程的操作结果！(管程是一种通用的同步原语，synchronized就是管程的实现）<br>
<code>volatile变量规则</code>：就是如果一个线程先去写一个volatile变量，然后一个线程去读这个变量，那么这个写操作的结果一定对读的这个线程可见。<br>
<code>线程启动规则</code>：在主线程A执行过程中，启动子线程B，那么线程A在启动子线程B之前对共享变量的修改结果对线程B可见。<br>
<code>线程终止规则</code>：在主线程A执行过程中，子线程B终止，那么线程B在终止之前对共享变量的修改结果在线程A中可见。也称线程join()规则。<br>
<code>线程中断规则</code>：对线程interrupt()方法的调用先行发生于被中断线程代码检测到中断事件的发生，可以通过Thread.interrupted()检测到是否发生中断。<br>
<code>传递性规则</code>：这个简单的，就是happens-before原则具有传递性，即hb(A, B) ， hb(B, C)，那么hb(A, C)。<br>
<code>对象终结规则</code>：这个也简单的，就是一个对象的初始化的完成，也就是构造函数执行的结束一定 happens-before它的finalize()方法。</p>
<h3 id="顺序一致性内存模型">顺序一致性内存模型</h3>
<p>顺序一致性内存模型是一个被计算机科学家理想化了的理论参考模型，它为程序员提供了极强的内存可见性保证。顺序一致性内存模型有两大特性：</p>
<ol>
<li>一个线程中的所有操作必须按照程序的顺序来执行。</li>
<li>（不管程序是否同步）所有线程都只能看到一个单一的操作执行顺序。在顺序一致性内存模型中，每个操作都必须原子执行且立刻对所有线程可见。</li>
</ol>
<p>在概念上，顺序一致性模型有一个单一的全局内存，这个内存通过一个开关可以连接到任意一个线程。同时，每一个线程必须按程序的顺序来执行内存读/写操作。在任意时间点最多只能有一个线程可以连接到内存。当多个线程并发执行时，开关装置能把所有线程的所有内存读/写操作串行化。</p>
<p>为了更好的理解，下面我们来对顺序一致性模型的特性做进一步的说明。</p>
<p>假设有两个线程A和B并发执行。其中A线程有三个操作，它们在程序中的顺序是：A1-&gt;A2-&gt;A3。B线程也有三个操作，它们在程序中的顺序是：B1-&gt;B2-&gt;B3。</p>
<p>假设这两个线程使用监视器来正确同步：A线程的三个操作执行后释放监视器，随后B线程获取同一个监视器。</p>
<p>现在我们再假设这两个线程没有做同步，未同步程序在顺序一致性模型中虽然整体执行顺序是无序的，但所有线程都只能看到一个一致的整体执行顺序。假设，线程A和B看到的执行顺序都是：B1-&gt;A1-&gt;A2-&gt;B2-&gt;A3-&gt;B3。之所以能得到这个保证是因为顺序一致性内存模型中的每个操作必须立即对任意线程可见。</p>
<p>但是，在JMM中就没有这个保证。未同步程序在JMM中不但整体的执行顺序是无序的，而且所有线程看到的操作执行顺序也可能不一致。比如，在当前线程把写过的数据缓存在本地内存中，且还没有刷新到主内存之前，这个写操作仅对当前线程可见；从其他线程的角度来观察，会认为这个写操作根本还没有被当前线程执行。只有当前线程把本地内存中写过的数据刷新到主内存之后，这个写操作才能对其他线程可见。在这种情况下，当前线程和其它线程看到的操作执行顺序将不一致。</p>
<p><strong>Java内存模型</strong></p>
<p>关于Java内存模型的书籍文章，汗牛充栋，想必大家也都有自己的理解。那就仅仅由上面的顺序一致性模型来引出JMM，看看具体区别在哪。<br>
<img src="https://mmbiz.qpic.cn/mmbiz_png/6fuT3emWI5L2ia8pMCBIIMcJS5mdJUl6qPH8FLPQnoyYbQDM3VsSQIB0m7wrvsm7QgPBGyhaMRmoOHV1cSHqbCA/640?tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></p>
<p>可以看出，本地内存是一个明显区别于顺序一致性内存模型的地方。事实上，造成可见性问题的根源之一，就在于这个本地内存（强调一下，包括缓存、写缓冲和寄存器等等）。本地内存使得每个线程都有了自己的私有存储，大部分时间对数据的存取工作都在这个区域完成。但是我们写一个数据，是直到数据写到主存中才算真正完成。实际上每个线程维护了一个<strong>副本</strong>，所有线程都在自己的本地内存中不断地读/写一个共享内存中的数据的副本。单线程情况下，这个副本不会造成任何问题；但一旦到多线程，有一个线程将变量写到主存，其他线程却不知道，其他线程的副本就都过期。比如，由于本地内存的存在，程序员写的一段代码，写一个普通的共享变量，其可能先被写到缓冲区，那指令完成的时间就被推迟了，实际表现也就是我们常说的“指令重排序”（这实际上是内存模型层面的重排序，重排序还可能是编译器、机器指令层级上的乱序）。</p>
<p>因此，在Java内存模型中，每个线程不再像顺序一致性模型中那样有确定的指令执行视图，一个指令可能被重排了。从一个线程的角度看，其他线程（甚至是这个线程本身）执行的指令顺序有多种可能性，也就是说，一个线程的执行结果对其他线程的可见性无法保证。</p>
<p>总结一下导致可见性问题的原因：</p>
<ol>
<li>数据的写无法及时通知到别的线程，如写缓冲区的引入</li>
<li>线程不能及时读到其他线程对共享变量的修改，如缓存的使用</li>
<li>各种层级上对指令的重排序，导致指令执行的顺序无法确定</li>
</ol>
<p>所以要解决可见性问题，本质是要让线程对共享变量的修改，及时同步到其他线程。我们所使用的硬件架构下，不具备顺序一致性内存模型的全局一致的指令执行顺序，<strong>讨论指令执行的时间先后并不存在意义或者说根本没办法确定时间上的先后</strong>。可以看看下面程序，每个线程中的flag副本会在多久后被更新呢？答案是：无法确定，看线程何时刷新自己的本地内存。</p>
<pre><code class="language-java">public class testVisibility {
    public static boolean flag = false;

    public static void main(String[] args) {
        List&lt;Thread&gt; thdList = new ArrayList&lt;Thread&gt;();
        for(int i = 0; i &lt; 10; i++) {
            Thread t = new Thread(new Runnable(){
                public void run() {
                    while (true) {
                        if (flag) {
                            // 多运行几次，可能并不会打印出来也可能会打印出来
                            // 如果不打印，则表示Thread看到的仍然是本地内存中的flag
                            // 可以尝试将flag变成volatile再运行几次看看
                                  System.out.println(Thread.currentThread().getId() + &quot; is true now&quot;); 
                        }
                    }
                }
            });
            t.start();
            thdList.add(t);
        }

        flag = true;
        System.out.println(&quot;set flag true&quot;);

        // 等待线程执行完毕
        try {
            for (Thread t : thdList) {
                t.join();
            }
        } catch (Exception e) {

        }
    }
}
</code></pre>
<p>那么既然我们无法讨论指令执行的先后，也不需要讨论，我们实际只想知道某线程的操作对另一个线程是否可见，于是就规定了happens-before这个<strong>可见性原则</strong>，程序员可以基于这个原则进行可见性的判断。</p>
<h2 id="volatile原理">Volatile原理</h2>
<p>Java语言提供了一种稍弱的同步机制，即volatile变量，用来确保将变量的更新操作通知到其他线程。当把变量声明为volatile类型后，编译器与运行时都会注意到这个变量是共享的，因此不会将该变量上的操作与其他内存操作一起重排序。volatile变量不会被缓存在寄存器或者对其他处理器不可见的地方，因此在读取volatile类型的变量时总会返回最新写入的值。</p>
<p>在访问volatile变量时不会执行加锁操作，因此也就不会使执行线程阻塞，因此<code>volatile</code>变量是一种比<code>sychronized</code>关键字更轻量级的同步机制。<br>
<img src="https://tinaxiawuhao.github.io/post-images/1619330405178.png" alt="" loading="lazy"></p>
<p>当对非 volatile 变量进行读写的时候，每个线程先从内存拷贝变量到CPU缓存中。如果计算机有多个CPU，每个线程可能在不同的CPU上被处理，这意味着每个线程可以拷贝到不同的 CPU cache 中。</p>
<p>而声明变量是 volatile 的，JVM 保证了每次读变量都从内存中读，跳过 CPU cache 这一步。</p>
<p><strong>当一个变量定义为 volatile 之后，将具备两种特性：</strong></p>
<p>1. 保证此变量对所有的线程的可见性，这里的“可见性”，如本文开头所述，当一个线程修改了这个变量的值，volatile 保证了新值能立即同步到主内存，以及每次使用前立即从主内存刷新。但普通变量做不到这点，普通变量的值在线程间传递均需要通过主内存来完成。</p>
<p>2. 禁止指令重排序优化。有volatile修饰的变量，赋值后多执行了一个添加<strong>内存屏障</strong>操作（指令重排序时不能把后面的指令重排序到内存屏障之前的位置），只有一个CPU访问内存时，并不需要内存屏障；（什么是指令重排序：是指CPU采用了允许将多条指令不按程序规定的顺序分开发送给各相应电路单元处理）。</p>
<p><strong>volatile 性能：</strong></p>
<p>volatile 的读性能消耗与普通变量几乎相同，但是写操作稍慢，因为它需要在本地代码中插入许多内存屏障指令来保证处理器不发生乱序执行。</p>
<h3 id="volatile变量">volatile变量</h3>
<p>volatile就是一个践行happens-before的关键字。看以下对volatile的描述，就不难知道，happens-before指的是线程<strong>接收其他线程修改共享变量的消息</strong>与该线程<strong>读取共享变量</strong>的<strong>先后关系</strong>。大家可以再细想一下，如果没有happens-before原则，岂不是相当于一个线程读取自己的共享变量副本时，其他线程修改这个变量的消息还没有同步过来？这就是可见性问题。</p>
<p><strong>volatile变量规则</strong>：对一个volatile的写，happens-before于任意后续对这个volatile变量的读。</p>
<p><strong>线程A写一个volatile变量</strong>，实质上是线程A向接下来要获取这个锁的某个线程发出了（线程A对共享变量修改的）消息。</p>
<p><strong>线程B读一个volatile变量</strong>，实质上是线程B接收了之前某个线程发出的（对共享变量所做修改的）消息。</p>
<p><strong>线程A写一个volatile变量，随后线程B读这个变量</strong>，这个过程实质上是线程A通过主内存向线程B发送消息。</p>
<p>其实仔细看看volatile的实现方式，实际上就是限制了重排序的范围——加入内存屏障(Memory Barrier or Memory Fence)。也即是说，允许指令执行的时间先后顺序在一定范围内发生变化，而这个范围就是根据happens-before原则来规定。内存屏障概括起来有两个功能：</p>
<ol>
<li>使写缓冲区的内容刷新到内存，保证对其他线程/CPU可见</li>
<li>禁止读写操作的越过内存屏障进行重排序</li>
</ol>
<p>每个volatile写操作的前面插入一个<code>StoreStore</code>屏障</p>
<p>每个volatile写操作的后面插入一个<code>StoreLoad</code>屏障</p>
<p>每个volatile读操作的后面插入一个<code>LoadLoad</code>屏障</p>
<p>每个volatile读操作的后面插入一个<code>LoadStore</code>屏障</p>
<p>关于内存屏障的种类，这里不是研究的重点。一直困扰我的是，在多处理器系统下，这个屏障如何能跨越处理器来阻止操作执行的顺序呢？比如下面的读写操作：</p>
<pre><code class="language-java">public static volatile int race = 0;
// Thread A
public static void save(int src) {
    race = src;
}
// Thread B
public static int load() {
    return race;
}
</code></pre>
<p>这就要提到从操作系统到硬件层面的观念转换，可以参看总线事务（Bus transaction）的概念。当CPU要与内存进行数据交换的时候，实际上总线会同步数据交换操作，同一时刻只能有一个CPU进行读/写内存，所以我们所看到的多处理器并行，并行的是CPU的计算资源。在总线看来，对于存储的读写操作就是串行的，是按照一定顺序的。这也就是为什么一个内存屏障能够跨越处理器去限制读写、去完成通信。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java内存模型JMM]]></title>
        <id>https://tinaxiawuhao.github.io/post/rNVfAh0Yb/</id>
        <link href="https://tinaxiawuhao.github.io/post/rNVfAh0Yb/">
        </link>
        <updated>2021-04-28T05:31:21.000Z</updated>
        <content type="html"><![CDATA[<h2 id="为什么要有内存模型">为什么要有内存模型</h2>
<p>在介绍Java内存模型之前，先来看一下到底什么是计算机内存模型，然后再来看Java内存模型在计算机内存模型的基础上做了哪些事情。要说计算机的内存模型，就要说一下一段古老的历史，看一下为什么要有内存模型。</p>
<p><strong>内存模型，英文名Memory Model，他是一个很老的老古董了。他是与计算机硬件有关的一个概念。那么我先给你介绍下他和硬件到底有啥关系。</strong></p>
<h3 id="cpu和缓存一致性">CPU和缓存一致性</h3>
<p>我们应该都知道，计算机在执行程序的时候，每条指令都是在CPU中执行的，而执行的时候，又免不了要和数据打交道。而计算机上面的数据，是存放在主存当中的，也就是计算机的物理内存啦。</p>
<p>刚开始，还相安无事的，但是随着CPU技术的发展，CPU的执行速度越来越快。而由于内存的技术并没有太大的变化，所以从内存中读取和写入数据的过程和CPU的执行速度比起来差距就会越来越大,这就导致CPU每次操作内存都要耗费很多等待时间。</p>
<blockquote>
<p>这就像一家创业公司，刚开始，创始人和员工之间工作关系其乐融融，但是随着创始人的能力和野心越来越大，逐渐和员工之间出现了差距，普通员工原来越跟不上CEO的脚步。老板的每一个命令，传到到基层员工之后，由于基层员工的理解能力、执行能力的欠缺，就会耗费很多时间。这也就无形中拖慢了整家公司的工作效率。</p>
</blockquote>
<p>可是，不能因为内存的读写速度慢，就不发展CPU技术了吧，总不能让内存成为计算机处理的瓶颈吧。</p>
<p>所以，人们想出来了一个好的办法，就是在CPU和内存之间增加高速缓存。缓存的概念大家都知道，就是保存一份数据拷贝。他的特点是速度快，内存小，并且昂贵。</p>
<p>那么，程序的执行过程就变成了：</p>
<p><strong>当程序在运行过程中，会将运算需要的数据从主存复制一份到CPU的高速缓存当中，那么CPU进行计算时就可以直接从它的高速缓存读取数据和向其中写入数据，当运算结束之后，再将高速缓存中的数据刷新到主存当中。</strong></p>
<blockquote>
<p>之后，这家公司开始设立中层管理人员，管理人员直接归CEO领导，领导有什么指示，直接告诉管理人员，然后就可以去做自己的事情了。管理人员负责去协调底层员工的工作。因为管理人员是了解手下的人员以及自己负责的事情的。所以，大多数时候，公司的各种决策，通知等，CEO只要和管理人员之间沟通就够了。</p>
</blockquote>
<p>而随着CPU能力的不断提升，一层缓存就慢慢的无法满足要求了，就逐渐的衍生出多级缓存。</p>
<p>按照数据读取顺序和与CPU结合的紧密程度，CPU缓存可以分为一级缓存（L1），二级缓存（L2），部分高端CPU还具有三级缓存（L3），每一级缓存中所储存的全部数据都是下一级缓存的一部分。</p>
<p>这三种缓存的技术难度和制造成本是相对递减的，所以其容量也是相对递增的。</p>
<p>那么，在有了多级缓存之后，程序的执行就变成了：</p>
<p><strong>当CPU要读取一个数据时，首先从一级缓存中查找，如果没有找到再从二级缓存中查找，如果还是没有就从三级缓存或内存中查找。</strong></p>
<blockquote>
<p>随着公司越来越大，老板要管的事情越来越多，公司的管理部门开始改革，开始出现高层，中层，底层等管理者。一级一级之间逐层管理。</p>
</blockquote>
<p>单核CPU只含有一套<code>L1</code>，<code>L2</code>，<code>L3</code>缓存；</p>
<p>如果CPU含有多个核心，即多核CPU，则每个核心都含有一套<code>L1</code>（甚至和<code>L2</code>）缓存，而共享<code>L3</code>（或者和<code>L2</code>）缓存。</p>
<blockquote>
<p>公司也分很多种，有些公司只有一个大Boss，他一个人说了算。但是有些公司有比如联席总经理、合伙人等机制。</p>
<p>单核CPU就像一家公司只有一个老板，所有命令都来自于他，那么就只需要一套管理班底就够了。</p>
<p>多核CPU就像一家公司是由多个合伙人共同创办的，那么，就需要给每个合伙人都设立一套供自己直接领导的高层管理人员，多个合伙人共享使用的是公司的底层员工。</p>
<p>还有的公司，不断壮大，开始差分出各个子公司。各个子公司就是多个CPU了，互相之前没有共用的资源。互不影响。</p>
</blockquote>
<p>下图为一个单CPU双核的缓存结构。</p>
<figure data-type="image" tabindex="1"><img src="https://mmbiz.qpic.cn/mmbiz_png/6fuT3emWI5L2ia8pMCBIIMcJS5mdJUl6qbVptr1SL2RchPZB8opYbGz1A465IJmufub0NCHo0Pa3koVDQAvqGtA/640?tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<p>随着计算机能力不断提升，开始支持多线程。那么问题就来了。我们分别来分析下单线程、多线程在单核CPU、多核CPU中的影响。</p>
<p><strong>单线程。</strong><code>cpu</code>核心的缓存只被一个线程访问。缓存独占，不会出现访问冲突等问题。</p>
<p><strong>单核CPU，多线程</strong>进程中的多个线程会同时访问进程中的共享数据，CPU将某块内存加载到缓存后，不同线程在访问相同的物理地址的时候，都会映射到相同的缓存位置，这样即使发生线程的切换，缓存仍然不会失效。但由于任何时刻只能有一个线程在执行，因此不会出现缓存访问冲突。</p>
<p><strong>多核CPU，多线程</strong>每个核都至少有一个<code>L1</code> 缓存。多个线程访问进程中的某个共享内存，且这多个线程分别在不同的核心上执行，则每个核心都会在各自的<code>caehe</code>中保留一份共享内存的缓冲。由于多核是可以并行的，可能会出现多个线程同时写各自的缓存的情况，而各自的cache之间的数据就有可能不同。</p>
<p>在CPU和主存之间增加缓存，在多线程场景下就可能存在<strong>缓存一致性问题</strong>，也就是说，在多核CPU中，每个核的自己的缓存中，关于同一个数据的缓存内容可能不一致。</p>
<blockquote>
<p>如果这家公司的命令都是串行下发的话，那么就没有任何问题。</p>
<p>如果这家公司的命令都是并行下发的话，并且这些命令都是由同一个CEO下发的，这种机制是也没有什么问题。因为他的命令执行者只有一套管理体系。</p>
<p>如果这家公司的命令都是并行下发的话，并且这些命令是由多个合伙人下发的，这就有问题了。因为每个合伙人只会把命令下达给自己直属的管理人员，而多个管理人员管理的底层员工可能是公用的。</p>
<p>比如，合伙人1要辞退员工a，合伙人2要给员工a升职，升职后的话他再被辞退需要多个合伙人开会决议。两个合伙人分别把命令下发给了自己的管理人员。合伙人1命令下达后，管理人员a在辞退了员工后，他就知道这个员工被开除了。而合伙人2的管理人员2这时候在没得到消息之前，还认为员工a是在职的，他就欣然的接收了合伙人给他的升职a的命令。</p>
</blockquote>
<figure data-type="image" tabindex="2"><img src="https://mmbiz.qpic.cn/mmbiz_png/6fuT3emWI5L2ia8pMCBIIMcJS5mdJUl6q0yeGmFNvrp5MmQicGwicCDVjQsE45SdqWk2T3qGVfgR4Sur5We04FJaA/640?tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<h3 id="处理器优化和指令重排">处理器优化和指令重排</h3>
<p>上面提到在在CPU和主存之间增加缓存，在多线程场景下会存在<strong>缓存一致性问题</strong>。除了这种情况，还有一种硬件问题也比较重要。那就是为了使处理器内部的运算单元能够尽量的被充分利用，处理器可能会对输入代码进行乱序执行处理。这就是<strong>处理器优化</strong>。</p>
<p>除了现在很多流行的处理器会对代码进行优化乱序处理，很多编程语言的编译器也会有类似的优化，比如Java虚拟机的<code>即时编译器（JIT</code>）也会做<strong>指令重排</strong>。</p>
<p>可想而知，如果任由处理器优化和编译器对指令重排的话，就可能导致各种各样的问题。</p>
<blockquote>
<p>关于员工组织调整的情况，如果允许人事部在接到多个命令后进行随意拆分乱序执行或者重排的话，那么对于这个员工以及这家公司的影响是非常大的。</p>
</blockquote>
<h2 id="并发编程的问题">并发编程的问题</h2>
<p>前面说的和硬件有关的概念你可能听得有点蒙，还不知道他到底和软件有啥关系。但是关于并发编程的问题你应该有所了解，比如原子性问题，可见性问题和有序性问题。</p>
<p>其实，原子性问题，可见性问题和有序性问题。是人们抽象定义出来的。而这个抽象的底层问题就是前面提到的缓存一致性问题、处理器优化问题和指令重排问题等。</p>
<p>这里简单回顾下这三个问题，并不准备深入展开，感兴趣的读者可以自行学习。我们说，并发编程，为了保证数据的安全，需要满足以下三个特性：</p>
<p><strong>原子性</strong>是指在一个操作中就是cpu不可以在中途暂停然后再调度，既不被中断操作，要不执行完成，要不就不执行。</p>
<p><strong>可见性</strong>是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。</p>
<p><strong>有序性</strong>即程序执行的顺序按照代码的先后顺序执行。</p>
<p>有没有发现，<strong>缓存一致性问题</strong>其实就是<strong>可见性问题</strong>。而<strong>处理器优化</strong>是可以导致<strong>原子性问题</strong>的。<strong>指令重排</strong>即会导致<strong>有序性问题</strong>。所以，后文将不再提起硬件层面的那些概念，而是直接使用大家熟悉的原子性、可见性和有序性。</p>
<h3 id="什么是内存模型">什么是内存模型</h3>
<p>前面提到的，缓存一致性问题、处理器器优化的指令重排问题是硬件的不断升级导致的。那么，有没有什么机制可以很好的解决上面的这些问题呢？</p>
<p>最简单直接的做法就是废除处理器和处理器的优化技术、废除CPU缓存，让CPU直接和主存交互。但是，这么做虽然可以保证多线程下的并发问题。但是，这就有点因噎废食了。</p>
<p>所以，为了保证并发编程中可以满足原子性、可见性及有序性。有一个重要的概念，那就是——内存模型。</p>
<p><strong>为了保证共享内存的正确性（可见性、有序性、原子性），内存模型定义了共享内存系统中多线程程序读写操作行为的规范</strong>通过这些规则来规范对内存的读写操作，从而保证指令执行的正确性。它与处理器有关、与缓存有关、与并发有关、与编译器也有关。他解决了CPU多级缓存、处理器优化、指令重排等导致的内存访问问题，保证了并发场景下的一致性、原子性和有序性。</p>
<p>内存模型解决并发问题主要采用两种方式：<strong>限制处理器优化</strong>和<strong>使用内存屏障</strong>。本文就不深入底层原理来展开介绍了，感兴趣的朋友可以自行学习。</p>
<h3 id="什么是java内存模型">什么是Java内存模型</h3>
<p>前面介绍过了计算机内存模型，这是解决多线程场景下并发问题的一个重要规范。那么具体的实现是如何的呢，不同的编程语言，在实现上可能有所不同。</p>
<p>我们知道，Java程序是需要运行在Java虚拟机上面的，<strong>Java内存模型（Java Memory Model ,JMM）就是一种符合内存模型规范的，屏蔽了各种硬件和操作系统的访问差异的，保证了Java程序在各种平台下对内存的访问都能保证效果一致的机制及规范。</strong></p>
<p>提到Java内存模型，一般指的是<code>JDK 5</code>开始使用的新的内存模型，主要由<code>JSR-133: JavaTM Memory Model and Thread Specification</code>描述。感兴趣的可以参看下这份<code>PDF</code>文档（http://www.cs.umd.edu/~pugh/java/memoryModel/jsr133.pdf）</p>
<p>Java内存模型规定了所有的变量都存储在主内存中，每条线程还有自己的工作内存，线程的工作内存中保存了该线程中是用到的变量的主内存副本拷贝，线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量的传递均需要自己的工作内存和主存之间进行数据同步进行。</p>
<p>而<code>JMM</code>就作用于工作内存和主存之间数据同步过程。他规定了如何做数据同步以及什么时候做数据同步。</p>
<figure data-type="image" tabindex="3"><img src="https://mmbiz.qpic.cn/mmbiz_png/6fuT3emWI5L2ia8pMCBIIMcJS5mdJUl6qPH8FLPQnoyYbQDM3VsSQIB0m7wrvsm7QgPBGyhaMRmoOHV1cSHqbCA/640?tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<p>这里面提到的主内存和工作内存，读者可以简单的类比成计算机内存模型中的主存和缓存的概念。特别需要注意的是，主内存和工作内存与<code>JVM</code>内存结构中的Java堆、栈、方法区等并不是同一个层次的内存划分，无法直接类比。《深入理解Java虚拟机》中认为，如果一定要勉强对应起来的话，从变量、主内存、工作内存的定义来看，主内存主要对应于Java堆中的对象实例数据部分。工作内存则对应于虚拟机栈中的部分区域。</p>
<p><strong>所以，再来总结下，JMM是一种规范，目的是解决由于多线程通过共享内存进行通信时，存在的本地内存数据不一致、编译器会对代码指令重排序、处理器会对代码乱序执行等带来的问题。目的是保证并发编程场景中的原子性、可见性和有序性。</strong></p>
<h3 id="java内存模型的实现">Java内存模型的实现</h3>
<p>了解Java多线程的朋友都知道，在Java中提供了一系列和并发处理相关的关键字，比如<code>volatile</code>、<code>synchronized</code>、<code>final</code>、<code>concurrent</code>包等。其实这些就是Java内存模型封装了底层的实现后提供给程序员使用的一些关键字。</p>
<p>在开发多线程的代码的时候，我们可以直接使用<code>synchronized</code>等关键字来控制并发，从来就不需要关心底层的编译器优化、缓存一致性等问题。所以，<strong>Java内存模型，除了定义了一套规范，还提供了一系列原语，封装了底层实现后，供开发者直接使用。</strong></p>
<p>本文并不准备把所有的关键字逐一介绍其用法，因为关于各个关键字的用法，网上有很多资料。读者可以自行学习。本文还有一个重点要介绍的就是，我们前面提到，并发编程要解决原子性、有序性和一致性的问题，我们就再来看下，在Java中，分别使用什么方式来保证。</p>
<h3 id="原子性">原子性</h3>
<p>在Java中，为了保证原子性，提供了两个高级的字节码指令<code>monitorenter</code>和<code>monitorexit</code>。在<a href="http://mp.weixin.qq.com/s?__biz=MzI3NzE0NjcwMg==&amp;mid=2650120537&amp;idx=1&amp;sn=f56201217c0ca6fde45ee12965b56296&amp;chksm=f36bbc78c41c356ee363367addcdc0b311afb2f9df86a7ee20d21348b3332fd64f273d6028ca&amp;scene=21#wechat_redirect">synchronized的实现原理</a>文章中，介绍过，这两个字节码，在Java中对应的关键字就是<code>synchronized</code>。</p>
<p>因此，在Java中可以使用<code>synchronized</code>来保证方法和代码块内的操作是原子性的。</p>
<h3 id="可见性">可见性</h3>
<p>Java内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值的这种依赖主内存作为传递媒介的方式来实现的。</p>
<p>Java中的<code>volatile</code>关键字提供了一个功能，那就是被其修饰的变量在被修改后可以立即同步到主内存，被其修饰的变量在每次是用之前都从主内存刷新。因此，可以使用<code>volatile</code>来保证多线程操作时变量的可见性。</p>
<p>除了<code>volatile</code>，Java中的<code>synchronized</code>和<code>final</code>两个关键字也可以实现可见性。只不过实现方式不同，被synchronized修饰的代码，在开始执行时会加锁，执行完成后会进行解锁，但在一个变量解锁之前，必须先把此变量同步回主存中，这样解锁后，后续其它线程就可以访问到被修改后的值，从而保证可见性。</p>
<h3 id="有序性">有序性</h3>
<p>在Java中，可以使用<code>synchronized</code>和<code>volatile</code>来保证多线程之间操作的有序性。实现方式有所区别：</p>
<p><code>volatile</code>关键字会禁止指令重排。<code>synchronized</code>关键字保证同一时刻只允许一条线程操作。</p>
<p>好了，这里简单的介绍完了Java并发编程中解决原子性、可见性以及有序性可以使用的关键字。读者可能发现了，好像<code>synchronized</code>关键字是万能的，他可以同时满足以上三种特性，这其实也是很多人滥用<code>synchronized</code>的原因。</p>
<p>但是<code>synchronized</code>是比较影响性能的，虽然编译器提供了很多锁优化技术，但是也不建议过度使用。</p>
<h2 id="总结">总结</h2>
<p>在读完本文之后，相信你应该了解了什么是Java内存模型、Java内存模型的作用以及Java中内存模型做了什么事情等。</p>
<p>关于Java中这些和内存模型有关的关键字，希望读者还可以继续深入学习，并且自己写几个例子亲自体会一下。可以参考《深入理解Java虚拟机》和《Java并发编程的艺术》两本书。</p>
<h2 id="面试如何回答">面试如何回答</h2>
<p>前面我介绍完了一些和Java内存模型有关的基础知识，只是基础，并不是全部，因为随便一个知识点还是都可以展开的，如volatile是如何实现可见性的？synchronized是如何实现有序性的？</p>
<p>但是，当面试官问你：能简单介绍下你理解的内存模型吗？</p>
<p>首先，先和面试官确认一下：您说的内存模型指的是<code>JMM</code>，也就是和并发编程有关的那一个吧？</p>
<p>在得到肯定答复后，再开始介绍（如果不是，那可能就要回答堆、栈、方法区哪些了….囧…）：</p>
<p>Java内存模型，其实是保证了Java程序在各种平台下对内存的访问都能够得到一致效果的机制及规范。目的是解决由于多线程通过共享内存进行通信时，存在的原子性、可见性（缓存一致性）以及有序性问题。</p>
<p>除此之外，Java内存模型还提供了一系列原语，封装了底层实现后，供开发者直接使用。如我们常用的一些关键字：synchronized、volatile以及并发包等。</p>
<p>回答到这里就可以了，然后面试官可能会继续追问，然后根据他的追问再继续往下回答即可。</p>
<p>所以，当有人再问你Java内存模型的时候，不要一张嘴就直接回答堆栈、方法区甚至<code>GC</code>了，那样显得很不专业！</p>
<blockquote>
<p>作者： Hollis<br>
原文地址：<a href="https://mp.weixin.qq.com/s?__biz=MzI3NzE0NjcwMg==&amp;mid=2650121599&amp;idx=1&amp;sn=42b2cfabfb3057ac6c09026a8b9656cd&amp;chksm=f36bb85ec41c31489e461a53e78f2959f0224c87c312724f420265b70e67e4efdae2331155aa&amp;scene=21#wechat_redirect">Java内存模型</a></p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ JVM 的核心知识梳理]]></title>
        <id>https://tinaxiawuhao.github.io/post/8iu5aa5DN/</id>
        <link href="https://tinaxiawuhao.github.io/post/8iu5aa5DN/">
        </link>
        <updated>2021-04-27T03:20:47.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<h2 id="运行时数据区域">运行时数据区域</h2>
<h3 id="java虚拟机运行时有哪些数据区域他们都有什么用途">java虚拟机运行时有哪些数据区域，他们都有什么用途？</h3>
<p>有<code>程序计数器</code>、<code>java虚拟机栈</code>、<code>本地方法栈</code>、<code>堆</code>和<code>方法区</code>五大模块。请看下图：<br>
<img src="https://tinaxiawuhao.github.io/post-images/1619321084766.png" alt="" loading="lazy"></p>
<h3 id="程序计数器">程序计数器</h3>
<p>程序计数器是一块较小的内存空间，他可以看做是当期线程所执行的字节码的行号指令器。字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令。在任何一个确定的时刻，一个处理器都只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各个线程之间互不影响，独立存储，所以程序计数器是“线程私有的”。另外，程序计数器是唯一一个在java虚拟机规范中没有规定OOM的区域。</p>
<h3 id="java虚拟机栈">Java虚拟机栈</h3>
<p>Java虚拟机栈也是线程私有的，它的生命周期与线程相同，虚拟机栈描述的是Java方法执行的内存模型，每个方法在执行的同时都会创建一个栈帧用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每个方法从调用直至执行完成的过程，对应着一个栈帧在虚拟机栈中入栈到出栈的过程。（程序员经常会把Java内存划分为堆内存和栈内存，这种说法比较粗糙，其中的栈内存就是指虚拟机栈，或者说是虚拟机栈中的局部变量表的部分）</p>
<p>在Java虚拟机规范中，对这个区域规定了两种异常：如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverFlowError异常。如果虚拟机栈可以动态扩展，如果扩展时无法申请到足够的内存，就会抛出OOM异常。</p>
<h3 id="本地方法栈">本地方法栈</h3>
<p>本地方法栈与虚拟机栈作用类似，他们之间的区别不过是虚拟机栈是为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则为虚拟机使用到的Native方法服务。与虚拟机栈一样，本地方法栈也会抛出StackOverFlowError异常和OOM异常。</p>
<h3 id="堆">堆</h3>
<p>Java堆是Java虚拟机管理的最大的一块内存，是所有线程共享的区域，在虚拟机启动时就创建。堆用来存放对象实例，几乎所有的对象实例都在这里分配内存（注意是几乎所有）。这一点在Java虚拟机规范中描述为：所有的对象实例以及数组都要在堆上分配，但随着JIT编译器的发展和逃逸分析技术的成熟，栈上分配、标量替换技术将会导致一些微妙的变化发生，所有对象都分配在堆上也不是那么绝对了。</p>
<p>如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OOM异常。</p>
<h3 id="方法区">方法区</h3>
<p>方法区与Java堆一样，是各个线程共享的区域，它用来存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。根据Java虚拟机规范，当方法区无法满足内存分配的 需求时，将抛出OOM异常。</p>
<p>运行时常量池是方法区的一部分，用于存放编译器生成的各种字面量和符号引用。运行时常量池相对于Class文件常量池的另外一个重要特征就是具备动态性。也就是说运行期间也可能将新的常量 放入池中，这种特性被利用的比较多的就是String类的intern()方法。</p>
<h3 id="直接内存">直接内存</h3>
<p>直接内存并不是运行时数据区的一部分，也不是Java虚拟机定义的内存区域。本机直接内存的分配不受Java堆大小的限制，但是受本机总内存大小以及处理器寻址空间的限制。</p>
<h2 id="内存溢出">内存溢出</h2>
<h3 id="堆内存溢出">堆内存溢出</h3>
<p>Java堆用于存储对象实例，只要不断创建对象，并且保证GC Roots到对象之间有可达路径来避免垃圾回收机制清除这些对象，那么在对象数量达到最大堆容量限制后就会OOM。（轻易不要运行）</p>
<pre><code class="language-java">public class HeapOOMTest {
    
    static class OOMObject {
        
    }
    
    public static void main(String [] args) {
        List&lt;OOMObject&gt; list = new ArrayList&lt;&gt;();
        while (true) {
            list.add(new OOMObject());
        }
    }
}
</code></pre>
<p>Java堆内存的OOM异常是实际应用中最常见的内存溢出，当出现了咋办？一般的手段是先通过内存映像分析工具对Dump出来的堆转储快照进行分析，重点是确认内存中的对象是否是必要的，也就是确认是内存泄露还是内存溢出。</p>
<p>如果是内存泄露，可进一步通过工具查看泄露对象到GCRoots的引用链，找到为什么垃圾收集器无法回收它们。如果不存在泄露，就是内存中的对象必须都存活，那就要检查虚拟机的堆内存是否可以调大，从代码上检查是否某些对象生命周期过长，减少内存消耗，优化代码。</p>
<h3 id="虚拟机栈溢出">虚拟机栈溢出</h3>
<p>关于虚拟机栈，在java虚拟机规范中描述了两种异常：</p>
<p>（1）如果线程请求的栈深度大于虚拟机所允许的最大深度，将抛出StackOverFlowError异常。</p>
<p>（2）如果虚拟机在扩展栈时无法申请到足够的内存空间，则抛出OutOdMemoryError异常。</p>
<p>这里描述的两种情况实际上有些重叠：当栈空间无法继续分配的时候，到底是内存太小导致的，还是已使用的栈空间太大，本质上是一样的。</p>
<pre><code class="language-java">public class StackSOFTest {

    private int stackLength = -1;

    public void stackLeak() {
        stackLength++;
        stackLeak();
    }

    public static void main(String [] args) throws Throwable {
        StackSOFTest oom = new StackSOFTest();
        try {
            oom.stackLeak();
        } catch (Throwable e) {
            System.out.println(&quot;stack length:&quot;+oom.stackLength);
            throw e;
        }
    }
}
</code></pre>
<p>运行结果：</p>
<pre><code class="language-java">tack length:13980
Exception in thread &quot;main&quot; java.lang.StackOverflowError
    at oom.StackSOFTest.stackLeak(StackSOFTest.java:14)
    at oom.StackSOFTest.stackLeak(StackSOFTest.java:14)
    at oom.StackSOFTest.stackLeak(StackSOFTest.java:14)
    ...后续省略
</code></pre>
<p>实验结果表明：在单个线程下，无论是由于栈帧太大还是虚拟机栈容量太小，当内存无法分配时，虚拟机抛出的都是StackOverflowError异常。</p>
<h3 id="哪些内存需要回收">哪些内存需要回收？</h3>
<p>猿们都知道JVM的内存结构包括五大区域：程序计数器、虚拟机栈、本地方法栈、堆区、方法区。其中程序计数器、虚拟机栈、本地方法栈3个区域随线程而生、随线程而灭，因此这几个区域的内存分配和回收都具备确定性，就不需要过多考虑回收的问题，因为方法结束或者线程结束时，内存自然就跟随着回收了。而Java堆区和方法区则不一样、不一样!(怎么不一样说的朗朗上口)，这部分内存的分配和回收是动态的，正是垃圾收集器所需关注的部分。</p>
<p>垃圾收集器在对堆区和方法区进行回收前，首先要确定这些区域的对象哪些可以被回收，哪些暂时还不能回收，这就要用到判断对象是否存活的算法！（面试官肯定没少问你吧）</p>
<h4 id="21-引用计数算法">2.1 引用计数算法</h4>
<p><strong>2.1.1 算法分析</strong></p>
<p>引用计数是垃圾收集器中的早期策略。在这种方法中，堆中每个对象实例都有一个引用计数。当一个对象被创建时，就将该对象实例分配给一个变量，该变量计数设置为1。当任何其它变量被赋值为这个对象的引用时，计数加1（a = b,则b引用的对象实例的计数器+1），但当一个对象实例的某个引用超过了生命周期或者被设置为一个新值时，对象实例的引用计数器减1。任何引用计数器为0的对象实例可以被当作垃圾收集。当一个对象实例被垃圾收集时，它引用的任何对象实例的引用计数器减1。</p>
<p><strong>2.1.2 优缺点</strong></p>
<p><strong>优点</strong>：引用计数收集器可以很快的执行，交织在程序运行中。对程序需要不被长时间打断的实时环境比较有利。</p>
<p><strong>缺点</strong>：无法检测出循环引用。如父对象有一个对子对象的引用，子对象反过来引用父对象。这样，他们的引用计数永远不可能为0。</p>
<p><strong>2.1.3 是不是很无趣，来段代码压压惊</strong></p>
<pre><code class="language-java">public class ReferenceFindTest {
    public static void main(String[] args) {
        MyObject object1 = new MyObject();
        MyObject object2 = new MyObject();
          
        object1.object = object2;
        object2.object = object1;
          
        object1 = null;
        object2 = null;
    }
}
</code></pre>
<p>这段代码是用来验证引用计数算法不能检测出循环引用。最后面两句将object1和object2赋值为null，也就是说object1和object2指向的对象已经不可能再被访问，但是由于它们互相引用对方，导致它们的引用计数器都不为0，那么垃圾收集器就永远不会回收它们。</p>
<h4 id="22-可达性分析算法">2.2 可达性分析算法</h4>
<p>可达性分析算法是从离散数学中的图论引入的，程序把所有的引用关系看作一张图，从一个节点GC ROOT开始，寻找对应的引用节点，找到这个节点以后，继续寻找这个节点的引用节点，当所有的引用节点寻找完毕之后，剩余的节点则被认为是没有被引用到的节点，即无用的节点，无用的节点将会被判定为是可回收的对象。</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1631165973388.jpeg" alt="" loading="lazy"></figure>
<p>在Java语言中，可作为GC Roots的对象包括下面几种：</p>
<p>a) 虚拟机栈中引用的对象（栈帧中的本地变量表）；</p>
<p>b) 方法区中类静态属性引用的对象；</p>
<p>c) 方法区中常量引用的对象；</p>
<p>d) 本地方法栈中JNI（Native方法）引用的对象。</p>
<h2 id="对象是生是死">对象是“生”是“死</h2>
<h3 id="对象的四种引用">对象的四种引用</h3>
<p>引用分为<code>强引用</code>，<code>软引用</code>，<code>弱引用</code>和<code>虚引用</code>四种，这四种引用强度依次逐渐减弱。</p>
<h4 id="强引用">强引用</h4>
<blockquote>
<p>强引用就是指在程序代码中普遍存在的，是指创建一个对象并把这个对象赋给一个引用变量，类似Object obj = new Object()这类的引用，只要强引用还存在，垃圾收集器就永远不会回收被引用的对象。如果想中断强引用和某个对象之间的关联，可以显示的将引用赋值为null，这样jvm在合适的时间就会回收该对象。</p>
</blockquote>
<h4 id="软引用">软引用</h4>
<blockquote>
<p>软引用是用来描述一些还有用但并非必需的对象。对于软引用关联着的对象，在系统将会发生内存溢出异常之前，将会把这些对象列进回收范围之中进行第二次回收。SoftReference的特点是它的一个实例保存对一个Java对象的软引用，该软引用的存在不妨碍垃圾收集器线程对该Java对象的回收。</p>
</blockquote>
<h4 id="弱引用">弱引用</h4>
<blockquote>
<p>弱引用也是用来描述非必需对象的。当JVM进行垃圾回收时，无论内存是否充足，都会回收被弱引用关联的对象。在java中，用java.lang.ref.WeakReference类来表示。</p>
</blockquote>
<h4 id="虚引用">虚引用</h4>
<blockquote>
<p>虚引用和前面的软引用和弱引用不同，它并不影响对象的生命周期。在java中使用PhantomReference类来表示。如果一个对象与虚引用关联，跟没有引用与之关联一样，任何时候都可能被回收。要注意的是，虚引用必须和引用队列关联使用。当垃圾收集器准备回收一个对象时，如果发现它还有虚引用，就会把这个虚引用加入到与之关联的引用队列中。为对象设置虚引用的唯一目的就是能在这个对象被垃圾收集器回收时收到一个系统通知。</p>
</blockquote>
<h3 id="引用计数法的缺陷">引用计数法的缺陷</h3>
<p>引用计数法就是给对象添加一个引用计数器，每当有一个地方引用它时，计数器值就加1.当引用失效时，计数器的值就减一。任何时刻计数器值为0的对象就是不可能再被使用的。</p>
<p>优缺点：实现简单，判断效率高，大部分情况下是个很不错的算法。但是致命问题是没办法解决对象之间相互循环引用的问题。</p>
<pre><code class="language-java">public class ReferenceCountingGC {

    private Object instance = null;

    private static final int _1MB = 1024*1024;

    private byte[] bigSize = new byte[2*_1MB];

    public static void main(String [] args) {

        ReferenceCountingGC objA = new ReferenceCountingGC();
        ReferenceCountingGC objB = new ReferenceCountingGC();
        objA.instance = objB;
        objB.instance = objA;

        objA = null;
        objB = null;

        //假设在这行发生GC，ObjA和ObjB是否能被回收
        System.gc();
    }
}
</code></pre>
<p>观察GC日志可以看出GC发生了内存回收，意味着虚拟机并没有因为这两个对象相互引用就不回收它们，这也从侧面说明虚拟机并没有采用引用计数法来判断对象是否存活。</p>
<h3 id="可达性分析">可达性分析</h3>
<p>这个算法的基本思想是通过一系列被称为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索走过的路径叫做引用链，当一个对象到GC Roots没有任何引用链相连 （用图论的话来说就是从GC Roots到这个对象不可达），则证明此对象是不可用的。</p>
<p><strong>在 Java语言中，可作为GC Roots的对象包括以下几种</strong></p>
<p>（1）虚拟机栈（栈帧中的本地变量表）中引用的对象。</p>
<p>（2）方法区中类静态属性引用的对象。</p>
<p>（3）方法区中常量引用的对象。</p>
<p>（4）本地方法栈中JNI（即一般说的Native方法）引用的对象。</p>
<p><strong>对象是生存还是死亡？</strong></p>
<p>即使在可达性分析法中不可达的对象，也并非“非死不可”，他们还有拯救自己的机会。要宣告一个对象死亡，至少要经历两次标记过程：如果对象在进行可达性分析后没有与GC Roots的引用链，那么它将会被第一次标记，并且此时需要判断是否有必要执行finalize()方法。没有必要的话，那么这个对象就宣告死亡，可以回收了。</p>
<p>如果有必要执行，那么这个对象会被放置在一个叫做F-Queue的队列中，并在稍后由虚拟机自动建立的低优先级的Finalizer线程去执行它。finalize()是对象拯救自己的最后一次机会-只要重新与引用链上的 任何一个对象建立关联即可（譬如把自己赋值给某个类变量或者对象的成员变量），那么在第二次标记时它将被移除“可回收”的集合，如果对象还没有逃脱，基本上就真的被回收了。</p>
<p>具体的过程见下图：</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1619321104140.png" alt="" loading="lazy"></figure>
<h2 id="垃圾收集算法">垃圾收集算法</h2>
<h3 id="标记清除算法">标记清除算法</h3>
<p>标记-清除算法是最基础的算法，分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收。</p>
<p>它的主要不足有两个：一是效率问题，标记和清除两个过程的效率都不高；另一个是空间问题，标记清楚之后会产生大量不连续的内存碎片。</p>
<p>标记-清除算法的执行过程见下图：</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1619321111512.png" alt="" loading="lazy"></figure>
<h3 id="复制算法">复制算法</h3>
<p>为了解决效率问题，“复制”算法出现了。它将内存空间划分为大小相等的两块，每次只使用其中的一块，当这一块的内存用完了，就将还存活的对象复制到另外一块上，然后再把已使用的的内存空间一次性清理掉。</p>
<p>这样每次都是对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。但是这种算法的代码是将内存空间缩小为原来的一半。</p>
<p>复制算法的执行过程见下图：</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1619321118627.png" alt="" loading="lazy"></figure>
<h3 id="标记-整理算法">标记-整理算法</h3>
<p>标记过程仍然与标记-清除算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉边界以外的内存。</p>
<p>标记-整理算法的执行过程见下图：</p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1619321125289.png" alt="" loading="lazy"></figure>
<h3 id="分代收集算法">分代收集算法</h3>
<p>分代收集算法是目前大部分JVM的垃圾收集器采用的算法。它的核心思想是根据对象存活的生命周期将内存划分为若干个不同的区域。一般情况下将堆区划分为老年代（Tenured Generation）和新生代（Young Generation），在堆区之外还有一个代就是永久代（Permanet Generation）。老年代的特点是每次垃圾收集时只有少量对象需要被回收，而新生代的特点是每次垃圾回收时都有大量的对象需要被回收，那么就可以根据不同代的特点采取最适合的收集算法。</p>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1631166010532.jpeg" alt="" loading="lazy"></figure>
<p><strong>3.4.1 年轻代（Young Generation）的回收算法</strong></p>
<p>a) 所有新生成的对象首先都是放在年轻代的。年轻代的目标就是尽可能快速的收集掉那些生命周期短的对象。</p>
<p>b) 新生代内存按照8:1:1的比例分为一个eden区和两个survivor(survivor0,survivor1)区。一个Eden区，两个 Survivor区(一般而言)。大部分对象在Eden区中生成。回收时先将eden区存活对象复制到一个survivor0区，然后清空eden区，当这个survivor0区也存放满了时，则将eden区和survivor0区存活对象复制到另一个survivor1区，然后清空eden和这个survivor0区，此时survivor0区是空的，然后将survivor0区和survivor1区交换，即保持survivor1区为空， 如此往复。</p>
<p>c) 当survivor1区不足以存放 eden和survivor0的存活对象时，就将存活对象直接存放到老年代。若是老年代也满了就会触发一次Full GC，也就是新生代、老年代都进行回收。</p>
<p>d) 新生代发生的GC也叫做Minor GC，MinorGC发生频率比较高(不一定等Eden区满了才触发)。</p>
<p><strong>3.4.2 年老代（Old Generation）的回收算法</strong></p>
<p>a) 在年轻代中经历了N次垃圾回收后仍然存活的对象，就会被放到年老代中。因此，可以认为年老代中存放的都是一些生命周期较长的对象。</p>
<p>b) 内存比新生代也大很多(大概比例是1:2)，当老年代内存满时触发Major GC即Full GC，Full GC发生频率比较低，老年代对象存活时间比较长，存活率标记高。</p>
<p><strong>3.4.3 持久代（Permanent Generation）的回收算法</strong></p>
<p>用于存放静态文件，如Java类、方法等。持久代对垃圾回收没有显著影响，但是有些应用可能动态生成或者调用一些class，例如Hibernate 等，在这种时候需要设置一个比较大的持久代空间来存放这些运行过程中新增的类。持久代也称方法区，</p>
<h2 id="垃圾收集器">垃圾收集器</h2>
<p>堆内存是垃圾收集器主要回收垃圾对象的地方，堆内存可以根据对象生命周期的不同分为新生代和老年代，分代收集，新生代使用复制算法，老年代使用标记清除或者标记整理算法。</p>
<p>HotSpot虚拟机提供了7种垃圾收集器，其中新生代三种：Serial/ParNew/Parallel Scavenge收集器，老年代三种：Serial Old/Parallel Old/CMS，都适用的是G1收集器。所有垃圾收集器组合 情况如下图：</p>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1619321134376.webp" alt="" loading="lazy"></figure>
<h3 id="serial收集器">Serial收集器</h3>
<p>最基本也是发展历史最长的垃圾收集器，在进行垃圾收集时，必须Stop The World(暂停其他工作线程)，直到收集结束。只使用一条线程完成垃圾收集，但是效率高，因为没有线程交互的开销，拥有更高的单线程收集效率。发生在新生代区域，使用复制算法。</p>
<h3 id="parnew收集器">ParNew收集器</h3>
<p>Serial收集器的多线程版本。在进行垃圾收集时同样需要Stop The World（暂停其他工作线程），直到收集结束。使用多条线程进行垃圾收集（由于存在线程交互的开销，所以在单CPU的环境下，性能差于Serial收集器）。目前，只有Parnew收集器能与CMS收集器配合工作。发生在新生代区域，使用复制算法。</p>
<h3 id="parallel-scavenge收集器">Parallel Scavenge收集器</h3>
<p>ParNew收集器的升级版，具备ParNew收集器并发多线程收集的特点，以达到可控制吞吐量为目标。（吞吐量：CPU用于运行用户代码的时间与CPU总消耗时间（运行用户代码时间+垃圾收集时间）的比值）。该垃圾收集器能根据当前系统运行情况，动态调整自身参数，从而达到最大吞吐量的目标。（该特性成为GC自适应的调节策略）。发生在新生代，使用复制算法。</p>
<h3 id="serial-old收集器">Serial Old收集器</h3>
<p>Serial 收集器应用在老年代的版本。并发、单线程、效率高。使用标记整理算法。</p>
<h3 id="parallel-old收集器">Parallel Old收集器</h3>
<p>是Parallel Scavenge应用在老年代的版本，以达到可控制吞吐量、自适应调节和多线程收集为目标，使用标记整理算法。</p>
<h3 id="cms收集器">CMS收集器</h3>
<p>CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。使用这类收集器的应用重视服务的响应速度，希望系统停顿时间最短，以带来更好的用户体验。</p>
<p>使用标记清除算法，一共四个步骤：初始标记、并发标记、重新标记和并发清除。详情见下表：</p>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1619321143708.webp" alt="" loading="lazy"></figure>
<p>下面说下CMS的优缺点：</p>
<h4 id="优点">优点：</h4>
<p>（1）并行：用户线程和垃圾收集线程同时进行。</p>
<p>（2）单线程收集：只使用一条线程完成垃圾收集。</p>
<p>（3）垃圾收集停顿时间短：获取最短的回收停顿时间，即希望系统停顿的时间最短，提高响应速度。</p>
<h4 id="缺点">缺点：</h4>
<p>（1）总吞吐量会降低：因为该收集器对CPU资源非常敏感，在并发阶段不会导致停顿用户线程，但会因为占用部分线程（CPU资源）导致应用程序变慢，总吞吐量会降低。</p>
<p>（2）无法处理浮动垃圾：由于并发清理时用户线程还在运行，所以会有新的垃圾不断产生，只能等到下一次GC时再清理。（因为这一部分垃圾出现在标记过程之后，所以CMS 无法在当次GC中处理他们，因此CMS无法等到老年代填满再进行Full GC，CMS需要预留一部分空间）。</p>
<p>（3）垃圾收集后会产生大量的内存碎片：因为CMS收集器是使用标记-清除算法的。</p>
<p>下面一张图了解下CMS的工作过程：<br>
<img src="https://tinaxiawuhao.github.io/post-images/1619321151348.png" alt="" loading="lazy"></p>
<h3 id="g1收集器">G1收集器</h3>
<p>G1收集器是最新最前沿的垃圾收集器。特点如下：</p>
<p>（1）并行：用户线程和垃圾收集线程同时进行。</p>
<p>（2）多线程：即使用多条垃圾收集线程进行垃圾回收。（并发和并行充分利用多CPU和多核环境的硬件优势来缩短垃圾收集的停顿时间）</p>
<p>（3）垃圾收集效率高：G1收集器是针对性对Java堆内存区域进行垃圾收集，而非每次都对整个区域进行收集。即G1除了将Java堆内存分为新生代和老年代之外，还会细分为许多个 大小相等的独立区域（Region），然后G1收集器会跟踪每个Region里的垃圾代价值大小，并在后台维护一个列表。每次回收时，会根据允许的垃圾收集时间优先回收价值最大的 Region，从而避免了对整个Java堆内存区域的回收，提高了效率。因为上述机制，G1收集器还能建立可预测的时间模型：即让使用者明确执行一个长度为M毫秒的时间片段，消耗在 垃圾收集上的时间不得超出N毫秒。即具备实时性。</p>
<p>（4）不会产生内存碎片。从整理上看，G1收集器是基于标记-整理算法的，从局部看是基于复制算法的。在新生代使用复制算法，在老年代使用标记-整理算法。</p>
<p>下面了解下工作流程，跟CMS有点像。</p>
<figure data-type="image" tabindex="9"><img src="https://tinaxiawuhao.github.io/post-images/1619321159419.png" alt="" loading="lazy"></figure>
<p>下面是G1的工作过程：</p>
<figure data-type="image" tabindex="10"><img src="https://tinaxiawuhao.github.io/post-images/1619321168987.webp" alt="" loading="lazy"></figure>
<h2 id="总结">总结</h2>
<p>本文讲解了运行时数据区域，内存溢出，如何判断对象是否存活，垃圾回收算法和垃圾收集器几个方面，涵盖jvm的核心考点，希望你有所收获。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java内存结构JVM]]></title>
        <id>https://tinaxiawuhao.github.io/post/nxmi3zjCk/</id>
        <link href="https://tinaxiawuhao.github.io/post/nxmi3zjCk/">
        </link>
        <updated>2021-04-26T02:49:02.000Z</updated>
        <content type="html"><![CDATA[<h2 id="jvm内存模型">JVM内存模型</h2>
<p><code>内存空间(Runtime Data Area)</code>中可以按照是否线程共享分为两块，线程共享的是<code>方法区(Method Area)</code>和<code>堆(Heap)</code>，线程独享的是<code>Java虚拟机栈(Java Stack)</code>，<code>本地方法栈(Native Method Stack)</code>和<code>PC寄存器(Program Counter Register)</code>。具体参见下图：</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1619319113675.png" alt="" loading="lazy"></figure>
<h3 id="虚拟机栈">虚拟机栈：</h3>
<p>每个线程有一个私有的栈，随着线程的创建而创建。栈里面存放着一种叫做“栈帧”的东西，每个方法会创建一个栈帧，栈帧中存放了局部变量表(基本数据类型和对象引用)、操作数栈、方法出口等信息。栈的大小可以固定也可以动态扩展。当栈调用深度大于<code>JVM</code>所允许的范围，会抛出<code>StackOverflowError</code>的错误，不过这个深度范围不是一个恒定的值，我们通过下面这段程序可以测试一下这个结果：</p>
<pre><code class="language-java">// 栈溢出测试源码
ackage com.paddx.test.memory;
 
/**
 * Created by root on 2/28/17.
 */
public class StackErrorMock {
    private static int index = 1;
 
    public void call() {
        index++;
        call();
    }
 
    public static void main(String[] args) {
        StackErrorMock mock = new StackErrorMock();
        try {
            mock.call();
        } catch(Throwable e) {
            System.out.println(&quot;Stack deep: &quot; + index);
            e.printStackTrace();
        }
    }
}
</code></pre>
<p>运行三次，可以看出每次栈的深度都是不一样的，输出结果如下：<br>
<img src="https://tinaxiawuhao.github.io/post-images/1619327479989.png" alt="" loading="lazy"><br>
<img src="https://tinaxiawuhao.github.io/post-images/1619327486623.png" alt="" loading="lazy"><br>
<img src="https://tinaxiawuhao.github.io/post-images/1619319135044.png" alt="" loading="lazy"></p>
<p>查看三张结果图，可以看出每次的Stack deep值都有所不同。究其原因，就需要深入到<code>JVM</code>的源码中才能探讨，这里不作赘述。</p>
<p>虚拟机栈除了上述错误外，还有另一种错误，那就是当申请不到空间时，会抛出<code>OutOfMemoryError</code>。这里有一个小细节需要注意，catch捕获的是Throwable，而不是Exception，这是因为<code>StackOverflowError</code>和<code>OutOfMemoryError</code>都不属于Exception的子类。</p>
<h3 id="本地方法栈">本地方法栈：</h3>
<p>这部分主要与虚拟机用到的Native方法相关，一般情况下，Java应用程序员并不需要关系这部分内容。</p>
<h3 id="pc寄存器">PC寄存器：</h3>
<p>PC寄存器，也叫程序计数器。<code>JVM</code>支持多个线程同时运行，每个线程都有自己的程序计数器。倘若当前执行的是<code>JVM</code>方法，则该寄存器中保存当前执行指令的地址；倘若执行的是native方法，则PC寄存器为空。</p>
<h3 id="堆">堆 ：</h3>
<p>堆内存是<code>JVM</code>所有线程共享的部分，在虚拟机启动的时候就已经创建。所有的对象和数组都在堆上进行分配。这部分空间可通过<code>GC</code>进行回收。当申请不到空间时，会抛出<code>OutOfMemoryError</code>。下面我们简单的模拟一个堆内存溢出的情况：</p>
<pre><code class="language-java">package com.paddx.test.memory;
 
import java.util.ArrayList;
import java.util.List;
 
/**
 * Created by root on 2/28/17.
 */
public class HeapOomMock {
    public static void main(String[] args) {
        List&lt;byte[]&gt; list = new ArrayList&lt;byte[]&gt;();
        int i = 0;
        boolean flag = true;
        while(flag) {
            try {
                i++;
                list.add(new byte[1024 * 1024]); // 每次增加1M大小的数组对象
            }catch(Throwable e) {
                e.printStackTrace();
                flag = false;
                System.out.println(&quot;Count = &quot; + i); // 记录运行的次数
            }
        }
    }
}
</code></pre>
<p>首先配置运行时虚拟机的启动参数：<br>
<img src="https://tinaxiawuhao.github.io/post-images/1619319145433.png" alt="" loading="lazy"></p>
<p>然后运行代码，输出结果如下：</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1619319151622.png" alt="" loading="lazy"></figure>
<p>注意，这里我们指定了堆内存的大小为16M，所以这个地方显示的Count=13(这个数字不是固定的)，至于为什么会是13或其他数字，需要根据GC日志来判断。</p>
<h3 id="方法区">方法区：</h3>
<p>方法区也是所有线程共享的。主要用于存储类的信息、常量池、方法数据、方法代码等。方法区逻辑上属于堆的一部分，但是为了与堆进行区分，通常又叫“非堆”。关于方法区的内存溢出问题会在下文中详细讨论。</p>
<h2 id="permgen永久代">PermGen(永久代)</h2>
<p>绝大部分Java程序员应该都见过<code>“java.lang.OutOfMemoryError: PremGen space”</code>异常。这里的<code>“PermGen space”</code>其实指的就是方法区。不过方法区和<code>“PermGen space”</code>又有着本质的区别。前者是<code>JVM</code>的规范，而后者则是<code>JVM</code>规范的一种实现，并且只有<code>HotSpot</code>才有<code>“PermGen space”</code>，而对于其他类型的虚拟机，如<code>JRockit(Oracle)</code>、<code>J9(IBM)</code>并没有<code>“PermGen space”</code>。由于方法区主要存储类的相关信息，所以对于动态生成类的情况比较容易出现永久代的内存溢出。最典型的场景就是，在<code>JSP</code>页面比较多的情况，容易出现永久代内存溢出。我们现在通过动态生成类来模拟<code>“PermGen space”</code>的内存溢出：</p>
<pre><code class="language-java">package com.paddx.test.memory;
 
import java.io.File;
import java.net.URL;
import java.net.URLClassLoader;
import java.util.ArrayList;
import java.util.List;
 
public class PermGenOomMock {
	public static void main(String[] args) {
		URL url = null;
		List&lt;ClassLoader&gt; classLoaderList = new ArrayList&lt;ClassLoader&gt;();
		try {
			url = new File(&quot;/tmp&quot;).toURI().toURL();
			URL[] urls = {url};
			while(true) {
				ClassLoader loader = new URLClassLoader(urls);
				classLoaderList.add(loader);
				loader.loadClass(&quot;com.paddx.test.memory.Test&quot;);
			}
		}catch(Exception e) {
			e.printStackTrace();
		}
	}
}
</code></pre>
<pre><code class="language-java">package com.paddx.test.memory;
 
public class Test {}
</code></pre>
<p>运行结果如下：</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1619319159980.png" alt="" loading="lazy"></figure>
<p>本例中使用的<code>JDK</code>版本是1.7，指定的<code>PermGen</code>区的大小为<code>8M</code>。通过每次生成不同<code>URLClassLoader</code>对象加载Test类，从而生成不同的类对象，这样就能看到我们熟悉的<code>“java.lang.OutOfMemoryError: PermGen space”</code>异常了。这里之所以采用<code>JDK 1.7</code>，是因为在<code>JDK 1.8</code>中，<code>HotSpot</code>已经没有<code>“PermGen space”</code>这个区间了，取而代之是一个叫做<code>Metaspace(元空间)</code>的东西。下面我们就来看看<code>Metaspace</code>与<code>PermGen space</code>的区别。</p>
<h3 id="metaspace元空间">Metaspace(元空间)</h3>
<p>其实，移除永久代的工作从<code>JDK 1.7</code>就开始了。<code>JDK 1.7</code>中，存储在永久代的部分数据就已经转移到<code>Java Heap</code>或者<code>Native Heap</code>。但永久代仍存在于<code>JDK 1.7</code>中，并没有完全移除，譬如符号引用(Symbols)转移到了native heap；字面量(interned strings)转移到了Java heap；类的静态变量(class statics)转移到了Java heap。我们可以通过一段程序来比较<code>JDK 1.6</code>、<code>JDK 1.7</code>与<code>JDK 1.8</code>的区别，以字符串常量为例：</p>
<pre><code class="language-java">package com.paddx.test.memory;
 
import java.util.ArrayList;
import java.util.List;
 
public class StringOomMock {
	static String base = &quot;string&quot;;
	public static void main(String[] args) {
		List&lt;String&gt; list = new ArrayList&lt;String&gt;();
		for (int i = 0; i &lt; Integer.MAX_VALUE; i++) {
			String str = base + base;
			base = str;
			list.add(str.intern());
		}
	}
}
</code></pre>
<p>这段程序以2的指数级不断的生成新的字符串，这样可以比较快速的消耗内存。我们通过<code>JDK 1.6</code>、<code>JDK 1.7</code>和<code>JDK 1.8</code>分别运行：</p>
<p><code>JDK 1.6</code>的运行结果：</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1619319168920.png" alt="" loading="lazy"></figure>
<p><code>JDK 1.7</code>的运行结果：</p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1619319175662.png" alt="" loading="lazy"></figure>
<p><code>JDK 1.8</code>的运行结果：</p>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1619319183606.png" alt="" loading="lazy"></figure>
<p>从上述结果可以看出，<code>JDK 1.6</code>下，会出现<code>“PermGen space”</code>的内存溢出，而在<code>JDK 1.7</code>和<code>JDK 1.8</code>中，会出现堆内存溢出，并且<code>JDK 1.8</code>中参数<code>PermSize</code>和<code>MaxPermSize</code>已经失效。因此，可以大致验证<code>JDK 1.7</code>和<code>JDK 1.8</code>中将字符串常量由永久代转移到堆中，并且<code>JDK 1.8</code>中已经不存在永久代的结论。现在我们来看一看元空间到底是一个什么东西？</p>
<p><code>JDK1.8</code>对<code>JVM</code>架构的改造将类元数据放到本地内存中，另外，将常量池和静态变量放到Java堆里。<code>HotSpot VM</code>将会为类的元数据明确分配和释放本地内存。在这种架构下，类元信息就突破了原来<code>-XX:MaxPermSize</code>的限制，现在可以使用更多的本地内存。这样就从一定程度上解决了原来在运行时生成大量类造成经常<code>Full GC</code>问题，如运行时使用反射、代理等。所以升级以后Java堆空间可能会增加。</p>
<p>元空间的本质和永久代类似，都是对<code>JVM</code>规范中方法区的实现。不过元空间与永久代之间的最大区别在于：元空间并不在虚拟机中，而是使用本地内存。因此，默认情况下，元空间的大小仅受本地内存限制，但可以通过以下参数指定元空间的大小：</p>
<p><code>-XX:MetaspaceSize</code>，初始空间大小，达到该值就会触发垃圾收集进行类型卸载，同时GC会对改值进行调整：如果释放了大量的空间，就适当降低该值；如果释放了很少的空间，那么在不超过<code>MaxMetaspaceSize</code>时，适当提高该值。</p>
<p><code>-XX:MaxMetaspaceSize</code>，最大空间，默认是没有限制的。</p>
<p>除了上面的两个指定大小的选项外，还有两个与<code>GC</code>相关的属性：</p>
<p><code>-XX:MinMetaspaceFreeRatio</code>，在<code>GC</code>之后，最小的<code>Metaspace</code>剩余空间容量的百分比，减少为分配空间所导致的垃圾收集。</p>
<p><code>-XX:MaxMetaspaceFreeRatio</code>，在<code>GC</code>之后，最大的<code>Metaspace</code>剩余空间容量的百分比，减少为释放空间所导致的垃圾收集。</p>
<p>现在我们在<code>JDK 1.8</code>重新运行一下上面第二部分<code>(PermGen(永久代))</code>的代码，不过这次不再指定<code>PermSize</code>和<code>MaxPermSize</code>。而是制定<code>MetaspaceSize</code>和<code>MaxMetaspaceSize</code>的大小。输出结果如下：</p>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1619319190434.png" alt="" loading="lazy"></figure>
<p>从输出结果，我们可以看出，这次不再出现永久代溢出，而是出现元空间的溢出。</p>
<p><strong>四、总结</strong></p>
<p>通过上面的分析，大家应该大致了解了<code>JVM</code>的内存划分，也清楚了<code>JDK 1.8</code>中永久代向元空间的转换。不过大家应该有一个疑问，就是为什么要做这个转换？以下为大家总结几点原因：</p>
<ol>
<li>字符串在永久代中，容易出现性能问题和内存溢出。</li>
<li>类及方法的信息等比较难确定大小，因此对于永久代的大小指定比较困难，太小容易出现永久代溢出，太大则容易出现老年代溢出。</li>
<li>永久代会为<code>GC</code>带来不必要的复杂度，并且回收效率偏低。</li>
<li>Oracle可能会将<code>HotSpot</code>与<code>JRockit</code>合二为一。</li>
</ol>
<blockquote>
<p>作者：liuxiaopeng<br>
博客地址：https://www.cnblogs.com/paddix/p/5309550.html</p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ 漫画：什么是B+树？]]></title>
        <id>https://tinaxiawuhao.github.io/post/jVTlR3ljT/</id>
        <link href="https://tinaxiawuhao.github.io/post/jVTlR3ljT/">
        </link>
        <updated>2021-04-25T09:03:03.000Z</updated>
        <content type="html"><![CDATA[<p>原创  [程序员小灰(公众号，强烈推荐)]</p>
<p>在上一篇漫画中，我们介绍了B-树的原理和应用，没看过的小伙伴们可以点击下面的链接：</p>
<p><a href="https://tinaxiawuhao.github.io/post/LhRxiTagh/">漫画：什么是B-树？</a></p>
<p>这一次我们来介绍B+树。</p>
<p>—————————————————</p>
<figure data-type="image" tabindex="1"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pWnUZWGqFibB67D1jJSrCib7dbKwb9alIrbd1EGrtCMP5cApLl7fOfu8dg/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="2"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pWxXe8URSjDot9qRMPfwUgLR0vYIEXPZm2PtyKhW5cDX0YYwiatwwicPDQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="3"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pWI1nOoibYtF5g3ViaasktduzvaQa82RYIYKK7PpjR9GowH1d9ngRQLDpA/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="4"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pWDGkGmp0pbWZHy0ARgq5mFnEU43icOKl2WTkmRTt26hsOxSvr040ISOQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<p><strong>一个m阶的B树具有如下几个特征：</strong></p>
<p>1.根结点至少有两个子女。</p>
<p>2.每个中间节点都包含k-1个元素和k个孩子，其中 m/2 &lt;= k &lt;= m</p>
<p>3.每一个叶子节点都包含k-1个元素，其中 m/2 &lt;= k &lt;= m</p>
<p>4.所有的叶子结点都位于同一层。</p>
<p>5.每个节点中的元素从小到大排列，节点当中k-1个元素正好是k个孩子包含的元素的值域分划。</p>
<figure data-type="image" tabindex="5"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pWlS1Ga5NPKfWy0oMOdwic51e1GmB6Ly86xtnHJuOvPojiaZiazfn3G8o9g/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<p><strong>一个m阶的B+树具有如下几个特征：</strong></p>
<p>1.有k个子树的中间节点包含有k个元素（B树中是k-1个元素），每个元素不保存数据，只用来索引，所有数据都保存在叶子节点。</p>
<p>2.所有的叶子结点中包含了全部元素的信息，及指向含这些元素记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。</p>
<p>3.所有的中间节点元素都同时存在于子节点，在子节点元素中是最大（或最小）元素。</p>
<figure data-type="image" tabindex="6"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pWvGPhcLC5KUR6nS0y43UkBickpRqNDHoCyeKmNDcpwxgteSsyrdJSxibQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="7"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pWlKtp41Tb329jCECIe2a05icnlBlVOTCdeQKNP6BPS8mtksdLStWIqoQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="8"><img src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="9"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pWdKrHQez446RaDLFZ9GzkcdduW75BlwD4YicSn9vDVianRuJrdK1x3xBQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="10"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pWlENKtSK6Hw1giabCJm8ictbI6RcYpe2ibQ5bptEiakbyJ9aPh2tQyozbicQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="11"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pWTKSPRlWicrkEvJVcPibE9wGyjJzfbntOSCTdg2B23fpLFmwx8uQibW3nw/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="12"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pWkfCibcqSxZANC3vkHibXasqAibGY15qqc1QicpyboHorSpep9XZnaDIefg/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="13"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pWyqIwczSBNzHJF9UkBKaPJFva7z1zA9OlpVXac0xFiar3eapQFhfZnCg/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="14"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pW9yjIQHedIcYbWGTdknjMb4k2YCJbu4R0oenib3aHKKmNLrNHFVHFjHA/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="15"><img src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="16"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pWI9NoahgCbKFYcQZ0x3sMMTzzpOUx4WuHl6PaoNeicczBT9xxRvaqjpw/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="17"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pWu9JxaBSILSojEUdby9NHbApkSfJhCcqTR0zwma0p6CPLF6vTBFtGEg/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="18"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pWibeDfY4E8p2UFFm3UnBC02mwAI0ic7LvYGddoC1NT7E96XlKM5yDI9fg/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="19"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pWfgialxT2Lk6EKIW2keLbSCQI9oibwvnJthSGahclps7c1u0RtqzJ5UNA/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<p>B-树中的卫星数据（Satellite Information）：</p>
<figure data-type="image" tabindex="20"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pW7cPy9dgkyNkgRmSSR0n0Hueuc6xiatV8xjV3csnrLKQtibsbAzHODq6g/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="21"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pWWUQgyrJINKO4tNI5R3XRdNAIYViaIS1icuUzYibtok7mPokibTYlc5iaYwg/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<p>B+树中的卫星数据（Satellite Information）：</p>
<figure data-type="image" tabindex="22"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pWHh99F2iakg9snMXq2riaQvI96ZBKq8ibOyVABr12HichuYYBgDAU6JibmuQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<p>需要补充的是，在数据库的聚集索引（Clustered Index）中，叶子节点直接包含卫星数据。在非聚集索引（NonClustered Index）中，叶子节点带有指向卫星数据的指针。</p>
<figure data-type="image" tabindex="23"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pWlibEclqdicliczItOQ0BTCc94Tjx4hK3QOibTBYqTic9W99bfkZEepHhobg/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="24"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pW97oNUTsZBesRIa9JMfgHPugQRiaXOR9ByFYawic5zp5O7ZIppicY9ibpaw/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="25"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pW1O0oglp3SdXsN4iaKAuhQdpwkj9vMD4N5JjOgA4guCNPtmetOgiaP3Rg/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<p>第一次磁盘IO：</p>
<figure data-type="image" tabindex="26"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pWALKA2cKa2Az6vFk9jcXkSCgXW23aECY3IM9qkZibEeJsW1133T32q0A/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<p>第二次磁盘IO：</p>
<figure data-type="image" tabindex="27"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pWQ5xibk8HqcNj2Py6qSXaFSDFPicrtMlctR8ibwibp8NOHibY7UTYAGkXPNQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<p>第三次磁盘IO：</p>
<figure data-type="image" tabindex="28"><img src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="29"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pWRUfNhz8DaSYPmp49KBibHYmiab2oPFqa27pnNH22N6UdicgpVUibx7cjKA/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="30"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pWHTfuPgD3Okks1JvaiafgwCoFISZs4ja9ILVUXsupMHSv7p6K5licH0Vw/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="31"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pWrR88bBnTTqgjtjxxsYUpDdg9ra3rchusBudFN9b11ncLHHG0OQw3mA/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="32"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pWt280MzTs4m5ZE1LXib1pW2Kdm9y7icjtTq8lHzot5SneAh4ubibzFibiawA/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="33"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pWBeRTP5g5InIURA5g5V8hcgzvkqowr3d7m0p3dkt19Mmic3QNtqtFyaA/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="34"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pWkpblZmEgJKVZZtkhrTlf8JYxS5ohjmoWhkIww4WFficHkENauhl7F4g/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<p><strong>B-树的范围查找过程</strong></p>
<p>**<br>
**</p>
<p>自顶向下，查找到范围的下限（3）：</p>
<figure data-type="image" tabindex="35"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pWRZKppF7LWMS5ibIvtRnIhgyp2Ufvg6iaGqaXiaPWLdA62yc7egmTPlnmg/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<p>中序遍历到元素6：</p>
<figure data-type="image" tabindex="36"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pW1Z3JotpdD0ibcfYg4hLwUyUmrN6ia4t7sVVh0yfpMmlib2XbQI6mVQRwA/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<p>中序遍历到元素8：</p>
<figure data-type="image" tabindex="37"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pW8F3jYDUmNbLyoBTKP5nDiblULjyWGpkicic7Icm5QvibzcfNfC05rvB6VA/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<p>中序遍历到元素9：</p>
<figure data-type="image" tabindex="38"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pWEKahLygMy0dib0UU7MXs0PEicYFhicHSFTeiahGib5TCAWX9vFia94asDoyg/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<p>中序遍历到元素11，遍历结束：</p>
<figure data-type="image" tabindex="39"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pWlVibahZaopYBD1QKLPk7pnCKbOeRmVa6iavA5o8O2GczP67oEu7rQqSg/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="40"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pWhp9SXcoMfE53EIEug81ibmJafmfTglXgwO7rwG9AZj9FY71icD6ujU5A/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="41"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pW9KrEfPDm82hWPBByicp4JGmktZeQlvr6nEF7BC812o9jQ4ktmMcoPuw/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<p><strong>B+树的范围查找过程</strong></p>
<p>**<br>
**</p>
<p>自顶向下，查找到范围的下限（3）：</p>
<figure data-type="image" tabindex="42"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pWhgC1HqVwF8WQYv7icZ0uFmibfDLRCLQiby5pfPLnJ1BYxeW9bfxEG8LPQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<p>通过链表指针，遍历到元素6, 8：</p>
<figure data-type="image" tabindex="43"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pWQEQzMogDLI7WicDib78y1WDn4Jic4YN7m2FAEUyyfA82UVVdmSKQ5P6sw/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<p>通过链表指针，遍历到元素9, 11，遍历结束：</p>
<figure data-type="image" tabindex="44"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pWxkfoKkeDiasB0srl8Aa34QfPhHmeurELvHic0nFzUOHLvO7v2FUW1ZfQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="45"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pWkGfwgBuz8sufnXHjjLZPibHy5LM0vKlzf39Z9uuQoiaOhQcUKickNSGdw/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="46"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pW0HcK41YwayXk62aBHiba7tKN5B1CLEPTmU0ZvcpOiaalMXujvJicr7JqQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="47"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pWkWdGj1PIO1ria6VjicQZO8O7vubRGQtLCyXveOFEKRUhD8FlyloX11pQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="48"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pWD8dD8T7Gp6VsVJTFiaxGNFjhyYJL5nnPN7hJ3WumQPSJdXHwo4sosSg/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<p><strong>B+树的特征：</strong></p>
<p>1.有k个子树的中间节点包含有k个元素（B树中是k-1个元素），每个元素不保存数据，只用来索引，所有数据都保存在叶子节点。</p>
<p>2.所有的叶子结点中包含了全部元素的信息，及指向含这些元素记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。</p>
<p>3.所有的中间节点元素都同时存在于子节点，在子节点元素中是最大（或最小）元素。</p>
<p><strong>B+树的优势：</strong></p>
<p>1.单一节点存储更多的元素，使得查询的IO次数更少。</p>
<p>2.所有查询都要查找到叶子节点，查询性能稳定。</p>
<p>3.所有叶子节点形成有序链表，便于范围查询。</p>
<figure data-type="image" tabindex="49"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrhjbBgkNEqGwLjaRu359pWGz1E1iciaq8bzs2miaDPcn7pibLThbjA5llpOjTh0DdyCQXT9g8evfibdPQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<p>—————END—————</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[漫画：什么是B-树？]]></title>
        <id>https://tinaxiawuhao.github.io/post/LhRxiTagh/</id>
        <link href="https://tinaxiawuhao.github.io/post/LhRxiTagh/">
        </link>
        <updated>2021-04-25T08:58:34.000Z</updated>
        <content type="html"><![CDATA[<p>原创  [程序员小灰(公众号，强烈推荐)]</p>
<figure data-type="image" tabindex="1"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGoX9aS1vS0cNOWWdNpKV4omperuU9tXVmGtiaebVYhIH8LzNQ4SQ9gcmt8lFRmbVsote0EWZnYWkFQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="2"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGoX9aS1vS0cNOWWdNpKV4omvE3DX4LSX7UibSEHDpZOf4OXTIkmqCKs1ib0kbiaiauTePPDaxIqwLyLeg/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="3"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGoX9aS1vS0cNOWWdNpKV4omELrLF4iagicxUdv5w5btvMcQQ1ohptiaaSwAia1Fkuch7G3fkknia7fNePg/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="4"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGoX9aS1vS0cNOWWdNpKV4omSKmWO5RhbfETA3zpFeHZ4cibNoIicvH53qDjqG8ACNCicNcWEfzw4XWAg/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<p>————————————</p>
<figure data-type="image" tabindex="5"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGoX9aS1vS0cNOWWdNpKV4om3Qb9JbdqRkZrupQiao3q5icrLj50oKiclmhqoQ7KYhrMw9U0RkccRn8LA/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="6"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGoX9aS1vS0cNOWWdNpKV4omZgqJwlvKKIEiboZYN1bj1ptC8JDBpSgMK5sGsXVbfvqLhmAsYnCwa1A/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="7"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGoX9aS1vS0cNOWWdNpKV4om164ApDQhpkSADVz47icNO3o935TepKIUW9xrsR2G3D5I1mXGBTEuHXg/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="8"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGoX9aS1vS0cNOWWdNpKV4omcoibibpZkKHvjlCKsltt6ibWFekKiaVmJhVolWSicZxNu7PdWF0gyoia1xuQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="9"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGoX9aS1vS0cNOWWdNpKV4omicanwicic4BYm8mbD3Q8pke9DVg0PtxeURueV3GgANAejY08UFSsThehQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="10"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGoX9aS1vS0cNOWWdNpKV4om0W1TkatXcgYSTJ7oJ2LqfJmw3qQug4b9P3mUyTc0K0fzKj1EIBJynQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="11"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGoX9aS1vS0cNOWWdNpKV4omBUWHsicmVibFZUZZReEcs6Zc3ib6QXLYK4ia47FTFicTMX0OUhdAph2v64Q/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="12"><img src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="13"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGoX9aS1vS0cNOWWdNpKV4omjicVxJO4kgHOBz8b22xEXHHzGr1pYlAibauqDbm2VA0MI1oITlpzZ5Yw/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<p>————————————</p>
<figure data-type="image" tabindex="14"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGoX9aS1vS0cNOWWdNpKV4omdmtOGTVtHfdQf3LclwKpo1CKYmUfMR4l2QUksDsl1oX13yMBe9FD0Q/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="15"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGoX9aS1vS0cNOWWdNpKV4omaDShib6S2yT1WpbviaA9LIUfkoiaGNh0l4CXvUm1ZJCrAhibqaZm06RgOQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="16"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGoX9aS1vS0cNOWWdNpKV4om6Hic9ucmUQKD1sOvC8y3JicHFGXEaOBl2MqpFsggOShs3g7BQzzPXicXA/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="17"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGoX9aS1vS0cNOWWdNpKV4ommNia994ceJWX4EWfoMh1WX62ZaicIichj5saiaVpexWyKrLicubIjHckKrA/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="18"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGoX9aS1vS0cNOWWdNpKV4omSOUSOqWqT1nIZABVxuOOj73vcJwzWXnTdLpNTuGgib4MJnQoLTxaMdg/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="19"><img src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="20"><img src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="21"><img src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="22"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGoBqEgxvibyZ3S2O8GG2EcibsCoxqcduibyKDpCnAnmibnVNaqJV0YibhpYYp3gE65N1W771XqzzibZQelA/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="23"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGoBqEgxvibyZ3S2O8GG2Ecibs1G1ickrTiaqeCZU52j6ibcj17vYGUiccE8oALmTQXbiaeOKcc5ZibAwj966Q/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="24"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGoBqEgxvibyZ3S2O8GG2EcibscvQzdW5SqAhOjV8y1Q3XewCCkG8YbzlBFibQMMAeOJQLFgtiaqcJYnwA/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="25"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGoBqEgxvibyZ3S2O8GG2EcibsLu2WteEnEZdVUbm2XLh5rDfKcWeLYYbUkDl75lo24jib4CbWmGHCZug/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="26"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGoBqEgxvibyZ3S2O8GG2EcibsoaByag5Eh52qcZNialGyVKHvcicQ9HFxrWTsvJ7Zeh02evJN2ufTZ5Rw/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="27"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGoBqEgxvibyZ3S2O8GG2EcibsKyTxsxAClzrIgScDUhDEhO1zTcncial0ZJwu3ZJQRwKRug9F1VlU9icQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<p>二叉查找树的结构：</p>
<figure data-type="image" tabindex="28"><img src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" alt="图片" loading="lazy"></figure>
<p>第1次磁盘IO：</p>
<figure data-type="image" tabindex="29"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGoBqEgxvibyZ3S2O8GG2EcibsMKibN9giaNVMbFIlnvTkruWuatuQdvoN07INpbQMFfibtlamFibYTYZjTw/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<p>第2次磁盘IO：</p>
<figure data-type="image" tabindex="30"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGoBqEgxvibyZ3S2O8GG2EcibsonW75DsA6sbibqEEDib8e127Bmlx1cjNiacNAtJRtHdgssedibHxWVz0Bg/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<p>第3次磁盘IO：</p>
<figure data-type="image" tabindex="31"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGoBqEgxvibyZ3S2O8GG2EcibsnjKOKCu20S5b2apqe3RHqiaL5cRTPxicF2NQ4j4ic8dbvBwTGgdCLHbxg/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<p>第4次磁盘IO：</p>
<figure data-type="image" tabindex="32"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGoBqEgxvibyZ3S2O8GG2EcibsqUOlpMg643uxxrb9ygP4Shq20MEicRsv5GqzxqImolibJOVf5Qn9ySgQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="33"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGoBqEgxvibyZ3S2O8GG2EcibsRbGPSjia4RQWOVQ2DZVhYibibJasdg3v3QMNS0p4IJtDnAcOnVP4xYp8Q/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="34"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGoBqEgxvibyZ3S2O8GG2Ecibsr6LX79azuhDhNsNibBibVanpqDbccbibgkFziaNHsTPQNsLPq8GSxgNQtQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="35"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGoBqEgxvibyZ3S2O8GG2EcibsmRy2uqE5dPtRSbhIJ4ciaZTMGD3dzDYTAQETXGa3zxj0AdLfFphhCtA/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="36"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGoBqEgxvibyZ3S2O8GG2EcibsibqHeTIn9hibc3GJGiarSS9xH0SpPhaclQvKBYy5nbmTg1cYnJM3AFfpg/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<p>下面来具体介绍一下B-树（Balance Tree），一个m阶的B树具有如下几个特征：</p>
<p>1.根结点至少有两个子女。</p>
<p>2.每个中间节点都包含k-1个元素和k个孩子，其中 m/2 &lt;= k &lt;= m</p>
<p>3.每一个叶子节点都包含k-1个元素，其中 m/2 &lt;= k &lt;= m</p>
<p>4.所有的叶子结点都位于同一层。</p>
<p>5.每个节点中的元素从小到大排列，节点当中k-1个元素正好是k个孩子包含的元素的值域分划。</p>
<figure data-type="image" tabindex="37"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGoBqEgxvibyZ3S2O8GG2EcibsjkSxcKGRzGmJ3iaxkBAnc0vqOfTn2nMJWTQLICNFh8f4S8TeVpzeX6w/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="38"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGoBqEgxvibyZ3S2O8GG2EcibsBx8AoeUa9IVbk2JbdsjMZ5p0tdicHkO6fN6dCIwdIojkxicK4GdAv7XQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="39"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGoBqEgxvibyZ3S2O8GG2Ecibs5LFXxLRhEVH55mqXMhGf9C2icZ4iaFcBhUhABThvG0hiaoD1z4icgQJbbA/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="40"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrbI83f8meYn1UlzibHGBcqRSQb6eDxZctbAxvNt5gYKPlFEiaNaPcqor2hJ6peyuxGQDmQ8Gaougibw/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="41"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrbI83f8meYn1UlzibHGBcqRictJGn6axEj3BMbc5RwBiaAPPC9mWxYl6yhQ8icB1YAnux37NmYiatKQXQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="42"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrbI83f8meYn1UlzibHGBcqRwHXAS5B5icGP98ChYyCQ3jiaw7ickeibRBibZTtu5HwWM30R15VAbCh4tOQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="43"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrbI83f8meYn1UlzibHGBcqRxZ6vZjclNWA40cibmZAic9ZZYeZT4aOibCZVTAc4CaauXJN76UvDb7m3Q/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<p>第1次磁盘IO：</p>
<figure data-type="image" tabindex="44"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrbI83f8meYn1UlzibHGBcqRCCdQPjxVB531QYltibYibYIo6ialib6bg8sXJOBOeicDvEUvniastwicibaeibg/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<p>在内存中定位（和9比较）：</p>
<figure data-type="image" tabindex="45"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrbI83f8meYn1UlzibHGBcqRIiasUvxOs9ibvlu4PP4gtPZmAbhEVich1tpja1PDWeHyx5491J9bLE12A/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<p>第2次磁盘IO：</p>
<figure data-type="image" tabindex="46"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrbI83f8meYn1UlzibHGBcqR4ccGREXzfjztA98p0b4dICrLAXrsibqYaQU5MRezYuAchHlpdl9MIzw/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<p>在内存中定位（和2，6比较）：</p>
<figure data-type="image" tabindex="47"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrbI83f8meYn1UlzibHGBcqRKf8XQytR3X9B321Nkva8Fovzn9Fmn95HZP4oK1Il7aFFtCdyhHffUw/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<p>第3次磁盘IO：</p>
<figure data-type="image" tabindex="48"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrbI83f8meYn1UlzibHGBcqRMqrICiaHEH2ucwtbSgh4AT3usOO98Axv3mwHGWOea2GkJQ77Svxfs5g/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<p>在内存中定位（和3，5比较）：</p>
<figure data-type="image" tabindex="49"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrbI83f8meYn1UlzibHGBcqRu8LjAqtagyeicY27yaUG0SmmLQLCOP3VQrQNIeMCaxfibY6PpicuF1tyg/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="50"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrbI83f8meYn1UlzibHGBcqROjXMmxDcDp47DBcuORbpMnxg50rsBQ96CN1V8kxL2Z7KjsgJCl5diaw/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="51"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrbI83f8meYn1UlzibHGBcqRY7fntn7UFgicRUrjHaD0bdmWVYwVFHbcxYNVcibSeWIXbhiaAoVzccEiaQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="52"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrbI83f8meYn1UlzibHGBcqRzlhRceia6QePPtGlxXchpFllA5Pj2uxicwJGQNLiaJQcicDNYQ3ptnqn2g/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="53"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrbI83f8meYn1UlzibHGBcqRXpicfJ3TeTpKia3Q3O8g2GveeiadPpGQLU4LAt4hNCKra1fFSlHTvCWNw/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="54"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrbI83f8meYn1UlzibHGBcqRK4Kd1rCcGicTltzlzVFUWiblatibLy2rYfiaYrCKwv8IXb8egabgXJgWJg/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<p>自顶向下查找4的节点位置，发现4应当插入到节点元素3，5之间。</p>
<figure data-type="image" tabindex="55"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrbI83f8meYn1UlzibHGBcqRYk5euDrbMgVubTR4gvIL3U4LdicK3Fu1f7ATq9tGChL9YLXibJeuCTCA/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<p>节点3，5已经是两元素节点，无法再增加。父亲节点 2， 6 也是两元素节点，也无法再增加。根节点9是单元素节点，可以升级为两元素节点。于是<strong>拆分</strong>节点3，5与节点2，6，让根节点9升级为两元素节点4，9。节点6独立为根节点的第二个孩子。</p>
<figure data-type="image" tabindex="56"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrbI83f8meYn1UlzibHGBcqRSBqOKQc3NYe8HA7mX4QjSjUpfkWLqGBfWm8wHmic7qajFaickGSTX8NA/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="57"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrbI83f8meYn1UlzibHGBcqR9v2h25hzn192XuqicoUVCWIBEt6gKRocujXzDJiamrgib1EV1ibSpxNQUA/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="58"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrbI83f8meYn1UlzibHGBcqRbtPeqBtFvXneXlicy7aPRWiaQ59goTjyCAmnX1tTQ0KlY24NbMxtfF0w/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="59"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrbI83f8meYn1UlzibHGBcqRmC7NLG3HUZoqpvP30UDSMTj0WNwoUYhakYNibAQaUlKiclicvyMNt3bGA/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<p>自顶向下查找元素11的节点位置。</p>
<figure data-type="image" tabindex="60"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrbI83f8meYn1UlzibHGBcqRfnGwPGrX4NhnkJfBuKqNdXAyHWJiaBd5b0ruibuhHJvUnmCYpt1eJxdg/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<p>删除11后，节点12只有一个孩子，不符合B树规范。因此找出12,13,15三个节点的中位数13，取代节点12，而节点12自身下移成为第一个孩子。（这个过程称为<strong>左旋</strong>）</p>
<figure data-type="image" tabindex="61"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrbI83f8meYn1UlzibHGBcqRta9bOwANA1gjzduWKKAhl5N9IkFgZPNYNNzzdByY7LYiautLXVNnJ4w/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="62"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrbI83f8meYn1UlzibHGBcqRbDOA2SYhksUO3BlibgZciauxcTZFfXobCnFwPegUjLHYqwq4CW7gTYGg/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="63"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrbI83f8meYn1UlzibHGBcqRJL3EcNOic0fHafn4ltyInugPY8jtiaUkfQWMYOia3zcsqEmibZ7xszsvvw/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="64"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrbI83f8meYn1UlzibHGBcqRdkMYKpR4OMWfwLVEjyVTFvN247FyLu2xh6tiaAaZHLq3CdtbpHJNCicQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="65"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrbI83f8meYn1UlzibHGBcqRDNv7EqMgsEBvBibODkjW2iaO8ib2pOvBlarsmXK3bVPTJcqCV6qS9yTqA/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<figure data-type="image" tabindex="66"><img src="https://mmbiz.qpic.cn/mmbiz_jpg/NtO5sialJZGrbI83f8meYn1UlzibHGBcqR9e717QtA8PSsFvkWnwjs9HuI28mbpmvaLFFfSiakAlfnotvdZ0gibApA/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" loading="lazy"></figure>
<p>—————END—————</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[数据结构常见的八大排序算法]]></title>
        <id>https://tinaxiawuhao.github.io/post/0BBhLzjWl/</id>
        <link href="https://tinaxiawuhao.github.io/post/0BBhLzjWl/">
        </link>
        <updated>2021-04-25T08:06:18.000Z</updated>
        <content type="html"><![CDATA[<p>八大排序，三大查找是《数据结构》当中非常基础的知识点，在这里为了复习顺带总结了一下常见的八种排序算法。</p>
<p>常见的八大排序算法，他们之间关系如下：</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1619339616659.png" alt="" loading="lazy"></figure>
<p>他们的性能比较：</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1619339624226.png" alt="" loading="lazy"></figure>
<p>下面，利用java分别将他们进行实现。</p>
<h2 id="直接插入排序">直接插入排序</h2>
<h3 id="算法思想">算法思想：</h3>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1619339633556.gif" alt="" loading="lazy"></figure>
<p>直接插入排序的核心思想就是：将数组中的所有元素依次跟前面已经排好的元素相比较，如果选择的元素比已排序的元素小，则交换，直到全部元素都比较过。</p>
<p>因此，从上面的描述中我们可以发现，直接插入排序可以用两个循环完成：</p>
<ol>
<li>第一层循环：遍历待比较的所有数组元素</li>
<li>第二层循环：将本轮选择的元素(selected)与已经排好序的元素(ordered)相比较。</li>
</ol>
<p>如果：selected &lt; ordered，那么将二者交换</p>
<h3 id="代码实现">代码实现</h3>
<pre><code class="language-java">package sort;

import java.util.Arrays;

/**
 * @author wuhao
 * @desc 直接插入排序
 * @date 2020-12-02 15:04:57
 * 直接插入排序的核心思想就是：将数组中的所有元素依次跟前面已经排好的元素相比较，如果选择的元素比已排序的元素小，则交换，直到全部元素都比较过。
 * 因此，从上面的描述中我们可以发现，直接插入排序可以用两个循环完成：
 * 第一层循环：遍历待比较的所有数组元素
 * 第二层循环：将本轮选择的元素(selected)与已经排好序的元素(ordered)相比较。
 * 如果：selected &lt; ordered，那么将二者交换
 */
public class DirectInsertionSort {
    public static void main(String[] args) {
        int[] arr = {12, 32, 22, 7, 48};
        insertSort(arr);
    }

    private static void insertSort(int[] arr) {
       for (int i = 1; i &lt; arr.length; i++) {
           int temp = arr[i];
           int j;
           for (j = i - 1; j &gt;= 0; j--) {
               if (temp &lt; arr[j]) {
                   arr[j + 1] = arr[j];
               } else {
                   break;
               }
           }
           arr[j + 1] = temp;
       }

        System.out.println(Arrays.toString(arr));
    }
}

</code></pre>
<h2 id="希尔排序">希尔排序</h2>
<h3 id="算法思想-2">算法思想：</h3>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1619339644637.png" alt="" loading="lazy"></figure>
<p>希尔排序的算法思想：将待排序数组按照步长gap进行分组，然后将每组的元素利用直接插入排序的方法进行排序；每次将gap折半减小，循环上述操作；当gap=1时，利用直接插入，完成排序。</p>
<p>同样的：从上面的描述中我们可以发现：希尔排序的总体实现应该由三个循环完成：</p>
<ol>
<li>第一层循环：将gap依次折半，对序列进行分组，直到gap=1</li>
<li>第二、三层循环：也即直接插入排序所需要的两次循环。具体描述见上。</li>
</ol>
<h3 id="代码实现-2">代码实现</h3>
<pre><code class="language-java">package sort;

import java.util.Arrays;

/**
 * @author wuhao
 * @desc 希尔排序
 * @date 2020-12-02 15:20:43
 * 希尔排序的算法思想：将待排序数组按照步长gap进行分组，然后将每组的元素利用直接插入排序的方法进行排序；每次将gap折半减小，循环上述操作；当gap=1时，利用直接插入，完成排序。
 * 同样的：从上面的描述中我们可以发现：希尔排序的总体实现应该由三个循环完成：
 * 第一层循环：将gap依次折半，对序列进行分组，直到gap=1
 * 第二、三层循环：也即直接插入排序所需要的两次循环。具体描述见上。
 */
public class HillSort {
    public static void main(String[] args) {
        int[] arr = {12, 32, 22, 7, 48, 3, 5, 6, 8, 24};
        shellSort(arr);
    }

    private static void shellSort(int[] arr) {
        for (int step = arr.length / 2; step &gt; 0; step /= 2) {
//            for (int i = step; i &lt; arr.length; i++) {
//                int temp = arr[i];
//                int j;
//                for (j = i - step; j &gt;= 0 &amp;&amp; arr[j] &gt; temp; j -= step) {
//                    arr[j + step] = arr[j];
//                }
//                arr[j + step] = temp;
//            }
            for (int i = step; i &lt; arr.length; i++) {
                int k=i;
                for (int j = i-step; j &gt;=0 &amp;&amp; arr[j] &gt; arr[k]; j -= step,k -=step) {
                   int temp = arr[j];
                    arr[j]= arr[k];
                    arr[k]=temp;
                }
            }
        }

        System.out.println(Arrays.toString(arr));

    }
}

</code></pre>
<h2 id="简单选择排序">简单选择排序</h2>
<h3 id="算法思想-3">算法思想</h3>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1619339776440.gif" alt="" loading="lazy"></figure>
<p>简单选择排序的基本思想：比较+交换。</p>
<ol>
<li>从待排序序列中，找到关键字最小的元素；</li>
<li>如果最小元素不是待排序序列的第一个元素，将其和第一个元素互换；</li>
<li>从余下的 N - 1 个元素中，找出关键字最小的元素，重复(1)、(2)步，直到排序结束。</li>
</ol>
<p>因此我们可以发现，简单选择排序也是通过两层循环实现。</p>
<p>第一层循环：依次遍历序列当中的每一个元素</p>
<p>第二层循环：将遍历得到的当前元素依次与余下的元素进行比较，符合最小元素的条件，则交换。</p>
<h3 id="代码实现-3">代码实现</h3>
<pre><code class="language-java">package sort;

import java.util.Arrays;

/**
 * @author wuhao
 * @desc 简单选择排序
 * @date 2020-12-02 16:21:47
 * 简单选择排序的基本思想：比较+交换。
 * 从待排序序列中，找到关键字最小的元素；
 * 如果最小元素不是待排序序列的第一个元素，将其和第一个元素互换；
 * 从余下的 N - 1 个元素中，找出关键字最小的元素，重复(1)、(2)步，直到排序结束。
 * 因此我们可以发现，简单选择排序也是通过两层循环实现。
 * 第一层循环：依次遍历序列当中的每一个元素
 * 第二层循环：将遍历得到的当前元素依次与余下的元素进行比较，符合最小元素的条件，则交换。
 */
public class SimpleSelectionSort {
    public static void main(String[] args) {
        int[] arr = {12, 32, 22, 7, 48, 3, 5, 6, 8, 24};
        selectionSort(arr);
    }

    private static void selectionSort(int[] arr) {
        for (int i = 0; i &lt; arr.length; i++) {
            int k = i;
            for (int j = i + 1; j &lt; arr.length; j++) {
                if (arr[j] &lt; arr[k]) {
                    k = j;
                }
            }
            if (k != i) {
                int temp = arr[i];
                arr[i] = arr[k];
                arr[k] = temp;
            }


        }
        System.out.println(Arrays.toString(arr));
    }
}
</code></pre>
<h2 id="堆排序">堆排序</h2>
<h3 id="堆的概念">堆的概念</h3>
<p>堆：本质是一种数组对象。特别重要的一点性质：<b>任意的叶子节点小于（或大于）它所有的父节点</b>。对此，又分为大顶堆和小顶堆，大顶堆要求节点的元素都要大于其孩子，小顶堆要求节点元素都小于其左右孩子，两者对左右孩子的大小关系不做任何要求。</p>
<p>利用堆排序，就是基于大顶堆或者小顶堆的一种排序方法。下面，我们通过大顶堆来实现。</p>
<h3 id="基本思想">基本思想：</h3>
<p>堆排序可以按照以下步骤来完成：</p>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1619339787440.png" alt="" loading="lazy"></figure>
<p>构建大顶堆.png</p>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1619339794481.png" alt="" loading="lazy"></figure>
<p>Paste_Image.png</p>
<ol>
<li>构建初始堆，将待排序列构成一个大顶堆(或者小顶堆)，升序大顶堆，降序小顶堆；</li>
<li>将堆顶元素与堆尾元素交换，并断开(从待排序列中移除)堆尾元素。</li>
<li>重新构建堆。</li>
<li>重复2~3，直到待排序列中只剩下一个元素(堆顶元素)。</li>
</ol>
<h3 id="代码实现-4">代码实现：</h3>
<pre><code class="language-java">package sort;

import java.util.Arrays;

/**
 * @author wuhao
 * @desc 堆排序
 * @date 2020-12-04 09:13:58
 * 堆排序可以按照以下步骤来完成：
 * 首先将序列构建称为大顶堆；
 * （这样满足了大顶堆那条性质：位于根节点的元素一定是当前序列的最大值）
 * 取出当前大顶堆的根节点，将其与序列末尾元素进行交换；
 * （此时：序列末尾的元素为已排序的最大值；由于交换了元素，当前位于根节点的堆并不一定满足大顶堆的性质）
 * 对交换后的n-1个序列元素进行调整，使其满足大顶堆的性质；
 * 重复2.3步骤，直至堆中只有1个元素为止
 */
public class HeapSort {
    public static void main(String[] args) {
        int[] arr = {11, 44, 23, 67, 88, 65, 34, 48, 9, 12};
        heapSort(arr);
        System.out.println(Arrays.toString(arr));
    }

    private static void heapSort(int[] a) {
        // 首先需要创建根堆
        for (int i = a.length / 2; i &gt;= 0; i--) { // 从最后一个非终端结点开始，然后一次--
            HeapAdjust(a, i, a.length);
        }

        for (int i = a.length - 1; i &gt; 0; --i) {// 这个循环是把最大值a[0]放到末尾 ，
            int temp = a[0];
            a[0] = a[i]; // 此时i代表最后一个元素
            a[i] = temp;
            HeapAdjust(a, 0, i );
        }
    }

    // 调整堆
    private static void HeapAdjust(int[] a, int parent, int m) {// parent代表当前 m代表最后
        int temp = a[parent]; // 先把a[parent]的值赋给temp保存起来
        for (int j = 2 * parent; j &lt; m; j *= 2) {
            if (j+1 &lt; m &amp;&amp; a[j] &lt; a[j + 1]) { // 判断是a[parent]大还是a[j + 1]大，如果a[j + 1]大 就++j，把j换成当前最大
                j++;
            }
            if (temp &gt;= a[j]) { // 如果temp中比最大值还大，代表本身就是一个根堆，break
                break;// 如果大于，就代表当前为大跟对，退出
            }
            a[parent] = a[j];// 否则就把最大给[parent]
            parent = j;// 然后把最大下标给parent，继续循环,检查是否因为调整根堆而破坏了子树
        }
        a[parent] = temp;
    }

    /**
     * 创建堆，
     * @param arr 待排序列
     */
//    private static void heapSort(int[] arr) {
//        //创建堆
//        for (int i = (arr.length - 1) / 2; i &gt;= 0; i--) {
//            //从第一个非叶子结点从下至上，从右至左调整结构
//            adjustHeap(arr, i, arr.length);
//        }
//
//        //调整堆结构+交换堆顶元素与末尾元素
//        for (int i = arr.length - 1; i &gt; 0; i--) {
//            //将堆顶元素与末尾元素进行交换
//            int temp = arr[i];
//            arr[i] = arr[0];
//            arr[0] = temp;
//
//            //重新对堆进行调整
//            adjustHeap(arr, 0, i);
//        }
//    }

    /**
     * 调整堆
     * @param arr 待排序列
     * @param parent 父节点
     * @param length 待排序列尾元素索引
     */
//    private static void adjustHeap(int[] arr, int parent, int length) {
//        //将temp作为父节点
//        int temp = arr[parent];
//        //左孩子
//        int lChild = 2 * parent + 1;
//
//        while (lChild &lt; length) {
//            //右孩子
//            int rChild = lChild + 1;
//            // 如果有右孩子结点，并且右孩子结点的值大于左孩子结点，则选取右孩子结点
//            if (rChild &lt; length &amp;&amp; arr[lChild] &lt; arr[rChild]) {
//                lChild++;
//            }
//
//            // 如果父结点的值已经大于孩子结点的值，则直接结束
//            if (temp &gt;= arr[lChild]) {
//                break;
//            }
//
//            // 把孩子结点的值赋给父结点
//            arr[parent] = arr[lChild];
//
//            //选取孩子结点的左孩子结点,继续向下筛选
//            parent = lChild;
//            lChild = 2 * lChild + 1;
//        }
//        arr[parent] = temp;
//    }

}

</code></pre>
<h2 id="冒泡排序">冒泡排序</h2>
<h3 id="基本思想-2">基本思想</h3>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1619339811436.gif" alt="" loading="lazy"></figure>
<p>冒泡排序思路比较简单：</p>
<ul>
<li>
<ol>
<li>将序列当中的左右元素，依次比较，保证右边的元素始终大于左边的元素；</li>
</ol>
</li>
</ul>
<p>（ 第一轮结束后，序列最后一个元素一定是当前序列的最大值；）</p>
<ul>
<li>
<ol>
<li>对序列当中剩下的n-1个元素再次执行步骤1。</li>
<li>对于长度为n的序列，一共需要执行n-1轮比较</li>
</ol>
</li>
</ul>
<p>（利用while循环可以减少执行次数）</p>
<h3 id="代码实现-5">代码实现</h3>
<pre><code class="language-java">package sort;

import java.util.Arrays;

/**
 * @author wuhao
 * @desc 冒泡排序
 * @date 2020-12-02 16:34:57
 * 冒泡排序思路比较简单：
 * 将序列当中的左右元素，依次比较，保证右边的元素始终大于左边的元素；
 * （ 第一轮结束后，序列最后一个元素一定是当前序列的最大值；）
 * 对序列当中剩下的n-1个元素再次执行步骤1。
 * 对于长度为n的序列，一共需要执行n-1轮比较
 * （利用while循环可以减少执行次数）
 */
public class BubbleSort {
    public static void main(String[] args) {
        int[] arr = {12, 32, 22, 7, 48};
        bubbleSort(arr);
    }

    private static void bubbleSort(int[] arr) {
        for (int i = 0; i &lt; arr.length; i++) {
            for (int j = 0; j &lt; i; j++) {
                if (arr[i] &lt; arr[j]) {
                    int temp=arr[j];
                    arr[j]=arr[i];
                    arr[i]=temp;
                }
            }
        }
        System.out.println(Arrays.toString(arr));
    }
}

</code></pre>
<h2 id="快速排序">快速排序</h2>
<h3 id="算法思想-4">算法思想：</h3>
<figure data-type="image" tabindex="9"><img src="https://tinaxiawuhao.github.io/post-images/1619339820307.gif" alt="" loading="lazy"></figure>
<p>快速排序的基本思想：挖坑填数+分治法</p>
<ul>
<li>
<ol>
<li>从序列当中选择一个基准数(pivot)</li>
</ol>
</li>
</ul>
<p>在这里我们选择序列当中第一个数为基准数</p>
<ul>
<li>
<ol>
<li>将序列当中的所有数依次遍历，比基准数大的位于其右侧，比基准数小的位于其左侧</li>
<li>重复步骤a.b，直到所有子集当中只有一个元素为止。</li>
</ol>
</li>
</ul>
<p>用伪代码描述如下：</p>
<p>1．i =L; j = R; 将基准数挖出形成第一个坑a[i]。</p>
<p>2．j--由后向前找比它小的数，找到后挖出此数填前一个坑a[i]中。</p>
<p>3．i++由前向后找比它大的数，找到后也挖出此数填到前一个坑a[j]中。</p>
<p>4．再重复执行2，3二步，直到i==j，将基准数填入a[i]中</p>
<h3 id="代码实现-6">代码实现：</h3>
<pre><code class="language-java">package sort;

import java.util.Arrays;
import java.util.Stack;

/**
 * @author wuhao
 * @desc 快速排序
 * @date 2020-12-02 17:08:57
 * 快速排序的基本思想：挖坑填数+分治法
 * 从序列当中选择一个基准数(pivot)
 * 在这里我们选择序列当中第一个数为基准数
 * 将序列当中的所有数依次遍历，比基准数大的位于其右侧，比基准数小的位于其左侧
 * 重复步骤a.b，直到所有子集当中只有一个元素为止。
 * 用伪代码描述如下：
 * 1．i =L; j = R; 将基准数挖出形成第一个坑a[i]。
 * 2．j--由后向前找比它小的数，找到后挖出此数填前一个坑a[i]中。
 * 3．i++由前向后找比它大的数，找到后也挖出此数填到前一个坑a[j]中。
 * 4．再重复执行2，3二步，直到i==j，将基准数填入a[i]中
 */
public class QuickSort {
    public static void main(String[] args) {
        int[] arr = {12, 32, 22, 7, 48, 3, 35, 6, 8, 42};
//        quickSort(arr, 0, arr.length - 1);
        System.out.println(Arrays.toString(arr));

        /*-----------非递归实现----------*/
        sort(arr, 0, arr.length - 1);
        System.out.println(Arrays.toString(arr));
    }

    private static void quickSort(int[] arr, int left, int right) {
        if (left &gt; right) {
            return;
        }
        // base中存放基准数
        int base = arr[left];
        int i = left, j = right;
        while (i != j) {
            // 顺序很重要，先从右边开始往左找，直到找到比base值小的数
            while (arr[j] &gt;= base &amp;&amp; i &lt; j) {
                j--;
            }

            // 再从左往右边找，直到找到比base值大的数
            while (arr[i] &lt;= base &amp;&amp; i &lt; j) {
                i++;
            }

            // 上面的循环结束表示找到了位置或者(i&gt;=j)了，交换两个数在数组中的位置
            if (i &lt; j) {
                int tmp = arr[i];
                arr[i] = arr[j];
                arr[j] = tmp;
            }
        }
        // 将基准数放到中间的位置（基准数归位）
        arr[left] = arr[i];
        arr[i] = base;

        // 递归，继续向基准的左右两边执行和上面同样的操作
        // i的索引处为上面已确定好的基准值的位置，无需再处理
        quickSort(arr, left, i - 1);
        quickSort(arr, i + 1, right);

    }


    /*-----------------------------非递归实现------------------------------*/
    public static void sort(int[] arr, int left, int right) {
        int privot, top, last;
        Stack&lt;Integer&gt; s = new Stack&lt;&gt;();
        privot = QuickSort(arr, left, right);
        if (privot &gt; left + 1) {
            s.push(left);
            s.push(privot - 1);

        }
        if (privot &lt; right - 1) {
            s.push(privot + 1);
            s.push(right);
        }
        while (!s.empty()) {
            top = s.pop();
            last = s.pop();
            privot = QuickSort(arr, last, top);
            if (privot &gt; last + 1) {
                s.push(last);
                s.push(privot - 1);
            }
            if (privot &lt; top - 1) {
                //System.out.println(top);
                s.push(privot + 1);
                s.push(top);
            }
        }
    }

    public static int QuickSort(int[] arr, int left, int right) {
        int privot = left;
        while (left &lt; right) {
            while ((arr[privot] &lt; arr[right]) &amp; left &lt; right) {
                right--;
            }
            int temp = arr[privot];
            arr[privot] = arr[right];
            arr[right] = temp;
            privot = right;

            while ((arr[privot] &gt; arr[left]) &amp; left &lt; right) {
                left++;
            }
            temp = arr[privot];
            arr[privot] = arr[left];
            arr[left] = temp;
            privot = left;
        }
        return privot;
    }
}

</code></pre>
<h2 id="归并排序">归并排序</h2>
<h3 id="算法思想-5">算法思想：</h3>
<figure data-type="image" tabindex="10"><img src="https://tinaxiawuhao.github.io/post-images/1619339833766.png" alt="" loading="lazy"></figure>
<ul>
<li>
<ol>
<li>归并排序是建立在归并操作上的一种有效的排序算法，该算法是采用0的一个典型的应用。它的基本操作是：将已有的子序列合并，达到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。</li>
<li>归并排序其实要做两件事：</li>
</ol>
</li>
<li>
<ul>
<li>分解----将序列每次折半拆分</li>
<li>合并----将划分后的序列段两两排序合并</li>
</ul>
</li>
</ul>
<p>因此，归并排序实际上就是两个操作，拆分+合并</p>
<ul>
<li>
<ol>
<li>如何合并？</li>
</ol>
</li>
</ul>
<p>L[first...mid]为第一段，L[mid+1...last]为第二段，并且两端已经有序，现在我们要将两端合成达到L[first...last]并且也有序。</p>
<ul>
<li>
<ul>
<li>首先依次从第一段与第二段中取出元素比较，将较小的元素赋值给temp[]</li>
<li>重复执行上一步，当某一段赋值结束，则将另一段剩下的元素赋值给temp[]</li>
<li>此时将temp[]中的元素复制给L[]，则得到的L[first...last]有序</li>
</ul>
</li>
<li>
<ol>
<li>如何分解？</li>
</ol>
</li>
</ul>
<p>在这里，我们采用递归的方法，首先将待排序列分成A,B两组；然后重复对A、B序列</p>
<p>分组；直到分组后组内只有一个元素，此时我们认为组内所有元素有序，则分组结束。</p>
<h3 id="代码实现-7">代码实现</h3>
<pre><code class="language-java">package sort;

import java.util.Arrays;

/**
 * @author wuhao
 * @desc 归并排序
 * @date 2020-12-03 09:35:00
 * 归并排序是建立在归并操作上的一种有效的排序算法，该算法是采用0的一个典型的应用。它的基本操作是：将已有的子序列合并，达到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。
 * 归并排序其实要做两件事：
 * 分解----将序列每次折半拆分
 * 合并----将划分后的序列段两两排序合并
 * 因此，归并排序实际上就是两个操作，拆分+合并
 * 如何合并？
 * L[first...mid]为第一段，L[mid+1...last]为第二段，并且两端已经有序，现在我们要将两端合成达到L[first...last]并且也有序。
 * 首先依次从第一段与第二段中取出元素比较，将较小的元素赋值给temp[]
 * 重复执行上一步，当某一段赋值结束，则将另一段剩下的元素赋值给temp[]
 * 此时将temp[]中的元素复制给L[]，则得到的L[first...last]有序
 * 如何分解？
 * 在这里，我们采用递归的方法，首先将待排序列分成A,B两组；然后重复对A、B序列
 * 分组；直到分组后组内只有一个元素，此时我们认为组内所有元素有序，则分组结束。
 */
public class MergeSort {
    public static void main(String[] args) {
        int[] arr = {11, 44, 23, 67, 88, 65, 34, 48, 9, 12};
        int[] tmp = new int[arr.length];    //新建一个临时数组存放
        mergeSort(arr, 0, arr.length - 1, tmp);
        System.out.println(Arrays.toString(arr));
    }

    private static void mergeSort(int[] arr, int low, int high, int[] tmp) {
        if (low &lt; high) {
            int mid = (low + high) / 2;
            mergeSort(arr, low, mid, tmp);
            mergeSort(arr, mid + 1, high, tmp);
            merge(arr, low, mid, high, tmp);
        }
    }

    private static void merge(int[] arr, int low, int mid, int high, int[] tmp) {
        int i = 0;
        int j = low, k = mid + 1;
        while (j &lt;= mid &amp;&amp; k &lt;= high) {
            if (arr[j] &lt; arr[k]) {
                tmp[i++] = arr[j++];
            } else {
                tmp[i++] = arr[k++];
            }
        }
        while (j &lt;= mid) {
            tmp[i++] = arr[j++];
        }
        while (k &lt;= high) {
            tmp[i++] = arr[k++];
        }
        for (int l = 0; l &lt; i; l++) {
            arr[low+l] = tmp[l];
        }

    }
}

</code></pre>
<h2 id="基数排序">基数排序</h2>
<h3 id="算法思想-6">算法思想</h3>
<figure data-type="image" tabindex="11"><img src="https://tinaxiawuhao.github.io/post-images/1619339840696.gif" alt="" loading="lazy"></figure>
<ul>
<li>
<ol>
<li>基数排序：通过序列中各个元素的值，对排序的N个元素进行若干趟的“分配”与“收集”来实现排序。</li>
</ol>
</li>
</ul>
<p>分配：我们将L[i]中的元素取出，首先确定其个位上的数字，根据该数字分配到与之序号相同的桶中</p>
<p>收集：当序列中所有的元素都分配到对应的桶中，再按照顺序依次将桶中的元素收集形成新的一个待排序列L[ ]</p>
<p>对新形成的序列L[]重复执行分配和收集元素中的十位、百位...直到分配完该序列中的最高位，则排序结束</p>
<h3 id="代码实现-8">代码实现</h3>
<pre><code class="language-java">package sort;

import java.util.Arrays;

/**
 * @author wuhao
 * @desc 基数排序
 * @date 2020-12-03 09:58:32
 * 基数排序：通过序列中各个元素的值，对排序的N个元素进行若干趟的“分配”与“收集”来实现排序。
 * 分配：我们将L[i]中的元素取出，首先确定其个位上的数字，根据该数字分配到与之序号相同的桶中
 * 收集：当序列中所有的元素都分配到对应的桶中，再按照顺序依次将桶中的元素收集形成新的一个待排序列L[ ]
 * 对新形成的序列L[]重复执行分配和收集元素中的十位、百位...直到分配完该序列中的最高位，则排序结束
 * 根据上述“基数排序”的展示，我们可以清楚的看到整个实现的过程
 */
public class BaseSort {
    public static void main(String[] args) {
        int[] arr = {63, 157, 189, 51, 101, 47, 141, 121, 157, 156,
                194, 117, 98, 139, 67, 133, 181, 12, 28, 0, 109};

        radixSort(arr);
        System.out.println(Arrays.toString(arr));
    }

    private static void radixSort(int[] arr) {
        //待排序列最大值
        int max = arr[0];
        int exp;//指数
        //计算最大值
        for (int anArr : arr) {
            if (anArr &gt; max) {
                max = anArr;
            }
        }
        //从个位开始，对数组进行排序
        for (exp = 1; max / exp &gt; 0; exp *= 10) {
            //存储待排元素的临时数组
            int[] temp = new int[arr.length];
            //分桶个数
            int[] buckets = new int[10];

            //将数据出现的次数存储在buckets中
            for (int value : arr) {
                //(value / exp) % 10 :value的最底位(个位)
                buckets[(value / exp) % 10]++;
            }

            //更改buckets[i]，
            for (int i = 1; i &lt; 10; i++) {
                buckets[i] += buckets[i - 1];
            }

            //将数据存储到临时数组temp中
            for (int i = arr.length - 1; i &gt;= 0; i--) {
                temp[buckets[(arr[i] / exp) % 10] - 1] = arr[i];
                buckets[(arr[i] / exp) % 10]--;
            }

            //将有序元素temp赋给arr
            System.arraycopy(temp, 0, arr, 0, arr.length);
        }

    }
}
</code></pre>
<h2 id="后记">后记</h2>
<p>写完之后运行了一下时间比较：</p>
<p>从运行结果上来看，堆排序、归并排序、基数排序是真的快。</p>
<p>对于快速排序迭代深度超过的问题，可以将考虑将快排通过非递归的方式进行实现。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Linux文件操作高频使用命令]]></title>
        <id>https://tinaxiawuhao.github.io/post/yzriNkrRn/</id>
        <link href="https://tinaxiawuhao.github.io/post/yzriNkrRn/">
        </link>
        <updated>2021-04-25T02:28:57.000Z</updated>
        <content type="html"><![CDATA[<h2 id="新建操作">新建操作：</h2>
<pre><code class="language-shell">mkdir abc #新建一个文件夹
touch abc.sh #新建一个文件
</code></pre>
<h2 id="查看操作">查看操作</h2>
<h3 id="查看目录">查看目录：</h3>
<pre><code class="language-shell">ll #显示目录文件详细信息 
du -h 文件/目录  #查看大小
pwd #显示路径
</code></pre>
<h3 id="查看文件内容">查看文件内容：</h3>
<h4 id="catheadtail命令">cat|head|tail命令</h4>
<pre><code class="language-shell">#查看abc的内容 
cat abc.txt      
 #查看abc前5行内容。默认是10行 
head -5 abc.txt 
tail [选项] 文件名 各选项的含义如下：
    +num：从第num行以后开始显示 
    -num：从距文件尾num行处开始显示。如果省略num参数，系统默认值为10. 
    -f: 循环读取,例如查看服务器日志时，可以实时观察 
#filename 文件里的最尾部的内容显示在屏幕上，并且不断刷新。 
tail -f filename  
#查看最后20行 
tail -f filename
</code></pre>
<h4 id="more命令">more命令：</h4>
<pre><code class="language-shell">more命令一次显示一屏信息，若信息未显示完屏幕底部将出现“-More-（xx%）”。

此时按Space键，可显示下一屏内容；

按“回车”键，显示下一行内容；

按B键，显示上一屏；

按Q键，可退出more命令。
</code></pre>
<h4 id="less命令">less命令：</h4>
<p>和more命令类似，但是比more命令更强大。在很多时候，必须使用less,比如管道。例如：</p>
<pre><code class="language-shell">ll /etc | less
</code></pre>
<h4 id="stat-命令">stat 命令：</h4>
<p>查看文件的详细信息，比如创建修改时间，大小等</p>
<pre><code class="language-sh">[root@localhost zx]# stat index.html 
  文件：&quot;index.html&quot;
  大小：29006     	块：64         IO 块：4096   普通文件
设备：fd00h/64768d	Inode：17589607    硬链接：1
权限：(0644/-rw-r--r--)  Uid：(    0/    root)   Gid：(    0/    root)
环境：unconfined_u:object_r:home_root_t:s0
最近访问：2021-04-25 21:47:41.824053666 +0800
最近更改：2021-04-25 21:44:33.588587500 +0800
最近改动：2021-04-25 21:44:33.588587500 +0800
创建时间：-
</code></pre>
<h4 id="du-命令">du 命令：</h4>
<p>选项：-h 以合适的单位显示（会根据文件的大小自动选择kb或M等单位）</p>
<pre><code class="language-shell">[root@localhost zx]# du -h index.html
32K	index.html
</code></pre>
<h2 id="复制操作">复制操作</h2>
<h3 id="同一机器的复制">同一机器的复制：</h3>
<h4 id="cp复制文件或目录">cp:复制文件或目录</h4>
<h4 id="语法">语法：</h4>
<pre><code class="language-shell">cp [options] source dest

    -a：此选项通常在复制目录时使用，它保留链接、文件属性，并复制目录下的所有内容。其作用等于dpR参数组合。
    -d：复制时保留链接。这里所说的链接相当于Windows系统中的快捷方式。
    -f：覆盖已经存在的目标文件而不给出提示。
    -i：与-f选项相反，在覆盖目标文件之前给出提示，要求用户确认是否覆盖，回答&quot;y&quot;时目标文件将被覆盖。
    -p：除复制文件的内容外，还把修改时间和访问权限也复制到新文件中。
    -r：若给出的源文件是一个目录文件，此时将复制该目录下所有的子目录和文件。
    -l：不复制文件，只是生成链接文件。
</code></pre>
<h4 id="举例">举例：</h4>
<pre><code class="language-shell">#将../html/index.html 复制到当前目录
cp ../html/index.html .    
#将../html/ 目录下的文件及子目录复制到当前的tt目录下，如果tt不存在，会自动创建
cp -r ../html/  tt/       
#将文件file复制到目录/usr/men/tmp下，并改名为file1
cp file /usr/men/tmp/file1  
    
#如果dir2目录已存在，则需要使用
cp -r dir1/. dir2
#如果这时使用cp -r dir1 dir2,则也会将dir1目录复制到dir2中，明显不符合要求。
ps:dir1、dir2改成对应的目录路径即可
</code></pre>
<h3 id="远程复制">远程复制</h3>
<pre><code class="language-shell">#将当前目录下的test.txt复制到远程111.12机器的/zx目录下
scp test.txt root@192.168.111.12:/zx

#将test.txt复制到远程用户的根目录，并命名为textA.txt
scp test.txt root@192.168.111.12:testA.txt

#也可以不指定用户，在后续提示中再输入，如下：
scp test.txt 192.168.111.12:/zx

#从远程复制到本地： -r用于递归整个目录
scp -r remote_user@remote_ip:remote_folder local_path
</code></pre>
<h2 id="移动操作">移动操作:</h2>
<p>移动操作可以理解成复制文件后，删除原文件。</p>
<pre><code class="language-shell">#复制/zx/soft目录中的所有文件到当前目录
mv /zx/soft/* . 
#复制当前目录a.txt到当前的test目录下。
mv a.txt ./test/a.txt  
#复制文件夹到/tmp/下，必须保证tmp是存在的文件夹
mv /zx/soft/  /tmp/soft  
</code></pre>
<h2 id="重命名操作">重命名操作</h2>
<p>重命名还是用的移动操作命令，比如：</p>
<pre><code class="language-shell">#将目录(文件)A重命名为B
mv A B
#将/a目录(文件)移动到/b下，并重命名为c。要保证b目录存在。
mv /a /b/c
#将当前test1目录移动到当前的test目录并命名为b
mv ./test1 ./test/b 
</code></pre>
<h2 id="解压压缩操作">解压压缩操作</h2>
<h3 id="tar">tar</h3>
<pre><code class="language-shell">-c: 建立压缩档案
-x：解压
-t：查看内容
-r：向压缩归档文件末尾追加文件
-u：更新原压缩包中的文件
这五个是独立的命令，压缩解压都要用到其中一个，可以和别的命令连用但只能用其中一个。下面的参数是根据需要在压缩或解压档案时可选的。

-z：有gzip属性的
-j：有bz2属性的
-Z：有compress属性的
-v：显示所有过程
-O：将文件解开到标准输出

下面的参数-f是必须的
-f: 使用档案名字，切记，这个参数是最后一个参数，后面只能接档案名。
</code></pre>
<h4 id="举例说明">举例说明</h4>
<pre><code class="language-shell">tar -cf all.tar *.jpg
这条命令是将所有.jpg的文件打成一个名为all.tar的包。-c是表示产生新的包，-f指定包的文件名。
tar -tf all.tar
这条命令是列出all.tar包中所有文件，-t是列出文件的意思
tar -xf all.tar
这条命令是解出all.tar包中所有文件，-x是解开的意思
压缩
tar –cvf jpg.tar *.jpg //将目录里所有jpg文件打包成jpg.tar
eg2:
    tar -xzf nginx-1.14.0.tar.gz //解压到当前目录
    tar -zxf nginx-1.14.0.tar.gz -C /usr/local/nginx  #解压到对应目录
 eg3:
 	tar -zxvf nginx...tar.gz #解压并显示过程
 	
注意：有些压缩程序提示命令找不到，需要进行安装，例如：
yum install unzip
或在ubuntu上：
apt-get install unzip
</code></pre>
<h4 id="总结">总结</h4>
<pre><code class="language-shell">1、*.tar 用 tar –xvf 解压
2、*.gz 用 gzip -d或者gunzip 解压
3、*.tar.gz和*.tgz 用 tar –xzf 解压
4、*.bz2 用 bzip2 -d或者用bunzip2 解压
5、*.tar.bz2用tar –xjf 解压
6、*.Z 用 uncompress 解压
7、*.tar.Z 用tar –xZf 解压
8、*.rar 用 unrar e解压
9、*.zip 用 unzip 解压  

解压的时候，有时候不想覆盖已经存在的文件，那么可以加上-n参数
unzip -n test.zip
unzip -n -d /temp test.zip
只看一下zip压缩包中包含哪些文件，不进行解压缩
unzip -l test.zip
查看显示的文件列表还包含压缩比率
unzip -v test.zip
检查zip文件是否损坏
unzip -t test.zip
如果已有相同的文件存在，要求unzip命令覆盖原先的文件
unzip -o test.zip -d /tmp/
示例：
 eg1:  unzip mydata.zip -d mydatabak #解压到mydatabak目录
 
1.  xz
	这是两层压缩，外面是xz压缩方式，里层是tar压缩,所以可以分两步实现解压
	$ xz -d node-v6.10.1-linux-x64.tar.xz
    $ tar -xvf node-v6.10.1-linux-x64.tar
</code></pre>
<h2 id="上传文件工具">上传文件工具</h2>
<p>从本地windows上传一些文件到远程Linux服务器可以通过xshell的xftp也可以通过下面这个小工具lrzsz，使用更加方便。</p>
<pre><code class="language-shell">#安装工具
yum install lrzsz 

常用命令：
#下载文件dist.zip到本地
sz dist.zip 
#会打开窗口，上传文件到远程服务器
rz 
</code></pre>
<h2 id="ln-file和touch命令">ln、file和touch命令</h2>
<h3 id="ln命令">ln命令</h3>
<p>用于创建链接文件，包括硬链接(Hard Link)和符号链接（Symbolic Link) 。我们常用的是符号链接，也称软连接。软连接就类似windows里的快捷方式。</p>
<h4 id="示例">示例：</h4>
<pre><code class="language-shell">#在当前目录创建一个软连接，指向/etc/fastab，名称也是fastab
ln -s /etc/fastab

#在当前目录创建一个指向/boot/grub的软连接，命名为gb
ln -s /boot/grub gb
</code></pre>
<p>注意：删除软连接 正确方式是：</p>
<pre><code class="language-shell">rm -rf ./gb
</code></pre>
<p>错误方式:</p>
<pre><code class="language-shell">rm -rf ./gb/
</code></pre>
<p>这样会删除了原有grub下的内容。特别是针对系统文件的软连接，删除一定要慎重。</p>
<h4 id="file命令">file命令</h4>
<p>用于识别文件的类型</p>
<p>Linux中文件后缀只是方便使用者识别，没有实质的约束作用。file命令可以查看文件的实质类型：</p>
<pre><code class="language-shell">file [-bcLz] 文件|目录

选项说明：

    文件|目录：需要识别的文件或目录
    -b: 显示识别结果时，不显示文件名
    -c: 显示执行过程
    -L: 直接显示符号链接文件指向的文件类型
    -z: 尝试去解读压缩文件的内容
</code></pre>
<h4 id="示例-2">示例：</h4>
<p>可以看出，index.mp4本质是一个HTML而非一个mp4文件</p>
<pre><code class="language-shell">[root@VM_0_13_centos soft]# file index.mp4 
index.mp4: HTML document, UTF-8 Unicode text, with very long lines**touch命令：** 用于改变文件或目录的访问时间和修改时间。
</code></pre>
<h3 id="touch命令">touch命令：</h3>
<p>用于改变文件或目录的访问时间和修改时间。</p>
<pre><code class="language-shell">touch [-am] [-t&lt;日期时间&gt;] [目录|文件]
</code></pre>
<p>如果指定目录文件不存在，则会直接创建一个空文件，所以touch也常用来创建一个空白文件</p>
<pre><code class="language-shell">#创建一个新文件aa.txt
touch aa.txt

选项说明：

    -a: 只修改访问时间
    -m : 只修改 修改时间
    -t : 使用指定日期时间，而非系统时间 。例如要修改为2019年10月20日16：38分13秒。参数就是：‘20191020163813’
</code></pre>
<h4 id="示例-3">示例：</h4>
<p>修改之前可以先查看文件的时间戳: 用stat 命令查看</p>
<pre><code class="language-shell">[root@VM_0_13_centos soft]# stat index.html 
  File: ‘index.html’
  Size: 17215     	Blocks: 40         IO Block: 4096   regular file
Device: fd01h/64769d	Inode: 529352      Links: 1
Access: (0644/-rw-r--r--)  Uid: (    0/    root)   Gid: (    0/    root)
Access: 2021-04-25 15:15:37.280616254 +0800
Modify: 2021-04-25 15:15:37.280616254 +0800
Change: 2021-04-25 15:15:37.290616257 +0800
 Birth: -
</code></pre>
<p>开始修改：将index.html文件的访问和修改时间修改成当前系统的时间。</p>
<pre><code class="language-shell">touch index.html
</code></pre>
<h2 id="查找操作命令">查找操作命令：</h2>
<p>对于要用到的文件，目录等，经常有忘记的时候，所以查找命令就显得极为必要：</p>
<h3 id="find">find:</h3>
<p>查找文件或目录 (<strong>常用</strong>)</p>
<p>语法如下：</p>
<pre><code class="language-shell">find [目录…] [-amin &lt;分钟&gt;] [-atime &lt;24小时数&gt;] [-cmin &lt;分钟&gt;] [-ctime&lt;24小时数&gt;][-empty][-exec&lt;执行命令&gt;][-fls&lt;列表文件&gt;][-follow]
    [-fstype &lt;系统文件类型&gt;] [-gid &lt;组编号&gt;] [-group &lt;组名称&gt;] [-nogroup] [-mmin &lt;分钟&gt;]  [-mtime
    &lt;24小时数&gt;] [-name &lt;查找内容&gt;] [-nogroup] [-nouser] [-perm &lt;权限数值&gt;] [-size &lt;文件大小&gt;] [-uid
    &lt;用户编号&gt;] [-user &lt;用户名称&gt;] [-nouser]
</code></pre>
<p><strong>几个常用选项说明：</strong></p>
<pre><code class="language-shell">    -size &lt;文件大小&gt;：查找符合指定大小的文件。文件大小单位可以是“c”表示Byte；“k”表示KB。如配置为“100k”，find命令会查找文件大小正好100KB的文件；配置为“+100k”，find命令会查找文件大小大于100KB的文件；配置为“-100k”，find命令会查找文件大小小于100KB的文件。
    -user&lt;用户名称&gt;：查找所有者是指定用户的文件或目录，也能以用户编号指定
    -name &lt;查找内容&gt;：查找指定的内容，在查找内容中使用“*” 表示任意个字符；使用“?”表示任何一个字符
    -mtime &lt;24小时数&gt;：查找在指定时间**曾更改过内容**的文件或目录，单位以24小时计算。如配置为2，find命令会查找刚好在48小时之前更改过内容的文件；配置为+2，find命令会查找超过在48小时之前更改过内容的文件；配置为-2，find命令会查找在48小时之内更改过内容的文件。
    -mmin &lt;分钟&gt;：查找在指定时间曾被**更改过内容**的文件或目录，单位以分钟计算。
    -cmin &lt;分钟&gt;：查找在指定时间曾被**更改过权限**属性的文件或目录，单位以分钟计算。-ctime对应小时。
    -amin &lt;分钟&gt;：查找的是指定时间**访问过**的文件或目录。-atim对应小时。
    -perm &lt;权限数值&gt;：查找符合指定权限数值（有关权限数值见第6章）的文件或目录。如配置为“0700”，find命令会查找权限数值正好是“0700”的文件或目录；配置为“+0700”，find命令会查找权限数值大于 “0700”的文件或目录；配置为“-0700”，find
</code></pre>
<p>选项大概有以下几类：</p>
<p>1.按时间范围查找</p>
<p>2.按文件大小查找</p>
<p>3.按文件名称查找</p>
<p>4.按其他：比如权限、用户组、类型等</p>
<h4 id="示例-4">示例：</h4>
<pre><code class="language-shell">#从根目开始，查找名称以nginx开头的目录和文件
find / -name nginx*  

#查找文件大小超过100M的文件
find / -size +100M

#查找/home/zx目录下，10分钟内被修改过的文件和目录
find /home/zx/  -mmin -10
</code></pre>
<h3 id="locate">locate：</h3>
<p>查找文件或目录(<strong>不常用</strong>)</p>
<pre><code class="language-shell">locate 查找内容
</code></pre>
<p>例如：locate nginx 会将所有包含nginx的目录和文件都列出来。可以用* 或？等匹配符。</p>
<p>locate的查找速度非常快，因为该命令查找的是数据库，所以有些刚修改的文件和目录，可能无法找到。可以采用：updatedb 命令更新数据库。</p>
<h3 id="which">which:</h3>
<p>查找文件(<strong>不常用</strong>)</p>
<pre><code class="language-shell">which [文件]

which命令只会在PATH环境变量定义的路径及命令别名中查找，所以范围有限。
</code></pre>
<h3 id="whereis">whereis :</h3>
<p>查找文件(<strong>不常用</strong>)</p>
<pre><code class="language-shell">

whichis [-bu] [-B&lt;目录&gt;] [-M&lt;目录&gt;] [-S&lt;目录&gt;] [文件]

常用选项：

    文件：要查找的命令

    -b: 只查找二进制文件

    -u: 查找不包含指定类型的文件

    -B&lt;目录&gt;： 只在指定目录下查找二进制文件

    -M&lt;目录&gt;：只在指定目录查找帮助文件

    -S&lt;目录&gt;：只在指定目录查找源码目录

例如： 默认只会在指定目录查找（/bin ,/etc ,/usr)

[root@VM_0_13_centos soft]# whereis nginx
nginx: /usr/local/nginx /usr/local/nginx/sbin/nginx /usr/local/nginx/sbin/nginx.bak
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[JVM调优]]></title>
        <id>https://tinaxiawuhao.github.io/post/HEMJYLqMW/</id>
        <link href="https://tinaxiawuhao.github.io/post/HEMJYLqMW/">
        </link>
        <updated>2021-04-24T09:19:16.000Z</updated>
        <content type="html"><![CDATA[<h3 id="堆大小设置">堆大小设置</h3>
<p>​	JVM 中最大堆大小有三方面限制：相关操作系统的数据模型（32-bt还是64-bit）限制；系统的可用虚拟内存限制；系统的可用物理内存限制。32位系统下，一般限制在1.5G~2G；64为操作系统对内存无限制。我在Windows Server 2003 系统，3.5G物理内存，JDK5.0下测试，最大可设置为1478m。</p>
<p>典型设置：</p>
<pre><code class="language-sh">java -Xmx3550m -Xms3550m -Xmn2g -Xss128k 

// -Xmx3550m：设置JVM最大堆可用内存为3550M。 

// -Xms3550m：设置JVM初始堆内存为3550m。此值可以设置与-Xmx相同，以避免每次垃圾回收完成后JVM重新分配内存。 

// -Xmn2g：设置年轻代大小为2G。整个JVM内存大小=年轻代大小 + 年老代大小 + 持久代大小。持久代一般固定大小为64m，所以增大年轻代后，将会减小年老代大小。此值对系统性能影响较大，Sun官方推荐配置为整个堆的3/8。 

// -Xss128k：设置每个线程的堆栈大小。JDK5.0以后每个线程堆栈大小为1M，以前每个线程堆栈大小为256K。根据应用的线程所需内存大小进行调整。在相同物理内存下，减小这个值能生成更多的线程。但是操作系统对一个进程内的线程数还是有限制的，不能无限生成，经验值在3000~5000左右。 
</code></pre>
<pre><code class="language-sh"> java -Xmx3550m -Xms3550m -Xss128k -XX:NewRatio=4 -XX:SurvivorRatio=4 -XX:MaxPermSize=16m -XX:MaxTenuringThreshold=0 

// -XX:NewRatio=4:设置年轻代（包括Eden和两个Survivor区）与年老代的比值（除去持久代）。设置为4，则年轻代与年老代所占比值为1：4，年轻代占整个堆栈的1/5 

// -XX:SurvivorRatio=4：设置年轻代中Eden区与Survivor区的大小比值。设置为4，则两个Survivor区与一个Eden区的比值为2:4，一个Survivor区占整个年轻代的1/6 

// -XX:MaxPermSize=16m:设置持久代大小为16m。 

// -XX:MaxTenuringThreshold=0：设置垃圾最大年龄。如果设置为0的话，则年轻代对象不经过Survivor区，直接进入年老代。对于年老代比较多的应用，可以提高效率。如果将此值设置为一个较大值，则年轻代对象会在Survivor区进行多次复制，这样可以增加对象再年轻代的存活时间，增加在年轻代即被回收的概论。
</code></pre>
<h3 id="回收器选择">回收器选择</h3>
<p>​	JVM给了三种选择：<code>串行收集器</code>、<code>并行收集器</code>、<code>并发收集器</code>，但是串行收集器只适用于小数据量的情况，所以这里的选择主要针对并行收集器和并发收集器。默认情况下，JDK5.0以前都是使用串行收集器，如果想使用其他收集器需要在启动时加入相应参数。JDK5.0以后，JVM会根据当前系统配置进行判断。</p>
<ol>
<li>吞吐量优先的并行收集器</li>
</ol>
<p>如上文所述，并行收集器主要以到达一定的吞吐量为目标，适用于科学技术和后台处理等。</p>
<p>典型配置：</p>
<pre><code class="language-sh">java -Xmx3800m -Xms3800m -Xmn2g -Xss128k -XX:+UseParallelGC -XX:ParallelGCThreads=20

// -XX:+UseParallelGC：选择垃圾收集器为并行收集器。此配置仅对年轻代有效。即上述配置下，年轻代使用并发收集，而年老代仍旧使用串行收集。

// -XX:ParallelGCThreads=20：配置并行收集器的线程数，即：同时多少个线程一起进行垃圾回收。此值最好配置与处理器数目相等。
</code></pre>
<pre><code class="language-sh">java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:+UseParallelGC -XX:ParallelGCThreads=20 -XX:+UseParallelOldGC 

// -XX:+UseParallelOldGC：配置年老代垃圾收集方式为并行收集。JDK6.0支持对年老代并行收集。 
</code></pre>
<pre><code class="language-sh">java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:+UseParallelGC -XX:MaxGCPauseMillis=100 

// -XX:MaxGCPauseMillis=100:设置每次年轻代垃圾回收的最长时间，如果无法满足此时间，JVM会自动调整年轻代大小，以满足此值。 
</code></pre>
<pre><code class="language-sh">java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:+UseParallelGC -XX:MaxGCPauseMillis=100 -XX:+UseAdaptiveSizePolicy 

// -XX:+UseAdaptiveSizePolicy：设置此选项后，并行收集器会自动选择年轻代区大小和相应的Survivor区比例，以达到目标系统规定的最低相应时间或者收集频率等，此值建议使用并行收集器时，一直打开。
</code></pre>
<ol start="2">
<li>响应时间优先的并发收集器</li>
</ol>
<p>如上文所述，并发收集器主要是保证系统的响应时间，减少垃圾收集时的停顿时间。适用于应用服务器、电信领域等。</p>
<p>典型配置：</p>
<pre><code class="language-sh">java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:ParallelGCThreads=20 -XX:+UseConcMarkSweepGC -XX:+UseParNewGC 

// -XX:+UseConcMarkSweepGC：设置年老代为并发收集。测试中配置这个以后，-XX:NewRatio=4的配置失效了，原因不明。所以，此时年轻代大小最好用-Xmn设置。 

// -XX:+UseParNewGC:设置年轻代为并行收集。可与CMS收集同时使用。JDK5.0以上，JVM会根据系统配置自行设置，所以无需再设置此值。 
</code></pre>
<pre><code class="language-sh">java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:+UseConcMarkSweepGC -XX:CMSFullGCsBeforeCompaction=5 -XX:+UseCMSCompactAtFullCollection 

// -XX:CMSFullGCsBeforeCompaction：由于并发收集器不对内存空间进行压缩、整理，所以运行一段时间以后会产生“碎片”，使得运行效率降低。此值设置运行多少次GC以后对内存空间进行压缩、整理。 

// -XX:+UseCMSCompactAtFullCollection：打开对年老代的压缩。可能会影响性能，但是可以消除碎片
</code></pre>
<ol start="3">
<li>辅助信息</li>
</ol>
<p>JVM提供了大量命令行参数，打印信息，供调试使用。主要有以下一些：</p>
<pre><code class="language-sh">-XX:+PrintGC 

输出形式：[GC 118250K-&gt;113543K(130112K), 0.0094143 secs] [Full GC 121376K-&gt;10414K(130112K), 0.0650971 secs] 

-XX:+PrintGCDetails 

输出形式：[GC [DefNew: 8614K-&gt;781K(9088K), 0.0123035 secs] 118250K-&gt;113543K(130112K), 0.0124633 secs] [GC [DefNew: 8614K-&gt;8614K(9088K), 0.0000665 secs][Tenured: 112761K-&gt;10414K(121024K), 0.0433488 secs] 121376K-&gt;10414K(130112K), 0.0436268 secs] 

-XX:+PrintGCTimeStamps -XX:+PrintGC：PrintGCTimeStamps可与上面两个混合使用 

输出形式：11.851: [GC 98328K-&gt;93620K(130112K), 0.0082960 secs] 

-XX:+PrintGCApplicationConcurrentTime:打印每次垃圾回收前，程序未中断的执行时间。可与上面混合使用 

输出形式：Application time: 0.5291524 seconds 

-XX:+PrintGCApplicationStoppedTime：打印垃圾回收期间程序暂停的时间。可与上面混合使用 

输出形式：Total time for which application threads were stopped: 0.0468229 seconds 

-XX:PrintHeapAtGC:打印GC前后的详细堆栈信息 

-Xloggc:filename:与上面几个配合使用，把相关日志信息记录到文件以便分析。
</code></pre>
<h3 id="常见配置汇总">常见配置汇总</h3>
<ol>
<li>
<p>堆设置</p>
<ul>
<li><code>-Xms</code>:等价于(-XX:InitialHeapSize)初始堆大小</li>
<li><code>-Xmx</code>:等价于(-XX:MaxHeapSize)最大堆大小</li>
<li><code>-Xmn</code>:堆中新生代初始及最大大小，如果需要进一步细化，初始化大小用-XX:NewSize，最大大小用-XX:MaxNewSize</li>
<li><code>-Xss</code>:等价于(-XX:ThreadStackSize)每个线程堆栈的大小</li>
<li><code>-XX:NewSize=n</code>:设置年轻代大小</li>
<li><code>-XX:NewRatio=n</code>:设置年轻代和年老代的比值。如:为3，表示年轻代与年老代比值为1：3，年轻代占整个年轻代年老代和的1/4</li>
<li><code>-XX:SurvivorRatio=n</code>:年轻代中Eden区与两个Survivor区的比值。注意Survivor区有两个。如：3，表示Eden：Survivor=3：2，一个Survivor区占整个年轻代的1/5</li>
<li><code>-XX:MaxPermSize=n</code>:设置持久代大小</li>
<li><code>-XX:MaxTenuringThreshold=n</code>:设置垃圾最大年龄,年轻代复制次数</li>
</ul>
</li>
<li>
<p>收集器设置</p>
<ul>
<li><code>-XX:+UseSerialGC</code>:设置串行收集器</li>
<li><code>-XX:+UseParallelGC</code>:设置并行收集器</li>
<li><code>-XX:+UseParalledlOldGC</code>:设置并行年老代收集器</li>
<li><code>-XX:+UseConcMarkSweepGC</code>:设置并发收集器</li>
</ul>
</li>
<li>
<p>垃圾回收统计信息</p>
<ul>
<li><code>-XX:+PrintGC</code> :打印GC信息</li>
<li><code>-XX:+PrintGCDetails</code>:打印GC时的内存</li>
<li><code>-XX:+PrintGCTimeStamps</code>：选择打印GC的方式后，再添加此参数。比如：-XX:+PrintGC -XX:+PrintGCTimeStamps每次GC时会打印程序启动后至GC发生的时间戳。</li>
<li><code>-Xloggc:filename</code>：将GC日志输出到指定位置</li>
</ul>
</li>
<li>
<p>并行收集器设置</p>
<ul>
<li><code>-XX:ParallelGCThreads=n</code>:设置并行收集器收集时使用的CPU数。并行收集线程数。</li>
<li><code>-XX:MaxGCPauseMillis=n</code>:设置并行收集最大暂停时间</li>
<li><code>-XX:GCTimeRatio=n</code>:设置垃圾回收时间占程序运行时间的百分比。公式为1/(1+n)</li>
</ul>
</li>
<li>
<p>并发收集器设置</p>
<ul>
<li><code>-XX:+CMSIncrementalMode</code>:设置为增量模式。适用于单CPU情况。</li>
<li><code>-XX:ParallelGCThreads=n</code>:设置并发收集器年轻代收集方式为并行收集时，使用的CPU数。并行收集线程数。</li>
</ul>
</li>
</ol>
<h3 id="调优总结">调优总结</h3>
<ol>
<li>
<p>年轻代大小选择</p>
<ul>
<li>响应时间优先的应用：尽可能设大，直到接近系统的最低响应时间限制（根据实际情况选择）。在此种情况下，年轻代收集发生的频率也是最小的。同时，减少到达年老代的对象。</li>
<li>吞吐量优先的应用：尽可能的设置大，可能到达Gbit的程度。因为对响应时间没有要求，垃圾收集可以并行进行，一般适合8CPU以上的应用。</li>
</ul>
</li>
<li>
<p>年老代大小选择</p>
<ul>
<li>响应时间优先的应用：年老代使用并发收集器，所以其大小需要小心设置，一般要考虑并发会话率和会话持续时间等一些参数。如果堆设置小了，可以会造成内存碎片、高回收频率以及应用暂停而使用传统的标记清除方式；如果堆大了，则需要较长的收集时间。最优化的方案，一般需要参考以下数据获得：
<ul>
<li>并发垃圾收集信息</li>
<li>持久代并发收集次数</li>
<li>传统GC信息</li>
<li>花在年轻代和年老代回收上的时间比例</li>
<li>减少年轻代和年老代花费的时间，一般会提高应用的效率</li>
<li>吞吐量优先的应用：一般吞吐量优先的应用都有一个很大的年轻代和一个较小的年老代。原因是，这样可以尽可能回收掉大部分短期对象，减少中期的对象，而年老代尽存放长期存活对象。</li>
</ul>
</li>
</ul>
</li>
<li>
<p>较小堆引起的碎片问题</p>
<p>因为年老代的并发收集器使用标记、清除算法，所以不会对堆进行压缩。当收集器回收时，他会把相邻的空间进行合并，这样可以分配给较大的对象。但是，当堆空间较小时，运行一段时间以后，就会出现“碎片”，如果并发收集器找不到足够的空间，那么并发收集器将会停止，然后使用传统的标记、清除方式进行回收。如果出现“碎片”，可能需要进行如下配置：</p>
<ul>
<li><code>-XX:+UseCMSCompactAtFullCollection</code>：使用并发收集器时，开启对年老代的压缩。</li>
<li><code>-XX:CMSFullGCsBeforeCompaction=0</code>：上面配置开启的情况下，这里设置多少次Full GC后，对年老代进行压缩</li>
</ul>
</li>
</ol>
<h3 id="实际应用命令">实际应用命令</h3>
<p><strong>jps</strong><br>
查看所有的jvm进程，包括进程ID，进程启动的路径等等。</p>
<p>我自己也用PS，即：ps -ef | grep java</p>
<p><strong>jstack</strong><br>
观察jvm中当前所有线程的运行情况和线程当前状态。</p>
<p>系统崩溃了？如果java程序崩溃生成core文件，jstack工具可以用来获得core文件的java stack和native stack的信息，从而可以轻松地知道java程序是如何崩溃和在程序何处发生问题。</p>
<p>系统hung住了？jstack工具还可以附属到正在运行的java程序中，看到当时运行的java程序的java stack和native stack的信息, 如果现在运行的java程序呈现hung的状态，jstack是非常有用的。</p>
<p><strong>jstat</strong><br>
jstat利用JVM内建的指令对Java应用程序的资源和性能进行实时的命令行的监控，包括了对进程的classloader，compiler，gc情况；</p>
<p>特别的，一个极强的监视内存的工具，可以用来监视VM内存内的各种堆和非堆的大小及其内存使用量，以及加载类的数量。</p>
<p><strong>jmap</strong><br>
监视进程运行中的jvm物理内存的占用情况，该进程内存内，所有对象的情况，例如产生了哪些对象，对象数量；</p>
<p>系统崩溃了？jmap 可以从core文件或进程中获得内存的具体匹配情况，包括Heap size, Perm size等等</p>
<p><strong>jinfo</strong><br>
观察进程运行环境参数，包括Java System属性和JVM命令行参数</p>
<p>系统崩溃了？jinfo可以从core文件里面知道崩溃的Java应用程序的配置信息。</p>
<p><code>java -XX:+PrintFlagsInitial -version</code>:查看所有初始化默认配置<br>
<code>java -XX:+PrintFlagsFinal -version</code>:查看所有及修改更新配置<br>
<code>java -XX:+printCommandLineFlags -version</code>:打印命令参数配置<br>
<code>:=</code>:被jvm或人为修改过的参数<br>
<code>-XX:+UseParallelGC</code>:采用并行垃圾回收器<br>
<code>-XX:+UseSerialGC</code>:采用串行垃圾回收器</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java的值传递]]></title>
        <id>https://tinaxiawuhao.github.io/post/nRZ1sLPT7/</id>
        <link href="https://tinaxiawuhao.github.io/post/nRZ1sLPT7/">
        </link>
        <updated>2021-04-23T08:35:57.000Z</updated>
        <content type="html"><![CDATA[<h3 id="形参与实参">形参与实参</h3>
<p>我们先来重温一组语法：</p>
<ol>
<li>
<p>形参：方法被调用时需要传递进来的参数，如：<code>func(int a)</code>中的a，它只有在<code>func</code>被调用期间a才有意义，也就是会被分配内存空间，在方法<code>func</code>执行完成后，a就会被销毁释放空间，也就是不存在了</p>
</li>
<li>
<p>实参：方法被调用时传入的实际值，它在方法被调用前就已经被初始化并且在方法被调用时传入。</p>
</li>
</ol>
<p>举个栗子：</p>
<pre><code class="language-java">public static void func(int a){
    a=20; 
    System.out.println(a);
}
public static void main(String[] args) { 
    int a=10;  
    func(a); 
}
</code></pre>
<p>例子中</p>
<p><code>int a=10;</code>中的a在被调用之前就已经创建并初始化，在调用<code>func</code>方法时，他被当做参数传入，所以这个a是实参。</p>
<p>而<code>func(int a)</code>中的a只有在<code>func</code>被调用时它的生命周期才开始，而在<code>func</code>调用结束之后，它也随之被<code>JVM</code>释放掉，所以这个a是形参。</p>
<h3 id="java的数据类型">Java的数据类型</h3>
<p>所谓数据类型，是编程语言中对内存的一种抽象表达方式，我们知道程序是由代码文件和静态资源组成，在程序被运行前，这些代码存在在硬盘里，程序开始运行，这些代码会被转成计算机能识别的内容放到内存中被执行。</p>
<p>因此</p>
<blockquote>
<p>数据类型实质上是用来定义编程语言中相同类型的数据的存储形式，也就是决定了如何将代表这些值的位存储到计算机的内存中。</p>
</blockquote>
<p>所以，数据在内存中的存储，是根据数据类型来划定存储形式和存储位置的。</p>
<p>那么</p>
<p>Java的数据类型有哪些？</p>
<ol>
<li>
<p>基本类型：编程语言中内置的最小粒度的数据类型。它包括四大类八种类型：</p>
<p>4种整数类型：byte、short、int、long</p>
<p>2种浮点数类型：float、double</p>
<p>1种字符类型：char</p>
<p>1种布尔类型：boolean</p>
</li>
<li>
<p>引用类型：引用也叫句柄，引用类型，是编程语言中定义的在句柄中存放着实际内容所在地址的地址值的一种数据形式。它主要包括：</p>
<p>类</p>
<p>接口</p>
<p>数组</p>
</li>
</ol>
<p>有了数据类型，<code>JVM</code>对程序数据的管理就规范化了，不同的数据类型，它的存储形式和位置是不一样的，要想知道<code>JVM</code>是怎么存储各种类型的数据，就得先了解<code>JVM</code>的内存划分以及每部分的职能。</p>
<h3 id="jvm内存的划分及职能">JVM内存的划分及职能</h3>
<p>​	Java语言本身是不能操作内存的，它的一切都是交给<code>JVM</code>来管理和控制的，因此Java内存区域的划分也就是<code>JVM</code>的区域划分，在说<code>JVM</code>的内存划分之前，我们先来看一下Java程序的执行过程，如下图：</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1619167275279.jpeg" alt="" loading="lazy"></figure>
<p>有图可以看出：Java代码被编译器编译成字节码之后，<code>JVM</code>开辟一片内存空间（也叫运行时数据区），通过类加载器加到到运行时数据区来存储程序执行期间需要用到的数据和相关信息，在这个数据区中，它由以下几部分组成：</p>
<ol>
<li>
<p>虚拟机栈</p>
</li>
<li>
<p>堆</p>
</li>
<li>
<p>程序计数器</p>
</li>
<li>
<p>方法区</p>
</li>
<li>
<p>本地方法栈</p>
</li>
</ol>
<p>我们接着来了解一下每部分的原理以及具体用来存储程序执行过程中的哪些数据。</p>
<h4 id="虚拟机栈">虚拟机栈</h4>
<p>虚拟机栈是Java方法执行的内存模型，栈中存放着栈帧，每个栈帧分别对应一个被调用的方法，方法的调用过程对应栈帧在虚拟机中入栈到出栈的过程。</p>
<p>栈是线程私有的，也就是线程之间的栈是隔离的；当程序中某个线程开始执行一个方法时就会相应的创建一个栈帧并且入栈（位于栈顶），在方法结束后，栈帧出栈。</p>
<p>下图表示了一个Java栈的模型以及栈帧的组成：<br>
<img src="https://tinaxiawuhao.github.io/post-images/1619167296313.jpeg" alt="" loading="lazy"></p>
<p><strong>栈帧</strong>:是用于支持虚拟机进行方法调用和方法执行的数据结构，它是虚拟机运行时数据区中的虚拟机栈的栈元素。</p>
<p>每个栈帧中包括：</p>
<ol>
<li>局部变量表:用来存储方法中的局部变量（非静态变量、函数形参）。当变量为基本数据类型时，直接存储值，当变量为引用类型时，存储的是指向具体对象的引用。</li>
<li>操作数栈:Java虚拟机的解释执行引擎被称为&quot;基于栈的执行引擎&quot;，其中所指的栈就是指操作数栈。</li>
<li>指向运行时常量池的引用:存储程序执行时可能用到常量的引用。</li>
<li>方法返回地址:存储方法执行完成后的返回地址。</li>
</ol>
<h4 id="堆">堆</h4>
<p>堆是用来存储对象本身和数组的，在<code>JVM</code>中只有一个堆，因此，堆是被所有线程共享的。</p>
<h4 id="方法区">方法区：</h4>
<p>​	方法区是一块所有线程共享的内存逻辑区域，在<code>JVM</code>中只有一个方法区，用来存储一些线程可共享的内容，它是线程安全的，多个线程同时访问方法区中同一个内容时，只能有一个线程装载该数据，其它线程只能等待。</p>
<p>​	方法区可存储的内容有：类的全路径名、类的直接超类的权全限定名、类的访问修饰符、类的类型（类或接口）、类的直接接口全限定名的有序列表、常量池（字段，方法信息，静态变量，类型引用（class））等。</p>
<h4 id="本地方法栈">本地方法栈：</h4>
<p>​	本地方法栈的功能和虚拟机栈是基本一致的，并且也是线程私有的，它们的区别在于虚拟机栈是为执行Java方法服务的，而本地方法栈是为执行本地方法服务的。</p>
<p>有人会疑惑：什么是本地方法？为什么Java还要调用本地方法？</p>
<h4 id="程序计数器">程序计数器：</h4>
<p>​	线程私有的。记录着当前线程所执行的字节码的行号指示器，在程序运行过程中，字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、异常处理、线程恢复等基础功能都需要依赖计数器完成。</p>
<h3 id="数据如何在内存中存储">数据如何在内存中存储？</h3>
<p>从上面程序运行图我们可以看到，<code>JVM</code>在程序运行时的内存分配有三个地方：</p>
<ul>
<li>堆</li>
<li>栈</li>
<li>静态方法区</li>
<li>常量区</li>
</ul>
<p>相应地，每个存储区域都有自己的内存分配策略：</p>
<ul>
<li>堆式：</li>
<li>栈式</li>
<li>静态</li>
</ul>
<p>我们已经知道：Java中的数据类型有基本数据类型和引用数据类型，那么这些数据的存储都使用哪一种策略呢？</p>
<p>这里要分以下的情况进行探究：</p>
<ol>
<li>
<p>基本数据类型的存储：</p>
<ul>
<li>A. 基本数据类型的局部变量</li>
<li>B. 基本数据类型的成员变量</li>
<li>C. 基本数据类型的静态变量</li>
</ul>
</li>
<li>
<p>引用数据类型的存储</p>
</li>
</ol>
<h4 id="基本数据类型的存储">基本数据类型的存储</h4>
<p>我们分别来研究一下：</p>
<p>A.基本数据类型的局部变量</p>
<ol>
<li>定义基本数据类型的局部变量以及数据都是直接存储在内存中的栈上，也就是前面说到的“虚拟机栈”，数据本身的值就是存储在栈空间里面。</li>
</ol>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1619167321876.jpeg" alt="" loading="lazy"></figure>
<p>如上图，在方法内定义的变量直接存储在栈中，如</p>
<pre><code class="language-java">int age=50; 
int weight=50; 
int grade=6;
</code></pre>
<p>当我们写“int age=50；”，其实是分为两步的：</p>
<p><code>int age;</code>//定义变量<code>age=50;</code>//赋值</p>
<p>​	首先<code>JVM</code>创建一个名为age的变量，存于局部变量表中，然后去栈中查找是否存在有字面量值为50的内容，如果有就直接把age指向这个地址，如果没有，<code>JVM</code>会在栈中开辟一块空间来存储“50”这个内容，并且把age指向这个地址。因此我们可以知道：</p>
<p>​	我们声明并初始化基本数据类型的局部变量时，变量名以及字面量值都是存储在栈中，而且是真实的内容。</p>
<p>​	我们再来看<code>“int weight=50；”</code>，按照刚才的思路：字面量为50的内容在栈中已经存在，因此weight是直接指向这个地址的。由此可见：栈中的数据在当前线程下是共享的。</p>
<p>​	那么如果再执行下面的代码呢？</p>
<p>​	<code>weight=40；</code></p>
<p>​	当代码中重新给weight变量进行赋值时，<code>JVM</code>会去栈中寻找字面量为40的内容，发现没有，就会开辟一块内存空间存储40这个内容，并且把weight指向这个地址。由此可知：</p>
<p>​	基本数据类型的数据本身是不会改变的，当局部变量重新赋值时，并不是在内存中改变字面量内容，而是重新在栈中寻找已存在的相同的数据，若栈中不存在，则重新开辟内存存新数据，并且把要重新赋值的局部变量的引用指向新数据所在地址。</p>
<p>B. 基本数据类型的成员变量</p>
<p>成员变量：顾名思义，就是在类体中定义的变量。</p>
<p>看下图：<br>
<img src="https://tinaxiawuhao.github.io/post-images/1619167338990.jpeg" alt="" loading="lazy"></p>
<p>我们看per的地址指向的是堆内存中的一块区域，我们来还原一下代码：</p>
<pre><code class="language-java"> public class Person{ 
     private int age;  
     private String name; 
     private int grade; //省略setter getter方法  
     static void run(){    
         System.out.println(&quot;run....&quot;);   
     }; 
 }
//调用 Person per=new Person();
</code></pre>
<p>​	同样是局部变量的age、name、grade却被存储到了堆中为per对象开辟的一块空间中。因此可知：基本数据类型的成员变量名和值都存储于堆中，其生命周期和对象的是一致的。</p>
<p>C. 基本数据类型的静态变量</p>
<p>​	前面提到方法区用来存储一些共享数据，因此基本数据类型的静态变量名以及值存储于方法区的运行时常量池中，静态变量随类加载而加载，随类消失而消失</p>
<h4 id="引用数据类型的存储">引用数据类型的存储:</h4>
<p>上面提到：堆是用来存储对象本身和数组，而引用（句柄）存放的是实际内容的地址值，因此通过上面的程序运行图，也可以看出，当我们定义一个对象时</p>
<pre><code class="language-java">Person per=new Person();
</code></pre>
<p>实际上，它也是有两个过程：</p>
<pre><code class="language-java">Person per;//定义变量 
per=new Person();//赋值
</code></pre>
<p>​	在执行<code>Person per;</code>时，<code>JVM</code>先在虚拟机栈中的变量表中开辟一块内存存放per变量，在执行<code>per=new Person()</code>时，<code>JVM</code>会创建一个Person类的实例对象并在堆中开辟一块内存存储这个实例，同时把实例的地址值赋值给per变量。因此可见：</p>
<p>对于引用数据类型的对象/数组，变量名存在栈中，变量值存储的是对象的地址，并不是对象的实际内容。</p>
<h3 id="值传递和引用传递">值传递和引用传递</h3>
<p>​	前面已经介绍过形参和实参，也介绍了数据类型以及数据在内存中的存储形式，接下来，就是文章的主题：值传递和引用的传递。</p>
<h4 id="值传递">值传递：</h4>
<blockquote>
<p>在方法被调用时，实参通过形参把它的内容副本传入方法内部，此时形参接收到的内容是实参值的一个拷贝，因此在方法内对形参的任何操作，都仅仅是对这个副本的操作，不影响原始值的内容。</p>
</blockquote>
<p>来看个例子：</p>
<pre><code class="language-java"> public static void valueCrossTest(int age,float weight){
     System.out.println(&quot;传入的age：&quot;+age);
     System.out.println(&quot;传入的weight：&quot;+weight);
     age=33;
     weight=89.5f;
     System.out.println(&quot;方法内重新赋值后的age：&quot;+age);
     System.out.println(&quot;方法内重新赋值后的weight：&quot;+weight);
     }
 
//测试
public static void main(String[] args) {
        int a=25;
        float w=77.5f;
        valueCrossTest(a,w);
        System.out.println(&quot;方法执行后的age：&quot;+a);
        System.out.println(&quot;方法执行后的weight：&quot;+w);
}
</code></pre>
<p>输出结果：</p>
<pre><code class="language-sh">传入的age：25
传入的weight：77.5

方法内重新赋值后的age：33
方法内重新赋值后的weight：89.5

方法执行后的age：25
方法执行后的weight：77.5
</code></pre>
<p>从上面的打印结果可以看到：</p>
<p>a和w作为实参传入<code>valueCrossTest</code>之后，无论在方法内做了什么操作，最终a和w都没变化。</p>
<p>这是什么造型呢？！！</p>
<p>下面我们根据上面学到的知识点，进行详细的分析：</p>
<p>首先程序运行时，调用<code>mian()</code>方法，此时<code>JVM</code>为<code>main()</code>方法往虚拟机栈中压入一个栈帧，即为当前栈帧，用来存放<code>main()</code>中的局部变量表(包括参数)、操作栈、方法出口等信息，如a和w都是<code>mian()</code>方法中的局部变量，因此可以断定，a和w是躺着<code>mian</code>方法所在的栈帧中</p>
<p>如图：</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1619167361127.jpeg" alt="" loading="lazy"></figure>
<p>而当执行到<code>valueCrossTest()</code>方法时，<code>JVM</code>也为其往虚拟机栈中压入一个栈，即为当前栈帧，用来存放<code>valueCrossTest()</code>中的局部变量等信息，因此age和weight是躺着<code>valueCrossTest</code>方法所在的栈帧中，而他们的值是从a和w的值copy了一份副本而得，如图：</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1619167368733.jpeg" alt="" loading="lazy"></figure>
<p>因而可以a和age、w和weight对应的内容是不一致的，所以当在方法内重新赋值时，实际流程如图：<br>
<img src="https://tinaxiawuhao.github.io/post-images/1619167375812.jpeg" alt="" loading="lazy"></p>
<p>也就是说，age和weight的改动，只是改变了当前栈帧（<code>valueCrossTest</code>方法所在栈帧）里的内容，当方法执行结束之后，这些局部变量都会被销毁，<code>mian</code>方法所在栈帧重新回到栈顶，成为当前栈帧，再次输出a和w时，依然是初始化时的内容。</p>
<p>因此：</p>
<p>值传递传递的是真实内容的一个副本，对副本的操作不影响原内容，也就是形参怎么变化，不会影响实参对应的内容。</p>
<h4 id="引用传递">引用传递：</h4>
<p>​	”引用”也就是指向真实内容的地址值，在方法调用时，实参的地址通过方法调用被传递给相应的形参，在方法体内，形参和实参指向同一块内存地址，对形参的操作会影响的真实内容。</p>
<p>举个栗子：</p>
<p>先定义一个对象：</p>
<pre><code class="language-java"> public class Person {   
     private String name;   
     private int age;        
     public String getName() {   
         return name;       
     }       
     public void setName(String name) { 
         this.name = name;    
     }      
     public int getAge() {  
         return age;     
     }       
     public void setAge(int age) {  
         this.age = age;       
     }
 }
</code></pre>
<p>我们写个函数测试一下：</p>
<pre><code class="language-java">public static void PersonCrossTest(Person person){  
    System.out.println(&quot;传入的person的name：&quot;+person.getName());  
    person.setName(&quot;我是张三&quot;);        
    System.out.println(&quot;方法内重新赋值后的name：&quot;+person.getName());   
} 
//测试
public static void main(String[] args) { 
    Person p=new Person();        
    p.setName(&quot;我是李四&quot;);   
    p.setAge(45);       
    PersonCrossTest(p);   
    System.out.println(&quot;方法执行后的name：&quot;+p.getName()); 
}
</code></pre>
<p>输出结果：</p>
<pre><code class="language-sh">传入的person的name：我是李四
方法内重新赋值后的name：我是张三
方法执行后的name：我是张三
</code></pre>
<p>可以看出，person经过<code>personCrossTest()</code>方法的执行之后，内容发生了改变，这印证了上面所说的“引用传递”，对形参的操作，改变了实际对象的内容。</p>
<p>那么，到这里就结题了吗？</p>
<p>不是的，没那么简单，</p>
<p>能看得到想要的效果</p>
<p>是因为刚好选对了例子而已！！！</p>
<p>下面我们对上面的例子稍作修改，加上一行代码，</p>
<pre><code class="language-java">public static void PersonCrossTest(Person person){    
    System.out.println(&quot;传入的person的name：&quot;+person.getName());     
    person=new Person();//加多此行代码    
    person.setName(&quot;我是张三&quot;);   
    System.out.println(&quot;方法内重新赋值后的name：&quot;+person.getName());  
}
</code></pre>
<p>输出结果：</p>
<pre><code class="language-sh">传入的person的name：我是李四 
方法内重新赋值后的name：我是张三 
方法执行后的name：我是李四
</code></pre>
<p>为什么这次的输出和上次的不一样了呢？</p>
<p>看出什么问题了吗？</p>
<p>按照上面讲到<code>JVM</code>内存模型可以知道，对象和数组是存储在Java堆区的，而且堆区是共享的，因此程序执行到main（）方法中的下列代码时</p>
<pre><code class="language-java">Person p=new Person();      
p.setName(&quot;我是李四&quot;);    
p.setAge(45);      
PersonCrossTest(p);
</code></pre>
<p><code>JVM</code>会在堆内开辟一块内存，用来存储p对象的所有内容，同时在main（）方法所在线程的栈区中创建一个引用p存储堆区中p对象的真实地址，如图：</p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1619167401540.jpeg" alt="" loading="lazy"></figure>
<p>当执行到<code>PersonCrossTest()</code>方法时，因为方法内有这么一行代码：</p>
<pre><code class="language-java">person=new Person();
</code></pre>
<p><code>JVM</code>需要在堆内另外开辟一块内存来存储new Person()，假如地址为<code>“xo3333”</code>，那此时形参person指向了这个地址，假如真的是引用传递，那么由上面讲到：引用传递中形参实参指向同一个对象，形参的操作会改变实参对象的改变。</p>
<p>可以推出：实参也应该指向了新创建的person对象的地址，所以在执行<code>PersonCrossTest()</code>结束之后，最终输出的应该是后面创建的对象内容。</p>
<p>然而实际上，最终的输出结果却跟我们推测的不一样，最终输出的仍然是一开始创建的对象的内容。</p>
<p>由此可见：引用传递，在Java中并不存在。</p>
<p>但是有人会疑问：为什么第一个例子中，在方法内修改了形参的内容，会导致原始对象的内容发生改变呢？</p>
<p>这是因为：无论是基本类型和是引用类型，在实参传入形参时，都是值传递，也就是说传递的都是一个副本，而不是内容本身。</p>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1619167408670.jpeg" alt="" loading="lazy"></figure>
<p>有图可以看出，方法内的形参person和实参p并无实质关联，它只是由p处copy了一份指向对象的地址，此时：</p>
<p>p和person都是指向同一个对象。</p>
<p>因此在第一个例子中，对形参p的操作，会影响到实参对应的对象内容。而在第二个例子中，当执行到new Person()之后，<code>JVM</code>在堆内开辟一块空间存储新对象，并且把person改成指向新对象的地址，此时：</p>
<p>p依旧是指向旧的对象，person指向新对象的地址。</p>
<p>所以此时对person的操作，实际上是对新对象的操作，于实参p中对应的对象毫无关系。</p>
<h3 id="结语">结语</h3>
<p>因此可见：在Java中所有的参数传递，不管基本类型还是引用类型，都是值传递，或者说是副本传递。</p>
<p>只是在传递过程中：</p>
<p>如果是对基本数据类型的数据进行操作，由于原始内容和副本都是存储实际值，并且是在不同的栈区，因此形参的操作，不影响原始内容。</p>
<p>如果是对引用类型的数据进行操作，分两种情况，一种是形参和实参保持指向同一个对象地址，则形参的操作，会影响实参指向的对象的内容。一种是形参被改动指向新的对象地址（如重新赋值引用），则形参的操作，不会影响实参指向的对象的内容。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[附录 kafka常见面试问题汇总]]></title>
        <id>https://tinaxiawuhao.github.io/post/aFuh1RRNc/</id>
        <link href="https://tinaxiawuhao.github.io/post/aFuh1RRNc/">
        </link>
        <updated>2021-04-22T05:38:23.000Z</updated>
        <content type="html"><![CDATA[<h2 id="基础题目">基础题目</h2>
<h3 id="1-apache-kafka-是什么">1、Apache Kafka 是什么?</h3>
<p>Apach Kafka 是一款分布式流处理框架，用于实时构建流处理应用。它有一个核心 的功能广为人知，即作为企业级的消息引擎被广泛使用。</p>
<p>你一定要先明确它的流处理框架地位，这样能给面试官留 下一个很专业的印象。</p>
<h3 id="2-什么是消费者组">2、什么是消费者组?</h3>
<p>消费者组是 Kafka 独有的概念，如果面试官问这 个，就说明他对此是有一定了解的。我先给出标准答案：<br>
1、定义：即消费者组是 Kafka 提供的可扩展且具有容错性的消费者机制。<br>
2、原理：在 Kafka 中，消费者组是一个由多个消费者实例 构成的组。多个实例共同订阅若干个主题，实现共同消费。同一个组下的每个实例都配置有 相同的组 ID，被分配不同的订阅分区。当某个实例挂掉的时候，其他实例会自动地承担起 它负责消费的分区。</p>
<p>此时，又有一个小技巧给到你:消费者组的题目，能够帮你在某种程度上掌控下面的面试方向。</p>
<h4 id="21消费者组的位移提交机制">2.1消费者组的位移提交机制</h4>
<p>broker维护消费者的消费位移信息，老的版本存储在zk上，新版本存储在内部的topic里。本质上，位移信息消费者自己维护也可以，但是如果消费者挂了或者重启，对于某一个分区的消费位移不就丢失了吗？所以，还是需要提交到broker端做持久化的。</p>
<h4 id="22消费者组与-broker-之间的交互">2.2消费者组与 Broker 之间的交互</h4>
<ol>
<li>
<p>Kafka中消费者的消费方式</p>
<p>consumer采用pull(拉)模式从broker中读取数据。 拉取模式也有不足，如果kafka没有数据，消费者可能会陷入循环中，一直返回空数据。针对这一点，kafka消费者在消费数据时会传入一个时长参数timeout，如果当前没有数据可供消费，consumer会等待一段时间后再返回，这段时长即为timeout</p>
</li>
<li>
<p>Kafka的分区分配策略</p>
<p>一个消费者组中有多个消费者，一个broker有多个分区，所有必然会涉及到分区分配问题，即确定哪一个分区由哪一个consumer来消费。kafka有两种分区分配策略：RoundRobin和Range</p>
<p>1） RoundRobin</p>
<p>按照消费者组划分，将消费者组作为一个整体，要求整个消费者组内的消费者订阅相同的主题，否则会导致错误的分配的问题。</p>
<p>2） Range （默认）</p>
<p>按照单个主题划分，可能导致消费者消费分区个数不对等的问题；</p>
<p><strong>offset的维护</strong></p>
<p>由于kafka可能出现故障，故障之后要恢复到上一次消费的位置，往下继续进行消费。因此consumer需要实时记录自己消费到了哪一个offset，从0.9版本开始，consumer默认将offset保存在kafka的内置topic中，该topic为_consumer_offsets（0.9版本前放在zookeeper中）</p>
</li>
</ol>
<h3 id="3-在-kafka-中zookeeper-的作用是什么">3、在 Kafka 中，ZooKeeper 的作用是什么?</h3>
<p>目前，Kafka 使用 ZooKeeper 存放集群元数据、成员管理、Controller 选举，以及其他一些管理类任务。之后，等 KIP-500 提案完成后，Kafka 将完全不再依赖 于 ZooKeeper。</p>
<p>记住，<strong>一定要突出“目前”</strong>，以彰显你非常了解社区的演进计划。“存放元数据”是指主题 分区的所有数据都保存在 ZooKeeper 中，且以它保存的数据为权威，其他“人”都要与它 保持对齐。“成员管理”是指 Broker 节点的注册、注销以及属性变更，等 等。“Controller 选举”是指选举集群 Controller，而其他管理类任务包括但不限于主题 删除、参数配置等。</p>
<p>不过，抛出 KIP-500 也可能是个双刃剑。碰到非常资深的面试官，他可能会进一步追问你 KIP-500 是怎么做的。一言以蔽之:<strong>KIP-500 思想，是使用社区自研的基于 Raft 的共识算法， 替代 ZooKeeper，实现 Controller 自选举</strong>。</p>
<h3 id="4-解释下-kafka-中位移offset的作用">4、解释下 Kafka 中位移(offset)的作用</h3>
<p>在 Kafka 中，每个 主题分区下的每条消息都被赋予了一个唯一的 ID 数值，用于标识它在分区中的位置。这个 ID 数值，就被称为位移，或者叫偏移量。一旦消息被写入到分区日志，它的位移值将不能 被修改。</p>
<p>答完这些之后，你还可以把整个面试方向转移到你希望的地方。常见方法有以下 3 种:</p>
<ol>
<li>如果你深谙 Broker 底层日志写入的逻辑，可以强调下消息在日志中的存放格式;</li>
<li>如果你明白位移值一旦被确定不能修改，可以强调下“Log Cleaner 组件都不能影响位 移值”这件事情;</li>
<li>如果你对消费者的概念还算熟悉，可以再详细说说位移值和消费者位移值之间的区别。</li>
</ol>
<h3 id="5-partition的leader-replica和follower-replica的区别">5、Partition的Leader Replica和Follower Replica的区别</h3>
<p>这道题表面上是考核你对 Leader 和 Follower 区别的理解，但很容易引申到 Kafka 的同步 机制上。因此，我建议你主动出击，一次性地把隐含的考点也答出来，也许能够暂时把面试 官“唬住”，并体现你的专业性。</p>
<p>你可以这么回答:<strong>Kafka 副本当前分为领导者副本和追随者副本。只有 Leader 副本才能 对外提供读写服务，响应 Clients 端的请求。Follower 副本只是采用拉(PULL)的方 式，被动地同步 Leader 副本中的数据，并且在 Leader 副本所在的 Broker 宕机后，随时 准备应聘 Leader 副本。</strong></p>
<p>通常来说，回答到这个程度，其实才只说了 60%，因此，我建议你再回答两个额外的加分 项。</p>
<ul>
<li><strong>强调 Follower 副本也能对外提供读服务</strong>。自 Kafka 2.4 版本开始，社区通过引入新的 Broker 端参数，允许 Follower 副本有限度地提供读服务。</li>
<li><strong>强调 Leader 和 Follower 的消息序列在实际场景中不一致</strong>。很多原因都可能造成 Leader 和 Follower 保存的消息序列不一致，比如程序 Bug、网络问题等。这是很严重 的错误，必须要完全规避。你可以补充下，之前确保一致性的主要手段是高水位机制， 但高水位值无法保证 Leader 连续变更场景下的数据一致性，因此，社区引入了 Leader Epoch 机制，来修复高水位值的弊端。关于“Leader Epoch 机制”，国内的资料不是 很多，它的普及度远不如高水位，不妨大胆地把这个概念秀出来，力求惊艳一把。</li>
</ul>
<h2 id="炫技式题目">炫技式题目</h2>
<h3 id="6-leo-lso-ar-isr-hw-都表示什么含义">6、LEO、LSO、AR、ISR、HW 都表示什么含义?</h3>
<ul>
<li><strong>LEO</strong>:Log End Offset。日志末端位移值或末端偏移量，表示日志下一条待插入消息的 位移值。举个例子，如果日志有 10 条消息，位移值从 0 开始，那么，第 10 条消息的位 移值就是 9。此时，LEO = 10。</li>
<li><strong>LSO</strong>:Log Stable Offset。这是 Kafka 事务的概念。如果你没有使用到事务，那么这个 值不存在(其实也不是不存在，只是设置成一个无意义的值)。该值控制了事务型消费 者能够看到的消息范围。它经常与 Log Start Offset，即日志起始位移值相混淆，因为 有些人将后者缩写成 LSO，这是不对的。在 Kafka 中，LSO 就是指代 Log Stable Offset。</li>
<li><strong>AR</strong>:Assigned Replicas。AR 是主题被创建后，分区创建时被分配的副本集合，副本个 数由副本因子决定。</li>
<li><strong>ISR</strong>:In-Sync Replicas。Kafka 中特别重要的概念，指代的是 AR 中那些与 Leader 保 持同步的副本集合。在 AR 中的副本可能不在 ISR 中，但 Leader 副本天然就包含在 ISR 中。关于 ISR，<strong>还有一个常见的面试题目是如何判断副本是否应该属于 ISR</strong>。目前的判断 依据是:<strong>Follower 副本的 LEO 落后 Leader LEO 的时间，是否超过了 Broker 端参数 replica.lag.time.max.ms 值</strong>。如果超过了，副本就会被从 ISR 中移除。</li>
<li><strong>HW</strong>:高水位值(High watermark)。这是控制消费者可读取消息范围的重要字段。一 个普通消费者只能“看到”Leader 副本上介于 Log Start Offset 和 HW(不含)之间的 所有消息。水位以上的消息是对消费者不可见的。关于 HW，问法有很多，我能想到的 最高级的问法，就是让你完整地梳理下 Follower 副本拉取 Leader 副本、执行同步机制 的详细步骤。这就是我们的第 20 道题的题目，一会儿我会给出答案和解析。</li>
</ul>
<h3 id="7kafka-的-isr-机制是什么">7，Kafka 的 ISR 机制是什么?</h3>
<p>这个机制简单来说，就是会自动给每个 Partition 维护一个 ISR 列表，这个列表里一定会有 Leader，然后还会包含跟 Leader 保持同步的 Follower。</p>
<p>也就是说，只要 Leader 的某个 Follower 一直跟他保持数据同步，那么就会存在于 ISR 列表里。</p>
<p>但是如果 Follower 因为自身发生一些问题，导致不能及时的从 Leader 同步数据过去，那么这个 Follower 就会被认为是“out-of-sync”，被从 ISR 列表里踢出去。</p>
<p>所以大家先得明白这个 ISR 是什么，说白了，就是 Kafka 自动维护和监控哪些 Follower 及时的跟上了 Leader 的数据同步。</p>
<h3 id="8kafka-写入的数据如何保证不丢失">8，Kafka 写入的数据如何保证不丢失?</h3>
<p>所以如果要让写入 Kafka 的数据不丢失，你需要保证如下几点：</p>
<ul>
<li>每个 Partition 都至少得有 1 个 Follower 在 ISR 列表里，跟上了 Leader 的数据同步。</li>
<li>每次写入数据的时候，都要求至少写入 Partition Leader 成功，同时还有至少一个 ISR 里的 Follower 也写入成功，才算这个写入是成功了。</li>
<li>如果不满足上述两个条件，那就一直写入失败，让生产系统不停的尝试重试，直到满足上述两个条件，然后才能认为写入成功。</li>
<li>按照上述思路去配置相应的参数，才能保证写入 Kafka 的数据不会丢失。</li>
</ul>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1622096799684.png" alt="" loading="lazy"></figure>
<p>如上图所示，假如现在 Leader 没有 Follower 了，或者是刚写入 Leader，Leader 立马就宕机，还没来得及同步给 Follower。</p>
<p>在这种情况下，写入就会失败，然后你就让生产者不停的重试，直到 Kafka 恢复正常满足上述条件，才能继续写入。这样就可以让写入 Kafka 的数据不丢失。</p>
<h3 id="9-高水位和epoch">9. 高水位和Epoch</h3>
<p>在Kafka中，高水位的作用主要有两个</p>
<ul>
<li>定义消息可见性，即用来标识分区下的哪些消息是可以被消费者消费的。</li>
<li>帮助Kafka完成副本同步</li>
</ul>
<p>下面这张图展示了多个与高水位相关的 Kafka 术语。</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1622096512111.png" alt="" loading="lazy"></figure>
<p>假设这是某个分区 Leader 副本的高水位图。首先，请注意图中的“已提交消息”和“未提交消息”。之前在讲到 Kafka 持久性保障的时候，特意对两者进行了区分。现在，再次强调一下。在分区高水位以下的消息被认为是已提交消息，反之就是未提交消息。</p>
<p>消费者只能消费已提交消息，即图中位移小于 8 的所有消息。注意，这里我们不讨论 Kafka 事务，因为事务机制会影响消费者所能看到的消息的范围，它不只是简单依赖高水位来判断。它依靠一个名为 LSO（Log Stable Offset）的位移值来判断事务型消费者的可见性。</p>
<p>另外，<strong>位移值等于高水位的消息也属于未提交消息。也就是说，高水位上的消息是不能被消费者消费的</strong>。</p>
<h4 id="log-end-offsetleo">Log End Offset（LEO）</h4>
<p>Log End Offset（LEO）表示副本写入下一条消息的位移值。注意，数字 15 所在的方框是虚线，这就说明，这个副本当前只有 15 条消息，位移值是从 0 到 14，下一条新消息的位移是 15。显然，介于高水位和 LEO 之间的消息就属于未提交消息。这也从侧面告诉了我们一个重要的事实，那就是：<strong>同一个副本对象，其高水位值不会大于 LEO 值</strong>。</p>
<p><strong>高水位和 LEO 是副本对象的两个重要属性</strong>。Kafka 所有副本都有对应的高水位和 LEO 值，而不仅仅是 Leader 副本。只不过 Leader 副本比较特殊，Kafka 使用 Leader 副本的高水位来定义所在分区的高水位。换句话说，<strong>分区的高水位就是其 Leader 副本的高水位</strong>。</p>
<h4 id="高水位和leo更新机制">高水位和LEO更新机制</h4>
<p>现在，我们知道了每个副本对象都保存了一组高水位值和 LEO 值，但实际上，在 Leader 副本所在的 Broker 上，还保存了其他 Follower 副本的HW和LEO 值。</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1622096529006.png" alt="" loading="lazy"></figure>
<p>如上图所示，Broker 0 上保存了某分区的 Leader 副本和所有 Follower 副本的 LEO 值，而 Broker 1 上仅仅保存了该分区的某个 Follower 副本。Kafka 把 Broker 0 上保存的这些 Follower 副本又称为远程副本（Remote Replica）。Kafka 副本机制在运行过程中，会更新 Broker 1 上 Follower 副本的高水位和 LEO 值，同时也会更新 Broker 0 上 Leader 副本的高水位和 LEO 以及所有远程副本的 LEO，但它不会更新远程副本的高水位值，也就是我在图中标记为灰色的部分。</p>
<p>保存远程副本的作用主要是帮助 Leader 副本确定其高水位，也就是分区高水位。下图是副本同步机制：<br>
<img src="https://tinaxiawuhao.github.io/post-images/1622096536181.png" alt="" loading="lazy"></p>
<h3 id="10leader副本保持同步">10,Leader副本保持同步</h3>
<p>与Leader副本保持同步的判断条件有两个：</p>
<ol>
<li>该远程Follower副本在ISR中。</li>
<li>该远程Follower副本LEO值落后于Leader副本LEO值的时间，不超过Broker端参数replica.lag.time.max.ms的值（默认值10秒）</li>
</ol>
<h4 id="副本同步全流程">副本同步全流程</h4>
<p>当生产者发送一条消息时，Leader 和 Follower 副本对应的高水位是怎么被更新的呢？</p>
<p>首先是初始状态。下面这张图中的 remote LEO 就是刚才的远程副本的 LEO 值。在初始状态时，所有值都是 0。</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1622096547680.png" alt="" loading="lazy"></figure>
<p>当生产者给主题分区发送一条消息后，状态变更为：</p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1622096554503.png" alt="" loading="lazy"></figure>
<p>此时，Leader 副本成功将消息写入了本地磁盘，故 LEO 值被更新为 1。</p>
<p>Follower 再次尝试从 Leader 拉取消息。和之前不同的是，这次有消息可以拉取了，因此状态进一步变更为：</p>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1622096561747.png" alt="" loading="lazy"></figure>
<p>这时，Follower 副本也成功地更新 LEO 为 1。此时，Leader 和 Follower 副本的 LEO 都是 1，但各自的高水位依然是 0，还没有被更新。它们需要在下一轮的拉取中被更新，如下图所示：</p>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1622096573656.png" alt="" loading="lazy"></figure>
<p>在新一轮的拉取请求中，由于位移值是 0 的消息已经拉取成功，因此 Follower 副本这次请求拉取的是位移值 =1 的消息。Leader 副本接收到此请求后，更新远程副本 LEO 为 1，然后更新 Leader 高水位为 1。做完这些之后，它会将当前已更新过的高水位值 1 发送给 Follower 副本。Follower 副本接收到以后，也将自己的高水位值更新成 1。至此，一次完整的消息同步周期就结束了。事实上，Kafka 就是利用这样的机制，实现了 Leader 和 Follower 副本之间的同步。</p>
<h4 id="leader-epoch">Leader Epoch</h4>
<p>从刚才的分析中，我们知道，Follower 副本的高水位更新需要一轮额外的拉取请求才能实现。如果把上面那个例子扩展到多个 Follower 副本，情况可能更糟，也许需要多轮拉取请求。也就是说，Leader 副本高水位更新和 Follower 副本高水位更新在时间上是存在错配的。这种错配是很多“数据丢失”或“数据不一致”问题的根源。基于此，社区在 0.11 版本正式引入了 Leader Epoch 概念，来规避因高水位更新错配导致的各种不一致问题。</p>
<p>所谓 Leader Epoch，我们大致可以认为是 Leader 版本。它由两部分数据组成。</p>
<ol>
<li>Epoch。一个单调增加的版本号。每当副本领导权发生变更时，都会增加该版本号。小版本号的 Leader 被认为是过期 Leader，不能再行使 Leader 权力。</li>
<li>起始位移（Start Offset）。Leader 副本在该 Epoch 值上写入的首条消息的位移。</li>
</ol>
<p>举个例子来说明一下 Leader Epoch。假设现在有两个 Leader Epoch&lt;0, 0&gt; 和 &lt;1, 120&gt;，那么，第一个 Leader Epoch 表示版本号是 0，这个版本的 Leader 从位移 0 开始保存消息，一共保存了 120 条消息。之后，Leader 发生了变更，版本号增加到 1，新版本的起始位移是 120。</p>
<p>Kafka Broker 会在内存中为每个分区都缓存 Leader Epoch 数据，同时它还会定期地将这些信息持久化到一个 checkpoint 文件中。当 Leader 副本写入消息到磁盘时，Broker 会尝试更新这部分缓存。如果该 Leader 是首次写入消息，那么 Broker 会向缓存中增加一个 Leader Epoch 条目，否则就不做更新。这样，每次有 Leader 变更时，新的 Leader 副本会查询这部分缓存，取出对应的 Leader Epoch 的起始位移，以避免数据丢失和不一致的情况。</p>
<p>接下来看一个实际的例子，它展示的是 Leader Epoch 是如何防止数据丢失的。</p>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1622096585706.png" alt="" loading="lazy"></figure>
<p>引用 Leader Epoch 机制后，Follower 副本 B 重启回来后，需要向 A 发送一个特殊的请求去获取 Leader 的 LEO 值。在这个例子中，该值为 2。当获知到 Leader LEO=2 后，B 发现该 LEO 值不比它自己的 LEO 值小，而且缓存中也没有保存任何起始位移值 &gt; 2 的 Epoch 条目，因此 B 无需执行任何日志截断操作。这是对高水位机制的一个明显改进，即副本是否执行日志截断不再依赖于高水位进行判断。</p>
<p>现在，副本 A 宕机了，B 成为 Leader。同样地，当 A 重启回来后，执行与 B 相同的逻辑判断，发现也不用执行日志截断，至此位移值为 1 的那条消息在两个副本中均得到保留。后面当生产者程序向 B 写入新消息时，副本 B 所在的 Broker 缓存中，会生成新的 Leader Epoch 条目：[Epoch=1, Offset=2]。之后，副本 B 会使用这个条目帮助判断后续是否执行日志截断操作。这样，通过 Leader Epoch 机制，Kafka 完美地规避了这种数据丢失场景。</p>
<h2 id="深度思考题">深度思考题</h2>
<h3 id="11-kafka-为什么不支持读写分离">11、Kafka 为什么不支持读写分离?</h3>
<p>这道题目考察的是你对 Leader/Follower 模型的思考。</p>
<p>Leader/Follower 模型并没有规定 Follower 副本不可以对外提供读服务。很多框架都是允 许这么做的，只是 Kafka 最初为了避免不一致性的问题，而采用了让 Leader 统一提供服 务的方式。</p>
<p>不过，在开始回答这道题时，你可以率先亮出观点:<strong>自 Kafka 2.4 之后，Kafka 提供了有限度的读写分离，也就是说，Follower 副本能够对外提供读服务</strong>。</p>
<p>说完这些之后，你可以再给出之前的版本不支持读写分离的理由。</p>
<ul>
<li><strong>场景不适用</strong>。读写分离适用于那种读负载很大，而写操作相对不频繁的场景，可 Kafka 不属于这样的场景。</li>
<li><strong>同步机制</strong>。Kafka 采用 PULL 方式实现 Follower 的同步，因此，Follower 与 Leader 存 在不一致性窗口。如果允许读 Follower 副本，就势必要处理消息滞后(Lagging)的问题。</li>
</ul>
<h3 id="12-如何调优-kafka">12、如何调优 Kafka?</h3>
<p>回答任何调优问题的第一步，就是 <strong>确定优化目标，并且定量给出目标!</strong> 这点特别重要。对于 Kafka 而言，常见的优化目标是吞吐量、延时、持久性和可用性。每一个方向的优化思路都 是不同的，甚至是相反的。</p>
<p>确定了目标之后，还要明确优化的维度。有些调优属于通用的优化思路，比如对操作系统、 JVM 等的优化;有些则是有针对性的，比如要优化 Kafka 的 TPS。我们需要从 3 个方向去考虑</p>
<ul>
<li><strong>Producer 端</strong>:增加 batch.size、linger.ms，启用压缩，关闭重试等。</li>
<li><strong>Broker 端</strong>:增加 num.replica.fetchers，提升 Follower 同步 TPS，避免 Broker Full GC 等。</li>
<li><strong>Consumer</strong>:增加 fetch.min.bytes 等</li>
</ul>
<h3 id="13-controller-发生网络分区network-partitioning时kafka-会怎-么样">13、Controller 发生网络分区(Network Partitioning)时，Kafka 会怎 么样?</h3>
<p>这道题目能够诱发我们对分布式系统设计、CAP 理论、一致性等多方面的思考。不过，针 对故障定位和分析的这类问题，我建议你首先言明“实用至上”的观点，即不论怎么进行理论分析，永远都要以实际结果为准。一旦发生 Controller 网络分区，那么，第一要务就是 查看集群是否出现“脑裂”，即同时出现两个甚至是多个 Controller 组件。这可以根据 Broker 端监控指标 ActiveControllerCount 来判断。</p>
<p>现在，我们分析下，一旦出现这种情况，Kafka 会怎么样。</p>
<p>由于 Controller 会给 Broker 发送 3 类请求，即LeaderAndIsrRequest、 StopReplicaRequest 和 UpdateMetadataRequest，因此，一旦出现网络分区，这些请求将不能顺利到达 Broker 端。这将影响主题的创建、修改、删除操作的信息同步，表现为 集群仿佛僵住了一样，无法感知到后面的所有操作。因此，网络分区通常都是非常严重的问 题，要赶快修复。</p>
<h3 id="14-java-consumer-为什么采用单线程来获取消息">14、Java Consumer 为什么采用单线程来获取消息?</h3>
<p>在回答之前，如果先把这句话说出来，一定会加分:<strong>Java Consumer 是双线程的设计。一 个线程是用户主线程，负责获取消息;另一个线程是心跳线程，负责向 Kafka 汇报消费者 存活情况。将心跳单独放入专属的线程，能够有效地规避因消息处理速度慢而被视为下线 的“假死”情况。</strong></p>
<p>单线程获取消息的设计能够避免阻塞式的消息获取方式。单线程轮询方式容易实现异步非阻塞式，这样便于将消费者扩展成支持实时流处理的操作算子。因为很多实时流处理操作算子都不能是阻塞式的。另外一个可能的好处是，可以简化代码的开发。多线程交互的代码是非常容易出错的。</p>
<h3 id="15-简述-follower-副本消息同步的完整流程">15、简述 Follower 副本消息同步的完整流程</h3>
<p>首先，Follower 发送 FETCH 请求给 Leader。接着，Leader 会读取底层日志文件中的消 息数据，再更新它内存中的 Follower 副本的 LEO 值，更新为 FETCH 请求中的 fetchOffset 值。最后，尝试更新分区高水位值。Follower 接收到 FETCH 响应之后，会把 消息写入到底层日志，接着更新 LEO 和 HW 值。</p>
<p>Leader 和 Follower 的 HW 值更新时机是不同的，Follower 的 HW 更新永远落后于 Leader 的 HW。这种时间上的错配是造成各种不一致的原因。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[第三章 Apache Kafka 与Spark的集成]]></title>
        <id>https://tinaxiawuhao.github.io/post/2csXIfKdw/</id>
        <link href="https://tinaxiawuhao.github.io/post/2csXIfKdw/">
        </link>
        <updated>2021-04-21T05:33:58.000Z</updated>
        <content type="html"><![CDATA[<p>在本章中，我们将讨论如何将Apache Kafka与Spark Streaming API集成。</p>
<h2 id="关于spark">关于Spark</h2>
<p>Spark Streaming API支持实时数据流的可扩展，高吞吐量，容错流处理。 数据可以从诸如Kafka，Flume，Twitter等许多源中提取，并且可以使用复杂的算法来处理，例如地图，缩小，连接和窗口等高级功能。 最后，处理的数据可以推送到文件系统，数据库和活动仪表板。 弹性分布式数据集(RDD)是Spark的基本数据结构。 它是一个不可变的分布式对象集合。 RDD中的每个数据集划分为逻辑分区，可以在集群的不同节点上计算。</p>
<h2 id="与spark集成">与Spark集成</h2>
<p>Kafka是Spark流式传输的潜在消息传递和集成平台。 Kafka充当实时数据流的中心枢纽，并使用Spark Streaming中的复杂算法进行处理。 一旦数据被处理，Spark Streaming可以将结果发布到另一个Kafka主题或存储在HDFS，数据库或仪表板中。 下图描述了概念流程。</p>
<figure data-type="image" tabindex="1"><img src="https://atts.w3cschool.cn/attachments/tuploads/apache_kafka/integration_spark.jpg" alt="Integration with Spark" loading="lazy"></figure>
<p>现在，让我们详细了解Kafka-Spark API。</p>
<h3 id="sparkconf-api">SparkConf API</h3>
<p>它表示Spark应用程序的配置。 用于将各种Spark参数设置为键值对。</p>
<p>SparkConf 类有以下方法 -</p>
<ul>
<li><strong>set(string key，string value)</strong> - 设置配置变量。</li>
<li><strong>remove(string key)</strong> - 从配置中移除密钥。</li>
<li><strong>setAppName(string name)</strong> - 设置应用程序的应用程序名称。</li>
<li><strong>get(string key)</strong> - get key</li>
</ul>
<h3 id="streamingcontext-api">StreamingContext API</h3>
<p>这是Spark功能的主要入口点。 SparkContext表示到Spark集群的连接，可用于在集群上创建RDD，累加器和广播变量。 签名的定义如下所示。</p>
<pre><code class="language-java">public StreamingContext(String master, String appName, Duration batchDuration, 
   String sparkHome, scala.collection.Seq&lt;String&gt; jars, 
   scala.collection.Map&lt;String,String&gt; environment)
</code></pre>
<ul>
<li><strong>主</strong> - 要连接的群集网址(例如mesos:// host:port，spark:// host:port，local [4])。</li>
<li><strong>appName</strong> - 作业的名称，以显示在集群Web UI上</li>
<li><strong>batchDuration</strong> - 流式数据将被分成批次的时间间隔</li>
</ul>
<pre><code class="language-java">public StreamingContext(SparkConf conf, Duration batchDuration)
</code></pre>
<p>通过提供新的SparkContext所需的配置创建StreamingContext。</p>
<ul>
<li><strong>conf</strong> - Spark参数</li>
<li><strong>batchDuration</strong> - 流式数据将被分成批次的时间间隔</li>
</ul>
<h3 id="kafkautils-api">KafkaUtils API</h3>
<p>KafkaUtils API用于将Kafka集群连接到Spark流。 此API具有如下定义的显着方法 createStream 。</p>
<pre><code class="language-java">public static ReceiverInputDStream&lt;scala.Tuple2&lt;String,String&gt;&gt; createStream(
   StreamingContext ssc, String zkQuorum, String groupId,
   scala.collection.immutable.Map&lt;String,Object&gt; topics, StorageLevel storageLevel)
</code></pre>
<p>上面显示的方法用于创建从Kafka Brokers提取消息的输入流。</p>
<ul>
<li><strong>ssc</strong> - StreamingContext对象。</li>
<li><strong>zkQuorum</strong> - Zookeeper quorum。</li>
<li><strong>groupId</strong> - 此消费者的组ID。</li>
<li><strong>主题</strong> - 返回要消费的主题的地图。</li>
<li><strong>storageLevel</strong> - 用于存储接收的对象的存储级别。</li>
</ul>
<p>KafkaUtils API有另一个方法createDirectStream，用于创建一个输入流，直接从Kafka Brokers拉取消息，而不使用任何接收器。 这个流可以保证来自Kafka的每个消息都包含在转换中一次。</p>
<p>示例应用程序在Scala中完成。 要编译应用程序，请下载并安装 sbt ，scala构建工具(类似于maven)。 主要应用程序代码如下所示。</p>
<pre><code class="language-java">import java.util.HashMap

import org.apache.kafka.clients.producer.{KafkaProducer, ProducerConfig, Produc-erRecord}
import org.apache.spark.SparkConf
import org.apache.spark.streaming._
import org.apache.spark.streaming.kafka._

object KafkaWordCount {
   def main(args: Array[String]) {
      if (args.length &lt; 4) {
         System.err.println(&quot;Usage: KafkaWordCount &lt;zkQuorum&gt;&lt;group&gt; &lt;topics&gt; &lt;numThreads&gt;&quot;)
         System.exit(1)
      }

      val Array(zkQuorum, group, topics, numThreads) = args
      val sparkConf = new SparkConf().setAppName(&quot;KafkaWordCount&quot;)
      val ssc = new StreamingContext(sparkConf, Seconds(2))
      ssc.checkpoint(&quot;checkpoint&quot;)

      val topicMap = topics.split(&quot;,&quot;).map((_, numThreads.toInt)).toMap
      val lines = KafkaUtils.createStream(ssc, zkQuorum, group, topicMap).map(_._2)
      val words = lines.flatMap(_.split(&quot; &quot;))
      val wordCounts = words.map(x =&gt; (x, 1L))
         .reduceByKeyAndWindow(_ &amp;plus; _, _ - _, Minutes(10), Seconds(2), 2)
      wordCounts.print()

      ssc.start()
      ssc.awaitTermination()
   }
}
</code></pre>
<h3 id="构建脚本">构建脚本</h3>
<p>spark-kafka集成取决于Spark，Spark流和Spark与Kafka的集成jar。 创建一个新文件 build.sbt ，并指定应用程序详细信息及其依赖关系。 在编译和打包应用程序时， sbt 将下载所需的jar。</p>
<pre><code class="language-sh">name := &quot;Spark Kafka Project&quot;
version := &quot;1.0&quot;
scalaVersion := &quot;2.10.5&quot;

libraryDependencies += &quot;org.apache.spark&quot; %% &quot;spark-core&quot; % &quot;1.6.0&quot;
libraryDependencies += &quot;org.apache.spark&quot; %% &quot;spark-streaming&quot; % &quot;1.6.0&quot;
libraryDependencies += &quot;org.apache.spark&quot; %% &quot;spark-streaming-kafka&quot; % &quot;1.6.0&quot;
</code></pre>
<h3 id="编译包装">编译/包装</h3>
<p>运行以下命令以编译和打包应用程序的jar文件。 我们需要将jar文件提交到spark控制台以运行应用程序。</p>
<pre><code class="language-sh">sbt package
</code></pre>
<h3 id="提交到spark">提交到Spark</h3>
<p>启动Kafka Producer CLI(在上一章中解释)，创建一个名为 my-first-topic 的新主题，并提供一些样本消息，如下所示。</p>
<pre><code class="language-sh">Another spark test message
</code></pre>
<p>运行以下命令将应用程序提交到spark控制台。</p>
<pre><code class="language-sh">/usr/local/spark/bin/spark-submit --packages org.apache.spark:spark-streaming
-kafka_2.10:1.6.0 --class &quot;KafkaWordCount&quot; --master local[4] target/scala-2.10/spark
-kafka-project_2.10-1.0.jar localhost:2181 &lt;group name&gt; &lt;topic name&gt; &lt;number of threads&gt;
</code></pre>
<p>此应用程序的示例输出如下所示。</p>
<pre><code class="language-sh">spark console messages ..
(Test,1)
(spark,1)
(another,1)
(message,1)
spark console message ..
</code></pre>
<blockquote>
<p>原文：https://www.w3cschool.cn/apache_kafka/apache_kafka_integration_spark.html</p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[第二章 Apache Kafka 整合 Storm]]></title>
        <id>https://tinaxiawuhao.github.io/post/wAqEEPZon/</id>
        <link href="https://tinaxiawuhao.github.io/post/wAqEEPZon/">
        </link>
        <updated>2021-04-20T05:29:47.000Z</updated>
        <content type="html"><![CDATA[<p>在本章中，我们将学习如何将Kafka与Apache Storm集成。</p>
<h2 id="关于storm">关于Storm</h2>
<p>Storm最初由Nathan Marz和BackType的团队创建。 在短时间内，Apache Storm成为分布式实时处理系统的标准，允许您处理大量数据。 Storm是非常快的，并且一个基准时钟为每个节点每秒处理超过一百万个元组。 Apache Storm持续运行，从配置的源(Spouts)消耗数据，并将数据传递到处理管道(Bolts)。 联合，Spouts和Bolt构成一个拓扑。</p>
<h2 id="与storm集成">与Storm集成</h2>
<p>Kafka和Storm自然互补，它们强大的合作能够实现快速移动的大数据的实时流分析。 Kafka和Storm集成是为了使开发人员更容易地从Storm拓扑获取和发布数据流。</p>
<h3 id="概念流">概念流</h3>
<p>Spouts是流的源。 例如，一个喷头可以从Kafka Topic读取元组并将它们作为流发送。 Bolt消耗输入流，处理并可能发射新的流。 Bolt可以从运行函数，过滤元组，执行流聚合，流连接，与数据库交谈等等做任何事情。 Storm拓扑中的每个节点并行执行。 拓扑无限运行，直到终止它。 Storm将自动重新分配任何失败的任务。 此外，Storm保证没有数据丢失，即使机器停机和消息被丢弃。</p>
<p>让我们详细了解Kafka-Storm集成API。 有三个主要类集成Kafka与Storm。 他们如下 -</p>
<h3 id="brokerhosts-zkhosts-statichosts">BrokerHosts - ZkHosts &amp; StaticHosts</h3>
<p>BrokerHosts是一个接口，ZkHosts和StaticHosts是它的两个主要实现。 ZkHosts用于通过在ZooKeeper中维护细节来动态跟踪Kafka代理，而StaticHosts用于手动/静态设置Kafka代理及其详细信息。 ZkHosts是访问Kafka代理的简单快捷的方式。</p>
<p>ZkHosts的签名如下 -</p>
<pre><code class="language-java">public ZkHosts(String brokerZkStr, String brokerZkPath)
public ZkHosts(String brokerZkStr)
</code></pre>
<p>其中brokerZkStr是ZooKeeper主机，brokerZkPath是ZooKeeper路径以维护Kafka代理详细信息。</p>
<h3 id="kafkaconfig-api">KafkaConfig API</h3>
<p>此API用于定义Kafka集群的配置设置。 Kafka Con-fig的签名定义如下</p>
<pre><code class="language-java">public KafkaConfig(BrokerHosts hosts, string topic)
</code></pre>
<ul>
<li>
<p><strong>主机</strong> - BrokerHosts可以是ZkHosts / StaticHosts。</p>
</li>
<li>
<p><strong>主题</strong> - 主题名称。</p>
</li>
</ul>
<h3 id="spoutconfig-api">SpoutConfig API</h3>
<p>Spoutconfig是KafkaConfig的扩展，支持额外的ZooKeeper信息。</p>
<pre><code class="language-java">public SpoutConfig(BrokerHosts hosts, string topic, string zkRoot, string id)
</code></pre>
<ul>
<li><strong>主机</strong> - BrokerHosts可以是BrokerHosts接口的任何实现</li>
<li><strong>主题</strong> - 主题名称。</li>
<li><strong>zkRoot</strong> - ZooKeeper根路径。</li>
<li><strong>id -</strong> spouts存储在Zookeeper中消耗的偏移量的状态。 ID应该唯一标识您的喷嘴。</li>
</ul>
<h3 id="schemeasmultischeme">SchemeAsMultiScheme</h3>
<p>SchemeAsMultiScheme是一个接口，用于指示如何将从Kafka中消耗的ByteBuffer转换为风暴元组。 它源自MultiScheme并接受Scheme类的实现。 有很多Scheme类的实现，一个这样的实现是StringScheme，它将字节解析为一个简单的字符串。 它还控制输出字段的命名。 签名定义如下。</p>
<pre><code class="language-java">public SchemeAsMultiScheme(Scheme scheme)
</code></pre>
<ul>
<li><strong>方案</strong> - 从kafka消耗的字节缓冲区。</li>
</ul>
<h3 id="kafkaspout-api">KafkaSpout API</h3>
<p>KafkaSpout是我们的spout实现，它将与Storm集成。 它从kafka主题获取消息，并将其作为元组发送到Storm生态系统。 KafkaSpout从SpoutConfig获取其配置详细信息。</p>
<p>下面是一个创建一个简单的Kafka喷水嘴的示例代码。</p>
<pre><code class="language-java">// ZooKeeper connection string
BrokerHosts hosts = new ZkHosts(zkConnString);

//Creating SpoutConfig Object
SpoutConfig spoutConfig = new SpoutConfig(hosts, 
   topicName, &quot;/&quot; + topicName UUID.randomUUID().toString());

//convert the ByteBuffer to String.
spoutConfig.scheme = new SchemeAsMultiScheme(new StringScheme());

//Assign SpoutConfig to KafkaSpout.
KafkaSpout kafkaSpout = new KafkaSpout(spoutConfig);
</code></pre>
<h2 id=""></h2>
<h2 id="创建bolt">创建Bolt</h2>
<p>Bolt是一个使用元组作为输入，处理元组，并产生新的元组作为输出的组件。 Bolt将实现IRichBolt接口。 在此程序中，使用两个Bolt类WordSplitter-Bolt和WordCounterBolt来执行操作。</p>
<p>IRichBolt接口有以下方法 -</p>
<ul>
<li><strong>准备</strong> - 为Bolt提供要执行的环境。 执行器将运行此方法来初始化喷头。</li>
<li><strong>执行</strong> - 处理单个元组的输入。</li>
<li><strong>清理</strong> - 当Bolt要关闭时调用。</li>
<li><strong>declareOutputFields</strong> - 声明元组的输出模式。</li>
</ul>
<p>让我们创建SplitBolt.java，它实现逻辑分割一个句子到词和CountBolt.java，它实现逻辑分离独特的单词和计数其出现。</p>
<h3 id="splitboltjava">SplitBolt.java</h3>
<pre><code class="language-java">import java.util.Map;

import backtype.storm.tuple.Tuple;
import backtype.storm.tuple.Fields;
import backtype.storm.tuple.Values;

import backtype.storm.task.OutputCollector;
import backtype.storm.topology.OutputFieldsDeclarer;
import backtype.storm.topology.IRichBolt;
import backtype.storm.task.TopologyContext;

public class SplitBolt implements IRichBolt {
   private OutputCollector collector;
   
   @Override
   public void prepare(Map stormConf, TopologyContext context,
      OutputCollector collector) {
      this.collector = collector;
   }
   
   @Override
   public void execute(Tuple input) {
      String sentence = input.getString(0);
      String[] words = sentence.split(&quot; &quot;);
      
      for(String word: words) {
         word = word.trim();
         
         if(!word.isEmpty()) {
            word = word.toLowerCase();
            collector.emit(new Values(word));
         }
         
      }

      collector.ack(input);
   }
   
   @Override
   public void declareOutputFields(OutputFieldsDeclarer declarer) {
      declarer.declare(new Fields(&quot;word&quot;));
   }

   @Override
   public void cleanup() {}
   
   @Override
   public Map&lt;String, Object&gt; getComponentConfiguration() {
      return null;
   }
   
}
</code></pre>
<h3 id="countboltjava">CountBolt.java</h3>
<pre><code class="language-java">import java.util.Map;
import java.util.HashMap;

import backtype.storm.tuple.Tuple;
import backtype.storm.task.OutputCollector;
import backtype.storm.topology.OutputFieldsDeclarer;
import backtype.storm.topology.IRichBolt;
import backtype.storm.task.TopologyContext;

public class CountBolt implements IRichBolt{
   Map&lt;String, Integer&gt; counters;
   private OutputCollector collector;
   
   @Override
   public void prepare(Map stormConf, TopologyContext context,
   OutputCollector collector) {
      this.counters = new HashMap&lt;String, Integer&gt;();
      this.collector = collector;
   }

   @Override
   public void execute(Tuple input) {
      String str = input.getString(0);
      
      if(!counters.containsKey(str)){
         counters.put(str, 1);
      }else {
         Integer c = counters.get(str) +1;
         counters.put(str, c);
      }
   
      collector.ack(input);
   }

   @Override
   public void cleanup() {
      for(Map.Entry&lt;String, Integer&gt; entry:counters.entrySet()){
         System.out.println(entry.getKey()&amp;plus;&quot; : &quot; &amp;plus; entry.getValue());
      }
   }

   @Override
   public void declareOutputFields(OutputFieldsDeclarer declarer) {
   
   }

   @Override
   public Map&lt;String, Object&gt; getComponentConfiguration() {
      return null;
   }
}
</code></pre>
<h2 id="提交拓扑">提交拓扑</h2>
<p>Storm拓扑基本上是一个Thrift结构。 TopologyBuilder类提供了简单而容易的方法来创建复杂的拓扑。 TopologyBuilder类具有设置spout(setSpout)和设置bolt(setBolt)的方法。 最后，TopologyBuilder有createTopology来创建to-pology。 shuffleGrouping和fieldsGrouping方法有助于为喷头和Bolt设置流分组。</p>
<p><strong>本地集群</strong> - 为了开发目的，我们可以使用 LocalCluster 对象创建本地集群，然后使用 LocalCluster的 submitTopology 类。</p>
<h3 id="kafkastormsamplejava">KafkaStormSample.java</h3>
<pre><code class="language-java">import backtype.storm.Config;
import backtype.storm.LocalCluster;
import backtype.storm.topology.TopologyBuilder;

import java.util.ArrayList;
import java.util.List;
import java.util.UUID;

import backtype.storm.spout.SchemeAsMultiScheme;
import storm.kafka.trident.GlobalPartitionInformation;
import storm.kafka.ZkHosts;
import storm.kafka.Broker;
import storm.kafka.StaticHosts;
import storm.kafka.BrokerHosts;
import storm.kafka.SpoutConfig;
import storm.kafka.KafkaConfig;
import storm.kafka.KafkaSpout;
import storm.kafka.StringScheme;

public class KafkaStormSample {
   public static void main(String[] args) throws Exception{
      Config config = new Config();
      config.setDebug(true);
      config.put(Config.TOPOLOGY_MAX_SPOUT_PENDING, 1);
      String zkConnString = &quot;localhost:2181&quot;;
      String topic = &quot;my-first-topic&quot;;
      BrokerHosts hosts = new ZkHosts(zkConnString);
      
      SpoutConfig kafkaSpoutConfig = new SpoutConfig (hosts, topic, &quot;/&quot; + topic,    
         UUID.randomUUID().toString());
      kafkaSpoutConfig.bufferSizeBytes = 1024 * 1024 * 4;
      kafkaSpoutConfig.fetchSizeBytes = 1024 * 1024 * 4;
      kafkaSpoutConfig.forceFromStart = true;
      kafkaSpoutConfig.scheme = new SchemeAsMultiScheme(new StringScheme());

      TopologyBuilder builder = new TopologyBuilder();
      builder.setSpout(&quot;kafka-spout&quot;, new KafkaSpout(kafkaSpoutCon-fig));
      builder.setBolt(&quot;word-spitter&quot;, new SplitBolt()).shuffleGroup-ing(&quot;kafka-spout&quot;);
      builder.setBolt(&quot;word-counter&quot;, new CountBolt()).shuffleGroup-ing(&quot;word-spitter&quot;);
         
      LocalCluster cluster = new LocalCluster();
      cluster.submitTopology(&quot;KafkaStormSample&quot;, config, builder.create-Topology());

      Thread.sleep(10000);
      
      cluster.shutdown();
   }
}
</code></pre>
<p>在移动编译之前，Kakfa-Storm集成需要策展人ZooKeeper客户端java库。 策展人版本2.9.1支持Apache Storm 0.9.5版(我们在本教程中使用)。 下载下面指定的jar文件并将其放在java类路径中。</p>
<ul>
<li>curator-client-2.9.1.jar</li>
<li>curator-framework-2.9.1.jar</li>
</ul>
<p>在包括依赖文件之后，使用以下命令编译程序，</p>
<pre><code class="language-sh">javac -cp &quot;/path/to/Kafka/apache-storm-0.9.5/lib/*&quot; *.java
</code></pre>
<h3 id="执行">执行</h3>
<p>启动Kafka Producer CLI(在上一章节中解释)，创建一个名为 my-first-topic 的新主题，并提供一些样本消息，如下所示 -</p>
<pre><code class="language-sh">hello
kafka
storm
spark
test message
another test message
</code></pre>
<p>现在使用以下命令执行应用程序 -</p>
<pre><code class="language-sh">java -cp “/path/to/Kafka/apache-storm-0.9.5/lib/*&quot;:. KafkaStormSample
</code></pre>
<p>此应用程序的示例输出如下所示 -</p>
<pre><code class="language-sh">storm : 1
test : 2
spark : 1
another : 1
kafka : 1
hello : 1
message : 2
</code></pre>
<blockquote>
<p>原文：https://www.w3cschool.cn/apache_kafka/apache_kafka_integration_storm.html</p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[第一章 Kafka的安装与使用]]></title>
        <id>https://tinaxiawuhao.github.io/post/w7MMk_8-a/</id>
        <link href="https://tinaxiawuhao.github.io/post/w7MMk_8-a/">
        </link>
        <updated>2021-04-19T02:41:18.000Z</updated>
        <content type="html"><![CDATA[<h3 id="kafka-基础知识">Kafka 基础知识</h3>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1619146086328.png" alt="" loading="lazy"></figure>
<p>对于大数据，我们要考虑的问题有很多，首先海量数据如何收集（如 Flume），然后对于收集到的数据如何存储（典型的分布式文件系统 HDFS、分布式数据库 HBase、NoSQL 数据库 Redis），其次存储的数据不是存起来就没事了，要通过计算从中获取有用的信息，这就涉及到计算模型（典型的离线计算 MapReduce、流式实时计算Storm、Spark），或者要从数据中挖掘信息，还需要相应的机器学习算法。在这些之上，还有一些各种各样的查询分析数据的工具（如 Hive、Pig 等）。除此之外，要构建分布式应用还需要一些工具，比如分布式协调服务 Zookeeper 等等。</p>
<p>这里，我们讲到的是消息系统，Kafka 专为分布式高吞吐量系统而设计，其他消息传递系统相比，Kafka 具有更好的吞吐量，内置分区，复制和固有的容错能力，这使得它非常适合大规模消息处理应用程序。</p>
<h3 id="消息系统">消息系统</h3>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1619146163330.png" alt="" loading="lazy"></figure>
<p>​		点对点消息系统：生产者发送一条消息到queue，一个queue可以有很多消费者，但是一个消息只能被一个消费者接受，当没有消费者可用时，这个消息会被保存直到有 一个可用的消费者，所以Queue实现了一个可靠的负载均衡。</p>
<p>​		发布订阅消息系统：发布者发送到topic的消息，只有订阅了topic的订阅者才会收到消息。topic实现了发布和订阅，当你发布一个消息，所有订阅这个topic的服务都能得到这个消息，所以从1到N个订阅者都能得到这个消息的拷贝。</p>
<h3 id="kafka术语">kafka术语</h3>
<p>Apache Kafka 是一个分布式发布 - 订阅消息系统和一个强大的队列，可以处理大量的数据，并使你能够将消息从一个端点传递到另一个端点。 Kafka 适合离线和在线消息消费。 Kafka 消息保留在磁盘上，并在群集内复制以防止数据丢失。 Kafka 构建在 ZooKeeper 同步服务之上。 它与 Apache Storm 和 Spark 非常好地集成，用于实时流式数据分析。</p>
<p>Kafka 是一个分布式消息队列，具有高性能、持久化、多副本备份、横向扩展能力。生产者往队列里写消息，消费者从队列里取消息进行业务逻辑。一般在架构设计中起到解耦、削峰、异步处理的作用。</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1619146174125.png" alt="" loading="lazy"></figure>
<p>​		消息由producer产生，消息按照topic归类，并发送到broker中，broker中保存了一个或多个topic的消息，consumer通过订阅一组topic的消息，通过持续的poll操作从broker获取消息，并进行后续的消息处理。</p>
<p><strong>Producer</strong> ：消息生产者，就是向broker发指定topic消息的客户端。</p>
<p><strong>Consumer</strong> ：消息消费者，通过订阅一组topic的消息，从broker读取消息的客户端。</p>
<p><strong>Broker</strong> ：一个kafka集群包含一个或多个服务器，一台kafka服务器就是一个broker，用于保存producer发送的消息。一个broker可以容纳多个topic。</p>
<p><strong>Topic</strong> ：每条发送到broker的消息都有一个类别，可以理解为一个队列或者数据库的一张表。</p>
<p><strong>Partition</strong>：一个topic的消息由多个partition队列存储的，一个partition队列在kafka上称为一个分区。每个partition是一个有序的队列，多个partition间则是无序的。partition中的每条消息都会被分配一个有序的id（offset）。</p>
<p><strong>Offset</strong>：偏移量。kafka为每条在分区的消息保存一个偏移量offset，这也是消费者在分区的位置。kafka的存储文件都是按照offset.kafka来命名，位于2049位置的即为2048.kafka的文件。比如一个偏移量是5的消费者，表示已经消费了从0-4偏移量的消息，下一个要消费的消息的偏移量是5。</p>
<p><strong>Consumer Group （CG）</strong>：若干个Consumer组成的集合。这是kafka用来实现一个topic消息的广播（发给所有的consumer）和单播（发给任意一个consumer）的手段。一个topic可以有多个CG。topic的消息会复制（不是真的复制，是概念上的）到所有的CG，但每个CG只会把消息发给该CG中的一个consumer。如果需要实现广播，只要每个consumer有一个独立的CG就可以了。要实现单播只要所有的consumer在同一个CG。用CG还可以将consumer进行自由的分组而不需要多次发送消息到不同的topic。</p>
<p>​		假如一个消费者组有两个消费者，订阅了一个具有4个分区的topic的消息，那么这个消费者组的每一个消费者都会消费两个分区的消息。消费者组的成员是动态维护的，如果新增或者减少了消费者组中的消费者，那么每个消费者消费的分区的消息也会动态变化。比如原来一个消费者组有两个消费者，其中一个消费者因为故障而不能继续消费消息了，那么剩下一个消费者将会消费全部4个分区的消息。</p>
<h3 id="apache-kafka基本原理">Apache Kafka基本原理</h3>
<h4 id="1-分布式和分区distributed-partitioned">1、分布式和分区（distributed、partitioned）</h4>
<p>我们说 kafka 是一个分布式消息系统，所谓的分布式，实际上我们已经大致了解。消息保存在 Topic 中，而为了能够实现大数据的存储，一个 topic 划分为多个分区，每个分区对应一个文件，可以分别存储到不同的机器上，以实现分布式的集群存储。另外，每个 partition 可以有一定的副本，备份到多台机器上，以提高可用性。</p>
<p>总结起来就是：一个 topic 对应的多个 partition 分散存储到集群中的多个 broker 上，存储方式是一个 partition 对应一个文件，每个 broker 负责存储在自己机器上的 partition 中的消息读写。</p>
<h4 id="2-副本replicated">2、副本（replicated ）</h4>
<p>kafka 还可以配置 partitions 需要备份的个数(replicas),每个 partition 将会被备份到多台机器上,以提高可用性，备份的数量可以通过配置文件指定。</p>
<p>这种冗余备份的方式在分布式系统中是很常见的，那么既然有副本，就涉及到对同一个文件的多个备份如何进行管理和调度。kafka 采取的方案是：每个 partition 选举一个 server 作为“leader”，由 leader 负责所有对该分区的读写，其他 server 作为 follower 只需要简单的与 leader 同步，保持跟进即可。如果原来的 leader 失效，会重新选举由其他的 follower 来成为新的 leader。</p>
<p>至于如何选取 leader，实际上如果我们了解 ZooKeeper，就会发现其实这正是 Zookeeper 所擅长的，Kafka 使用 ZK 在 Broker 中选出一个 Controller，用于 Partition 分配和 Leader 选举。</p>
<p>另外，这里我们可以看到，实际上作为 leader 的 server 承担了该分区所有的读写请求，因此其压力是比较大的，从整体考虑，从多少个 partition 就意味着会有多少个leader，kafka 会将 leader 分散到不同的 broker 上，确保整体的负载均衡。</p>
<h4 id="3-整体数据流程">3、整体数据流程</h4>
<p>Kafka 的总体数据流满足下图，该图可以说是概括了整个 kafka 的基本原理。<br>
<img src="https://tinaxiawuhao.github.io/post-images/1622083894591.jpg" alt="" loading="lazy"></p>
<p><strong>（1）数据生产过程（Produce）</strong></p>
<p>对于生产者要写入的一条记录，可以指定四个参数：分别是 topic、partition、key 和 value，其中 topic 和 value（要写入的数据）是必须要指定的，而 key 和 partition 是可选的。</p>
<p>对于一条记录，先对其进行序列化，然后按照 Topic 和 Partition，放进对应的发送队列中。如果 Partition 没填，那么情况会是这样的：a、Key 有填。按照 Key 进行哈希，相同 Key 去一个 Partition。b、Key 没填。Round-Robin 来选 Partition。</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1622083907859.png" alt="" loading="lazy"></figure>
<p>producer 将会和Topic下所有 partition leader 保持 socket 连接，消息由 producer 直接通过 socket 发送到 broker。其中 partition leader 的位置( host : port )注册在 zookeeper 中，producer 作为 zookeeper client，已经注册了 watch 用来监听 partition leader 的变更事件，因此，可以准确的知道谁是当前的 leader。</p>
<p>producer 端采用异步发送：将多条消息暂且在客户端 buffer 起来，并将他们批量的发送到 broker，小数据 IO 太多，会拖慢整体的网络延迟，批量延迟发送事实上提升了网络效率。</p>
<p><strong>（2）数据消费过程（Consume）</strong></p>
<p>对于消费者，不是以单独的形式存在的，每一个消费者属于一个 consumer group，一个 group 包含多个 consumer。特别需要注意的是：订阅 Topic 是以一个消费组来订阅的，发送到 Topic 的消息，只会被订阅此 Topic 的每个 group 中的一个 consumer 消费。</p>
<p>如果所有的 Consumer 都具有相同的 group，那么就像是一个点对点的消息系统；如果每个 consumer 都具有不同的 group，那么消息会广播给所有的消费者。</p>
<p>具体说来，这实际上是根据 partition 来分的，一个 Partition，只能被消费组里的一个消费者消费，但是可以同时被多个消费组消费，消费组里的每个消费者是关联到一个 partition 的，因此有这样的说法：对于一个 topic,同一个 group 中不能有多于 partitions 个数的 consumer 同时消费,否则将意味着某些 consumer 将无法得到消息。</p>
<p>同一个消费组的两个消费者不会同时消费一个 partition。</p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1622083921378.png" alt="" loading="lazy"></figure>
<p>在 kafka 中，采用了 pull 方式，即 consumer 在和 broker 建立连接之后，主动去 pull(或者说 fetch )消息，首先 consumer 端可以根据自己的消费能力适时的去 fetch 消息并处理，且可以控制消息消费的进度(offset)。</p>
<p>partition 中的消息只有一个 consumer 在消费，且不存在消息状态的控制，也没有复杂的消息确认机制，可见 kafka broker 端是相当轻量级的。当消息被 consumer 接收之后，需要保存 Offset 记录消费到哪，以前保存在 ZK 中，由于 ZK 的写性能不好，以前的解决方法都是 Consumer 每隔一分钟上报一次，在 0.10 版本后，Kafka 把这个 Offset 的保存，从 ZK 中剥离，保存在一个名叫 consumeroffsets topic 的 Topic 中，由此可见，consumer 客户端也很轻量级。</p>
<h4 id="4-消息传送机制">4、消息传送机制</h4>
<p>Kafka 支持 3 种消息投递语义,在业务中，常常都是使用 At least once 的模型。</p>
<ul>
<li>At most once：最多一次，消息可能会丢失，但不会重复。</li>
<li>At least once：最少一次，消息不会丢失，可能会重复。</li>
<li>Exactly once：只且一次，消息不丢失不重复，只且消费一次。</li>
</ul>
<h3 id="kafka安装和使用">kafka安装和使用</h3>
<p>在Windows安装运行Kafka：https://blog.csdn.net/weixin_38004638/article/details/91893910</p>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1619146234260.png" alt="" loading="lazy"></figure>
<h3 id="kafka运行">kafka运行</h3>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1619146260426.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1619146275373.png" alt="" loading="lazy"></figure>
<p>一次写入，支持多个应用读取，读取信息是相同的</p>
<figure data-type="image" tabindex="9"><img src="https://tinaxiawuhao.github.io/post-images/1619146288083.png" alt="" loading="lazy"></figure>
<p><code>kafka-study.pom</code></p>
<pre><code class="language-java">&lt;dependencies&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;
        &lt;artifactId&gt;kafka_2.12&lt;/artifactId&gt;
        &lt;version&gt;2.2.1&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
        &lt;artifactId&gt;slf4j-nop&lt;/artifactId&gt;
        &lt;version&gt;1.7.24&lt;/version&gt;
    &lt;/dependency&gt;
&lt;/dependencies&gt;
&lt;build&gt;
    &lt;plugins&gt;
        &lt;plugin&gt;
            &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
            &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
            &lt;version&gt;3.0&lt;/version&gt;
            &lt;configuration&gt;
                &lt;source&gt;1.8&lt;/source&gt;
                &lt;target&gt;1.8&lt;/target&gt;
                &lt;encoding&gt;UTF-8&lt;/encoding&gt;
            &lt;/configuration&gt;
        &lt;/plugin&gt;
    &lt;/plugins&gt;
&lt;/build&gt;
</code></pre>
<h3 id="producer生产者">Producer生产者</h3>
<p>​		发送消息的方式，只管发送，不管结果：只调用接口发送消息到 Kafka 服务器，但不管成功写入与否。由于 Kafka 是高可用的，因此大部分情况下消息都会写入，但在异常情况下会丢消息</p>
<p><code>同步发送</code>：调用 send() 方法返回一个 Future 对象，我们可以使用它的 get() 方法来判断消息发送成功与否</p>
<p><code>异步发送</code>：调用 send() 时提供一个回调方法，当接收到 broker 结果后回调此方法</p>
<pre><code class="language-java">public class MyProducer {
    private static KafkaProducer&lt;String, String&gt; producer;
    //初始化
    static {
        Properties properties = new Properties();
        //kafka启动，生产者建立连接broker的地址
        properties.put(&quot;bootstrap.servers&quot;, &quot;127.0.0.1:9092&quot;);
        //kafka序列化方式
        properties.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);
        properties.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);
        //自定义分区分配器
        properties.put(&quot;partitioner.class&quot;, &quot;com.imooc.kafka.CustomPartitioner&quot;);
        producer = new KafkaProducer&lt;&gt;(properties);
    }

    /**
     * 创建topic：.\bin\windows\kafka-topics.bat --create --zookeeper localhost:2181
     * --replication-factor 1 --partitions 1 --topic kafka-study
     * 创建消费者：.\bin\windows\kafka-console-consumer.bat --bootstrap-server localhost:9092
     * --topic kafka-study --from-beginning
     */
    //发送消息，发送完后不做处理
    private static void sendMessageForgetResult() {
        ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;&gt;(&quot;kafka-study&quot;, &quot;name&quot;, &quot;ForgetResult&quot;);
        producer.send(record);
        producer.close();
    }
    //发送同步消息，获取发送的消息
    private static void sendMessageSync() throws Exception {
        ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;&gt;(&quot;kafka-study&quot;, &quot;name&quot;, &quot;sync&quot;);
        RecordMetadata result = producer.send(record).get();
        System.out.println(result.topic());//kafka-study
        System.out.println(result.partition());//分区为name的hash对应分区
        System.out.println(result.offset());//已发送一条消息，此时偏移量+1
        producer.close();
    }
    /**
     * 创建topic：.\bin\windows\kafka-topics.bat --create --zookeeper localhost:2181
     * --replication-factor 1 --partitions 3 --topic kafka-study-x
     * 创建消费者：.\bin\windows\kafka-console-consumer.bat --bootstrap-server localhost:9092
     * --topic kafka-study-x --from-beginning
     */
      //发送异步消息，获取回调的消息
    private static void sendMessageCallback() {
        ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;&gt;(&quot;kafka-study-x&quot;, &quot;name&quot;, &quot;callback&quot;);
        producer.send(record, new MyProducerCallback());
        //发送多条消息
        record = new ProducerRecord&lt;&gt;(&quot;kafka-study-x&quot;, &quot;name-x&quot;, &quot;callback&quot;);
        producer.send(record, new MyProducerCallback());
        producer.close();
    }
}
</code></pre>
<pre><code class="language-java">//发送异步消息

//场景：每条消息发送有延迟，多条消息发送，无需同步等待，可以执行其他操作，程序会自动异步调用 
private static class MyProducerCallback implements Callback {
       @Override
       public void onCompletion(RecordMetadata recordMetadata, Exception e) {
           if (e != null) {
               e.printStackTrace();
               return;
           }
           System.out.println(&quot;*** MyProducerCallback ***&quot;);
           System.out.println(recordMetadata.topic());
           System.out.println(recordMetadata.partition());
           System.out.println(recordMetadata.offset());
       }
   }
   public static void main(String[] args) throws Exception {
       //sendMessageForgetResult();
       //sendMessageSync();
       sendMessageCallback();
   }
}
</code></pre>
<p>自定义分区分配器：决定消息存放在哪个分区.。默认分配器使用轮询存放，轮到已满分区将会写入失败。</p>
<pre><code class="language-java">public class CustomPartitioner implements Partitioner {
    @Override
    public int partition(String topic, Object key, byte[] keyBytes,
                         Object value, byte[] valueBytes, Cluster cluster) {
        //获取topic所有分区
        List&lt;PartitionInfo&gt; partitionInfos = cluster.partitionsForTopic(topic);
        int numPartitions = partitionInfos.size();
        //消息必须有key
        if (null == keyBytes || !(key instanceof String)) {
            throw new InvalidRecordException(&quot;kafka message must have key&quot;);
        }
        //如果只有一个分区，即0号分区
        if (numPartitions == 1) {return 0;}
        //如果key为name，发送至最后一个分区
        if (key.equals(&quot;name&quot;)) {return numPartitions - 1;}
        return Math.abs(Utils.murmur2(keyBytes)) % (numPartitions - 1);
    }
    @Override
    public void close() {}
    @Override
    public void configure(Map&lt;String, ?&gt; map) {}
}
</code></pre>
<p>启动生产者发送消息，通过自定义分区分配器分配，查询到topic信息的offset、partitioner</p>
<table>
<thead>
<tr>
<th>topic</th>
<th>partition</th>
<th>offset</th>
</tr>
</thead>
<tbody>
<tr>
<td>kafka-study</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>kafka-study</td>
<td>1</td>
<td>2</td>
</tr>
<tr>
<td>kafka-study-x</td>
<td>0</td>
<td>1</td>
</tr>
</tbody>
</table>
<h3 id="kafka消费者组">Kafka消费者（组）</h3>
<pre><code class="language-java">public class MyConsumer {
    private static KafkaConsumer&lt;String, String&gt; consumer;
    private static Properties properties;
    //初始化
    static {
        properties = new Properties();
        //建立连接broker的地址
        properties.put(&quot;bootstrap.servers&quot;, &quot;127.0.0.1:9092&quot;);
        //kafka反序列化
        properties.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);
        properties.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);
        //指定消费者组
        properties.put(&quot;group.id&quot;, &quot;KafkaStudy&quot;);
    }

    //自动提交位移：由consume自动管理提交
    private static void generalConsumeMessageAutoCommit() {
        //配置
        properties.put(&quot;enable.auto.commit&quot;, true);
        consumer = new KafkaConsumer&lt;&gt;(properties);
        //指定topic
        consumer.subscribe(Collections.singleton(&quot;kafka-study-x&quot;));
        try {
            while (true) {
                boolean flag = true;
                //拉取信息，超时时间100ms
                ConsumerRecords&lt;String, String&gt; records = consumer.poll(100);
                //遍历打印消息
                for (ConsumerRecord&lt;String, String&gt; record : records) {
                    System.out.println(String.format(
                            &quot;topic = %s, partition = %s, key = %s, value = %s&quot;,
                            record.topic(), record.partition(), record.key(), record.value()
                    ));
                    //消息发送完成
                    if (record.value().equals(&quot;done&quot;)) { flag = false; }
                }
                if (!flag) { break; }
            }
        } finally {
            consumer.close();
        }
    }

    //手动同步提交当前位移，根据需求提交，但容易发送阻塞，提交失败会进行重试直到抛出异常
    private static void generalConsumeMessageSyncCommit() {
        properties.put(&quot;auto.commit.offset&quot;, false);
        consumer = new KafkaConsumer&lt;&gt;(properties);

        consumer.subscribe(Collections.singletonList(&quot;kafka-study-x&quot;));
        while (true) {
            boolean flag = true;
            ConsumerRecords&lt;String, String&gt; records = consumer.poll(100);
            for (ConsumerRecord&lt;String, String&gt; record : records) {
                System.out.println(String.format(
                        &quot;topic = %s, partition = %s, key = %s, value = %s&quot;,
                        record.topic(), record.partition(), record.key(), record.value()
                ));
                if (record.value().equals(&quot;done&quot;)) { flag = false; }
            }
            try {
                //手动同步提交
                consumer.commitSync();
            } catch (CommitFailedException ex) {
                System.out.println(&quot;commit failed error: &quot; + ex.getMessage());
            }
            if (!flag) { break; }
        }
    }

    //手动异步提交当前位移，提交速度快，但失败不会记录
    private static void generalConsumeMessageAsyncCommit() {
        properties.put(&quot;auto.commit.offset&quot;, false);
        consumer = new KafkaConsumer&lt;&gt;(properties);
        consumer.subscribe(Collections.singletonList(&quot;kafka-study-x&quot;));
        while (true) {
            boolean flag = true;
            ConsumerRecords&lt;String, String&gt; records = consumer.poll(100);
            for (ConsumerRecord&lt;String, String&gt; record : records) {
                System.out.println(String.format(
                        &quot;topic = %s, partition = %s, key = %s, value = %s&quot;,
                        record.topic(), record.partition(), record.key(), record.value()
                ));
                if (record.value().equals(&quot;done&quot;)) { flag = false; }
            }
            //手动异步提交
            consumer.commitAsync();
            if (!flag) { break; }
        }
    }

    //手动异步提交当前位移带回调
    private static void generalConsumeMessageAsyncCommitWithCallback() {
        properties.put(&quot;auto.commit.offset&quot;, false);
        consumer = new KafkaConsumer&lt;&gt;(properties);
        consumer.subscribe(Collections.singletonList(&quot;kafka-study-x&quot;));
        while (true) {
            boolean flag = true;
            ConsumerRecords&lt;String, String&gt; records = consumer.poll(100);
            for (ConsumerRecord&lt;String, String&gt; record : records) {
                System.out.println(String.format(
                        &quot;topic = %s, partition = %s, key = %s, value = %s&quot;,
                        record.topic(), record.partition(), record.key(), record.value()
                ));
                if (record.value().equals(&quot;done&quot;)) { flag = false; }
            }
            //使用java8函数式编程
            consumer.commitAsync((map, e) -&gt; {
                if (e != null) {
                    System.out.println(&quot;commit failed for offsets: &quot; + e.getMessage());
                }
            });
            if (!flag) { break; }
        }
    }

    //混合同步与异步提交位移
    @SuppressWarnings(&quot;all&quot;)
    private static void mixSyncAndAsyncCommit() {
        properties.put(&quot;auto.commit.offset&quot;, false);
        consumer = new KafkaConsumer&lt;&gt;(properties);
        consumer.subscribe(Collections.singletonList(&quot;kafka-study-x&quot;));
        try {
            while (true) {
                //boolean flag = true;
                ConsumerRecords&lt;String, String&gt; records = consumer.poll(100);
                for (ConsumerRecord&lt;String, String&gt; record : records) {
                    System.out.println(String.format(
                            &quot;topic = %s, partition = %s, key = %s, &quot; + &quot;value = %s&quot;,
                            record.topic(), record.partition(),
                            record.key(), record.value()
                    ));
                    //if (record.value().equals(&quot;done&quot;)) { flag = false; }
                }
                //手动异步提交，保证性能
                consumer.commitAsync();
                //if (!flag) { break; }
            }
        } catch (Exception ex) {
            System.out.println(&quot;commit async error: &quot; + ex.getMessage());
        } finally {
            try {
                //异步提交失败，再尝试手动同步提交
                consumer.commitSync();
            } finally {
                consumer.close();
            }
        }
    }

    public static void main(String[] args) {
        //自动提交位移
        generalConsumeMessageAutoCommit();
        //手动同步提交当前位移
        //generalConsumeMessageSyncCommit();
        //手动异步提交当前位移
        //generalConsumeMessageAsyncCommit();
        //手动异步提交当前位移带回调
        //generalConsumeMessageAsyncCommitWithCallback()
        //混合同步与异步提交位移
        //mixSyncAndAsyncCommit();
    }
}
</code></pre>
<p>先启动消费者等待接收消息，再启动生产者发送消息，进行消费消息</p>
<table>
<thead>
<tr>
<th>topic</th>
<th>partition</th>
<th>key</th>
<th>value</th>
</tr>
</thead>
<tbody>
<tr>
<td>kafka-study-x</td>
<td>1</td>
<td>name-x</td>
<td>callback</td>
</tr>
<tr>
<td>kafka-study-x</td>
<td>2</td>
<td>name-x</td>
<td>callback</td>
</tr>
<tr>
<td>kafka-study-x</td>
<td>1</td>
<td>name-x</td>
<td>callback</td>
</tr>
<tr>
<td>kafka-study-x</td>
<td>1</td>
<td>name-x</td>
<td>callback</td>
</tr>
<tr>
<td>kafka-study-x</td>
<td>2</td>
<td>name-x</td>
<td>callback</td>
</tr>
</tbody>
</table>
]]></content>
    </entry>
</feed>