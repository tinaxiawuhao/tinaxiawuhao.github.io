<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://tinaxiawuhao.github.io</id>
    <title>tianxia</title>
    <updated>2022-07-24T13:36:33.381Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://tinaxiawuhao.github.io"/>
    <link rel="self" href="https://tinaxiawuhao.github.io/atom.xml"/>
    <subtitle>In me the tiger sniffs the rose</subtitle>
    <logo>https://tinaxiawuhao.github.io/images/avatar.png</logo>
    <icon>https://tinaxiawuhao.github.io/favicon.ico</icon>
    <rights>All rights reserved 2022, tianxia</rights>
    <entry>
        <title type="html"><![CDATA[ZipKin核心架构]]></title>
        <id>https://tinaxiawuhao.github.io/post/OTKk-Bytc/</id>
        <link href="https://tinaxiawuhao.github.io/post/OTKk-Bytc/">
        </link>
        <updated>2022-07-14T13:31:40.000Z</updated>
        <content type="html"><![CDATA[<h2 id="zipkin核心架构">ZipKin核心架构</h2>
<p>Zipkin 是 Twitter 的一个开源项目，它基于Google Dapper论文实现，可以收集微服务运行过程中的实时链路数据，并进行展示。</p>
<h3 id="zipkin概述">ZipKin概述</h3>
<p>Zipkin是一种分布式链路跟踪系统，能够收集微服务运行过程中的实时调用链路信息，并能够将这些调用链路信息展示到Web界面上供开发人员分析，开发人员能够从ZipKin中分析出调用链路中的性能瓶颈，识别出存在问题的应用程序，进而定位问题和解决问题。</p>
<h3 id="zipkin核心架构-2">ZipKin核心架构</h3>
<p>ZipKin的核心架构图如下所示。</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1658669584317.png" alt="" loading="lazy"></figure>
<p>注：图片来源：zipkin.io/pages/architecture.html</p>
<p>其中，ZipKin核心组件的功能如下所示。</p>
<ul>
<li>Reporter：ZipKin中上报链路数据的模块，主要配置在具体的微服务应用中。</li>
<li>Transport：ZipKin中传输链路数据的模块，此模块可以配置为Kafka，RocketMQ、RabbitMQ等。</li>
<li>Collector：ZipKin中收集并消费链路数据的模块，默认是通过http协议收集，可以配置为Kafka消费。</li>
<li>Storage：ZipKin中存储链路数据的模块，此模块的具体可以配置为ElasticSearch、Cassandra或者MySQL，目前ZipKin支持这三种数据持久化方式。</li>
<li>API：ZipKin中的API 组件，主要用来提供外部访问接口。比如给客户端展示跟踪信息，或是开放给外部系统实现监控等。</li>
<li>UI：ZipKin中的UI 组件，基于API组件实现的上层应用。通过UI组件用户可以方便并且很直观地查询和分析跟踪信息。</li>
</ul>
<p>Zipkin在总体上会分为两个端，一个是Zipkin服务端，一个是Zipkin客户端，客户端主要是配置在微服务应用中，收集微服务中的调用链路信息，将数据发送给ZipKin服务端。</p>
<h2 id="项目整合zipkin">项目整合ZipKin</h2>
<p>Zipkin总体上分为服务端和客户端，我们需要下载并启动ZipKin服务端的Jar包，在微服务中集成ZipKin的客户端。</p>
<h3 id="下载安装zipkin服务端">下载安装ZipKin服务端</h3>
<p>（1）下载ZipKin服务端Jar文件，可以直接在浏览器中输入如下链接进行下载。</p>
<pre><code class="language-java">https://search.maven.org/remote_content?g=io.zipkin.java&amp;a=zipkin-server&amp;v=LATEST&amp;c=exec
</code></pre>
<p>如果大家使用的是Linux操作系统，也可以在命令行输入如下命令进行下载。</p>
<pre><code class="language-java">wget https://search.maven.org/remote_content?g=io.zipkin.java&amp;a=zipkin-server&amp;v=LATEST&amp;c=exec
</code></pre>
<p>这里，我通过浏览器下载的ZipKin服务端Jar文件为：zipkin-server-2.12.9-exec.jar。</p>
<p>（2）在命令行输入如下命令启动ZipKin服务端。</p>
<pre><code class="language-java">java -jar zipkin-server-2.12.9-exec.jar
</code></pre>
<p>（3）由于ZipKin服务端启动时，默认监听的端口号为9411，所以，在浏览器中输入<code>http://localhost:9411</code>链接就可以打开ZipKin的界面，如下所示。</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1658669599290.png" alt="" loading="lazy"></figure>
<p>在浏览器中输入<code>http://localhost:9411</code>链接能够打开上述页面就说明ZipKin服务端已经准备好啦。</p>
<h3 id="项目整合zipkin客户端">项目整合ZipKin客户端</h3>
<p>（1）在每个微服务（用户微服务shop-user，商品微服务shop-product，订单微服务shop-order，网关服务shop-gateway）中添加ZipKin依赖，如下所示。</p>
<pre><code class="language-java">&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<p>（2）在网关服务shop-gateway的application.yml文件中添加如下配置。</p>
<pre><code class="language-java">spring:
  sleuth:
    sampler:
      probability: 1.0
  zipkin:
    base-url: http://127.0.0.1:9411
    discovery-client-enabled: false
</code></pre>
<p>其中各配置的说明如下所示。</p>
<ul>
<li>spring.sleuth.sampler.probability：表示Sleuth的采样百分比。</li>
<li>spring.zipkin.base-url：ZipKin服务端的地址。</li>
<li>spring.zipkin.discovery-client-enabled：配置成false，使Nacos将其当成一个URL，不要按服务名处理。</li>
</ul>
<p>（3）分别启动用户微服务，商品微服务，订单微服务和服务网关，在浏览器中访问链接<code>http://localhost:10001/server-order/order/submit_order?userId=1001&amp;productId=1001&amp;count=1</code>，如下所示。</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1658669612230.png" alt="" loading="lazy"></figure>
<p>（4）点击Zipkin界面上的查找按钮，如下所示。</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1658669621403.png" alt="" loading="lazy"></figure>
<p>点击后的界面如下所示。</p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1658669630450.png" alt="" loading="lazy"></figure>
<p>可以看到，点击查找按钮后，会出现一个请求链路，包含：网关服务server-gateway耗时63.190毫秒，订单微服务server-order耗时53.101毫秒，用户微服务server-user耗时14.640毫秒，商品微服务server-product耗时10.941毫秒。</p>
<p>（5）点开ZipKin界面上显示的调用链路，如下所示。</p>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1658669639633.png" alt="" loading="lazy"></figure>
<p>点开后的界面如下所示。</p>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1658669648357.png" alt="" loading="lazy"></figure>
<p>可以非常清晰的看到整个调用的访问链路。</p>
<p>我们还可以点击具体的节点来查看具体的调用信息。</p>
<p>例如我们点击网关微服务查看网关的具体链路，如下所示。</p>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1658669660361.png" alt="" loading="lazy"></figure>
<p>点开后的效果如下所示。</p>
<figure data-type="image" tabindex="9"><img src="https://tinaxiawuhao.github.io/post-images/1658669669867.png" alt="" loading="lazy"></figure>
<p>接下来，查看下订单微服务的调用链路具体信息，如下所示。</p>
<figure data-type="image" tabindex="10"><img src="https://tinaxiawuhao.github.io/post-images/1658669680389.png" alt="" loading="lazy"></figure>
<p>点开后的效果如下所示。</p>
<figure data-type="image" tabindex="11"><img src="https://tinaxiawuhao.github.io/post-images/1658669689570.png" alt="" loading="lazy"></figure>
<p>可以看到，通过ZipKin能够查看服务的调用链路，并且能够查看具体微服务的调用情况。我们可以基于ZipKin来分析系统的调用链路情况，找出系统的瓶颈点，进而进行针对性的优化。</p>
<p>另外，ZipKin中也支持下载系统调用链路的Json数据，如下所示。</p>
<figure data-type="image" tabindex="12"><img src="https://tinaxiawuhao.github.io/post-images/1658669701393.png" alt="" loading="lazy"></figure>
<p>点击JSON按钮后，效果如下所示。</p>
<figure data-type="image" tabindex="13"><img src="https://tinaxiawuhao.github.io/post-images/1658669710853.png" alt="" loading="lazy"></figure>
<p>其中，显示的Json数据如下所示。</p>
<pre><code class="language-java">[
  [
    {
      &quot;traceId&quot;: &quot;9d244edbc1668d92&quot;,
      &quot;parentId&quot;: &quot;3f01ba499fac4ce9&quot;,
      &quot;id&quot;: &quot;5f0932b5d06fe757&quot;,
      &quot;kind&quot;: &quot;SERVER&quot;,
      &quot;name&quot;: &quot;get /get/{pid}&quot;,
      &quot;timestamp&quot;: 1652413758790051,
      &quot;duration&quot;: 10941,
      &quot;localEndpoint&quot;: {
        &quot;serviceName&quot;: &quot;server-product&quot;,
        &quot;ipv4&quot;: &quot;192.168.0.111&quot;
      },
      &quot;remoteEndpoint&quot;: {
        &quot;ipv4&quot;: &quot;192.168.0.111&quot;,
        &quot;port&quot;: 54140
      },
      &quot;tags&quot;: {
        &quot;http.method&quot;: &quot;GET&quot;,
        &quot;http.path&quot;: &quot;/product/get/1001&quot;,
        &quot;mvc.controller.class&quot;: &quot;ProductController&quot;,
        &quot;mvc.controller.method&quot;: &quot;getProduct&quot;
      },
      &quot;shared&quot;: true
    },
    {
      &quot;traceId&quot;: &quot;9d244edbc1668d92&quot;,
      &quot;parentId&quot;: &quot;3f01ba499fac4ce9&quot;,
      &quot;id&quot;: &quot;c020c7f6e0fa1604&quot;,
      &quot;kind&quot;: &quot;SERVER&quot;,
      &quot;name&quot;: &quot;get /update_count/{pid}/{count}&quot;,
      &quot;timestamp&quot;: 1652413758808052,
      &quot;duration&quot;: 5614,
      &quot;localEndpoint&quot;: {
        &quot;serviceName&quot;: &quot;server-product&quot;,
        &quot;ipv4&quot;: &quot;192.168.0.111&quot;
      },
      &quot;remoteEndpoint&quot;: {
        &quot;ipv4&quot;: &quot;192.168.0.111&quot;,
        &quot;port&quot;: 54140
      },
      &quot;tags&quot;: {
        &quot;http.method&quot;: &quot;GET&quot;,
        &quot;http.path&quot;: &quot;/product/update_count/1001/1&quot;,
        &quot;mvc.controller.class&quot;: &quot;ProductController&quot;,
        &quot;mvc.controller.method&quot;: &quot;updateCount&quot;
      },
      &quot;shared&quot;: true
    },
    {
      &quot;traceId&quot;: &quot;9d244edbc1668d92&quot;,
      &quot;parentId&quot;: &quot;9d244edbc1668d92&quot;,
      &quot;id&quot;: &quot;3f01ba499fac4ce9&quot;,
      &quot;kind&quot;: &quot;CLIENT&quot;,
      &quot;name&quot;: &quot;get&quot;,
      &quot;timestamp&quot;: 1652413758763816,
      &quot;duration&quot;: 54556,
      &quot;localEndpoint&quot;: {
        &quot;serviceName&quot;: &quot;server-gateway&quot;,
        &quot;ipv4&quot;: &quot;192.168.0.111&quot;
      },
      &quot;remoteEndpoint&quot;: {
        &quot;ipv4&quot;: &quot;192.168.0.111&quot;,
        &quot;port&quot;: 8080
      },
      &quot;tags&quot;: {
        &quot;http.method&quot;: &quot;GET&quot;,
        &quot;http.path&quot;: &quot;/order/submit_order&quot;
      }
    },
    {
      &quot;traceId&quot;: &quot;9d244edbc1668d92&quot;,
      &quot;parentId&quot;: &quot;9d244edbc1668d92&quot;,
      &quot;id&quot;: &quot;475ff483fb0973b1&quot;,
      &quot;kind&quot;: &quot;CLIENT&quot;,
      &quot;name&quot;: &quot;get&quot;,
      &quot;timestamp&quot;: 1652413758759023,
      &quot;duration&quot;: 59621,
      &quot;localEndpoint&quot;: {
        &quot;serviceName&quot;: &quot;server-gateway&quot;,
        &quot;ipv4&quot;: &quot;192.168.0.111&quot;
      },
      &quot;tags&quot;: {
        &quot;http.method&quot;: &quot;GET&quot;,
        &quot;http.path&quot;: &quot;/order/submit_order&quot;
      }
    },
    {
      &quot;traceId&quot;: &quot;9d244edbc1668d92&quot;,
      &quot;id&quot;: &quot;9d244edbc1668d92&quot;,
      &quot;kind&quot;: &quot;SERVER&quot;,
      &quot;name&quot;: &quot;get&quot;,
      &quot;timestamp&quot;: 1652413758757034,
      &quot;duration&quot;: 63190,
      &quot;localEndpoint&quot;: {
        &quot;serviceName&quot;: &quot;server-gateway&quot;,
        &quot;ipv4&quot;: &quot;192.168.0.111&quot;
      },
      &quot;remoteEndpoint&quot;: {
        &quot;ipv4&quot;: &quot;127.0.0.1&quot;,
        &quot;port&quot;: 54137
      },
      &quot;tags&quot;: {
        &quot;http.method&quot;: &quot;GET&quot;,
        &quot;http.path&quot;: &quot;/server-order/order/submit_order&quot;
      }
    },
    {
      &quot;traceId&quot;: &quot;9d244edbc1668d92&quot;,
      &quot;parentId&quot;: &quot;3f01ba499fac4ce9&quot;,
      &quot;id&quot;: &quot;a048eda8d5fd3dc9&quot;,
      &quot;kind&quot;: &quot;CLIENT&quot;,
      &quot;name&quot;: &quot;get&quot;,
      &quot;timestamp&quot;: 1652413758774201,
      &quot;duration&quot;: 12054,
      &quot;localEndpoint&quot;: {
        &quot;serviceName&quot;: &quot;server-order&quot;,
        &quot;ipv4&quot;: &quot;192.168.0.111&quot;
      },
      &quot;tags&quot;: {
        &quot;http.method&quot;: &quot;GET&quot;,
        &quot;http.path&quot;: &quot;/user/get/1001&quot;
      }
    },
    {
      &quot;traceId&quot;: &quot;9d244edbc1668d92&quot;,
      &quot;parentId&quot;: &quot;3f01ba499fac4ce9&quot;,
      &quot;id&quot;: &quot;5f0932b5d06fe757&quot;,
      &quot;kind&quot;: &quot;CLIENT&quot;,
      &quot;name&quot;: &quot;get&quot;,
      &quot;timestamp&quot;: 1652413758787924,
      &quot;duration&quot;: 12557,
      &quot;localEndpoint&quot;: {
        &quot;serviceName&quot;: &quot;server-order&quot;,
        &quot;ipv4&quot;: &quot;192.168.0.111&quot;
      },
      &quot;tags&quot;: {
        &quot;http.method&quot;: &quot;GET&quot;,
        &quot;http.path&quot;: &quot;/product/get/1001&quot;
      }
    },
    {
      &quot;traceId&quot;: &quot;9d244edbc1668d92&quot;,
      &quot;parentId&quot;: &quot;3f01ba499fac4ce9&quot;,
      &quot;id&quot;: &quot;c020c7f6e0fa1604&quot;,
      &quot;kind&quot;: &quot;CLIENT&quot;,
      &quot;name&quot;: &quot;get&quot;,
      &quot;timestamp&quot;: 1652413758805787,
      &quot;duration&quot;: 7031,
      &quot;localEndpoint&quot;: {
        &quot;serviceName&quot;: &quot;server-order&quot;,
        &quot;ipv4&quot;: &quot;192.168.0.111&quot;
      },
      &quot;tags&quot;: {
        &quot;http.method&quot;: &quot;GET&quot;,
        &quot;http.path&quot;: &quot;/product/update_count/1001/1&quot;
      }
    },
    {
      &quot;traceId&quot;: &quot;9d244edbc1668d92&quot;,
      &quot;parentId&quot;: &quot;9d244edbc1668d92&quot;,
      &quot;id&quot;: &quot;3f01ba499fac4ce9&quot;,
      &quot;kind&quot;: &quot;SERVER&quot;,
      &quot;name&quot;: &quot;get /submit_order&quot;,
      &quot;timestamp&quot;: 1652413758765048,
      &quot;duration&quot;: 53101,
      &quot;localEndpoint&quot;: {
        &quot;serviceName&quot;: &quot;server-order&quot;,
        &quot;ipv4&quot;: &quot;192.168.0.111&quot;
      },
      &quot;remoteEndpoint&quot;: {
        &quot;ipv4&quot;: &quot;127.0.0.1&quot;
      },
      &quot;tags&quot;: {
        &quot;http.method&quot;: &quot;GET&quot;,
        &quot;http.path&quot;: &quot;/order/submit_order&quot;,
        &quot;mvc.controller.class&quot;: &quot;OrderController&quot;,
        &quot;mvc.controller.method&quot;: &quot;submitOrder&quot;
      },
      &quot;shared&quot;: true
    },
    {
      &quot;traceId&quot;: &quot;9d244edbc1668d92&quot;,
      &quot;parentId&quot;: &quot;3f01ba499fac4ce9&quot;,
      &quot;id&quot;: &quot;a048eda8d5fd3dc9&quot;,
      &quot;kind&quot;: &quot;SERVER&quot;,
      &quot;name&quot;: &quot;get /get/{uid}&quot;,
      &quot;timestamp&quot;: 1652413758777073,
      &quot;duration&quot;: 14640,
      &quot;localEndpoint&quot;: {
        &quot;serviceName&quot;: &quot;server-user&quot;,
        &quot;ipv4&quot;: &quot;192.168.0.111&quot;
      },
      &quot;remoteEndpoint&quot;: {
        &quot;ipv4&quot;: &quot;192.168.0.111&quot;,
        &quot;port&quot;: 54139
      },
      &quot;tags&quot;: {
        &quot;http.method&quot;: &quot;GET&quot;,
        &quot;http.path&quot;: &quot;/user/get/1001&quot;,
        &quot;mvc.controller.class&quot;: &quot;UserController&quot;,
        &quot;mvc.controller.method&quot;: &quot;getUser&quot;
      },
      &quot;shared&quot;: true
    }
  ]
]
</code></pre>
<p>小伙伴们也可以根据Json数据分析下系统的调用链路。</p>
<h2 id="zipkin数据持久化">ZipKin数据持久化</h2>
<p>我们实现了在项目中集成ZipKin，但是此时我们集成ZipKin后，ZipKin中的数据是保存在系统内存中的，如果我们重启了ZipKin，则保存在系统内存中的数据就会丢失，那我如何避免数据丢失呢？ZipKin支持将数据进行持久化来防止数据丢失，可以将数据保存到ElasticSearch、Cassandra或者MySQL中。这里，我们重点介绍下如何将数据保存到MySQL和ElasticSearch中。</p>
<h3 id="zipkin数据持久化到mysql">ZipKin数据持久化到MySQL</h3>
<p>（1）将Zipkin数据持久化到MySQL，我们需要知道MySQL的数据表结构，好在ZipKin提供了MySQL脚本，小伙伴们可以在链接：https://github.com/openzipkin/zipkin/tree/master/zipkin-storage里面下载。</p>
<figure data-type="image" tabindex="14"><img src="https://tinaxiawuhao.github.io/post-images/1658669727877.png" alt="" loading="lazy"></figure>
<p>当然，我将下载后的MySQL脚本放到了网关服务shop-gateway的resources目录下的scripts目录下。</p>
<figure data-type="image" tabindex="15"><img src="https://tinaxiawuhao.github.io/post-images/1658669734767.png" alt="" loading="lazy"></figure>
<p>（2）在MySQL数据库中新建zipkin数据库，如下所示。</p>
<pre><code class="language-java">create database if not exists zipkin;
</code></pre>
<p>（3）在新建的数据库zipkin中运行mysql.sql脚本，运行脚本后的效果如下所示。</p>
<figure data-type="image" tabindex="16"><img src="https://tinaxiawuhao.github.io/post-images/1658669743490.png" alt="" loading="lazy"></figure>
<p>可以看到，在zipkin数据库中新建了zipkin_annotations、zipkin_dependencies和zipkin_spans三张数据表。</p>
<p>（4）启动ZipKin时指定MySQL数据源，如下所示。</p>
<pre><code class="language-java">java -jar zipkin-server-2.12.9-exec.jar --STORAGE_TYPE=mysql --MYSQL_HOST=127.0.0.1 --MYSQL_TCP_PORT=3306 --MYSQL_DB=zipkin --MYSQL_USER=root --MYSQL_PASS=root
</code></pre>
<p>（5）启动ZipKin后，在浏览器中访问链接<code>http://localhost:10001/server-order/order/submit_order?userId=1001&amp;productId=1001&amp;count=1</code>，如下所示。</p>
<figure data-type="image" tabindex="17"><img src="https://tinaxiawuhao.github.io/post-images/1658669752307.png" alt="" loading="lazy"></figure>
<p>（6）查看zipkin数据库中的数据，发现zipkin_annotations数据表与zipkin_spans数据表已经存在系统的调用链路数据。</p>
<ul>
<li>zipkin_annotations数据表部分数据如下所示。</li>
</ul>
<figure data-type="image" tabindex="18"><img src="https://tinaxiawuhao.github.io/post-images/1658669758514.png" alt="" loading="lazy"></figure>
<ul>
<li>zipkin_spans数据表部分数据如下所示。</li>
</ul>
<figure data-type="image" tabindex="19"><img src="https://tinaxiawuhao.github.io/post-images/1658669768628.png" alt="" loading="lazy"></figure>
<p>可以看到，ZipKin已经将数据持久化到MySQL中，重启ZipKin后就会从MySQL中读取数据，数据也不会丢失了。</p>
<h3 id="zipkin数据持久化到elasticsearch">ZipKin数据持久化到ElasticSearch</h3>
<p>（1）到ElasticSearch官网下载ElasticSearch，链接为：</p>
<p>https://www.elastic.co/cn/downloads/elasticsearch。</p>
<p>这里下载的安装包是：elasticsearch-8.2.0-windows-x86_64.zip。</p>
<p>（2）解压elasticsearch-8.2.0-windows-x86_64.zip，在解压后的bin目录下找到elasticsearch.bat脚本，双击运行ElasticSearch。</p>
<p>（3）启动ZipKin服务端时，指定ElasticSearch，如下所示。</p>
<pre><code class="language-java">java -jar zipkin-server-2.12.9-exec.jar --STORAGE_TYPE=elasticsearch --ESHOST=localhost:9200
</code></pre>
<p>（4）启动ZipKin服务端后，在浏览器中访问链接<code>http://localhost:10001/server-order/order/submit_order?userId=1001&amp;productId=1001&amp;count=1</code>，如下所示。</p>
<figure data-type="image" tabindex="20"><img src="https://tinaxiawuhao.github.io/post-images/1658669778050.png" alt="" loading="lazy"></figure>
<p>ZipKin就会将请求的链路信息保存到ElasticSearch中进行持久化。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sleuth概述]]></title>
        <id>https://tinaxiawuhao.github.io/post/ZbHW6UCYN/</id>
        <link href="https://tinaxiawuhao.github.io/post/ZbHW6UCYN/">
        </link>
        <updated>2022-07-13T13:28:21.000Z</updated>
        <content type="html"><![CDATA[<h2 id="sleuth概述">Sleuth概述</h2>
<p>Sleuth是SpringCloud中提供的一个分布式链路追踪组件，在设计上大量参考并借用了Google Dapper的设计。</p>
<h3 id="span简介">Span简介</h3>
<p>Span在Sleuth中代表一组基本的工作单元，当请求到达各个微服务时，Sleuth会通过一个唯一的标识，也就是SpanId来标记开始通过这个微服务，在当前微服务中执行的具体过程和执行结束。</p>
<p>此时，通过SpanId标记的开始时间戳和结束时间戳，就能够统计到当前Span的调用时间，也就是当前微服务的执行时间。另外，也可以用过Span获取到事件的名称，请求的信息等数据。</p>
<p><strong>总结：远程调用和Span是一对一的关系，是分布式链路追踪中最基本的工作单元，每次发送一个远程调用服务就会产生一个 Span。Span Id 是一个 64 位的唯一 ID，通过计算 Span 的开始和结束时间，就可以统计每个服务调用所耗费的时间。</strong></p>
<h3 id="trace简介">Trace简介</h3>
<p>Trace的粒度比Span的粒度大，Trace主要是由具有一组相同的Trace ID的Span组成的，从请求进入分布式系统入口经过调用各个微服务直到返回的整个过程，都是一个Trace。</p>
<p>也就是说，当请求到达分布式系统的入口时，Sleuth会为请求创建一个唯一标识，这个唯一标识就是Trace Id，不管这个请求在分布式系统中如何流转，也不管这个请求在分布式系统中调用了多少个微服务，这个Trace Id都是不变的，直到整个请求返回。</p>
<p><strong>总结：一个 Trace 可以对应多个 Span，Trace和Span是一对多的关系。Trace Id是一个64 位的唯一ID。Trace Id可以将进入分布式系统入口经过调用各个微服务，再到返回的整个过程的请求串联起来，内部每通过一次微服务时，都会生成一个新的SpanId。Trace串联了整个请求链路，而Span在请求链路中区分了每个微服务。</strong></p>
<h3 id="annotation简介">Annotation简介</h3>
<p>Annotation记录了一段时间内的事件，内部使用的重要注解如下所示。</p>
<ul>
<li>cs（Client Send）客户端发出请求，标记整个请求的开始时间。</li>
<li>sr（Server Received）服务端收到请求开始进行处理，通过sr与cs可以计算网络的延迟时间，例如：sr－ cs = 网络延迟（服务调用的时间）。</li>
<li>ss（Server Send）服务端处理完毕准备将结果返回给客户端， 通过ss与sr可以计算服务器上的请求处理时间，例如：ss - sr = 服务器上的请求处理时间。</li>
<li>cr（Client Reveived）客户端收到服务端的响应，请求结束。通过cr与cs可以计算请求的总时间，例如：cr - cs = 请求的总时间。</li>
</ul>
<p><strong>总结：链路追踪系统内部定义了少量核心注解，用来定义一个请求的开始和结束，通过这些注解，我们可以计算出请求的每个阶段的时间。需要注解的是，这里说的请求，是在系统内部流转的请求，而不是从浏览器、APP、H5、小程序等发出的请求。</strong></p>
<h2 id="项目整合sleuth">项目整合Sleuth</h2>
<p>Sleuth提供了分布式链路追踪能力，如果需要使用Sleuth的链路追踪功能，需要在项目中集成Sleuth。</p>
<h3 id="最简使用">最简使用</h3>
<p>（1）在每个微服务（用户微服务shop-user、商品微服务shop-product、订单微服务shop-order、网关服务shop-gateway）下的pom.xml文件中添加如下Sleuth的依赖。</p>
<pre><code class="language-java">&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-sleuth&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<p>（2）将项目的application.yml文件备份成application-pre-filter.yml，并将application.yml文件的内容替换为application-sentinel.yml文件的内容，这一步是为了让整个项目集成Sentinel、SpringCloud Gateway和Nacos。application.yml替换后的文件内容如下所示。</p>
<pre><code class="language-java">server:
  port: 10002
spring:
  application:
    name: server-gateway
  cloud:
    nacos:
      discovery:
        server-addr: 127.0.0.1:8848
    sentinel:
      transport:
        port: 7777
        dashboard: 127.0.0.1:8888
      web-context-unify: false
      eager: true

    gateway:
      globalcors:
        cors-configurations:
          '[/**]':
            allowedOrigins: &quot;*&quot;
            allowedMethods: &quot;*&quot;
            allowCredentials: true
            allowedHeaders: &quot;*&quot;
      discovery:
        locator:
          enabled: true
          route-id-prefix: gateway-
</code></pre>
<p>（3）分别启动Nacos、Sentinel、用户微服务shop-user，商品微服务shop-product，订单微服务shop-order和网关服务shop-gateway，在浏览器中输入链接<code>localhost:10001/server-order/order/submit_order?userId=1001&amp;productId=1001&amp;count=1</code>，如下所示。</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1658669367689.png" alt="" loading="lazy"></figure>
<p>（4）分别查看用户微服务shop-user，商品微服务shop-product，订单微服务shop-order和网关服务shop-gateway的控制台输出，每个服务的控制台都输出了如下格式所示的信息。</p>
<pre><code class="language-java">[微服务名称,TraceID,SpanID,是否将结果输出到第三方平台]
</code></pre>
<p>具体如下所示。</p>
<ul>
<li>用户微服务shop-user</li>
</ul>
<pre><code class="language-java">[server-user,03fef3d312450828,76b298dba54ec579,true]
</code></pre>
<ul>
<li>商品微服务shop-product</li>
</ul>
<pre><code class="language-java">[server-product,03fef3d312450828,41ac8836d2df4eec,true]
[server-product,03fef3d312450828,6b7b3662d63372bf,true]
</code></pre>
<ul>
<li>订单微服务shop-order</li>
</ul>
<pre><code class="language-java">[server-order,03fef3d312450828,cbd935d57cae84f9,true]
</code></pre>
<ul>
<li>网关服务shop-gateway</li>
</ul>
<pre><code class="language-java">[server-gateway,03fef3d312450828,03fef3d312450828,true]
</code></pre>
<p>可以看到，每个服务都打印出了链路追踪的日志信息，说明引入Sleuth的依赖后，就可以在命令行查看链路追踪情况。</p>
<h3 id="抽样采集数据">抽样采集数据</h3>
<p>Sleuth支持抽样采集数据。尤其是在高并发场景下，如果采集所有的数据，那么采集的数据量就太大了，非常耗费系统的性能。通常的做法是可以减少一部分数据量，特别是对于采用Http方式去发送采集数据，能够提升很大的性能。</p>
<p>Sleuth可以采用如下方式配置抽样采集数据。</p>
<pre><code class="language-java">spring:
  sleuth:
    sampler:
      probability: 1.0
</code></pre>
<h3 id="追踪自定义线程池">追踪自定义线程池</h3>
<p>Sleuth支持对异步任务的链路追踪，在项目中使用@Async注解开启一个异步任务后，Sleuth会为异步任务重新生成一个Span。但是如果使用了自定义的异步任务线程池，则会导致Sleuth无法新创建一个Span，而是会重新生成Trace和Span。此时，需要使用Sleuth提供的LazyTraceExecutor类来包装下异步任务线程池，才能在异步任务调用链路中重新创建Span。</p>
<p>在服务中开启异步线程池任务，需要使用@EnableAsync。所以，在演示示例前，先在用户微服务shop-user的<code>io.binghe.shop.UserStarter</code>启动类上添加@EnableAsync注解，如下所示。</p>
<pre><code class="language-java">/**
 * @author binghe
 * @version 1.0.0
 * @description 启动用户服的类
 */
@SpringBootApplication
@EnableTransactionManagement(proxyTargetClass = true)
@MapperScan(value = { &quot;io.binghe.shop.user.mapper&quot; })
@EnableDiscoveryClient
@EnableAsync
public class UserStarter {
    public static void main(String[] args){
        SpringApplication.run(UserStarter.class, args);
    }
}
</code></pre>
<h4 id="演示使用async注解开启任务">演示使用@Async注解开启任务</h4>
<p>（1）在用户微服务shop-user的<code>io.binghe.shop.user.service.UserService</code>接口中定义一个asyncMethod()方法，如下所示。</p>
<pre><code class="language-java">void asyncMethod();
</code></pre>
<p>（2）在用户微服务shop-user的<code>io.binghe.shop.user.service.impl.UserServiceImpl</code>类中实现asyncMethod()方法，并在asyncMethod()方法上添加@Async注解，如下所示。</p>
<pre><code class="language-java">@Async
@Override
public void asyncMethod() {
    log.info(&quot;执行了异步任务...&quot;);
}
</code></pre>
<p>（3）在用户微服务shop-user的<code>io.binghe.shop.user.controller.UserController</code>类中新增asyncApi()方法，如下所示。</p>
<pre><code class="language-java">@GetMapping(value = &quot;/async/api&quot;)
public String asyncApi() {
    log.info(&quot;执行异步任务开始...&quot;);
    userService.asyncMethod();
    log.info(&quot;异步任务执行结束...&quot;);
    return &quot;asyncApi&quot;;
}
</code></pre>
<p>（4）分别启动用户微服务和网关服务，在浏览器中输入链接<code>http://localhost:10001/server-user/user/async/api</code></p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1658669494937.png" alt="" loading="lazy"></figure>
<p>（5）查看用户微服务与网关服务的控制台日志，分别存在如下日志。</p>
<ul>
<li>用户微服务</li>
</ul>
<pre><code class="language-java">[server-user,499d6c7128399ed0,a81bd920de0b07de,true]执行异步任务开始...
[server-user,499d6c7128399ed0,a81bd920de0b07de,true]异步任务执行结束...
[server-user,499d6c7128399ed0,e2f297d512f40bb8,true]执行了异步任务...
</code></pre>
<ul>
<li>网关服务</li>
</ul>
<pre><code class="language-java">[server-gateway,499d6c7128399ed0,499d6c7128399ed0,true]
</code></pre>
<p>可以看到Sleuth为异步任务重新生成了Span。</p>
<h4 id="演示自定义任务线程池">演示自定义任务线程池</h4>
<p>在演示使用@Async注解开启任务的基础上继续演示自定义任务线程池，验证Sleuth是否为自定义线程池新创建了Span。</p>
<p>（1）在用户微服务shop-user中新建<code>io.binghe.shop.user.config</code>包，在包下创建ThreadPoolTaskExecutorConfig类，继承<code>org.springframework.scheduling.annotation.AsyncConfigurerSupport</code>类，用来自定义异步任务线程池，代码如下所示。</p>
<pre><code class="language-java">/**
 * @author binghe
 * @version 1.0.0
 * @description Sleuth异步线程池配置
 */
@Configuration
@EnableAutoConfiguration
public class ThreadPoolTaskExecutorConfig extends AsyncConfigurerSupport {

    @Override
    public Executor getAsyncExecutor() {
        ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();
        executor.setCorePoolSize(2);
        executor.setMaxPoolSize(5);
        executor.setQueueCapacity(10);
        executor.setThreadNamePrefix(&quot;trace-thread-&quot;);
        executor.initialize();
        return executor;
    }
}
</code></pre>
<p>（2）以debug的形式启动用户微服务和网关服务，并在<code>io.binghe.shop.user.config.ThreadPoolTaskExecutorConfig#getAsyncExecutor()</code>方法中打上断点，如下所示。</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1658669396054.png" alt="" loading="lazy"></figure>
<p>可以看到，项目启动后并没有进入<code>io.binghe.shop.user.config.ThreadPoolTaskExecutorConfig#getAsyncExecutor()</code>方法，说明项目启动时，并不会创建异步任务线程池。</p>
<p>（3）在浏览器中输入链接<code>http://localhost:10001/server-user/user/async/api</code>，此时可以看到程序已经执行到<code>io.binghe.shop.user.config.ThreadPoolTaskExecutorConfig#getAsyncExecutor()</code>方法的断点位置。</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1658669404005.png" alt="" loading="lazy"></figure>
<p>说明异步任务线程池是在调用了异步任务的时候创建的。</p>
<p>接下来，按F8跳过断点继续运行程序，可以看到浏览器上的显示结果如下。</p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1658669411575.png" alt="" loading="lazy"></figure>
<p>（4）查看用户微服务与网关服务的控制台日志，分别存在如下日志。</p>
<ul>
<li>用户微服务</li>
</ul>
<pre><code class="language-java">[server-user,f89f2355ec3f9df1,4d679555674e96a4,true]执行异步任务开始...
[server-user,f89f2355ec3f9df1,4d679555674e96a4,true]异步任务执行结束...
[server-user,0ee48d47e58e2a42,0ee48d47e58e2a42,true]执行了异步任务...
</code></pre>
<ul>
<li>网关服务</li>
</ul>
<pre><code class="language-java">[server-gateway,f89f2355ec3f9df1,f89f2355ec3f9df1,true]
</code></pre>
<p>可以看到，使用自定义异步任务线程池时，在用户微服务中在执行异步任务时，重新生成了Trace和Span。</p>
<p><strong>注意对比用户微服务中输出的三条日志信息，最后一条日志信息的TraceID和SpanID与前两条日志都不同。</strong></p>
<h4 id="演示包装自定义线程池">演示包装自定义线程池</h4>
<p>在自定义任务线程池的基础上继续演示包装自定义线程池，验证Sleuth是否为包装后的自定义线程池新创建了Span。</p>
<p>（1）在用户微服务shop-user的<code>io.binghe.shop.user.config.ThreadPoolTaskExecutorConfig</code>类中注入BeanFactory，并在getAsyncExecutor()方法中使用<code>org.springframework.cloud.sleuth.instrument.async.LazyTraceExecutor()</code>来包装返回的异步任务线程池，修改后的<code>io.binghe.shop.user.config.ThreadPoolTaskExecutorConfig</code>类的代码如下所示。</p>
<pre><code class="language-java">/**
 * @author binghe
 * @version 1.0.0
 * @description Sleuth异步线程池配置
 */
@Configuration
@EnableAutoConfiguration
public class ThreadPoolTaskExecutorConfig extends AsyncConfigurerSupport {

    @Autowired
    private BeanFactory beanFactory;

    @Override
    public Executor getAsyncExecutor() {
        ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();
        executor.setCorePoolSize(2);
        executor.setMaxPoolSize(5);
        executor.setQueueCapacity(10);
        executor.setThreadNamePrefix(&quot;trace-thread-&quot;);
        executor.initialize();
        return new LazyTraceExecutor(this.beanFactory, executor);
    }
}
</code></pre>
<p>（2）分别启动用户微服务和网关服务，在浏览器中输入链接<code>http://localhost:10001/server-user/user/async/api</code></p>
<p><img src="https://tinaxiawuhao.github.io/post-images/1658669421269.png" alt="" loading="lazy"><br>
（3）查看用户微服务与网关服务的控制台日志，分别存在如下日志。</p>
<ul>
<li>用户微服务</li>
</ul>
<pre><code class="language-java">[server-user,157891cb90fddb65,0a278842776b1f01,true]执行异步任务开始...
[server-user,157891cb90fddb65,0a278842776b1f01,true]异步任务执行结束...
[server-user,157891cb90fddb65,1ba55fd3432b77ae,true]执行了异步任务...
</code></pre>
<ul>
<li>网关服务</li>
</ul>
<pre><code class="language-java">[server-gateway,157891cb90fddb65,157891cb90fddb65,true]
</code></pre>
<p>可以看到Sleuth为异步任务重新生成了Span。</p>
<p><strong>综上说明：Sleuth支持对异步任务的链路追踪，在项目中使用@Async注解开启一个异步任务后，Sleuth会为异步任务重新生成一个Span。但是如果使用了自定义的异步任务线程池，则会导致Sleuth无法新创建一个Span，而是会重新生成Trace和Span。此时，需要使用Sleuth提供的LazyTraceExecutor类来包装下异步任务线程池，才能在异步任务调用链路中重新创建Span。</strong></p>
<h3 id="自定义链路过滤器">自定义链路过滤器</h3>
<p>在Sleuth中存在链路过滤器，并且还支持自定义链路过滤器。</p>
<h4 id="自定义链路过滤器概述">自定义链路过滤器概述</h4>
<p>TracingFilter是Sleuth中负责处理请求和响应的组件，可以通过注册自定义的TracingFilter实例来实现一些扩展性的需求。</p>
<h4 id="演示自定义链路过滤器">演示自定义链路过滤器</h4>
<p>本案例演示通过过滤器验证只有HTTP或者HTTPS请求才能访问接口，并且在访问的链接不是静态文件时，将traceId放入HttpRequest中在服务端获取，并在响应结果中添加自定义Header，名称为SLEUTH-HEADER，值为traceId。</p>
<p>（1）在用户微服务shop-user中新建<code>io.binghe.shop.user.filter</code>包，并创建MyGenericFilter类，继承<code>org.springframework.web.filter.GenericFilterBean</code>类，代码如下所示。</p>
<pre><code class="language-java">/**
 * @author binghe
 * @version 1.0.0
 * @description 链路过滤器
 */
@Component
@Order( Ordered.HIGHEST_PRECEDENCE + 6)
public class MyGenericFilter extends GenericFilterBean{

    private Pattern skipPattern = Pattern.compile(SleuthWebProperties.DEFAULT_SKIP_PATTERN);

    private final Tracer tracer;
    public MyGenericFilter(Tracer tracer){
        this.tracer = tracer;
    }

    @Override
    public void doFilter(ServletRequest request, ServletResponse response,
                         FilterChain chain) throws IOException, ServletException {

        if (!(request instanceof HttpServletRequest) || !(response instanceof HttpServletResponse)){
            throw new ServletException(&quot;只支持HTTP访问&quot;);
        }
        Span currentSpan = this.tracer.currentSpan();
        if (currentSpan == null) {
            chain.doFilter(request, response);
            return;
        }
        HttpServletRequest httpServletRequest = (HttpServletRequest) request;
        HttpServletResponse httpServletResponse = ((HttpServletResponse) response);
        boolean skipFlag = skipPattern.matcher(httpServletRequest.getRequestURI()).matches();
        if (!skipFlag){
            String traceId = currentSpan.context().traceIdString();
            httpServletRequest.setAttribute(&quot;traceId&quot;, traceId);
            httpServletResponse.addHeader(&quot;SLEUTH-HEADER&quot;, traceId);
        }
        chain.doFilter(httpServletRequest, httpServletResponse);
    }
}
</code></pre>
<p>（2）在用户微服务shop-user的<code>io.binghe.shop.user.controller.UserController</code>类中新建sleuthFilter()方法，在sleuthFilter()方法中获取并打印traceId，如下所示。</p>
<pre><code class="language-java">@GetMapping(value = &quot;/sleuth/filter/api&quot;)
public String sleuthFilter(HttpServletRequest request) {
    Object traceIdObj = request.getAttribute(&quot;traceId&quot;);
    String traceId = traceIdObj == null ? &quot;&quot; : traceIdObj.toString();
    log.info(&quot;获取到的traceId为: &quot; + traceId);
    return &quot;sleuthFilter&quot;;
}
</code></pre>
<p>（3）分别启动用户微服务和网关服务，在浏览器中输入<code>http://localhost:10001/server-user/user/sleuth/filter/api</code>，如下所示。</p>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1658669436388.png" alt="" loading="lazy"></figure>
<p>查看用户微服务的控制台会输出如下信息。</p>
<pre><code class="language-java">获取到的traceId为: f63ae7702f6f4bba
</code></pre>
<p>查看浏览器的控制台，看到在响应的结果信息中新增了一个名称为SLEUTH-HEADER，值为f63ae7702f6f4bba的Header，如下所示。</p>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1658669443121.png" alt="" loading="lazy"></figure>
<p>说明使用Sleuth的过滤器可以处理请求和响应信息，并且可以在Sleuth的过滤器中获取到TraceID。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[分布式链路追踪]]></title>
        <id>https://tinaxiawuhao.github.io/post/Lq63Gr95h/</id>
        <link href="https://tinaxiawuhao.github.io/post/Lq63Gr95h/">
        </link>
        <updated>2022-07-12T13:27:12.000Z</updated>
        <content type="html"><![CDATA[<p>随着互联网的不断发展，企业的业务系统变得越来越复杂，原本单一的单体应用系统已经无法满足企业业务发展的需要。于是，很多企业开始了对项目的分布式与微服务改造，新项目也在开始的时候就会采用分布式与微服务的架构模式。</p>
<p>一个系统采用分布式与微服务架构后，会被拆分成许多服务模块，这些服务模块之间的调用关系错综复杂，对于客户端请求的分析与处理就会显得异常复杂。此时，就需要一种技术来解决这些问题，而这种技术就是分布式链路追踪技术。</p>
<h2 id="分布式链路追踪">分布式链路追踪</h2>
<p>随着互联网业务快速扩展，企业的业务系统变得越来越复杂，不少企业开始向分布式、微服务方向发展，将原本的单体应用拆分成分布式、微服务。这也使得当客户端请求系统的接口时，原本在同一个系统内部的请求逻辑变成了需要在多个微服务之间流转的请求。</p>
<p>单体架构中可以使用AOP在调用具体的业务逻辑前后分别打印一下时间即可计算出整体的调用时间，使用 AOP捕获异常也可知道是哪里的调用导致的异常。</p>
<p>但是在分布式微服务场景下，使用AOP技术是无法追踪到各个微服务的调用情况的，也就无法知道系统中处理一次请求的整体调用链路。</p>
<p>另外，在分布式与微服务场景下，我们需要解决如下问题：</p>
<ul>
<li>如何快速发现并定位到分布式系统中的问题。</li>
<li>如何尽可能精确的判断故障对系统的影响范围与影响程度。</li>
<li>如何尽可能精确的梳理出服务之间的依赖关系，并判断出服务之间的依赖关系是否合理。</li>
<li>如何尽可能精确的分析整个系统调用链路的性能与瓶颈点。</li>
<li>如何尽可能精确的分析系统的存储瓶颈与容量规划。</li>
<li>如何实时观测系统的整体调用链路情况。</li>
</ul>
<p>上述问题就是分布式链路追踪技术要解决的问题。所谓的分布式链路追踪，就是将对分布式系统的一次请求转化成一个完整的调用链路。这个完整的调用链路从请求进入分布式系统的入口开始，直到整个请求返回为止。并在请求调用微服务的过程中，记录相应的调用日志，监控系统调用的性能，并且可以按照某种方式显示请求调用的情况。</p>
<p>在分布式链路追踪中，可以统计调用每个微服务的耗时，请求会经过哪些微服务的流转，每个微服务的运行状况等信息。</p>
<h2 id="核心原理">核心原理</h2>
<p>假定三个微服务调用的链路如下图所示：Service 1 调用 Service 2，Service 2 调用 Service 3 和 Service 4。</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1658669279892.png" alt="" loading="lazy"></figure>
<p>那么链路追踪会在每个服务调用的时候加上 Trace ID 和 Span ID。如下图所示：</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1658669287303.png" alt="" loading="lazy"></figure>
<p>小伙伴注意上面的颜色，相同颜色的代表是同一个 Span ID，说明是链路追踪中的一个节点。</p>
<ul>
<li>第一步：用户端调用 Service 1，生成一个 Request，Trace ID 和 Span ID 为空，那个时候请求还没有到 Service 1。</li>
<li>第二步：请求到达 Service 1，记录了 Trace ID = X，Span ID 等于 A。</li>
<li>第三步：Service 1 发送请求给 Service 2，Span ID 等于 B，被称作 Client Sent，即用户端发送一个请求。</li>
<li>第四步：请求到达 Service 2，Span ID 等于 B，Trace ID 不会改变，被称作 Server Received，即服务端取得请求并准备开始解决它。</li>
<li>第五步：Service 2 开始解决这个请求，解决完之后，Trace ID 不变，Span ID = C。</li>
<li>第六步：Service 2 开始发送这个请求给 Service 3，Trace ID 不变，Span ID = D，被称作 Client Sent，即用户端发送一个请求。</li>
<li>第七步：Service 3 接收到这个请求，Span ID = D，被称作 Server Received。</li>
<li>第八步：Service 3 开始解决这个请求，解决完之后，Span ID = E。</li>
<li>第九步：Service 3 开始发送响应给 Service 2，Span ID = D，被称作 Server Sent，即服务端发送响应。</li>
<li>第十步：Service 3 收到 Service 2 的响应，Span ID = D，被称作 Client Received，即用户端接收响应。</li>
<li>第十一步：Service 2 开始返回 响应给 Service 1，Span ID = B，和第三步的 Span ID 相同，被称作 Client Received，即用户端接收响应。</li>
<li>第十二步：Service 1 解决完响应，Span ID = A，和第二步的 Span ID 相同。</li>
<li>第十三步：Service 1 开始向用户端返回响应，Span ID = A、</li>
<li>Service 3 向 Service 4 发送请求和 Service 3 相似，对应的 Span ID 是 F 和 G。可以参照上面前面的第六步到第十步。</li>
</ul>
<p><strong>把以上的相同颜色的步骤简化为下面的链路追踪图：</strong></p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1658669296206.png" alt="" loading="lazy"></figure>
<ul>
<li>第一个节点：Span ID = A，Parent ID = null，Service 1 接收到请求。</li>
<li>第二个节点：Span ID = B，Parent ID= A，Service 1 发送请求到 Service 2 返回响应给Service 1 的过程。</li>
<li>第三个节点：Span ID = C，Parent ID= B，Service 2 的 中间解决过程。</li>
<li>第四个节点：Span ID = D，Parent ID= C，Service 2 发送请求到 Service 3 返回响应给Service 2 的过程。</li>
<li>第五个节点：Span ID = E，Parent ID= D，Service 3 的中间解决过程。</li>
<li>第六个节点：Span ID = F，Parent ID= C，Service 3 发送请求到 Service 4 返回响应给 Service 3 的过程。</li>
<li>第七个节点：Span ID = G，Parent ID= F，Service 4 的中间解决过程。</li>
</ul>
<p>通过 Parent ID 就可找到父节点，整个链路即可以进行跟踪追溯了。</p>
<p>备注：核心原理部分内容来源：cnblogs.com/jackson0714/p/sleuth_zipkin.html</p>
<h2 id="解决方案">解决方案</h2>
<p>目前，行业内比较成熟的分布式链路追踪技术解决方案如下所示。</p>
<table>
<thead>
<tr>
<th style="text-align:left">技术</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Cat</td>
<td style="text-align:left">由大众点评开源，基于Java开发的实时应用监控平台，包括实时应用监控，业务监控 。集成方案是通过代码埋点的方式来实现监控，比如：拦截器，过滤器等。对代码的侵入性很大，集成成本较高。风险较大。</td>
</tr>
<tr>
<td style="text-align:left">ZipKin</td>
<td style="text-align:left">由Twitter公司开源，开放源代码分布式的跟踪系统，用于收集服务的定时数据，以解决微服务架构中的延迟问题，包括：数据的收集、存储、查找和展现。结合spring-cloud-sleuth使用较为简单， 集成方便， 但是功能较简单。</td>
</tr>
<tr>
<td style="text-align:left">Pinpoint</td>
<td style="text-align:left">Pinpoint是一款开源的基于字节码注入的调用链分析，以及应用监控分析工具。特点是支持多种插件， UI功能强大，接入端无代码侵入。</td>
</tr>
<tr>
<td style="text-align:left">Skywalking</td>
<td style="text-align:left">SkyWalking是国人开源的基于字节码注入的调用链分析，以及应用监控分析工具。特点是支持多种插件， UI功能较强，接入端无代码侵入。</td>
</tr>
<tr>
<td style="text-align:left">Sleuth</td>
<td style="text-align:left">Sleuth是SpringCloud中的一个组件，为Spring Cloud实现了分布式跟踪解决方案。</td>
</tr>
</tbody>
</table>
<p><strong>注意：我们后续会使用 Sleuth+ZipKin的方案实现分布式链路追踪。</strong></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[网关断言]]></title>
        <id>https://tinaxiawuhao.github.io/post/ipsD-XbrM/</id>
        <link href="https://tinaxiawuhao.github.io/post/ipsD-XbrM/">
        </link>
        <updated>2022-07-11T13:21:48.000Z</updated>
        <content type="html"><![CDATA[<h2 id="网关断言">网关断言</h2>
<p>断言的英文是Predicate，也可以翻译成谓词。主要的作用就是进行条件判断，可以在网关中实现多种条件判断，只有所有的判断结果都通过时，也就是所有的条件判断都返回true，才会真正的执行路由功能。</p>
<h3 id="springcloud-gateway内置断言">SpringCloud Gateway内置断言</h3>
<p>SpringCloud Gateway包括许多内置的断言工厂，所有这些断言都与HTTP请求的不同属性匹配。</p>
<h4 id="基于日期时间类型的断言">基于日期时间类型的断言</h4>
<p>基于日期时间类型的断言根据时间做判断，主要有三个：</p>
<ul>
<li>AfterRoutePredicateFactory：接收一个日期时间参数，判断当前请求的日期时间是否晚于指定的日期时间。</li>
<li>BeforeRoutePredicateFactory：接收一个日期时间参数，判断当前请求的日期时间是否早于指定的日期时间。</li>
<li>BetweenRoutePredicateFactory：接收两个日期时间参数，判断当前请求的日期时间是否在指定的时间时间段内。</li>
</ul>
<h4 id="使用示例">使用示例</h4>
<pre><code class="language-java">- After=2022-05-10T23:59:59.256+08:00[Asia/Shanghai]
</code></pre>
<h4 id="基于远程地址的断言">基于远程地址的断言</h4>
<p>RemoteAddrRoutePredicateFactory：接收一个IP地址段，判断发出请求的客户端的IP地址是否在指定的IP地址段内。</p>
<h4 id="使用示例-2">使用示例</h4>
<pre><code class="language-java">- RemoteAddr=192.168.0.1/24
</code></pre>
<h4 id="基于cookie的断言">基于Cookie的断言</h4>
<p>CookieRoutePredicateFactory：接收两个参数， Cookie的名称和一个正则表达式。判断请求的Cookie是否具有给定名称且值与正则表达式匹配。</p>
<h4 id="使用示例-3">使用示例</h4>
<pre><code class="language-java">- Cookie=name, binghe.
</code></pre>
<h4 id="基于header的断言">基于Header的断言</h4>
<p>HeaderRoutePredicateFactory：接收两个参数，请求Header的名称和正则表达式。判断请求Header中是否具有给定的名称且值与正则表达式匹配。</p>
<h4 id="使用示例-4">使用示例</h4>
<pre><code class="language-java">- Header=X-Request-Id, \d+
</code></pre>
<h4 id="基于host的断言">基于Host的断言</h4>
<p>HostRoutePredicateFactory：接收一个参数，这个参数通常是主机名或者域名的模式，例如<code>**.binghe.com</code>这种格式。判断发出请求的主机是否满足匹配规则。</p>
<h4 id="使用示例-5">使用示例</h4>
<pre><code class="language-java">- Host=**.binghe.com
</code></pre>
<h4 id="基于method请求方法的断言">基于Method请求方法的断言</h4>
<p>MethodRoutePredicateFactory：接收一个参数，判断请求的类型是否跟指定的类型匹配，通常指的是请求方式。例如，POST、GET、PUT等请求方式。</p>
<h4 id="使用示例-6">使用示例</h4>
<pre><code class="language-java">- Method=GET
</code></pre>
<h4 id="基于path请求路径的断言">基于Path请求路径的断言</h4>
<p>PathRoutePredicateFactory：接收一个参数，判断请求的链接地址是否满足路径规则，通常指的是请求的URI部分。</p>
<h4 id="使用示例-7">使用示例</h4>
<pre><code class="language-java">- Path=/binghe/{segment}
</code></pre>
<h4 id="基于query请求参数的断言">基于Query请求参数的断言</h4>
<p>QueryRoutePredicateFactory ：接收两个参数，请求参数和正则表达式， 判断请求的参数是否具有给定的名称并且参数值是否与正则表达式匹配。</p>
<h4 id="使用示例-8">使用示例</h4>
<pre><code class="language-java">- Query=name, binghe.
</code></pre>
<h4 id="基于路由权重的断言">基于路由权重的断言</h4>
<p>WeightRoutePredicateFactory：接收一个[组名,权重]格式的数组，然后对于同一个组内的路由按照权重转发。</p>
<h4 id="使用示例-9">使用示例</h4>
<pre><code class="language-java">- id: weight1
  uri: http://localhost:8080
  predicates:
    - Path=/api/**
    - Weight=group1,2
  filters:
    - StripPrefix=1
- id: weight2
  uri: http://localhost:8081
  predicates:
    - Path=/api/**
    - Weight=group1,8
  filters:
    - StripPrefix=1
</code></pre>
<h3 id="演示内置断言">演示内置断言</h3>
<p>在演示的示例中，我们基于Path请求路径的断言判断请求路径是否符合规则，基于远程地址的断言判断请求主机地址是否在地址段中，并且限制请求的方式为GET方式。整个演示的过程以访问用户微服务的接口为例。</p>
<p>（1）由于在开发项目时，所有的服务都是在我本地启动的，首先查看下我本机的IP地址，如下所示。</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1658668997017.png" alt="" loading="lazy"></figure>
<p>可以看到，我本机的IP地址为192.168.0.27，属于192.168.0.1/24网段。</p>
<p>（2）在服务网关模块shop-gateway中，将application.yml文件备份成application-sentinel.yml文件，并将application.yml文件中的内容修改成application-simple.yml文件中的内容。接下来，在application.yml文件中的<code>spring.cloud.gateway.routes</code>节点下的<code>- id: user-gateway</code>下面进行断言配置，配置后的结果如下所示。</p>
<pre><code class="language-java">spring:
  cloud:
    gateway:
      routes:
        - id: user-gateway
          uri: http://localhost:8060
          order: 1
          predicates:
            - Path=/server-user/**
            - RemoteAddr=192.168.0.1/24
            - Method=GET
          filters:
            - StripPrefix=1
</code></pre>
<p><strong>注意：完整的配置参见案例完整源代码。</strong></p>
<p>（3）配置完成后启动用户微服务和网关服务，通过网关服务访问用户微服务，在浏览器中输入<code>http://localhost:10001/server-user/user/get/1001</code>，如下所示。</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1658669013855.png" alt="" loading="lazy"></figure>
<p>可以看到通过<code>http://localhost:10001/server-user/user/get/1001</code>链接不能正确访问到用户信息。</p>
<p>接下来，在浏览器中输入<code>http://192.168.0.27:10001/server-user/user/get/1001</code>，能够正确获取到用户的信息。</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1658669028281.png" alt="" loading="lazy"></figure>
<p>（4）停止网关微服务，将基于远程地址的断言配置成<code>- RemoteAddr=192.168.1.1/24</code>，也就是将基于远程地址的断言配置成与我本机IP地址不在同一个网段，这样就能演示请求主机地址不在地址段中的情况，修改后的基于远程地址的断言配置如下所示。</p>
<pre><code class="language-java">- RemoteAddr=192.168.1.1/24
</code></pre>
<p>（5）重启网关服务，再次在浏览器中输入<code>http://localhost:10001/server-user/user/get/1001</code>，如下所示。</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1658669041992.png" alt="" loading="lazy"></figure>
<p>可以看到通过<code>http://localhost:10001/server-user/user/get/1001</code>链接不能正确访问到用户信息。</p>
<p>接下来，在浏览器中输入<code>http://192.168.0.27:10001/server-user/user/get/1001</code>，也不能正确获取到用户的信息了。</p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1658669056498.png" alt="" loading="lazy"></figure>
<h3 id="自定义断言">自定义断言</h3>
<p>SpringCloud Gateway支持自定义断言功能，我们可以在具体业务中，基于SpringCloud Gateway自定义特定的断言功能。</p>
<h4 id="自定义断言概述">自定义断言概述</h4>
<p>SpringCloud Gateway虽然提供了多种内置的断言功能，但是在某些场景下无法满足业务的需要，此时，我们就可以基于SpringCloud Gateway自定义断言功能，以此来满足我们的业务场景。</p>
<h4 id="实现自定义断言">实现自定义断言</h4>
<p>这里，我们基于SpringCloud Gateway实现断言功能，实现后的效果是在服务网关的application.yml文件中的<code>spring.cloud.gateway.routes</code>节点下的<code>- id: user-gateway</code>下面进行如下配置。</p>
<pre><code class="language-java">spring:
  cloud:
    gateway:
      routes:
        - id: user-gateway
          uri: http://localhost:8060
          order: 1
          predicates:
            - Path=/server-user/**
            - Name=binghe
          filters:
            - StripPrefix=1
</code></pre>
<p>通过服务网关访问用户微服务时，只有在访问的链接后面添加<code>?name=binghe</code>参数时才能正确访问用户微服务。</p>
<p>（1）在网关服务shop-gateway中新建<code>io.binghe.shop.predicate</code>包，在包下新建NameRoutePredicateConfig类，主要定义一个Spring类型的name成员变量，用来接收配置文件中的参数，源码如下所示。</p>
<pre><code class="language-java">/**
 * @author binghe
 * @version 1.0.0
 * @description 接收配置文件中的参数
 */
@Data
public class NameRoutePredicateConfig implements Serializable {
    private static final long serialVersionUID = -3289515863427972825L;
    private String name;
}
</code></pre>
<p>（2）实现自定义断言时，需要新建类继承<code>org.springframework.cloud.gateway.handler.predicate.AbstractRoutePredicateFactory</code>类，在<code>io.binghe.shop.predicate</code>包下新建NameRoutePredicateFactory类，继承<code>org.springframework.cloud.gateway.handler.predicate.AbstractRoutePredicateFactory</code>类，并覆写相关的方法，源码如下所示。</p>
<pre><code class="language-java">/**
 * @author binghe
 * @version 1.0.0
 * @description 自定义断言功能
 */
@Component
public class NameRoutePredicateFactory extends AbstractRoutePredicateFactory&lt;NameRoutePredicateConfig&gt; {

    public NameRoutePredicateFactory() {
        super(NameRoutePredicateConfig.class);
    }

    @Override
    public Predicate&lt;ServerWebExchange&gt; apply(NameRoutePredicateConfig config) {
        return (serverWebExchange)-&gt;{
            String name = serverWebExchange.getRequest().getQueryParams().getFirst(&quot;name&quot;);
            if (StringUtils.isEmpty(name)){
                name = &quot;&quot;;
            }
            return name.equals(config.getName());
        };
    }

    @Override
    public List&lt;String&gt; shortcutFieldOrder() {
        return Arrays.asList(&quot;name&quot;);
    }
}
</code></pre>
<p>（3）在服务网关的application.yml文件中的<code>spring.cloud.gateway.routes</code>节点下的<code>- id: user-gateway</code>下面进行如下配置。</p>
<pre><code class="language-java">spring:
  cloud:
    gateway:
      routes:
        - id: user-gateway
          uri: http://localhost:8060
          order: 1
          predicates:
            - Path=/server-user/**
            - Name=binghe
          filters:
            - StripPrefix=1
</code></pre>
<p>（4）分别启动用户微服务与网关服务，在浏览器中输入<code>http://localhost:10001/server-user/user/get/1001</code>，如下所示。</p>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1658669075580.png" alt="" loading="lazy"></figure>
<p>可以看到，在浏览器中输入<code>http://localhost:10001/server-user/user/get/1001</code>，无法获取到用户信息。</p>
<p>（5）在浏览器中输入<code>http://localhost:10001/server-user/user/get/1001?name=binghe</code>，如下所示。</p>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1658669099356.png" alt="" loading="lazy"></figure>
<p>可以看到，在访问链接后添加<code>?name=binghe</code>参数后，能够正确获取到用户信息。</p>
<p>至此，我们实现了自定义断言功能。</p>
<h2 id="网关过滤器">网关过滤器</h2>
<p>过滤器可以在请求过程中，修改请求的参数和响应的结果等信息。在生命周期的角度总体上可以分为前置过滤器（Pre）和后置过滤器(Post)。在实现的过滤范围角度可以分为局部过滤器（GatewayFilter）和全局过滤器（GlobalFilter）。局部过滤器作用的范围是某一个路由，全局过滤器作用的范围是全部路由。</p>
<ul>
<li>Pre前置过滤器：在请求被网关路由之前调用，可以利用这种过滤器实现认证、鉴权、路由等功能，也可以记录访问时间等信息。</li>
<li>Post后置过滤器：在请求被网关路由到微服务之后执行。可以利用这种过滤器修改HTTP的响应Header信息，修改返回的结果数据（例如对于一些敏感的数据，可以在此过滤器中统一处理后返回），收集一些统计信息等。</li>
<li>局部过滤器（GatewayFilter）：也可以称为网关过滤器，这种过滤器主要是作用于单一路由或者某个路由分组。</li>
<li>全局过滤器（GlobalFilter）：这种过滤器主要作用于所有的路由。</li>
</ul>
<h3 id="局部过滤器">局部过滤器</h3>
<p>局部过滤器又称为网关过滤器，这种过滤器主要是作用于单一路由或者某个路由分组。</p>
<h4 id="局部过滤器概述">局部过滤器概述</h4>
<p>在SpringCloud Gateway中内置了很多不同类型的局部过滤器，主要如下所示。</p>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1658669111264.png" alt="" loading="lazy"></figure>
<h4 id="演示内部过滤器">演示内部过滤器</h4>
<p>演示内部过滤器时，我们为原始请求添加一个名称为IP的Header，值为localhost，并添加一个名称为name的参数，参数值为binghe。同时修改响应的结果状态，将结果状态修改为1001。</p>
<p>（1）在服务网关的application.yml文件中的<code>spring.cloud.gateway.routes</code>节点下的<code>- id: user-gateway</code>下面进行如下配置。</p>
<pre><code class="language-java">spring:
  cloud:
    gateway:
      routes:
        - id: user-gateway
          uri: http://localhost:8060
          order: 1
          predicates:
            - Path=/server-user/**
          filters:
            - StripPrefix=1
            - AddRequestHeader=IP,localhost
            - AddRequestParameter=name,binghe
            - SetStatus=1001
</code></pre>
<p>（2）在用户微服务的<code>io.binghe.shop.user.controller.UserController</code>类中新增apiFilter1()方法，如下所示。</p>
<pre><code class="language-java">@GetMapping(value = &quot;/api/filter1&quot;)
public String apiFilter1(HttpServletRequest request, HttpServletResponse response){
    log.info(&quot;访问了apiFilter1接口&quot;);
    String ip = request.getHeader(&quot;IP&quot;);
    String name = request.getParameter(&quot;name&quot;);
    log.info(&quot;ip = &quot; + ip + &quot;, name = &quot; + name);
    return &quot;apiFilter1&quot;;
}
</code></pre>
<p>可以看到，在新增加的apiFilter1()方法中，获取到新增加的Header与参数，并将获取出来的参数与Header打印出来。并且方法返回的是字符串apiFilter1。</p>
<p>（3）分别启动用户微服务与网关服务，在浏览器中输入<code>http://localhost:10001/server-user/user/api/filter1</code>，如下所示。</p>
<figure data-type="image" tabindex="9"><img src="https://tinaxiawuhao.github.io/post-images/1658669123448.png" alt="" loading="lazy"></figure>
<p>此时，查看浏览器中的响应状态码，如下所示。</p>
<figure data-type="image" tabindex="10"><img src="https://tinaxiawuhao.github.io/post-images/1658669132840.png" alt="" loading="lazy"></figure>
<p>可以看到，此时的状态码已经被修改为1001。</p>
<p>接下来，查看下用户微服务的控制台输出的信息，发现在输出的信息中存在如下数据。</p>
<pre><code class="language-java">访问了apiFilter1接口
ip = localhost, name = binghe
</code></pre>
<p>说明使用SpringCloud Gateway的内置过滤器成功为原始请求添加了一个名称为IP的Header，值为localhost，并添加了一个名称为name的参数，参数值为binghe。同时修改了响应的结果状态，将结果状态修改为1001，符合预期效果。</p>
<h4 id="自定义局部过滤器">自定义局部过滤器</h4>
<p>这里，我们基于SpringCloud Gateway自定义局部过滤器实现是否开启灰度发布的功能，整个实现过程如下所示。</p>
<p>（1）在服务网关的application.yml文件中的<code>spring.cloud.gateway.routes</code>节点下的<code>- id: user-gateway</code>下面进行如下配置。</p>
<pre><code class="language-java">spring:
  cloud:
    gateway:
      routes:
        - id: user-gateway
          uri: http://localhost:8060
          order: 1
          predicates:
            - Path=/server-user/**
          filters:
            - StripPrefix=1
            - Grayscale=true
</code></pre>
<p>（2）在网关服务模块shop-gateway中新建<code>io.binghe.shop.filter</code>包，在包下新建GrayscaleGatewayFilterConfig类，用于接收配置中的参数，如下所示。</p>
<pre><code class="language-java">/**
 * @author binghe
 * @version 1.0.0
 * @description 接收配置参数
 */
@Data
public class GrayscaleGatewayFilterConfig implements Serializable {
    private static final long serialVersionUID = 983019309000445082L;
    private boolean grayscale;
}
</code></pre>
<p>（3）在<code>io.binghe.shop.filter</code>包下GrayscaleGatewayFilterFactory类，继承<code>org.springframework.cloud.gateway.filter.factory.AbstractGatewayFilterFactory</code>类，主要是实现自定义过滤器，模拟实现灰度发布。代码如下所示。</p>
<pre><code class="language-java">/**
 * @author binghe
 * @version 1.0.0
 * @description 自定义过滤器模拟实现灰度发布
 */
@Component
public class GrayscaleGatewayFilterFactory extends AbstractGatewayFilterFactory&lt;GrayscaleGatewayFilterConfig&gt; {

    public GrayscaleGatewayFilterFactory(){
        super(GrayscaleGatewayFilterConfig.class);
    }
    @Override
    public GatewayFilter apply(GrayscaleGatewayFilterConfig config) {
        return (exchange, chain) -&gt; {
            if (config.isGrayscale()){
                System.out.println(&quot;开启了灰度发布功能...&quot;);
            }else{
                System.out.println(&quot;关闭了灰度发布功能...&quot;);
            }
            return chain.filter(exchange);
        };
    }

    @Override
    public List&lt;String&gt; shortcutFieldOrder() {
        return Arrays.asList(&quot;grayscale&quot;);
    }
}
</code></pre>
<p>（4）分别启动用户微服务和服务网关，在浏览器中输入<code>http://localhost:10001/server-user/user/get/1001</code>，如下所示。</p>
<figure data-type="image" tabindex="11"><img src="https://tinaxiawuhao.github.io/post-images/1658669147257.png" alt="" loading="lazy"></figure>
<p>可以看到，通过服务网关正确访问到了用户微服务，并正确获取到了用户信息。</p>
<p>接下来，查看下服务网关的终端，发现已经成功输出了如下信息。</p>
<pre><code class="language-java">开启了灰度发布功能...
</code></pre>
<p>说明正确实现了自定义的局部过滤器。</p>
<h3 id="全局过滤器">全局过滤器</h3>
<p>全局过滤器是一系列特殊的过滤器，会根据条件应用到所有路由中。</p>
<h4 id="全局过滤器概述">全局过滤器概述</h4>
<p>在SpringCloud Gateway中内置了多种不同的全局过滤器，如下所示。</p>
<figure data-type="image" tabindex="12"><img src="https://tinaxiawuhao.github.io/post-images/1658669168091.png" alt="" loading="lazy"></figure>
<h4 id="演示全局过滤器">演示全局过滤器</h4>
<p>（1）在服务网关模块shop-gateway模块下的<code>io.binghe.shop.config</code>包下新建GatewayFilterConfig类，并在类中配置几个全局过滤器，如下所示。</p>
<pre><code class="language-java">/**
 * @author binghe
 * @version 1.0.0
 * @description 网关过滤器配置
 */
@Configuration
@Slf4j
public class GatewayFilterConfig {
    @Bean
    @Order(-1)
    public GlobalFilter globalFilter() {
        return (exchange, chain) -&gt; {
            log.info(&quot;执行前置过滤器逻辑&quot;);
            return chain.filter(exchange).then(Mono.fromRunnable(() -&gt; {
                log.info(&quot;执行后置过滤器逻辑&quot;);
            }));
        };
    }
}
</code></pre>
<p><strong>注意：@Order注解中的数字越小，执行的优先级越高。</strong></p>
<p>（2）启动用户微服务与服务网关，在浏览器中访问<code>http://localhost:10001/server-user/user/get/1001</code>，如下所示。</p>
<figure data-type="image" tabindex="13"><img src="https://tinaxiawuhao.github.io/post-images/1658669177407.png" alt="" loading="lazy"></figure>
<p>在服务网关终端输出如下信息。</p>
<pre><code class="language-java">执行前置过滤器逻辑
执行后置过滤器逻辑
</code></pre>
<p>说明我们演示的全局过滤器生效了。</p>
<h4 id="自定义全局过滤器">自定义全局过滤器</h4>
<p>SpringCloud Gateway内置了很多全局过滤器，一般情况下能够满足实际开发需要，但是对于某些特殊的业务场景，还是需要我们自己实现自定义全局过滤器。</p>
<p>这里，我们就模拟实现一个获取客户端访问信息，并统计访问接口时长的全局过滤器。</p>
<p>（1）在网关服务模块shop-order的<code>io.binghe.shop.filter</code>包下，新建GlobalGatewayLogFilter类，实现<code>org.springframework.cloud.gateway.filter.GlobalFilter</code>接口和<code>org.springframework.core.Ordered</code>接口，代码如下所示。</p>
<pre><code class="language-java">/**
 * @author binghe
 * @version 1.0.0
 * @description 自定义全局过滤器，模拟实现获取客户端信息并统计接口访问时长
 */
@Slf4j
@Component
public class GlobalGatewayLogFilter implements GlobalFilter, Ordered {
    /**
     * 开始访问时间
     */
    private static final String BEGIN_VISIT_TIME = &quot;begin_visit_time&quot;;

    @Override
    public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) {
        //先记录下访问接口的开始时间
        exchange.getAttributes().put(BEGIN_VISIT_TIME, System.currentTimeMillis());
        return chain.filter(exchange).then(Mono.fromRunnable(()-&gt;{
            Long beginVisitTime = exchange.getAttribute(BEGIN_VISIT_TIME);
            if (beginVisitTime != null){
                log.info(&quot;访问接口主机: &quot; + exchange.getRequest().getURI().getHost());
                log.info(&quot;访问接口端口: &quot; + exchange.getRequest().getURI().getPort());
                log.info(&quot;访问接口URL: &quot; + exchange.getRequest().getURI().getPath());
                log.info(&quot;访问接口URL参数: &quot; + exchange.getRequest().getURI().getRawQuery());
                log.info(&quot;访问接口时长: &quot; + (System.currentTimeMillis() - beginVisitTime) + &quot;ms&quot;);
            }
        }));
    }

    @Override
    public int getOrder() {
        return 0;
    }
}
</code></pre>
<p>上述代码的实现逻辑还是比较简单的，这里就不再赘述了。</p>
<p>（2）启动用户微服务与网关服务，在浏览器中输入<code>http://localhost:10001/server-user/user/api/filter1?name=binghe</code>，如下所示。</p>
<figure data-type="image" tabindex="14"><img src="https://tinaxiawuhao.github.io/post-images/1658669189664.png" alt="" loading="lazy"></figure>
<p>接下来，查看服务网关的终端日志，可以发现已经输出了如下信息。</p>
<pre><code class="language-java">访问接口主机: localhost
访问接口端口: 10001
访问接口URL: /server-user/user/api/filter1
访问接口URL参数: name=binghe
访问接口时长: 126ms
</code></pre>
<p>说明我们自定义的全局过滤器生效了。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[gateway项目整合网关]]></title>
        <id>https://tinaxiawuhao.github.io/post/PN2nvPeue/</id>
        <link href="https://tinaxiawuhao.github.io/post/PN2nvPeue/">
        </link>
        <updated>2022-07-10T13:10:47.000Z</updated>
        <content type="html"><![CDATA[<h2 id="项目整合网关">项目整合网关</h2>
<p>我们需要在项目中增加一个服务网关模块shop-gateway，在服务网关模块中实现网关的能力。此时，我们的项目中就会有用户微服务、商品微服务、订单微服务和服务网关。</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1658668356973.png" alt="" loading="lazy"></figure>
<h3 id="新建网关模块">新建网关模块</h3>
<p>在项目中新建shop-gateway模块，新增网关模块后项目的结构如下图所示。</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1658668389660.png" alt="" loading="lazy"></figure>
<h3 id="初步整合springcloud-gateway">初步整合SpringCloud Gateway</h3>
<p>（1）在服务网关shop-gateway模块的pom.xml文件中添加如下依赖。</p>
<pre><code class="language-java">&lt;dependencies&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
        &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;
    &lt;/dependency&gt;
&lt;/dependencies&gt;
</code></pre>
<p>（2）在服务网关shop-gateway模块的resources目录下新建application.yml文件，并在文件中添加如下配置信息。</p>
<pre><code class="language-java">server:
  port: 10001
spring:
  application:
    name: server-gateway
  cloud:
    gateway:
      globalcors:
        cors-configurations:
          '[/**]':
            allowedOrigins: &quot;*&quot;
            allowedMethods: &quot;*&quot;
            allowCredentials: true
            allowedHeaders: &quot;*&quot;

      routes:
        - id: user-gateway
          uri: http://localhost:8060
          order: 1
          predicates:
            - Path=/server-user/**
          filters:
            - StripPrefix=1

        - id: product-gateway
          uri: http://localhost:8070
          order: 1
          predicates:
            - Path=/server-product/**
          filters:
            - StripPrefix=1

        - id: order-gateway
          uri: http://localhost:8080
          order: 1
          predicates:
            - Path=/server-order/**
          filters:
            - StripPrefix=1
</code></pre>
<p>我们重点来看下 <code>spring.cloud.gateway</code> 节点下的配置。</p>
<ul>
<li>globalcors：此节点下的配置是为了解决SpringCloud Gateway跨域的问题。</li>
<li>routes：表示一个路由数组，可以在此节点下配置多个路由信息。</li>
<li>id：当前路由的唯一标识。</li>
<li>order：路由的优先级，数字越小表示优先级越高。</li>
<li>predicates：网关断言，也就是路由转发的条件，也是一个数组，可以配置多个路由转发条件。</li>
<li>Path：当客户端请求的路径满足Path的规则时，进行路由转发操作。</li>
<li>filters：网关过滤器，在过滤器中可以修改请求的参数和header信息，以及响应的结果和header信息，网关过滤器也是一个数组，可以配置多个过滤规则。</li>
<li>StripPrefix：网关在进行路由转发之前，会去掉1层访问路径。</li>
</ul>
<p>（3）在服务网关shop-gateway模块的<code>io.binghe.shop</code>包下新建GatewayStarter类，表示服务网关的启动类，源码如下所示。</p>
<pre><code class="language-java">/**
 * @version 1.0.0
 * @description 服务网关启动类
 */
@SpringBootApplication
public class GatewayStarter {
    public static void main(String[] args){
        SpringApplication.run(GatewayStarter.class, args);
    }
}
</code></pre>
<p>（4）由于之前项目中整合了Nacos和Sentinel，所以，在启动项目前，要分别启动Nacos和Sentinel。</p>
<ul>
<li>进入到Nacos的bin目录下，输入如下命令启动Nacos。</li>
</ul>
<pre><code class="language-java">startup.cmd -m standalone
</code></pre>
<ul>
<li>进入Sentinel Jar包所在的目录，输入如下命令启动Sentinel。</li>
</ul>
<pre><code class="language-java">java -Dserver.port=8888 -Dcsp.sentinel.dashboard.server=localhost:8888 -Dproject.name=sentinel-dashboard -jar sentinel-dashboard-1.8.4.jar
</code></pre>
<p>（5）分别启动用户微服务、商品微服务、订单微服务和服务网关。</p>
<p>（6）通过服务网关访问用户微服务，在浏览器中输入<code>http://localhost:10001/server-user/user/get/1001</code>，如下所示。</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1658668418813.png" alt="" loading="lazy"></figure>
<p>用户微服务返回的原始数据如下所示。</p>
<pre><code class="language-java">{
  &quot;id&quot;: 1001,
  &quot;username&quot;: &quot;binghe&quot;,
  &quot;password&quot;: &quot;c26be8aaf53b15054896983b43eb6a65&quot;,
  &quot;phone&quot;: &quot;13212345678&quot;,
  &quot;address&quot;: &quot;北京&quot;
}
</code></pre>
<p>可以看到，通过服务网关能够正确访问到用户微服务。</p>
<p>（7）通过服务网关访问商品微服务，在浏览器中输入<code>http://localhost:10001/server-product/product/get/1001</code>，如下所示。</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1658668445345.png" alt="" loading="lazy"></figure>
<p>商品微服务返回的原始数据如下所示。</p>
<pre><code class="language-java">{
  &quot;id&quot;: 1001,
  &quot;proName&quot;: &quot;华为&quot;,
  &quot;proPrice&quot;: 2399,
  &quot;proStock&quot;: 100
}
</code></pre>
<p>可以看到，通过服务网关能够正确访问到商品微服务。</p>
<p>（8）通过服务网关访问订单微服务，在浏览器中输入<code>http://localhost:10001/server-order/order/test_sentinel</code>，如下所示。</p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1658668471947.png" alt="" loading="lazy"></figure>
<p>可以看到，通过服务网关能够正确访问到订单微服务。</p>
<h3 id="网关整合nacos">网关整合Nacos</h3>
<p>在初步整合SpringCloud Gateway中，我们在服务网关模块的application.yml文件中硬编码配置了服务转发的地址，如下所示。</p>
<ul>
<li>硬编码用户微服务地址</li>
</ul>
<pre><code class="language-java"> uri: http://localhost:8060
</code></pre>
<ul>
<li>硬编码商品微服务地址</li>
</ul>
<pre><code class="language-java">uri: http://localhost:8070
</code></pre>
<ul>
<li>硬编码订单微服务地址</li>
</ul>
<pre><code class="language-java">uri: http://localhost:8080
</code></pre>
<p>这里，我们将网关整合Nacos实现从Nacos注册中心获取转发的服务地址。</p>
<p>（1）在服务网关shop-gateway模块的pom.xml文件中继续添加如下依赖。</p>
<pre><code class="language-java">&lt;dependency&gt;
    &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<p>（2）在服务网关shop-gateway模块的启动类<code>io.binghe.shop.GatewayStarter</code>上添加@EnableDiscoveryClient注解，如下所示。</p>
<pre><code class="language-java">/**
 * @version 1.0.0
 * @description 服务网关启动类
 */
@SpringBootApplication
@EnableDiscoveryClient
public class GatewayStarter {
    public static void main(String[] args){
        SpringApplication.run(GatewayStarter.class, args);
    }
}
</code></pre>
<p>（3）将application.yml备份一份，命名为application-simple.yml，并修改application.yml配置文件，修改后的文件如下所示。</p>
<pre><code class="language-java">server:
  port: 10001
spring:
  application:
    name: server-gateway

  cloud:
    nacos:
      discovery:
        server-addr: 127.0.0.1:8848

    gateway:
      globalcors:
        cors-configurations:
          '[/**]':
            allowedOrigins: &quot;*&quot;
            allowedMethods: &quot;*&quot;
            allowCredentials: true
            allowedHeaders: &quot;*&quot;
      discovery:
        locator:
          enabled: true

      routes:
        - id: user-gateway
          uri: lb://server-user
          order: 1
          predicates:
            - Path=/server-user/**
          filters:
            - StripPrefix=1

        - id: product-gateway
          uri: lb://server-product
          order: 1
          predicates:
            - Path=/server-product/**
          filters:
            - StripPrefix=1

        - id: order-gateway
          uri: lb://server-order
          order: 1
          predicates:
            - Path=/server-order/**
          filters:
            - StripPrefix=1
</code></pre>
<p>上述配置中增加了Nacos相关的配置，如下所示。</p>
<pre><code class="language-java">spring:
  cloud:
    nacos:
      discovery:
        server-addr: 127.0.0.1:8848
</code></pre>
<p>新增了让SpringCloud Gateway可以发现Nacos中的服务配置，如下所示。</p>
<pre><code class="language-java">Spring:
  cloud:
    gateway:
      discovery:
        locator:
          enabled: true
</code></pre>
<p>另外，将硬编码的服务转发地址修改成从Nacos中按照名称获取微服务地址，并按照负载均衡策略分发。</p>
<ul>
<li>从Nacos中获取用户微服务</li>
</ul>
<pre><code class="language-java">uri: lb://server-user
</code></pre>
<ul>
<li>从Nacos中获取商品微服务</li>
</ul>
<pre><code class="language-java">uri: lb://server-product
</code></pre>
<ul>
<li>从Nacos中获取订单微服务</li>
</ul>
<pre><code class="language-java">uri: lb://server-order
</code></pre>
<p>其中，lb指的是从Nacos中按照微服务的名称获取微服务地址，并按照负载均衡的策略分发。使用lb从Nacos中获取微服务时，遵循如下的格式。</p>
<pre><code class="language-java">lb://微服务名称
</code></pre>
<p>微服务的名称就是各个微服务在application.yml文件中配置的服务名称。</p>
<pre><code class="language-java">spring:
  application:
    name: 服务名称
</code></pre>
<p>（4）分别启动用户微服务、商品微服务、订单微服务和服务网关。</p>
<p>（5）通过服务网关访问用户微服务，在浏览器中输入<code>http://localhost:10001/server-user/user/get/1001</code>，如下所示。</p>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1658668500284.png" alt="" loading="lazy"></figure>
<p>用户微服务返回的原始数据如下所示。</p>
<pre><code class="language-java">{
  &quot;id&quot;: 1001,
  &quot;username&quot;: &quot;binghe&quot;,
  &quot;password&quot;: &quot;c26be8aaf53b15054896983b43eb6a65&quot;,
  &quot;phone&quot;: &quot;13212345678&quot;,
  &quot;address&quot;: &quot;北京&quot;
}
</code></pre>
<p>可以看到，通过服务网关能够正确访问到用户微服务。</p>
<p>（6）通过服务网关访问商品微服务，在浏览器中输入<code>http://localhost:10001/server-product/product/get/1001</code>，如下所示。</p>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1658668536499.png" alt="" loading="lazy"></figure>
<p>商品微服务返回的原始数据如下所示。</p>
<pre><code class="language-java">{
  &quot;id&quot;: 1001,
  &quot;proName&quot;: &quot;华为&quot;,
  &quot;proPrice&quot;: 2399,
  &quot;proStock&quot;: 100
}
</code></pre>
<p>可以看到，通过服务网关能够正确访问到商品微服务。</p>
<p>（7）通过服务网关访问订单微服务，在浏览器中输入<code>http://localhost:10001/server-order/order/test_sentinel</code>，如下所示。</p>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1658668556502.png" alt="" loading="lazy"></figure>
<p>可以看到，通过服务网关能够正确访问到订单微服务。</p>
<h3 id="网关整合nacos最简配置">网关整合Nacos最简配置</h3>
<p>SpringCloud Gateway整合Nacos后，可以不用手动指定其他微服务的名称来从Nacos中获取微服务的地址。接下来，我们就来实现SpringCloud Gateway网关整合Nacos的最简配置。</p>
<p>（1）将application.yml备份一份，命名为application-nacos.yml，并修改application.yml配置文件，修改后的文件如下所示。</p>
<pre><code class="language-java">server:
  port: 10001
spring:
  application:
    name: server-gateway

  cloud:
    nacos:
      discovery:
        server-addr: 127.0.0.1:8848

    gateway:
      globalcors:
        cors-configurations:
          '[/**]':
            allowedOrigins: &quot;*&quot;
            allowedMethods: &quot;*&quot;
            allowCredentials: true
            allowedHeaders: &quot;*&quot;
      discovery:
        locator:
          enabled: true
</code></pre>
<p>可以看到，在application.yml文件中，去掉了<code>spring.cloud.gateway.routes</code> 节点及其下面的所有配置。</p>
<p>（2）分别启动用户微服务、商品微服务、订单微服务和服务网关。</p>
<p>（3）通过服务网关访问用户微服务，在浏览器中输入<code>http://localhost:10001/server-user/user/get/1001</code>，如下所示。</p>
<figure data-type="image" tabindex="9"><img src="https://tinaxiawuhao.github.io/post-images/1658668577780.png" alt="" loading="lazy"></figure>
<p>用户微服务返回的原始数据如下所示。</p>
<pre><code class="language-java">{
  &quot;id&quot;: 1001,
  &quot;username&quot;: &quot;binghe&quot;,
  &quot;password&quot;: &quot;c26be8aaf53b15054896983b43eb6a65&quot;,
  &quot;phone&quot;: &quot;13212345678&quot;,
  &quot;address&quot;: &quot;北京&quot;
}
</code></pre>
<p>可以看到，通过服务网关能够正确访问到用户微服务。</p>
<p>（4）通过服务网关访问商品微服务，在浏览器中输入<code>http://localhost:10001/server-product/product/get/1001</code>，如下所示。</p>
<figure data-type="image" tabindex="10"><img src="https://tinaxiawuhao.github.io/post-images/1658668595804.png" alt="" loading="lazy"></figure>
<p>商品微服务返回的原始数据如下所示。</p>
<pre><code class="language-java">{
  &quot;id&quot;: 1001,
  &quot;proName&quot;: &quot;华为&quot;,
  &quot;proPrice&quot;: 2399,
  &quot;proStock&quot;: 100
}
</code></pre>
<p>可以看到，通过服务网关能够正确访问到商品微服务。</p>
<p>（5）通过服务网关访问订单微服务，在浏览器中输入<code>http://localhost:10001/server-order/order/test_sentinel</code>，如下所示。</p>
<figure data-type="image" tabindex="11"><img src="https://tinaxiawuhao.github.io/post-images/1658668615921.png" alt="" loading="lazy"></figure>
<p>可以看到，通过服务网关能够正确访问到订单微服务。</p>
<p><strong>注意：SpringCloud Gateway整合Nacos最简配置时，通过网关访问微服务的格式如下所示。</strong></p>
<pre><code class="language-java">http(s)://网关IP:网关端口/访问的目标微服务名称/接口地址
</code></pre>
<h2 id="网关整合sentinel限流">网关整合Sentinel限流</h2>
<p>Sentinel从1.6.0版本开始，提供了SpringCloud Gateway的适配模块，并且可以提供两种资源维度的限流，一种是route维度；另一种是自定义API分组维度。</p>
<ul>
<li>route维度：对application.yml文件中配置的<code>spring.cloud.gateway.routes.id</code>限流，并且资源名为<code>spring.cloud.gateway.routes.id</code>对应的值。</li>
<li>自定义API分组维度：利用Sentinel提供的API接口来自定义API分组，并且对这些API分组进行限流。</li>
</ul>
<h3 id="实现route维度限流">实现route维度限流</h3>
<p>（1）在服务网关shop-gateway模块的pom.xml文件中添加如下依赖。</p>
<pre><code class="language-java">&lt;dependencies&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;
        &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt;
    &lt;/dependency&gt;

    &lt;dependency&gt;
        &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;
        &lt;artifactId&gt;spring-cloud-alibaba-sentinel-gateway&lt;/artifactId&gt;
    &lt;/dependency&gt;

    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
        &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;
    &lt;/dependency&gt;

    &lt;dependency&gt;
        &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;
        &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;
    &lt;/dependency&gt;

    &lt;dependency&gt;
        &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt;
        &lt;artifactId&gt;sentinel-spring-cloud-gateway-adapter&lt;/artifactId&gt;
    &lt;/dependency&gt;
&lt;/dependencies&gt;
</code></pre>
<p>（2）在服务网关shop-gateway模块中新建<code>io.binghe.shop.config</code>包，并在包下新建GatewayConfig类。基于Sentinel 的Gateway限流是通过其提供的Filter来完成的，使用时只需注入对应的SentinelGatewayFilter实例以及 SentinelGatewayBlockExceptionHandler 实例即可。</p>
<p>GatewayConfig类的源代码如下所示。</p>
<pre><code class="language-java">/**
 * @version 1.0.0
 * @description 网关配置类
 */
@Configuration
public class GatewayConfig {

    private final List&lt;ViewResolver&gt; viewResolvers;

    private final ServerCodecConfigurer serverCodecConfigurer;

    @Value(&quot;${spring.cloud.gateway.discovery.locator.route-id-prefix}&quot;)
    private String routeIdPrefix;

    public GatewayConfig(ObjectProvider&lt;List&lt;ViewResolver&gt;&gt; viewResolversProvider,
                                ServerCodecConfigurer serverCodecConfigurer) {
        this.viewResolvers = viewResolversProvider.getIfAvailable(Collections::emptyList);
        this.serverCodecConfigurer = serverCodecConfigurer;
    }

    /**
     * 初始化一个限流的过滤器
     */
    @Bean
    @Order(Ordered.HIGHEST_PRECEDENCE)
    public GlobalFilter sentinelGatewayFilter() {
        return new SentinelGatewayFilter();
    }

    @PostConstruct
    public void init() {
       this.initGatewayRules();
       this.initBlockHandlers();
    }

    /**
     * 配置初始化的限流参数
     */
    private void initGatewayRules() {
        Set&lt;GatewayFlowRule&gt; rules = new HashSet&lt;&gt;();

        /**
         * Sentinel整合SpringCloud Gateway使用的API类型为Route ID类型，也就是基于route维度时，
         * 由于Sentinel为SpringCloud Gateway网关生成的API名称规则如下：
         * 生成的规则为：${spring.cloud.gateway.discovery.locator.route-id-prefix}后面直接加上目标微服务的名称，如下所示。
         * ${spring.cloud.gateway.discovery.locator.route-id-prefix}目标微服务的名称
         * 其中，${spring.cloud.gateway.discovery.locator.route-id-prefix}是在yml文件中配置的访问前缀
         *
         * 为了让通过服务网关访问目标微服务链接后，请求链路中生成的API名称与流控规则中生成的API名称一致，以达到启动项目即可实现访问链接的限流效果，
         * 而无需登录Setinel管理界面手动配置限流规则，可以将
         * resource参数设置为${spring.cloud.gateway.discovery.locator.route-id-prefix}目标微服务的名称
         *
         * 当然，如果不按照上述配置，也可以在项目启动后，通过服务网关访问目标微服务链接后，在Sentinel管理界面的请求链路中找到对应的API名称所代表的请求链路，
         * 然后手动配置限流规则。
         **/
//        //用户微服务网关
//        rules.add(this.getGatewayFlowRule(&quot;user-gateway&quot;));
//        //商品微服务网关
//        rules.add(this.getGatewayFlowRule(&quot;product-gateway&quot;));
//        //订单微服务网关
//        rules.add(this.getGatewayFlowRule(&quot;order-gateway&quot;));
        //用户微服务网关
        rules.add(this.getGatewayFlowRule(getResource(&quot;server-user&quot;)));
        //商品微服务网关
        rules.add(this.getGatewayFlowRule(getResource(&quot;server-product&quot;)));
        //订单微服务网关
        rules.add(this.getGatewayFlowRule(getResource(&quot;server-order&quot;)));
        //加载规则
        GatewayRuleManager.loadRules(rules);
    }

    private String getResource(String targetServiceName){
        if (routeIdPrefix == null){
            routeIdPrefix = &quot;&quot;;
        }
        return routeIdPrefix.concat(targetServiceName);
    }

    private GatewayFlowRule getGatewayFlowRule(String resource){
        //传入资源名称生成GatewayFlowRule
        GatewayFlowRule gatewayFlowRule = new GatewayFlowRule(resource);
        //限流阈值
        gatewayFlowRule.setCount(1);
        //统计的时间窗口，单位为
        gatewayFlowRule.setIntervalSec(1);
        return gatewayFlowRule;
    }

    /**
     * 配置限流的异常处理器
     */
    @Bean
    @Order(Ordered.HIGHEST_PRECEDENCE)
    public SentinelGatewayBlockExceptionHandler sentinelGatewayBlockExceptionHandler() {
        return new SentinelGatewayBlockExceptionHandler(viewResolvers, serverCodecConfigurer);
    }

    /**
     * 自定义限流异常页面
     */
    private void initBlockHandlers() {
        BlockRequestHandler blockRequestHandler = new BlockRequestHandler() {
            @Override
            public Mono&lt;ServerResponse&gt; handleRequest(ServerWebExchange serverWebExchange, Throwable throwable) {
                Map map = new HashMap&lt;&gt;();
                map.put(&quot;code&quot;, 1001);
                map.put(&quot;codeMsg&quot;, &quot;接口被限流了&quot;);
                return ServerResponse.status(HttpStatus.OK).
                        contentType(MediaType.APPLICATION_JSON_UTF8).
                        body(BodyInserters.fromObject(map));
            }
        };
        GatewayCallbackManager.setBlockHandler(blockRequestHandler);
    }
}
</code></pre>
<p>GatewayConfig类的源代码看上去比较多，但是都是一些非常简单的方法，冰河在这里就不再赘述了。</p>
<p><strong>这里有个需要特别注意的地方：</strong></p>
<p><strong>Sentinel1.8.4整合SpringCloud Gateway使用的API类型为Route ID类型时，也就是基于route维度时，由于Sentinel为SpringCloud Gateway网关生成的API名称规则如下：</strong></p>
<p><strong>生成的规则为：****${spring.cloud.gateway.discovery.locator.route-id-prefix}后面直接加上目标微服务的名称，如下所示。</strong></p>
<p><strong>{spring.cloud.gateway.discovery.locator.route-id-prefix}目标微服务的名称。其中，${spring.cloud.gateway.discovery.locator.route-id-prefix}是在yml文件中配置的访问前缀。</strong></p>
<p><strong>为了让通过服务网关访问目标微服务链接后，请求链路中生成的API名称与流控规则中生成的API名称一致，以达到启动项目即可实现访问链接的限流效果，而无需登录Setinel管理界面手动配置限流规则，可以将生成GatewayFlowRule对象的resource参数设置为${spring.cloud.gateway.discovery.locator.route-id-prefix}目标微服务的名称</strong></p>
<p><strong>当然，如果不按照上述配置，也可以在项目启动后，通过服务网关访问目标微服务链接后，在Sentinel管理界面的请求链路中找到对应的API名称所代表的请求链路，然后手动配置限流规则。</strong></p>
<p>（3）将服务网关shop-gateway模块的application.yml文件备份一份名称为application-nacos-simple.yml的文件，并将application.yml文件的内容修改成如下所示。</p>
<pre><code class="language-java">server:
  port: 10001
spring:
  application:
    name: server-gateway
  main:
    allow-bean-definition-overriding: true
  cloud:
    nacos:
      discovery:
        server-addr: 127.0.0.1:8848
    sentinel:
      transport:
        port: 7777
        dashboard: 127.0.0.1:8888
      web-context-unify: false
      eager: true
      
    gateway:
      globalcors:
        cors-configurations:
          '[/**]':
            allowedOrigins: &quot;*&quot;
            allowedMethods: &quot;*&quot;
            allowCredentials: true
            allowedHeaders: &quot;*&quot;
      discovery:
        locator:
          enabled: true
          route-id-prefix: gateway-
</code></pre>
<p>其中：</p>
<ul>
<li><code>spring.cloud.sentinel.eager</code>表示程序启动时，流控规则是否立即注册到Sentinel，配置为true表示立即注册到Sentinel。</li>
<li><code>spring.cloud.gateway.discovery.locator.route-id-prefix</code>：生成流控规则API名称的前缀。</li>
</ul>
<p>（4）在IDEA中配置启动服务网关shop-gateway模块的参数<code>-Dcsp.sentinel.app.type=1</code>，如下所示。</p>
<p><img src="https://tinaxiawuhao.github.io/post-images/1658668642858.png" alt="" loading="lazy"><br>
如果是在命令行启动网关服务的Jar包，则可以使用如下命令。</p>
<pre><code class="language-java">java -Dcsp.sentinel.app.type=1 shop-gateway.jar
</code></pre>
<p>或者在启动类<code>io.binghe.shop.GatewayStarter</code>的main()方法中添加一行<code>System.setProperty(&quot;csp.sentinel.app.type&quot;, &quot;1&quot;);</code>代码，如下所示。</p>
<pre><code class="language-java">/**
 * @version 1.0.0
 * @description 服务网关启动类
 */
@SpringBootApplication
@EnableDiscoveryClient
public class GatewayStarter {
    public static void main(String[] args){
        System.setProperty(&quot;csp.sentinel.app.type&quot;, &quot;1&quot;);
        SpringApplication.run(GatewayStarter.class, args);
    }
}
</code></pre>
<p>（5）分别启动用户微服务、商品微服务、订单微服务和服务网关，启动后会在Sentinel管理界面左侧菜单栏中看到server-gateway菜单，如下所示。</p>
<figure data-type="image" tabindex="12"><img src="https://tinaxiawuhao.github.io/post-images/1658668665072.png" alt="" loading="lazy"></figure>
<p>在server-gateway菜单下的流控规则子菜单中可以看到网关的流控规则已经注册到Sentinel，如下所示。</p>
<figure data-type="image" tabindex="13"><img src="https://tinaxiawuhao.github.io/post-images/1658668680016.png" alt="" loading="lazy"></figure>
<p>（6）通过服务网关访问用户微服务，在浏览器中输入<code>http://localhost:10001/server-user/user/get/1001</code>，不断刷新页面，如下所示。</p>
<figure data-type="image" tabindex="14"><img src="https://tinaxiawuhao.github.io/post-images/1658668691646.png" alt="" loading="lazy"></figure>
<p>用户微服务返回的原始数据如下所示。</p>
<pre><code class="language-java">{
  &quot;code&quot;: 1001,
  &quot;codeMsg&quot;: &quot;接口被限流了&quot;
}
</code></pre>
<p>可以看到，通过服务网关不断刷新用户微服务时，触发了服务限流，并返回了自定义的限流结果数据。</p>
<p>（7）通过服务网关访问商品微服务，在浏览器中输入<code>http://localhost:10001/server-product/product/get/1001</code>，不断刷新页面，如下所示。</p>
<figure data-type="image" tabindex="15"><img src="https://tinaxiawuhao.github.io/post-images/1658668707383.png" alt="" loading="lazy"></figure>
<p>商品微服务返回的原始数据如下所示。</p>
<pre><code class="language-java">{
  &quot;code&quot;: 1001,
  &quot;codeMsg&quot;: &quot;接口被限流了&quot;
}
</code></pre>
<p>可以看到，通过服务网关不断刷新商品微服务时，触发了服务限流，并返回了自定义的限流结果数据。</p>
<p>（8）通过服务网关访问订单微服务，在浏览器中输入<code>http://localhost:10001/server-order/order/test_sentinel</code>，不断刷新页面，如下所示。</p>
<figure data-type="image" tabindex="16"><img src="https://tinaxiawuhao.github.io/post-images/1658668723929.png" alt="" loading="lazy"></figure>
<p>可以看到，通过服务网关不断刷新订单微服务时，触发了服务限流，并返回了自定义的限流结果数据。</p>
<h3 id="实现自定义api分组维度限流">实现自定义API分组维度限流</h3>
<p>前面，我们实现了route维度的限流，接下来，我们再基于Sentinel与SpringCloud gateway实现自定义API分组维度的限流。</p>
<p>（1）在服务网关shop-gateway模块的<code>io.binghe.shop.config.GatewayConfig</code>配置类中新增initCustomizedApis()方法，初始化API管理的信息，源码如下所示。</p>
<pre><code class="language-java">private void initCustomizedApis() {
    Set&lt;ApiDefinition&gt; definitions = new HashSet&lt;&gt;();
    ApiDefinition api1 = new ApiDefinition(&quot;user_api1&quot;)
        .setPredicateItems(new HashSet&lt;ApiPredicateItem&gt;() {{
            // 以/server-user/user/api1 开头的请求
            add(new ApiPathPredicateItem().setPattern(&quot;/server-user/user/api1/**&quot;).
                setMatchStrategy(SentinelGatewayConstants.URL_MATCH_STRATEGY_PREFIX));
        }});
    ApiDefinition api2 = new ApiDefinition(&quot;user_api2&quot;)
        .setPredicateItems(new HashSet&lt;ApiPredicateItem&gt;() {{
            // 以/server-user/user/api2/demo1 完成的url路径匹配
            add(new ApiPathPredicateItem().setPattern(&quot;/server-user/user/api2/demo1&quot;));
        }});
    definitions.add(api1);
    definitions.add(api2);
    GatewayApiDefinitionManager.loadApiDefinitions(definitions);
}
</code></pre>
<p>上述代码中，配置了两个API分组，每个API分组的规则如下。</p>
<ul>
<li>user_api1分组：匹配以<code>/product-serv/product/api1</code>开头的所有请求。</li>
<li>user_api2分组：精确匹配<code>/server-user/user/api2/demo1</code>。</li>
</ul>
<p>（2）在服务网关shop-gateway模块的<code>io.binghe.shop.config.GatewayConfig</code>配置类中init()方法中调用initCustomizedApis()方法，为了避免route维度的限流对自定义API分组维度的限流产生影响，这里，同时在init()方法中注释掉调用initGatewayRules()方法，修改后的init()方法的代码如下所示。</p>
<pre><code class="language-java">@PostConstruct
public void init() {
    //this.initGatewayRules();
    this.initBlockHandlers();
    this.initCustomizedApis();
}
</code></pre>
<p>（3）在用户微服务shop-user的<code>io.binghe.shop.user.controller.UserController</code>类中新增四个测试接口，源码如下所示。</p>
<pre><code class="language-java">@GetMapping(value = &quot;/api1/demo1&quot;)
public String api1Demo1(){
    log.info(&quot;访问了api1Demo1接口&quot;);
    return &quot;api1Demo1&quot;;
}
@GetMapping(value = &quot;/api1/demo2&quot;)
public String api1Demo2(){
    log.info(&quot;访问了api1Demo2接口&quot;);
    return &quot;api1Demo2&quot;;
}

@GetMapping(value = &quot;/api2/demo1&quot;)
public String api2Demo1(){
    log.info(&quot;访问了api2Demo1接口&quot;);
    return &quot;api2Demo1&quot;;
}
@GetMapping(value = &quot;/api2/demo2&quot;)
public String api2Demo2(){
    log.info(&quot;访问了api2Demo2接口&quot;);
    return &quot;api2Demo2&quot;;
}
</code></pre>
<p>（4）分别启动用户微服务、商品微服务、订单微服务和服务网关，启动后会在Sentinel管理界面左侧菜单栏中看到server-gateway菜单，如下所示。</p>
<figure data-type="image" tabindex="17"><img src="https://tinaxiawuhao.github.io/post-images/1658668748563.png" alt="" loading="lazy"></figure>
<p>此时，由于我们注释了调用以route维度限流的方法，所以，在流控规则里的限流规则为空，如下所示。</p>
<figure data-type="image" tabindex="18"><img src="https://tinaxiawuhao.github.io/post-images/1658668764215.png" alt="" loading="lazy"></figure>
<p>在API管理里面会发现我们定义的API分组已经自动注册到Sentinel中了，如下所示。</p>
<figure data-type="image" tabindex="19"><img src="https://tinaxiawuhao.github.io/post-images/1658668773447.png" alt="" loading="lazy"></figure>
<p>（5）在Sentinel管理界面的流控规则中，新增网关流控规则，如下所示。</p>
<figure data-type="image" tabindex="20"><img src="https://tinaxiawuhao.github.io/post-images/1658668783657.png" alt="" loading="lazy"></figure>
<p>点击新增网关流控规则后，会弹出新增网关流控规则配置框，按照如下方式为user_api1分组配置限流规则。</p>
<figure data-type="image" tabindex="21"><img src="https://tinaxiawuhao.github.io/post-images/1658668798808.png" alt="" loading="lazy"></figure>
<p>点击新增按钮后，按照同样的方式为user_api2分组配置限流规则。</p>
<figure data-type="image" tabindex="22"><img src="https://tinaxiawuhao.github.io/post-images/1658668819062.png" alt="" loading="lazy"></figure>
<p>配置完毕后，在流控规则中的限流规则如下所示。</p>
<figure data-type="image" tabindex="23"><img src="https://tinaxiawuhao.github.io/post-images/1658668856618.png" alt="" loading="lazy"></figure>
<p>（6）预期的测试结果如下。</p>
<ul>
<li>当频繁访问<code>http://localhost:10001/server-user/user/api1/demo1</code>时会被限流。</li>
<li>当频繁访问<code>http://localhost:10001/server-user/user/api1/demo2</code>时会被限流。</li>
<li>当频繁访问<code>http://localhost:10001/server-user/user/api2/demo1</code>时会被限流。</li>
<li>当频繁访问<code>http://localhost:10001/server-user/user/api2/demo2</code>时不会被限流。</li>
</ul>
<p><strong>注意：只有最后一个不会被限流。</strong></p>
<p>（7）在浏览器上频繁访问<code>http://localhost:10001/server-user/user/api1/demo1</code>，如下所示。</p>
<figure data-type="image" tabindex="24"><img src="https://tinaxiawuhao.github.io/post-images/1658668864366.png" alt="" loading="lazy"></figure>
<p>返回的原始数据如下所示。</p>
<pre><code class="language-java">{
  &quot;code&quot;: 1001,
  &quot;codeMsg&quot;: &quot;接口被限流了&quot;
}
</code></pre>
<p>说明触发了服务限流，并返回了自定义的限流结果数据。</p>
<p>（8）在浏览器上频繁访问<code>http://localhost:10001/server-user/user/api1/demo2</code>，如下所示。</p>
<figure data-type="image" tabindex="25"><img src="https://tinaxiawuhao.github.io/post-images/1658668872082.png" alt="" loading="lazy"></figure>
<p>返回的原始数据如下所示。</p>
<pre><code class="language-java">{
  &quot;code&quot;: 1001,
  &quot;codeMsg&quot;: &quot;接口被限流了&quot;
}
</code></pre>
<p>说明触发了服务限流，并返回了自定义的限流结果数据。</p>
<p>（9）在浏览器上频繁访问<code>http://localhost:10001/server-user/user/api2/demo1</code>，如下所示。</p>
<figure data-type="image" tabindex="26"><img src="https://tinaxiawuhao.github.io/post-images/1658668880990.png" alt="" loading="lazy"></figure>
<p>返回的原始数据如下所示。</p>
<pre><code class="language-java">{
  &quot;code&quot;: 1001,
  &quot;codeMsg&quot;: &quot;接口被限流了&quot;
}
</code></pre>
<p>说明触发了服务限流，并返回了自定义的限流结果数据。</p>
<p>（10）在浏览器上频繁访问<code>http://localhost:10001/server-user/user/api2/demo2</code>，如下所示。</p>
<figure data-type="image" tabindex="27"><img src="https://tinaxiawuhao.github.io/post-images/1658668890430.png" alt="" loading="lazy"></figure>
<p>可以看到，访问<code>http://localhost:10001/server-user/user/api2/demo2</code>时，无论访问的频率多频繁，都不会触发Sentinel限流。</p>
<p>至此，我们就成功在项目中整合了SpringCloud Gateway网关，并通过Sentinel整合SpringCloud Gateway实现了网关的限流操作。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[gateway网关概述]]></title>
        <id>https://tinaxiawuhao.github.io/post/8Wk_K0cjl/</id>
        <link href="https://tinaxiawuhao.github.io/post/8Wk_K0cjl/">
        </link>
        <updated>2022-07-09T13:04:50.000Z</updated>
        <content type="html"><![CDATA[<p>网关概述</p>
<p>当采用分布式、微服务的架构模式开发系统中，服务网关是整个系统中必不可少的一部分。</p>
<h3 id="没有网关的弊端">没有网关的弊端</h3>
<p>当一个系统使用分布式、微服务架构后，系统会被拆分为一个个小的微服务，每个微服务专注一个小的业务。那么，客户端如何调用这么多微服务的接口呢？如果不做任何处理，没有服务网关，就只能在客户端记录下每个微服务的每个接口地址，然后根据实际需要去调用相应的接口。</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1658668221351.png" alt="" loading="lazy"></figure>
<p>这种直接使用客户端记录并管理每个微服务的每个接口的方式，存在着太多的问题。比如，这里我列举几个常见的问题。</p>
<ul>
<li>由客户端记录并管理所有的接口缺乏安全性。</li>
<li>由客户端直接请求不同的微服务，会增加客户端程序编写的复杂性。</li>
<li>涉及到服务认证与鉴权规则时，需要在每个微服务中实现这些逻辑，增加了代码的冗余性。</li>
<li>客户端调用多个微服务，由于每个微服务可能部署的服务器和域名不同，存在跨域的风险。</li>
<li>当客户端比较多时，每个客户端上都管理和配置所有的接口，维护起来相对比较复杂。</li>
</ul>
<h3 id="引入api网关">引入API网关</h3>
<p>API网关，其实就是整个系统的统一入口。网关会封装微服务的内部结构，为客户端提供统一的入口服务，同时，一些与具体业务逻辑无关的通用逻辑可以在网关中实现，比如认证、授权、路由转发、限流、监控等。引入API网关后，如下所示。</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1658668228282.png" alt="" loading="lazy"></figure>
<p>可以看到，引入API网关后，客户端只需要连接API网关，由API网关根据实际情况进行路由转发，将请求转发到具体的微服务，同时，API网关会提供认证、授权、限流和监控等功能。</p>
<h2 id="主流的api网关">主流的API网关</h2>
<p>当系统采用分布式、微服务的架构模式后，API网关就成了整个系统不可分割的一部分。业界通过不断的探索与创新，实现了多种API网关的解决方案。目前，比较主流的API网关有：Nginx+Lua、Kong官网、Zuul网关、Apache Shenyu网关、SpringCloud Gateway网关。</p>
<h3 id="nginxlua">Nginx+Lua</h3>
<p>Nginx的一些插件本身就实现了限流、缓存、黑白名单和灰度发布，再加上Nginx的反向代理和负载均衡，能够实现对服务接口的负载均衡和高可用。而Lua语言可以实现一些简单的业务逻辑，Nginx又支持Lua语言。所以，可以基于Nginx+Lua脚本实现网关。</p>
<h3 id="kong网关">Kong网关</h3>
<p>Kong网关基于Nginx与Lua脚本开发，性能高，比较稳定，提供多个限流、鉴权等插件，这些插件支持热插拔，开箱即用。Kong网关提供了管理页面，但是，目前基于Kong网关二次开发比较困难。</p>
<h3 id="zuul网关">Zuul网关</h3>
<p>Zuul网关是Netflix开源的网关，功能比较丰富，主要基于Java语言开发，便于在Zuul网关的基础上进行二次开发。但是Zuul网关无法实现动态配置规则，依赖的组件相对来说也比较多，在性能上不如Nginx。</p>
<h3 id="apache-shenyu网关">Apache Shenyu网关</h3>
<p>Dromara社区开发的网关框架，ShenYu 的前名是 soul，最近正式加入了 Apache 的孵化器，因此改名为 ShenYu。其是一个异步的，高性能的，跨语言的，响应式的API网关，并在此基础上提供了非常丰富的扩展功能：</p>
<ul>
<li>支持各种语言(http协议)，支持Dubbo, Spring-Cloud, Grpc, Motan, Sofa, Tars等协议。</li>
<li>插件化设计思想，插件热插拔，易扩展。</li>
<li>灵活的流量筛选，能满足各种流量控制。</li>
<li>内置丰富的插件支持，鉴权，限流，熔断，防火墙等等。</li>
<li>流量配置动态化，性能极高。</li>
<li>支持集群部署，支持 A/B Test，蓝绿发布。</li>
</ul>
<h3 id="springcloud-gateway网关">SpringCloud Gateway网关</h3>
<p>Spring为了替换Zuul而开发的网关，SpringCloud Alibaba技术栈中，并没有单独实现网关的组件。在后续的案例实现中，我们会使用SpringCloud Gateway实现网关功能。</p>
<h2 id="springcloud-gateway网关-2">SpringCloud Gateway网关</h2>
<p>Spring Cloud Gateway是Spring公司基于Spring 5.0， Spring Boot 2.0 和 Project Reactor 等技术开发的网关，它旨在为微服务架构提供一种简单有效的统一的 API 路由管理方式。</p>
<p>它的目标是替代Netflix Zuul，其不仅提供统一的路由方式，并且基于 Filter 链的方式提供了网关基本的功能，例如：安全，监控和限流、重试等。</p>
<h3 id="springcloud-gateway概述">SpringCloud Gateway概述</h3>
<p>Spring  Cloud Gateway是Spring Cloud的一个全新项目，基于Spring 5.0 + Spring Boot 2.0和Project Reactor等技术开发的网关，它旨在为微服务架构提供一种简单有效的统一的API路由管理方式。</p>
<p>Spring Cloud  Geteway作为Spring Cloud生态系统中的网关，目标是替代Zuul，在Spring  Cloud2.0以上版本中，没有对新版本的Zuul 2.0以上最新高性能版本进行集成，仍然还是使用的Zuul  1.x非Reactor模式的老版本。</p>
<p>为了提升网关性能，Spring Cloud  Gateway是基于WebFlux框架实现的，而WebFlux框架底层则使用了高性能的Reactor模式通信框架Netty。</p>
<p>Spring Cloud Gateway的目标提供统一的路由方式且基于Filter链的方式提供了网关基本的功能，例如：安全，监控/指标，和限流。</p>
<p><strong>总结一句话：Spring Cloud Gateway使用的Webflux中的reactor-netty响应式编程组件，底层使用Netty通讯框架。</strong></p>
<h3 id="springcloud-gateway核心架构">SpringCloud Gateway核心架构</h3>
<p>客户端请求到 Gateway 网关，会先经过 Gateway Handler Mapping 进行请求和路由匹配。匹配成功后再发送到  Gateway Web Handler  处理，然后会经过特定的过滤器链，经过所有前置过滤后，会发送代理请求。请求结果返回后，最后会执行所有的后置过滤器。</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1658668237193.png" alt="" loading="lazy"></figure>
<p>由上图可以看出，SpringCloud Gateway的主要流程为：客户端请求会先打到Gateway，具体的讲应该是DispacherHandler（因为Gateway引入了WebFlux，作用可以类比MVC的DispacherServlet）。</p>
<p>Gateway根据用户的请求找到相应的HandlerMapping，请求和具体的handler之间有一个映射关系，网关会对请求进行路由，handler会匹配到RoutePredicateHandlerMapping，匹配请求对应的Route，然后到达Web处理器。</p>
<p>WebHandler代理了一系列网关过滤器和全局过滤器的实例，这些过滤器可以对请求和响应进行修改，最后由代理服务完成用户请求，并将结果返回。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sentinel源码拓展之——限流的各种实现方式]]></title>
        <id>https://tinaxiawuhao.github.io/post/xUda2KT1A/</id>
        <link href="https://tinaxiawuhao.github.io/post/xUda2KT1A/">
        </link>
        <updated>2022-07-08T12:56:51.000Z</updated>
        <content type="html"><![CDATA[<p>Sentinel源码拓展之——限流的各种实现方式</p>
<h3 id="一-常见的限流功能实现有以下三种方式">一 常见的限流功能实现有以下三种方式</h3>
<p>滑动时间窗口、令牌桶、漏桶，这三种实现方式，有各自擅长的应用场景，而在 Sentinel 中这三种限流实现都有被用到，只不过使用在不同的限流场景下：</p>
<ul>
<li>**滑动时间窗口：**普通QPS限流下的快速失败、Warmup预热，使用场景最多；—— Sentinel的实现，是使用“环形时间窗口”来表示无边无际的时间；</li>
<li>**令牌桶：**热点参数限流，需要为每一个请求参数，创建一个令牌桶；—— Sentinel的实现，实际不是真的创建很多个桶；</li>
<li>**漏桶（流量整形）：**普通QPS限流下的排队等待，将请求暂存在一个队列中，按时间间隔拉取并处理；—— Sentinel的实现，实际不是真的放入一个队列中；</li>
</ul>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1658667500749.png" alt="" loading="lazy"></figure>
<h4 id="1-时间窗口滑动时间窗口">1 时间窗口（滑动时间窗口）</h4>
<p>固定时间窗口，由于时间窗口粒度太粗，而时间本身其实是没有边界的，所以无法保证任意单位时间窗口中的QPS都不超限（如下图粉红色区域）；</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1658667533086.png" alt="" loading="lazy"></figure>
<p>为了解决这种问题，可以将我们设置的时间窗口做N等分，划分为更小粒度的窗口，这就是滑动时间窗口：</p>
<ul>
<li>假设滑动时间跨度Internel为1秒，我们可以做N=2等分，那么最小时间窗口其实就是500ms；</li>
<li>在限流统计QPS时，窗口范围就是从( currentTime – interval) 之后的第一个时区开始，到 currentTime 所在时间窗口。</li>
</ul>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1658667562075.png" alt="" loading="lazy"></figure>
<p>随着N的值越大，限流的精度就会越高。</p>
<h4 id="2-令牌桶">2 令牌桶</h4>
<ul>
<li>以固定的速率生成令牌，存在令牌桶中，如果令牌桶满了以后，多余的令牌将会被丢弃；</li>
<li>请求进入后，必须先尝试从令牌桶中获取令牌，获取到令牌的请求才会被处理，没有获取到令牌的请求将会被拒绝，或者等待。</li>
</ul>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1658667591134.png" alt="" loading="lazy"></figure>
<h4 id="3-漏桶">3 漏桶</h4>
<ul>
<li>将每一个“请求”视作“水滴”，放入“漏桶”中存储；</li>
<li>“漏桶”以固定速率向外“漏出”请求进行处理，如果“漏桶”空了则代表没有待处理的请求；</li>
<li>如果“漏桶”满了，则多余的“请求”将被快速拒绝；</li>
</ul>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1658667624330.png" alt="" loading="lazy"></figure>
<blockquote>
<p>以上都是三种实现方案的理论知识，而Sentinel在实际实现时，是做了一定的优化的！</p>
</blockquote>
<hr>
<h3 id="二-sentinel中三种限流方案的实现源码剖析之滑动时间窗口算法">二 Sentinel中三种限流方案的实现源码剖析之——滑动时间窗口算法</h3>
<p><strong>滑动时间窗口 —— QPS快速失败 + WarmUp预热：</strong></p>
<p>Sentinel中的时间窗口，其实使用的是如下图所示的环形时间窗口：</p>
<ul>
<li>因为时间是没有边界的，</li>
<li>而且我们一般也只会关注一个Internel之内的时间，如果一个Internel被分成了N个小窗口，那么我们也只会关注N个小的时间窗口；</li>
</ul>
<p>所以使用环形时间窗口，既能满足使用需求，又能解决内存空间。</p>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1658667653355.png" alt="" loading="lazy"></figure>
<p>通过上一篇关于 ProcessorSlotChain 插槽链的介绍，我们已经清楚了：</p>
<ul>
<li>QPS 的统计工作将会由 StatisticSlot 插槽完成；</li>
<li>限流判断的逻辑将会由 FlowSlot 插槽来完成；</li>
</ul>
<p>而所有的 PrcessorSlot 的处理逻辑，都在他们的 entry() 方法中；</p>
<h4 id="1-时间窗口请求量统计statisticslot">1 时间窗口请求量统计：StatisticSlot</h4>
<pre><code class="language-java">public class StatisticSlot extends AbstractLinkedProcessorSlot&lt;DefaultNode&gt; {
 
    @Override
    public void entry(Context context, ResourceWrapper resourceWrapper, DefaultNode node, int count,
                      boolean prioritized, Object... args) throws Throwable {
        try {
            // 先去执行后面插槽和请求体的任务
            fireEntry(context, resourceWrapper, node, count, prioritized, args);
 
            // 处理完之后才会回来做统计（如果后面失败了，肯定就不用统计了）
            node.increaseThreadNum();  // 线程数统计（服务隔离）
            node.addPassRequest(count); // QPS请求量统计（服务限流）
             
            ......
        } catch (Exception e){
            ......
        }
    }
}

// com.alibaba.csp.sentinel.node.DefaultNode#addPassRequest
public void addPassRequest(int count) {
    super.addPassRequest(count);  // 为DefaultNode做统计
    this.clusterNode.addPassRequest(count); // 为ClusterNode做统计
}
</code></pre>
<ul>
<li>我们知道DefaultNode 和 ClusterNode 都是 StatisticNode 的子类，所以这里都会调用到StatisticNode的addPassRequest()方法：</li>
</ul>
<pre><code class="language-java">public class StatisticNode implements Node {
 
    // 秒级统计（看变量名就知道是一个环形计数器）
    private transient volatile Metric rollingCounterInSecond = new ArrayMetric(SampleCountProperty.SAMPLE_COUNT,
        IntervalProperty.INTERVAL);
 
    // 分钟级统计（看变量名就知道是一个环形计数器）
    private transient Metric rollingCounterInMinute = new ArrayMetric(60, 60 * 1000, false);
 
    // 统计QPS方法
    public void addPassRequest(int count) {
        rollingCounterInSecond.addPass(count); // 秒级统计
        rollingCounterInMinute.addPass(count); // 分钟级统计
    }    
}

// intervalInMs：滑动窗口的时间间隔，Sentinel默认为 1000ms
// sampleCount：时间窗口的分割数量，Sentinel默认为 2
// 所以最小的时间窗口就为 500ms
public class ArrayMetric implements Metric {
 
    private final LeapArray&lt;MetricBucket&gt; data;
 
    public ArrayMetric(int sampleCount, int intervalInMs) {
        this.data = new OccupiableBucketLeapArray(sampleCount, intervalInMs);
    }
}
</code></pre>
<p>时间线铺平的效果如下图：</p>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1658667679910.png" alt="" loading="lazy"></figure>
<ul>
<li>获取当前请求所在时间窗口，并增加计数</li>
</ul>
<pre><code class="language-java">public class ArrayMetric implements Metric {
 
    private final LeapArray&lt;MetricBucket&gt; data;
     
    public ArrayMetric(int sampleCount, int intervalInMs) {
        this.data = new OccupiableBucketLeapArray(sampleCount, intervalInMs);
    }
 
    @Override
    public void addPass(int count) {
        // 获取当前请求所在时间窗口
        WindowWrap&lt;MetricBucket&gt; wrap = data.currentWindow();
         
        // 计数器 + count
        wrap.value().addPass(count);
    }
}
</code></pre>
<ul>
<li>ArrayMetric 又是如何获取当前所在时间窗口的呢？</li>
</ul>
<p>首先我们得要弄清楚LeapArray保存了哪些数据？</p>
<pre><code class="language-java">public abstract class LeapArray&lt;T&gt; {
 
    // 小时间窗口的时间长度，默认为 500ms
    protected int windowLengthInMs;
     
    // 一个Interval时间被划分的数量，秒级统计默认为2，分钟级默认为60
    protected int sampleCount;
     
    // 滑动时间窗口时间间隔，默认为 1000ms
    protected int intervalInMs;
     
    // 每一个Interval时间窗口内的小窗口数组，这里就是2
    protected final AtomicReferenceArray&lt;WindowWrap&lt;T&gt;&gt; array;
}
</code></pre>
<p>再次上图，LeapArray是一个环形数组：</p>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1658667708685.png" alt="" loading="lazy"></figure>
<ul>
<li>我们直接看data.currentWindow() 方法：</li>
</ul>
<pre><code class="language-java">// com.alibaba.csp.sentinel.slots.statistic.base.LeapArray#currentWindow(当前时间戳)
public WindowWrap&lt;T&gt; currentWindow(long timeMillis) {
    if (timeMillis &lt; 0) {
        return null;
    }
    // 计算当前时间对应的数组角标 = (当前时间/500ms)%16
    int idx = calculateTimeIdx(timeMillis);
    // 计算当前时间所在窗口的开始时间 = 当前时间 - 当前时间 % 500ms
    long windowStart = calculateWindowStart(timeMillis);
 
    /*
    * 先根据角标获取数组中保存的 oldWindow 对象，可能是旧数据，需要判断.
    *
    * (1) oldWindow 不存在, 说明是第一次，创建新 window并存入，然后返回即可
    * (2) oldWindow的 starTime = 本次请求的 windowStar, 说明正是要找的窗口，直接返回.
    * (3) oldWindow的 starTime &lt; 本次请求的 windowStar, 说明是旧数据，需要被覆盖，创建 
    *     新窗口，覆盖旧窗口
    */
    while (true) {
        WindowWrap&lt;T&gt; old = array.get(idx);
        if (old == null) {
            // 创建新 window
            WindowWrap&lt;T&gt; window = new WindowWrap&lt;T&gt;(windowLengthInMs, windowStart, newEmptyBucket(timeMillis));
            // 基于CAS写入数组，避免线程安全问题
            if (array.compareAndSet(idx, null, window)) {
                // 写入成功，返回新的 window
                return window;
            } else {
                // 写入失败，说明有并发更新，等待其它人更新完成即可
                Thread.yield();
            }
        } else if (windowStart == old.windowStart()) {
            return old;
        } else if (windowStart &gt; old.windowStart()) {
            if (updateLock.tryLock()) {
                try {
                    // 获取并发锁，覆盖旧窗口并返回
                    return resetWindowTo(old, windowStart);
                } finally {
                    updateLock.unlock();
                }
            } else {
                // 获取锁失败，等待其它线程处理就可以了
                Thread.yield();
            }
        } else if (windowStart &lt; old.windowStart()) {
            // 这种情况不应该存在，写这里只是以防万一。
            return new WindowWrap&lt;T&gt;(windowLengthInMs, windowStart, newEmptyBucket(timeMillis));
        }
    }
}
</code></pre>
<ul>
<li>获取到时间窗口后，增加计数就比较简单了，使用“自旋 + CAS”的方式完成计数器安全增加即可。</li>
</ul>
<h4 id="2-滑动窗口qps计算并判断限流逻辑flowslot">2 滑动窗口QPS计算，并判断限流逻辑：FlowSlot</h4>
<pre><code class="language-java">public class FlowSlot extends AbstractLinkedProcessorSlot&lt;DefaultNode&gt; {
 
    @Override
    public void entry(Context context, ResourceWrapper resourceWrapper, DefaultNode node, int count,
                      boolean prioritized, Object... args) throws Throwable {
        // 先做限流判断
        checkFlow(resourceWrapper, context, node, count, prioritized);
 
        // 判断通过后，才会放行到下一个插槽
        fireEntry(context, resourceWrapper, node, count, prioritized, args);
    }
}
</code></pre>
<p>FlowSlot的限流判断最终都由<code>TrafficShapingController</code>接口中的<code>canPass</code>方法来实现。该接口有三个实现类：</p>
<ul>
<li>DefaultController：快速失败，默认的方式，基于滑动时间窗口算法；</li>
<li>WarmUpController：预热模式，基于滑动时间窗口算法，只不过阈值是动态的；</li>
<li>RateLimiterController：排队等待模式，基于漏桶算法；</li>
</ul>
<p>这里我们就以DefaultController.canPass() 方法为例：</p>
<pre><code class="language-java">com.alibaba.csp.sentinel.slots.block.flow.controller.DefaultController#canPass()
public boolean canPass(Node node, int acquireCount, boolean prioritized) {
    // 重点：计算目前为止滑动窗口内已经存在的请求量
    int curCount = avgUsedTokens(node);
    // 判断：已使用请求量 + 需要的请求量（1） 是否大于 窗口的请求阈值
    if (curCount + acquireCount &gt; count) {
        // 大于，说明超出阈值，返回false
        if (prioritized &amp;&amp; grade == RuleConstant.FLOW_GRADE_QPS) {
            long currentTime;
            long waitInMs;
            currentTime = TimeUtil.currentTimeMillis();
            waitInMs = node.tryOccupyNext(currentTime, acquireCount, count);
            if (waitInMs &lt; OccupyTimeoutProperty.getOccupyTimeout()) {
                node.addWaitingRequest(currentTime + waitInMs, acquireCount);
                node.addOccupiedPass(acquireCount);
                sleep(waitInMs);
 
                // PriorityWaitException indicates that the request will pass after waiting for {@link @waitInMs}.
                throw new PriorityWaitException(waitInMs);
            }
        }
        return false;
    }
    // 小于等于，说明在阈值范围内，返回true
    return true;
}

</code></pre>
<ul>
<li>很显然，关键点就在于，如何计算滑动窗口内已经用掉的请求量</li>
</ul>
<pre><code class="language-java">private int avgUsedTokens(Node node) {
    if (node == null) {
        return DEFAULT_AVG_USED_TOKENS;
    }
    return grade == RuleConstant.FLOW_GRADE_THREAD ? node.curThreadNum() : (int)(node.passQps());
}

// 我们这里肯定是QPS限流
// com.alibaba.csp.sentinel.node.StatisticNode#passQps
public double passQps() {
    // 请求量 ÷ 滑动窗口时间间隔(默认1秒) ，得到的就是QPS
    return rollingCounterInSecond.pass() / rollingCounterInSecond.getWindowIntervalInSec();
}
</code></pre>
<ul>
<li>那么rollingCounterInSecond.pass() 又是如何计算当前时间窗口内的请求量的呢？</li>
</ul>
<blockquote>
<p>以秒级统计为例，其实环形数组的长度只为2，只需要记录当前小时间窗口和前一个小时间窗口即可，一个都不多记录，节约内存！</p>
</blockquote>
<figure data-type="image" tabindex="9"><img src="https://tinaxiawuhao.github.io/post-images/1658667751679.png" alt="" loading="lazy"></figure>
<pre><code class="language-java">// com.alibaba.csp.sentinel.slots.statistic.metric.ArrayMetric#pass
public long pass() {
    // 获取当前窗口
    data.currentWindow();
    long pass = 0;
    // 获取 当前时间的 滑动窗口范围内 的所有小窗口
    List&lt;MetricBucket&gt; list = data.values();
    // 遍历
    for (MetricBucket window : list) {
        // 累加求和
        pass += window.pass();
    }
    // 返回
    return pass;
}
|
|
// data.values()如何获取 滑动窗口范围内 的所有小窗口的
// com.alibaba.csp.sentinel.slots.statistic.base.LeapArray#values(long)
public List&lt;T&gt; values(long timeMillis) {
    if (timeMillis &lt; 0) {
        return new ArrayList&lt;T&gt;();
    }
    // 创建空集合，大小等于 LeapArray长度（2）
    int size = array.length();
    List&lt;T&gt; result = new ArrayList&lt;T&gt;(size);
    // 遍历 LeapArray
    for (int i = 0; i &lt; size; i++) {
        // 获取每一个小窗口
        WindowWrap&lt;T&gt; windowWrap = array.get(i);
        // 判断这个小窗口是否在 滑动窗口时间范围内（1秒内）
        if (windowWrap == null || isWindowDeprecated(timeMillis, windowWrap)) {
            // 不在范围内，则跳过
            continue;
        }
        // 在范围内，则添加到集合中
        result.add(windowWrap.value());
    }
    // 返回集合
    return result;
}
|
|
// isWindowDeprecated(timeMillis, windowWrap)又是如何判断窗口是否符合要求呢？
public boolean isWindowDeprecated(long time, WindowWrap&lt;T&gt; windowWrap) {
    // 当前时间 - 窗口开始时间  是否大于 滑动窗口的最大间隔（1秒）
    // 也就是说，我们要统计的是 距离当前时间1秒内的 小窗口的 count之和
    return time - windowWrap.windowStart() &gt; intervalInMs;
}
</code></pre>
<p>到这里，我们就可以理清了：</p>
<ul>
<li>
<p>StatisticSlot会帮助我们记录每一次的request请求，统计每个小时间窗口内的请求数；</p>
</li>
<li>
<ul>
<li>秒级统计的时间窗口环只有 2 格；</li>
<li>分钟级统计的时间窗口环有 60格；</li>
</ul>
</li>
<li>
<p>FlowSlot在需要的时候，会去除当前时间窗口内包含的所有小窗口，然后累加他们的请求量；</p>
</li>
<li>
<p>最后判断是否溢出限流阈值，允许通过，或直接拒绝！</p>
</li>
</ul>
<hr>
<h3 id="三-sentinel中三种限流方案的实现源码剖析之令牌桶算法">三 Sentinel中三种限流方案的实现源码剖析之——令牌桶算法</h3>
<blockquote>
<p>“热点参数”限流策略，不适合使用 StatisticSlot 中常规的 “滑动时间窗口算法”，因为StatisticSlot中统计的维度是Node级别；</p>
<p>很显然，“热点参数”并不适合使用上面的“环形时间窗口算法”来实现；</p>
<p>相比下来，“令牌桶算法”最适合用在“热点参数限流”场景下，只需要为每个不同的参数值创建一个令牌桶即可。</p>
</blockquote>
<ul>
<li><strong>Controller中的方法资源是不可以进行热点参数限流的：通过Sentinel添加的springmvc拦截器实现，创建Entry时候没有传入params参数；</strong></li>
<li><strong>其它的我们通过@SentinelResource添加的资源才艺进行热点参数限流：通过AOP切面编程实现，创建Entry的时候，也将Params一并传入了；</strong></li>
</ul>
<pre><code class="language-java">public class ParamFlowSlot extends AbstractLinkedProcessorSlot&lt;DefaultNode&gt; {
 
    public void entry(Context context, ResourceWrapper resourceWrapper, DefaultNode node, int count, boolean prioritized, Object... args) throws Throwable {
        if (!ParamFlowRuleManager.hasRules(resourceWrapper.getName())) {
            this.fireEntry(context, resourceWrapper, node, count, prioritized, args);
        } else {
            // 校验参数限流
            this.checkFlow(resourceWrapper, count, args);
            // 放行到下一个插槽
            this.fireEntry(context, resourceWrapper, node, count, prioritized, args);
        }
    }
 
    void checkFlow(ResourceWrapper resourceWrapper, int count, Object... args) throws BlockException {
        // args == null 情况有二：1、确实没有参数； 2、Controller方法无法进行参数限流
        if (args != null) {
            if (ParamFlowRuleManager.hasRules(resourceWrapper.getName())) {
                List&lt;ParamFlowRule&gt; rules = ParamFlowRuleManager.getRulesOfResource(resourceWrapper.getName());
                Iterator var5 = rules.iterator();
     
                ParamFlowRule rule;
                 
                // do-while循环，对每一条rule规则做判断
                do {
                    if (!var5.hasNext()) {
                        return;
                    }
     
                    rule = (ParamFlowRule)var5.next();
                    this.applyRealParamIdx(rule, args.length);
                     
                    // 初始化“令牌桶”—— 加“”号，并非真的令牌桶
                    ParameterMetricStorage.initParamMetricsFor(resourceWrapper, rule);
                } while(ParamFlowChecker.passCheck(resourceWrapper, rule, count, args));
     
                String triggeredParam = &quot;&quot;;
                if (args.length &gt; rule.getParamIdx()) {
                    Object value = args[rule.getParamIdx()];
                    triggeredParam = String.valueOf(value);
                }
     
                throw new ParamFlowException(resourceWrapper.getName(), triggeredParam, rule);
            }
        }
    }
}
</code></pre>
<h4 id="1parametermetricstorageinitparammetricsfor-令牌桶初始化方法">1ParameterMetricStorage.initParamMetricsFor() 令牌桶初始化方法</h4>
<pre><code class="language-java">public final class ParameterMetricStorage {
 
    // 以资源名区分不同资源下的令牌桶容器（因为这还不是真正的令牌桶）
    private static final Map&lt;String, ParameterMetric&gt; metricsMap = new ConcurrentHashMap();
    private static final Object LOCK = new Object();
 
    public static void initParamMetricsFor(ResourceWrapper resourceWrapper, ParamFlowRule rule) {
        if (resourceWrapper != null &amp;&amp; resourceWrapper.getName() != null) {
            String resourceName = resourceWrapper.getName();
            ParameterMetric metric;
            if ((metric = (ParameterMetric)metricsMap.get(resourceName)) == null) {
                synchronized(LOCK) {
                    // 如果当前资源还没创建过自己的令牌桶容器，那就创建一个
                    if ((metric = (ParameterMetric)metricsMap.get(resourceName)) == null) {
                        metric = new ParameterMetric();
                        metricsMap.put(resourceWrapper.getName(), metric);
                        RecordLog.info(&quot;[ParameterMetricStorage] Creating parameter metric for: &quot; + resourceWrapper.getName(), new Object[0]);
                    }
                }
            }
             
            // 对令牌桶容器进行初始化
            metric.initialize(rule);
        }
    }
}
</code></pre>
<h4 id="2-初始化令牌桶容器真正的令牌桶即将出现">2 初始化令牌桶容器，真正的令牌桶即将出现</h4>
<p>Sentinel中的令牌桶，其实是维护2个双层Map：</p>
<ul>
<li>容器中剩余令牌数的Map：&lt;ParamFlowRule, &lt;参数值, 属于这个参数值得桶中的剩余可用令牌数&gt;&gt;：此时第二层Map还是空Map；</li>
<li>记录最近一次通过的请求时间戳的Map：&lt;ParamFlowRule, &lt;参数值, 最近一次请求的时间戳&gt;&gt;：此时第二层Map还是空Map；</li>
</ul>
<pre><code class="language-java">public class ParameterMetric {
    private static final int THREAD_COUNT_MAX_CAPACITY = 4000;
    private static final int BASE_PARAM_MAX_CAPACITY = 4000;
    private static final int TOTAL_MAX_CAPACITY = 200000;
    private final Object lock = new Object();
     
    // 令牌桶实现之一：双层Map：&lt;ParamFlowRule, &lt;参数值, 上次请求的时间戳&gt;&gt;
    private final Map&lt;ParamFlowRule, CacheMap&lt;Object, AtomicLong&gt;&gt; ruleTimeCounters = new HashMap();
    // 令牌桶之二：桶中剩余的令牌数
    private final Map&lt;ParamFlowRule, CacheMap&lt;Object, AtomicLong&gt;&gt; ruleTokenCounter = new HashMap();
    private final Map&lt;Integer, CacheMap&lt;Object, AtomicInteger&gt;&gt; threadCountMap = new HashMap();
     
    // 初始化令牌桶容器
    public void initialize(ParamFlowRule rule) {
        long size;
        if (!this.ruleTimeCounters.containsKey(rule)) {
            synchronized(this.lock) {
                // 初始化ParamRule对应的“最近请求时间戳Map”
                if (this.ruleTimeCounters.get(rule) == null) {
                    size = Math.min(4000L * rule.getDurationInSec(), 200000L);
                    this.ruleTimeCounters.put(rule, new ConcurrentLinkedHashMapWrapper(size));
                }
            }
        }
     
        if (!this.ruleTokenCounter.containsKey(rule)) {
            synchronized(this.lock) {
                // 初始化ParamRule对应的“桶中可用令牌Map”
                if (this.ruleTokenCounter.get(rule) == null) {
                    size = Math.min(4000L * rule.getDurationInSec(), 200000L);
                    this.ruleTokenCounter.put(rule, new ConcurrentLinkedHashMapWrapper(size));
                }
            }
        }
     
        if (!this.threadCountMap.containsKey(rule.getParamIdx())) {
            synchronized(this.lock) {
                if (this.threadCountMap.get(rule.getParamIdx()) == null) {
                    this.threadCountMap.put(rule.getParamIdx(), new ConcurrentLinkedHashMapWrapper(4000L));
                }
            }
        }
     
    }
}
</code></pre>
<blockquote>
<p>以上，<strong>只算是将令牌桶容器初始化好了，但是还没开始正式使用！</strong></p>
</blockquote>
<h4 id="3-正式使用上面创建的令牌桶容器一步步调用至热点参数限流判断逻辑核心方法">3 正式使用上面创建的令牌桶容器，一步步调用至“热点参数限流”判断逻辑核心方法</h4>
<pre><code class="language-java">ParamFlowChecker.passCheck(resourceWrapper, rule, count, args)

com.alibaba.csp.sentinel.slots.block.flow.param.ParamFlowChecker#passLocalCheck

com.alibaba.csp.sentinel.slots.block.flow.param.ParamFlowChecker#passSingleValueCheck

com.alibaba.csp.sentinel.slots.block.flow.param.ParamFlowChecker#passDefaultLocalCheck
</code></pre>
<h4 id="4paramflowcheckerpassdefaultlocalcheck-即为热点限流逻辑的核心方法">4ParamFlowChecker.passDefaultLocalCheck() 即为“热点限流逻辑”的核心方法</h4>
<figure data-type="image" tabindex="10"><img src="https://tinaxiawuhao.github.io/post-images/1658667803098.jpg" alt="" loading="lazy"></figure>
<pre><code class="language-java">// com.alibaba.csp.sentinel.slots.block.flow.param.ParamFlowChecker#passDefaultLocalCheck  
static boolean passDefaultLocalCheck(ResourceWrapper resourceWrapper, ParamFlowRule rule, int acquireCount, Object value) {
    ParameterMetric metric = getParameterMetric(resourceWrapper);
     
    // 根据rule从上面初始化好的令牌桶容器中去除第二层Map
    // &lt;参数值, 上次请求的时间戳&gt;
    // &lt;参数值, 属于这个参数值得桶中的剩余可用令牌数&gt;
    CacheMap&lt;Object, AtomicLong&gt; tokenCounters = metric == null ? null : metric.getRuleTokenCounter(rule);
    CacheMap&lt;Object, AtomicLong&gt; timeCounters = metric == null ? null : metric.getRuleTimeCounter(rule);
     
    if (tokenCounters != null &amp;&amp; timeCounters != null) {
        Set&lt;Object&gt; exclusionItems = rule.getParsedHotItems().keySet();
        long tokenCount = (long)rule.getCount();
        if (exclusionItems.contains(value)) {
            tokenCount = (long)(Integer)rule.getParsedHotItems().get(value);
        }
 
        if (tokenCount == 0L) {
            return false;
        } else {
         
            // 允许的最大请求数，也是桶的最大值，也是我们rule中设置的单机阈值
            // 后者是突发阈值，一般不配置，为0
            long maxCount = tokenCount + (long)rule.getBurstCount(); 
            if ((long)acquireCount &gt; maxCount) {
                return false;
            } else {
                while(true) {
                    long currentTime = TimeUtil.currentTimeMillis();
                     
                    // 从timeMap中获取最近一次请求通过的时间戳
                    AtomicLong lastAddTokenTime = (AtomicLong)timeCounters.putIfAbsent(value, new AtomicLong(currentTime));
                    if (lastAddTokenTime == null) { 
                        // 相同参数第一次，直接放行，并更新tokenMap = maxCount - 1
                        tokenCounters.putIfAbsent(value, new AtomicLong(maxCount - (long)acquireCount));
                        return true;
                    }
 
                    // 距离上一次请求通过的时间的差值
                    long passTime = currentTime - lastAddTokenTime.get();
                    AtomicLong oldQps;
                    long restQps;
                     
                    // 距最近一次时间差 &gt; 一次统计窗口
                    if (passTime &gt; rule.getDurationInSec() * 1000L) {
                        oldQps = (AtomicLong)tokenCounters.putIfAbsent(value, new AtomicLong(maxCount - (long)acquireCount));
                        if (oldQps == null) {
                            lastAddTokenTime.set(currentTime);
                            return true;
                        }
 
                        // tokenMap中剩余的令牌数
                        restQps = oldQps.get();
                         
                        // 在距离上次请求的这段时间内，应该补充生成多少新的令牌
                        long toAddCount = passTime * tokenCount / (rule.getDurationInSec() * 1000L);
                         
                        // 上面2者相加，与maxCount允许的最大令牌数对比，取min值，并减去本次需要的令牌数
                        long newQps = toAddCount + restQps &gt; maxCount ? maxCount - (long)acquireCount : restQps + toAddCount - (long)acquireCount;
                        if (newQps &lt; 0L) {
                            return false;
                        }
 
                        // 通过CAS替换原来的tokenMap，并修改最新通过的请求时间戳
                        if (oldQps.compareAndSet(restQps, newQps)) {
                            lastAddTokenTime.set(currentTime);
                            return true;
                        }
 
                        Thread.yield();
                    } else {  // 距最近一次时间差 &lt; 一次统计窗口
                        oldQps = (AtomicLong)tokenCounters.get(value);
                        if (oldQps != null) {
                            restQps = oldQps.get();
                            // tokenMap中剩余令牌不足，直接拒绝
                            if (restQps - (long)acquireCount &lt; 0L) {
                                return false;
                            }
 
                            // 剩余令牌充足，CAS从tokenMap中减去当前需要的令牌数
                            if (oldQps.compareAndSet(restQps, restQps - (long)acquireCount)) {
                                return true;
                            }
                        }
 
                        Thread.yield();
                    }
                }
            }
        }
    } else {
        return true;
    }
}
</code></pre>
<p>总结：对于热点参数限流：</p>
<ul>
<li>
<p>Sentinel 会为每个资源，维护两个双层数组：</p>
</li>
<li>
<ul>
<li>容器中剩余令牌数的tokenMap：&lt;ParamFlowRule, &lt;参数值, 属于这个参数值得桶中的剩余可用令牌数&gt;&gt;</li>
<li>记录最近一次通过的请求时间戳的timeMap：&lt;ParamFlowRule, &lt;参数值, 最近一次请求的时间戳&gt;&gt;</li>
</ul>
</li>
<li>
<p>以参数 x=100，限流为5为例：</p>
</li>
<li>
<ul>
<li>第一次到达时，肯定不会超限，放行，同时往tokenMap中put入&lt;100, 4&gt;</li>
</ul>
</li>
<li>
<p>过一会儿，x = 100 的请求再次到达，则判断，本次请求，距离上一次请求时间，是否超过一个时间统计窗口：</p>
</li>
<li>
<ul>
<li>在同一个时间窗口，则在前一次的基础上继续减少token值，tokenMap中值变为 &lt;100, 3&gt;</li>
<li>如果不在一个时间窗口，那么计算距离上次请求的这段时间内，应该新生成的token数 + 现在桶中剩余的token数，与maxToken数做对比，取小值就相当于是此时桶中应该有的令牌数，然后减去自己本次需要的令牌数，之后再更新tokenMap；</li>
</ul>
</li>
</ul>
<hr>
<h3 id="四-sentinel中三种限流方案的实现源码剖析之漏桶算法">四、Sentinel中三种限流方案的实现源码剖析之——漏桶算法</h3>
<p>漏桶算法的核心思想是：将请求放在漏桶中，漏桶会按照固定时间间隔，向外“漏出”请求，进行处理，这样很明显的好处就是“流量整形”，当瞬间流量过大时，也可以先放在漏桶中，慢慢处理！</p>
<p>漏桶算法的入口也是在FlowSlot中，上面有讲过：</p>
<p>FlowSlot的限流判断最终都由<code>TrafficShapingController</code>接口中的<code>canPass</code>方法来实现。该接口有三个实现类：</p>
<ul>
<li>DefaultController：快速失败，默认的方式，基于滑动时间窗口算法；</li>
<li>WarmUpController：预热模式，基于滑动时间窗口算法，只不过阈值是动态的；</li>
<li>RateLimiterController：排队等待模式，基于漏桶算法；</li>
</ul>
<p><strong>直接进入RateLimiterController.canPass()方法逻辑：</strong></p>
<pre><code class="language-java">// com.alibaba.csp.sentinel.slots.block.flow.controller.RateLimiterController#canPass()
 
// 最新一次的请求执行时间（不一定是已经通过的，而是队列中排在最尾端的请求的预期执行时间）
private final AtomicLong latestPassedTime = new AtomicLong(-1);
 
@Override
public boolean canPass(Node node, int acquireCount, boolean prioritized) {
    // Pass when acquire count is less or equal than 0.
    if (acquireCount &lt;= 0) {
        return true;
    }
    // 阈值小于等于 0 ，阻止请求，不太可能
    if (count &lt;= 0) {
        return false;
    }
     
    // 获取当前时间
    long currentTime = TimeUtil.currentTimeMillis();
    // 计算两次请求之间允许的最小时间间隔
    // 正常时候acquireCount=1，那么costTime = 200ms
    long costTime = Math.round(1.0 * (acquireCount) / count * 1000);
 
    // 计算本次请求 允许执行的时间点 = 上一次请求的可能执行时间 + 两次请求的最小间隔
    long expectedTime = costTime + latestPassedTime.get();
    // 如果允许执行的时间点小于当前时间，说明可以立即执行
    if (expectedTime &lt;= currentTime) {
        // 更新上一次的请求的执行时间
        latestPassedTime.set(currentTime);
        // 这种情况说明该执行了，立即执行
        return true;
    } else {
        // 不能立即执行，需要计算 预期等待时长
        // 预期等待时长 = 两次请求的最小间隔 + 最近一次请求的可执行时间 - 当前时间
        long waitTime = costTime + latestPassedTime.get() - TimeUtil.currentTimeMillis();
        // 如果预期等待时间超出阈值，则拒绝请求
        if (waitTime &gt; maxQueueingTimeMs) {
            return false;
        } else {
            // 预期等待时间小于阈值，更新最近一次请求的可执行时间，加上costTime
            long oldTime = latestPassedTime.addAndGet(costTime);
            try {
                // 保险起见，再判断一次预期等待时间，是否超过阈值
                waitTime = oldTime - TimeUtil.currentTimeMillis();
                if (waitTime &gt; maxQueueingTimeMs) {
                    // 如果超过，则把刚才 加 的时间再 减回来
                    latestPassedTime.addAndGet(-costTime);
                    // 拒绝
                    return false;
                }
                // in race condition waitTime may &lt;= 0
                if (waitTime &gt; 0) {
                    // 预期等待时间在阈值范围内，休眠要等待的时间，醒来后继续执行
                    Thread.sleep(waitTime);
                }
                return true;
            } catch (InterruptedException e) {
            }
        }
    }
    return false;
}
</code></pre>
<p>总结：</p>
<p>Sentinel的漏桶算法，不是真的维护了一个队列，而是通过计算各个请求的预计执行时间；</p>
<ul>
<li>如果预计执行时间 &gt; 最大等待时间，那么久不用等了，直接拒绝；</li>
<li>如果预计执行时间 &lt; 最大等待时间，那么就等待吧，自己通过 Thread.sleep(waitTime) 实现等待！</li>
</ul>
<figure data-type="image" tabindex="11"><img src="https://tinaxiawuhao.github.io/post-images/1658667818074.png" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sentinel核心源码——插槽机制（责任链模式）]]></title>
        <id>https://tinaxiawuhao.github.io/post/xdN8U8BuX/</id>
        <link href="https://tinaxiawuhao.github.io/post/xdN8U8BuX/">
        </link>
        <updated>2022-07-07T12:52:10.000Z</updated>
        <content type="html"><![CDATA[<p>Sentinel核心源码——插槽机制（责任链模式）</p>
<p>Sentinel的工作原理：https://github.com/alibaba/Sentinel/wiki</p>
<ul>
<li>
<p><strong>Sentinel会为所有的资源，以资源名为区分，创建各自的DefaultProcessorSlotChain，放在缓存中；</strong></p>
</li>
<li>
<p><strong>DefaultProcessorSlotChain的9个ProcessorSlot插槽都是通过SPI机制从 META/services/ 目录下加载的；</strong></p>
</li>
<li>
<p><strong>每一个ProcessorSlot 其实是一个 AbstractLinkedProcessorSlot 抽象链表处理器插槽，</strong></p>
<p><strong>有一个next属性，指向下一个Slot，当某一个Slot执行完后，会调用fireEntry()方法，</strong></p>
<p><strong>将请求转到下一个Slot继续执行。</strong></p>
</li>
<li>
<p><strong>最终完成责任链上所有ProcessorSlot的逻辑！</strong></p>
</li>
<li>
<p><strong>——————————————————————————————————————————————</strong></p>
</li>
<li>
<p><strong>Context链路上下文为request请求级别的，放在ThreadLocal中，请求结束即释放；</strong></p>
</li>
<li>
<p><strong>entranceNode是应用级别的，创建完成后，会缓存起来（key为contextName），下一个请求可以继续使用；</strong></p>
</li>
<li>
<p><strong>processorSlotChain也是应用级别的，创建完成后，会缓存起来（key为resourceName），下一个请求可以继续使用；</strong></p>
</li>
</ul>
<h3 id="一-processorslotchain处理器插槽链和node节点的引入">一 ProcessorSlotChain处理器插槽链和Node节点的引入</h3>
<p>首先，根据官方Wiki中的图，我们可以很形象地看到，整个请求处理过程就像一个链条一样，一步步地向后执行，这是一种典型地“责任链模式”；</p>
<p>责任链模式 —— 为请求创建一个接收者对象的链，链上的每一个节点服务处理各自的业务逻辑，实现解耦，每一个处理者节点记录着下一个节点的引用，请求将沿着这条链被传递下去，以此处理对应的逻辑。</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1658667201037.png" alt="" loading="lazy"></figure>
<h4 id="1-processorslotchain处理器插槽链的引入">1 ProcessorSlotChain处理器插槽链的引入</h4>
<p>ProcessorSlotChain是上图整个链的骨架，基于“责任链模式”设计，将“统计、授权、限流、降级等”处理逻辑封装成一个个的Slot插槽，串联起来。</p>
<p>处理链中的Slot插槽可粗分为上下两大类：数据统计部分 + 规则判断部分</p>
<ul>
<li>
<p>数据统计：</p>
</li>
<li>
<ul>
<li>**NodeSelectorSlot：**负责构建簇点链路中的各个节点（DefaultNode），形成NodeTree</li>
<li>**ClusterBuilderSlot：**负责构建某个资源的ClusterNode（具体的DefaultNode和ClusterNode的区别见下文）</li>
<li>**StatisticSlot：**负责实时统计请求的各种调用信息，如来源信息、请求次数、运行信息等；</li>
</ul>
</li>
<li>
<p>规则判断：</p>
</li>
<li>
<ul>
<li><strong>AuthoritySlot</strong>：授权规则判断（来源控制）</li>
<li><strong>SystemSlot</strong>：系统保护规则判断，当系统资源使用量达到一定程度后，拒绝新的请求进入等；</li>
<li><strong>ParamFlowSlot</strong>：热点参数限流规则判断</li>
<li><strong>FlowSolt</strong>：普通限流规则判断</li>
<li><strong>DegradeSlot</strong>：降级规则判断</li>
</ul>
</li>
</ul>
<h4 id="2-为什么要存在nodeselectorslot和clusterbuilderslot两个插槽defaultnode和clusternode有什么区别">2 为什么要存在NodeSelectorSlot和ClusterBuilderSlot两个插槽？DefaultNode和ClusterNode有什么区别？</h4>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1658667225838.png" alt="" loading="lazy"></figure>
<ul>
<li>**DefaultNode： 同一份资源，经过不同的链路调用，会创建不同的DefaultNode，记录不同链路访问当前资源的统计元数据 **，因为整个Sentinel是支持“根据链路限流”的，所以肯定要分开统计；</li>
<li><strong>ClusterNode： 同一份资源，在整个系统中只会创建一个ClusterNode，记录所有入口访问当前资源的统计元数据</strong>，因为很多时候，我们只需要统计该资源的整体使用情况。</li>
</ul>
<p>注意这里的用词，DefaultNode和ClusterNode都只是负责记录统计元数据，真正的统计工作由之后的StatisticSlot进行，另外ParmFlowSlot会负责热点参数限流这种特殊场景下的数据统计。（热点参数限流的统计为什么要单独出来，后面做限流算法实现的讲解时就清楚了）。</p>
<h4 id="3-如何自定义一个sentinel资源sentinelresource注解">3 如何自定义一个Sentinel资源？@SentinelResource注解？</h4>
<p>我们知道，在实际使用过程中，当我们要自定义sentinel资源时，只需要使用@SentinelResource注解定义即可，很方便。</p>
<p>而且Sentinel默认就已经将 springmvc 的 controller 中的方法注册为sentinel资源了，但是这些方法并没有添加 @SentinelResource 注解呀！</p>
<p>其实@SentinelResource底层也就是通过AOP + Entry 的方式来手动注册 Sentinel资源的：</p>
<pre><code class="language-java">// 资源名可使用任意有业务语义的字符串，比如方法名、接口名或其它可唯一标识的字符串。
try (Entry entry = SphU.entry(&quot;resourceName&quot;)) {
  // 被保护的业务逻辑
  // do something here...
} catch (BlockException ex) {
  // 资源访问阻止，被限流或被降级
  // 在此处进行相应的处理操作
}
</code></pre>
<p>SentinelResourceAspect切面类：</p>
<pre><code class="language-java">@Aspect
public class SentinelResourceAspect extends AbstractSentinelAspectSupport {
 
    @Pointcut(&quot;@annotation(com.alibaba.csp.sentinel.annotation.SentinelResource)&quot;)
    public void sentinelResourceAnnotationPointcut() {
     
    }
 
    // 经典AOP实现
    @Around(&quot;sentinelResourceAnnotationPointcut()&quot;)
    public Object invokeResourceWithSentinel(ProceedingJoinPoint pjp) throws Throwable {
        Method originMethod = this.resolveMethod(pjp);
        SentinelResource annotation = (SentinelResource)originMethod.getAnnotation(SentinelResource.class);
        if (annotation == null) {
            throw new IllegalStateException(&quot;Wrong state for SentinelResource annotation&quot;);
        } else {
            String resourceName = this.getResourceName(annotation.value(), originMethod);
            EntryType entryType = annotation.entryType();
            int resourceType = annotation.resourceType();
            Entry entry = null;
 
            try {
                Object var18;
                try {
                    // 注册对应的资源
                    entry = SphU.entry(resourceName, resourceType, entryType, pjp.getArgs());
                    // 执行具体的业务逻辑
                    return pjp.proceed();
                } catch (Exception e) {
                    ......
                }
            } finally {
                ......
            }
        }
    }
}
</code></pre>
<blockquote>
<p><strong>所以，通过Entry手动注册资源 和 通过@SentinelResource 注解自动注入资源，原理上时一样的，都是通过 SphU.entry(…) 方法实现。</strong></p>
</blockquote>
<h4 id="4-链路上下文context">4 链路上下文Context</h4>
<pre><code class="language-java">public class Context {
    private final String name;
    private DefaultNode entranceNode;
    private Entry curEntry;
    private String origin = &quot;&quot;;
    private final boolean async;
}
</code></pre>
<ul>
<li>Context代表调用链路的上下文，贯穿一次链路调用中的所有资源（Entry），基于ThreadLocal实现；</li>
<li>Context维护者入口节点（entranceNode）、当前资源节点（curEntry —&gt;curNode）、调用来源origin等信息；</li>
<li>后续所有的Slot插槽都可以通过context拿到DefaultNode 和 ClusterNode，从而完成统计或判断逻辑；</li>
<li>Context创建过程中，会创建EntranceNode，contextName 就是entranceNode的名称；</li>
</ul>
<pre><code class="language-java">// 创建context，包含两个参数：context名称、 来源名称
ContextUtil.enter(&quot;contextName&quot;, &quot;originName&quot;);
</code></pre>
<ul>
<li>默认情况下，Sentinel的entranceNode是sentinel_default_context，如果我们要想做链路限流，就必须关闭“统一入口配置”，从而让每一个Controller方法为Context的入口。</li>
</ul>
<pre><code class="language-java">public final static String CONTEXT_DEFAULT_NAME = &quot;sentinel_default_context&quot;;

spring:
  cloud:
    sentinel:
      web-context-unify: false  # 关闭context统一入口配置
</code></pre>
<hr>
<h3 id="二-sentinel源码剖析context的初始化">二 Sentinel源码剖析——Context的初始化</h3>
<h4 id="1-spring-cloud-starter-alibaba-sentinel-的-springfactory-中有两个相关的自动装配类">1 spring-cloud-starter-alibaba-sentinel 的 spring.factory 中有两个相关的自动装配类</h4>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1658667252485.png" alt="" loading="lazy"></figure>
<blockquote>
<p>由于，Context的初始化，涉及到了将Controller中的方法定义为entranceNode的过程，所以肯定是看 SentinelWebAutoConfiguration 这个自动装配类！</p>
</blockquote>
<h4 id="2-向-springmvc-处理链中添加一个sentinel的拦截器">2 向 springmvc 处理链中添加一个Sentinel的拦截器</h4>
<pre><code class="language-java">@Configuration(
    proxyBeanMethods = false  // Lite模式，关闭Full模式
)
@ConditionalOnWebApplication(
    type = Type.SERVLET
)
@ConditionalOnProperty(
    name = {&quot;spring.cloud.sentinel.enabled&quot;},
    matchIfMissing = true
)
@ConditionalOnClass({SentinelWebInterceptor.class})
@EnableConfigurationProperties({SentinelProperties.class})
public class SentinelWebAutoConfiguration implements WebMvcConfigurer {
 
    // 通过实现 WebMvcConfigurer 接口，允许了手动向springmvc中添加拦截器 Interceptor
 
    ......
     
    // 注入本类下文定义的SentinelWebInterceptor 
    @Autowired
    private Optional&lt;SentinelWebInterceptor&gt; sentinelWebInterceptorOptional;
     
    public SentinelWebAutoConfiguration() {
    }
     
    // 添加
    public void addInterceptors(InterceptorRegistry registry) {
        if (this.sentinelWebInterceptorOptional.isPresent()) {
            Filter filterConfig = this.properties.getFilter();
            registry.addInterceptor((HandlerInterceptor)this.sentinelWebInterceptorOptional.get())
                .order(filterConfig.getOrder()).addPathPatterns(filterConfig.getUrlPatterns());
        }
    }
     
    // 向 IOC 容器中注入一个 SentinelWebInterceptor 拦截器
    @Bean
    @ConditionalOnProperty(
        name = {&quot;spring.cloud.sentinel.filter.enabled&quot;},
        matchIfMissing = true
    )
    public SentinelWebInterceptor sentinelWebInterceptor(SentinelWebMvcConfig sentinelWebMvcConfig) {
        return new SentinelWebInterceptor(sentinelWebMvcConfig);
    }
     
}
</code></pre>
<h4 id="3-sentinelwebinterceptor拦截器的核心方法">3 SentinelWebInterceptor拦截器的核心方法</h4>
<p>SentinelWebInterceptor 中会对父类 AbstractSentinelInterceptor 中的抽象方法做实现（模板方法模式）：</p>
<pre><code class="language-java">public class SentinelWebInterceptor extends AbstractSentinelInterceptor {
 
    // 获取resourceName：
    // controller中请求方法的路径（资源）：/order/{orderId}
    protected String getResourceName(HttpServletRequest request) {
        Object resourceNameObject = request.getAttribute(HandlerMapping.BEST_MATCHING_PATTERN_ATTRIBUTE);
        if (resourceNameObject != null &amp;&amp; resourceNameObject instanceof String) {
            String resourceName = (String)resourceNameObject;
            UrlCleaner urlCleaner = this.config.getUrlCleaner();
            if (urlCleaner != null) {
                resourceName = urlCleaner.clean(resourceName);
            }
     
            if (StringUtil.isNotEmpty(resourceName) &amp;&amp; this.config.isHttpMethodSpecify()) {
                resourceName = request.getMethod().toUpperCase() + &quot;:&quot; + resourceName;
            }
     
            return resourceName;
        } else {
            return null;
        }
    }
     
    // 获取contextName：
    // 如果开启了统一入口配置，则contextName就是默认的统一入口：sentinel_spring_web_context
    // 如果关闭了统一入口配置，则contextName就是当前资源的名称；
    protected String getContextName(HttpServletRequest request) {
        return this.config.isWebContextUnify() ? super.getContextName(request) : this.getResourceName(request);
    }
}
</code></pre>
<p>而作为一个拦截器，最重要的逻辑，肯定是在 prehandler() 中：</p>
<pre><code class="language-java">public abstract class AbstractSentinelInterceptor implements HandlerInterceptor {
 
    public static final String SENTINEL_SPRING_WEB_CONTEXT_NAME = &quot;sentinel_spring_web_context&quot;;
    private static final String EMPTY_ORIGIN = &quot;&quot;;
    private final BaseWebMvcConfig baseWebMvcConfig;
 
    // 前置拦截的核心逻辑
    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {
        try {
            // 获取资源名称，一般是controller方法的@RequestMapping路径，例如/order/{orderId}
            String resourceName = this.getResourceName(request);
            if (StringUtil.isEmpty(resourceName)) {
                return true;
            } else if (this.increaseReferece(request, this.baseWebMvcConfig.getRequestRefName(), 1) != 1) {
                return true;
            } else {
                // 从request中获取请求来源，将来做 授权规则（来源控制） 判断时会用
                String origin = this.parseOrigin(request);
                 
                // 获取 contextName，默认是sentinel_spring_web_context；
                // 如果关闭统一入口，那就是当前resourceName
                String contextName = this.getContextName(request);
                // 创建Context核心方法
                ContextUtil.enter(contextName, origin);
                 
                // 构建ProcessorSlotChain处理器插槽链的核心逻辑
                Entry entry = SphU.entry(resourceName, 1, EntryType.IN);
                request.setAttribute(this.baseWebMvcConfig.getRequestAttributeName(), entry);
                return true;
            }
        } catch (BlockException var12) {
            BlockException e = var12;
     
            try {
                this.handleBlockException(request, response, e);
            } finally {
                ContextUtil.exit();
            }
     
            return false;
        }
    }
 
    // 当请求体业务处理完成后，关闭所有的资源
    public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception {
        if (this.increaseReferece(request, this.baseWebMvcConfig.getRequestRefName(), -1) == 0) {
            Entry entry = this.getEntryInRequest(request, this.baseWebMvcConfig.getRequestAttributeName());
            if (entry == null) {
                ...Log...
            } else {
                this.traceExceptionAndExit(entry, ex);  // entry.exit()退出
                this.removeEntryInRequest(request); 
                ContextUtil.exit();  // contextHolder.set(null);
            }
        }
    }
}
 
// private static ThreadLocal&lt;Context&gt; contextHolder = new ThreadLocal&lt;&gt;(); // 保存context的threadLocal
</code></pre>
<p><strong>4、ContextUtil.enter(contextName, origin) 创建Context核心方法：</strong></p>
<pre><code class="language-java">// com.alibaba.csp.sentinel.context.ContextUtil#enter
public static Context enter(String name, String origin) {
    // &quot;sentinel_default_context&quot;是不允许被创建的
    if (Constants.CONTEXT_DEFAULT_NAME.equals(name)) {
        throw new ContextNameDefineException(
            &quot;The &quot; + Constants.CONTEXT_DEFAULT_NAME + &quot; can't be permit to defined!&quot;);
    }
    return trueEnter(name, origin);
}
|
|
// com.alibaba.csp.sentinel.context.ContextUtil#trueEnter
protected static Context trueEnter(String name, String origin) {
    // 尝试获取context，一般一个新的请求到达后，获取context肯定为null
    Context context = contextHolder.get();
    // 判空
    if (context == null) {
        // 如果为空，开始初始化
        Map&lt;String, DefaultNode&gt; localCacheNameMap = contextNameNodeMap;
        // 尝试获取入口节点
        DefaultNode node = localCacheNameMap.get(name);
        if (node == null) {
            LOCK.lock();
            try {
                node = contextNameNodeMap.get(name);
                if (node == null) { // 双重检测锁
                    // 入口节点为空，初始化入口节点 EntranceNode
                    node = new EntranceNode(new StringResourceWrapper(name, EntryType.IN), null);
                    // 添加入口节点到 ROOT，所有的节点共用一个ROOT根节点
                    Constants.ROOT.addChild(node);
                    // 将入口节点放入缓存（下次请求时候，根据contextName获取，可直接使用）
                    Map&lt;String, DefaultNode&gt; newMap = new HashMap&lt;&gt;(contextNameNodeMap.size() + 1);
                    newMap.putAll(contextNameNodeMap);
                    newMap.put(name, node);
                    contextNameNodeMap = newMap; // CopyOnWrite
                }
            } finally {
                LOCK.unlock();
            }
        }
        // 创建Context，参数为：入口节点 和 contextName
        context = new Context(node, name);
        // 设置请求来源 origin
        context.setOrigin(origin);
        // 将context放入ThreadLocal
        contextHolder.set(context);
    }
    // 返回
    return context;
}
</code></pre>
<p>由此我们可以得出重要结论：</p>
<ul>
<li>在每一个请求到达时，Sentinel的拦截器都会为本次请求封装一个“链路上下文context”，然后放入到ThreadLocal中，便于请求在后面的处理过程中取用；</li>
<li>默认情况下，“统一入口配置开启”，“链路上下文context”以sentinel-spring-web-context 命名；</li>
<li>如果关闭了“统一入口配置”，“链路上下文context”将以本次请求对应的controller方法的 @RequestMapping() 的值命名，如“/order/{orderId}”；</li>
<li>由于context是放在Thread中的，所以当本次请求结束后，context就会被释放，下次请求需要重新创建；<strong>（context生命周期为request）</strong></li>
<li>但是入口 entranceNode 却是放在缓存HashMap中的，所以下一次新的请求到达时，就没有必要再重新创建了；<strong>(entranceNode生命周期为应用级)</strong></li>
<li><strong>创建入口方法 entranceNode 时，使用了 双重检测锁 + CopyOnWrite ，因为存在多个请求线程并发情况；</strong></li>
<li><strong>创建 context 过程不需要考虑多线程安全 ，原因也是因为 context时线程内的，单线程 。</strong></li>
</ul>
<hr>
<h3 id="三-sentinel核心源码之processorslotchain的构建">三 Sentinel核心源码之ProcessorSlotChain的构建</h3>
<h4 id="1-入口方法正式上文拦截器中创建context之后的方法">1 入口方法，正式上文拦截器中创建Context之后的方法</h4>
<pre><code class="language-java">Entry entry = SphU.entry(resourceName, 1, EntryType.IN);
</code></pre>
<p>该方法，将“一脉单传”调用到以下方法 entryWithPriority() ：</p>
<pre><code class="language-java">private Entry entryWithPriority(ResourceWrapper resourceWrapper, int count, boolean prioritized, Object... args)
    throws BlockException {
    // 获取 Context
    Context context = ContextUtil.getContext();
 
    if (context == null) {
        // Using default context.
        context = InternalContextUtil.internalEnter(Constants.CONTEXT_DEFAULT_NAME);
    }
    // 获取 Slot执行链，同一个资源（如：/order/{orderId}），会创建一个执行链，放入缓存
    ProcessorSlot&lt;Object&gt; chain = lookProcessChain(resourceWrapper);
 
    // 创建 Entry，并将 resource、chain、context 记录在 Entry中
    Entry e = new CtEntry(resourceWrapper, chain, context);
    try {
        // 执行 slotChain
        chain.entry(context, resourceWrapper, null, count, prioritized, args);
    } catch (BlockException e1) {
        // 如果执行 slotChain 过程中发生异常，也直接将对应的资源释放
        e.exit(count, args);
        ......
    }
    return e;
}
</code></pre>
<h4 id="2-lookprocesschain-创建或获取资源对应的processorslotchain的方法">2 lookProcessChain() 创建或获取资源对应的ProcessorSlotChain的方法</h4>
<pre><code class="language-java">// com.alibaba.csp.sentinel.CtSph#lookProcessChain
ProcessorSlot&lt;Object&gt; lookProcessChain(ResourceWrapper resourceWrapper) {
    // 从缓存chainMap中获取
    ProcessorSlotChain chain = chainMap.get(resourceWrapper);
    if (chain == null) {
        synchronized (LOCK) {
            chain = chainMap.get(resourceWrapper);
            if (chain == null) {  // 又是双重检测锁
                // Entry size limit.
                if (chainMap.size() &gt;= Constants.MAX_SLOT_CHAIN_SIZE) {
                    return null;
                }
 
                // 入口本资源对应的chain不存在，则创建一个新的
                chain = SlotChainProvider.newSlotChain();
                Map&lt;ResourceWrapper, ProcessorSlotChain&gt; newMap = new HashMap&lt;ResourceWrapper, ProcessorSlotChain&gt;(
                    chainMap.size() + 1);
                newMap.putAll(chainMap);
                newMap.put(resourceWrapper, chain);
                chainMap = newMap; // 又是CopyOnWrite
            }
        }
    }
    return chain;
}
</code></pre>
<p>虽然每一次请求的ResourceWrapper都是新new的，但是由于它的hashCode() 和 equals() 方法，只会对比 name;</p>
<pre><code class="language-java">public abstract class ResourceWrapper {
 
    protected final String name;
 
    protected final EntryType entryType;
    protected final int resourceType;
 
    @Override
    public int hashCode() {
        return getName().hashCode();
    }
 
    @Override
    public boolean equals(Object obj) {
        if (obj instanceof ResourceWrapper) {
            ResourceWrapper rw = (ResourceWrapper)obj;
            return rw.getName().equals(getName());
        }
        return false;
    }
}
</code></pre>
<p>所以，得出结论：</p>
<ul>
<li><strong>Sentinel会为所有的资源，以资源名为区分，创建对应的ProcessorSlotChain ，并缓存到chainMap中；</strong></li>
<li>ProcessorSlotChain应用级有效，创建后，下次相同名称的Resource请求进入时，将不需要再次创建chain；</li>
</ul>
<h4 id="3-slotchainprovidernewslotchain-处理器插槽链的构建过程">3 SlotChainProvider.newSlotChain() 处理器插槽链的构建过程</h4>
<pre><code class="language-java">// com.alibaba.csp.sentinel.slotchain.SlotChainProvider#newSlotChain
public static ProcessorSlotChain newSlotChain() {
    if (slotChainBuilder != null) {
        return slotChainBuilder.build();
    }
 
    // 默认肯定是得到一个 DefaultSlotChainBuilder
    slotChainBuilder = SpiLoader.loadFirstInstanceOrDefault(SlotChainBuilder.class, DefaultSlotChainBuilder.class);
 
    if (slotChainBuilder == null) {
        slotChainBuilder = new DefaultSlotChainBuilder();
    } else {
        ......
    }
    return slotChainBuilder.build();
}

public class DefaultSlotChainBuilder implements SlotChainBuilder {
 
    @Override
    public ProcessorSlotChain build() {
        // 创建一个 DefaultProcessorSlotChain
        ProcessorSlotChain chain = new DefaultProcessorSlotChain();
 
        // 该方法会通过spi机制从 \META-INF\services\目录下，加载所有的ProcessorSlot类
        List&lt;ProcessorSlot&gt; sortedSlotList = SpiLoader.loadPrototypeInstanceListSorted(ProcessorSlot.class);
        for (ProcessorSlot slot : sortedSlotList) {
            if (!(slot instanceof AbstractLinkedProcessorSlot)) {
                continue;
            }
             
            // 最终创建的
            chain.addLast((AbstractLinkedProcessorSlot&lt;?&gt;) slot);
        }
 
        return chain;
    }
}
</code></pre>
<h4 id="4-spiloaderloadprototypeinstancelistsortedprocessorslotclass通过spi机制加载所有的processorslot插槽类">4 SpiLoader.loadPrototypeInstanceListSorted(ProcessorSlot.class)通过SPI机制加载所有的ProcessorSlot插槽类</h4>
<pre><code class="language-java">// com.alibaba.csp.sentinel.util.SpiLoader#loadPrototypeInstanceListSorted
public static &lt;T&gt; List&lt;T&gt; loadPrototypeInstanceListSorted(Class&lt;T&gt; clazz) {
    try {
        // Not use SERVICE_LOADER_MAP, to make sure the instances loaded are different.
        ServiceLoader&lt;T&gt; serviceLoader = ServiceLoaderUtil.getServiceLoader(clazz);
 
        List&lt;SpiOrderWrapper&lt;T&gt;&gt; orderWrappers = new ArrayList&lt;&gt;();
         
        // SPI机制会从本地的 META-INF/services/ 目录下加载 ProcessorSlot 列表；
        for (T spi : serviceLoader) {
            int order = SpiOrderResolver.resolveOrder(spi);
            // Since SPI is lazy initialized in ServiceLoader, we use online sort algorithm here.
            SpiOrderResolver.insertSorted(orderWrappers, spi, order);
        }
        List&lt;T&gt; list = new ArrayList&lt;&gt;(orderWrappers.size());
        for (int i = 0; i &lt; orderWrappers.size(); i++) {
            list.add(orderWrappers.get(i).spi);
        }
        return list;
    } catch (Throwable t) {
        t.printStackTrace();
        return new ArrayList&lt;&gt;();
    }
}
</code></pre>
<p>本地 META/services/ 目录下的 ProcessorSlot文件定义了9个插槽！</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1658667294348.png" alt="" loading="lazy"></figure>
<h4 id="5-最终构建成的processorslotchain的结构">5 最终构建成的ProcessorSlotChain的结构</h4>
<p>首先，所有的9大ProcessorSlot都继承于一个AbstractLinkedProcessorSlot类：</p>
<pre><code class="language-java">public abstract class AbstractLinkedProcessorSlot&lt;T&gt; implements ProcessorSlot&lt;T&gt; {
 
    private AbstractLinkedProcessorSlot&lt;?&gt; next = null;
 
    // fireEntry的作用主要就是让请求流转到下一个ProcessorSlot(如果存在的话)
    @Override
    public void fireEntry(Context context, ResourceWrapper resourceWrapper, Object obj, int count, boolean prioritized, Object... args)
        throws Throwable {
        if (next != null) {
            next.transformEntry(context, resourceWrapper, obj, count, prioritized, args);
        }
    }
     
    // 所有ProcessorSlot的入口方法，其中会通过模板方法模式，调用各自的entry处理逻辑
    // 而再所有的处理逻辑的最后，都会再调一次 fireEntry() 方法
    void transformEntry(Context context, ResourceWrapper resourceWrapper, Object o, int count, boolean prioritized, Object... args)
    throws Throwable {
        T t = (T)o;
        entry(context, resourceWrapper, t, count, prioritized, args);
    }
}
</code></pre>
<p>经过 next 指向，最终构建出来的 DefaultProcessorSlotChain 如下：</p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1658667303745.png" alt="" loading="lazy"></figure>
<p>综上总结：</p>
<ul>
<li><strong>Sentinel会 为所有的资源，以资源名为区分，创建各自的DefaultProcessorSlotChain，放在缓存 中；</strong></li>
<li><strong>DefaultProcessorSlotChain的 每一个ProcessorSlot插槽都是通过SPI机制从 META/services/ 目录下加载的 ；</strong></li>
<li><strong>每一个ProcessorSlot 其实是一个 AbstractLinkedProcessorSlot 抽象链表处理器插槽，有一个next属性，指向下一个Slot ，当某一个Slot执行完后，会调用 fireEntry() 方法，将请求转到下一个Slot继续执行。</strong></li>
<li><strong>最终完成责任链上所有ProcessorSlot的逻辑！</strong></li>
</ul>
<hr>
<h3 id="四-九大processorslot处理器插槽的工作原理">四 九大ProcessorSlot处理器插槽的工作原理</h3>
<blockquote>
<p>LogSlot插槽是一个边缘插槽，做一些日志记录，所以不算重要，排除在外后，就剩8大插槽，也就是&lt;第一章节&gt;列出的八大插槽：</p>
</blockquote>
<p>数据统计部分 + 规则判断部分</p>
<ul>
<li>
<p>数据统计：</p>
</li>
<li>
<ul>
<li><strong>NodeSelectorSlot</strong>：负责构建簇点链路中的各个节点（DefaultNode），形成NodeTree</li>
<li><strong>ClusterBuilderSlot</strong>：负责构建某个资源的ClusterNode（具体的DefaultNode和ClusterNode的区别见下文）</li>
<li><strong>StatisticSlot</strong>：负责实时统计请求的各种调用信息，如来源信息、请求次数、运行信息等；</li>
</ul>
</li>
<li>
<p>规则判断：</p>
</li>
<li>
<ul>
<li><strong>AuthoritySlot</strong>：授权规则判断（来源控制）</li>
<li><strong>SystemSlot</strong>：系统保护规则判断，当系统资源使用量达到一定程度后，拒绝新的请求进入等；</li>
<li><strong>ParamFlowSlot</strong>：热点参数限流规则判断</li>
<li><strong>FlowSolt</strong>：普通限流规则判断</li>
<li><strong>DegradeSlot</strong>：降级规则判断</li>
</ul>
</li>
</ul>
<p>其实，当Sentinel的整体架构，和调用逻辑梳理清楚后，每一个责任链节点的处理逻辑就很简单了</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sentinel限流熔断降级——知识点总结]]></title>
        <id>https://tinaxiawuhao.github.io/post/XPUt_T_-A/</id>
        <link href="https://tinaxiawuhao.github.io/post/XPUt_T_-A/">
        </link>
        <updated>2022-07-06T12:43:19.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>Sentinei官网地址：https://sentinelguard.io/zh-cn/docs/quick-start.html</p>
<p>Sentinel Github地址：https://github.com/alibaba/Sentinel/wiki</p>
<p>Sentinel生产级使用：https://github.com/alibaba/Sentinel/wiki/在生产环境中使用-Sentinel</p>
</blockquote>
<h3 id="一-sentinel是什么为什么要引入sentinel">一 Sentinel是什么,为什么要引入Sentinel</h3>
<h4 id="1-什么是服务雪崩">1 什么是“服务雪崩”？</h4>
<p>在微服务架构中，存在着大量的服务间调用，有时候，由于某个服务发生了故障，而<strong>导致调用它的服务的资源得不到正常释放</strong>，从而也发生故障，故障不断传播，最终导致整个微服务无法对外提供服务，这就发生了“服务雪崩”！</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1658666676257.png" alt="" loading="lazy"></figure>
<h4 id="2-服务雪崩如何解决">2 “服务雪崩”如何解决？</h4>
<p>解决“服务雪崩”的核心点有2个：尽量控制流量，不要让服务因为过载还出现故障；当一个服务已经出现故障时，不要让故障在微服务整个调用链路中进行传播！</p>
<p>针对上面两点，“服务雪崩”就有了常见的2大类解决方案：</p>
<ul>
<li>
<p>流量控制，避免出现故障：</p>
</li>
<li>
<ul>
<li><strong>流量控制</strong>：在微服务调用链路的各个核心资源点，进行流量控制，超出的流量直接不要放行，以对目标资源进行直接保护！</li>
</ul>
</li>
<li>
<p>出现故障时，防止故障传播：</p>
</li>
<li>
<ul>
<li><strong>超时处理</strong>：设置超时时间，超过设定时间就返回报错信息，做对应处理，防止“无休止”等待！</li>
<li><strong>服务隔离</strong>：限定每个业务能使用的线程数，避免耗尽整个服务的所有线程资源，保护其他业务！</li>
<li><strong>熔断降级</strong>：通过断路器统计服务调用的“异常数”或“异常比例”，如果超出设定阈值，则直接熔断，后续一定时间内的请求到达时，直接返回降级处理的结果，而不真正去调用目标服务！</li>
</ul>
</li>
</ul>
<p>而上面所说的这一系列解决方案，Sentinel都为我们提供了实现，所以我们选择Sentinel！</p>
<h4 id="3-阿里的sentinel和网飞的hystrix的对比">3 阿里的Sentinel和网飞的Hystrix的对比？</h4>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1658666694073.png" alt="" loading="lazy"></figure>
<blockquote>
<p>其实很明显，Sentinel比Hystrix强大很多，而且Hystrix已经进入维护期不再更新了，以后的微服务项目中肯定是选择Sentinel！</p>
</blockquote>
<hr>
<h3 id="二-sentinel的简单使用和">二 Sentinel的简单使用和</h3>
<p>首先虽然Sentinel是作为SpringCloud Alibaba的重要组件而出名，但是并不是强依赖于SpringCloud Alibaba！</p>
<p>独立使用Sentinel文档：https://sentinelguard.io/zh-cn/docs/quick-start.html</p>
<p>在spring-cloud-alibaba框架中使用：https://github.com/alibaba/spring-cloud-alibaba/wiki/Sentinel</p>
<h4 id="1-在spring-cloud-alibaba框架中的简单使用sentinel">1 在spring-cloud-alibaba框架中的简单使用Sentinel</h4>
<ul>
<li>引入依赖starter：</li>
</ul>
<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<ul>
<li>启动Sentinel Dashboard控制台：</li>
</ul>
<p>https://sentinelguard.io/zh-cn/docs/dashboard.html</p>
<pre><code class="language-shell"># Sentinel的启动非常简单，java -jar sentinel-dashboard.jar 运行即可：
java -Dserver.port=8080 -Dcsp.sentinel.dashboard.server=localhost:8080 -Dproject.name=sentinel-dashboard -jar sentinel-dashboard.jar
</code></pre>
<ul>
<li>在我们的项目文件中配置sentinel-dashboard控制台的地址：</li>
</ul>
<pre><code class="language-yaml">spring:
  cloud:
    sentinel:
      transport:
        dashboard: localhost:8080
</code></pre>
<h4 id="2-开启sentinel对feign调用的支持">2 开启Sentinel对Feign调用的支持</h4>
<p>除了上面的依赖和配置外，我们还需要增加一下配置：</p>
<p>如果我们引入的Feign是通过 spring-cloud-starter-openfeign 引入Feign的，那么 Sentinel starter 中的自动配置类就会生效！</p>
<ul>
<li>此时，我们只需要在 application.yml 配置文件中开启 Sentinel 对 Feign 的支持即可：</li>
</ul>
<pre><code class="language-yaml">feign:
  sentinel:
    enabled: true # 开启feign对sentinel的支持
</code></pre>
<h4 id="3-sentinel-dashboard-的配置持久化到-nacos-配置中心">3 Sentinel Dashboard 的配置持久化到 Nacos 配置中心</h4>
<p>https://github.com/alibaba/Sentinel/wiki/在生产环境中使用-Sentinel</p>
<p>Sentinel Dashboard中的所有配置在默认情况下，刷新后就会丢失，那么实际生产中肯定是可允许的，所以我们必须要想办法将Sentinel的配置持久化；</p>
<p><strong>而正好Nacos就提供了配置的“持久化”与“监听机制”，所以我们就选择通过 Nacos 完成 Sentinel 的配置持久化！（push模式，也是生产中最常用的）</strong></p>
<ul>
<li>在项目的pom.xml中增加 sentinel-datasource-nacos 的依赖，开启对nacos的配置中心的监听：</li>
</ul>
<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt;
    &lt;artifactId&gt;sentinel-datasource-nacos&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<ul>
<li>在 application.yml 中增加 sentinel 的数据源配置：</li>
</ul>
<pre><code class="language-xml">spring:
  application:
    name: orderservice
  cloud:
    sentinel:
      transport:
        dashboard: localhost:8080 # sentinel控制台地址
      web-context-unify: false # 关闭context整合
      datasource:
        flow:
          nacos:
            server-addr: localhost:8848 # nacos地址
            dataId: orderservice-flow-rules
            groupId: SENTINEL_GROUP
            rule-type: flow # 还可以是：degrade、authority、param-flow
             
feign:
  sentinel:
    enabled: true # 开启feign对sentinel的支持
</code></pre>
<h4 id="4-sentinel的三种规则配置管理模式">4 Sentinel的三种规则配置管理模式</h4>
<ul>
<li>
<p><strong>原始模式</strong>：如果我们简单使用Dashboard，不做任何修改，就是采用的这种模式：</p>
<p>​    客户端在启动时，会同时启动一个ServerSocket，默认端口为：8719（如果被占用，尝试3次后+1，继续尝试），告诉Dashboard，当Dashboard中的配置有变化时，通过API接口告诉我们的服务中的Sentinel客户端，Sentinel将这些配置存到内存中，服务重启即丢失，<strong>该模式只能用于简单测试，一定不能用于生产环境！</strong></p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1658666719119.png" alt="" loading="lazy"></figure>
<p>可从Env类一路向下研究，就可以知道逻辑：</p>
</li>
</ul>
<pre><code class="language-java"> public class Env {
     public static final Sph sph = new CtSph();
     static {
         // If init fails, the process will exit.
         InitExecutor.doInit();
     }
 }
</code></pre>
<ul>
<li>
<p><strong>Pull模式</strong>：Sentinel客户端（我们的应用服务）向远端的配置管理中心主动定期轮询拉取规则，更新到内存缓存，同时写入到本地磁盘文件，这样的话也可以实现持久化，但是数据一致性、实时性不太好，而且大量的轮询对服务性能又有影响！</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1658666739217.png" alt="" loading="lazy"></figure>
</li>
</ul>
<pre><code class="language-java"> // 需要在客户端注册数据源：
 // —将对应的读数据源注册至对应的 RuleManager，
 // ——将写数据源注册至 transport 的 WritableDataSourceRegistry 中。
 public class FileDataSourceInit implements InitFunc {
  
     @Override
     public void init() throws Exception {
         String flowRulePath = &quot;xxx&quot;;
  
         ReadableDataSource&lt;String, List&lt;FlowRule&gt;&gt; ds = new FileRefreshableDataSource&lt;&gt;(
                 flowRulePath, source -&gt; JSON.parseObject(source, new TypeReference&lt;List&lt;FlowRule&gt;&gt;() {})
         );
         // 将可读数据源注册至 FlowRuleManager.
         FlowRuleManager.register2Property(ds.getProperty());
  
         WritableDataSource&lt;List&lt;FlowRule&gt;&gt; wds = new FileWritableDataSource&lt;&gt;(flowRulePath, this::encodeJson);
         // 将可写数据源注册至 transport 模块的 WritableDataSourceRegistry 中.
         // 这样收到控制台推送的规则时，Sentinel 会先更新到内存，然后将规则写入到文件中.
         WritableDataSourceRegistry.registerFlowDataSource(wds);
     }
  
     private &lt;T&gt; String encodeJson(T t) {
         return JSON.toJSONString(t);
     }
 }
</code></pre>
<ul>
<li>
<p><strong>Push模式：生产环境最推荐的一种模式，需要依赖于外部的注册中心，nacos、zookeeper等</strong></p>
</li>
<li>
<ul>
<li>
<p>我们在Sentinel Dashboard中修改的规则配置，首先会先持久化到我们的配置中心中（配置中心已经实现了持久化）；</p>
</li>
<li>
<p>sentinel客户端（我们的应用程序）是从配置中心获取数据。</p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1658666808514.png" alt="" loading="lazy"></figure>
</li>
</ul>
</li>
<li>
<p>具体的Push模式（nacos）的实现已经在“第3段”有讲述；</p>
</li>
<li>
<p>但是暂时默认开源的Sentinel Dashboard中并没有直接提供对nacos等注册中心的直接支持，得自己改造，或者直接去Nacos中盲配！</p>
</li>
</ul>
<hr>
<h3 id="三-sentinel-dashboard中得各种规则配置与解读">三 Sentinel Dashboard中得各种规则配置与解读</h3>
<p>首先，当我们第一次打开Sentinel Dashboard时，我们会发现控制台空空如也，这是由于Sentinel使用的是懒加载，所以，我们需要先调用一次服务的接口，然后才可以看到“簇点链路”：</p>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1658666865289.png" alt="" loading="lazy"></figure>
<p>之后我们就可以开始愉快的配置啦！</p>
<p>本章节，不做具体配置和调试，主要是对所有的配置进行解释，加深印象！</p>
<h4 id="1-流控规则见名知意流量控制">1 流控规则：见名知意，流量控制</h4>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1658666880890.png" alt="" loading="lazy"></figure>
<ul>
<li>
<p><strong>2种阈值类型</strong>：</p>
</li>
<li>
<ul>
<li><strong>QPS</strong>：对单位时间内的请求数量进行统计，控制流量；</li>
<li><strong>线程数</strong>：属于服务隔离（线程隔离），Sentinel默认使用的是“信号量隔离”，而Hystrix默认采用的是“线程池隔离”</li>
<li>
<ul>
<li>
<ul>
<li>信号量隔离：通过“信号量计数器”实现，开销小，但是隔离性一般；适合“扇出”大的场景，如gateway就是扇出比较大的场景；</li>
<li>线程池隔离：基于线程池实现，额外开销大，但是隔离性更强；适合于“扇出”小的场景；</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>3种流控模式：</strong></p>
</li>
<li>
<ul>
<li><strong>直接</strong>：流量统计对象 和 限流对象 都是当前资源本身；</li>
<li><strong>关联</strong>：流量统计的对象是其它资源，限流的对象却是自己；</li>
<li><strong>链路</strong>：只统计从指定链路访问本资源的请求，触发阈值时，也只对指定的链路进行限流；</li>
</ul>
</li>
</ul>
<blockquote>
<p>注意，默认情况下，所有的请求的入口链路都是默认的： sentinel_default_context ，链路模式是不好使用的，所以，如果要使用链路模式，需要关闭“context统一入口配置”</p>
<pre><code class="language-yaml">spring:
  application:
    name: orderservice
  cloud:
    sentinel:
      transport:
        dashboard: localhost:8080 # sentinel控制台地址
      web-context-unify: false # 关闭context统一入口
</code></pre>
</blockquote>
<ul>
<li>
<p><strong>3种流控效果</strong>：</p>
</li>
<li>
<ul>
<li><strong>快速失败</strong>：达到限流阈值后，直接抛出FlowException异常；</li>
<li><strong>WarmUp预热</strong>：与“快速失败”类似，达到阈值后，也是直接抛出FlowException异常，但是该模式下的阈值是变化的，默认从一个最大值的1/3，逐渐增加到最大值；常用于服务的预热启动阶段，防止服务流量一下子打到最大，导致一些非常态问题发生；</li>
<li><strong>排队等待（流量整形）</strong>：请求到达后，放入一个队列中，按照 1/QPS 的速度进行消费处理，在队列中的请求等待时间，最大不可以超过“设定的超时时间”！</li>
</ul>
</li>
</ul>
<h4 id="2-热点规则热点限流规则-特殊的流控规则">2 热点规则（热点限流规则）—— 特殊的流控规则</h4>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1658666900562.png" alt="" loading="lazy"></figure>
<p>由于Sentinel默认知乎将Springmvc的注解如@RequestMapping等注册为资源，所以当我们需要定义其它资源时，需要手动使用@SentinelResource注解去定义：</p>
<pre><code class="language-java">@SentinelResource(&quot;hot&quot;)
public Order queryOrderById(Long orderId) {
    // 1.查询订单
    Order order = orderMapper.findById(orderId);
    // 2.用Feign远程调用
    User user = userClient.findById(order.getUserId());
    // 3.封装user到Order
    order.setUser(user);
    // 4.返回
    return order;
}
</code></pre>
<p>之后，当我们调用过一次后，就可以看到“hot”这个资源了，而后对它进行流控配置：</p>
<blockquote>
<p>上图的热点流控规则解读为：对于hot这个资源，对于它的第0个请求参数，允许它1秒内相同值的最大请求数为5，同时，包含一个特殊情况，对于value=101，允许的QPS阈值为10。</p>
</blockquote>
<h4 id="3-降级规则熔断降级">3 降级规则（熔断降级）</h4>
<p>熔断降级通常配置 Feign 服务间调用使用，我们通常会定义两个类 UserClient代理接口 + UserClientFallbackFactory降级工厂类：</p>
<p>UserClient：</p>
<pre><code class="language-java">@FeignClient(value = &quot;userservice&quot;, fallbackFactory = UserClientFallbackFactory.class)
public interface UserClient {
 
    @GetMapping(&quot;/user/{id}&quot;)
    User findById(@PathVariable(&quot;id&quot;) Long id);
}
</code></pre>
<p>UserClientFallbackFactory：</p>
<pre><code class="language-java">@Slf4j
@Component
public class UserClientFallbackFactory implements FallbackFactory&lt;UserClient&gt; {
    @Override
    public UserClient create(Throwable throwable) {
        return new UserClient() {
            @Override
            public User findById(Long id) {
                log.info(&quot;请求用户数据失败&quot;);
                return new User().setId(100L).setUsername(&quot;default&quot;).setAddress(&quot;defaultAddress&quot;);
            }
        };
    }
}
</code></pre>
<figure data-type="image" tabindex="9"><img src="https://tinaxiawuhao.github.io/post-images/1658666913571.png" alt="" loading="lazy"></figure>
<p>上图的熔断降级规则解读为：</p>
<p>当ResponseTime时间<strong>超过400ms时为慢调用，统计最近10000ms内的请求，如果请求总数超过10次，且慢调用的比例达到0.6，则触发熔断</strong>OPEN；</p>
<p>熔断时常为5秒；</p>
<p><strong>5秒后，进入HALF-OPEN状态，放行一次请求做测试</strong>，如果OK，则断路器重新CLOSE闭合，开始正常工作！<br>
<img src="https://tinaxiawuhao.github.io/post-images/1658666926145.png" alt="" loading="lazy"></p>
<p><strong>4、授权规则（对请求的来源做控制）</strong></p>
<p>有时候，我们担心由于服务暴露，导致有些请求会越过Gateway，而直接访问我们的服务，这时候，我们就可以通过Sentinel授权只允许从Gateway过来的请求访问我们的服务。</p>
<figure data-type="image" tabindex="10"><img src="https://tinaxiawuhao.github.io/post-images/1658666936655.png" alt="" loading="lazy"></figure>
<p>在gateway中通过filter为经过的请求增加一个header值 origin = gateway：</p>
<pre><code class="language-yaml">spring:
  application:
    name: gateway
  cloud:
    nacos:
      server-addr: localhost:8848 # nacos地址
    gateway:
      routes:
        - id: user-service # 路由标示，必须唯一
          uri: lb://userservice # 路由的目标地址
          predicates: # 路由断言，判断请求是否符合规则
            - Path=/user/** # 路径断言，判断路径是否是以/user开头，如果是则符合
        - id: order-service
          uri: lb://orderservice
          predicates:
            - Path=/order/**
      default-filters:
        - AddRequestHeader=origin,gateway
</code></pre>
<p>在项目中注入一个RequestOriginParser：</p>
<pre><code class="language-java">@Component
public class HeaderOriginParser implements RequestOriginParser {
    @Override
    public String parseOrigin(HttpServletRequest request) {
        // 1.获取请求头
        String origin = request.getHeader(&quot;origin&quot;);
        // 2.非空判断
        if (StringUtils.isEmpty(origin)) {
            origin = &quot;blank&quot;;
        }
        return origin;
    }
}
</code></pre>
<p>最后，配置一条授权规则白名单：</p>
<figure data-type="image" tabindex="11"><img src="https://tinaxiawuhao.github.io/post-images/1658666945938.png" alt="" loading="lazy"></figure>
<blockquote>
<p>上图授权规则解读：只允许请求头中，origin = gateway 的请求通过！</p>
</blockquote>
<hr>
<h3 id="四-补充其他知识点">四 补充其他知识点</h3>
<h4 id="1-默认情况下发生限流-授权拦截时会直接抛出异常到调用方很不友好最好要自定义异常返回结果">1 默认情况下，发生限流、授权拦截时，会直接抛出异常到调用方，很不友好，最好要自定义异常返回结果</h4>
<p>需要为 BlockExceptionHandler 写一个实现：</p>
<pre><code class="language-java">@Component
public class SentinelExceptionHandler implements BlockExceptionHandler {
    @Override
    public void handle(HttpServletRequest request, HttpServletResponse response, BlockException e) throws Exception {
        String msg = &quot;未知异常&quot;;
        int status = 429;
 
        if (e instanceof FlowException) {
            msg = &quot;请求被限流了&quot;;
        } else if (e instanceof ParamFlowException) {
            msg = &quot;请求被热点参数限流&quot;;
        } else if (e instanceof DegradeException) {
            msg = &quot;请求被降级了&quot;;
        } else if (e instanceof AuthorityException) {
            msg = &quot;没有权限访问&quot;;
            status = 401;
        }
 
        response.setContentType(&quot;application/json;charset=utf-8&quot;);
        response.setStatus(status);
        response.getWriter().println(&quot;{\&quot;msg\&quot;: &quot; + msg + &quot;, \&quot;status\&quot;: &quot; + status + &quot;}&quot;);
    }
}
</code></pre>
<h4 id="2-不同的流控规则使用的技术实现方案不一样">2 不同的流控规则，使用的技术实现方案不一样</h4>
<p>对于限流的需求，常见的实现方案有多种，滑动时间窗口、令牌桶、漏桶，这三种有各自擅长的业务场景，而Sentinel支持的业务场景很多，在不同的场景下，就选择了不同的限流实现。</p>
<ul>
<li>快速失败、WarmUp预热：滑动时间窗口</li>
<li>热点限流：令牌桶</li>
<li>排队等待：漏桶</li>
</ul>
<p>具体的限流实现，请参阅另一篇文章：<a href="http://tinaxiawuhao.github.io/post/xUda2KT1A/">Sentinel源码拓展之——限流的各种实现方式</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[openfeign-ribbon核心源码剖析]]></title>
        <id>https://tinaxiawuhao.github.io/post/Y45PUcltI/</id>
        <link href="https://tinaxiawuhao.github.io/post/Y45PUcltI/">
        </link>
        <updated>2022-07-05T12:39:41.000Z</updated>
        <content type="html"><![CDATA[<h3 id="一-总结前置">一、总结前置：</h3>
<h4 id="1-ribbonfeignopenfeign三者的对比">1 ribbon,feign,openfeign三者的对比</h4>
<p>我们现在工作中现在几乎都是直接使用openfeign，而我们很有必要了解一下，ribbon、feign、openfeign三者之间的关系！</p>
<ul>
<li><strong>ribbon：<strong>ribbon是netflix开源的客户端负载均衡组件，可以</strong>调用注册中心获取服务列表，并通过负载均衡算法挑选一台Server</strong>；</li>
<li>**feign：**feign也是netflix开源的，<strong>是对ribbon的一层封装，通过接口的方式使用，更加优雅</strong>，不需要每次都去写restTemplate，只需要定义一个接口来使用；<strong>但是Feign不支持springmvc的注解；</strong></li>
<li><strong>openfeign：<strong>是</strong>对feign的进一步封装，使其能够支持springmvc注解，如@GetMapping等</strong>，使用起来更加方便和优雅！</li>
</ul>
<h4 id="2-工作中都是如何使用openfeign">2 工作中都是如何使用openfeign</h4>
<pre><code class="language-java">// 想要使用openfeign，必须要在启动类增加@EnableFeignClient注解，否则启动报错
@FeignClient(&quot;feign-provider&quot;)
public interface OrderService {
 
    @GetMapping(&quot;/order/get/{id}&quot;)
    public String getById(@PathVariable(&quot;id&quot;) String id);
}
</code></pre>
<h4 id="3-openfeign与ribbon如何分工">3 openfeign与ribbon如何分工</h4>
<ul>
<li><strong>openfeign通过动态代理</strong>的方式，对feignclient注解修饰的类进行动态代理，<strong>拼接成临时URL：http://feign-provider/order/get/100</strong>，交给ribbon</li>
<li><strong>ribbon通过自己的拦截器</strong>，截取出serviceName<strong>在服务注册表中找到对应的serverList，并通过负载均衡策略挑选一台Server</strong>，<strong>拼接成最终的URL：http://10.206.73.156:1111/order/get/100</strong>，交还给feign；</li>
<li>最后，<strong>feign通过自己封装的Client对目标地址发起调用</strong>，并获得返回结果；（Client是对原生 java.net 中的URL类的封装，实现远程调用）</li>
</ul>
<hr>
<h3 id="二-核心代码openfeign生成的动态代理类是啥">二 核心代码——Openfeign生成的动态代理类是啥</h3>
<h4 id="1-启动类必须增加enablefeignclient那我们就从这里入口">1 启动类必须增加@EnableFeignClient，那我们就从这里入口</h4>
<pre><code class="language-java">@EnableFeignClients
@Import(FeignClientsRegistrar.class)
// 遇到import(Registrar)，我们就去看它的registerBeanDefinitions()方法：
public void registerBeanDefinitions(AnnotationMetadata metadata,
      BeanDefinitionRegistry registry) {
   registerDefaultConfiguration(metadata, registry);
    
   // 注册FeignClient，其实FeignClient就是我们需要的动态代理类
   registerFeignClients(metadata, registry);  
}

public void registerFeignClients(AnnotationMetadata metadata,BeanDefinitionRegistry registry) {
   ......
   // 定义过滤器，把加了@FeignClient注解的接口都过滤出来
   AnnotationTypeFilter annotationTypeFilter = new AnnotationTypeFilter(FeignClient.class);
   ...过滤逻辑...
 
   for (String basePackage : basePackages) {
      Set&lt;BeanDefinition&gt; candidateComponents = scanner
            .findCandidateComponents(basePackage);
      for (BeanDefinition candidateComponent : candidateComponents) {
         if (candidateComponent instanceof AnnotatedBeanDefinition) {
            // verify annotated class is an interface
            AnnotatedBeanDefinition beanDefinition = (AnnotatedBeanDefinition) candidateComponent;
            AnnotationMetadata annotationMetadata = beanDefinition.getMetadata();
            Assert.isTrue(annotationMetadata.isInterface(),
                  &quot;@FeignClient can only be specified on an interface&quot;);
 
            Map&lt;String, Object&gt; attributes = annotationMetadata
                  .getAnnotationAttributes(
                        FeignClient.class.getCanonicalName());
 
            String name = getClientName(attributes);
            registerClientConfiguration(registry, name,
                  attributes.get(&quot;configuration&quot;));
 
            // 将为每一个过滤出来的接口，注册FeignClient
            registerFeignClient(registry, annotationMetadata, attributes);
         }
      }
   }
}

private void registerFeignClient(BeanDefinitionRegistry registry,
      AnnotationMetadata annotationMetadata, Map&lt;String, Object&gt; attributes) {
   String className = annotationMetadata.getClassName();
   BeanDefinitionBuilder definition = BeanDefinitionBuilder
         .genericBeanDefinition(FeignClientFactoryBean.class);
    
   ...目标FactoryBean为FeignClientFactoryBean...
   ...FactoryBean一般用于定制化一些特殊的Bean，spring会调用它的getObject接口...
 
   BeanDefinitionHolder holder = new BeanDefinitionHolder(beanDefinition, className,
         new String[] { alias });
   BeanDefinitionReaderUtils.registerBeanDefinition(holder, registry);
}
</code></pre>
<h4 id="2-见名知意feignclient的工厂beanfeignclientfactorybeangetobject方法">2 见名知意FeignClient的工厂bean：FeignClientFactoryBean.getObject()方法</h4>
<pre><code class="language-java">class FeignClientFactoryBean{
    @Override
    public Object getObject() throws Exception {
       return getTarget();
    }
     
    &lt;T&gt; T getTarget() {
       FeignContext context = this.applicationContext.getBean(FeignContext.class);
       Feign.Builder builder = feign(context);
 
       // 当我们不为@FeignClient()注解配置url属性时
       // 这里同时会根据注解，拼接出url前缀，如：http://feign-provider
       if (!StringUtils.hasText(this.url)) {
          if (!this.name.startsWith(&quot;http&quot;)) {
             this.url = &quot;http://&quot; + this.name;
          }
          else {
             this.url = this.name;
          }
          this.url += cleanPath();
          return (T) loadBalance(builder, context,
                new HardCodedTarget&lt;&gt;(this.type, this.name, this.url));
       }
        
       ...如果我们为@FeignClient()注解配置url属性之后的逻辑...
    }
}

protected &lt;T&gt; T loadBalance(Feign.Builder builder, FeignContext context,
      HardCodedTarget&lt;T&gt; target) {
   // 从容器中获取一个类型为Client的bean，那么IOC容器中肯定有一个这样的Bean
   Client client = getOptional(context, Client.class);
   if (client != null) {
      builder.client(client);
      Targeter targeter = get(context, Targeter.class);
      return targeter.target(this, builder, context, target);
   }
 
   // 如果找不到类型为Client的Bean就是有问题的啦！
   throw new IllegalStateException(
         &quot;No Feign Client for loadBalancing defined. Did you forget to include spring-cloud-starter-netflix-ribbon?&quot;);
}
</code></pre>
<h4 id="3-容器中类型为client的bean是谁">3 容器中类型为Client的Bean是谁</h4>
<p>此时还是启动阶段，我们去看看有哪些bean会被注入，在 spring.factories 中，我们会找到两个自动配置类：</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1658666477690.png" alt="" loading="lazy"></figure>
<p>这两个类，很关键，都会往容器中注入负载均衡的Client Bean，但是只会有一个成功，</p>
<p>FeignRibbonClientAutoCOnfiguration类：</p>
<pre><code class="language-java">@ConditionalOnClass({ ILoadBalancer.class, Feign.class })
@ConditionalOnProperty(value = &quot;spring.cloud.loadbalancer.ribbon.enabled&quot;,matchIfMissing = true)
@Configuration(proxyBeanMethods = false)
// 重点1：在FeignAutoConfiguration之前装载配置
@AutoConfigureBefore(FeignAutoConfiguration.class) 
@EnableConfigurationProperties({ FeignHttpClientProperties.class })
 
@Import({ HttpClientFeignLoadBalancedConfiguration.class,
      OkHttpFeignLoadBalancedConfiguration.class,
      DefaultFeignLoadBalancedConfiguration.class }) // 重点2：
public class FeignRibbonClientAutoConfiguration {
    ...非重点...
}

@Configuration(proxyBeanMethods = false)
class DefaultFeignLoadBalancedConfiguration {
 
   @Bean
   @ConditionalOnMissingBean  // 如果Client类型的bean已经存在，则不执行
   public Client feignClient(CachingSpringLoadBalancerFactory cachingFactory,
         SpringClientFactory clientFactory) {
      return new LoadBalancerFeignClient(new Client.Default(null, null), cachingFactory,
            clientFactory);
   }
 
}
</code></pre>
<p>FeignLoadBalancerAutoConfiguration类：</p>
<pre><code class="language-java">@ConditionalOnClass(Feign.class)
@ConditionalOnBean(BlockingLoadBalancerClient.class)
@AutoConfigureBefore(FeignAutoConfiguration.class)
// 重点1：在FeignRibbonClientAutoConfiguration之后装载配置
@AutoConfigureAfter(FeignRibbonClientAutoConfiguration.class) 
@EnableConfigurationProperties(FeignHttpClientProperties.class)
@Configuration(proxyBeanMethods = false)
 
@Import({ HttpClientFeignLoadBalancerConfiguration.class,
      OkHttpFeignLoadBalancerConfiguration.class,
      DefaultFeignLoadBalancerConfiguration.class })  // 重点2：
public class FeignLoadBalancerAutoConfiguration {
       ...非重点...
}

@Configuration(proxyBeanMethods = false)
class DefaultFeignLoadBalancerConfiguration {
 
   @Bean
   @ConditionalOnMissingBean  // 如果Client类型的bean已经存在，则不执行
   public Client feignClient(BlockingLoadBalancerClient loadBalancerClient) {
      return new FeignBlockingLoadBalancerClient(new Client.Default(null, null),
            loadBalancerClient);
   }
 
}
</code></pre>
<p>到这里就非常清晰了：</p>
<ul>
<li>通过spring.factories注入了两个配置类，并通过 @AutoConfigureBefore 和 @AutoConfigureAfter强制了两个配置类的装载顺序！</li>
<li>这两个配置类各import 了 另一个配置类：DefaultFeignLoadBalancedConfiguration（注入：LoadBalancerFeignClient） 和 DefaultFeignLoadBalancerConfiguration（注入：FeignBlockingLoadBalancerClient），但是由于@ConditionalOnMissingBean注解，只有一个前面那个会注入成功！</li>
<li>所以，结论就是：IOC容器中的“Client”类型的 Bean 为 “LoadBalancerFeignClient”</li>
</ul>
<p>所以，<strong>最终的结论就是：Openfeign通过的动态代理，为每个“@FeignClient”注解修饰的接口生成一个类型为 “LoadBalancerFeignClient”的代理类。</strong></p>
<hr>
<h3 id="三-feignclient代理类执行时是如何使用ribbon的">三 FeignClient代理类执行时，是如何使用Ribbon的</h3>
<h4 id="1-当执行loadbalancerfeignclientexecute方法时">1 当执行LoadBalancerFeignClient.execute()方法时：</h4>
<pre><code class="language-java">// org.springframework.cloud.openfeign.ribbon.LoadBalancerFeignClient#execute
public Response execute(Request request, Request.Options options) throws IOException {
   try {
      URI asUri = URI.create(request.url());
      String clientName = asUri.getHost();
      URI uriWithoutHost = cleanUrl(request.url(), clientName);
      FeignLoadBalancer.RibbonRequest ribbonRequest = new FeignLoadBalancer.RibbonRequest(
            this.delegate, request, uriWithoutHost);
 
      // 可以获取到nacos的一些信息
      IClientConfig requestConfig = getClientConfig(options, clientName);
       
      // lbClient(clientName)：可以获得具体的代理类，每个@FeignClient修饰的接口代理类时独立的
      return lbClient(clientName)
            .executeWithLoadBalancer(ribbonRequest, requestConfig).toResponse();
   }
   catch (ClientException e) {
      ......
   }
}
</code></pre>
<p>我们可以很清楚的看到，这里肯定会要用到Ribbon；</p>
<h4 id="2-通过负载均衡器执行调用并返回结果">2 通过负载均衡器，执行调用，并返回结果</h4>
<pre><code class="language-java">// com.netflix.client.AbstractLoadBalancerAwareClient#executeWithLoadBalancer(...)
public T executeWithLoadBalancer(final S request, final IClientConfig requestConfig) throws ClientException {
    LoadBalancerCommand&lt;T&gt; command = buildLoadBalancerCommand(request, requestConfig);
 
    try {
        return command.submit(  // 这步会返回具体的，负载均衡选定好的Server
            new ServerOperation&lt;T&gt;() {
                @Override
                public Observable&lt;T&gt; call(Server server) {  // submit选好的Server作为入参
                    URI finalUri = reconstructURIWithServer(server, request.getUri());
                    S requestForServer = (S) request.replaceUri(finalUri);
                    try {
                        return Observable.just(AbstractLoadBalancerAwareClient.this.execute(requestForServer, requestConfig));
                    } 
                    catch (Exception e) {
                        return Observable.error(e);
                    }
                }
            })
            .toBlocking()
            .single();
    } catch (Exception e) {
        ......
    }
}

// com.netflix.loadbalancer.reactive.LoadBalancerCommand#submit
public Observable&lt;T&gt; submit(final ServerOperation&lt;T&gt; operation) {
    final ExecutionInfoContext context = new ExecutionInfoContext();
    ......
    final int maxRetrysSame = retryHandler.getMaxRetriesOnSameServer();
    final int maxRetrysNext = retryHandler.getMaxRetriesOnNextServer();
 
    // selectServer()方法会通过负载均衡选择一台Server
    Observable&lt;T&gt; o = (server == null ? selectServer() : Observable.just(server))
            .concatMap(new Func1&lt;Server, Observable&lt;T&gt;&gt;() {
                ......
            });
}
</code></pre>
<h4 id="3-selectserver具体方法">3 selectServer()具体方法</h4>
<pre><code class="language-java">// com.netflix.loadbalancer.reactive.LoadBalancerCommand#selectServer
private Observable&lt;Server&gt; selectServer() {
    return Observable.create(new OnSubscribe&lt;Server&gt;() {
        @Override
        public void call(Subscriber&lt;? super Server&gt; next) {
            try {
                Server server = loadBalancerContext.getServerFromLoadBalancer(loadBalancerURI, loadBalancerKey);   
                next.onNext(server);
                next.onCompleted();
            } catch (Exception e) {
                next.onError(e);
            }
        }
    });
}
</code></pre>
<h4 id="4-这里将使用到非常重要的一个zoneawareloadbalancer">4 这里将使用到非常重要的一个ZoneAwareLoadBalancer</h4>
<pre><code class="language-java">// com.netflix.loadbalancer.LoadBalancerContext#getServerFromLoadBalancer
public Server getServerFromLoadBalancer(@Nullable URI original, @Nullable Object loadBalancerKey) throws ClientException {
    String host = null;
    int port = -1;
    if (original != null) {
        host = original.getHost();
    }
    if (original != null) {
        Pair&lt;String, Integer&gt; schemeAndPort = deriveSchemeAndPortFromPartialUri(original);        
        port = schemeAndPort.second();
    }
 
    // 关键一步，获得了一个ILoadBalancer
    ILoadBalancer lb = getLoadBalancer();
    if (host == null) {
        // 重要：这里其实获得的是ZoneAwareLoadBalancer类的Bean
        if (lb != null){  
            Server svc = lb.chooseServer(loadBalancerKey);
            if (svc == null){
                throw new ClientException(ClientException.ErrorType.GENERAL,
                        &quot;Load balancer does not have available server for client: &quot;
                                + clientName);
            }
            host = svc.getHost();
            return svc;
        } else {
            ......
        }
    } else {
        ......
    }
    return new Server(host, port);
}

// com.netflix.loadbalancer.BaseLoadBalancer#chooseServer
public Server chooseServer(Object key) {
    if (!ENABLED.get() || getLoadBalancerStats().getAvailableZones().size() &lt;= 1) {
        logger.debug(&quot;Zone aware logic disabled or there is only one zone&quot;);
        return super.chooseServer(key);
    }
    ...其它分支在国内一般不会走，没有zone的概念...
}

// com.netflix.loadbalancer.BaseLoadBalancer#chooseServer
public Server chooseServer(Object key) {
    if (counter == null) {
        counter = createCounter();
    }
    counter.increment();
    if (rule == null) {
        return null;
    } else {
        try {
            return rule.choose(key); // PredicateBasedRule
        } catch (Exception e) {
            return null;
        }
    }
}

// com.netflix.loadbalancer.PredicateBasedRule#choose
public Server choose(Object key) {
    ILoadBalancer lb = getLoadBalancer();
    Optional&lt;Server&gt; server = getPredicate().chooseRoundRobinAfterFiltering(lb.getAllServers(), key);
    if (server.isPresent()) {
        return server.get();
    } else {
        return null;
    }       
}
</code></pre>
<h4 id="5-可以看到-lbgetallserver正是zoneawareloadbalancergetallservers方法">5 可以看到 lb.getAllServer()，正是ZoneAwareLoadBalancer.getAllServers()方法</h4>
<pre><code class="language-java">// com.netflix.loadbalancer.BaseLoadBalancer#getAllServers
public class BaseLoadBalancer extends AbstractLoadBalancer {
    protected volatile List&lt;Server&gt; allServerList = Collections.synchronizedList(new ArrayList&lt;Server&gt;());
 
    public List&lt;Server&gt; getAllServers() {
        return Collections.unmodifiableList(allServerList);
    }
}
</code></pre>
<p>所以，我们现在用弄清楚的有两点：</p>
<ul>
<li><strong>为什么重要的ILoadBalancer的实现就是ZoneAwareLoadBalancer；</strong></li>
<li><strong>ZoneAwareLoadBalancer中的allServerList属性是何时被赋值的；</strong></li>
</ul>
<hr>
<h3 id="四-zoneawareloadbalancer是何时注入的">四 ZoneAwareLoadBalancer是何时注入的</h3>
<h4 id="1-在spring-cloud-netfliex-ribbon包的springfactories中有ribbonautoconfiguration类">1 在spring-cloud-netfliex-ribbon包的spring.factories中有RibbonAutoConfiguration类</h4>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1658666526979.png" alt="" loading="lazy"></figure>
<p>我们看到这个类的构造方法，创建了一个SpringClientFactory工厂类：</p>
<pre><code class="language-java">@Configuration
@Conditional(RibbonAutoConfiguration.RibbonClassesConditions.class)
@RibbonClients
@AutoConfigureAfter(name = &quot;org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration&quot;)
@AutoConfigureBefore({ LoadBalancerAutoConfiguration.class,
      AsyncLoadBalancerAutoConfiguration.class })
@EnableConfigurationProperties({ RibbonEagerLoadProperties.class,
      ServerIntrospectorProperties.class })
public class RibbonAutoConfiguration {
 
   @Autowired(required = false)
   private List&lt;RibbonClientSpecification&gt; configurations = new ArrayList&lt;&gt;();
 
   @Autowired
   private RibbonEagerLoadProperties ribbonEagerLoadProperties;
 
   @Bean
   public HasFeatures ribbonFeature() {
      return HasFeatures.namedFeature(&quot;Ribbon&quot;, Ribbon.class);
   }
 
   @Bean
   public SpringClientFactory springClientFactory() {
       // SpringClientFactory这个Client工厂类很关键
      SpringClientFactory factory = new SpringClientFactory();
      factory.setConfigurations(this.configurations);
      return factory;
   }
}
</code></pre>
<p>我们再看看这个工厂类的构造方法做了什么事：</p>
<pre><code class="language-java">public class SpringClientFactory extends NamedContextFactory&lt;RibbonClientSpecification&gt; {
 
   static final String NAMESPACE = &quot;ribbon&quot;;
 
   public SpringClientFactory() {
      super(RibbonClientConfiguration.class, NAMESPACE, &quot;ribbon.client.name&quot;);
   }
}

public abstract class NamedContextFactory&lt;C extends NamedContextFactory.Specification&gt; implements DisposableBean, ApplicationContextAware {
    private final String propertySourceName;
    private final String propertyName;
    private Map&lt;String, AnnotationConfigApplicationContext&gt; contexts = new ConcurrentHashMap();
    private Map&lt;String, C&gt; configurations = new ConcurrentHashMap();
    private ApplicationContext parent;
    private Class&lt;?&gt; defaultConfigType;
 
    public NamedContextFactory(Class&lt;?&gt; defaultConfigType, String propertySourceName, String propertyName) {
        this.defaultConfigType = defaultConfigType;
        this.propertySourceName = propertySourceName;
        this.propertyName = propertyName;
    }
}
</code></pre>
<p>显然，<strong>构造了一个上下工厂“NamedContextFactory”类，这个工厂类的默认配置类是“RibbonClientConfiguraion”</strong>，这个在之后Feign的调用过程中非常关键；</p>
<h4 id="2-loadbalancerfeignclient这个代理类的execute方法中">2 LoadBalancerFeignClient这个代理类的execute()方法中</h4>
<pre><code class="language-java">// org.springframework.cloud.openfeign.ribbon.LoadBalancerFeignClient#execute
public Response execute(Request request, Request.Options options) throws IOException {
   try {
      URI asUri = URI.create(request.url());
      String clientName = asUri.getHost();
      URI uriWithoutHost = cleanUrl(request.url(), clientName);
      FeignLoadBalancer.RibbonRequest ribbonRequest = new FeignLoadBalancer.RibbonRequest(
            this.delegate, request, uriWithoutHost);
 
      // 这个方法不用讲，得到的IclientConfig肯定是RibbonClientConfiguraion
      IClientConfig requestConfig = getClientConfig(options, clientName);
      return lbClient(clientName)
            .executeWithLoadBalancer(ribbonRequest, requestConfig).toResponse();
   }
   catch (ClientException e) {
      ......
   }
}

// org.springframework.cloud.openfeign.ribbon.LoadBalancerFeignClient#getClientConfig
IClientConfig getClientConfig(Request.Options options, String clientName) {
    ......
    requestConfig = this.clientFactory.getClientConfig(clientName);
    ......
}

// org.springframework.cloud.netflix.ribbon.SpringClientFactory#getClientConfig
public IClientConfig getClientConfig(String name) {
   return getInstance(name, IClientConfig.class);
}

// org.springframework.cloud.netflix.ribbon.SpringClientFactory#getInstance
public &lt;C&gt; C getInstance(String name, Class&lt;C&gt; type) {
    // SpringClientFactory的super父类就是NamedContextFactory
   C instance = super.getInstance(name, type);
   if (instance != null) {
      return instance;
   }
   IClientConfig config = getInstance(name, IClientConfig.class);
   return instantiateWithConfig(getContext(name), type, config);
}

// org.springframework.cloud.context.named.NamedContextFactory#getInstance
public &lt;T&gt; T getInstance(String name, Class&lt;T&gt; type) {
    AnnotationConfigApplicationContext context = this.getContext(name);
    return BeanFactoryUtils.beanNamesForTypeIncludingAncestors(context, type).length &gt; 0 ? context.getBean(type) : null;
}
</code></pre>
<p>找到了**NamedContextFactory  ，就和第一点串起来了，它的 默认 配置类正是RibbonClientConfiguration **；</p>
<h4 id="3-ribbonclientconfiguration又是如何注入我们需要的zoneawareloadbalancer的">3 RibbonClientConfiguration又是如何注入我们需要的ZoneAwareLoadBalancer的</h4>
<pre><code class="language-java">@Configuration(proxyBeanMethods = false)
@EnableConfigurationProperties
// Order is important here, last should be the default, first should be optional
// see
// https://github.com/spring-cloud/spring-cloud-netflix/issues/2086#issuecomment-316281653
@Import({ HttpClientConfiguration.class, OkHttpRibbonConfiguration.class,
      RestClientRibbonConfiguration.class, HttpClientRibbonConfiguration.class })
public class RibbonClientConfiguration {
 
    @Bean
    @ConditionalOnMissingBean
    public ILoadBalancer ribbonLoadBalancer(IClientConfig config,
          ServerList&lt;Server&gt; serverList, ServerListFilter&lt;Server&gt; serverListFilter,
          IRule rule, IPing ping, ServerListUpdater serverListUpdater) {
       if (this.propertiesFactory.isSet(ILoadBalancer.class, name)) {
          return this.propertiesFactory.get(ILoadBalancer.class, config, name);
       }
        
       // 默认注入的类正是ZoneAwareLoadBalancer
       return new ZoneAwareLoadBalancer&lt;&gt;(config, rule, ping, serverList,
             serverListFilter, serverListUpdater);
    }
 
}
</code></pre>
<p><strong>所以，这就解释了，为什么在后面的 ILoadBalancer lb = getLoadBalancer(); 获得到的就是ZoneAwareLoadBalancer！</strong></p>
<p><strong>同时，这个类是在动态代理被执行execute()的时候被调起的，所以Ribbon也是在被使用时才从Nacos获取注册表的，并不是在容器启动时！</strong></p>
<hr>
<h3 id="五-ribbon又是何时从nacos服务端获取allserverlist的">五 Ribbon又是何时从Nacos服务端获取allServerList的</h3>
<h4 id="1-我们需要跟踪zoneawareloadbalancer对应的bean的构造过程">1 我们需要跟踪ZoneAwareLoadBalancer对应的Bean的构造过程</h4>
<pre><code class="language-java">// com.netflix.loadbalancer.ZoneAwareLoadBalancer#ZoneAwareLoadBalancer
public ZoneAwareLoadBalancer(IClientConfig clientConfig, IRule rule,
                             IPing ping, ServerList&lt;T&gt; serverList, ServerListFilter&lt;T&gt; filter,
                             ServerListUpdater serverListUpdater) {
    super(clientConfig, rule, ping, serverList, filter, serverListUpdater);
}

// com.netflix.loadbalancer.DynamicServerListLoadBalancer#DynamicServerListLoadBalancer
public DynamicServerListLoadBalancer(IClientConfig clientConfig, IRule rule, IPing ping,
                                     ServerList&lt;T&gt; serverList, ServerListFilter&lt;T&gt; filter,
                                     ServerListUpdater serverListUpdater) {
    super(clientConfig, rule, ping);
    this.serverListImpl = serverList;
    this.filter = filter;
    this.serverListUpdater = serverListUpdater;
    if (filter instanceof AbstractServerListFilter) {
        ((AbstractServerListFilter) filter).setLoadBalancerStats(getLoadBalancerStats());
    }
     
    //执行远程调用，并初始化BaseLoadBalancer中的allServerList
    restOfInit(clientConfig);
}
</code></pre>
<h4 id="2-远程调用nacos并初始化restofinit方法的逻辑">2 远程调用Nacos并初始化restOfInit()方法的逻辑</h4>
<pre><code class="language-java">void restOfInit(IClientConfig clientConfig) {
    boolean primeConnection = this.isEnablePrimingConnections();
    // turn this off to avoid duplicated asynchronous priming done in BaseLoadBalancer.setServerList()
    this.setEnablePrimingConnections(false);
     
    // 获取服务列表功能
    enableAndInitLearnNewServersFeature();
 
    updateListOfServers();
    if (primeConnection &amp;&amp; this.getPrimeConnections() != null) {
        this.getPrimeConnections()
                .primeConnections(getReachableServers());
    }
    this.setEnablePrimingConnections(primeConnection);
}

public void enableAndInitLearnNewServersFeature() {
    serverListUpdater.start(updateAction);
}
</code></pre>
<p>这个updateAction变量是可执行的：</p>
<pre><code class="language-java">protected final ServerListUpdater.UpdateAction updateAction = new ServerListUpdater.UpdateAction() {
    @Override
    public void doUpdate() {
        updateListOfServers(); // 更新Servers列表
    }
};
</code></pre>
<p>3、updateListOfServer()方法如何从Nacos服务端获取服务列表：</p>
<pre><code class="language-java">// com.netflix.loadbalancer.DynamicServerListLoadBalancer#updateListOfServers
public void updateListOfServers() {
    List&lt;T&gt; servers = new ArrayList&lt;T&gt;();
    if (serverListImpl != null) {
        // 其中的serverListImpl有三个实现，其中之一就是Nacos
        servers = serverListImpl.getUpdatedListOfServers();
        LOGGER.debug(&quot;List of Servers for {} obtained from Discovery client: {}&quot;,
                getIdentifier(), servers);
 
        if (filter != null) {
            servers = filter.getFilteredListOfServers(servers);
            LOGGER.debug(&quot;Filtered List of Servers for {} obtained from Discovery client: {}&quot;,
                    getIdentifier(), servers);
        }
    }
     
    // 用获得到的服务列表更新BaseLoadBalancer中的allServerList
    updateAllServerList(servers);
}
</code></pre>
<p>不用想了，肯定是NacosServerList，这个简单追踪就不赘述了！</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1658666558990.png" alt="" loading="lazy"></figure>
<blockquote>
<p><strong>NacosServerList.getUpdatedListOfServers()最终会调用nacos客户端的核心类 NacosNamingServer.selectInstances() 方法，该方法只会返回健康实例列表；</strong></p>
</blockquote>
<h4 id="4-根据从nacos获得到的servers更新本地的allserverlist属性">4 根据从nacos获得到的Servers，更新本地的allServerList属性</h4>
<pre><code class="language-java">// com.netflix.loadbalancer.DynamicServerListLoadBalancer#updateAllServerList
protected void updateAllServerList(List&lt;T&gt; ls) {
    // other threads might be doing this - in which case, we pass
    if (serverListUpdateInProgress.compareAndSet(false, true)) {
        try {
            for (T s : ls) {
                s.setAlive(true); // set so that clients can start using these
                                  // servers right away instead
                                  // of having to wait out the ping cycle.
            }
            setServersList(ls);
            super.forceQuickPing();
        } finally {
            serverListUpdateInProgress.set(false);
        }
    }
}

public void setServersList(List lsrv) {
    super.setServersList(lsrv);  // 核心
    List&lt;T&gt; serverList = (List&lt;T&gt;) lsrv;
    Map&lt;String, List&lt;Server&gt;&gt; serversInZones = new HashMap&lt;String, List&lt;Server&gt;&gt;();
    for (Server server : serverList) {
        // make sure ServerStats is created to avoid creating them on hot
        // path
        getLoadBalancerStats().getSingleServerStat(server);
        String zone = server.getZone();
        if (zone != null) {
            zone = zone.toLowerCase();
            List&lt;Server&gt; servers = serversInZones.get(zone);
            if (servers == null) {
                servers = new ArrayList&lt;Server&gt;();
                serversInZones.put(zone, servers);
            }
            servers.add(server);
        }
    }
    setServerListForZones(serversInZones);
}

// com.netflix.loadbalancer.BaseLoadBalancer#setServersList
public void setServersList(List lsrv) {
    Lock writeLock = allServerLock.writeLock();
    logger.debug(&quot;LoadBalancer [{}]: clearing server list (SET op)&quot;, name);
     
    ArrayList&lt;Server&gt; newServers = new ArrayList&lt;Server&gt;();
    writeLock.lock();
    try {
        ArrayList&lt;Server&gt; allServers = new ArrayList&lt;Server&gt;();
         
        ...对每一个Server进行下包装...
         
        allServerList = allServers; //本地的allServerList赋值
        if (canSkipPing()) {
            for (Server s : allServerList) {
                s.setAlive(true);
            }
            upServerList = allServerList;
        } else if (listChanged) {
            forceQuickPing();
        }
    } finally {
        writeLock.unlock();
    }
}
</code></pre>
<p>到这里，总算和 二.5 章节中的allServerList进行呼应了！</p>
<blockquote>
<p>至此，整个从FeignClient注解生成动态代理类LoadBalancerFeignClient；</p>
<p>——&gt; Client执行时会生成ribbon下的ZoneAwareLoadBalancer类，调用nacos服务端获取服务列表；</p>
<p>——&gt; 在通过ZoneAwareLoadBalancer的父类的BaseLoadBalancer.chooseServer()方法根据负载均衡算法挑选一台服务器；</p>
<p>——&gt; 最后交给Feign的的Client通过URL类完成调用。</p>
</blockquote>
<hr>
<h3 id="六-feign和ribbon的重试机制">六 Feign和Ribbon的重试机制</h3>
<h4 id="1-首先我们做两个事情">1 首先我们做两个事情</h4>
<p>服务提供者feign-provider：</p>
<pre><code class="language-java">@GetMapping(&quot;/get/{id}&quot;)
public String getById(@PathVariable(&quot;id&quot;) String id){
    System.out.println(&quot;被调用，时间：&quot; + System.currentTimeMillis());
    try {
        TimeUnit.SECONDS.sleep(100);
    } catch (InterruptedException e) {
        e.printStackTrace();
    }
    return &quot;feign-provider:com.jiguiquan.springcloud.controller.OrderController#getById=&quot; + id;
}
</code></pre>
<p>服务消费者feign-consumer：</p>
<pre><code class="language-java">@GetMapping(&quot;test&quot;)
public String test(){
    return orderService.getById(&quot;100&quot;);
}
</code></pre>
<h4 id="2-不配置任何重试机制使用默认值">2 不配置任何重试机制，使用默认值</h4>
<p>调用接口后，看服务提供者的日志（重试了2次，时间间隔为1秒）：</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1658666579245.png" alt="" loading="lazy"></figure>
<h4 id="3-我们为系统注入feign的默认retryer重试机制">3 我们为系统注入Feign的默认Retryer重试机制</h4>
<pre><code class="language-java">@Bean
public Retryer retryer(){
   return new Retryer.Default();
}
</code></pre>
<p>再次调用，再看日志（重试了10次，）：</p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1658666591041.png" alt="" loading="lazy"></figure>
<h4 id="4-feign的默认重试器的核心代码默认是不开启的">4 Feign的默认重试器的核心代码（默认是不开启的）</h4>
<pre><code class="language-java">public static class Default implements Retryer {
    private final int maxAttempts;
    private final long period;
    private final long maxPeriod;
    int attempt;
    long sleptForMillis;
 
    public Default() {
        // 默认的重试间隔时间100ms，最大间隔时间为1s，最大重试次数为5次
        this(100L, TimeUnit.SECONDS.toMillis(1L), 5);
    }
     
    // 默认下次重试间隔时间 100 * 1.5^(尝试轮次-1) 次方
    // 第一次尝试：100 * 1.5(2 -1) = 150ms; 以此类推
    long nextMaxInterval() {
        long interval = (long)((double)this.period * Math.pow(1.5D, (double)(this.attempt - 1)));
        return interval &gt; this.maxPeriod ? this.maxPeriod : interval;
    }
}
</code></pre>
<h4 id="5-ribbon和feign的重试器的源码就不过度追溯了直接上结论">5 Ribbon和Feign的重试器的源码就不过度追溯了，直接上结论</h4>
<ul>
<li><strong>Ribbon的重试机制默认是开启的，重试1次，共调用两次；</strong></li>
<li><strong>Feign的Retryer重试器默认是关闭的 NEVER_RETRY;</strong></li>
<li><strong>Feign如果想开启默认重试器，直接在Spring容器中注入 Retryer.Default 即可，默认重试5次；</strong></li>
</ul>
<h4 id="6-修改ribbon的默认重试机制">6 修改Ribbon的默认重试机制</h4>
<pre><code class="language-yaml"># Ribbon 配置
ribbon:
  # 单节点最大重试次数(不包含默认调用的1次)，达到最大值时，切换到下一个示例
  MaxAutoRetries: 0  # 0 相当于关闭ribbon重试
   
  # 更换下一个重试节点的最大次数，可以设置为服务提供者副本数（副本数 = 总机器数 - 1），也是就每个副本都查询一次
  MaxAutoRetriesNextServer: 0
   
  # 是否对所有请求进行重试，默认fasle，则只会对GET请求进行重试，建议配置为false，不然添加数据接口，会造成多条重复，也就是幂等性问题。
  OkToRetryOnAllOperations: false
</code></pre>
<h4 id="7-自定义feign重试机制直接给-retryerdefault-构造方法传参即可">7 自定义Feign重试机制（直接给 Retryer.Default 构造方法传参即可）</h4>
<pre><code class="language-java">@Bean
public Retryer retryer(){
   return new Retryer.Default(100, 1000, 3); // 调用3次（包含原本的一次调用）
}
</code></pre>
<p>当然，如果对 Retryer.Dafault 的默认的方法逻辑不认可，可以直接实现一个自己的CustomRetryer注入到spring容器中即可：</p>
<pre><code class="language-java">@Bean
public Retryer customerRetryer(){
    return new Retryer() {
        @Override
        public void continueOrPropagate(RetryableException e) {
             
        }
 
        @Override
        public Retryer clone() {
            return null;
        }
    };
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Nacos核心源码剖析——配置中心]]></title>
        <id>https://tinaxiawuhao.github.io/post/bp8DT_bHg/</id>
        <link href="https://tinaxiawuhao.github.io/post/bp8DT_bHg/">
        </link>
        <updated>2022-07-04T12:33:38.000Z</updated>
        <content type="html"><![CDATA[<p>Nacos官方文档：https://nacos.io/zh-cn/docs/quick-start.html</p>
<p>服务端对外暴露的API：https://nacos.io/zh-cn/docs/open-api.html</p>
<p>Nacos的Server端其实就是一个Web服务，对外提供了Http服务接口，所有的客户端与服务端的通讯都通过Http调用完成（短链接）。</p>
<blockquote>
<p><strong>Nacos注册服务核心类：NacosNamingService</strong></p>
<p><strong>Nacos配置中心核心类：NacosConfigService</strong></p>
</blockquote>
<p>Nacos配置中心的nameSpace/Group和注册中心类似，但是没有集群Cluster的概念！</p>
<p>配置文件的核心主键是DataId（与注册中心不一样，注册中心为ServiceName）</p>
<pre><code class="language-yaml">spring:
  application:
    name: nacos-config-client
  cloud:
    nacos:
      config:
        server-addr: 10.206.73.156:8848
        namespace: haier-iot
        group: dev
        file-extension: yaml
# 上面的配置，拼装成的最高优先级配置文件为 haier-iot/dev/ nacos-config-client-dev.yaml
</code></pre>
<p><strong>Nacos还支持扩展配置：extension-configs，和共享配置：shared-configs</strong>，以支持各种复杂的应用场景！</p>
<p>官方github wiki地址：https://github.com/alibaba/spring-cloud-alibaba/wiki/Nacos-config</p>
<p><strong>Client客户端核心知识点：</strong></p>
<ul>
<li><strong>当需要获取配置时，先尝试从本地配置文件获取，获取不到时，再去远端Server获取；从远端获取成功后，保存到本地配置文件，后面通过ClientWorker中的长轮询完成配置的实时更新!</strong></li>
</ul>
<p>ClientWorker中有两个线程executor和executorService：</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1658666099885.png" alt="" loading="lazy"></figure>
<ul>
<li>
<p><strong>单线程executor定时任务</strong>：每10ms执行checkConfigInfo()方法，看看本地配置信息是否有变化，以3000个为一组，判断是否要增加新的LongPollingRunnable长轮询任务；</p>
</li>
<li>
<p><strong>多线程executorService执行LongPollingRunnable长轮询任务核心逻辑</strong>：根据本地配置项的dataId，group，Md5值，tenant拼接字符串，调用服务端“监听配置——长轮询接口”看看这批次的配置是否有变化，有变化的话，就遍历调用“获取配置详情接口”获取最新配置值，没变化的不用动，任务最后，再次执行this，循环往复执行此长轮询任务！</p>
<p>当本地的配置文件发生改变时，会回调注册在这些配置上的监听器的回调方法，从而完成应用程序的配置更新！（refresh(context)后完成Nacos监听器的注册）</p>
</li>
</ul>
<p><strong>服务端核心知识点：</strong></p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1658666125421.png" alt="" loading="lazy"></figure>
<ul>
<li><strong>服务端即使配置了mysql，每次请求也不是直接去查询mysql的，而是借助 本地内存缓存中的元数据 + 本地磁盘中的配置文件；</strong></li>
<li><strong>Mysql主要用于集群节点启动时的数据加载（全量加载、增量加载） 和 数据变动时的刷新同步；</strong></li>
<li><strong>某节点处理配置发布请求时，不是着急更新自己的状态，而是会先写入mysql数据库，之后通过ConfigDataChangeEvent事件实现异步处理，通知所有节点更新自己的内存缓存和本地磁盘文件；（包括自己）</strong></li>
<li>AP集群，存在数据的短时间不一致，但是可以保证最终一致性，对客户端的影响也就是可能配置更新慢那么一点。</li>
</ul>
<hr>
<h3 id="一-nacos客户端加载配置的核心逻辑">一 nacos客户端加载配置的核心逻辑</h3>
<h4 id="1-nacos核心配置nacospropertysourcelocator类的定位"><strong>1 nacos核心配置NacosPropertySourceLocator类的定位：</strong></h4>
<p>如果要弄清楚Nacos配置文件加载到Spring容器中的流程，还需要熟悉Springcloud的源码流程，了解Springcloud中的配置，还有重要的Bean是如果装载到Spring容器中的；</p>
<p>这里只能大概聊一下：</p>
<ul>
<li>Springboot项目启动时，在prepareEnvironment()阶段，会通过spring.factories文件中的BootstrapConfiguration类找到NacosConfigBootstrapConfiguration配置类，并完成注入：</li>
</ul>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1658666155462.png" alt="" loading="lazy"></figure>
<ul>
<li>NacosConfigBootstrapConfiguration配置类，会向Spring容器中注入几个Nacos配置读取重要的类</li>
</ul>
<pre><code class="language-java">public class NacosConfigBootstrapConfiguration {
    public NacosConfigBootstrapConfiguration() {
    }
 
    @Bean
    @ConditionalOnMissingBean
    public NacosConfigProperties nacosConfigProperties() {
        return new NacosConfigProperties();
    }
 
    @Bean
    @ConditionalOnMissingBean
    public NacosConfigManager nacosConfigManager(NacosConfigProperties nacosConfigProperties) {
        return new NacosConfigManager(nacosConfigProperties);
    }
 
    // NacosPropertySourceLocator能够一步步地把把Nacos的配置文件都找到
    @Bean
    public NacosPropertySourceLocator nacosPropertySourceLocator(NacosConfigManager nacosConfigManager) {
        return new NacosPropertySourceLocator(nacosConfigManager);  
    }
}
</code></pre>
<ul>
<li>然后在prepareContext()上下文的时候，会通过之前从spring.factories中读取到的ApplicationInitializer初始化器，这里遍历执行时，就会执行到springcloud的PropertySpurceBootstrapConfiguration类的initialize()方法：</li>
</ul>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1658666184206.png" alt="" loading="lazy"></figure>
<p>可以看到PropertySpurceBootstrapConfiguration.initialize()方法中需要用到PropertySourceLocator接口的实现类，而我们配置的Nacos正好为这个接口提供了实现类NacosPropertySourceLocator</p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1658666209114.png" alt="" loading="lazy"></figure>
<h4 id="2-通过nacospropertysourcelocator类理清nacos各中配置文件的优先级"><strong>2 通过NacosPropertySourceLocator类，理清Nacos各中配置文件的优先级：</strong></h4>
<pre><code class="language-java">// com.alibaba.cloud.nacos.client.NacosPropertySourceLocator#locate
public PropertySource&lt;?&gt; locate(Environment env) {
    this.nacosConfigProperties.setEnvironment(env);
    ConfigService configService = this.nacosConfigManager.getConfigService();
    if (null == configService) {
        log.warn(&quot;no instance of config service found, can't load config from nacos&quot;);
        return null;
    } else {
        long timeout = (long)this.nacosConfigProperties.getTimeout();
        this.nacosPropertySourceBuilder = new NacosPropertySourceBuilder(configService, timeout);
        String name = this.nacosConfigProperties.getName();
        String dataIdPrefix = this.nacosConfigProperties.getPrefix();
        if (StringUtils.isEmpty(dataIdPrefix)) {
            dataIdPrefix = name;
        }
 
        if (StringUtils.isEmpty(dataIdPrefix)) {
            dataIdPrefix = env.getProperty(&quot;spring.application.name&quot;);
        }
 
        CompositePropertySource composite = new CompositePropertySource(&quot;NACOS&quot;);
        // 1. 先加载共享配置文件
        this.loadSharedConfiguration(composite); 
        // 2. 再加载扩展配置文件 
        this.loadExtConfiguration(composite);  
        // 3. 最后才加载本应用自己的配置文件
        this.loadApplicationConfiguration(composite, dataIdPrefix, this.nacosConfigProperties, env); 
        return composite;
    }
}
</code></pre>
<p>本应用自己的配置文件也是可以存在多个的，也是有优先级的：</p>
<pre><code class="language-java">// 入参中的dataIdPrefix，理解为就是spring.application.name
private void loadApplicationConfiguration(CompositePropertySource compositePropertySource, String dataIdPrefix, NacosConfigProperties properties, Environment environment) {
    String fileExtension = properties.getFileExtension();
    String nacosGroup = properties.getGroup();
    // 1. 先尝试加载：纯微服务名称对应的配置文件，如：order-config
    this.loadNacosDataIfPresent(compositePropertySource, dataIdPrefix, nacosGroup, fileExtension, true);
    // 2. 再尝试加载：微服务名称 + &quot;.&quot; + 文件扩展名的文件，如：order-config.yaml
    this.loadNacosDataIfPresent(compositePropertySource, dataIdPrefix + &quot;.&quot; + fileExtension, nacosGroup, fileExtension, true);
    String[] var7 = environment.getActiveProfiles();
    int var8 = var7.length;
 
    // 3. 最后再尝试加载：微服务名称 + &quot;-&quot; + profile + &quot;.&quot; + 文件扩展名的文件，如：order-config-dev.yaml
    for(int var9 = 0; var9 &lt; var8; ++var9) {
        String profile = var7[var9];
        String dataId = dataIdPrefix + &quot;-&quot; + profile + &quot;.&quot; + fileExtension;
        this.loadNacosDataIfPresent(compositePropertySource, dataId, nacosGroup, fileExtension, true);
    }
 
}
</code></pre>
<blockquote>
<p>根据后加载的覆盖先加载的原则，最后我们很容易就可以知道整个服务的配置文件的优先级为：</p>
<p><strong>order-config-dev.yaml &gt; order-config.yaml &gt; order-config &gt; extension-configs &gt; shared-configs</strong></p>
</blockquote>
<hr>
<h3 id="二-nacos配置中心的核心类nacosconfigservice的引入">二 Nacos配置中心的核心类NacosConfigService的引入</h3>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1658666249886.png" alt="" loading="lazy"></figure>
<h4 id="1-客户端是何时从远程配置nacos服务端拉取配置的"><strong>1 客户端是何时从远程配置Nacos服务端拉取配置的</strong></h4>
<pre><code class="language-java">// 还记得刚开始时候，通过spring.factories注入了一个配置类NacosConfigBootstrapConfiguration 
// 该配置类，会向Spring容器中注入一个Bean：NacosConfigManager
@Bean
@ConditionalOnMissingBean
public NacosConfigManager nacosConfigManager(NacosConfigProperties nacosConfigProperties) {
    return new NacosConfigManager(nacosConfigProperties);
}
 
//而NacosConfigManager的构造方法中，就会“写死”为我们create一个ConfigService，赋值给静态变量service
private static ConfigService service = createConfigService(nacosConfigProperties);
|
public static ConfigService createConfigService(Properties properties) throws NacosException {
    try {
        Class&lt;?&gt; driverImplClass = Class.forName(&quot;com.alibaba.nacos.client.config.NacosConfigService&quot;);
        Constructor constructor = driverImplClass.getConstructor(Properties.class);
        ConfigService vendorImpl = (ConfigService)constructor.newInstance(properties);
        return vendorImpl;
    } catch (Throwable var4) {
        throw new NacosException(-400, var4);
    }
}
</code></pre>
<p>此时，NacosConfigService闪亮登场！</p>
<h4 id="2-nacosconfigservice类的构造方法中会创建重要的两个属性agent和worker"><strong>2 NacosConfigService类的构造方法中会创建重要的两个属性agent和worker：</strong></h4>
<pre><code class="language-java">public NacosConfigService(Properties properties) throws NacosException {
    ValidatorUtils.checkInitParam(properties);
    String encodeTmp = properties.getProperty(PropertyKeyConst.ENCODE);
    if (StringUtils.isBlank(encodeTmp)) {
        this.encode = Constants.ENCODE;
    } else {
        this.encode = encodeTmp.trim();
    }
    initNamespace(properties);
     
    // agent是一个http代理，如果需要登录验证等操作，ServerHttpAgent构造时会完成验证
    this.agent = new MetricsHttpAgent(new ServerHttpAgent(properties));
    this.agent.start();
     
    // 客户端的实际工作者ClientWorker，其中的agent也就是上面创建的agent
    this.worker = new ClientWorker(this.agent, this.configFilterChainManager, properties);
}
</code></pre>
<p>####<strong>3 NacosConfigService中的核心获取配置方法getConfig() ——&gt; getConfigInner()：</strong></p>
<ul>
<li>客户端需要使用配置文件时，<strong>不是直接去调用远端Server获取，而是先尝试从本地Failover文件获取</strong>；</li>
<li>如果<strong>本地文件不存在，则才会从远端Server获取</strong>；</li>
<li>从<strong>远端Server成功获取配置后，会向本地文件保存快照</strong>，以备后用；（本地文件的更新由后面的长轮询完成）</li>
</ul>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1658666274991.png" alt="" loading="lazy"></figure>
<pre><code class="language-java">private String getConfigInner(String tenant, String dataId, String group, long timeoutMs) throws NacosException {
    group = null2defaultGroup(group);
    ParamUtils.checkKeyParam(dataId, group);
    ConfigResponse cr = new ConfigResponse();
     
    cr.setDataId(dataId);
    cr.setTenant(tenant);
    cr.setGroup(group);
     
    // 优先使用本地配置
    String content = LocalConfigInfoProcessor.getFailover(agent.getName(), dataId, group, tenant);
    if (content != null) {
        cr.setContent(content);
        configFilterChainManager.doFilter(null, cr);
        content = cr.getContent();
        return content;
    }
     
    try {
        // 本地没有后，就尝试从远端获取配置
        String[] ct = worker.getServerConfig(dataId, group, tenant, timeoutMs);
        cr.setContent(ct[0]);
         
        configFilterChainManager.doFilter(null, cr);
        content = cr.getContent();
         
        return content;
    } catch (NacosException ioe) {
        ......
    }
     
    ......
    return content;
}
</code></pre>
<blockquote>
<p>所以Nacos配置中心与注册中心类似，都是先尝试从本地获取配置，只不过注册中心比配置中心多了一份内存注册表！</p>
<ul>
<li>注册中心：本地Failover故障转移文件 ——&gt; 本地内存注册表 ——&gt; 远端请求服务列表</li>
<li>配置中心：本地Failover故障转移文件（也就是本地配置快照文件）——&gt; 远端请求配置文件</li>
</ul>
</blockquote>
<p>worker.getServerConfig()远端配置请求成功后，还会往本地配置文件存一份Snapshot：</p>
<pre><code class="language-java">// worker.getServerConfig()
public String[] getServerConfig(String dataId, String group, String tenant, long readTimeout){
    // 从远端Server获取配置，这里的agent就是NacosConfigService构造方法中创建的agent代理
    result = agent.httpGet(Constants.CONFIG_CONTROLLER_PATH, null, params, agent.getEncode(), readTimeout);
     
    switch (result.getCode()) {
        case HttpURLConnection.HTTP_OK:
            // 往本地配置快照文件存一份
            LocalConfigInfoProcessor.saveSnapshot(agent.getName(), dataId, group, tenant, result.getData());
            ct[0] = result.getData();
            if (result.getHeader().getValue(CONFIG_TYPE) != null) {
                ct[1] = result.getHeader().getValue(CONFIG_TYPE);
            } else {
                ct[1] = ConfigType.TEXT.getType();
            }
            return ct;
        case HttpURLConnection.HTTP_NOT_FOUND:
            LocalConfigInfoProcessor.saveSnapshot(agent.getName(), dataId, group, tenant, null);
            return ct;
        case HttpURLConnection.HTTP_CONFLICT: {
            ...
        }
        case HttpURLConnection.HTTP_FORBIDDEN: {
            ...
        }
        default: {
            ...
        }
    }
}
</code></pre>
<h4 id="4-client第一次获取到server端配置后之后如何进行定时更新"><strong>4 Client第一次获取到Server端配置后，之后如何进行定时更新？</strong></h4>
<pre><code class="language-java">// ClientWorker构造时，会创建2个线程池
// 1. executor(单线程) ：定时每10毫秒执行checkConfigInfo()方法
// 2. executorService(1~核数/2): 具体的执行长轮询的线程
public ClientWorker(final HttpAgent agent, final ConfigFilterChainManager configFilterChainManager,final Properties properties) {
    this.agent = agent;
    this.configFilterChainManager = configFilterChainManager;
     
    // Initialize the timeout parameter
     
    init(properties);
     
    this.executor = Executors.newScheduledThreadPool(1, new ThreadFactory() {
        @Override
        public Thread newThread(Runnable r) {
            Thread t = new Thread(r);
            t.setName(&quot;com.alibaba.nacos.client.Worker.&quot; + agent.getName());
            t.setDaemon(true);
            return t;
        }
    });
     
    this.executorService = Executors
            .newScheduledThreadPool(Runtime.getRuntime().availableProcessors(), new ThreadFactory() {
                @Override
                public Thread newThread(Runnable r) {
                    Thread t = new Thread(r);
                    t.setName(&quot;com.alibaba.nacos.client.Worker.longPolling.&quot; + agent.getName());
                    t.setDaemon(true);
                    return t;
                }
            });
     
    this.executor.scheduleWithFixedDelay(new Runnable() {
        @Override
        public void run() {
            try {
                checkConfigInfo();
            } catch (Throwable e) {
                LOGGER.error(&quot;[&quot; + agent.getName() + &quot;] [sub-check] rotate check error&quot;, e);
            }
        }
    }, 1L, 10L, TimeUnit.MILLISECONDS);
}
 
public void checkConfigInfo() {
    // 将总的需要监听的配置数，以3000个为一组，创建长轮询LongPollingRunnable任务，监听配置更新！
    int listenerSize = cacheMap.get().size();
    int longingTaskCount = (int) Math.ceil(listenerSize / ParamUtil.getPerTaskConfigSize()); 
    if (longingTaskCount &gt; currentLongingTaskCount) {
        for (int i = (int) currentLongingTaskCount; i &lt; longingTaskCount; i++) {
            // 实际的干活线程，从远端拉取最新的config，与本地的config对比MD5值，看是否发生变化
            executorService.execute(new LongPollingRunnable(i));
        }
        currentLongingTaskCount = longingTaskCount;
    }
}
</code></pre>
<blockquote>
<p><strong>总结：ClientWorker实例化时，会创建两个线程：executor和executorService</strong></p>
<ul>
<li><strong>executor（单线程）：每隔10ms检查本地的配置数是否发生改变，以3000为一批次创建长轮询任务，不足的话，不另外创建长轮询任务；</strong></li>
<li><strong>executorService（多线程1~核数/2）:具体执行长轮询LongPolling任务的工作线程；</strong></li>
</ul>
</blockquote>
<h4 id="5-nacos客户端长轮询longpolling任务的核心逻辑md5比对"><strong>5 Nacos客户端长轮询LongPolling任务的核心逻辑（md5比对）：</strong></h4>
<p>监听配置的长轮询接口API：https://nacos.io/zh-cn/docs/open-api.html</p>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1658666302821.png" alt="" loading="lazy"></figure>
<pre><code class="language-java">// LongPollingRunnable.run()
public void run() {
     
    List&lt;CacheData&gt; cacheDatas = new ArrayList&lt;CacheData&gt;();
    List&lt;String&gt; inInitializingCacheList = new ArrayList&lt;String&gt;();
    try {
        // 检查本地的配置文件
        for (CacheData cacheData : cacheMap.get().values()) {
            if (cacheData.getTaskId() == taskId) {
                cacheDatas.add(cacheData);
                try {
                    checkLocalConfig(cacheData);
                    if (cacheData.isUseLocalConfigInfo()) {
                        cacheData.checkListenerMd5();
                    }
                } catch (Exception e) {
                    LOGGER.error(&quot;get local config info error&quot;, e);
                }
            }
        }
         
        // 会根据上面得到的cacheDatas，组装参数，调用服务端的监听配置的长轮询接口/nacos/v1/cs/configs/listener
        // 长轮询的返回值是dataId^2group^2tenant^1，空串代表无变化
        List&lt;String&gt; changedGroupKeys = checkUpdateDataIds(cacheDatas, inInitializingCacheList);
        if (!CollectionUtils.isEmpty(changedGroupKeys)) {
            LOGGER.info(&quot;get changedGroupKeys:&quot; + changedGroupKeys);
        }
         
        for (String groupKey : changedGroupKeys) {
            String[] key = GroupKey.parseKey(groupKey);
            String dataId = key[0];
            String group = key[1];
            String tenant = null;
            if (key.length == 3) {
                tenant = key[2];
            }
            try {
                // 会根据返回值中有变化的dataId配置项，单独去获取最新的配置值回本地
                String[] ct = getServerConfig(dataId, group, tenant, 3000L);
                CacheData cache = cacheMap.get().get(GroupKey.getKeyTenant(dataId, group, tenant));
                cache.setContent(ct[0]);
                if (null != ct[1]) {
                    cache.setType(ct[1]);
                }
                LOGGER.info(&quot;[{}] [data-received] dataId={}, group={}, tenant={}, md5={}, content={}, type={}&quot;,
                        agent.getName(), dataId, group, tenant, cache.getMd5(),
                        ContentUtils.truncateContent(ct[0]), ct[1]);
            } catch (NacosException ioe) {
                String message = String
                        .format(&quot;[%s] [get-update] get changed config exception. dataId=%s, group=%s, tenant=%s&quot;,
                                agent.getName(), dataId, group, tenant);
                LOGGER.error(message, ioe);
            }
        }
        for (CacheData cacheData : cacheDatas) {
            if (!cacheData.isInitializing() || inInitializingCacheList
                    .contains(GroupKey.getKeyTenant(cacheData.dataId, cacheData.group, cacheData.tenant))) {
                cacheData.checkListenerMd5();
                cacheData.setInitializing(false);
            }
        }
        inInitializingCacheList.clear();
         
        // 再次执行该方法，不断循环，不停监听配置文件的更新
        executorService.execute(this);
         
    } catch (Throwable e) {
         
        // If the rotation training task is abnormal, the next execution time of the task will be punished
        LOGGER.error(&quot;longPolling error : &quot;, e);
        executorService.schedule(this, taskPenaltyTime, TimeUnit.MILLISECONDS);
    }
}
</code></pre>
<p>checkUpdateDataIds(cacheDatas, inInitializingCacheList)核心逻辑：</p>
<pre><code class="language-java">// 拼接本地所有的dataId为一个长字符串
List&lt;String&gt; checkUpdateDataIds(List&lt;CacheData&gt; cacheDatas, List&lt;String&gt; inInitializingCacheList) throws Exception {
    StringBuilder sb = new StringBuilder();
    for (CacheData cacheData : cacheDatas) {
        if (!cacheData.isUseLocalConfigInfo()) {
            sb.append(cacheData.dataId).append(WORD_SEPARATOR);
            sb.append(cacheData.group).append(WORD_SEPARATOR);
            if (StringUtils.isBlank(cacheData.tenant)) {
                sb.append(cacheData.getMd5()).append(LINE_SEPARATOR);
            } else {
                sb.append(cacheData.getMd5()).append(WORD_SEPARATOR);
                sb.append(cacheData.getTenant()).append(LINE_SEPARATOR);
            }
            if (cacheData.isInitializing()) {
                // It updates when cacheData occours in cacheMap by first time.
                inInitializingCacheList
                        .add(GroupKey.getKeyTenant(cacheData.dataId, cacheData.group, cacheData.tenant));
            }
        }
    }
    boolean isInitializingCacheList = !inInitializingCacheList.isEmpty();
    return checkUpdateConfigStr(sb.toString(), isInitializingCacheList);
}

// 向服务端发起长轮询的查询逻辑，超时为30秒，不要挂起我
List&lt;String&gt; checkUpdateConfigStr(String probeUpdateString, boolean isInitializingCacheList) {
     
    Map&lt;String, String&gt; params = new HashMap&lt;String, String&gt;(2);
    params.put(Constants.PROBE_MODIFY_REQUEST, probeUpdateString);
    Map&lt;String, String&gt; headers = new HashMap&lt;String, String&gt;(2);
    headers.put(&quot;Long-Pulling-Timeout&quot;, &quot;&quot; + timeout);
     
    if (isInitializingCacheList) {
        headers.put(&quot;Long-Pulling-Timeout-No-Hangup&quot;, &quot;true&quot;); 
    }
     
    if (StringUtils.isBlank(probeUpdateString)) {
        return Collections.emptyList();
    }
     
    try {
        // In order to prevent the server from handling the delay of the client's long task,
        // increase the client's read timeout to avoid this problem.
         
        long readTimeoutMs = timeout + (long) Math.round(timeout &gt;&gt; 1);
        HttpRestResult&lt;String&gt; result = agent
                .httpPost(Constants.CONFIG_CONTROLLER_PATH + &quot;/listener&quot;, headers, params, agent.getEncode(),
                        readTimeoutMs);
         
        if (result.ok()) {
            setHealthServer(true);
            return parseUpdateDataIdResponse(result.getData());
        } else {
            setHealthServer(false);
            LOGGER.error(&quot;[{}] [check-update] get changed dataId error, code: {}&quot;, agent.getName(),
                    result.getCode());
        }
    } catch (Exception e) {
        setHealthServer(false);
        LOGGER.error(&quot;[&quot; + agent.getName() + &quot;] [check-update] get changed dataId exception&quot;, e);
        throw e;
    }
    return Collections.emptyList();
}
</code></pre>
<blockquote>
<p>总结：长轮询LongPollingRunnable长轮询任务的核心逻辑就是：</p>
<ul>
<li><strong>先查询本地配置文件Failover文件</strong>（本地配置快照Snapshot文件）；</li>
<li>根据本地配置文件，得到<strong>所有配置项，拼接请求参数（dataId/group/Md5/tenant），向服务端提供的长轮询接口（监听配置）：POST：/nacos/v1/cs/configs/listener 发起长轮询调用</strong>；</li>
<li>如果<strong>本批次的配置项有变动，服务端就会返回有变动的配置项字符串数组</strong>，如果没有变动，就返回空串；</li>
<li>如果返回不为空，说明有变动，就<strong>遍历这些变动项，然后通过具体的获取配置接口：GET：/nacos/v1/cs/configs 获取该配置项的最新配置</strong>；</li>
<li>最后，<strong>再次执行本次的 LongPollingRunnable 任务，循环往复，完成配置的实时监听更新</strong>！</li>
</ul>
</blockquote>
<h4 id="6-经过长轮询后如果本地配置文件更新后该如何通知到我们的应用程序注册监听器"><strong>6 经过长轮询后，如果本地配置文件更新后，该如何通知到我们的应用程序（注册监听器）？</strong></h4>
<p>在Springboot项目完成refresh(context)后，会调用 listeners.running(context) 方法，这个方法会向系统发出ApplicationReadyEvent事件，其它的监听了这个事件的Listener就可以做对应的工作了，而<strong>NacosContextRefresher</strong>就是其中之一！</p>
<pre><code class="language-java">public class NacosContextRefresher implements ApplicationListener&lt;ApplicationReadyEvent&gt;, ApplicationContextAware {
 
    // 监听到ApplicationReadyEvent事件后，开始注册Nacos的监听器
    public void onApplicationEvent(ApplicationReadyEvent event) {
        if (this.ready.compareAndSet(false, true)) {
            this.registerNacosListenersForApplications();
        }
    }
     
     
  private void registerNacosListenersForApplications() {
        if (this.isRefreshEnabled()) {
            Iterator var1 = NacosPropertySourceRepository.getAll().iterator();
     
            while(var1.hasNext()) {
                NacosPropertySource propertySource = (NacosPropertySource)var1.next();
                if (propertySource.isRefreshable()) {  // 默认使开启的
                    String dataId = propertySource.getDataId();
                    this.registerNacosListener(propertySource.getGroup(), dataId);
                }
            }
        }
     
    }
}

</code></pre>
<figure data-type="image" tabindex="9"><img src="https://tinaxiawuhao.github.io/post-images/1658666327231.png" alt="" loading="lazy"></figure>
<blockquote>
<p><strong>有了这一系列的监听器，当客户端知道配置发生改变时，就会回调对应的监听器的回调方法，通知应用程序更新对应的Bean（从IOC容器中删除旧Bean，放入新的Bean）。</strong></p>
</blockquote>
<hr>
<h3 id="三-ap模式nacos集群服务端如何工作">三 AP模式nacos集群，服务端如何工作</h3>
<p>首先一定要清楚，即使集群情况下，配置了mysql，当客户端查询配置时，也不是直接从mysql获取的，而是从每个节点的本地文件读取；</p>
<ul>
<li><strong>各节点本地文件：具体的配置；</strong></li>
<li><strong>各节点内存缓存：存储配置的元信息，如Md5值等；</strong></li>
<li><strong>Mysql：具体的配置的最新值和历史记录，方便新节点启动时加载，以及节点之间的数据同步；</strong></li>
</ul>
<figure data-type="image" tabindex="10"><img src="https://tinaxiawuhao.github.io/post-images/1658666346288.png" alt="" loading="lazy"></figure>
<h4 id="1-配置文件的dump加载dumpservice"><strong>1 配置文件的Dump加载：DumpService</strong></h4>
<p>DumpService由两个实现类：EmbeddedDumpService（derby） 和 ExternalDumpService（mysql）；</p>
<p>当新节点启动时，需要从mysql中加载配置数据，如果最后心跳时间&gt;6h，则从mysql加载全量数据；如果最后心跳时间&lt;6h，则从mysql加载增量数据；</p>
<ul>
<li>全量加载：删除本地的配置文件，全部从mysql加载配置数据；（每次捞取1000条）</li>
<li>增量加载：捞取最近6小时的新增配置，更新本地和内存元数据后，与mysql数据库中的配置进行比对，如果不一致，则再同步一次！</li>
</ul>
<h4 id="2-新的配置被发布后如何在集群间进行同步"><strong>2 新的配置被发布后，如何在集群间进行同步？</strong></h4>
<ul>
<li>AP集群，每个节点地位平等，发布配置后，根据轮询机制，会<strong>由某一台Server节点处理本地请求，该节点首先会将配置写入到Mysql数据库中</strong>；</li>
<li>该节点会<strong>发布一个ConfigDataChangeEvent事件</strong>，该事件会<strong>被自己的监听器处理</strong>，处理时，会<strong>通过HTTP调用集群的所有节点，告知配置发生改变（包括自己</strong>，因为上面只是写mysql，自己的本地文件和内存文件也都没有被修改）</li>
<li><strong>所有节点接收到本地配置修改的通知后，会到Mysql中同步最新的配置</strong>，刷新内存缓存 和 本地磁盘文件；</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Nacos核心源码剖析（CP架构）——注册中心]]></title>
        <id>https://tinaxiawuhao.github.io/post/zolXTKRvU/</id>
        <link href="https://tinaxiawuhao.github.io/post/zolXTKRvU/">
        </link>
        <updated>2022-07-03T12:30:58.000Z</updated>
        <content type="html"><![CDATA[<h3 id="一-nacos-cp集群架构的基础知识">一 Nacos CP集群架构的基础知识</h3>
<h4 id="1-nacos集群部署后可以同时支持ap和cp注意不是同时支持cap">1 Nacos集群部署后，可以同时支持AP和CP（注意，不是同时支持CAP）</h4>
<ul>
<li>AP架构：临时实例</li>
<li>CP架构：持久化实例</li>
</ul>
<p>在注册服务时，如果我们让我们的节点注册为：持久化实例，即自动会走CP架构！</p>
<pre><code class="language-yaml">spring:
  application:
    name: nacos-config-client
  cloud:
    nacos:
      discovery:
        server-addr: 10.206.73.156:8848
        namespace: haier-iot
        group: dev
        cluster-name: BJ
        ephemeral: true  # 持久化实例走CP架构
</code></pre>
<h4 id="2-nacos-cp架构使用的分布式一致性协议简化版的raft">2 Nacos CP架构使用的分布式一致性协议？（简化版的Raft）</h4>
<p>Raft分布式一致性协议 和 Zookeeper使用的ZAB原子广播协议非常相似；</p>
<p>都是一个Leader带领多个Follower，区别在于，Leader选举时的投票机制：</p>
<ul>
<li><strong>ZAB投票时</strong>：<strong>所有候选节点都会发起投票，然后进行选票PK，决定谁胜出；</strong></li>
<li><strong>Raft投票时</strong>：<strong>会让所有节点随机睡眠，先睡醒的节点发起投票，投自己，并将选票发到其它节点等待结果；</strong></li>
</ul>
<p>但是，对结果的判断，ZAB 和 Raft 都遵循“半数机制”。</p>
<hr>
<h3 id="二-cp架构下持久化实例的注册逻辑">二 CP架构下，持久化实例的注册逻辑</h3>
<h4 id="1-注册实例的api接口不变nacosv1nsinstance">1 注册实例的API接口不变：/nacos/v1/ns/instance</h4>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1658665954910.png" alt="" loading="lazy"></figure>
<p>这里当然时选择RaftConsistencyServiceImpl的实现：</p>
<pre><code class="language-java">public void put(String key, Record value) throws NacosException {
    checkIsStopWork();
    try {
        raftCore.signalPublish(key, value);  
    } catch (Exception e) {
        ......
    }
}
</code></pre>
<h4 id="2-整个cp架构下的主节点注册逻辑都在signalpublish方法中">2 整个CP架构下的主节点注册逻辑都在signalPublish()方法中</h4>
<pre><code class="language-java">public void signalPublish(String key, Record value) throws Exception {
    if (stopWork) {
        throw new IllegalStateException(&quot;old raft protocol already stop work&quot;);
    }
    // 判断自己是不是Leader
    if (!isLeader()) {
        ObjectNode params = JacksonUtils.createEmptyJsonNode();
        params.put(&quot;key&quot;, key);
        params.replace(&quot;value&quot;, JacksonUtils.transferToJsonNode(value));
        Map&lt;String, String&gt; parameters = new HashMap&lt;&gt;(1);
        parameters.put(&quot;key&quot;, key);
 
        final RaftPeer leader = getLeader();
 
        // 如果本节点不是Leader，就把请求转发给Leader节点处理
        raftProxy.proxyPostLarge(leader.ip, API_PUB, params.toString(), parameters);
        return;
    }
 
    OPERATE_LOCK.lock();
    try {
        ......
 
        // 核心方法，写本地数据，写内存缓存，发布事件——更新内存服务注册表
        onPublish(datum, peers.local());
 
        final String content = json.toString();
 
        // 通过CountDownLatch实现半数ack的统计，如果获得到半数以上的ack，则Countdownlatch逻辑才可以继续向下走！
        final CountDownLatch latch = new CountDownLatch(peers.majorityCount());
        for (final String server : peers.allServersIncludeMyself()) {
            if (isLeader(server)) {  // 首先自己的钥匙先用上
                latch.countDown();
                continue;
            }
            final String url = buildUrl(server, API_ON_PUB);  // /v1/ns/raft/datum/commit
            HttpClient.asyncHttpPostLarge(url, Arrays.asList(&quot;key&quot;, key), content, new Callback&lt;String&gt;() {
                @Override
                public void onReceive(RestResult&lt;String&gt; result) {
                    latch.countDown();  // Http调用正常后，则当作一次ack
                }
 
                @Override
                public void onError(Throwable throwable) {
                     
                }
 
                @Override
                public void onCancel() {
 
                }
            });
 
        }
    } finally {
        OPERATE_LOCK.unlock();
    }
</code></pre>
<p>其实Nacos实现的简单Raft协议，逻辑有点不太严谨，就是：即使本次同步不成功，但是主节点的本地磁盘文件 + 内存文件 已经都修改过了，不像Zookeeper的两阶段提交；</p>
<p>后期Nacos的一致性协议会修改为JRaft，这点肯定会解决！</p>
<h4 id="3-leader本节点保存数据的逻辑onpublishdatum-peerslocal">3、Leader本节点保存数据的逻辑：onPublish(datum, peers.local())</h4>
<pre><code class="language-java">public void onPublish(Datum datum, RaftPeer source) throws Exception {
    ......
 
    // 逻辑能走到这，这个if正常都为true
    if (KeyBuilder.matchPersistentKey(datum.key)) {
        // 核心，将数据写到本地磁盘
        raftStore.write(datum);
    }
 
    // 往内存中保存一些注册表信息
    datums.put(datum.key, datum);
 
    if (isLeader()) {
        local.term.addAndGet(PUBLISH_TERM_INCREASE_COUNT);
    } else {
        if (local.term.get() + PUBLISH_TERM_INCREASE_COUNT &gt; source.term.get()) {
            //set leader term:
            getLeader().term.set(source.term.get());
            local.term.set(getLeader().term.get());
        } else {
            local.term.addAndGet(PUBLISH_TERM_INCREASE_COUNT);
        }
    }
    raftStore.updateTerm(local.term.get());
 
    // 发布一个ValueChangeEvent事件，PersistentNotifier.onEvent(ValueChangeEvent)会去处理这个事件
    NotifyCenter.publishEvent(ValueChangeEvent.builder().key(datum.key).action(DataOperation.CHANGE).build());
    Loggers.RAFT.info(&quot;data added/updated, key={}, term={}&quot;, datum.key, local.term);
}
</code></pre>
<p>Leader保存本节点数据，分为三个过程：</p>
<ul>
<li><strong>1. 保存数据到磁盘文件</strong></li>
<li><strong>2. 保存部分信息到缓存datums</strong></li>
<li><strong>3. 保存文件到内存中的服务注册表（双层ConcurrentHashMap）—— 但不是同步保存，而是通过事件发布，实现异步保存</strong></li>
</ul>
<p>需要保存到内存中的服务注册表时，会发布一个ValueChangeEvent事件，该事件会被PersisNotifier.onEvent(ValueChangeEvent)捕捉到，并进行处理：</p>
<pre><code class="language-java">// com.alibaba.nacos.naming.consistency.persistent.PersistentNotifier#onEvent
public void onEvent(ValueChangeEvent event) {
    notify(event.getKey(), event.getAction(), find.apply(event.getKey()));
}

public &lt;T extends Record&gt; void notify(final String key, final DataOperation action, final T value) {
    ......
 
    for (RecordListener listener : listenerMap.get(key)) {
        try {
            if (action == DataOperation.CHANGE) {
                listener.onChange(key, value); //执行updateIps更新内存注册表
                continue;
            }
            if (action == DataOperation.DELETE) {
                listener.onDelete(key);
            }
        } catch (Throwable e) {
            ......
        }
    }
}

public void onChange(String key, Instances value) throws Exception {    
    ......
    
   // 更新注册表（这个方法，在AP架构师，重点介绍过）
    updateIPs(value.getInstanceList(), KeyBuilder.matchEphemeralInstanceListKey(key));
     
    recalculateChecksum();
}
</code></pre>
<p>至此，整个Leader节点的持久化节点注册逻辑就完成了！</p>
<p>同步数据给其它Follower节点，就是HTTP调用“raft/datum/commit”接口，处理逻辑比主节点简单！</p>
<hr>
<h3 id="三-nacos-cp集群选举过程">三 Nacos CP集群选举过程</h3>
<h4 id="1-集群节点启动时会执行raftcoreinit核心方法">1 集群节点启动时，会执行RaftCore.init()核心方法</h4>
<p>这个Init()核心方法，会启动2个核心定时任务（每500ms执行一次）：</p>
<ul>
<li><strong>选举任务：new MasterElection()</strong></li>
<li><strong>心跳任务：new HeartBeat()</strong></li>
</ul>
<pre><code class="language-java">@Component
public class RaftCore implements Closeable {
    @PostConstruct
    public void init() throws Exception {
        // 启动CP集群节点
        raftStore.loadDatums(notifier, datums);  //从本地磁盘文件加载数据
     
        // 如果Leader周期不存在，则置为0
        setTerm(NumberUtils.toLong(raftStore.loadMeta().getProperty(&quot;term&quot;), 0L));
        initialized = true;
     
        // 每500ms做一次选举任务
        masterTask = GlobalExecutor.registerMasterElection(new MasterElection());
        // 每500ms做一次心跳任务
        heartbeatTask = GlobalExecutor.registerHeartbeat(new HeartBeat());
     
        versionJudgement.registerObserver(isAllNewVersion -&gt; {
            stopWork = isAllNewVersion;
            if (stopWork) {
                try {
                    shutdown();
                    raftListener.removeOldRaftMetadata();
                } catch (NacosException e) {
                    throw new NacosRuntimeException(NacosException.SERVER_ERROR, e);
                }
            }
        }, 100);
     
        // 注册PersistentNotifier监听器，用来监听处理 ValueChangeEvent 事件，保存内存中服务注册表时用的
        NotifyCenter.registerSubscriber(notifier);
    }
 
}
</code></pre>
<h4 id="2-选举任务的核心run方法">2 选举任务的核心run()方法</h4>
<pre><code class="language-java">public class MasterElection implements Runnable {
 
    @Override
    public void run() {
        try {
            RaftPeer local = peers.local();
            local.leaderDueMs -= GlobalExecutor.TICK_PERIOD_MS;
 
            if (local.leaderDueMs &gt; 0) {
                return;
            }
 
            // Raft选举前的随机休眠阶段（15s到20s之间的随机值）
            local.resetLeaderDue();
            // 重新心跳时间为5s
            local.resetHeartbeatDue();
 
            // 率先跳出休眠的节点，发起投票
            sendVote();
        } catch (Exception e) {
             
        }
 
    }
 
    private void sendVote() {
 
        RaftPeer local = peers.get(NetUtils.localServer());
         
        // 重置集群节点投票
        peers.reset();
 
        // 选举周期+1
        local.term.incrementAndGet();
        // 默认投给自己
        local.voteFor = local.ip;
        // 把自己的状态改为 “候选者”
        local.state = RaftPeer.State.CANDIDATE;
 
        Map&lt;String, String&gt; params = new HashMap&lt;&gt;(1);
        params.put(&quot;vote&quot;, JacksonUtils.toJson(local));
        for (final String server : peers.allServersWithoutMySelf()) {
            // 其它节点的API接口为：/raft/vote
            final String url = buildUrl(server, API_VOTE); 
            try {
                // 向其它节点发出选票
                HttpClient.asyncHttpPost(url, null, params, new Callback&lt;String&gt;() {
                    @Override
                    //其它节点给本节点的响应
                    public void onReceive(RestResult&lt;String&gt; result) { 
                        if (!result.ok()) {
                            Loggers.RAFT.error(&quot;NACOS-RAFT vote failed: {}, url: {}&quot;, result.getCode(), url);
                            return;
                        }
 
                        RaftPeer peer = JacksonUtils.toObj(result.getData(), RaftPeer.class);
 
 
                        // 判断是否达到半数选票，成为Leader
                        peers.decideLeader(peer);
 
                    }
 
                    @Override
                    public void onError(Throwable throwable) {
                         
                    }
 
                    @Override
                    public void onCancel() {
 
                    }
                });
            } catch (Exception e) {
                 
            }
        }
    }
}
</code></pre>
<h4 id="3-其它节点收到投票后的处理逻辑">3 其它节点收到投票后的处理逻辑</h4>
<ul>
<li>如果<strong>收到的候选节点的term小于自己本地节点的term，则voteFor自己</strong>；（我更适合做Leader，这一票我投给自己）</li>
<li><strong>否则，<strong>重置自己的election timeout，设置</strong>voteFor为收到的候选节点，更新集群周期term为候选节点的term</strong>；（我同意收到的节点做Leader）</li>
</ul>
<p>给Http的调用方返回response；</p>
<hr>
<h3 id="四-nacos-cp集群的心跳任务">四 Nacos CP集群的心跳任务</h3>
<h4 id="1-心跳任务由leader节点发出有2个作用">1 心跳任务由Leader节点发出，有2个作用</h4>
<ul>
<li><strong>确定Follower节点在线；</strong></li>
<li><strong>帮助Follower节点判断数据是否一致；</strong>（因为服务注册或变更时，Leader节点自己修改了，且收到了“过半”以上节点的ack，但是不排除有些节点没有执行成功，所以通过心跳任务，进行纠错容错）</li>
</ul>
<h4 id="2-心跳任务的核心run方法只有leader节点才可以向其它节点发送心跳包">2 心跳任务的核心run()方法(只有Leader节点才可以向其它节点发送心跳包)</h4>
<pre><code class="language-java">public class HeartBeat implements Runnable {
 
    @Override
    public void run() {
        try {
            if (stopWork) {
                return;
            }
            if (!peers.isReady()) {
                return;
            }
 
            RaftPeer local = peers.local();
            // 任务每0.5s执行一次，每次减0.5s，总共5s减完后，就可以开始sendBeat()
            local.heartbeatDueMs -= GlobalExecutor.TICK_PERIOD_MS;
            if (local.heartbeatDueMs &gt; 0) {
                return;
            }
             
            // 重置心跳间隔时间为5s
            local.resetHeartbeatDue();
 
            sendBeat();
        } catch (Exception e) {
            Loggers.RAFT.warn(&quot;[RAFT] error while sending beat {}&quot;, e);
        }
 
    }
 
    private void sendBeat() throws IOException, InterruptedException {
        RaftPeer local = peers.local();
        // 如果当前是单机模式，或者本节点不是Leader节点，则无权发送心跳，直接跳过
        if (EnvUtil.getStandaloneMode() || local.state != RaftPeer.State.LEADER) {
            return;
        }
 
        local.resetLeaderDue();
 
        // build data
        ObjectNode packet = JacksonUtils.createEmptyJsonNode();
        packet.replace(&quot;peer&quot;, JacksonUtils.transferToJsonNode(local));
 
        ArrayNode array = JacksonUtils.createEmptyArrayNode();
 
        if (switchDomain.isSendBeatOnly()) {
            Loggers.RAFT.info(&quot;[SEND-BEAT-ONLY] {}&quot;, switchDomain.isSendBeatOnly());
        }
 
        // 封装心跳包，从内存中获取Leader节点注册表缓存中抽取数据的key和timestamp值
        if (!switchDomain.isSendBeatOnly()) {
            for (Datum datum : datums.values()) {
 
                ObjectNode element = JacksonUtils.createEmptyJsonNode();
 
                if (KeyBuilder.matchServiceMetaKey(datum.key)) {
                    element.put(&quot;key&quot;, KeyBuilder.briefServiceMetaKey(datum.key));
                } else if (KeyBuilder.matchInstanceListKey(datum.key)) {
                    element.put(&quot;key&quot;, KeyBuilder.briefInstanceListkey(datum.key));
                }
                element.put(&quot;timestamp&quot;, datum.timestamp.get());
 
                array.add(element);
            }
        }
 
        packet.replace(&quot;datums&quot;, array);
        // broadcast
        Map&lt;String, String&gt; params = new HashMap&lt;String, String&gt;(1);
        params.put(&quot;beat&quot;, JacksonUtils.toJson(packet));
 
        String content = JacksonUtils.toJson(params);
 
        // 对心跳包做gzip压缩
        ByteArrayOutputStream out = new ByteArrayOutputStream();
        GZIPOutputStream gzip = new GZIPOutputStream(out);
        gzip.write(content.getBytes(StandardCharsets.UTF_8));
        gzip.close();
 
        byte[] compressedBytes = out.toByteArray();
        String compressedContent = new String(compressedBytes, StandardCharsets.UTF_8);
 
        // 把压缩后的心跳包，发送给除自己外的其他所有节点
        for (final String server : peers.allServersWithoutMySelf()) {
            try {
                // 心跳包的API为：/raft/beat
                final String url = buildUrl(server, API_BEAT);
 
                HttpClient.asyncHttpPostLarge(url, null, compressedBytes, new Callback&lt;String&gt;() {
                    @Override
                    public void onReceive(RestResult&lt;String&gt; result) {
                        peers.update(JacksonUtils.toObj(result.getData(), RaftPeer.class));
                    }
 
                    @Override
                    public void onError(Throwable throwable) {
 
                    }
 
                    @Override
                    public void onCancel() {
 
                    }
                });
            } catch (Exception e) {
 
            }
        }
 
    }
}
</code></pre>
<h4 id="3-follower节点收到心跳包后的处理逻辑">3 Follower节点收到心跳包后的处理逻辑</h4>
<ul>
<li>Leader发出的<strong>心跳包中，包含了数据中的所有key和timestamp</strong>，Follower节点<strong>通过遍历对比，可以排查</strong>自己数据是否为最新最全<strong>数据</strong>；</li>
<li>如果<strong>数据不是最新或最全的，则</strong>批量从Leader节点<strong>获取不一致的数据的最新值</strong>；（Leader节点新增或修改的数据）</li>
<li>同时要<strong>删除掉自己比Leader多出来的数据</strong>；（Leader节点删除掉的数据）</li>
</ul>
<pre><code class="language-java">public RaftPeer receivedBeat(JsonNode beat) throws Exception {
     
    ...从心跳包中解析数据...
     
    // 设置Leader为发送心跳包给我的机器，因为只有Leader才可以发送心跳包
    peers.makeLeader(remote);
 
    if (!switchDomain.isSendBeatOnly()) {
        // receivedKeysMap 的作用是判断出本节点 比 Leader节点多出来的数据（见方法的最后）
        Map&lt;String, Integer&gt; receivedKeysMap = new HashMap&lt;&gt;(datums.size());
 
        for (Map.Entry&lt;String, Datum&gt; entry : datums.entrySet()) {
            // 如果这个Map中的数据为0，则代表是本地自己的数据；
            // 接收到的主节点数据时，把对应的值改为1；
            // 那么直到处理最后，这个Map中还有0，说明这条数据在主节点并没有，只有一种可能，这条数据在主节点中被删除掉了！（妙）
            // 最后，可以把这些数据，在本地清除掉
            receivedKeysMap.put(entry.getKey(), 0);
        }
 
        // batch用来收集本节点没有的数据，或者不是最新的数据
        List&lt;String&gt; batch = new ArrayList&lt;&gt;();
 
        int processedCount = 0; // 已处理的数据条数
 
        for (Object object : beatDatums) {
            processedCount = processedCount + 1;
                
            ......
 
            receivedKeysMap.put(datumKey, 1);
 
            try {
                // 包含，且我自己缓存中这条key对应的数据的时间戳&gt;=收到的心跳中的数据，则代表这条数据我有，就可以跳出本轮
                if (datums.containsKey(datumKey) &amp;&amp; datums.get(datumKey).timestamp.get() &gt;= timestamp
                        &amp;&amp; processedCount &lt; beatDatums.size()) {
                    continue;
                }
 
                // 取反，不满足上面的条件，则说明这条数据我没有，或者不是最新的，则收集到batch中
                // 因为节点变化的时候，虽然Leader节点收到了半数以上的ack，但是毕竟还有可能有些节点没有收到，或者处理不成功，所以这里通过心跳包进行数据同步的容错处理
                if (!(datums.containsKey(datumKey) &amp;&amp; datums.get(datumKey).timestamp.get() &gt;= timestamp)) {
                    batch.add(datumKey);
                }
 
                // 当batch的数据量&gt;=50或者数据已经全部处理完，则就可以继续下面向Leader节点发起批量请求数据的逻辑；
                // 反过来，如果batch&lt;50，且数据还没有处理完，那么这里先跳过，不要向Leader节点发起批量获取数据的请求
                if (batch.size() &lt; 50 &amp;&amp; processedCount &lt; beatDatums.size()) {
                    continue;
                }
 
                String keys = StringUtils.join(batch, &quot;,&quot;);
 
                // 如果batch为空，当然也不用发请求
                if (batch.size() &lt;= 0) {
                    continue;
                }
 
                // update datum entry
                String url = buildUrl(remote.ip, API_GET);
                Map&lt;String, String&gt; queryParam = new HashMap&lt;&gt;(1);
                queryParam.put(&quot;keys&quot;, URLEncoder.encode(keys, &quot;UTF-8&quot;));
 
                // 从Leader批量获取本节点缺少的或过时的数据
                HttpClient.asyncHttpGet(url, null, queryParam, new Callback&lt;String&gt;() {
                    @Override
                    public void onReceive(RestResult&lt;String&gt; result) {
                     
                        ...获取缺少的或过时的数据成功后...
 
                        for (JsonNode datumJson : datumList) {
                            Datum newDatum = null;
                            OPERATE_LOCK.lock();
                            try {
 
                                ......
 
                                // 和上面Leader节点新增数据时候逻辑相同，写内存注册表
                                raftStore.write(newDatum);
 
                                datums.put(newDatum.key, newDatum);
                                notifier.notify(newDatum.key, DataOperation.CHANGE, newDatum.value);
 
                                ......
 
                            } catch (Throwable e) {
 
                            } finally {
                                OPERATE_LOCK.unlock();
                            }
                        }
                        return;
                    }
 
                    @Override
                    public void onError(Throwable throwable) {
 
                    }
 
                    @Override
                    public void onCancel() {
 
                    }
 
                });
 
                batch.clear();
 
            } catch (Exception e) {
                 
            }
 
        }
 
        // 如果最后receivedKeysMap中还有value为0的数据，说明这些数据在主节点已经被删除了，那我们从节点也主动删除一下
        List&lt;String&gt; deadKeys = new ArrayList&lt;&gt;();
        for (Map.Entry&lt;String, Integer&gt; entry : receivedKeysMap.entrySet()) {
            if (entry.getValue() == 0) {
                deadKeys.add(entry.getKey());
            }
        }
 
        for (String deadKey : deadKeys) {
            try {
                deleteDatum(deadKey);  //删除本节点多出来的数据逻辑
            } catch (Exception e) {
                 
            }
        }
 
    }
 
    return local;
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Nacos核心源码剖析（AP架构）——注册中心]]></title>
        <id>https://tinaxiawuhao.github.io/post/zMtbXOeeT/</id>
        <link href="https://tinaxiawuhao.github.io/post/zMtbXOeeT/">
        </link>
        <updated>2022-07-02T12:23:25.000Z</updated>
        <content type="html"><![CDATA[<p>Nacos官方文档：https://nacos.io/zh-cn/docs/quick-start.html</p>
<p>服务端对外暴露的API：https://nacos.io/zh-cn/docs/open-api.html</p>
<p>Nacos的Server端其实就是一个Web服务，对外提供了Http服务接口，所有的客户端与服务端的通讯都通过Http调用完成（短链接）。</p>
<blockquote>
<p><strong>Nacos注册服务核心类：NacosNamingService</strong></p>
<p><strong>Nacos配置中心核心类：NacosConfigService</strong></p>
</blockquote>
<hr>
<h3 id="一-微服务中常用的注册中心对比">一 微服务中常用的注册中心对比</h3>
<ul>
<li>Zookeeper（Apache）：典型的CP架构，有Leader节点，在选举Leader的过程中，整个集群对外不可用，为了强一致性，牺牲高可用性！（Client与Server之间为心跳维持的TCP长连接）</li>
<li>Eureka（Netflix）：AP架构，为了高可用性，牺牲强一致性；服务提供者新节点注册后，消费者需要一定的时间后才能拿到最新服务列表，最长可达60s；</li>
<li>Nacos（阿里）：参考了Zookeeper+Eureka，同时支持AP/CP架构，集群默认为AP架构，也可以通过配置切换为CP架构（Raft）；服务列表变动后，消费者获取最新列表最然会有一点延迟，但是比Eureka好很多，而且还可以通过udp实时通知，虽然UDP可靠性无法保证！（Client与Server之间为短链接Http调用）</li>
</ul>
<hr>
<h3 id="二-nacos的服务架构图">二 NACOS的服务架构图</h3>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1658665780310.png" alt="" loading="lazy"></figure>
<ul>
<li>**服务注册+服务心跳：**首先无论是“服务提供者”还是“服务消费者”都会将自己注册到nacos，并维持心跳。（每5秒发送一次心跳包）</li>
<li>**服务健康检查：**服务端再启动后，会以Service为单位，开启ClientBeatCheckTask心跳检查任务。（每5秒检查一次，如果某个客户端最后一次心跳超过15秒，标记为不健康，超过30秒踢除）</li>
<li><strong>服务发现：</strong>“服务消费者”会根据需要自己的自己所需的目标服务的namespace/group/serviceName/cluster只根据需要查询对应的服务注册表，保存在本地。（定时每10s去服务端更新一次）！</li>
<li>**服务同步：**服务端集群之间会同步服务注册表，用来保证服务信息的一致性！（注意AP架构的集群中，即使配置了mysql，也不是用来存放注册表）</li>
</ul>
<hr>
<h3 id="三-nacos的核心注册表结构双层concurrenthashmap">三 Nacos的核心注册表结构（双层ConcurrentHashMap）</h3>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1658665797704.png" alt="" loading="lazy"></figure>
<h4 id="1-nacos和eureka的注册表底层都是双层concurrenthashmap">1 Nacos和Eureka的注册表底层都是双层ConcurrentHashMap</h4>
<pre><code class="language-java">// 本篇只介绍Nacos
public class ServiceManager implements RecordListener&lt;Service&gt; {
    // Nacos服务注册表的实际存储结构（双层Map）
    Map&lt;String, Map&lt;String, Service&gt;&gt; serviceMap = new ConcurrentHashMap&lt;&gt;()
    //Map&lt;nameSpaceId, Map&lt;group::serverName, Service&gt;&gt; ————&gt; 通过nameSpaceId + group::serviceName定位到具体的服务(Service)
         
    //其中的Service服务实例的结构：
    public class Service {
        private Map&lt;String, Cluster&gt; clusterMap = new HashMap&lt;&gt;();
        //Map&lt;clusterName, Cluster&gt; ————&gt; 在具体的serviceInstance内通过clusterName定位到具体的Cluster集群
         
        //而Cluster集群，又是这样的结构
        public class Cluster {
            private Set&lt;Instance&gt; ephemeralInstances = new HashSet&lt;&gt;(); //这就是实际可以对外提供的单个服务（serviceInstanceItem）
        }
    }
}
</code></pre>
<blockquote>
<p>总结：Nacos底层数据结构，显示一个双层Map，<br>
—— 1、服务发现阶段，通过nameSpaceId, group::serviceName找到对应的服务 Service服务<br>
—— 2、在服务Service内通过clusterName定位到具体的集群Cluster<br>
—— 3、在Cluster集群里面以HashSet的形式，存放着所有能够提供服务的每个实例Instance（这个Instance中有访问它的详细信息），最后把整个Set列表返回给客户端即可!</p>
</blockquote>
<h4 id="2-nacos这么多层的配置该如何使用">2 Nacos这么多层的配置，该如何使用？</h4>
<ul>
<li>最佳实践一（中小型公司）：</li>
</ul>
<pre><code class="language-yaml">// namespace：用来区分不通的项目，如haier-iot / haier-code / cold-chain 
// group：用来区分不通项目的 prod / test / dev 等环境
// ————spring.application.name————
// cluster：可以以低于来划分集群：BJ / NJ / SH
 
// 示例：
spring:
  application:
    name: haier-iot-device-manager
  cloud:
    nacos:
      discovery:
        server-addr: 10.206.73.156:8848
        namespace: haier-iot
        group: dev
        cluster-name: BJ  //可以不区分
      config:
        server-addr: 10.206.73.156:8848
        file-extension: yaml
        namespace: haier-iot
        group: dev
        cluster-name: BJ  //可以不区分
</code></pre>
<ul>
<li>最佳实践二（大型公司）：</li>
</ul>
<pre><code class="language-yaml">//与最佳实践一的区别在于，直接使用nacos项目专用，直接使用 namespace 区分环境
// namespace：直接用来区分 prod / test / dev 等环境
// group：使用 DEFAULT_GROUP，因为微服务有可能太多，管理容易混乱；同时这一层可以做扩展，比如多个小服务可能属于另一个大服务下；
// ————spring.application.name————
// cluster：可以以低于来划分集群：BJ / NJ / SH
 
// 示例：
spring:
  application:
    name: haier-iot-device-manager
  cloud:
    nacos:
      discovery:
        server-addr: 10.206.73.156:8848
        namespace: dev 
        group: DEFAULT_GROUP  //默认GROUP可以不指定 
        cluster-name: BJ  //可以不区分
      config:
        server-addr: 10.206.73.156:8848
        namespace: dev
        group: DEFAULT_GROUP  //默认GROUP可以不指定
        file-extension: yaml
</code></pre>
<h4 id="3-为什么nacos要设计这么复杂的数据结构">3 为什么Nacos要设计这么复杂的数据结构</h4>
<p>因为Nacos是一个开放的产品，为了适应绝大多数使用者的使用场景，所以扩展性一定要好，这么多层的设计，几乎可以满足任意复杂的业务场景！</p>
<hr>
<h3 id="三-nacos的注册表写入性能保证">三 Nacos的注册表写入性能保证</h3>
<h4 id="1-nacos怎么负责的注册表结构如何支撑高并发场景阻塞队列-异步注册">1 Nacos怎么负责的注册表结构，如何支撑高并发场景？（阻塞队列、异步注册）</h4>
<pre><code class="language-java">// 使用内存阻塞队列实现异步注册 —— 当接收到provider的注册时，Nacos服务端会将任务封装成Task
public class DistroConsistencyServiceImpl{
    @PostConstruct
    public void init() {
        GlobalExecutor.submitDistroNotifyTask(notifier);
    }
     
    // 而notifier是一个线程，单线程处理服务注册任务，也避免了“并发覆盖”问题！
    public class Notifier implements Runnable {
        private BlockingQueue&lt;Pair&lt;String, DataOperation&gt;&gt; tasks = new ArrayBlockingQueue&lt;&gt;(1024 * 1024);
         
        // run()方法就是在处理放入到tasks队列中的Task任务
        @Override
        public void run() {            
            for (; ; ) {  // 死循环，即使出现异常也不会退出
                try {
                    Pair&lt;String, DataOperation&gt; pair = tasks.take(); //阻塞队列不消耗CPU
                    handle(pair);
                } catch (Throwable e) {
                    Loggers.DISTRO.error(&quot;[NACOS-DISTRO] Error while handling notifying task&quot;, e);
                }
            }
        }
         
    }
     
     
    // 新的Instance任务被封装成Task任务，放入到Notifier中
    public void put(String key, Record value) throws NacosException {
        onPut(key, value);  // 任务被封装成
        distroProtocol.sync(new DistroKey(key, KeyBuilder.INSTANCE_LIST_KEY_PREFIX), DataOperation.CHANGE,
                globalConfig.getTaskDispatchPeriod() / 2);
    }
     
    public void onPut(String key, Record value) {
        ...边缘逻辑...
        notifier.addTask(key, DataOperation.CHANGE);
    }
 
}
</code></pre>
<h4 id="2-使用阻塞队列实现异步注册会不会存在不一致问题还没注册成功就给客户端返回结果">2 使用阻塞队列实现异步注册，会不会存在不一致问题，还没注册成功就给客户端返回结果？</h4>
<blockquote>
<p>是的，肯定会存在这个问题，但是这是一个取舍，高性能的中间件内部都使用了大量的异步操作；<br>
想一想，我们的应用程序可能依赖很多第三方服务，如果第三方中间件都用同步的方式去执行自己的内部逻辑，那么应用程序的启动将变得非常地缓慢，最后的效果肯定是难以接受的；<br>
—— 支持高并发！<br>
—— 要说不及时，之前的Eureka更严重！<br>
其实正常情况下，几乎不会太过阻塞，因为几乎没有多少公司，是一次性增加n多台服务的，都是慢慢添加的，而且即使个别慢了，也是可以接受的，先用其它服务节点即可，站在服务消费者的角度，也就是provider服务起得有点慢而已。</p>
</blockquote>
<h4 id="3-为了解决高并发下的读写冲突问题nacos使用了copyonwrite方案">3 为了解决高并发下的读写冲突问题，Nacos使用了CopyOnWrite方案</h4>
<pre><code class="language-java">// 在Notifier.run()方法中：
listener.onChange(datumKey, dataStore.get(datumKey).value);
|
com.alibaba.nacos.naming.core.Service#onChange(){
    updateIPs(value.getInstanceList(), KeyBuilder.matchEphemeralInstanceListKey(key));
}
|
com.alibaba.nacos.naming.core.Service#updateIPs(){
    clusterMap.get(entry.getKey()).updateIps(entryIPs, ephemeral);
}
|
com.alibaba.nacos.naming.core.Cluster#updateIps{
    Set&lt;Instance&gt; toUpdateInstances = ephemeral ? ephemeralInstances : persistentInstances;
 
    // 将旧的临时实例ephemeralInstances列表，复制转化为一个Map进行更新操作
    HashMap&lt;String, Instance&gt; oldIpMap = new HashMap&lt;&gt;(toUpdateInstances.size());
    for (Instance ip : toUpdateInstances) {
        oldIpMap.put(ip.getDatumKey(), ip);
    }
     
    //...对旧Set拷贝后转化为HashMap进行更新操作...
     
    toUpdateInstances = new HashSet&lt;&gt;(ips);
    if (ephemeral) {
        ephemeralInstances = toUpdateInstances;
    } else {
        persistentInstances = toUpdateInstances;
    }
}
</code></pre>
<h4 id="4-同时n多个实例注册或更新都进行copyonwrite岂不是会存在更新覆盖">4 同时n多个实例注册或更新，都进行CopyOnWrite，岂不是会存在“更新覆盖”？</h4>
<pre><code class="language-java">// 1、首先，根据上面的第1条，Notifier的执行是一个单线程执行任务：
/// Notifier所在类DistroConsistencyServiceImpl是一个单例Service，@PostConstruct决定了init方法只会被调用一次：
//// 而GlobalExecutor 是一个单线程的线程池，所以处理实例注册的最终线程只会有一个
@PostConstruct
public void init() {
    GlobalExecutor.submitDistroNotifyTask(notifier);
}
 
// 2、CopyOnWrite后的集合中的元素不能直接修改，因为集合中的元素是引用！
// —— 当新增时，直接在新集合中新增Instance，然后替换原注册表中的集合即可！
// —— 当删除时，直接将新集合中的对应Instance删除，然后替换原注册表中的集合即可！
// —— 当更新时，新增一个Instance，然后删除原集合中的Instance元素，增加新的Instance元素即可！
// ————原则就是：永远是替换，不直接修改原Instance对象！
</code></pre>
<h4 id="5-随着注册表的不断增大进行copyonwrite时候的成本是不是变得非常大">5 随着注册表的不断增大，进行CopyOnWrite时候的成本是不是变得非常大？</h4>
<pre><code class="language-java">// 当然不是每次直接Copy整张注册表，那样开销肯定很大
// 每次Copy的粒度是缩小到Service下对应的Cluster中的Set&lt;Instance&gt;集合，这个粒度是很小的！
public class Cluster extends com.alibaba.nacos.api.naming.pojo.Cluster implements Cloneable {
    private Set&lt;Instance&gt; persistentInstances = new HashSet&lt;&gt;();  // AP模式实例列表（服务发现得到的列表就是它）
    private Set&lt;Instance&gt; ephemeralInstances = new HashSet&lt;&gt;();  // CP模式实例列表（服务发现得到的列表就是它）
     
    // 更新节点的操作（Cluster级别）
    public void updateIps(List&lt;Instance&gt; ips, boolean ephemeral) {
        Set&lt;Instance&gt; toUpdateInstances = ephemeral ? ephemeralInstances : persistentInstances;
        HashMap&lt;String, Instance&gt; oldIpMap = new HashMap&lt;&gt;(toUpdateInstances.size());
         
        //...对旧Set拷贝后转化为HashMap进行更新操作...
         
        toUpdateInstances = new HashSet&lt;&gt;(ips);
        if (ephemeral) {
            ephemeralInstances = toUpdateInstances;
        } else {
            persistentInstances = toUpdateInstances;
        }
    }
}
// 为了性能，CopyOnWrite的粒度一定要越小越好！
</code></pre>
<hr>
<h3 id="四-nacos的心跳机制定时去调nacos服务端http接口">四 Nacos的心跳机制（定时去调Nacos服务端Http接口）</h3>
<p>核心类：NacosNamingService</p>
<h4 id="1-client在向服务端注册服务的同时开启定时任务向服务端发送心跳请求">1 Client在向服务端注册服务的同时，开启定时任务向服务端发送心跳请求</h4>
<pre><code class="language-java">// com.alibaba.nacos.client.naming.NacosNamingService#registerInstance()
// 既是注册服务的核心代码，也是发送心跳的核心代码
public void registerInstance(String serviceName, String groupName, Instance instance) throws NacosException {
    String groupedServiceName = NamingUtils.getGroupedName(serviceName, groupName);
    if (instance.isEphemeral()) {
        BeatInfo beatInfo = beatReactor.buildBeatInfo(groupedServiceName, instance);
        beatReactor.addBeatInfo(groupedServiceName, beatInfo);  // 发送心跳
    }
    serverProxy.registerService(groupedServiceName, groupName, instance); // 注册实例
}
|
public void addBeatInfo(String serviceName, BeatInfo beatInfo) {
    ...
    // 第一次调用 = 触发心跳任务
    executorService.schedule(new BeatTask(beatInfo), beatInfo.getPeriod(), TimeUnit.MILLISECONDS);
    ...
}
|
//BeatTask.run()任务核心代码：
public void run() {
    if (!this.beatInfo.isStopped()) {
        // 计算下一次发送的时间
        long nextTime = this.beatInfo.getPeriod();
 
        try {
            //此处就是去调用“发送心跳API”
            JsonNode result = BeatReactor.this.serverProxy.sendBeat(this.beatInfo, BeatReactor.this.lightBeatEnabled);
            ...对心跳发送结果进行处理...
        } catch (NacosException var11) {
            ...log...
        }
 
        //第二次发送心跳，循环进行，就形成定时发送心跳的效果
        BeatReactor.this.executorService.schedule(BeatReactor.this.new BeatTask(this.beatInfo), nextTime, TimeUnit.MILLISECONDS);
    }
}
</code></pre>
<p>我们再看看执行“心跳任务”的线程长啥样：</p>
<pre><code class="language-java">// 定时任务线程
this.executorService = new ScheduledThreadPoolExecutor(threadCount, new ThreadFactory() {
    @Override
    public Thread newThread(Runnable r) {
        Thread thread = new Thread(r);
        thread.setDaemon(true); // 守护线程（所有用户线程结束后，守护线程会自动结束）
        thread.setName(&quot;com.alibaba.nacos.naming.beat.sender&quot;);
        return thread;
    }
});
</code></pre>
<blockquote>
<p>所以“心跳包”的核心就是：<strong>通过一个定时任务守护线程，定时去调用Nacos服务端的发送心跳包的API接口！</strong></p>
</blockquote>
<h4 id="2-心跳包的默认间隔时间是多少5-15-30">2 “心跳包”的默认间隔时间是多少？（5-15-30）</h4>
<pre><code class="language-java">// 构建心跳包的信息
BeatInfo beatInfo = this.beatReactor.buildBeatInfo(groupedServiceName, instance);
 
beatInfo.setPeriod(instance.getInstanceHeartBeatInterval());
 
public long getInstanceHeartBeatInterval() {
    return this.getMetaDataByKeyWithDefault(&quot;preserved.heart.beat.interval&quot;, Constants.DEFAULT_HEART_BEAT_INTERVAL);
}
 
//而Constants.DEFAULT_HEART_BEAT_INTERVAL是个常量
static {
    DEFAULT_HEART_BEAT_TIMEOUT = TimeUnit.SECONDS.toMillis(15L);  //15秒 收不到心跳，则会被标记为“不健康”
    DEFAULT_IP_DELETE_TIMEOUT = TimeUnit.SECONDS.toMillis(30L);   //30秒 收不到心跳，则“剔除”该实例IP
    DEFAULT_HEART_BEAT_INTERVAL = TimeUnit.SECONDS.toMillis(5L);  //默认心跳时间 5秒
</code></pre>
<h4 id="3-nacos服务端对心跳包的处理逻辑服务健康检查定时任务每5秒健康检查">3 Nacos服务端对心跳包的处理逻辑(服务健康检查)？(定时任务，每5秒健康检查)</h4>
<pre><code class="language-java">// 以Service为单位，每个Service在被初始化时，都会创建一个健康检查器HealthCheckReactor
public class Service {
    public void init() {
    // HealthCheckReactor 健康检查器，也是通过schduled线程池去做检查的
    HealthCheckReactor.scheduleCheck(clientBeatCheckTask);
    for (Map.Entry&lt;String, Cluster&gt; entry : clusterMap.entrySet()) {
       entry.getValue().setService(this);
       entry.getValue().init();
    }
   }
}
|
// HealthCheckReactor.scheduleCheck()方法就是开启定时任务线程
|线程池大小为1~核数/2
public static void scheduleCheck(BeatCheckTask task) {
    futureMap.putIfAbsent(task.taskKey(), GlobalExecutor.scheduleNamingHealth(task, 5000, 5000, TimeUnit.MILLISECONDS));
    //延迟5秒后，每5秒执行一次
}
</code></pre>
<p>健康检查任务的核心 run() 方法逻辑：</p>
<pre><code class="language-java">public class ClientBeatCheckTask implements BeatCheckTask {
    @Override
    public void run() {
        //拿出Service中所有的实例（后面遍历检查）
        List&lt;Instance&gt; instances = service.allIPs(true);
 
        // 系统当前时间 - 最后一次心跳时间 &gt; 不健康阈值（15秒），标记为不健康
        for (Instance instance : instances) {
            if (System.currentTimeMillis() - instance.getLastBeat() &gt; instance.getInstanceHeartBeatTimeOut()) {
                if (!instance.isMarked()) {
                    if (instance.isHealthy()) {
                        instance.setHealthy(false);
                        Loggers.EVT_LOG
                            .info(&quot;{POS} {IP-DISABLED} valid: {}:{}@{}@{}, region: {}, msg: client timeout after {}, last beat: {}&quot;,
                                  instance.getIp(), instance.getPort(), instance.getClusterName(),
                                  service.getName(), UtilsAndCommons.LOCALHOST_SITE,
                                  instance.getInstanceHeartBeatTimeOut(), instance.getLastBeat());
                        getPushService().serviceChanged(service);
                    }
                }
            }
        }
 
        if (!getGlobalConfig().isExpireInstance()) {
            return;
        }
 
        // 系统当前时间 - 最后一次心跳时间 &gt; 可剔除阈值（30秒），直接剔除
        for (Instance instance : instances) {
            if (System.currentTimeMillis() - instance.getLastBeat() &gt; instance.getIpDeleteTimeout()) {
                // delete instance
                Loggers.SRV_LOG.info(&quot;[AUTO-DELETE-IP] service: {}, ip: {}&quot;, service.getName(),
                                     JacksonUtils.toJson(instance));
                deleteIp(instance);
            }
        }
         
    }
}
</code></pre>
<blockquote>
<p>所以“服务健康检查”的逻辑就是：<strong>服务端</strong>以Service为单位，<strong>使用</strong>定时任务线程池，每5秒检查一次<strong>Service中所有实例的状态</strong>：</p>
<p><strong>最后心跳时间距当前</strong>超过15秒，标记为不健康；</p>
<p><strong>最后心跳时间距当前</strong>超过30秒，将此实例踢除！</p>
</blockquote>
<hr>
<h3 id="五-服务发现">五 服务发现</h3>
<blockquote>
<ul>
<li>当服务消费者需要查询自己需要的服务列表时，会<strong>优先从本地缓存注册表获取数据，第一次获取为空时，才会从远程Server端获取</strong>；</li>
<li>从远程Server获取服务列表的<strong>粒度为Cluster粒度</strong>，同时还会<strong>将自己的udp端口告诉Server端，便于Server变化时的主动通知</strong>；</li>
<li>从远程Server获取列表的同时，还会<strong>启动定时任务，每隔10秒从Server端同步一次自己的注册表</strong>（只同步自己需要的）；</li>
<li><strong>udp通知的可靠性不能保证</strong>，但是影响不大，因为<strong>有定时任务同步托底</strong>！</li>
</ul>
</blockquote>
<h4 id="1-获取服务实例列表核心方法nacosnamingservicegetallinstances">1 获取服务实例列表核心方法：NacosNamingService#getAllInstances()</h4>
<pre><code class="language-java">public List&lt;Instance&gt; getAllInstances(String serviceName, String groupName, List&lt;String&gt; clusters, boolean subscribe) {
     
    ServiceInfo serviceInfo;
    if (subscribe) {  // 默认是开启订阅（udp通知），所以走这一分支
        serviceInfo = hostReactor.getServiceInfo(NamingUtils.getGroupedName(serviceName, groupName),
                StringUtils.join(clusters, &quot;,&quot;));
    } else {
        serviceInfo = hostReactor
                .getServiceInfoDirectlyFromServer(NamingUtils.getGroupedName(serviceName, groupName),
                        StringUtils.join(clusters, &quot;,&quot;));
    }
    List&lt;Instance&gt; list;
    if (serviceInfo == null || CollectionUtils.isEmpty(list = serviceInfo.getHosts())) {
        return new ArrayList&lt;Instance&gt;();
    }
    return list;
}
|
public ServiceInfo getServiceInfo(final String serviceName, final String clusters) {
    String key = ServiceInfo.getKey(serviceName, clusters);
    if (failoverReactor.isFailoverSwitch()) {
        return failoverReactor.getService(key); // 故障转移功能，从故障转移文件获取服务列表
    }
     
    // 从本地缓存的注册表获取服务列表
    ServiceInfo serviceObj = getServiceInfo0(serviceName, clusters);
     
    if (null == serviceObj) { // 第一次启动时候，缓存肯定为空，所以会走这一分支
        serviceObj = new ServiceInfo(serviceName, clusters);
         
        serviceInfoMap.put(serviceObj.getKey(), serviceObj);
         
        updatingMap.put(serviceName, new Object());
        updateServiceNow(serviceName, clusters);  // 核心去远程获取服务列表的方法
        updatingMap.remove(serviceName);
         
    } else if (updatingMap.containsKey(serviceName)) {
         
        if (UPDATE_HOLD_INTERVAL &gt; 0) {
            // hold a moment waiting for update finish
            synchronized (serviceObj) {
                try {
                    serviceObj.wait(UPDATE_HOLD_INTERVAL);
                } catch (InterruptedException e) {
                    NAMING_LOGGER
                            .error(&quot;[getServiceInfo] serviceName:&quot; + serviceName + &quot;, clusters:&quot; + clusters, e);
                }
            }
        }
    }
     
    scheduleUpdateIfAbsent(serviceName, clusters);  // 开启定时任务，定时更新本地注册表
     
    return serviceInfoMap.get(serviceObj.getKey());
}
</code></pre>
<p>从远程获取服务列表没啥看的，我们重点看看定时任务更新本地缓存注册表的逻辑：</p>
<pre><code class="language-java">public void scheduleUpdateIfAbsent(String serviceName, String clusters) {
    synchronized (futureMap) {
        if (futureMap.get(ServiceInfo.getKey(serviceName, clusters)) != null) {
            return;
        }
         
        // UpdateTask见名知意
        ScheduledFuture&lt;?&gt; future = addTask(new UpdateTask(serviceName, clusters));
        futureMap.put(ServiceInfo.getKey(serviceName, clusters), future);
    }
}
|
// 看看UpdateTask.run()核心方法：
public void run() {
    long delayTime = -1;
     
    try {
         
        ...一系列逻辑，但是最终都会走finally中的逻辑...
        delayTime = serviceObj.getCacheMillis();
         
    } catch (Throwable e) {
        NAMING_LOGGER.warn(&quot;[NA] failed to update serviceName: &quot; + serviceName, e);
    } finally {
        if (delayTime &gt; 0) {
            // delayTime默认为10秒
            executor.schedule(this, delayTime, TimeUnit.MILLISECONDS);
        }
    }
     
}
</code></pre>
<blockquote>
<p>所以“服务发现”的逻辑就是：在<strong>客户端启动时，会根据需要从Nacos服务端获取自己需要的服务列表（Cluster级别）</strong>，</p>
<ul>
<li>并保存到本地缓存中的注册表中，并开启一个定时任务，<strong>每隔10秒去服务端同步</strong>一下对应的注册表；</li>
<li>之后每次需要时，都是<strong>从本地缓存中的注册表获取服务列表即可</strong>！</li>
</ul>
</blockquote>
<h4 id="2-如何尽可能地保证本地注册表的实时性开启订阅开放udp端口">2 如何尽可能地保证本地注册表的实时性？(开启订阅，开放udp端口)</h4>
<p>从第一条中我们看到一个开启订阅的逻辑，在对应的分支中，从服务端获取服务列表时：</p>
<pre><code class="language-java">updateServiceNow(serviceName, clusters);
String result = serverProxy.queryList(serviceName, clusters, pushReceiver.getUdpPort(), false);
// pushReceiver.getUdpPort()
// 可以知道，从服务端获取服务列表时，顺便把自己的udp端口也传给了服务端
// 那么当服务端发现对应的服务列表有变动时，就可以通过此Udp端口通知到本Client
</code></pre>
<hr>
<h3 id="六-服务同步">六 服务同步</h3>
<blockquote>
<p>​    Nacos集群即使配置了外部mysql数据库，注册表信息也是存储在每个节点的内存中的，而不是存储在mysql中，而当Client向Nacos服务端注册时，只会选择一个Nacos Server节点注册，那么就必须有一套机制能够实现Nacos集群的各个节点都能同步到数据，Nacos自己实现了一套Distro协议，以实现分布式集群各节点之间的数据最终一致性！</p>
</blockquote>
<h4 id="1-什么时distro协议">1 什么时Distro协议？</h4>
<p>Distro协议时Nacos社区自研的一套AP分布式协议，为了集群的高可用，牺牲强一致性，只追求最终一致性！</p>
<ul>
<li>Nacos集群的每个节点时平等的，都可以处理读写请求，同时把数据同步到其他节点；</li>
<li>每个节点只负责部分数据（服务健康检查等），定时发送自己负责的数据的校验值到其他节点，以保证数据的一致性；</li>
<li>每个节点独立处理请求，不需要经过其他节点同意，及时从本地发起对Client端的相应！</li>
</ul>
<h4 id="2-nacos集群中的节点如何知道其它节点的存在">2 Nacos集群中的节点，如何知道其它节点的存在？</h4>
<p>得熟悉Nacos AP集群得部署方式，Nacos集群在部署时，需要在配置 cluster.conf 文件中配置集群得各个节点，这样每台机器就都知道集群中得其它节点得ip:port了;</p>
<pre><code class="language-java">@Component(&quot;serverListManager&quot;)
public class ServerListManager extends MemberChangeListener {
 
    @PostConstruct
    public void init() {
        // 集群节点状态同步任务，它会每2秒调用集群其它节点的状态接口，以判断节点是否还在线！
        GlobalExecutor.registerServerStatusReporter(new ServerStatusReporter(), 2000);
        GlobalExecutor.registerServerInfoUpdater(new ServerInfoUpdater());
    }
     
    // 集群节点状态同步任务，每2秒执行一次，
    ServerStatusReporter.run(){
        // 很简单，就是调用其它节点的状态接口，告诉其它机器自己还活着（集群中每两台机器直接都会互相调用）；
        // 如果某个节点在一定时间内，没有收到其它某个节点的状态报告，那就认为这个节点挂了，就会更新自己本地认为的集群存活节点数；
        // 集群存活节点数会直接影响到“服务健康检查”的目标机器核心变量，从而决定每个Service，将会在哪个Server节点被执行健康检查！
        synchronizer.send(server.getAddress(), msg);
    }
}
</code></pre>
<h4 id="3-服务注册任务由哪个节点负责如何同步数据到其他节点">3 “服务注册”任务由哪个节点负责？如何同步数据到其他节点？</h4>
<p>“服务注册”任务，有Client端发起，根据负载均衡算法挑选一台Server机器进行注册；</p>
<p>被挑选到的Server节点，处理自己的注册任务的同时，通过Distro协议，同步到集群中的其它节点；</p>
<pre><code class="language-java">// com.alibaba.nacos.naming.consistency.ephemeral.distro.DistroConsistencyServiceImpl#put
public void put(String key, Record value) throws NacosException {
    // 在本机处理服务注册请求
    onPut(key, value);  
    // 同步给其它机器进行注册
    distroProtocol.sync(new DistroKey(key, KeyBuilder.INSTANCE_LIST_KEY_PREFIX), DataOperation.CHANGE,
            globalConfig.getTaskDispatchPeriod() / 2);
}
</code></pre>
<h4 id="4-如何判断各个service的健康检查任务由集群中的哪个节点负责检查">4 如何判断各个Service的健康检查任务，由集群中的哪个节点负责检查？</h4>
<pre><code class="language-java">// 我们找到心跳检查任务的run()方法：
ClientBeatCheckTask.run(){
    // 判断是否该由本节点负责该Service的心跳检查任务
    if (!getDistroMapper().responsible(service.getName())) {
        return;
    }
    ...如果是自己负责该Service的心跳检查，才会继续执行心跳检查任务...
}
 
// 判断逻辑
public boolean responsible(String serviceName) {
    final List&lt;String&gt; servers = healthyList;
     
    if (!switchDomain.isDistroEnabled() || EnvUtil.getStandaloneMode()) {
        return true;
    }
     
    if (CollectionUtils.isEmpty(servers)) {
        // means distro config is not ready yet
        return false;
    }
     
    int index = servers.indexOf(EnvUtil.getLocalAddress());
    int lastIndex = servers.lastIndexOf(EnvUtil.getLocalAddress());
    if (lastIndex &lt; 0 || index &lt; 0) {
        return true;  // 自己不在集群列表中，那可能当前就不是集群部署，所以自己得检查
    }
     
    // 对serviceName进行hash后，对当前集群节点数量取余，看看是不是自己
    // 如果不是自己，不用担心，其它机器在被注册时，也会走到这条逻辑，总有一台机器是负责该Service的“健康检查”的
    int target = distroHash(serviceName) % servers.size();
    return target &gt;= index &amp;&amp; target &lt;= lastIndex;
}
</code></pre>
<h4 id="5-集群间两个重要的同步任务">5 集群间两个重要的同步任务</h4>
<pre><code class="language-java">1. ServerListManager下的ServerStatusReporter任务：
—— 上面已经讲过，在集群之间通过定时调用状态接口的方式，同步集群各节点的在线状态！
 
2. ServiceManager下的ServiceReporter任务：
—— 当某个节点执行完健康检查后，如果发现某个Service实例状态改变了，它必须要同步给集群中其它节点，修改各自注册表中的状态（通过调用InstanceController中的API接口实现）
</code></pre>
<h4 id="6-如果有新节点加入集群如果从其它节点同步数据">6 如果有新节点加入集群，如果从其它节点同步数据？</h4>
<pre><code class="language-java">// 每个节点启动时，会注入一个DistroProtocol的Bean
@Component
public class DistroProtocol {
    // 在DistroProtocol的构造函数中，会启动DistroTask数据同步任务
    public DistroProtocol(ServerMemberManager memberManager, DistroComponentHolder distroComponentHolder,
        DistroTaskEngineHolder distroTaskEngineHolder, DistroConfig distroConfig) {
        this.memberManager = memberManager;
        this.distroComponentHolder = distroComponentHolder;
        this.distroTaskEngineHolder = distroTaskEngineHolder;
        this.distroConfig = distroConfig;
        startDistroTask();
    }
     
    private void startDistroTask() {
        // 如果时单节点运行，就不用同步啦
        if (EnvUtil.getStandaloneMode()) {
            isInitialized = true;
            return;
        }
        startVerifyTask();
        startLoadTask(); // 开启数据加载任务
    }
     
    private void startLoadTask() {
            DistroCallback loadCallback = new DistroCallback() {
                @Override
                public void onSuccess() {
                    isInitialized = true;
                }
                 
                @Override
                public void onFailed(Throwable throwable) {
                    isInitialized = false;
                }
            };
            GlobalExecutor.submitLoadDataTask(
                    new DistroLoadDataTask(memberManager, distroComponentHolder, distroConfig, loadCallback));
        }
}
 
//DistroLoadDataTask任务的核心run()方法：
DistroLoadDataTask.run(){
    try {
        load(); // 从其它节点加载数据
        if (!checkCompleted()) {
            // 如果不成功，就开个延时任务，过会儿继续尝试去加载
            GlobalExecutor.submitLoadDataTask(this, distroConfig.getLoadDataRetryDelayMillis());
        } else {
            loadCallback.onSuccess();
            Loggers.DISTRO.info(&quot;[DISTRO-INIT] load snapshot data success&quot;);
        }
    } catch (Exception e) {
        loadCallback.onFailed(e);
        Loggers.DISTRO.error(&quot;[DISTRO-INIT] load snapshot data failed. &quot;, e);
    }
}
</code></pre>
<p>真正的load()从远程加载逻辑：</p>
<pre><code class="language-java">private void load() throws Exception {
    while (memberManager.allMembersWithoutSelf().isEmpty()) {
        Loggers.DISTRO.info(&quot;[DISTRO-INIT] waiting server list init...&quot;);
        TimeUnit.SECONDS.sleep(1);
    }
    while (distroComponentHolder.getDataStorageTypes().isEmpty()) {
        Loggers.DISTRO.info(&quot;[DISTRO-INIT] waiting distro data storage register...&quot;);
        TimeUnit.SECONDS.sleep(1);
    }
    for (String each : distroComponentHolder.getDataStorageTypes()) {
        if (!loadCompletedMap.containsKey(each) || !loadCompletedMap.get(each)) {
            loadCompletedMap.put(each, loadAllDataSnapshotFromRemote(each));
        }
    }
}
 
// for循环尝试从所有远程节点获取注册表全量文件，只要有一个成功，则跳出for循环
private boolean loadAllDataSnapshotFromRemote(String resourceType) {
    DistroTransportAgent transportAgent = distroComponentHolder.findTransportAgent(resourceType);
    DistroDataProcessor dataProcessor = distroComponentHolder.findDataProcessor(resourceType);
    if (null == transportAgent || null == dataProcessor) {
        Loggers.DISTRO.warn(&quot;[DISTRO-INIT] Can't find component for type {}, transportAgent: {}, dataProcessor: {}&quot;,
                resourceType, transportAgent, dataProcessor);
        return false;
    }
    for (Member each : memberManager.allMembersWithoutSelf()) {
        try {
            // 调取远程节点的获取DatumSnapshot快照数据接口
            DistroData distroData = transportAgent.getDatumSnapshot(each.getAddress());
            // 处理数据，加载到本节点内存的注册表中，完成新节点数据初始化
            boolean result = dataProcessor.processSnapshot(distroData);
 
            if (result) {
                return true;  // 有一个节点成功，则跳出全部for循环，直接返回成功结果
            }
        } catch (Exception e) {
            ......
        }
    }
    return false;
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[上传文件到亚马逊云S3对象存储]]></title>
        <id>https://tinaxiawuhao.github.io/post/PTmSAlH_U/</id>
        <link href="https://tinaxiawuhao.github.io/post/PTmSAlH_U/">
        </link>
        <updated>2022-07-01T12:20:27.000Z</updated>
        <content type="html"><![CDATA[<h3 id="一-在亚马逊云s3创建一个存储桶并设置权限">一 在亚马逊云S3创建一个存储桶，并设置权限</h3>
<h4 id="1-创建一个存储桶并将权限设置为公开因为我正常时候是用来存放网站图片">1 创建一个存储桶，并将权限设置为公开，因为我正常时候是用来存放网站图片</h4>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1658665353168.png" alt="" loading="lazy"></figure>
<h4 id="2-配置存储卷策略">2 配置存储卷策略</h4>
<pre><code class="language-json">{
    &quot;Version&quot;: &quot;2012-10-17&quot;,
    &quot;Statement&quot;: [
        {
            &quot;Sid&quot;: &quot;PublicReadGetObject&quot;,
            &quot;Effect&quot;: &quot;Allow&quot;,
            &quot;Principal&quot;: &quot;*&quot;,
            &quot;Action&quot;: &quot;s3:GetObject&quot;,
            &quot;Resource&quot;: &quot;arn:aws:s3:::test.jiguiquan.com/*&quot;
        }
    ]
}
</code></pre>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1658665363503.png" alt="" loading="lazy"></figure>
<h4 id="3-配置跨域策略">3 配置跨域策略</h4>
<pre><code class="language-json">[
    {
        &quot;AllowedHeaders&quot;: [
            &quot;*&quot;
        ],
        &quot;AllowedMethods&quot;: [
            &quot;PUT&quot;,
            &quot;POST&quot;,
            &quot;GET&quot;
        ],
        &quot;AllowedOrigins&quot;: [
            &quot;*&quot;
        ],
        &quot;ExposeHeaders&quot;: [
            &quot;x-amz-server-side-encryption&quot;,
            &quot;x-amz-request-id&quot;,
            &quot;x-amz-id-2&quot;
        ],
        &quot;MaxAgeSeconds&quot;: 3000
    }
]
</code></pre>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1658665372479.png" alt="" loading="lazy"></figure>
<blockquote>
<p><strong>到这里，存储卷的配置就算是OK啦，满足正常网站图片的使用了！</strong></p>
</blockquote>
<hr>
<h3 id="二-编写java类完成文件的上传">二 编写Java类，完成文件的上传</h3>
<h4 id="1-在项目中引入-aws-sdk-的依赖">1 在项目中引入 aws-sdk 的依赖</h4>
<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;com.amazonaws&lt;/groupId&gt;
    &lt;artifactId&gt;aws-java-sdk-s3&lt;/artifactId&gt;
    &lt;version&gt;1.11.347&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<h4 id="2-编写上传文件的接口">2 编写上传文件的接口</h4>
<pre><code class="language-java">@Api(tags = &quot;Auth——第三方服务模块&quot;)
@RestController
@RequiredArgsConstructor
public class ThirdpartyController {
 
    @Value(&quot;${s3.accessKeyId}&quot;)
    private String s3AccessKeyId;
    @Value(&quot;${s3.accessKeySecret}&quot;)
    private String s3AccessKeySecret;
    @Value(&quot;${s3.bucketName}&quot;)
    private String s3BucketName;
    @Value(&quot;${s3.region}&quot;)
    private String s3Region;
 
    private static BasicAWSCredentials awsCreds;
    private static AmazonS3 s3;
 
    @PostConstruct
    private void init(){
        awsCreds = new BasicAWSCredentials(s3AccessKeyId, s3AccessKeySecret);
        s3 = AmazonS3ClientBuilder.standard()
                .withCredentials(new AWSStaticCredentialsProvider(awsCreds))
                //设置服务器所属地区
                .withRegion(s3Region)
                .build();
    }
 
    @ApiResponses({@ApiResponse(code = 200, message = &quot;文件url&quot;)})
    @ApiOperation(&quot;后端直接上传文件到亚马逊云S3&quot;)
    @PostMapping(&quot;/auth/s3/upload&quot;)
    public BaseResponse&lt;String&gt; uploadFileToS3(@RequestParam(&quot;file&quot;) MultipartFile file) {
        if (file.getSize() == 0){
            throw ZidanApiException.create(BmoonResponseCode.FILE_SIZE_ZERO);
        }
        if (StringUtils.isBlank(file.getOriginalFilename())){
            throw ZidanApiException.create(BmoonResponseCode.FILE_NAME_EMPTY);
        }
        // String host = &quot;https://s3.&quot; + s3Region + &quot;.amazonaws.com/&quot; + s3BucketName;
        String host = &quot;https://s3.ap-northeast-2.amazonaws.com/test.jiguiquan.com&quot;;
        String format = new SimpleDateFormat(&quot;yyyyMMdd&quot;).format(new Date());
        String uploadName = format + &quot;/&quot; + UUID.randomUUID().toString() + file.getOriginalFilename();
 
        ObjectMetadata metadata  = new ObjectMetadata();
        metadata.setContentType(file.getContentType());
        metadata.setContentLength(file.getSize());
 
        InputStream inputStream = null;
        try {
            inputStream = file.getInputStream();
            com.amazonaws.services.s3.model.PutObjectResult result = s3.putObject(new PutObjectRequest(s3BucketName, uploadName, inputStream, metadata));
            System.out.println(uploadName + &quot;:文件的Md5为：&quot; + result.getContentMd5());
            return BaseResponse.success(host + &quot;/&quot; + uploadName);
        }catch (Exception e) {
            e.printStackTrace();
            throw ZidanApiException.create(BmoonResponseCode.FILE_UPLOAD_FAILED);
        } finally {
            if (inputStream != null){
                try {
                    inputStream.close();
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }
        }
    }
}
</code></pre>
<hr>
<h3 id="三-测试文件的上传与访问">三 测试文件的上传与访问</h3>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1658665387619.png" alt="" loading="lazy"></figure>
<p>浏览器访问：</p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1658665394203.png" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[netty]]></title>
        <id>https://tinaxiawuhao.github.io/post/Hbra5M-xo/</id>
        <link href="https://tinaxiawuhao.github.io/post/Hbra5M-xo/">
        </link>
        <updated>2022-06-26T11:54:54.000Z</updated>
        <content type="html"><![CDATA[<h3 id="1-netty简单介绍">1. Netty简单介绍</h3>
<h4 id="1-原生nio存在的问题">1. 原生NIO存在的问题</h4>
<p>为什么有了 NIO ，还会出现 Netty，因为 NIO 有如下问题：<br>
NIO 的类库和 API 繁杂，使用麻烦：需要熟练掌握 Selector、ServerSocketChannel、 SocketChannel、ByteBuffer 等。<br>
需要具备其他的额外技能：要熟悉 Java 多线程编程，因为 NIO 编程涉及到 Reactor 模式，你必须对多线程和网络编程非常熟悉，才能编写出高质量的 NIO 程序。<br>
开发工作量和难度都非常大：例如客户端面临断连重连、网络闪断、半包读写、失败缓存、网络拥塞和异常流的处理等等。<br>
JDK NIO 的 Bug：例如臭名昭著的 Epoll Bug，它会导致 Selector 空轮询（死循环），最终导致 CPU 100%。直到 JDK 1.7 版本该问题仍旧存在，没有被根本解决</p>
<h4 id="2-netty官网说明">2. Netty官网说明</h4>
<p>官网地址 ：https://netty.io/<br>
Netty是一个异步事件驱动的网络应用程序框架，用于快速开发可维护的高性能的服务器和客户端。<br>
Netty 是由 JBOSS 提供的一个 Java 开源框架。Netty 提供异步的、基于事件驱动的网络应用程序框架，用以快速开发高性能、高可靠性的网络 IO 程序。<br>
Netty 可以帮助你快速、简单的开发出一个网络应用，相当于简化和流程化了 NIO 的 开发过程。<br>
Netty 是目前最流行的 NIO 框架，Netty 在互联网领域、大数据分布式计算领域、游戏行业、通信行业等获得了广泛的应用，知名的 Elasticsearch 、Dubbo 框架内部都采 用了 Netty。</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1656503871885.png" alt="" loading="lazy"></figure>
<h4 id="3-netty的优点">3. Netty的优点</h4>
<p>Netty 对 JDK 自带的 NIO 的 API 进行了封装，解决了上述问题。</p>
<p>设计优雅：适用于各种传输类型的统一 API 阻塞和非阻塞 Socket；基于灵活且可扩展的事件模型，可以清晰地分离关注点；高度可定制的线程模型 —— 单线程，一个或多个 线程池.<br>
使用方便：详细记录的 Javadoc，用户指南和示例；没有其他依赖项 (JDK 5 -&gt; Netty 3.x ; 6 -&gt; Netty 4.x 就可以支持了）。<br>
高性能、吞吐量更高：延迟更低；减少资源消耗；最小化不必要的内存复制。<br>
安全：完整的 SSL/TLS 和 StartTLS 支持。<br>
社区活跃、不断更新：社区活跃，版本迭代周期短，发现的 Bug 可以被及时修复， 同时，更多的新功能会被加入</p>
<h4 id="4-netty版本说明">4. Netty版本说明</h4>
<p>netty版本分为 netty3.x 和 netty4.x、netty5.x<br>
因为Netty5出现重大bug，已经被官网废弃了，目前推荐使用的是Netty4.x的稳定版本<br>
目前在官网可下载的版本 netty3.x netty4.0.x 和 netty4.1.x<br>
这里使用的是 Netty4.1.x 版本<br>
netty 下载地址： https://bintray.com/netty/downloads/netty/</p>
<h3 id="2-各线程模式">2. 各线程模式</h3>
<h4 id="1-传统阻塞-io-服务模型">1. 传统阻塞 I/O 服务模型</h4>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1656503894532.png" alt="" loading="lazy"></figure>
<p><strong>模型特点</strong><br>
采用阻塞IO模式获取输入的数据<br>
每个连接都需要独立的线程完成数据的输入（read），业务处理， 数据返回（send）<br>
<strong>问题分析</strong><br>
当并发数很大，就会创建大量的线程，占用很大系统资源<br>
连接创建后，如果当前线程暂时没有数据可读，该线程会阻塞在read 操作，造成线程资源浪费</p>
<h4 id="2-reactor-模式">2. Reactor 模式</h4>
<p>针对传统阻塞 I/O 服务模型的 2 个缺点，解决方案：</p>
<p><code>基于 I/O 复用模型</code>：多个连接共用一个阻塞对象，应用程序只需要在一个阻塞对象等待，无需阻塞等待所有连接。当某个连接有新的数据可以处理时，操作系统通知应用程序，线程从阻塞状态返回，开始进行业务处理</p>
<p><code>基于线程池复用线程资源</code>：不必再为每个连接创建线程，将连接完成后的业务处理任务分配给线程进行处理，一个线程可以处理多个连接的业务。</p>
<blockquote>
<p>Reactor 对应的叫法:<br>
反应器模式<br>
分发者模式(Dispatcher)<br>
通知者模式(notifier)</p>
</blockquote>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1656503912514.png" alt="" loading="lazy"></figure>
<p><strong>说明:</strong><br>
Reactor 模式，通过一个或多个输入同时传递给服务处理器的模式 (基于事件驱动)<br>
服务器端程序处理传入的多个请求, 并将它们同步分派到相应的处理线程， 因此Reactor（反应器）模式也叫 Dispatcher（分发者） 模式<br>
Reactor 模式使用IO复用监听事件, 收到事件后，分发给某个线程(进程), 这点就是网络服务器高并发处理关键</p>
<p><strong>核心组成：</strong><br>
Reactor：Reactor 在一个单独的线程中运行，负责监听和分发事件，分发给适当的处 理程序来对 IO 事件做出反应。 它就像公司的电话接线员，它接听来自客户的电话并 将线路转移到适当的联系人；<br>
Handlers：处理程序执行 I/O 事件要完成的实际事件，类似于客户想要与之交谈的公司中的实际官员。Reactor 通过调度适当的处理程序来响应 I/O 事件，处理程序执行非阻塞操作</p>
<p><strong>Reactor 模式分类：</strong></p>
<blockquote>
<p>单 Reactor 单线程<br>
单 Reactor 多线程<br>
主从 Reactor 多线程</p>
</blockquote>
<h4 id="3-单reactor-单线程">3. 单Reactor-单线程</h4>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1656503926332.png" alt="" loading="lazy"></figure>
<p><strong>说明：</strong><br>
Select 是前面 I/O 复用模型介绍的标准网络编程 API，可以实现应用程序通过一个阻塞对象监听多路连接请求<br>
Reactor 对象通过 Select 监控客户端请求事件，收到事件后通过 Dispatch 进行分发<br>
如果是建立连接请求事件，则由 Acceptor 通过 Accept 处理连接请求，然后创建一个 Handler 对象处理连接完成后的后续业务处理<br>
如果不是建立连接事件，则 Reactor 会分发调用连接对应的 Handler 来响应<br>
Handler 会完成 Read→业务处理→Send 的完整业务流程 结合实例：服务器端用一个线程通过多路复用搞定所有的 IO 操作（包括连接，读、写 等），编码简单，清晰明了，但是如果客户端连接数量较多，将无法支撑，前面的 NIO 案例就属于这种模型。<br>
<strong>优点：</strong><br>
模型简单，没有多线程、进程通信、竞争的问题，全部都在一个线程中完成<br>
<strong>缺点：</strong><br>
性能问题，只有一个线程，无法完全发挥多核 CPU 的性能。Handler 在处理某 个连接上的业务时，整个进程无法处理其他连接事件，很容易导致性能瓶颈<br>
可靠性问题，线程意外终止，或者进入死循环，会导致整个系统通信模块不 可用，不能接收和处理外部消息，造成节点故障<br>
使用场景：客户端的数量有限，业务处理非常快速，比如 Redis在业务处理的时间复 杂度 O(1) 的情况</p>
<h4 id="4-单-reactor-多线程">4. 单 Reactor 多线程</h4>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1656503940131.png" alt="" loading="lazy"></figure>
<p><strong>说明：</strong><br>
Reactor 对象通过 select 监控客户端请求事件, 收到事件后，通过 dispatch 进行分发<br>
如果建立连接请求, 则由 Acceptor 通过 accept 处理连接请求, 然后创建一个Handler对象处理完成连接后的各种事件<br>
如果不是连接请求，则由 Reactor 分发调用连接对 应的Handler 来处理<br>
Handler 只负责响应事件，不做具体的业务处理, 通过 read 读取数据后，会分发给后面的 Worker 线程池的某个线程处理业务<br>
Worker 线程池会分配独立线程完成真正的业务， 并将结果返回给 Handler<br>
Handler 收到响应后，通过 send 将结果返回给 Client</p>
<p><strong>优点</strong>：可以充分的利用多核cpu 的处理能力<br>
<strong>缺点</strong>：多线程数据共享和访问比较复杂,单 Reactor 处理所有的事件的监听和响应，在单线程运行， 在高并发场景容易出现性能瓶颈</p>
<h4 id="5-主从-reactor-多线程">5. 主从 Reactor 多线程</h4>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1656503952682.png" alt="" loading="lazy"></figure>
<p><strong>说明</strong></p>
<blockquote>
<p>1: Reactor 主线程 MainReactor 对象通过 select 监听连接事件, 收到事件后，通过 Acceptor 处理连接事件(主 Reactor 只处理连接事件)<br>
2：当 Acceptor 处理连接事件后，MainReactor 将连接分配给 SubReactor<br>
3：SubReactor 将连接加入到连接队列进行监听,并创建 Handler 进行各种事件处理<br>
4：当有新事件发生时， SubReactor 就会调用对应的 Handler处理，Handler 通过 read 读取数据，分发给后面的 （Worker 线程池）处理<br>
5：（Worker 线程池）分配独立的 （Worker 线程）进行业务处理，并返 回结果<br>
6：Handler 收到响应的结果后，再通过 send 将结果返回给 Client<br>
ps：一个 MainReactor 可以关联多个 SubReactor</p>
</blockquote>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1656503963761.png" alt="" loading="lazy"></figure>
<p><strong>优点</strong>： 父线程与子线程的数据交互简单职责明确，父线程只需要接收新连接，子线程完成后续的业务处理。<br>
父线程与子线程的数据交互简单，Reactor 主线程只需要把新连接传给子线程，子线程无需返回数据。<br>
<strong>缺点</strong>：编程复杂度较高<br>
结合实例：这种模型在许多项目中广泛使用，包括 Nginx 主从 Reactor 多进程模型， Memcached 主从多线程，Netty 主从多线程模型的支持</p>
<h4 id="6-reactor-模式小结">6. Reactor 模式小结</h4>
<p>3 种模式用生活案例来理解<br>
单 Reactor 单线程，前台接待员和服务员是同一个人，全程为顾客服<br>
单 Reactor 多线程，1 个前台接待员，多个服务员，接待员只负责接待<br>
主从 Reactor 多线程，多个前台接待员，多个服务生<br>
Reactor 模式具有如下的优点：<br>
响应快，不必为单个同步时间所阻塞，虽然 Reactor 本身依然是同步的<br>
可以最大程度的避免复杂的多线程及同步问题，并且避免了多线程/进程 的切换开销<br>
扩展性好，可以方便的通过增加 Reactor 实例个数来充分利用 CPU 资源<br>
复用性好，Reactor 模型本身与具体事件处理逻辑无关，具有很高的复用性</p>
<h3 id="3-netty模型">3. Netty模型</h3>
<h4 id="1-简单版">1. 简单版</h4>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1656503977148.png" alt="" loading="lazy"></figure>
<p><strong>说明 ：</strong></p>
<blockquote>
<p>BossGroup 线程维护Selector , 只关注Accecpt<br>
当接收到Accept事件，获取到对应的 SocketChannel, 封装成 NIOScoketChannel并注册到 Worker 线程(事件循环), 并进行维护<br>
当Worker线程监听到 Selector 中通道发生自己感 兴趣的事件后，就进行处理(就由 Handler 处理)， 注意 Handler 已经加入到通道</p>
</blockquote>
<h4 id="2-进阶版">2. 进阶版</h4>
<figure data-type="image" tabindex="9"><img src="https://tinaxiawuhao.github.io/post-images/1656503987315.png" alt="" loading="lazy"></figure>
<h4 id="3-完整版-非常重要">3. 完整版 非常重要</h4>
<figure data-type="image" tabindex="10"><img src="https://tinaxiawuhao.github.io/post-images/1656503997684.jpg" alt="" loading="lazy"></figure>
<p><strong>说明 ：</strong></p>
<blockquote>
<p>1：Netty 抽象出两组线程池 BossGroup 专门负责接收客户端的连接, WorkerGroup 专门负责网络的读写<br>
2：BossGroup 和 WorkerGroup 类型都是 NioEventLoopGroup<br>
3：NioEventLoopGroup 相当于一个事件循环组, 这个组中含有多个事件循环 ，每一个事件循环是 NioEventLoop<br>
4：NioEventLoop 表示一个不断循环的执行处理任务的线程， 每个 NioEventLoop 都有一个 Selector , 用于监听绑定在其上的 Socket 的网络通讯<br>
5:NioEventLoopGroup(BossGroup、WorkerGroup) 可以有多个线程, 即可以含有多个 NioEventLoop<br>
6:每个Boss 的 NioEventLoop 循环执行的步骤有3步<br>
(1):轮询accept 事件<br>
(2):处理accept 事件 , 与client建立连接 , 生成NioScocketChannel , 并将其注册到 Worker 的 (3):NIOEventLoop 上的 Selector<br>
处理任务队列的任务 ， 即 runAllTasks<br>
7：每个 Worker 的 NIOEventLoop 循环执行的步骤<br>
(1):轮询read, write 事件<br>
(2):处理i/o事件， 即read , write 事件，在对应NioScocketChannel 处理<br>
(3):处理任务队列的任务 ， 即 runAllTasks<br>
每个Worker NIOEventLoop 处理业务时，会使用 Pipeline(管道), Pipeline 中包含了 Channel , 即通过 Pipeline 可以获取到对应通道, 管道中维护了很多的处理器。管道可以使用 Netty 提供的，也可以自定义</p>
</blockquote>
<h4 id="4-理解重制版">4. 理解重制版</h4>
<figure data-type="image" tabindex="11"><img src="https://tinaxiawuhao.github.io/post-images/1656504035283.png" alt="" loading="lazy"></figure>
<p>服务器端首先创建一个ServerSocketChannel，bossGroup只处理客户端连接请求,workGroup处理读写事件，此二者为线程组，其中每一个NIOEventLoop都是线程组其中一个线程</p>
<p>客户端发送连接请求通过ServerSocketChannel被NIOLoopEventGroup线程组中的一个线程NIOLoopEvent的selector选择器监听，并将事件放入taskqueue队列进行轮询，一旦有accept事件就会封装NIOSocketChannel对象，并通过其去注册到workGroup的线程的selector中让其监听</p>
<p>一旦workGroup的线程的taskqueue轮询到读写事件，在对应的NIOSocketChannel进行处理</p>
<h3 id="4-netty实例分析">4. Netty实例分析</h3>
<h4 id="1-bossgroup-和-workgroup-怎么确定自己有多少个-nioeventloop">1. BossGroup 和 WorkGroup 怎么确定自己有多少个 NIOEventLoop</h4>
<p>BossGroup 和 WorkerGroup 含有的子线程数（NioEventLoop）默认为 CPU 核数*2</p>
<p>由源码中的构造方法可知 —— 想要设置线程数只要在参数中输入即可</p>
<h4 id="2-workergroup-是如何分配这些进程的">2. WorkerGroup 是如何分配这些进程的</h4>
<p>设置 BossGroup 进程数为 1 ； WorkerGroup 进程数为 4 ； Client 数位 8</p>
<p>在默认情况下，WorkerGroup 分配的逻辑就是按顺序循环分配的</p>
<h4 id="3-bossgroup-和-workergroup-中的-selector-和-taskqueue">3. BossGroup 和 WorkerGroup 中的 Selector 和 TaskQueue</h4>
<p>打断点进行 Debug</p>
<figure data-type="image" tabindex="12"><img src="https://tinaxiawuhao.github.io/post-images/1656504060284.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="13"><img src="https://tinaxiawuhao.github.io/post-images/1656504081513.png" alt="" loading="lazy"></figure>
<p><strong>每个子线程都具有自己的 Selector、TaskQueue……</strong></p>
<h4 id="4-ctx-上下文-channel-pipeline-之间关系">4. CTX 上下文、Channel、Pipeline 之间关系</h4>
<p>修改 <code>NettyServerHandler</code> ，并添加端点</p>
<figure data-type="image" tabindex="14"><img src="https://tinaxiawuhao.github.io/post-images/1656504102104.png" alt="" loading="lazy"></figure>
<p>先看 CTX 上下文中的信息</p>
<figure data-type="image" tabindex="15"><img src="https://tinaxiawuhao.github.io/post-images/1656504116118.png" alt="" loading="lazy"></figure>
<p>Pipeline</p>
<figure data-type="image" tabindex="16"><img src="https://tinaxiawuhao.github.io/post-images/1656504129630.png" alt="" loading="lazy"></figure>
<p>Channel</p>
<figure data-type="image" tabindex="17"><img src="https://tinaxiawuhao.github.io/post-images/1656504144493.png" alt="" loading="lazy"></figure>
<p>CTX 上下文、Channel、Pipeline 三者关系示意图</p>
<figure data-type="image" tabindex="18"><img src="https://tinaxiawuhao.github.io/post-images/1656504158613.png" alt="" loading="lazy"></figure>
<h4 id="5-设置通道参数">5. 设置通道参数</h4>
<p><strong>childOption() 方法</strong></p>
<p>给每条child channel 连接设置一些TCP底层相关的属性，比如上面，我们设置了两种TCP属性，其中 ChannelOption.SO_KEEPALIVE表示是否开启TCP底层心跳机制，true为开</p>
<p><strong>option() 方法</strong></p>
<p>对于server bootstrap而言，这个方法，是给parent channel 连接设置一些TCP底层相关的属性。</p>
<p>TCP连接的参数详细介绍如下。SO_RCVBUF ，SO_SNDBUF</p>
<p>这两个选项就是来设置TCP连接的两个buffer尺寸的。</p>
<p>每个TCP socket在内核中都有一个发送缓冲区和一个接收缓冲区，TCP的全双工的工作模式以及TCP的滑动窗口便是依赖于这两个独立的buffer以及此buffer的填充状态。</p>
<p><strong>SO_SNDBUF</strong><br>
  Socket参数，TCP数据发送缓冲区大小。该缓冲区即TCP发送滑动窗口，linux操作系统可使用命令：cat /proc/sys/net/ipv4/tcp_smem 查询其大小。</p>
<p><strong>TCP_NODELAY</strong><br>
  TCP参数，立即发送数据，默认值为Ture（Netty默认为True而操作系统默认为False）。该值设置Nagle算法的启用，改算法将小的碎片数据连接成更大的报文来最小化所发送的报文的数量，如果需要发送一些较小的报文，则需要禁用该算法。Netty默认禁用该算法，从而最小化报文传输延时。</p>
<p>这个参数，与是否开启Nagle算法是反着来的，true表示关闭，false表示开启。通俗地说，如果要求高实时性，有数据发送时就马上发送，就关闭，如果需要减少发送次数减少网络交互，就开启。</p>
<p><strong>SO_KEEPALIVE</strong><br>
  底层TCP协议的心跳机制。Socket参数，连接保活，默认值为False。启用该功能时，TCP会主动探测空闲连接的有效性。可以将此功能视为TCP的心跳机制，需要注意的是：默认的心跳间隔是7200s即2小时。Netty默认关闭该功能。</p>
<p><strong>SO_REUSEADDR</strong><br>
  Socket参数，地址复用，默认值False。有四种情况可以使用：<br>
(1).当有一个有相同本地地址和端口的socket1处于TIME_WAIT状态时，而你希望启动的程序的socket2要占用该地址和端口，比如重启服务且保持先前端口。<br>
(2).有多块网卡或用IP Alias技术的机器在同一端口启动多个进程，但每个进程绑定的本地IP地址不能相同。<br>
(3).单个进程绑定相同的端口到多个socket上，但每个socket绑定的ip地址不同。(4).完全相同的地址和端口的重复绑定。但这只用于UDP的多播，不用于TCP。</p>
<p><strong>SO_LINGER</strong><br>
  Socket参数，关闭Socket的延迟时间，默认值为-1，表示禁用该功能。-1表示socket.close()方法立即返回，但OS底层会将发送缓冲区全部发送到对端。0表示socket.close()方法立即返回，OS放弃发送缓冲区的数据直接向对端发送RST包，对端收到复位错误。非0整数值表示调用socket.close()方法的线程被阻塞直到延迟时间到或发送缓冲区中的数据发送完毕，若超时，则对端会收到复位错误。</p>
<p><strong>SO_BACKLOG</strong><br>
  Socket参数，服务端接受连接的队列长度，如果队列已满，客户端连接将被拒绝。默认值，Windows为200，其他为128。</p>
<pre><code class="language-java"> b.option(ChannelOption.SO_BACKLOG, 1024) 
</code></pre>
<p>表示系统用于临时存放已完成三次握手的请求的队列的最大长度，如果连接建立频繁，服务器处理创建新连接较慢，可以适当调大这个参数.</p>
<p><strong>SO_BROADCAST</strong><br>
  Socket参数，设置广播模式。</p>
<h3 id="5-taskqueue-任务队列">5. TaskQueue 任务队列</h3>
<p>任务队列中的 Task 有 3 种典型使用场景</p>
<blockquote>
<p>用户程序自定义的普通任务<br>
用户自定义定时任务<br>
非当前 Reactor 线程调用 Channel 的各种方法</p>
</blockquote>
<h3 id="6-异步模型">6. 异步模型</h3>
<h4 id="1-工作示意图">1. 工作示意图</h4>
<figure data-type="image" tabindex="19"><img src="https://tinaxiawuhao.github.io/post-images/1656504197703.png" alt="" loading="lazy"></figure>
<p><strong>说明</strong></p>
<p>1:在使用 Netty 进行编程时，拦截操作和转换出入站数据只需要您提供 callback 或利用 future 即可。这使得链式操作简单、高效, 并有利于编写可重用的、通用的代码。</p>
<p>2:Netty 框架的目标就是让你的业务逻辑从网络基础应用编码中分离出来</p>
<h4 id="2-future-listener-机制">2. Future-Listener 机制</h4>
<p>当 Future 对象刚刚创建时，处于非完成状态，调用者可以通过返回的 ChannelFuture 来获取操作执行的状态，注册监听函数来执行完成后的操作。<br>
常见有如下操作<br>
• 通过 isDone 方法来判断当前操作是否完成；<br>
• 通过 isSuccess 方法来判断已完成的当前操作是否成功；<br>
• 通过 getCause 方法来获取已完成的当前操作失败的原因；<br>
• 通过 isCancelled 方法来判断已完成的当前操作是否被取消；<br>
• 通过 addListener 方法来注册监听器，当操作已完成(isDone 方法返回完成)，将会通知 指定的监听器；如果 Future 对象已完成，则通知指定的监听器</p>
<p>代码示例</p>
<pre><code class="language-java">给一个 ChannelFuture 注册监听器，来监控我们关系的事件

channelFuture.addListener(new ChannelFutureListener() {
     @Override
     public void operationComplete(ChannelFuture channelFuture) throws Exception {
          if (channelFuture.isSuccess()){
               System.out.println(&quot;监听端口 6668 成功&quot;);
          }else {
               System.out.println(&quot;监听端口 6668 失败&quot;);
          }
      }
});
</code></pre>
<h4 id="3-快速入门实例-http服务">3. 快速入门实例-HTTP服务</h4>
<p>Netty 可以做Http服务开发，并且理解Handler实例 和客户端及其请求的关系</p>
<p><strong>编写代码 —— 服务端代码</strong></p>
<pre><code class="language-java"># 编写服务端： HttpServer
public static void main(String[] args) throws Exception {
    //创建BossGroup ,workGroup
    EventLoopGroup bossGroup = new NioEventLoopGroup();
    EventLoopGroup workGroup = new NioEventLoopGroup();
    try {
        ServerBootstrap serverBootstrap = new ServerBootstrap();
        serverBootstrap.group(bossGroup,workGroup)
            .channel(NioServerSocketChannel.class)
            .childHandler(new TestServerInitializer());
        ChannelFuture channelFuture = serverBootstrap.bind(8080).sync();
        channelFuture.channel().closeFuture().sync();
    } finally {
        bossGroup.shutdownGracefully();
        workGroup.shutdownGracefully();
    }
}
</code></pre>
<p><strong>编写 服务初始化器 ：HttpServerInitialize</strong></p>
<pre><code class="language-java">public class TestServerInitializer extends ChannelInitializer&lt;SocketChannel&gt; {
    @Override
    protected void initChannel(SocketChannel socketChannel) throws Exception {
        //向管道加入处理器
        ChannelPipeline pipeline = socketChannel.pipeline();
        //加入netty提供的httpServerCodec,netty提供的处理Http的编-解码器
        pipeline.addLast(&quot;MyHttpServerCodec&quot;,new HttpServerCodec());
        pipeline.addLast(&quot;MyTestHttpServerHandler&quot;,new TestHttpServerHandler());
    }
}
</code></pre>
<p><strong>编写 服务处理器 ：HttpServerHandler</strong></p>
<pre><code class="language-java">/**
*
* 1. SimpleChannelInboundHandler 是之前使用的 ChannelInboundHandlerAdapter 的子类
* 2. HttpObject 这个类型表示， 客户端、服务端 相互通信的数据需要被封装成什么类型
*
*/
public class TestHttpServerHandler extends SimpleChannelInboundHandler&lt;HttpObject&gt; {
	/**
    * 读取客户端数据
    * @param ctx
    * @param msg
    * @throws Exception
    */
    @Override
    protected void channelRead0(ChannelHandlerContext ctx, HttpObject msg) throws Exception {
        //判断msg 是不是HttpRequest 请求
        if(msg instanceof HttpRequest){
        System.out.println(&quot;msg 类型 = &quot;+msg.getClass());
        System.out.println(&quot;客户端地址&quot;+ctx.channel().remoteAddress());
        // 获取请求的 URI
        HttpRequest httpRequest = (HttpRequest) msg;
        URI uri = new URI(httpRequest.uri());
        // 判断请求路径为 /favicon.ico，就不做处理
        if (&quot;/favicon.ico&quot;.equals(uri.getPath())){
        System.out.println(&quot;请求了 图标 资源，不做响应&quot;);
        	return;
        }
        //回复信息给浏览器【HTTP协议】
        ByteBuf content = Unpooled.copiedBuffer(&quot;Hello I am server&quot;, CharsetUtil.UTF_8);
        //构造一个http回应，即httpResponse,HttpResponseStatus:状态码
        FullHttpResponse response = new DefaultFullHttpResponse(HttpVersion.HTTP_1_1, HttpResponseStatus.OK,content);
        response.headers().set(HttpHeaderNames.CONTENT_TYPE,&quot;text/plain&quot;);
        response.headers().set(HttpHeaderNames.CONTENT_LENGTH,content.readableBytes());
        //将构建好的response返回
        ctx.writeAndFlush(response);
    }
}
</code></pre>
<p><strong>编写代码 —— 对特定资源的过滤</strong><br>
上面的服务端启动后，在页面上不止接收到了文本，还接收到了一个网页的图标</p>
<figure data-type="image" tabindex="20"><img src="https://tinaxiawuhao.github.io/post-images/1656504226962.png" alt="" loading="lazy"></figure>
<p>现在把它过滤掉</p>
<pre><code class="language-java">// 修改 HttpServerHandler
 // 获取请求的 URI
HttpRequest httpRequest = (HttpRequest) msg;
URI uri = new URI(httpRequest.uri());
// 判断请求路径为 /favicon.ico，就不做处理
if (&quot;/favicon.ico&quot;.equals(uri.getPath())){
    System.out.println(&quot;请求了 图标 资源，不做响应&quot;);
    return;
}
</code></pre>
<h3 id="7-netty核心组件">7. netty核心组件</h3>
<h4 id="1-bootstrap-和-serverbootstrap">1. Bootstrap 和 ServerBootstrap</h4>
<p>Bootstrap 意思是引导，一个 Netty 应用通常由一个 Bootstrap 开始，主要作用是配置整个 Netty 程序，串联各个组件，Netty 中 Bootstrap类是客户端程序的启动引导类， ServerBootstrap是服务端启动引导类<br>
常见的方法有</p>
<blockquote>
<p>• public ServerBootstrap group(EventLoopGroup parentGroup, EventLoopGroup childGroup)，该方法用于服务器端，用来设置两个 EventLoop<br>
• public B channel(Class&lt;? extends C&gt; channelClass)，该方法用来设置一个服务器端的通道实现<br>
• public ChannelFuture bind(int inetPort) ，该方法用于服务器端，用来设置占用的端口号<br>
• public B option(ChannelOption option, T value)，用来给 ServerChannel 添加配置<br>
• public B group(EventLoopGroup group) ，该方法用于客户端，用来设置一个 EventLoop<br>
• public ChannelFuture connect(String inetHost, int inetPort) ，该方法用于客户端，用来连接服务器 端<br>
• public ServerBootstrap childOption(ChannelOption childOption, T value)，用来给接收到的通道添加配置<br>
• public ServerBootstrap childHandler(ChannelHandler childHandler)，该方法用来设置业务处理类 （自定义的 handler）</p>
</blockquote>
<pre><code>.childHandler(new TestServerInitializer())//对应workGroup
.handler(null)//对应bossGroup
</code></pre>
<h4 id="2-future-和-channelfuture">2. Future 和 ChannelFuture</h4>
<p>Netty 中所有的 IO 操作都是异步的，不能立刻得知消息是否被正确处理。但是可以过一会等它执行完成或者直接注册一个监听，具体的实现就是通过 Future 和 ChannelFutures，他们可以注册一个监听，当操作执行成功或失败时监听会自动触发注册的监听事件<br>
常见的方法有</p>
<blockquote>
<p>• Channel channel()，返回当前正在进行 IO 操作的通道<br>
• ChannelFuture sync()，等待异步操作执行完毕</p>
</blockquote>
<h4 id="3-channel">3. Channel</h4>
<p>Netty 网络通信的组件，能够用于执行网络 I/O 操作。<br>
通过Channel 可获得当前网络连接的通道的状态<br>
通过Channel 可获得网络连接的配置参数 （例如接收缓冲区大小）<br>
Channel 提供异步的网络 I/O 操作(如建立连接，读写，绑定端口)，异步调用意味着任何 I/O 调用都将立即返回，并且不保证在调用结束时所请求的 I/O 操作已完成<br>
调用立即返回一个 ChannelFuture 实例，通过注册监听器到 ChannelFuture 上，可以 I/O 操作成功、失败或取消时回调通知调用方<br>
支持关联 I/O 操作与对应的处理程序<br>
不同协议、不同的阻塞类型的连接都有不同的 Channel 类型与之对应</p>
<p>常用的 Channel 类型</p>
<blockquote>
<p>• NioSocketChannel，异步的客户端 TCP Socket 连接。<br>
• NioServerSocketChannel，异步的服务器端 TCP Socket 连接。<br>
• NioDatagramChannel，异步的 UDP 连接。<br>
• NioSctpChannel，异步的客户端 Sctp 连接。<br>
• NioSctpServerChannel，异步的 Sctp 服务器端连接，这些通道涵盖了 UDP 和 TCP 网络 IO 以及文件 IO。</p>
</blockquote>
<h4 id="4-selector">4. Selector</h4>
<p>Netty 基于 Selector 对象实现 I/O 多路复用，通过 Selector 一个线程可以监听多个连接的 Channel 事件。<br>
当向一个 Selector 中注册 Channel 后，Selector 内部的机制就可以自动不断地查询 (Select) 这些注册的 Channel 是否有已就绪的 I/O 事件（例如可读，可写，网络连接 完成等），这样程序就可以很简单地使用一个线程高效地管理多个 Channel</p>
<h4 id="5-channelhandler">5. ChannelHandler</h4>
<p>我们经常需要自定义一 个 Handler 类去继承 ChannelInboundHandlerA dapter，然后通过重写相应方法实现业务逻辑</p>
<p>常用的方法</p>
<pre><code class="language-java">public class ChannelInboundHandlerAdapter extends ChannelHandlerAdapter implements ChannelInboundHandler { 
	// 通道注册事件
	public void channelRegistered(ChannelHandlerContext ctx) throws Exception {
        ctx.fireChannelRegistered();
    }
	// 通道注销事件
    public void channelUnregistered(ChannelHandlerContext ctx) throws Exception {
        ctx.fireChannelUnregistered();
    }
	// 通道就绪事件 
	public void channelActive(ChannelHandlerContext ctx) throws Exception { 
		ctx.fireChannelActive(); 
	}
	// 通道读取数据事件 
	public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { 
		ctx.fireChannelRead(msg); 
	}
	// 通道读取数据完毕事件
    public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {
        ctx.fireChannelReadComplete();
    }
    // 通道发生异常事件
	public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
        ctx.fireExceptionCaught(cause);
    }
}
</code></pre>
<h4 id="6-pipeline-和-channelpipeline">6. Pipeline 和 ChannelPipeline</h4>
<p><code>ChannelPipeline</code> 是一个 Handler 的集合，它负责处理和拦截 inbound（入栈） 或者 outbound（出栈） 的事件和操作，相当于一个贯穿 Netty 的链。(也可以这样理解： ChannelPipeline 是 保存 ChannelHandler 的 List，用于处理或拦截 Channel 的入站 和出站 事件 / 操作)</p>
<p>ChannelPipeline 实现了一种高级形式的拦截过滤器模式，使用户可以完全控制事件的处理方式，以及 Channel 中各个的 ChannelHandler 如何相互交互</p>
<p>在 Netty 中每个 Channel 都有且仅有一个 ChannelPipeline 与之对应，它们的组成关系如下</p>
<figure data-type="image" tabindex="21"><img src="https://tinaxiawuhao.github.io/post-images/1656504246343.png" alt="" loading="lazy"></figure>
<p><strong>说明 ：</strong></p>
<blockquote>
<p>• 一个 Channel 包含了一个 ChannelPipeline，而 ChannelPipeline 中又维护了一个由 ChannelHandlerContext 组成的双向链表，并且每个 ChannelHandlerContext 中又关联着一个 ChannelHandler<br>
• 入站事件和出站事件在一个双向链表中，入站事件会从链表 head 往后传递到最后一个入站的 handler， 出站事件会从链表 tail 往前传递到最前一个出站的 handler，两种类型的 handler 互不干扰</p>
</blockquote>
<p><strong>常用方法</strong></p>
<pre><code>//把一个业务处理类（handler） 添加到链中的第一个位置
ChannelPipeline addFirst(ChannelHandler… handlers)
//把一个业务处理类（handler） 添加到链中的最后一个位置
ChannelPipeline addLast(ChannelHandler… handlers)
</code></pre>
<h3 id="8-netty-群聊">8. Netty 群聊</h3>
<p><strong>要求：</strong></p>
<blockquote>
<p>编写一个 Netty 群聊系统，实现服务器端和客户端之间的数据简单通讯（非阻塞）<br>
实现多人群聊<br>
服务器端：可以监测用户上线，离线，并实现消息转发功能<br>
客户端：通过channel 可以无阻塞发送消息给其它所有用户，同时可以接受其它用 户发送的消息(有服务器转发得到)</p>
</blockquote>
<p><strong>1. server端</strong></p>
<pre><code class="language-java">public class ChatServer {
    private int port;

    public ChatServer(int port) {
        this.port = port;
    }

    public void run() throws Exception{
        //创建bossGroup,workGroup
        EventLoopGroup bossGroup = new NioEventLoopGroup();
        EventLoopGroup workGroup = new NioEventLoopGroup();
        try {
            //创建辅助工具
            ServerBootstrap serverBootstrap = new ServerBootstrap();
            //循环事件组
            serverBootstrap.group(bossGroup,workGroup)//线程组
                    .channel(NioServerSocketChannel.class)//通道类型
                    .option(ChannelOption.SO_BACKLOG,128)
                    .childOption(ChannelOption.SO_KEEPALIVE,true)
                    .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() {
                        @Override
                        protected void initChannel(SocketChannel socketChannel) throws Exception {
                            ChannelPipeline pipeline = socketChannel.pipeline();
                            //加入解码器
                            pipeline.addLast(&quot;decoder&quot;,new StringDecoder());
                            //加入编码器
                            pipeline.addLast(&quot;encoder&quot;,new StringEncoder());
                            pipeline.addLast(new ChatServerHandler());

                        }
                    });
            System.out.println(&quot;server is ok&quot;);
            ChannelFuture channelFuture = serverBootstrap.bind(port).sync();
            channelFuture.channel().closeFuture().sync();
        } finally {
            bossGroup.shutdownGracefully();
            workGroup.shutdownGracefully();
        }
    }
    public static void main(String[] args) throws Exception {
       new ChatServer(8080).run();
    }
}
</code></pre>
<p><strong>2. serverHandler</strong></p>
<pre><code class="language-java">public class ChatServerHandler extends SimpleChannelInboundHandler&lt;String&gt; {
    /**
     * 定义一个 Channel 线程组，管理所有的 Channel, 参数 执行器
     *  GlobalEventExecutor =&gt; 全局事件执行器
     *  INSTANCE =&gt; 表示是单例的
     */
    private  static ChannelGroup channelGroup = new DefaultChannelGroup(GlobalEventExecutor.INSTANCE);
    SimpleDateFormat simpleDateFormat = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;);
    /**
     * 当连接建立之后，第一个被执行
     * 一连接成功，就把当前的 Channel 加入到 ChannelGroup，并将上线消息推送给其他客户
     */
    @Override
    public void handlerAdded(ChannelHandlerContext ctx) throws Exception {
        Channel channel = ctx.channel();
        // 将该客户上线的信息，推送给其他在线的 客户端
        // 该方法，会将 ChannelGroup 中所有的 Channel 遍历，并发送消息
        Date date = new Date(System.currentTimeMillis());
        channelGroup.writeAndFlush(&quot;[client]&quot; +channel.remoteAddress()+&quot;[&quot;+simpleDateFormat.format(date)+&quot;]&quot;+&quot;加入聊天&quot;);
        channelGroup.add(channel);

    }

    /**
     * 当断开连接激活，将 XXX 退出群聊消息推送给当前在线的客户
     * 当某个 Channel 执行到这个方法，会自动从 ChannelGroup 中移除
     */
    @Override
    public void handlerRemoved(ChannelHandlerContext ctx) throws Exception {
        Channel channel = ctx.channel();
        Date date = new Date(System.currentTimeMillis());
        channelGroup.writeAndFlush(&quot;[client]&quot;+channel.remoteAddress()+&quot;[&quot;+simpleDateFormat.format(date)+&quot;]&quot;+&quot;离开聊天&quot;);
        //channelGroup.remove(channel); 不需要，handlerRemoved（）直接删除了channel
    }

    /**
     * 提示客户端离线状态
     * @param ctx
     * @throws Exception
     */
    @Override
    public void channelInactive(ChannelHandlerContext ctx) throws Exception {
        Date date = new Date(System.currentTimeMillis());
        System.out.println(ctx.channel().remoteAddress()+&quot;[&quot;+simpleDateFormat.format(date)+&quot;]&quot;+&quot;下线了&quot;);
    }

    /**
     * 提示客户端上线状态
     * @param ctx
     * @throws Exception
     */
    @Override
    public void channelActive(ChannelHandlerContext ctx) throws Exception {
        Date date = new Date(System.currentTimeMillis());
        System.out.println(ctx.channel().remoteAddress()+&quot;[&quot;+simpleDateFormat.format(date)+&quot;]&quot;+&quot;上线了&quot;);;
    }

    /**
     * 读取消息，转发数据
     * @param ctx
     * @param msg
     * @throws Exception
     */
    @Override
    protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception {
        Channel channel = ctx.channel();
        Date date = new Date(System.currentTimeMillis());
        //遍历，根据不同对象发送不同数据
        channelGroup.forEach(ch -&gt;{
            if(channel != ch){//不是自己的channel
                ch.writeAndFlush(&quot;[客户]&quot;+channel.remoteAddress()+&quot;[&quot;+simpleDateFormat.format(date)+&quot;]&quot;+&quot;发送&quot;+msg+&quot;/n&quot;);
            }
            else{
                ch.writeAndFlush(&quot;[自己]发送了消息&quot;+&quot;[&quot;+simpleDateFormat.format(date)+&quot;]&quot;+msg+&quot;/n&quot;);
            }
        }

        );
    }

    /**
     * 异常处理
     * @param ctx
     * @param cause
     * @throws Exception
     */
    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
        ctx.close();
    }
}
</code></pre>
<p><strong>3. client端</strong></p>
<pre><code class="language-java">public class ChatClient {
    private final String HOST;
    private final int PORT;
    public ChatClient(String host, int port) {
        HOST = host;
        PORT = port;
    }

    public void run() throws InterruptedException {
        EventLoopGroup eventLoopGroup = new NioEventLoopGroup();
        try {
            Bootstrap bootstrap = new Bootstrap();
            bootstrap.group(eventLoopGroup)
                    .channel(NioSocketChannel.class)
                    .handler(new ChannelInitializer&lt;SocketChannel&gt;() {
                        @Override
                        protected void initChannel(SocketChannel socketChannel) throws Exception {
                            ChannelPipeline pipeline = socketChannel.pipeline();
                            //加入解码器
                            pipeline.addLast(&quot;decoder&quot;,new StringDecoder());
                            //加入编码器
                            pipeline.addLast(&quot;encoder&quot;,new StringEncoder());
                            pipeline.addLast(new ChatClientHandler());
                        }
                    });

            ChannelFuture channelFuture = bootstrap.connect(HOST, PORT).sync();
            System.out.println(&quot;client prepare is ok&quot;);
            Channel channel = channelFuture.channel();
            //客户端需要输入信息，定义扫描器
            Scanner scanner = new Scanner(System.in);
            while(scanner.hasNextLine()){
                String s = scanner.nextLine();
                channel.writeAndFlush(s);

            }
            channel.closeFuture().sync();
        } finally {
            eventLoopGroup.shutdownGracefully();
        }

    }
    public static void main(String[] args) throws InterruptedException {
        new ChatClient(&quot;localhost&quot;,8080).run();
    }
}
</code></pre>
<p><strong>4. clientHandler</strong></p>
<pre><code>public class ChatClientHandler extends SimpleChannelInboundHandler&lt;String&gt; {
    @Override
    protected void channelRead0(ChannelHandlerContext channelHandlerContext, String s) throws Exception {
        // 直接输出从服务端获得的信息
        System.out.println(s.trim());
    }
}
</code></pre>
<h3 id="9-心跳机制">9. 心跳机制</h3>
<p><strong>1. server端：</strong></p>
<pre><code class="language-java">public class MyServer {
    public static void main(String[] args) throws Exception{
        //创建bossGroup,workGroup
        EventLoopGroup bossGroup = new NioEventLoopGroup();
        EventLoopGroup workGroup = new NioEventLoopGroup();

        try {
            //创建辅助工具
            ServerBootstrap serverBootstrap = new ServerBootstrap();
            //循环事件组
            serverBootstrap.group(bossGroup,workGroup)//线程组
                .channel(NioServerSocketChannel.class)//通道类型
                .handler(new LoggingHandler(LogLevel.INFO))
                .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() {
                    @Override
                    protected void initChannel(SocketChannel socketChannel) throws Exception {
                        ChannelPipeline pipeline = socketChannel.pipeline();
                        /*
                 说明：
                 1. IdleStateHandler 是 Netty 提供的 空闲状态处理器
                 2. 四个参数：
                 readerIdleTime : 表示多久没有 读 事件后，就会发送一个心跳检测包，检测是否还是连接状态
                 writerIdleTime : 表示多久没有 写 事件后，就会发送一个心跳检测包，检测是否还是连接状态
                 allIdleTime : 表示多久时间既没读也没写 后，就会发送一个心跳检测包，检测是否还是连接状态
                 TimeUnit : 时间单位
                 1. 当 Channel 一段时间内没有执行 读 / 写 / 读写 事件后，就会触发一个 IdleStateEvent 空闲状态事件
                 2. 当 IdleStateEvent 触发后，就会传递给 Pipeline 中的下一个 Handler 去处理，通过回调下一个 Handler 的 userEventTriggered 方法，在该方法中处理 IdleStateEvent
                             */
                        pipeline.addLast(new IdleStateHandler(3,5,7, TimeUnit.SECONDS));
                        pipeline.addLast(new MyServerHandler());
                    }
                });
            System.out.println(&quot;server is ok&quot;);
            ChannelFuture channelFuture = serverBootstrap.bind(8080).sync();
            channelFuture.channel().closeFuture().sync();
        } finally {
            bossGroup.shutdownGracefully();
            workGroup.shutdownGracefully();
        }
    }

}
</code></pre>
<p><strong>2. handler</strong></p>
<pre><code class="language-java">public class MyServerHandler extends ChannelInboundHandlerAdapter {
    /**
     * @param ctx 上下文
      @param evt 事件
        * @throws Exception
     */
    @Override
    public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception {
        if(evt instanceof IdleStateEvent){
            //将 evt 向下转型 IdleStateEvent
            IdleStateEvent event =  (IdleStateEvent)evt;
            String eventType = null;
            //IdleStateEvent 枚举
            switch (event.state()){
                case READER_IDLE:
                    eventType = &quot;读空闲&quot;;
                    break;
                case WRITER_IDLE:
                    eventType = &quot;写空闲&quot;;
                    break;
                case ALL_IDLE:
                    eventType = &quot;读写空闲&quot;;
            }
            System.out.println(ctx.channel().remoteAddress()+&quot;---超时事件---&quot;+eventType);
        }
    }
}
</code></pre>
<p><strong>说明：</strong></p>
<blockquote>
<p>1: IdleStateHandler 是 Netty 提供的 空闲状态处理器</p>
<p>2: 四个参数：<br>
readerIdleTime : 表示多久没有 读 事件后，就会发送一个心跳检测包，检测是否还是连接状态<br>
writerIdleTime : 表示多久没有 写 事件后，就会发送一个心跳检测包，检测是否还是连接状态<br>
allIdleTime : 表示多久时间既没读也没写 后，就会发送一个心跳检测包，检测是否还是连接状态<br>
TimeUnit : 时间单位<br>
3: 当 Channel 一段时间内没有执行 读 / 写 / 读写 事件后，就会触发一个 IdleStateEvent 空闲状态事件</p>
<p>4: 当 IdleStateEvent 触发后，就会传递给 Pipeline 中的下一个 Handler 去处理，通过回调下一个 Handler 的 userEventTriggered 方法，在该方法中处理 IdleStateEvent</p>
</blockquote>
<h3 id="10-长连接">10. 长连接</h3>
<p><strong>要求：</strong><br>
实现基于webSocket的长连接 的全双工的交互<br>
改变Http协议多次请求的约束，实 现长连接了， 服务器可以发送消息 给浏览器<br>
客户端浏览器和服务器端会相互感 知，比如服务器关闭了，浏览器会 感知，同样浏览器关闭了，服务器 会感知</p>
<p>代码实现</p>
<p><strong>服务端 ：WebServer</strong></p>
<pre><code class="language-java">public class MyServer {
    public static void main(String[] args) throws InterruptedException {
        //创建bossGroup,workGroup
        EventLoopGroup bossGroup = new NioEventLoopGroup();
        EventLoopGroup workGroup = new NioEventLoopGroup();

        try {
            //创建辅助工具
            ServerBootstrap serverBootstrap = new ServerBootstrap();
            //循环事件组
            serverBootstrap.group(bossGroup,workGroup)//线程组
                .channel(NioServerSocketChannel.class)//通道类型
                .handler(new LoggingHandler(LogLevel.INFO))
                .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() {
                    @Override
                    protected void initChannel(SocketChannel socketChannel) throws Exception {
                        ChannelPipeline pipeline = socketChannel.pipeline();
                        //基于http协议使用http的编码和解码器
                        pipeline.addLast(new HttpServerCodec());
                        // 添加块处理器
                        pipeline.addLast(new ChunkedWriteHandler());
                        /*
                               说明：
                               1. 因为 HTTP 数据传输时是分段的，HttpObjectAggregator 可以将多个端聚合
                               2. 这就是为什么浏览器发送大量数据时，就会发出多次 HTTP 请求
                            */
                        pipeline.addLast(new HttpObjectAggregator(8192));
                        /*
                               说明：
                               1. 对于 WebSocket 是以 帧 的形式传递的
                               2. 后面的参数表示 ：请求的 URL
                               3. WebSocketServerProtocolHandler 将 HTTP 协议升级为 WebSocket 协议，即保持长连接
                               4. 切换协议通过一个状态码101
                            */
                        pipeline.addLast(new WebSocketServerProtocolHandler(&quot;/hello&quot;));
                        // 自定义的 Handler
                        pipeline.addLast(new MyTextWebSocketFrameHandler());


                    }
                });
            System.out.println(&quot;server is ok&quot;);
            ChannelFuture channelFuture = serverBootstrap.bind(8080).sync();
            channelFuture.channel().closeFuture().sync();
        } finally {
            bossGroup.shutdownGracefully();
            workGroup.shutdownGracefully();
        }
    }


}
</code></pre>
<p><strong>服务端的处理器 ：MyTextWebSocketFrameHandler</strong></p>
<pre><code class="language-java">/**
 * TextWebSocketFrame 类型，表示一个文本帧（flame）
 */
public class MyTextWebSocketFrameHandler extends SimpleChannelInboundHandler&lt;TextWebSocketFrame&gt; {
    @Override
    protected void channelRead0(ChannelHandlerContext ctx, TextWebSocketFrame msg) throws Exception {
        System.out.println(&quot;服务器收到消息&quot;+msg.text());

        //回复消息
        ctx.channel().writeAndFlush(new TextWebSocketFrame(&quot;服务器时间&quot;+ LocalDateTime.now()+msg.text()));
    }

    /**
         * 客户端连接后，触发方法
         * @param ctx
         * @throws Exception
         */
    @Override
    public void handlerAdded(ChannelHandlerContext ctx) throws Exception {
        //id表示唯一的值，Longtext是唯一的shortText 不是唯一
        System.out.println(&quot;handlerAdded 被调用&quot;+ctx.channel().id().asLongText());
        System.out.println(&quot;handlerAdded 被调用&quot;+ctx.channel().id().asShortText());
    }

    @Override
    public void handlerRemoved(ChannelHandlerContext ctx) throws Exception {
        System.out.println(&quot;handlerRemove被调用&quot;+ctx.channel().id().asLongText());
    }

    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
        System.out.println(&quot;异常发生&quot;+cause.getMessage());
        //关闭连接
        ctx.close();
    }

}
</code></pre>
<p>hello.html(浏览器)</p>
<pre><code class="language-html">&lt;!DOCTYPE html&gt;
&lt;html lang=&quot;en&quot;&gt;
&lt;head&gt;
    &lt;meta charset=&quot;UTF-8&quot;&gt;
    &lt;title&gt;Title&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;form onsubmit=&quot;return false&quot;&gt;
        &lt;textarea id=&quot;message&quot; name=&quot;message&quot; style=&quot;height: 300px; width: 300px&quot;&gt;&lt;/textarea&gt;
        &lt;input type=&quot;button&quot; value=&quot;发送消息&quot; onclick=&quot;send(this.form.message.value)&quot;&gt;
        &lt;textarea id=&quot;responseText&quot; style=&quot;height: 300px; width: 300px&quot;&gt;&lt;/textarea&gt;
        &lt;input type=&quot;button&quot; value=&quot;清空内容&quot; onclick=&quot;document.getElementById('responseText').value=''&quot;&gt;
    &lt;/form&gt;
    &lt;script&gt;
        var socket;
        // 判断当前浏览器是否支持 WebSocket
        if (window.WebSocket){
            socket = new WebSocket(&quot;ws://localhost:8080/hello&quot;);
            // 相当于 channelRead0 方法，ev 收到服务器端回送的消息
            socket.onmessage = function (ev){
                var rt = document.getElementById(&quot;responseText&quot;);
                rt.value = rt.value + &quot;\n&quot; + ev.data;
            }
            // 相当于连接开启，感知到连接开启
            socket.onopen = function (){
                var rt = document.getElementById(&quot;responseText&quot;);
                rt.value = rt.value + &quot;\n&quot; + &quot;连接开启……&quot;;
            }
            // 感知连接关闭
            socket.onclose = function (){
                var rt = document.getElementById(&quot;responseText&quot;);
                rt.value = rt.value + &quot;\n&quot; + &quot;连接关闭……&quot;;
            }
        }else {
            alert(&quot;不支持 WebSocket&quot;);
        }

        // 发送消息到服务器
        function send(message){
            // 判断 WebSocket 是否创建好了
            if (!window.socket){
                return ;
            }
            // 判断 WebSocket 是否开启
            if (socket.readyState == WebSocket.OPEN){
                // 通过 Socket 发送消息
                socket.send(message);
            }else {
                alert(&quot;连接未开启&quot;);
            }
        }
    &lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[NIO]]></title>
        <id>https://tinaxiawuhao.github.io/post/X2beO2j1l/</id>
        <link href="https://tinaxiawuhao.github.io/post/X2beO2j1l/">
        </link>
        <updated>2022-06-25T11:53:37.000Z</updated>
        <content type="html"><![CDATA[<h3 id="1-简介">1. 简介</h3>
<p>Netty 是由 JBOSS 提供的一个 Java 开源框架，现为 Github上的独立项目。<br>
Netty 是一个异步的、基于事件驱动（客户端的行为、读写事件）的网络应用框架，用以快速开发高性能、高可靠性的网络 IO 程序。<br>
Netty主要针对在TCP协议下，面向Clients端的高并发应用，或者Peer-to-Peer场景下的大量数据持续传输的应用。<br>
Netty本质是一个NIO框架，适用于服务器通讯相关的多种应用场景<br>
要透彻理解Netty ， 需要先学习 NIO ， 这样我们才能阅读 Netty 的源码。</p>
<h3 id="2-io-模型基本说明">2. I/O 模型基本说明</h3>
<p>I/O 模型简单的理解：就是用什么样的通道进行数据的发送和接收，很大程度上决定了程 序通信的性能</p>
<h4 id="21-java共支持3种网络编程模型io模式">2.1. Java共支持3种网络编程模型/IO模式：</h4>
<blockquote>
<p>BIO、NIO、AIO</p>
</blockquote>
<p><code>Java BIO</code> ： 同步并阻塞(传统阻塞型)，服务器实现模式为一个连接一个线程，即客户端 有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成 不必要的线程开销</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1656504376989.png" alt="" loading="lazy"></figure>
<p><code>Java NIO</code> ： 同步非阻塞，服务器实现模式为一个线程处理多个请求(连接)，即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有I/O请求就进行处理</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1656504386068.png" alt="" loading="lazy"></figure>
<p><code>Java AIO(NIO.2)</code> ： 异步非阻塞，AIO 引入异步通道的概念，采用了 Proactor 模式，简化了程序编写，有效的请求才启动线程，它的特点是先由操作系统完成后才通知服务端程</p>
<h4 id="22-bio-nio-aio适用场景分析">2.2. BIO、NIO、AIO适用场景分析</h4>
<p><code>BIO方式</code><br>
适用于连接数目比较小且固定的架构，这种方式对服务器资源要求比较高， 并发局限于应用中，JDK1.4以前的唯一选择，但程序简单易理解。</p>
<p><code>NIO方式</code><br>
适用于连接数目多且连接比较短（轻操作）的架构，比如聊天服务器，弹幕 系统，服务器间通讯等。编程比较复杂，JDK1.4开始支持。</p>
<p><code>AIO方式</code><br>
使用于连接数目多且连接比较长（重操作）的架构，比如相册服务器，充分 调用OS参与并发操作，编程比较复杂，JDK7开始支持。</p>
<h3 id="3-nio具体介绍">3. NIO具体介绍</h3>
<p>Java NIO 全称 java non-blocking IO，是指 JDK 提供的新 API。从 JDK1.4 开始，Java 提供了一系列改进的输入/输出 的新特性，被统称为 NIO(即 New IO)，是同步非阻塞的<br>
NIO 相关类都被放在 java.nio 包及子包下，并且对原 java.io 包中的很多类进行改写。<br>
NIO 有三大核心部分：Channel(通道)，Buffer(缓冲区), Selector(选择器)<br>
NIO是 面向缓冲区 ，或者面向块编程的。数据读取到一个 它稍后处理的缓冲区，需要时可在缓冲区中前后移动，这就 增加了处理过程中的灵活性，使用它可以提供非阻塞式的高 伸缩性网络<br>
Java NIO的非阻塞模式，使一个线程从某通道发送请求或者读取数据，但是它仅能得到目前可用的数据，如果目前没有数据可用时，就什么都不会获取，而不是保持线程阻塞，所以直至数据变的可以读取之前，该线程可以继续做其他的事情。 非阻塞写也是如此，一个线程请求写入一些数据到某通道，但不需要等待它完全写入，这 个线程同时可以去做别的事情。<br>
通俗理解：NIO是可以做到用一个线程来处理多个操作的。假设有10000个请求过来, 根据实际情况，可以分配50或者100个线程来处理。不像之前的阻塞IO那样，非得分配10000个。<br>
HTTP2.0使用了多路复用的技术，做到同一个连接并发处理多个请求，而且并发请求 的数量比HTTP1.1大了好几个数量级</p>
<h4 id="31-nio-三大核心">3.1. NIO 三大核心</h4>
<p>Selector 、 Channel 和 Buffer 的简单关系图</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1656504401555.png" alt="" loading="lazy"></figure>
<blockquote>
<p>关系图的说明:<br>
线程是非阻塞，buffer起很大的作用<br>
每个 Channel 都会对应一个 Buffer<br>
Selector 对应一个线程， 一个 Selector 对应多个 Channel(连接)<br>
该图反应了有三个 Channel 注册到该 selector<br>
程序切换到哪个 Channel 是由事件决定的, Event 就是一个重要的概念<br>
Selector 会根据不同的事件，在各个 Channel（通道）上切换<br>
Buffer 就是一个内存块 ， 底层是有一个数组<br>
数据的读取写入是通过 Buffer, 这个和BIO , BIO 中要么是输入流，或者是 输出流, 不能双向，但是NIO的 Buffer 是可以读也可以写, 需要 flip 方法切换</p>
</blockquote>
<h4 id="32-常用buffer子类一览">3.2. 常用Buffer子类一览</h4>
<blockquote>
<p>ByteBuffer，存储字节数据到缓冲区 =<mark>最常用</mark>=<br>
ShortBuffer，存储字符串数据到缓冲区<br>
CharBuffer，存储字符数据到缓冲区<br>
IntBuffer，存储整数数据到缓冲区<br>
LongBuffer，存储长整型数据到缓冲区<br>
DoubleBuffer，存储小数到缓冲区<br>
FloatBuffer，存储小数到缓冲区</p>
</blockquote>
<h4 id="33-buffer常用方法">3.3. buffer常用方法</h4>
<pre><code class="language-java">public abstract class Buffer { 
	//JDK1.4时，引入的api 
	public final int capacity( )// ★ 返回此缓冲区的容量 
	public final int position( )// ★ 返回此缓冲区的位置 
	public final Buffer position (int newPositio)// ★ 设置此缓冲区的位置 
	public final int limit( )// ★ 返回此缓冲区的限制 
	public final Buffer limit (int newLimit)// ★ 设置此缓冲区的限制 
	public final Buffer mark( )//在此缓冲区的位置设置标记 
	public final Buffer reset( )//将此缓冲区的位置重置为以前标记的位置 
	public final Buffer clear( )// ★ 清除此缓冲区, 即将各个标记恢复到初始状态，但是数据并没有真正擦除, 后面操作会覆盖 
	public final Buffer flip( )// ★ 反转此缓冲区 
	public final Buffer rewind( )//重绕此缓冲区 
	public final int remaining( )//返回当前位置与限制之间的元素数 
	public final boolean hasRemaining( )// ★ 告知在当前位置和限制之间是否有元素 
	public abstract boolean isReadOnly( );// ★ 告知此缓冲区是否为只读缓冲区 
    //JDK1.6时引入的api 
    public abstract boolean hasArray();// ★ 告知此缓冲区是否具有可访问的底层实现数组 
    public abstract Object array();// ★ 返回此缓冲区的底层实现数组 
    public abstract int arrayOffset();//返回此缓冲区的底层实现数组中第一个缓冲区元素的偏移量 
    public abstract boolean isDirect();//告知此缓冲区是否为直接缓冲区 
}
</code></pre>
<h4 id="34-通道channel">3.4. 通道(Channel)</h4>
<p><em>1：基本介绍</em><br>
NIO的通道类似于流，但有些区别如下：</p>
<blockquote>
<p>• 通道可以同时进行读写，而流只能读或者只能写<br>
• 通道可以实现异步读写数据<br>
• 通道可以从缓冲读数据，也可以写数据到缓冲:</p>
</blockquote>
<p>FileChannel主要用来对本地文件进行 IO 操作，常见的方法有</p>
<pre><code class="language-java">public int read(ByteBuffer dst) ，从通道读取数据并放到缓冲区中
public int write(ByteBuffer src) ，把缓冲区的数据写到通道中
public long transferFrom(ReadableByteChannel src, long position, long count)，从目标通道 中复制数据到当前通道
public long transferTo(long position, long count, WritableByteChannel target)，把数据从当 前通道复制给目标通道
</code></pre>
<p>首先channel与文件联立，判断是输入输出流看channel与buffer之间的关系</p>
<h4 id="35-关于buffer-和-channel的注意事项和细节">3.5. 关于Buffer 和 Channel的注意事项和细节</h4>
<p>1：ByteBuffer 支持类型化的 put 和 get, put 放入的是什么数据类型，get 就应该使用相应的数据类型来取出（取出的顺序也要和存入的顺序一致），否则可能有 BufferUnderflowException 异常。</p>
<p>2： 可以将一个普通Buffer 转成只读Buffer，如果对一个只读类型的 Buffer 进行写操作会报错 ReadOnlyBufferException</p>
<pre><code class="language-java">ByteBuffer buffer = ByteBuffer.allocate(3);
ByteBuffer byteBuffer = buffer.asReadOnlyBuffer();
System.out.println(buffer);
System.out.println(byteBuffer);
</code></pre>
<p>3：NIO 还提供了 MappedByteBuffer， 可以让文件直接在内存（堆外的内存）中进行修改， 而如何同步到文件由NIO 来完成.</p>
<pre><code class="language-java">/* 说明
    1. MappedByteBuffer 可以让文件直接在内存中修改，这样操作系统并不需要拷贝一次
    2. MappedByteBuffer 实际类型是 DirectByteBuffer
*/
public static void main(String[] args) throws Exception {
   RandomAccessFile randomAccessFile = new RandomAccessFile(&quot;D:\\file01.txt&quot;, &quot;rw&quot;);
   // 获取对应的文件通道
   FileChannel channel = randomAccessFile.getChannel();
   // 参数 ：使用 只读/只写/读写 模式 ； 可以修改的起始位置 ； 映射到内存的大小，即可以将文件的多少个字节映射到内存
   // 这里就表示，可以对 file01.txt 文件中 [0,5) 的字节进行 读写操作
   MappedByteBuffer map = channel.map(FileChannel.MapMode.READ_WRITE, 0, 5);
   // 进行修改操作
   map.put(0, (byte) 'A');
   map.put(3, (byte) '3');
   // 关闭通道
   channel.close();
}
</code></pre>
<p>4：前面我们讲的读写操作，都是通过一个Buffer 完成的，NIO 还支持 通过多个 Buffer (即 Buffer 数组) 完成读写操作，即 Scattering 和 Gathering ，遵循 依次写入，依次读取。</p>
<pre><code class="language-java">public static void main(String[] args) throws Exception {
    // 使用 ServerSocketChannel 和 InetSocketAddress 网络
    ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();
    InetSocketAddress inetSocketAddress = new InetSocketAddress(7000);
    //绑定端口到socket，启动
    serverSocketChannel.socket().bind(inetSocketAddress);

    //创建buffer的2个数组
    ByteBuffer[] byteBuffers = new ByteBuffer[2];
    byteBuffers[0] = ByteBuffer.allocate(5);
    byteBuffers[1] = ByteBuffer.allocate(3);

    //等待客户端连接
    SocketChannel socketChannel = serverSocketChannel.accept();
    int messageLength = 8;
    //循环的读取
    while(true){
        // 表示累计读取的字节数
        int byteRead = 0;
        // 假设从客户端最多接收 8 个字节
        while (byteRead &lt; messageLength){
            // 自动把数据分配到 byteBuffers-0、byteBuffers-1
            long read = socketChannel.read(byteBuffers);
            byteRead += read;
            // 使用流打印，查看当前 Buffer 的 Position 和 Limit
            Arrays.asList(byteBuffers).stream().
                    map(byteBuffer -&gt; &quot;{position: &quot;+byteBuffer.position()+&quot;, limit: &quot;+byteBuffer.limit()+&quot;}&quot;)
                    .forEach(System.out::println);
        }
        // 将所有的 Buffer 进行反转，为后面的其他操作做准备
        Arrays.asList(byteBuffers).forEach(Buffer -&gt;Buffer.flip());

        // 将数据读出，显示到客户端
        int byteWrite = 0;
        while (byteWrite &lt; messageLength){
            long write = socketChannel.write(byteBuffers);
            byteWrite += write;
        }

        // 将所有的 Buffer 进行清空，为后面的其他操作做准备
        Arrays.asList(byteBuffers).forEach(Buffer-&gt;Buffer.clear());

        // 打印处理的字节数
        System.out.println(&quot;{byteRead: &quot;+byteRead+&quot;, byteWrite: &quot;+byteWrite+&quot;}&quot;);

    }
}
</code></pre>
<h4 id="36-selector选择器">3.6. Selector选择器</h4>
<h5 id="1-基本介绍">1. 基本介绍</h5>
<blockquote>
<p>1: Java 的 NIO，用非阻塞的 IO 方式。可以用一个线程，处理多个的客户端连接，就会使用到Selector(选择器)<br>
2: Selector 能够检测多个注册的通道上是否有事件发生(注意:多个Channel以事件的方式可以注册到同一个Selector)，如果有事件发生，便获取事件然 后针对每个事件进行相应的处理。这样就可以只用一个单线程去管理多个通道，也就是管理多个连接和请求。<br>
3: 只有在 连接/通道 真正有读写事件发生时，才会进行读写，就大大地减少 了系统开销，并且不必为每个连接都创建一个线程，不用去维护多个线程<br>
4: 避免了多线程之间的上下文切换导致的开销</p>
</blockquote>
<h5 id="2-selector选择器">2. Selector(选择器)</h5>
<p>示意图</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1656504430406.png" alt="" loading="lazy"></figure>
<p>说明:</p>
<blockquote>
<p>Netty 的 IO 线程 NioEventLoop 聚合了 Selector(选择器， 也叫多路复用器)，可以同时并发处理成百上千个客 户端连接。<br>
当线程从某客户端 Socket 通道进行读写数据时，若没 有数据可用时，该线程可以进行其他任务。<br>
线程通常将非阻塞 IO 的空闲时间用于在其他通道上 执行 IO 操作，所以单独的线程可以管理多个输入和 输出通道。<br>
由于读写操作都是非阻塞的，这就可以充分提升 IO 线程的运行效率，避免由于频繁 I/O 阻塞导致的线程 挂起。<br>
一个 I/O 线程可以并发处理 N 个客户端连接和读写操作，这从根本上解决了传统同步阻塞 I/O 一连接一线 程模型，架构的性能、弹性伸缩能力和可靠性都得到 了极大的提升。</p>
</blockquote>
<h5 id="3-selector类相关方法">3. Selector类相关方法</h5>
<p>Selector 类是一个抽象类, 常用方法和说明如下</p>
<pre><code class="language-java">public abstract class Selector implements Closeable { 
	public static Selector open();//得到一个选择器对象 
	public int select(long timeout);//监控所有注册的通道，当其 中有 IO 操作可以进行时，将 对应的 SelectionKey 加入到内部集合中并返回，参数用来 设置超时时间 
	public Set&lt;SelectionKey&gt; selectedKeys();//从内部集合中得 到所有的 SelectionKey 
}
</code></pre>
<h5 id="4-注意事项">4. 注意事项</h5>
<p>NIO中的 ServerSocketChannel功能类似ServerSocket，SocketChannel功能类 似Socket</p>
<p>selector 相关方法说明</p>
<pre><code class="language-java">selector.select()//阻塞
selector.select(1000);//阻塞1000毫秒，在1000毫秒后返回
selector.wakeup();//唤醒
selector selector.selectNow();//不阻塞，立马返还
</code></pre>
<h4 id="37-nio-非阻塞-网络编程原理分析">3.7. NIO 非阻塞 网络编程原理分析</h4>
<p>NIO 非阻塞 网络编程相关的(Selector、SelectionKey、 ServerScoketChannel和SocketChannel) 关系梳理图</p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1656504451263.png" alt="" loading="lazy"></figure>
<p>说明：</p>
<blockquote>
<p>ServerSocketChannel 需要在selector注册，一旦有register事件（客户端一旦连接）就会建立SocketChannel<br>
客户端连接时需要会通过ServerSocketChannel 在selector注册，一旦有读写事件，反向获取通道channel，把channel数据读出到buffer<br>
事件发生通过SelectorKey来判断</p>
</blockquote>
<p><strong>代码演示：server端</strong></p>
<pre><code class="language-java">public static void main(String[] args) throws Exception {
    //服务器端创建ServerSocketChannel -&gt;ServerSocketChannel
    ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();   
	//得到一个Selector对象
    Selector selector = Selector.open();

    //绑定一个端口6666，在服务器端监听
    serverSocketChannel.socket().bind(new InetSocketAddress(6666));
    //设置为非阻塞
    serverSocketChannel.configureBlocking(false);

    //把serverSocketChannel 注册到 selector 关心的事件：op_ACCEPT
    serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);

    //循环等待客户端连接
    while(true){
        if(selector.select(1000) == 0){//没有事件发生
            System.out.println(&quot;服务器等待1s,无连接&quot;);
            continue;
        }

        //返回大于0，获取相关的selectionKey集合(获取到关注的事件)
        //selector.selectedKeys() 返回关注的事件集合
        Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys();

        //遍历,使用迭代器
        Iterator&lt;SelectionKey&gt; keyIterator = selectionKeys.iterator();

        while(keyIterator.hasNext()){
            //获取到SelectionKey
            SelectionKey key = keyIterator.next();
            //根据key 对应的通道发生的事件做相应的处理
            if(key.isAcceptable()){//如果是OP_ACCEPT,有新的客户端连接
                //该客户端生成一个SocketChannel
                SocketChannel socketChannel = serverSocketChannel.accept();
                System.out.println(&quot;客户端连接成功，生成一个socketChannel&quot;);
                //将socketChannel设置为非阻塞，这时线程可以做其他事
                socketChannel.configureBlocking(false);
                //将socketChannel 注册到Selector，关注OP_READ，同时给socketChannel关联一个buffer
               socketChannel.register(selector,SelectionKey.OP_READ, ByteBuffer.allocate(1024));

            }
            if(key.isReadable()){//发生OP_READ
                //通过key 反向获取对应的channel
                SocketChannel channel = (SocketChannel) key.channel();
                //获取改channel关联的buffer
                ByteBuffer buffer = (ByteBuffer) key.attachment();
                channel.read(buffer);
                System.out.println(&quot;form client &quot;+ new String(buffer.array()));
            }
            //手动从集合中移动当前的selectionKey,防止重复操作
            keyIterator.remove();

        }

    }
}
</code></pre>
<p><strong>client端：</strong></p>
<pre><code class="language-java">public static void main(String[] args) throws Exception {
    //得到一个网络通道
    SocketChannel socketChannel = SocketChannel.open();
    //设置非阻塞模式
    socketChannel.configureBlocking(false);    
	//提供服务器端的ip和端口
    InetSocketAddress inetSocketAddress = new InetSocketAddress(&quot;127.0.0.1&quot;,6666);

    //连接服务器
    if(!socketChannel.connect(inetSocketAddress)){
        while(!socketChannel.finishConnect()){
            System.out.println(&quot;连接需要时间，客户端不会阻塞，可做其他工作&quot;);
        }
    }
    //连接成功，发送数据
    String str = &quot;hello,world&quot;;
    //获得字节数组到buffer中,且buffer大小与字节长度一致
    ByteBuffer buffer = ByteBuffer.wrap(str.getBytes());
    //发送数据，将buffer 数据写入channel
    socketChannel.write(buffer);
    System.in.read();
}
</code></pre>
<h4 id="38-selectionkey">3.8. SelectionKey</h4>
<p>SelectionKey，表示 Selector 和网络通道的注册关系（OPS）, 共四种：</p>
<blockquote>
<p>int OP_ACCEPT：有新的网络连接可以 accept，值为 16<br>
int OP_CONNECT：代表连接已经建立，值为 8<br>
int OP_READ：代表读操作，值为 1<br>
int OP_WRITE：代表写操作，值为 4</p>
</blockquote>
<p>源码中：</p>
<blockquote>
<p>public static final int OP_READ = 1 &lt;&lt; 0;<br>
public static final int OP_WRITE = 1 &lt;&lt; 2;<br>
public static final int OP_CONNECT = 1 &lt;&lt; 3;<br>
public static final int OP_ACCEPT = 1 &lt;&lt; 4;</p>
</blockquote>
<p>SelectionKey相关方法</p>
<pre><code class="language-java">public abstract class SelectionKey { 
	public abstract Selector selector();//得到与之关联的 Selector 对象 
	public abstract SelectableChannel channel();//得到与之关 联的通道 
	public final Object attachment();//得到与之关联的共享数 据 
	public abstract SelectionKey interestOps(int ops);//设置或改 变监听事件 
	public final boolean isAcceptable();//是否可以 accept 
	public final boolean isReadable();//是否可以读 
	public final boolean isWritable();//是否可以写 
}
</code></pre>
<h4 id="39-serversocketchannel">3.9. ServerSocketChannel</h4>
<p>ServerSocketChannel 在服务器端监听新的客户端 Socket 连接</p>
<p>相关方法如下:</p>
<pre><code class="language-java">public abstract class ServerSocketChannel extends AbstractSelectableChannel implements NetworkChannel{ 
	public static ServerSocketChannel open()//得到一个 ServerSocketChannel 通道 
	public final ServerSocketChannel bind(SocketAddress local)//设置服务器端端口 号
	public final SelectableChannel configureBlocking(boolean block)//设置阻塞或非 阻塞模式，取值 false 表示采用非阻塞模式 
	public SocketChannel accept()//接受一个连接，返回代表这个连接的通道对象
	public final SelectionKey register(Selector sel, int ops)//注册一个选择器并设置 监听事件 
}
</code></pre>
<h4 id="310-socketchannel">3.10. SocketChannel</h4>
<p>SocketChannel，网络 IO 通道，具体负责进行读写操作。NIO 把缓冲区的数据写入通 道，或者把通道里的数据读到缓冲区。</p>
<p>相关方法如下</p>
<pre><code class="language-java">public abstract class SocketChannel extends AbstractSelectableChannel implements ByteChannel, ScatteringByteChannel, GatheringByteChannel, NetworkChannel{ 
	public static SocketChannel open();//得到一个 SocketChannel 通道 
	public final SelectableChannel configureBlocking(boolean block);//设置阻塞或非阻塞 模式，取值 false 表示采用非阻塞模式 
	public boolean connect(SocketAddress remote);//连接服务器 
	public boolean finishConnect();//如果上面的方法连接失败，接下来就要通过该方法 完成连接操作 
	public int write(ByteBuffer src);//往通道里写数据 
	public int read(ByteBuffer dst);//从通道里读数据 
	public final SelectionKey register(Selector sel, int ops, Object att);//注册一个选择器并 设置监听事件，最后一个参数可以设置共享数据 
	public final void close();//关闭通道 
}
</code></pre>
<h4 id="311-nio-网络编程应用实例-群聊系统">3.11. NIO 网络编程应用实例-群聊系统</h4>
<blockquote>
<p>要求:<br>
编写一个 NIO 群聊系统，实现服务器端和客户端之间的数据简单通讯（非阻塞）<br>
实现多人群聊<br>
服务器端：可以监测用户上线，离线， 并实现消息转发功能<br>
客户端：通过channel 可以无阻塞发送 消息给其它所有用户，同时可以接受 其它用户发送的消息(有服务器转发得到)<br>
目的：进一步理解NIO非阻塞网络编程 机制</p>
</blockquote>
<p><strong>代码实现：服务端</strong></p>
<pre><code class="language-java">package com.atguigu.groupchat;

import java.io.IOException;
import java.net.InetSocketAddress;
import java.nio.ByteBuffer;
import java.nio.channels.*;
import java.util.Iterator;

public class GroupChatServer {
    //定义属性
    private Selector selector;
    private ServerSocketChannel listenChannel;
    private static final int PORT = 6667;
    //构造器
    //初始化工作
    public GroupChatServer(){
        try {
            //得到选择器
            selector = Selector.open();
            //得到ServerSocketChannel
            listenChannel = ServerSocketChannel.open();
            //绑定端口
            listenChannel.socket().bind(new InetSocketAddress(PORT));
            //设置非阻塞
            listenChannel.configureBlocking(false);
            //listenChannel注册到Selector
            listenChannel.register(selector, SelectionKey.OP_ACCEPT);
    	} catch (IOException e) {
            e.printStackTrace();
       	}
	}
    //监听
    public void listen(){
        try {
            //循环处理监听
            while(true){
                int count = selector.select();
                if(count&gt;0){//有事件
                    //遍历得到selectionKey 集合
                    Iterator&lt;SelectionKey&gt; iterator = selector.selectedKeys().iterator();
                    while(iterator.hasNext()){
                        //取得selectionKey
                        SelectionKey key = iterator.next();
                        if(key.isAcceptable()){//连接事件
                            SocketChannel socketChannel = listenChannel.accept();
                            socketChannel.configureBlocking(false);
                            socketChannel.register(selector,SelectionKey.OP_READ);
                            //提示客户上线
                            System.out.println(socketChannel.getRemoteAddress()+&quot;上线了&quot;);
                        }
                        else if(key.isReadable()){//read事件
                            readDate(key);
                        }
                        //手动从集合中移动当前的selectionKey,防止重复操作
                        iterator.remove();
                    }

                }
                else{
                    System.out.println(&quot;waiting event&quot;);
                }
            }
        } catch (Exception e) {
            e.printStackTrace();
        }finally {

        }
    }
    //读取client数据
    public void readDate(SelectionKey key){
        //定义一个SocketChannel
        SocketChannel socketChannel = null;
        try {
            //取到关联的channel
            socketChannel = (SocketChannel)key.channel();
            //创建缓存
            ByteBuffer byteBuffer = ByteBuffer.allocate(1024);
            int count = socketChannel.read(byteBuffer);
            if(count&gt;0){
                //buffer的数据转成字符串
                String msg = new String(byteBuffer.array());
                //输出msg
                System.out.println(&quot;form client&quot;+msg);
                //向其他客户端转发消息
                sendInfoToOtherClient(msg,socketChannel);
            }
        } catch (IOException e) {
            try {
                System.out.println(socketChannel.getRemoteAddress()+&quot;离线了&quot;);
                //取消注册
                key.cancel();
                //关闭通道
                socketChannel.close();
            } catch (IOException ioException) {
                ioException.printStackTrace();
            }
        }

    }
    //转发消息给其他消息
    private void sendInfoToOtherClient(String msg,SocketChannel self) throws IOException{
        //遍历所有注册到selector的SocketChannel
        for(SelectionKey key: selector.keys()){
            Channel targetChannel = key.channel();
            //排除自己
            if(targetChannel != self &amp;&amp; targetChannel instanceof SocketChannel){
                //转发
                SocketChannel dest = (SocketChannel)targetChannel;
                //写入buffer
                ByteBuffer buffer = ByteBuffer.wrap(msg.getBytes());
                //写入通道
                dest.write(buffer);
            }
        }
    }
    public static void main(String[] args) {
        // 创建一个服务器对象
        GroupChatServer server = new GroupChatServer();
        server.listen();
    }
}
</code></pre>
<p><strong>代码实现：客户端</strong></p>
<pre><code class="language-java">package com.atguigu.groupchat;

import java.io.IOException;
import java.net.InetSocketAddress;
import java.nio.ByteBuffer;
import java.nio.channels.SelectionKey;
import java.nio.channels.Selector;
import java.nio.channels.SocketChannel;
import java.util.Iterator;
import java.util.Scanner;

public class GroupChatClient {
    // 定义相关属性
    // 服务器的IP
    private final String HOST = &quot;127.0.0.1&quot;;
    // 服务器的端口
    private final int PORT = 6667;
    private Selector selector;
    private SocketChannel socketChannel;
    private String username;

    // 构造器
    public GroupChatClient() throws IOException {
        // 完成初始化
        selector = Selector.open();
        // 连接服务器
        socketChannel = SocketChannel.open(new InetSocketAddress(HOST, PORT));
        // 设置 非阻塞
        socketChannel.configureBlocking(false);
        // 将 socketChannel 注册到 Selector
        socketChannel.register(selector, SelectionKey.OP_READ);
        // 得到 username
        username = socketChannel.getLocalAddress().toString().substring(1);
        System.out.println(username + &quot;is OK!&quot;);

    }

    // 向服务器发送消息
    public void sendMessage(String message){
        message = username + &quot;说：&quot;+ message;
        try {
            // 把 message 写入 buffer
            socketChannel.write(ByteBuffer.wrap(message.getBytes()));
            // 读取从服务器端回复的消息
        }catch (Exception e){
            e.printStackTrace();
        }finally {

        }
    }

    public void readmessage(){
        try {
            int select = selector.select();
            if (select &gt; 0){
                // 有事件发生的通道
                Iterator&lt;SelectionKey&gt; iterator = selector.selectedKeys().iterator();
                while (iterator.hasNext()){
                    SelectionKey key = iterator.next();
                    if (key.isReadable()){
                        // 得到相关的通道
                        SocketChannel channel = (SocketChannel) key.channel();
                        ByteBuffer buffer = ByteBuffer.allocate(1024);
                        channel.read(buffer);
                        String msg = new String(buffer.array());
                        System.out.println(msg.trim());
                    }
                }
                iterator.remove();//删除当前的selectionKey
            }else {
            //                System.out.println(&quot;没有可用的通道&quot;);
     		}
        }catch (Exception e){
            e.printStackTrace();
        }finally {

        }
    }

    public static void main(String[] args) throws IOException {
        // 启动客户端
        GroupChatClient client = new GroupChatClient();

        // 启动一个线程,每个三秒读取从服务器端读取数据
        new Thread(){
            public void run(){
                while (true){
                    client.readmessage();
                    try {
                        Thread.sleep(3000);
                    }catch (Exception e){
                        e.printStackTrace();
                    }
                }
            }

        }.start();

        // 发送数据给服务端
        Scanner scanner = new Scanner(System.in);
        while (scanner.hasNextLine()){
            String line = scanner.nextLine();
            client.sendMessage(line);
        }
    }
}     
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[前端简单部署]]></title>
        <id>https://tinaxiawuhao.github.io/post/KEyilqyTn/</id>
        <link href="https://tinaxiawuhao.github.io/post/KEyilqyTn/">
        </link>
        <updated>2022-06-18T03:54:16.000Z</updated>
        <content type="html"><![CDATA[<p>部署前端项目，将打包后的文件dist放入nginx，基于nginx的基础镜像创建前端项目的docker镜像即可</p>
<h3 id="一-前端项目的文件准备">一、前端项目的文件准备</h3>
<h4 id="1-文件准备">1、文件准备：</h4>
<pre><code class="language-shell">1,dockerfile(docker部署镜像打包文件)
2,dist(待部署前端文件夹)
3,default.conf
</code></pre>
<h4 id="2-dockerfile文件">2、Dockerfile文件：</h4>
<pre><code class="language-shell">FROM nginx
RUN rm /etc/nginx/conf.d/default.conf
ADD default.conf /etc/nginx/conf.d/
COPY dist/ /usr/share/nginx/html/
EXPOSE 80
</code></pre>
<h4 id="3-defaultconf">3、default.conf：</h4>
<pre><code class="language-shell">server {
    listen       80;
    server_name  localhost; # 修改为docker服务宿主机的ip
  
    location / {
        root   /usr/share/nginx/html;
        index  index.html index.htm;
        try_files $uri $uri/ /index.html =404;
    }
  
    error_page   500 502 503 504  /50x.html;
    location = /50x.html {
        root   html;
    }
    
    location /api/ {
        proxy_pass http://后端服务名:IP端口;
    }
}
</code></pre>
<hr>
<h3 id="二-vue项目的自动化部署">二、vue项目的自动化部署</h3>
<h4 id="1-安装jenkins">1、安装Jenkins</h4>
<blockquote>
<p>Jenkins的安装：https://tinaxiawuhao.github.io/post/MN_sOyfo3/</p>
</blockquote>
<h4 id="2-安装nodenpmyarn">2、安装node/npm/yarn</h4>
<blockquote>
<p>安装node与node/npm/yarn：https://tinaxiawuhao.github.io/post/XMNtsw8ig/</p>
</blockquote>
<h4 id="3-jenkins中配置harbor仓库的密钥">3、Jenkins中配置harbor仓库的密钥</h4>
<p>我们需要通过jenkinsfile文件推送docker镜像到指定的harbor仓库，需要在jenkins中配置仓库登录凭据</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1655524689375.png" alt="" loading="lazy"></figure>
<h4 id="4-编写jenkinsfile">4、编写Jenkinsfile</h4>
<pre><code>pipeline{
    agent any
 
    environment {
        WS = &quot;${WORKSPACE}&quot;
        HARBOR_URL=&quot;harbor的url&quot;
        HARBOR_ID=&quot;harbor密钥&quot;
    }
 
    stages {
        stage(&quot;环境检查&quot;){
            steps {
                sh 'docker version'
                sh 'npm -v'
                sh 'yarn -v'
            }
        }
        stage('yarn安装与编译') {
            steps {
                sh &quot;echo ${WS} &amp;&amp; ls -alh&quot;
                sh &quot;cd ${WS} &amp;&amp; yarn install&quot;
                sh &quot;cd ${WS} &amp;&amp; yarn build:hd&quot;
            }
        }
        stage('docker镜像与推送') {
            steps {
                sh &quot;cd ${WS} &amp;&amp; docker build -f Dockerfile -t ${HARBOR_URL}/test/web:latest .&quot;
                withCredentials([usernamePassword(credentialsId: &quot;${HARBOR_ID}&quot;, passwordVariable: 'password', usernameVariable: 'username')]) {
                    sh &quot;docker login -u ${username} -p ${password} ${HARBOR_URL}&quot;
                    sh &quot;docker push ${HARBOR_URL}/test/web:latest&quot;
                }
            }
        }
         
    }
     post {
        success {
            echo 'success!'
        }
        failure {
            echo 'failed...'
        }
    }
}
</code></pre>
<p><strong>harbor密钥获取</strong></p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1655524703581.png" alt="" loading="lazy"></figure>
<p>点进入刚才添加的凭证获取凭证</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1655524712540.png" alt="" loading="lazy"></figure>
<p>最后创建一个pipeline项目（可选择Pipeline或者多分支流水线），pipeline脚本定义选择Pipeline script from SCM，选择git项目</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1655524732059.png" alt="" loading="lazy"></figure>
<p>修改关注分支</p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1655524738660.png" alt="" loading="lazy"></figure>
<h3 id="三-模仿后端实现环境变量注入">三、模仿后端实现环境变量注入</h3>
<p><strong>借助Nginx1.19以后docker镜像的template新功能，可以实现配置文件环境变量的动态注入</strong></p>
<h4 id="1-准备-defaultconftemplate">1、准备 default.conf.template：</h4>
<pre><code class="language-shell">server {
    listen       80;
    listen  [::]:80;
    server_name  localhost; # 修改为docker服务宿主机的ip
 
    location / {
        root   /usr/share/nginx/html;
        index  index.html index.htm;
        ssi on;
        try_files $uri $uri/ /index.html;
        if ($request_filename ~* ^.*?\.(eot)|(ttf)|(woff)|(svg)|(otf)$) {
            add_header Access-Control-Allow-Origin *;
        }
    }
 
    error_page   500 502 503 504  /50x.html;
    location = /50x.html {
        root   /usr/share/nginx/html;
    }
 
    location /api/ {
        ssi on;  # 借助ssi
        proxy_pass ${BACKEND_SERVICE_URL};
    }
}
</code></pre>
<h4 id="2-编写dockerfile文件">2、编写Dockerfile文件：</h4>
<pre><code class="language-shell">FROM nginx:1.21
COPY dist /usr/share/nginx/html
# 注意和上面文件对比位置的改变
COPY default.conf.template /etc/nginx/templates/
EXPOSE 80
</code></pre>
<h4 id="3-设置环境变量">3、设置环境变量</h4>
<p>部署docker时候，设置环境变量-e BACKEND_SERVICE_URL= http://ip:port  后，实际的nginx配置就变为了：</p>
<blockquote>
<p>$BACKEND_SERVICE_URL = http://ip:port #后端服务的地址；</p>
</blockquote>
<pre><code class="language-shell">server {
    listen       80;
    listen  [::]:80;
    server_name  localhost; # 修改为docker服务宿主机的ip
 
    location / {
        root   /usr/share/nginx/html;
        index  index.html index.htm;
        ssi on;
        try_files $uri $uri/ /index.html;
        if ($request_filename ~* ^.*?\.(eot)|(ttf)|(woff)|(svg)|(otf)$) {
            add_header Access-Control-Allow-Origin *;
        }
    }
 
    error_page   500 502 503 504  /50x.html;
    location = /50x.html {
        root   /usr/share/nginx/html;
    }
 
    location /api/ {
        ssi on;  # 借助ssi
        proxy_pass  http://ip:port;
    }
}
</code></pre>
<p>切换服务就可以修改环境变量，切换不同的服务后端</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[gitlab提交代码自动触发Jenkins构建操作]]></title>
        <id>https://tinaxiawuhao.github.io/post/ymh_BwIfn/</id>
        <link href="https://tinaxiawuhao.github.io/post/ymh_BwIfn/">
        </link>
        <updated>2022-06-16T04:27:16.000Z</updated>
        <content type="html"><![CDATA[<h3 id="jenkins配置">Jenkins配置</h3>
<h4 id="插件安装">插件安装</h4>
<p>系统管理=====》插件管理=====》可选插件=====》搜索要按照的插件(gitlab hook-plugin和gitlab-plugin)<br>
如果找不到上面两个插件，安装gitlab和gitlab hook即可</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1655527394729.gif" alt="" loading="lazy"></figure>
<h4 id="创建测试项目">创建测试项目</h4>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1655527415958.gif" alt="" loading="lazy"></figure>
<h4 id="gitlab配置">gitlab配置</h4>
<p>打开要关联Jenkins项目的设置选项找到webhooks选项，把Jenkins中的项目触发器url以及Secret token配置到gitlab的webhooks选项中</p>
<p>URL</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1655527426929.png" alt="" loading="lazy"></figure>
<p>Secret token</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1655527439844.gif" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1655527449909.gif" alt="" loading="lazy"></figure>
<h4 id="验证效果">验证效果</h4>
<p>我们测试下点击刚刚关联的构建动作，Jenkins会不会自动构建<br>
当出现请求状态码200的时候证明我们的关联动作已经执行</p>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1655527459975.png" alt="" loading="lazy"></figure>
<p>下面我们去到Jenkins中看下是否有构建历史</p>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1655527466575.png" alt="" loading="lazy"></figure>
<p>再试下手动push代码到gitlab会不会触发Jenkins的构建任务<br>
手动去到服务器上向远程gitlab分支推送文件</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[linux安装node]]></title>
        <id>https://tinaxiawuhao.github.io/post/XMNtsw8ig/</id>
        <link href="https://tinaxiawuhao.github.io/post/XMNtsw8ig/">
        </link>
        <updated>2022-06-14T04:18:37.000Z</updated>
        <content type="html"><![CDATA[<p>以当前node版本16.13.0为例，新建演示目录/usr/local/node</p>
<h3 id="1-下载">1、下载</h3>
<pre><code>wget https://nodejs.org/dist/v16.13.0/node-v16.13.0-linux-x64.tar.xz
</code></pre>
<h3 id="2-移动到指定目录">2、移动到指定目录</h3>
<pre><code>mv node-v16.13.0-linux-x64.tar.xz  /usr/local/node
</code></pre>
<h3 id="3-解压">3、解压</h3>
<pre><code>xz -d node-v16.13.0-linux-x64.tar.xz
tar -xvf node-v16.13.0-linux-x64.tar
</code></pre>
<p>测试下：</p>
<pre><code>/root/sdemo/node-v16.13.0-linux-x64/bin/node -v
v16.13.0

/root/sdemo/node-v16.13.0-linux-x64/bin/npm -v
8.1.0
</code></pre>
<h3 id="4-设置软连接相当于windows设置环境变量">4、设置软连接，相当于windows设置环境变量</h3>
<pre><code>ln -s /usr/local/node/node-v16.13.0-linux-x64/bin/node   /usr/bin/node
ln -s /usr/local/node/node-v16.13.0-linux-x64/bin/npm   /usr/bin/npm
</code></pre>
<h3 id="5-安装yarn并设置yarn的软连">5、安装yarn,并设置yarn的软连</h3>
<pre><code>npm install yarn -g
ln -s /usr/local/node/node-v16.13.0-linux-x64/bin/yarn   /usr/bin/yarn
</code></pre>
<p>测试下：</p>
<pre><code>yarn -v
1.22.17
</code></pre>
<h3 id="6-安装cnpm">6、安装cnpm</h3>
<pre><code>npm install -g cnpm --registry=https://registry.npm.taobao.org
ln -s /usr/local/node/lib/node-v16.13.0-linux-x64/bin/cnpm  /usr/bin/cnpm
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[linux安装jenkins]]></title>
        <id>https://tinaxiawuhao.github.io/post/MN_sOyfo3/</id>
        <link href="https://tinaxiawuhao.github.io/post/MN_sOyfo3/">
        </link>
        <updated>2022-06-13T04:05:04.000Z</updated>
        <content type="html"><![CDATA[<h3 id="1-安装jdk">1、安装JDK</h3>
<pre><code class="language-shell">yum install -y java
</code></pre>
<h3 id="2-安装jenkins">2、安装jenkins</h3>
<p><strong>添加Jenkins库到yum库，Jenkins将从这里下载安装。</strong></p>
<pre><code class="language-shell">wget -O /etc/yum.repos.d/jenkins.repo http://pkg.jenkins-ci.org/redhat/jenkins.repo

rpm --import https://jenkins-ci.org/redhat/jenkins-ci.org.key

yum install -y jenkins
或
yum install jenkins -y --nogpgcheck
</code></pre>
<h3 id="3-修改jenkins端口">3、修改jenkins端口</h3>
<pre><code>[root@tools ~]# rpm -qa | grep jenkins
jenkins-2.340-1.1.noarch
</code></pre>
<pre><code>[root@tools ~]# rpm -ql jenkins-2.340-1.1.noarch
/etc/init.d/jenkins
/etc/logrotate.d/jenkins
/etc/sysconfig/jenkins
/usr/bin/jenkins
/usr/lib/systemd/system/jenkins.service
/usr/sbin/rcjenkins
/usr/share/java/jenkins.war
/usr/share/jenkins
/usr/share/jenkins/migrate
/var/cache/jenkins
/var/lib/jenkins
/var/log/jenkins
</code></pre>
<pre><code>[root@tools ~]# vim /usr/lib/systemd/system/jenkins.service
vi /etc/sysconfig/jenkins

找到修改端口号：
JENKINS_PORT=“9000” #此端口不冲突可以不修改
</code></pre>
<h3 id="4-启动jenkins">4、启动jenkins</h3>
<pre><code>systemctl start jenkins.service
</code></pre>
<pre><code>[root@tools ~]# netstat -nultp
</code></pre>
<blockquote>
<p>安装成功后Jenkins将作为一个守护进程随系统启动<br>
系统会创建一个“jenkins”用户来允许这个服务，如果改变服务所有者，同时需要修改/var/log/jenkins, /var/lib/jenkins, 和/var/cache/jenkins的所有者<br>
启动的时候将从/etc/sysconfig/jenkins获取配置参数<br>
默认情况下，Jenkins运行在8080端口，在浏览器中直接访问该端进行服务配置<br>
Jenkins的RPM仓库配置被加到/etc/yum.repos.d/jenkins.repo</p>
</blockquote>
<h3 id="5-打开jenkins">5、打开jenkins</h3>
<p>在浏览器中访问 http://192.168.3.200:9000/<br>
首次进入会要求输入初始密码</p>
<p>初始密码在：/var/lib/jenkins/secrets/initialAdminPassword</p>
<p>重置密码：admin/admin</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[k8s高可用集群搭建]]></title>
        <id>https://tinaxiawuhao.github.io/post/McgbXRFnx/</id>
        <link href="https://tinaxiawuhao.github.io/post/McgbXRFnx/">
        </link>
        <updated>2022-06-11T13:48:56.000Z</updated>
        <content type="html"><![CDATA[<h2 id="整体环境">整体环境</h2>
<p>3台master节点，3台<a href="https://so.csdn.net/so/search?q=node&amp;spm=1001.2101.3001.7020">node</a>节点。采用了Centos 7，有网络，互相可以ping通。</p>
<p><strong>准备工作查看单集群部署</strong></p>
<h3 id="1安装keepalived-和-haproxy">1.安装keepalived 和 haproxy</h3>
<h4 id="11安装keepalived和-haproxy">1.1安装keepalived和 haproxy</h4>
<pre><code class="language-shell">1yum install keepalived haproxy -y
</code></pre>
<h4 id="12-配置-keepalived">1.2 配置 keepalived</h4>
<pre><code class="language-shell">cat &lt;&lt;EOF &gt; /etc/keepalived/keepalived.conf
! Configuration File for keepalived

global_defs {
   router_id k8s
}

vrrp_script check_haproxy {
    script &quot;/bin/bash -c 'if [[ $(netstat -nlp | grep 16443) ]]; then exit 0; else exit 1; fi'&quot;
    interval 3
    weight -2
    fall 10
    rise 2
}

vrrp_instance VI_1 {
    state MASTER 
    interface ens33 
    virtual_router_id 51
    priority 250
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass ceb1b3ec013d66163d6ab
    }
    virtual_ipaddress {
        192.168.40.19
    }
    track_script {
        check_haproxy
    }

}

EOF
</code></pre>
<pre><code>cat &lt;&lt;EOF &gt; /etc/keepalived/keepalived.conf
! Configuration File for keepalived

global_defs {
   router_id k8s
}

vrrp_script check_haproxy {
    script &quot;/bin/bash -c 'if [[ $(netstat -nlp | grep 16443) ]]; then exit 0; else exit 1; fi'&quot;
    interval 3
    weight -2
    fall 10
    rise 2
}

vrrp_instance VI_1 {
    state BACKUP 
    interface ens33 
    virtual_router_id 51
    priority 150
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass ceb1b3ec013d66163d6ab
    }
    virtual_ipaddress {
        192.168.40.19
    }
    track_script {
        check_haproxy
    }

}

EOF
</code></pre>
<pre><code>cat &lt;&lt;EOF &gt; /etc/keepalived/keepalived.conf
! Configuration File for keepalived

global_defs {
   router_id k8s
}

vrrp_script check_haproxy {
    script &quot;/bin/bash -c 'if [[ $(netstat -nlp | grep 16443) ]]; then exit 0; else exit 1; fi'&quot;
    interval 3
    weight -2
    fall 10
    rise 2
}

vrrp_instance VI_1 {
    state BACKUP 
    interface ens33 
    virtual_router_id 51
    priority 200
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass ceb1b3ec013d66163d6ab
    }
    virtual_ipaddress {
        192.168.40.19
    }
    track_script {
        check_haproxy
    }

}

EOF
</code></pre>
<blockquote>
<ul>
<li>vrrp_script 用于检测 haproxy 是否正常。如果本机的 haproxy 挂掉，即使 keepalived 劫持vip，也无法将流量负载到 apiserver。</li>
<li>我所查阅的网络教程全部为检测进程, 类似 killall -0 haproxy。这种方式用在主机部署上可以，但容器部署时，在 keepalived 容器中无法知道另一个容器 haproxy 的活跃情况，因此我在此处通过检测端口号来判断 haproxy 的健康状况。</li>
<li>weight 可正可负。为正时检测成功 +weight，相当与节点检测失败时本身 priority 不变，但其他检测成功节点 priority 增加。为负时检测失败本身 priority 减少。</li>
<li>另外很多文章中没有强调 nopreempt 参数，意为不可抢占，此时 master 节点失败后，backup 节点也不能接管 vip，因此我将此配置删去</li>
</ul>
</blockquote>
<h4 id="13-配置haproxy">1.3 配置haproxy</h4>
<pre><code class="language-shell">cat &lt;&lt;EOF &gt; /etc/haproxy/haproxy.cfg
#---------------------------------------------------------------------
# Global settings
#---------------------------------------------------------------------
global
    # to have these messages end up in /var/log/haproxy.log you will
    # need to:
    # 1) configure syslog to accept network log events.  This is done
    #    by adding the '-r' option to the SYSLOGD_OPTIONS in
    #    /etc/sysconfig/syslog
    # 2) configure local2 events to go to the /var/log/haproxy.log
    #   file. A line like the following can be added to
    #   /etc/sysconfig/syslog
    #
    #    local2.*                       /var/log/haproxy.log
    #
    log         127.0.0.1 local0
    
    chroot      /var/lib/haproxy
    pidfile     /var/run/haproxy.pid
    maxconn     4000
    user        haproxy
    group       haproxy
    daemon 
       
    # turn on stats unix socket
    stats socket /var/lib/haproxy/stats
#---------------------------------------------------------------------
# common defaults that all the 'listen' and 'backend' sections will
# use if not designated in their block
#---------------------------------------------------------------------  
defaults
    mode                    http
    log                     global
    option                  httplog
    option                  dontlognull
    option http-server-close
    option forwardfor       except 127.0.0.0/8
    option                  redispatch
    retries                 3
    timeout http-request    10s
    timeout queue           1m
    timeout connect         10s
    timeout client          1m
    timeout server          1m
    timeout http-keep-alive 10s
    timeout check           10s
    maxconn                 3000
#---------------------------------------------------------------------
# kubernetes apiserver frontend which proxys to the backends
#--------------------------------------------------------------------- 
frontend kubernetes-apiserver
    mode                 tcp
    bind                 *:16443
    option               tcplog
    default_backend      kubernetes-apiserver    
#---------------------------------------------------------------------
# round robin balancing between the various backends
#---------------------------------------------------------------------
backend kubernetes-apiserver
    mode        tcp
    balance     roundrobin
    server      gk8s-master   192.168.40.20:6443 check
    server      gk8s-master2   192.168.40.21:6443 check
    server      gk8s-master3   192.168.40.22:6443 check
#---------------------------------------------------------------------
# collection haproxy statistics message
#---------------------------------------------------------------------
listen stats
    bind                 *:1080
    stats auth           admin:awesomePassword
    stats refresh        5s
    stats realm          HAProxy\ Statistics
    stats uri            /admin?stats
    
EOF
</code></pre>
<p>设置开机启动</p>
<pre><code>systemctl enable haproxy &amp;&amp; systemctl start haproxy 
systemctl enable keepalived &amp;&amp; systemctl start keepalived 
</code></pre>
<h3 id="2安装kubeadm-kubelet-kubectl">2.安装kubeadm、kubelet、kubectl</h3>
<h4 id="1配置文件修改">1.配置文件修改</h4>
<pre><code class="language-shell">cat &lt;&lt;EOF | sudo tee /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=0
repo_gpgcheck=0
gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF
</code></pre>
<h4 id="2安装启用">2.安装启用</h4>
<pre><code class="language-shell">sudo yum install -y kubelet-1.24.1 kubeadm-1.24.1 kubectl-1.24.1 --disableexcludes=kubernetes 
sudo systemctl enable kubelet &amp;&amp; systemctl start kubelet
</code></pre>
<h4 id="3修改kubelet的配置文件">3.修改kubelet的配置文件</h4>
<p>先查看配置文件位置</p>
<pre><code class="language-shell">systemctl status kubelet
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1653818855680.png" alt="" loading="lazy"></figure>
<pre><code class="language-shell">vi /usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf
</code></pre>
<p>并添加以下内容(使用和docker相同的cgroup-driver)。</p>
<pre><code class="language-shell">Environment=&quot;KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --cgroup-driver=systemd&quot;
</code></pre>
<h4 id="4重启kubelet">4.重启kubelet</h4>
<pre><code class="language-shell">systemctl daemon-reload &amp;&amp; systemctl restart kubelet
</code></pre>
<h3 id="3获取k8s镜像可忽略">3.获取K8S镜像（可忽略）</h3>
<h4 id="1获取镜像列表">1.获取镜像列表</h4>
<p><strong>使用阿里云镜像仓库下载（国内环境该命令可不执行，下步骤kubeadm init --image-repository registry.cn-hangzhou.aliyuncs.com/google_containers已经默认为国内环境）</strong></p>
<p>由于官方镜像地址被墙，所以我们需要首先获取所需镜像以及它们的版本。然后从国内镜像站获取。</p>
<pre><code class="language-bash">kubeadm config images list
</code></pre>
<p>获取镜像列表后可以通过下面的脚本从阿里云获取：</p>
<pre><code class="language-shell">vi /usr/local/k8s/k8s-images.sh
</code></pre>
<blockquote>
<p>下面的镜像应该去除&quot;k8s.gcr.io/&quot;的前缀，版本换成上面获取到的版本</p>
</blockquote>
<pre><code class="language-bash">images=(  
    kube-apiserver:v1.24.1
    kube-controller-manager:v1.24.1
    kube-scheduler:v1.24.1
    kube-proxy:v1.24.1
    pause:3.7
    etcd:3.5.3-0
    coredns:v1.8.6
)

for imageName in ${images[@]} ; do
    docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName
    docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName k8s.gcr.io/$imageName
    docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName
done
</code></pre>
<h4 id="2赋权执行">2.赋权执行</h4>
<pre><code class="language-shell">chmod +x k8s-images.sh &amp;&amp; ./k8s-images.sh
</code></pre>
<p><strong>以上操作在所有机器执行</strong></p>
<h3 id="4初始化环境master操作">4.初始化环境（master操作）</h3>
<h4 id="1安装镜像">1.安装镜像</h4>
<p><strong>采用模板配置文件加载</strong></p>
<pre><code class="language-shell">kubeadm config print init-defaults  &gt; kubeadm-config.yaml
</code></pre>
<pre><code class="language-yaml"># 模板随版本更新
[root@master1 ~]# cat kubeadm-config.yaml 
apiVersion: kubeadm.k8s.io/v1beta2
bootstrapTokens:
- groups:
  - system:bootstrappers:kubeadm:default-node-token
  token: abcdef.0123456789abcdef
  ttl: 24h0m0s
  usages:
  - signing
  - authentication
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 192.168.40.131    # 本机IP
  bindPort: 6443
nodeRegistration:
  criSocket: unix:///var/run/cri-docker.sock  # 此处千万不要忘记修改，如果不修改等于没有替换。(此处已经更改完了)
  #criSocket: unix:///run/containerd/containerd.sock      # 此处千万不要忘记修改，如果不修改等于没有替换。(此处已经更改完了)
  name: master1        # 本主机名
  taints:
  - effect: NoSchedule
    key: node-role.kubernetes.io/master
---
apiServer:
  certSANs:
    - k8s-master-01
    - k8s-master-02
    - k8s-master-03
    - master.k8s.io
    - 192.168.40.19
    - 192.168.40.20
    - 192.168.40.21
    - 192.168.40.22
    - 127.0.0.1
  extraArgs:
    authorization-mode: Node,RBAC
  timeoutForControlPlane: 4m0s
apiVersion: kubeadm.k8s.io/v1beta2
certificatesDir: /etc/kubernetes/pki
clusterName: kubernetes
controlPlaneEndpoint: &quot;192.168.40.19:16443&quot;      # 虚拟IP和haproxy端口
controllerManager: {}
dns:
  type: CoreDNS
etcd:
  local:
    dataDir: /var/lib/etcd
imageRepository: registry.aliyuncs.com/google_containers    # 镜像仓库源要根据自己实际情况修改
kind: ClusterConfiguration
kubernetesVersion: v1.24.1     # k8s版本
networking:
  dnsDomain: cluster.local
  podSubnet: &quot;10.244.0.0/16&quot;   #设置网段，和下面网络插件对应
  serviceSubnet: 10.96.0.0/12
scheduler: {}
 
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
featureGates:
  SupportIPVSProxyMode: true
mode: ipvs
</code></pre>
<h4 id="2查看kubeadm版本修改命令参数">2.查看kubeadm版本，修改命令参数</h4>
<pre><code class="language-shell">kubeadm version
</code></pre>
<p>这个就很简单了，只需要简单的一个命令：</p>
<pre><code class="language-bash">#直接使用已经下载好的镜像
kubeadm init --kubernetes-version=v1.24.1 --control-plane-endpoint &quot;192.168.40.19:16443&quot; --apiserver-advertise-address=192.168.40.20 --pod-network-cidr=10.244.0.0/16 --service-cidr=10.96.0.0/12 --ignore-preflight-errors=Swap  --cri-socket unix:///var/run/cri-docker.sock | tee kubeadm-init.log
#或者采用aliyuncs镜像下载
kubeadm init --kubernetes-version=v1.24.1 --control-plane-endpoint &quot;192.168.40.19:16443&quot; --apiserver-advertise-address=192.168.40.20 --image-repository  registry.aliyuncs.com/google_containers  --service-cidr=10.1.0.0/16 --pod-network-cidr=10.244.0.0/16 --cri-socket unix:///var/run/cri-docker.sock| tee kubeadm-init.log
#使用上面系统生成配置文件加载
kubeadm init --config kubeadm-config.yaml
</code></pre>
<h4 id="3初始化命令说明">3.初始化命令说明：</h4>
<blockquote>
<p>虚拟ip节点端口号</p>
</blockquote>
<pre><code class="language-bash">--control-plane-endpoint
</code></pre>
<blockquote>
<p>指明用 Master 的哪个 interface 与 Cluster 的其他节点通信。如果 Master 有多个 interface，建议明确指定，如果不指定，kubeadm 会自动选择有默认网关的 interface。</p>
</blockquote>
<pre><code class="language-bash">--apiserver-advertise-address
</code></pre>
<blockquote>
<p>指定 Pod 网络的范围。Kubernetes 支持多种网络方案，而且不同网络方案对 --pod-network-cidr 有自己的要求，这里设置为 10.244.0.0/16 是因为我们将使用 flannel 网络方案，必须设置成这个 CIDR。</p>
</blockquote>
<pre><code class="language-bash">--pod-network-cidr
</code></pre>
<blockquote>
<p>Kubenetes默认Registries地址是 k8s.gcr.io，在国内并不能访问 gcr.io，在1.19.3版本中我们可以增加–image-repository参数，默认值是 k8s.gcr.io，将其指定为阿里云镜像地址：registry.aliyuncs.com/google_containers。</p>
</blockquote>
<pre><code class="language-bash">--image-repository
</code></pre>
<blockquote>
<p>关闭版本探测，因为它的默认值是stable-1，会导致从https://dl.k8s.io/release/stable-1.txt下载最新的版本号，我们可以将其指定为固定版本（最新版：v1.24.1）来跳过网络请求。</p>
</blockquote>
<pre><code class="language-bash">--kubernetes-version=v1.24.1 
</code></pre>
<blockquote>
<p>指定启动时使用cri-docker调用docker</p>
</blockquote>
<pre><code class="language-shell">--cri-socket unix:///var/run/cri-docker.sock 
</code></pre>
<h4 id="4错误启动重置">4.错误启动重置</h4>
<pre><code class="language-shell"># 重置 如果有需要
kubeadm reset --cri-socket unix:///var/run/cri-docker.sock
</code></pre>
<h4 id="5初始化成功后为顺利使用kubectl执行以下命令">5.初始化成功后，为顺利使用kubectl，执行以下命令：</h4>
<pre><code class="language-shell">mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
</code></pre>
<h4 id="6添加其他主节点">6.添加其他主节点</h4>
<h5 id="1复制密钥及相关文件">1.复制密钥及相关文件</h5>
<pre><code class="language-shell">ssh root@192.168.40.21 mkdir -p /etc/kubernetes/pki/etcd
scp /etc/kubernetes/admin.conf root@192.168.40.21:/etc/kubernetes 
scp /etc/kubernetes/pki/{ca.*,sa.*,front-proxy-ca.*}root@192.168.40.21:/etc/kubernetes/pki
scp /etc/kubernetes/pki/etcd/ca.* root@192.168.40.21:/etc/kubernetes/pki/etcd
</code></pre>
<pre><code class="language-shell">ssh root@192.168.40.22 mkdir -p /etc/kubernetes/pki/etcd
scp /etc/kubernetes/admin.conf root@192.168.40.22:/etc/kubernetes 
scp /etc/kubernetes/pki/{ca.*,sa.*,front-proxy-ca.*} root@192.168.40.22:/etc/kubernetes/pki
scp /etc/kubernetes/pki/etcd/ca.* root@192.168.40.22:/etc/kubernetes/pki/etcd
</code></pre>
<h5 id="2添加节点">2.添加节点</h5>
<pre><code class="language-shell">kubeadm join 192.168.40.19:16443 --token pqir66.66fy6pexw3kprt2b --discovery-token-ca-cert-hash sha256:cd4c42e956fdc7e0ad48c990484c22cfd43da63cb3f3887bedc481e7f33a0be1 --control-plane --cri-socket unix:///var/run/cri-docker.sock 
</code></pre>
<h4 id="7执行kubectl-get-nodes查看master节点状态">7.执行kubectl get nodes，查看master节点状态：</h4>
<pre><code class="language-shell">kubectl get node
</code></pre>
<h4 id="8通过如下命令查看kubelet状态">8.通过如下命令查看kubelet状态：</h4>
<pre><code class="language-bash">journalctl -xef -u kubelet -n 20
</code></pre>
<p>提示未安装cni 网络插件。</p>
<h3 id="51安装flannel网络插件cni">5.1安装flannel网络插件(CNI)</h3>
<p>master执行以下命令安装flannel即可：</p>
<pre><code class="language-shell">kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
</code></pre>
<p>kube-flannel.yaml文件中的net-conf.json-&gt;Network地址默认为命令中–pod-network-cidr=值相同</p>
<p><strong>输入命令kubectl get pods -n kube-system,等待所有插件为running状态</strong>。</p>
<p><strong>待所有pod status为Running的时候，再次执行kubectl get nodes：</strong></p>
<pre><code class="language-shell">[root@k8s-master ~]# kubectl get node
NAME         STATUS   ROLES    AGE   VERSION
k8s-master   Ready    master   16m   v1.24.1
</code></pre>
<p><strong>如上所示，master状态变为，表明Master节点部署成功！</strong></p>
<h3 id="52安装calico网络功能更完善">5.2安装calico网络(功能更完善)</h3>
<h4 id="1在master上下载配置calico网络的yaml">1.在master上下载配置calico网络的yaml。</h4>
<pre><code class="language-shell">kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml
</code></pre>
<h4 id="2提前下载所需要的镜像">2.提前下载所需要的镜像。</h4>
<pre><code class="language-shell"># 查看此文件用哪些镜像：
[root@k8s-master ~]# grep image calico.yaml
image: docker.io/calico/cni:v3.23.1
image: docker.io/calico/node:v3.23.1
image: docker.io/calico/kube-controllers:v3.23.1
</code></pre>
<h4 id="3安装calico网络">3.安装calico网络。</h4>
<p>在master上执行如下命令：</p>
<pre><code class="language-shell">kubectl apply -f calico.yaml
</code></pre>
<h4 id="5验证结果">5.验证结果。</h4>
<p>再次在master上运行命令 kubectl get nodes查看运行结果：</p>
<pre><code class="language-shell">[root@k8s-master ~]# kubectl get nodes
NAME       STATUS   ROLES                  AGE   VERSION
master01   Ready    control-plane,master   21h   v1.23.4
worker01   Ready    control-plane,master   16h   v1.23.4
worker02   Ready    control-plane,master   16h   v1.23.4
</code></pre>
<h3 id="6部署k8s-node1-k8s-node2-k8s-node3集群">6.部署k8s-node1、k8s-node2、k8s-node3集群</h3>
<p><strong>1、在k8s-node1、k8s-node2、k8s-node3等三台虚拟机中重复执行上面的步骤，安装好docker、kubelet、kubectl、kubeadm。</strong></p>
<h4 id="1node节点加入集群">1.node节点加入集群</h4>
<p>在上面第初始化master节点成功后，输出了下面的kubeadm join命令：</p>
<pre><code class="language-shell">kubeadm join 192.168.40.131:6443 --token zj0u08.ge77y7uv76flqgdk --discovery-token-ca-cert-hash sha256:7cd23cec6afb192b2d34c5c719b378082a6315a9d91a22d91b83066c870d4db5 --cri-socket unix:///var/run/cri-docker.sock 
</code></pre>
<p>该命令就是node加入集群的命令，分别在k8s-node1、k8s-node2上执行该命令加入集群。</p>
<p>如果忘记该命令，可以通过以下命令重新生成：</p>
<pre><code class="language-shell">kubeadm token create --print-join-command
</code></pre>
<h4 id="2在master节点执行下面命令查看集群状态">2.在master节点执行下面命令查看集群状态：</h4>
<pre><code class="language-shell">kubectl get nodes
</code></pre>
<pre><code class="language-shell">[root@k8s-master ~]# kubectl get node
NAME         STATUS   ROLES    AGE     VERSION
k8s-master   Ready    master   24m     v1.24.1
k8s-master2  Ready    master   24m     v1.24.1
k8s-master3  Ready    master   24m     v1.24.1
k8s-node1    Ready    &lt;none&gt;   5m50s   v1.24.1
k8s-node2    Ready    &lt;none&gt;   5m21s   v1.24.1
k8s-node3    Ready    &lt;none&gt;   5m21s   v1.24.1
</code></pre>
<p>如上所示，所有节点都为ready，集群搭建成功。</p>
<h2 id="卸载集群命令">卸载集群命令</h2>
<pre><code class="language-shell">#建议所有服务器都执行
#!/bin/bash
kubeadm reset -f
modprobe -r ipip
lsmod
rm -rf ~/.kube/
rm -rf /etc/kubernetes/
rm -rf /etc/systemd/system/kubelet.service.d
rm -rf /etc/systemd/system/kubelet.service
rm -rf /usr/bin/kube*
rm -rf /etc/cni
rm -rf /opt/cni
rm -rf /var/lib/etcd
rm -rf /var/etcd
yum -y remove kubeadm* kubectl* kubelet* docker*
reboot
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Helm简介]]></title>
        <id>https://tinaxiawuhao.github.io/post/zIWVYloAQ/</id>
        <link href="https://tinaxiawuhao.github.io/post/zIWVYloAQ/">
        </link>
        <updated>2022-06-08T10:58:52.000Z</updated>
        <content type="html"><![CDATA[<h3 id="一-简介">一、简介</h3>
<p>Helm是Kubernetes的包管理器。包管理器类似于Ubuntu中使用的apt、Python中的pip一样，能快速查找、下载和安装软件包。<br>
<strong>Helm解决的痛点</strong></p>
<ul>
<li>在Kubernetes中部署一个可以使用的应用，需要涉及到很多的Kubernetes资源的共同协作。比如安装一个WordPress，用到了一些Kubernetes的一些资源对象，包括Deployment用于部署应用、Service提供服务发现、Secret配置 WordPress的用户名和密码，可能还需要pv和pvc来提供持久化服务。并且WordPress数据是存储在mariadb里面的，所以需要mariadb启动就绪后才能启动 WordPress。这些k8s资源过于分散，不方便进行管理。</li>
<li>Helm把Kubernetes资源(比如deployments、services或ingress等) 打包到一个chart中，而chart被保存到chart仓库。通过chart仓库可用来存储和分享chart。Helm使发布可配置，支持发布应用配置的版本管理，简化了Kubernetes部署应用的版本控制、打包、发布、删除、更新等操作。</li>
</ul>
<p><strong>Helm相关组件及概念</strong></p>
<ul>
<li><strong>helm</strong>是一个命令行工具，主要用于Kubernetes应用程序Chart的创建、打包、发布以及创建和管理本地和远程的Chart仓库。chart Helm的软件包，采用TAR格式。类似于APT的DEB包或者YUM的RPM包，其包含了一组定义Kubernetes资源相关的 YAML文件。</li>
<li><strong>Repoistory</strong> Helm的软件仓库，Repository本质上是一个Web服务器，该服务器保存了一系列的Chart软件包以供用户下载，并且提供了一个该Repository的Chart包的清单文件以供查询。Helm可以同时管理多个不同的Repository。</li>
<li><strong>release</strong>使用helm install命令在Kubernetes集群中部署的Chart称为Release。可以理解为Helm使用Chart包部署的一个应用实例。</li>
</ul>
<blockquote>
<p>创建release<br>
helm 客户端从指定的目录或本地tar文件或远程repo仓库解析出chart的结构信息<br>
helm 客户端根据 chart 和 values 生成一个 release<br>
helm 将install release请求直接传递给 kube-apiserver</p>
<p>删除release<br>
helm 客户端从指定的目录或本地tar文件或远程repo仓库解析出chart的结构信息<br>
helm 客户端根据 chart 和 values 生成一个 release<br>
helm 将delete release请求直接传递给 kube-apiserver</p>
<p>更新release<br>
helm 客户端从指定的目录或本地tar文件或远程repo仓库解析出chart的结构信息<br>
helm 将收到的信息生成新的 release，并同时更新这个 release 的 history<br>
helm 将新的 release 传递给 kube-apiserver 进行更新</p>
</blockquote>
<ul>
<li>
<p><strong>chart</strong>的基本结构</p>
<pre><code class="language-java">## Helm的打包格式叫做chart，所谓chart就是一系列文件, 它描述了一组相关的 k8s 集群资源。
## Chart中的文件安装特定的目录结构组织, 最简单的chart 目录如下所示：
./
├── charts                            #  目录存放依赖的chart
├── Chart.yaml                        #  包含Chart的基本信息，包括chart版本，名称等
├── templates                         #  目录下存放应用一系列k8s资源的yaml模板
│   ├── deployment.yaml
│   ├── _helpers.tpl                  #  此文件中定义一些可重用的模板片断，此文件中的定义在任何资源定义模板中可用
│   ├── ingress.yaml
│   ├── NOTES.txt                     #  介绍chart部署后的帮助信息，如何使用chart等
│   ├── serviceaccount.yaml
│   ├── service.yaml
│   └── tests
│       └── test-connection.yaml
└── values.yaml                       #  包含了必要的值定义（默认值）, 用于存储templates目录中模板文件中用到变量的值
</code></pre>
</li>
</ul>
<h3 id="二-安装helm">二、安装Helm</h3>
<h4 id="1-安装helm">1 安装Helm</h4>
<pre><code class="language-shell">[root@Ansible01 ~]# wget https://get.helm.sh/helm-v3.8.2-linux-amd64.tar.gz
[root@Ansible01 ~]# tar -zxvf helm-v3.0.0-linux-amd64.tar.gz
[root@Ansible01 ~]# mv linux-amd64/helm /usr/local/bin/helm
[root@Ansible01 ~]# helm version
version.BuildInfo{Version:&quot;v3.8.2&quot;, GitCommit:&quot;6e3701edea09e5d55a8ca2aae03a68917630e91b&quot;, GitTreeState:&quot;clean&quot;, GoVersion:&quot;go1.17.5&quot;}
</code></pre>
<h4 id="2-添加常用repo">2 添加常用repo</h4>
<p><strong>添加存储库</strong></p>
<pre><code class="language-shell">[root@Ansible01 ~]# helm repo add aliyun https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts
&quot;aliyun&quot; has been added to your repositories
</code></pre>
<p><strong>更新存储库</strong></p>
<pre><code class="language-shell">[root@Ansible01 ~]# helm repo update
Hang tight while we grab the latest from your chart repositories...
...Successfully got an update from the &quot;aliyun&quot; chart repository
...Successfully got an update from the &quot;stable&quot; chart repository
...Successfully got an update from the &quot;prometheus-community&quot; chart repository
...Successfully got an update from the &quot;bitnami&quot; chart repository
Update Complete. ⎈Happy Helming!⎈
</code></pre>
<p><strong>查看存储库</strong></p>
<pre><code class="language-shell">[root@Ansible01 ~]# helm repo list
NAME                    URL                                                   
bitnami                 https://charts.bitnami.com/bitnami                    
prometheus-community    https://prometheus-community.github.io/helm-charts    
stable                  http://mirror.azure.cn/kubernetes/charts              
aliyun                  https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts
</code></pre>
<p><strong>删除存储库</strong></p>
<pre><code class="language-shell">[root@Ansible01 ~]# helm repo remove  aliyun
&quot;aliyun&quot; has been removed from your repositories
</code></pre>
<h3 id="三-使用helm">三、使用Helm</h3>
<h4 id="1-使用chart部署一个mysql">1 使用chart部署一个mysql</h4>
<pre><code class="language-shell">#  查找所有repo下的所有chart
helm search repo

#  查找stable这个repo下的chart mysql
helm search repo stable/mysql
 
#  查看chart信息：
helm show chart stable/mysql

 #  安装包：
helm install db stable/mysql**

# 查看发布状态：
helm status db
</code></pre>
<pre><code class="language-shell">[root@Ansible01 ~]# kubectl get pod -n default
NAME                        READY   STATUS    RESTARTS       AGE
db-mysql-599d764c8c-knfqc   0/1     Pending   0              2m10s
</code></pre>
<pre><code class="language-shell">[root@Ansible01 ~]# kubectl describe pod db-mysql-599d764c8c-knfqc -n default
......
Events:
  Type     Reason            Age                  From               Message
  ----     ------            ----                 ----               -------
  Warning  FailedScheduling  17s (x3 over 2m33s)  default-scheduler  0/4 nodes are available: 4 pod has unbound immediate PersistentVolumeClaims.
</code></pre>
<h4 id="2-安装前自定义chart配置选项">2 安装前自定义chart配置选项</h4>
<ul>
<li>上面部署的mysql并没有成功，这是因为并不是所有的chart都能按照默认配置运行成功，可能会需要一些环境依赖，例如PV。</li>
<li>所以需要自定义chart配置选项，安装过程中有两种方法可以传递配置数据：–values（或-f）：指定带有覆盖的YAML文件。这可以多次指定，最右边的文件优先。</li>
<li>–set：在命令行上指定替代。如果两者都用，–set优先级高</li>
</ul>
<p><strong>创建满足的PV</strong></p>
<pre><code class="language-shell">[root@Ansible01 mysql]# cat pv.yaml 
apiVersion: v1
kind: PersistentVolume
metadata:
  name: mysql-pv-volume
  labels:
    type: local
spec:
  storageClassName: &quot;managed-nfs-storage&quot;
  capacity:
    storage: 10Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: &quot;/mnt/data&quot;

[root@Ansible01 hello-world]# kubectl get pv
NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM                                           STORAGECLASS          REASON   AGE
mysql-pv-volume                            10Gi       RWO            Retain           Available                                                   managed-nfs-storage            4s
</code></pre>
<pre><code class="language-shell">[root@Ansible01 hello-world]# helm uninstall db
release &quot;db&quot; uninstalled

[root@Ansible01 hello-world]# cat config.yaml 
persistence:
  enabled: true
  storageClass: &quot;managed-nfs-storage&quot;
  accessMode: ReadWriteOnce
  size: 8Gi
mysqlUser: &quot;k8s&quot;
mysqlPassword: &quot;123456&quot;
mysqlDatabase: &quot;k8s&quot;

[root@Ansible01 hello-world]# helm install db -f config.yaml stable/mysql

[root@Ansible01 hello-world]# kubectl get pv
NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS     CLAIM                                           STORAGECLASS          REASON   AGE
mysql-pv-volume                            10Gi       RWO            Retain           Bound      default/db-mysql                                managed-nfs-storage            17s


[root@Ansible01 hello-world]# kubectl get pod 
NAME                       READY   STATUS    RESTARTS       AGE
db-mysql-f7fbfdd68-tc8cm   1/1     Running   0              11s
</code></pre>
<h4 id="3-构建一个helm-chart">3 构建一个Helm Chart</h4>
<ul>
<li>命令来创建一个名为mychart 的helm chart</li>
</ul>
<pre><code class="language-shell">[root@Ansible01 2022-05-21]# helm create mychart
Creating mychart
[root@Ansible01 2022-05-21]# ls
mychart
</code></pre>
<ul>
<li>创建后会在目录创建一个mychart目录</li>
</ul>
<pre><code class="language-shell">[root@Ansible01 2022-05-21]# tree mychart/
mychart/
├── charts
├── Chart.yaml
├── templates
│   ├── deployment.yaml
│   ├── _helpers.tpl
│   ├── hpa.yaml
│   ├── ingress.yaml
│   ├── NOTES.txt
│   ├── serviceaccount.yaml
│   ├── service.yaml
│   └── tests
│       └── test-connection.yaml
└── values.yaml

3 directories, 10 files
</code></pre>
<ul>
<li>其中mychart目录下的templates目录中保存有部署的模板文件，values.yaml中定义了部署的变量，Chart.yaml文件包含有version（chart版本）和appVersion（包含应用的版本）。</li>
</ul>
<pre><code class="language-shell">[root@Ansible01 2022-05-21]# cat mychart/Chart.yaml  |grep -v &quot;^#&quot; |grep -v ^$
apiVersion: v2
name: mychart
description: A Helm chart for Kubernetes
type: application
version: 0.1.0
appVersion: &quot;1.16.0&quot;
</code></pre>
<ul>
<li>选择镜像及标签和副本数（这里设置1个）</li>
</ul>
<pre><code class="language-shell">[root@Ansible01 2022-05-21]# vi mychart/values.yaml
replicaCount: 1

image:
  repository: myapp
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  tag: &quot;v1&quot;
</code></pre>
<ul>
<li>编辑完成后检查依赖及模板配置是否正确</li>
</ul>
<pre><code class="language-shell">[root@Ansible01 2022-05-21]# cd mychart/
[root@Ansible01 mychart]# helm lint .
==&gt; Linting .
[INFO] Chart.yaml: icon is recommended

1 chart(s) linted, 0 chart(s) failed
</code></pre>
<ul>
<li>打包应用，其中0.1.0为在Chart.yaml文件中定义的version（chart版本）信息</li>
</ul>
<pre><code class="language-shell">[root@Ansible01 2022-05-21]# helm package mychart/
Successfully packaged chart and saved it to: /root/2022-05-21/mychart-0.1.0.tgz
[root@Ansible01 2022-05-21]# ls
mychart  mychart-0.1.0.tgz
</code></pre>
<ul>
<li>升级、回滚和删除</li>
</ul>
<pre><code class="language-shell">#  发布新版本的chart时，或者当您要更改发布的配置时，可以使用该helm upgrade 命令。
helm upgrade --set imageTag=1.17 web mychart
helm upgrade -f values.yaml web mychart
 
#  如果在发布后没有达到预期的效果，则可以使用helm rollback回滚到之前的版本。
例如将应用回滚到第一个版本：
helm rollback web 2

#  卸载发行版，请使用以下helm uninstall命令：
helm uninstall web

#  查看历史版本配置信息
helm get --revision 1 web
</code></pre>
<ul>
<li>下载、上传tar包</li>
</ul>
<pre><code class="language-shell">[root@Ansible01 2022-05-21]# helm pull stable/traefik
[root@Ansible01 2022-05-21]# ls
traefik-1.87.7.tgz
</code></pre>
<pre><code class="language-shell"># 　 一种方式是直接上传charts文件夹，seldon-mab是charts目录，harbor-test-helm是harbor charts repo名称。
helm push seldon-mab harbor-test-helm

#　　另一种是将charts package文件包push
helm push seldon-core-operator-1.5.1.tgz harbor-test-helm
</code></pre>
<ul>
<li>安装到k8s的其它空间：--namespace=monitoring</li>
</ul>
<pre><code class="language-shell">helm install --name prometheus-operator --set rbacEnable=true --namespace=monitoring stable/prometheus-operator
</code></pre>
<h3 id="四-helm使用minio搭建私有仓库">四、Helm使用minio搭建私有仓库</h3>
<p><strong>minio介绍</strong></p>
<p>我们一般是从本地的目录结构中的chart去进行部署，如果要集中管理chart,就需要涉及到repository的问题，因为helmrepository都是指到外面的地址，接下来我们可以通过minio建立一个企业私有的存放仓库。</p>
<p>Minio提供对象存储服务。它的应用场景被设定在了非结构化的数据的存储之上了。众所周知，非结构化对象诸如图像/音频/视频/log文件/系统备份/镜像文件…等等保存起来管理总是不那么方便，size变化很大，类型很多，再有云端的结合会使得情况更加复杂，minio就是解决此种场景的一个解决方案。Minio号称其能很好的适应非结构化的数据，支持AWS的S3，非结构化的文件从数KB到5TB都能很好的支持。</p>
<p>Minio的使用比较简单，只有两个文件，服务端minio,客户访问端mc,比较简单。</p>
<p>在项目中，我们可以直接找一台虚拟机作为Minio Server,提供服务，当然minio也支持作为Pod部署。</p>
<h4 id="1-helm3存储库更改">1 helm3存储库更改</h4>
<p>在Helm 2中，默认情况下包括稳定的图表存储库。在Helm 3中，默认情况下不包含任何存储库。因此需要做的第一件事就是添加一个存储库。官方图表存储库将在有限的时间内继续接收补丁，但是将不再作为默认存储库包含在Helm客户端中。</p>
<h4 id="2-minio介绍">2 minio介绍</h4>
<p>MinIO 是一个基于Apache License  v2.0开源协议的对象存储服务。它兼容亚马逊S3云存储服务接口，非常适合于存储大容量非结构化的数据，例如图片、视频、日志文件、备份数据和容器/虚拟机镜像等，而一个对象文件可以是任意大小，从几kb到最大5T不等。</p>
<p>MinIO是一个非常轻量的服务,可以很简单的和其他应用的结合，类似 NodeJS, Redis 或者 MySQL。</p>
<h4 id="3-安装minio服务端">3 安装minio服务端</h4>
<p><strong>1使用容器安装服务端</strong></p>
<pre><code class="language-shell">docker pull minio/minio
docker run -p 9000:9000 minio/minio server /data
</code></pre>
<p><strong>2使用二进制安装服务端</strong></p>
<pre><code class="language-shell">wget https://dl.min.io/server/minio/release/linux-amd64/minio
chmod +x minio
mkdir -p /chart
./minio server /chart
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1657191641142.png" alt="" loading="lazy"></figure>
<p><strong>访问Browser Access地址：</strong></p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1657191649298.png" alt="" loading="lazy"></figure>
<p><strong>在启动日志中获取access  key和secret  key</strong></p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1657191656837.png" alt="" loading="lazy"></figure>
<p>看到这个页面则表示登陆成功</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1657191664579.png" alt="" loading="lazy"></figure>
<p>至此服务端部署完成。</p>
<h4 id="4-安装minio客户端">4 安装minio客户端</h4>
<p><strong>1.使用容器安装客户端</strong></p>
<pre><code class="language-shell">docker pull minio/mc
docker run minio/mc ls play
</code></pre>
<p><strong>2.使用二进制安装客户端</strong></p>
<pre><code class="language-shell">wget https://dl.min.io/client/mc/release/linux-amd64/mc
chmod +x mc
./mc
</code></pre>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1657191674247.png" alt="" loading="lazy"></figure>
<h4 id="5-连接至服务端">5 连接至服务端</h4>
<pre><code class="language-shell">./mc config host add myminio http://172.17.0.1:9000 XH2LCA4AJIP52RDB4P5M CDDCuoS2FNsdW8S0bodkcs2729N+TH5lFov+rrT3
</code></pre>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1657191689882.png" alt="" loading="lazy"></figure>
<p>服务端启动时候的access  key和secret  key</p>
<h4 id="6-mc的shell使用别名">6 mc的shell使用别名</h4>
<pre><code class="language-shell">ls=mc ls
cp=mc cp
cat=mc cat
mkdir=mc mb
pipe=mc pipe
find=mc find
</code></pre>
<h4 id="7-创建bucket">7 创建bucket</h4>
<pre><code class="language-shell">./mc mb myminio/minio-helm-repo
</code></pre>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1657191697994.png" alt="" loading="lazy"></figure>
<h4 id="8-设置bucket和objects匿名访问">8 设置bucket和objects匿名访问</h4>
<pre><code class="language-shell">./mc policy set download myminio/minio-helm-repo
</code></pre>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1657191704821.png" alt="" loading="lazy"></figure>
<h4 id="9-helm创建与仓库连接的indexyaml文件">9 helm创建与仓库连接的index.yaml文件</h4>
<pre><code class="language-shell">mkdir /root/helm/repo
helm repo index helm/repo/
</code></pre>
<h4 id="10-helm与minio仓库进行连接">10 helm与minio仓库进行连接</h4>
<p><strong>1.将index.yaml文件推送到backet中去</strong></p>
<pre><code class="language-shell">./mc cp helm/repo/index.yaml myminio/minio-helm-repo
</code></pre>
<figure data-type="image" tabindex="9"><img src="https://tinaxiawuhao.github.io/post-images/1657191712580.png" alt="" loading="lazy"></figure>
<p><strong>2.helm连接私仓</strong></p>
<pre><code class="language-shell">helm repo add fengnan http://192.168.0.119:9000/minio-helm-repo
</code></pre>
<figure data-type="image" tabindex="10"><img src="https://tinaxiawuhao.github.io/post-images/1657191720766.png" alt="" loading="lazy"></figure>
<p><strong>3.更新repo仓库</strong></p>
<pre><code class="language-shell">helm repo update
</code></pre>
<figure data-type="image" tabindex="11"><img src="https://tinaxiawuhao.github.io/post-images/1657191729687.png" alt="" loading="lazy"></figure>
<p><strong>4.查看repo</strong></p>
<pre><code class="language-shell">helm repo list
</code></pre>
<figure data-type="image" tabindex="12"><img src="https://tinaxiawuhao.github.io/post-images/1657191738239.png" alt="" loading="lazy"></figure>
<p><strong>5.查看repo中的文件</strong></p>
<pre><code class="language-shell">./mc ls myminio/minio-helm-repo
</code></pre>
<figure data-type="image" tabindex="13"><img src="https://tinaxiawuhao.github.io/post-images/1657191745072.png" alt="" loading="lazy"></figure>
<p><strong>6.登录服务端web界面查看</strong></p>
<figure data-type="image" tabindex="14"><img src="https://tinaxiawuhao.github.io/post-images/1657191757447.png" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[k8s资源操作]]></title>
        <id>https://tinaxiawuhao.github.io/post/HhauOMn26/</id>
        <link href="https://tinaxiawuhao.github.io/post/HhauOMn26/">
        </link>
        <updated>2022-06-04T03:34:10.000Z</updated>
        <content type="html"><![CDATA[<h3 id="1资源类型">1.资源类型</h3>
<table>
<thead>
<tr>
<th>资源分类</th>
<th>类型</th>
<th>具体资源</th>
</tr>
</thead>
<tbody>
<tr>
<td>名称空间级别</td>
<td>工作负载型资源</td>
<td>Pod(pod:k8s 系统中可以创建和管理的最小单元)</td>
</tr>
<tr>
<td>名称空间级别</td>
<td>工作负载型资源</td>
<td>ReplicaSet(rs:用来确保容器应用的副本数始终保持在用户定义的副本数)</td>
</tr>
<tr>
<td>名称空间级别</td>
<td>工作负载型资源</td>
<td>Deployment(deployment:为 Pod 和 ReplicaSet 提供了一个 声明式定义 (declarative) 方法)</td>
</tr>
<tr>
<td>名称空间级别</td>
<td>工作负载型资源</td>
<td>StatefulSet(sts:为了解决有状态服务的问题)</td>
</tr>
<tr>
<td>名称空间级别</td>
<td>工作负载型资源</td>
<td>DaemonSet(ds:)</td>
</tr>
<tr>
<td>名称空间级别</td>
<td>工作负载型资源</td>
<td>Job(jobs:负责批处理任务，即仅执行一次的任务，它保证批处理任务的一个或多个 Pod)</td>
</tr>
<tr>
<td>名称空间级别</td>
<td>工作负载型资源</td>
<td>CronJob(jobs:管理基于时间的 Job)</td>
</tr>
<tr>
<td>名称空间级别</td>
<td>服务发现及负载均衡型资源</td>
<td>Service(svc:为一组功能相同的Pod提供一个供外界访问的地址)</td>
</tr>
<tr>
<td>名称空间级别</td>
<td>服务发现及负载均衡型资源</td>
<td>Ingress(ing:官方只能实现四层代理，INGRESS 可以实现七层代理)</td>
</tr>
<tr>
<td>名称空间级别</td>
<td>配置与存储型资源</td>
<td>Volume(存储卷)</td>
</tr>
<tr>
<td>名称空间级别</td>
<td>配置与存储型资源</td>
<td>CSI(容器存储接口-- 第三方存储卷)</td>
</tr>
<tr>
<td>名称空间级别</td>
<td>特殊类型的存储卷</td>
<td>ConfigMap(当配置中心来使用的资源类型)</td>
</tr>
<tr>
<td>名称空间级别</td>
<td>特殊类型的存储卷</td>
<td>Secret(保存敏感数据)</td>
</tr>
<tr>
<td>名称空间级别</td>
<td>特殊类型的存储卷</td>
<td>DownwardApi(把外部环境中的信息输出给容器)</td>
</tr>
<tr>
<td>集群级资源</td>
<td>集群级资源</td>
<td>Namespace(命名空间)</td>
</tr>
<tr>
<td>集群级资源</td>
<td>集群级资源</td>
<td>Node(集群节点)</td>
</tr>
<tr>
<td>集群级资源</td>
<td>集群级资源</td>
<td>Role(角色)</td>
</tr>
<tr>
<td>集群级资源</td>
<td>集群级资源</td>
<td>ClusterRole(集群角色)</td>
</tr>
<tr>
<td>集群级资源</td>
<td>集群级资源</td>
<td>RoleBinding(角色绑定)</td>
</tr>
<tr>
<td>集群级资源</td>
<td>集群级资源</td>
<td>ClusterRoleBinging(集群角色绑定)</td>
</tr>
<tr>
<td>元数据型资源</td>
<td>元数据型资源</td>
<td>HPA(根据 Pod的 CPU 利用率扩所容)</td>
</tr>
<tr>
<td>元数据型资源</td>
<td>元数据型资源</td>
<td>PodTemplate(pod资源模板)</td>
</tr>
<tr>
<td>元数据型资源</td>
<td>元数据型资源</td>
<td>LimitRange(资源限制)</td>
</tr>
</tbody>
</table>
<h3 id="2操作指令">2.操作指令</h3>
<table>
<thead>
<tr>
<th style="text-align:center">命令名</th>
<th style="text-align:center">类型</th>
<th style="text-align:center">作用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><code>get</code></td>
<td style="text-align:center">查</td>
<td style="text-align:center">列出某个类型的下属资源</td>
</tr>
<tr>
<td style="text-align:center"><code>describe</code></td>
<td style="text-align:center">查</td>
<td style="text-align:center">查看某个资源的详细信息</td>
</tr>
<tr>
<td style="text-align:center"><code>logs</code></td>
<td style="text-align:center">查</td>
<td style="text-align:center">查看某个 pod 的日志</td>
</tr>
<tr>
<td style="text-align:center"><code>create</code></td>
<td style="text-align:center">增</td>
<td style="text-align:center">新建资源</td>
</tr>
<tr>
<td style="text-align:center"><code>explain</code></td>
<td style="text-align:center">查</td>
<td style="text-align:center">查看某个资源的配置项</td>
</tr>
<tr>
<td style="text-align:center"><code>delete</code></td>
<td style="text-align:center">删</td>
<td style="text-align:center">删除某个资源</td>
</tr>
<tr>
<td style="text-align:center"><code>edit</code></td>
<td style="text-align:center">改</td>
<td style="text-align:center">修改某个资源的配置项</td>
</tr>
<tr>
<td style="text-align:center"><code>apply</code></td>
<td style="text-align:center">改</td>
<td style="text-align:center">应用某个资源的配置项</td>
</tr>
</tbody>
</table>
<h3 id="3查看和进入空间">3.查看和进入空间</h3>
<table>
<thead>
<tr>
<th style="text-align:center">命令名</th>
<th style="text-align:center">作用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">kubectl get pod -n名称空间</td>
<td style="text-align:center">查看对应名称空间内的pod</td>
</tr>
<tr>
<td style="text-align:center">kubectl exec -it pod名字 -n名称空间 bash</td>
<td style="text-align:center">进入对应名称空间的pod内</td>
</tr>
<tr>
<td style="text-align:center">kubectl get nodes -o wide</td>
<td style="text-align:center">获取节点和服务版本信息，并查看附加信息</td>
</tr>
<tr>
<td style="text-align:center">kubectl get pod</td>
<td style="text-align:center">获取pod信息，默认是default名称空间</td>
</tr>
<tr>
<td style="text-align:center">kubectl get pod -o wide</td>
<td style="text-align:center">获取pod信息，默认是default名称空间，并查看附加信息</td>
</tr>
<tr>
<td style="text-align:center">kubectl get pod -n kube-system</td>
<td style="text-align:center">获取指定名称空间的pod</td>
</tr>
<tr>
<td style="text-align:center">kubectl get pod -n kube-system podName</td>
<td style="text-align:center">获取指定名称空间中的指定pod</td>
</tr>
<tr>
<td style="text-align:center">kubectl get pod -A</td>
<td style="text-align:center">获取所有名称空间的pod</td>
</tr>
<tr>
<td style="text-align:center">kubectl get pods -o yaml<br />kubectl get pods -o json</td>
<td style="text-align:center">查看pod的详细信息，以yaml格式或json格式显示</td>
</tr>
<tr>
<td style="text-align:center">kubectl get pod -A --show-labels</td>
<td style="text-align:center">查看pod的标签信息</td>
</tr>
<tr>
<td style="text-align:center">kubectl get pod -A --selector=“k8s-app=kube-dns”</td>
<td style="text-align:center">根据Selector（label query）来查询pod</td>
</tr>
<tr>
<td style="text-align:center">kubectl exec podName env</td>
<td style="text-align:center">查看运行pod的环境变量</td>
</tr>
<tr>
<td style="text-align:center">kubectl logs -f --tail 500 -n kube-system kube-apiserver-k8s-master</td>
<td style="text-align:center">查看指定pod的日志</td>
</tr>
<tr>
<td style="text-align:center">kubectl get svc -A</td>
<td style="text-align:center">查看所有名称空间的service信息</td>
</tr>
<tr>
<td style="text-align:center">kubectl get svc -n kube-system</td>
<td style="text-align:center">查看指定名称空间的service信息</td>
</tr>
<tr>
<td style="text-align:center">kubectl get cs</td>
<td style="text-align:center">查看componentstatuses信息</td>
</tr>
<tr>
<td style="text-align:center">kubectl get cm -A</td>
<td style="text-align:center">查看所有configmaps信息</td>
</tr>
<tr>
<td style="text-align:center">kubectl get sa -A</td>
<td style="text-align:center">查看所有serviceaccounts信息</td>
</tr>
<tr>
<td style="text-align:center">kubectl get ds -A</td>
<td style="text-align:center">查看所有daemonsets信息</td>
</tr>
<tr>
<td style="text-align:center">kubectl get deploy -A</td>
<td style="text-align:center">查看所有deployments信息</td>
</tr>
<tr>
<td style="text-align:center">kubectl get rs -A</td>
<td style="text-align:center">查看所有replicasets信息</td>
</tr>
<tr>
<td style="text-align:center">kubectl get sts -A</td>
<td style="text-align:center">查看所有statefulsets信息</td>
</tr>
<tr>
<td style="text-align:center">kubectl get jobs -A</td>
<td style="text-align:center">查看所有jobs信息</td>
</tr>
<tr>
<td style="text-align:center">kubectl get ing -A</td>
<td style="text-align:center">查看所有ingresses信息</td>
</tr>
<tr>
<td style="text-align:center">kubectl get ns</td>
<td style="text-align:center">查看有哪些名称空间</td>
</tr>
<tr>
<td style="text-align:center">kubectl describe pod podName<br/>kubectl describe pod -n kube-system kube-apiserver-k8s-master</td>
<td style="text-align:center">查看pod的描述信息</td>
</tr>
<tr>
<td style="text-align:center">kubectl describe deploy -n kube-system coredns</td>
<td style="text-align:center">查看指定名称空间中指定deploy的描述信息</td>
</tr>
<tr>
<td style="text-align:center">kubectl top node<br/>kubectl top pod</td>
<td style="text-align:center">查看node或pod的资源使用情况<br/>（需要heapster 或metrics-server支持）</td>
</tr>
<tr>
<td style="text-align:center">kubectl cluster-info <br /> kubectl cluster-info dump</td>
<td style="text-align:center">查看集群信息</td>
</tr>
<tr>
<td style="text-align:center">kubectl -s https://172.16.1.110:6443 get componentstatuses</td>
<td style="text-align:center">查看各组件信息【172.16.1.110为master机器】</td>
</tr>
</tbody>
</table>
<h3 id="4进入pod启动的容器">4.进入pod启动的容器</h3>
<table>
<thead>
<tr>
<th style="text-align:center">命令名</th>
<th style="text-align:center">作用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">kubectl exec -it podName -n nsName /bin/sh</td>
<td style="text-align:center">进入容器</td>
</tr>
<tr>
<td style="text-align:center">kubectl exec -it podName -n nsName /bin/bash</td>
<td style="text-align:center">进入容器</td>
</tr>
</tbody>
</table>
<h3 id="5添加label值">5.添加label值</h3>
<table>
<thead>
<tr>
<th style="text-align:center">命令名</th>
<th style="text-align:center">作用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">kubectl label nodes k8s-node01 zone=north</td>
<td style="text-align:center">为指定节点添加标签</td>
</tr>
<tr>
<td style="text-align:center">kubectl label nodes k8s-node01 zone</td>
<td style="text-align:center">为指定节点删除标签</td>
</tr>
<tr>
<td style="text-align:center">kubectl label pod podName -n nsName role-name=test</td>
<td style="text-align:center">为指定pod添加标签</td>
</tr>
<tr>
<td style="text-align:center">kubectl label pod podName -n nsName role-name=dev --overwrite</td>
<td style="text-align:center">修改lable标签值</td>
</tr>
<tr>
<td style="text-align:center">kubectl label pod podName -n nsName role-name</td>
<td style="text-align:center">删除lable标签</td>
</tr>
</tbody>
</table>
<h3 id="6滚动升级">6.滚动升级</h3>
<table>
<thead>
<tr>
<th style="text-align:center">命令名</th>
<th style="text-align:center">作用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">kubectl apply -f myapp-deployment-v2.yaml</td>
<td style="text-align:center">通过配置文件滚动升级</td>
</tr>
<tr>
<td style="text-align:center">kubectl set image deploy/myapp-deployment myapp=“registry.cn-beijing.aliyuncs.com/google_registry/myapp:v3”</td>
<td style="text-align:center">通过命令滚动升级</td>
</tr>
<tr>
<td style="text-align:center">kubectl rollout undo deploy/myapp-deployment <br />kubectl rollout undo deploy myapp-deployment</td>
<td style="text-align:center">pod回滚到前一个版本</td>
</tr>
<tr>
<td style="text-align:center">kubectl rollout undo deploy/myapp-deployment --to-revision=2</td>
<td style="text-align:center">回滚到指定历史版本</td>
</tr>
</tbody>
</table>
<h3 id="7动态伸缩">7.动态伸缩</h3>
<table>
<thead>
<tr>
<th style="text-align:center">命令名</th>
<th style="text-align:center">作用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">kubectl scale deploy myapp-deployment --replicas=5</td>
<td style="text-align:center">动态伸缩</td>
</tr>
<tr>
<td style="text-align:center">kubectl scale --replicas=8 -f myapp-deployment-v2.yaml</td>
<td style="text-align:center">动态伸缩（根据yaml文件）</td>
</tr>
</tbody>
</table>
<h3 id="8操作类命令">8.操作类命令</h3>
<table>
<thead>
<tr>
<th style="text-align:center">命令名</th>
<th style="text-align:center">作用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">kubectl create -f xxx.yaml</td>
<td style="text-align:center">创建资源</td>
</tr>
<tr>
<td style="text-align:center">kubectl apply -f xxx.yaml</td>
<td style="text-align:center">应用资源</td>
</tr>
<tr>
<td style="text-align:center">kubectl apply -f</td>
<td style="text-align:center">应用资源，该目录下的所有 .yaml, .yml, 或 .json 文件都会被使用</td>
</tr>
<tr>
<td style="text-align:center">kubectl create namespace test</td>
<td style="text-align:center">创建test名称空间</td>
</tr>
<tr>
<td style="text-align:center">kubectl delete -f xxx.yaml<br/>kubectl delete -f</td>
<td style="text-align:center">删除资源</td>
</tr>
<tr>
<td style="text-align:center">kubectl delete pod podName</td>
<td style="text-align:center">删除指定的pod</td>
</tr>
<tr>
<td style="text-align:center">kubectl delete pod -n test podName</td>
<td style="text-align:center">删除指定名称空间的指定pod</td>
</tr>
<tr>
<td style="text-align:center">kubectl delete svc svcName<br/>kubectl delete deploy deployName<br/>kubectl delete ns nsName</td>
<td style="text-align:center">删除其他资源</td>
</tr>
<tr>
<td style="text-align:center">kubectl delete pod podName -n nsName --grace-period=0 --force<br/>kubectl delete pod podName -n nsName --grace-period=1<br/>kubectl delete pod podName -n nsName --now</td>
<td style="text-align:center">强制删除</td>
</tr>
<tr>
<td style="text-align:center">kubectl edit pod podName</td>
<td style="text-align:center">编辑资源</td>
</tr>
</tbody>
</table>
<h3 id="9状态">9.状态</h3>
<table>
<thead>
<tr>
<th style="text-align:center">状态名</th>
<th style="text-align:center">含义</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><code>Running</code></td>
<td style="text-align:center">运行中</td>
</tr>
<tr>
<td style="text-align:center"><code>Error</code></td>
<td style="text-align:center">异常，无法提供服务</td>
</tr>
<tr>
<td style="text-align:center"><code>Pending</code></td>
<td style="text-align:center">准备中，暂时无法提供服务</td>
</tr>
<tr>
<td style="text-align:center"><code>Terminaling</code></td>
<td style="text-align:center">结束中，即将被移除</td>
</tr>
<tr>
<td style="text-align:center"><code>Unknown</code></td>
<td style="text-align:center">未知状态，多发生于节点宕机</td>
</tr>
<tr>
<td style="text-align:center"><code>PullImageBackOff</code></td>
<td style="text-align:center">镜像拉取失败</td>
</tr>
</tbody>
</table>
<p>必须存在的属性</p>
<table>
<thead>
<tr>
<th>参数名</th>
<th>字段类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>version</td>
<td>String</td>
<td>K8S API版本, 可以使用kubectl api-version命令查询</td>
</tr>
<tr>
<td>kind</td>
<td>String</td>
<td>指的是yaml文件定义的资源类型和角色, 比如Pod</td>
</tr>
<tr>
<td>metadata</td>
<td>Object</td>
<td>元数据对象, 固定值就写metadata</td>
</tr>
<tr>
<td>metadata.name</td>
<td>String</td>
<td>元数据对象的名字, 比如命名Pod的名字</td>
</tr>
<tr>
<td>metadata.namespace</td>
<td>String</td>
<td>元数据对象的命名空间</td>
</tr>
<tr>
<td>Spec</td>
<td>Object</td>
<td>详细定义对象, 固定值就写Spec</td>
</tr>
<tr>
<td>spec.containers[]</td>
<td>list</td>
<td>Spec对象的容器列表定义, 是个列表</td>
</tr>
<tr>
<td>spec.containers[].name</td>
<td>String</td>
<td>容器的名字</td>
</tr>
<tr>
<td>spec.containers[].image</td>
<td>String</td>
<td>使用到的镜像名称</td>
</tr>
</tbody>
</table>
<p><strong>主要对象</strong></p>
<pre><code class="language-yaml">apiVersion: v1                  #必选，版本号，例如v1，可以用 kubectl api-versions 查询到
kind: Pod                       #必选，指yaml文件定义的k8s 资源类型或角色，比如：Pod
metadata:                       #必选，元数据对象
  name: string                  #必选，元数据对象的名字，自己定义，比如命名Pod的名字
  namespace: string             #必选，元数据对象的名称空间，默认为&quot;default&quot;
  labels:                       #自定义标签
    key1: value1      　        #自定义标签键值对1
    key2: value2      　        #自定义标签键值对2
  annotations:                  #自定义注解
    key1: value1      　        #自定义注解键值对1
    key2: value2      　        #自定义注解键值对2
spec:                           #必选，对象【如pod】的详细定义
  containers:                   #必选，spec对象的容器信息
  - name: string                #必选，容器名称
    image: string               #必选，要用到的镜像名称
    imagePullPolicy: [Always|Never|IfNotPresent]  #获取镜像的策略；(1)Always：意思是每次都尝试重新拉取镜像；(2)Never：表示仅使用本地镜像，即使本地没有镜像也不拉取；(3) IfNotPresent：如果本地有镜像就使用本地镜像，没有就拉取远程镜像。默认：Always
    command: [string]           #指定容器启动命令，由于是数组因此可以指定多个。不指定则使用镜像打包时指定的启动命令。
    args: [string]              #指定容器启动命令参数，由于是数组因此可以指定多个
    workingDir: string          #指定容器的工作目录
    volumeMounts:               #指定容器内部的存储卷配置
    - name: string              #指定可以被容器挂载的存储卷的名称。跟下面volume字段的name值相同表示使用这个存储卷
      mountPath: string         #指定可以被容器挂载的存储卷的路径，应少于512字符
      readOnly: boolean         #设置存储卷路径的读写模式，true或者false，默认为读写模式false
    ports:                      #需要暴露的端口号列表
    - name: string              #端口的名称
      containerPort: int        #容器监听的端口号
      #除非绝对必要，否则不要为 Pod 指定 hostPort。将 Pod 绑定到hostPort时，它会限制 Pod 可以调度的位置数
      #DaemonSet 中的 Pod 可以使用 hostPort，从而可以通过节点 IP 访问到 Pod；因为DaemonSet模式下Pod不会被调度到其他节点。
      #一般情况下 containerPort与hostPort值相同
      hostPort: int     #可以通过宿主机+hostPort的方式访问该Pod。例如：pod在/调度到了k8s-node02【172.16.1.112】，hostPort为8090，那么该Pod可以通过172.16.1.112:8090方式进行访问。
      protocol: string          #端口协议，支持TCP和UDP，默认TCP
    env:                        #容器运行前需设置的环境变量列表
    - name: string              #环境变量名称
      value: string             #环境变量的值
    resources:                  #资源限制和资源请求的设置（设置容器的资源上线）
      limits:                   #容器运行时资源使用的上线
        cpu: string             #CPU限制，单位为core数，允许浮点数，如0.1等价于100m，0.5等价于500m；因此如果小于1那么优先选择如100m的形式，精度为1m。这个数字用作 docker run 命令中的 --cpu-quota 参数。
        memory: string          #内存限制，单位：E,P,T,G,M,K；或者Ei,Pi,Ti,Gi,Mi,Ki；或者字节数。将用于docker run --memory参数
      requests:                 #容器启动和调度时的限制设定
        cpu: string             #CPU请求，容器启动时初始化可用数量，单位为core数，允许浮点数，如0.1等价于100m，0.5等价于500m；因此如果小于1那么优先选择如100m的形式，精度为1m。这个数字用作 docker run 命令中的 --cpu-shares 参数。
        memory: string          #内存请求,容器启动的初始化可用数量。单位：E,P,T,G,M,K；或者Ei,Pi,Ti,Gi,Mi,Ki；或者字节数
    # 参见官网地址：https://kubernetes.io/zh/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
    livenessProbe:      　　    #对Pod内各容器健康检查的设置，当探测无响应几次后将自动重启该容器，检查方法有exec、httpGet和tcpSocket，对一个容器【只需设置其中一种方法即可】
      exec:       　　　　　　  #对Pod内容器健康检查方式设置为exec方式
        command: [string]       #exec方式需要制定的命令或脚本
      httpGet:        　　　　  #对Pod内容器健康检查方法设置为HttpGet，需要制定Path、port
        path: string            #访问 HTTP 服务的路径
        port: number            #访问容器的端口号或者端口名。如果数字必须在 1 ~ 65535 之间。
        host: string            #当没有定义 &quot;host&quot; 时，使用 &quot;PodIP&quot;
        scheme: string          #当没有定义 &quot;scheme&quot; 时，使用 &quot;HTTP&quot;，scheme 只允许 &quot;HTTP&quot; 和 &quot;HTTPS&quot;
        HttpHeaders:            #请求中自定义的 HTTP 头。HTTP 头字段允许重复。
        - name: string
          value: string
      tcpSocket:      　　　　  #对Pod内容器健康检查方式设置为tcpSocket方式
         port: number
      initialDelaySeconds: 5    #容器启动完成后，kubelet在执行第一次探测前应该等待 5 秒。默认是 0 秒，最小值是 0。
      periodSeconds: 60    　　 #指定 kubelet 每隔 60 秒执行一次存活探测。默认是 10 秒。最小值是 1
      timeoutSeconds: 3    　　 #对容器健康检查探测等待响应的超时时间为 3 秒，默认1秒
      successThreshold: 1       #检测到有1次成功则认为服务是`就绪`
      failureThreshold: 5       #检测到有5次失败则认为服务是`未就绪`。默认值是 3，最小值是 1。
    restartPolicy: [Always|Never|OnFailure] #Pod的重启策略，默认Always。Always表示一旦不管以何种方式终止运行，kubelet都将重启；OnFailure表示只有Pod以非0退出码退出才重启；Nerver表示不再重启该Pod
    nodeSelector:           　　#定义Node的label过滤标签，以key：value的格式指定。节点选择，先给主机打标签kubectl label nodes kube-node01 key1=value1 
      key1: value1
    imagePullSecrets:     　　  #Pull镜像时使用的secret名称，以name：secretKeyName格式指定
    - name: string
    hostNetwork: false      　　#是否使用主机网络模式，默认为false。如果设置为true，表示使用宿主机网络，不使用docker网桥
  # volumes 和 containers 是同层级 ******************************
  # 参见官网地址：https://kubernetes.io/zh/docs/concepts/storage/volumes/
  volumes:        　　　　　　#定义了paues容器关联的宿主机或分布式文件系统存储卷列表 （volumes类型有很多种，选其中一种即可）
  - name: string     　　 　　#共享存储卷名称。
    emptyDir: {}      　　    #类型为emtyDir的存储卷，与Pod同生命周期的一个临时目录。当Pod因为某些原因被从节点上删除时，emptyDir卷中的数据也会永久删除。
    hostPath: string      　　#类型为hostPath的存储卷，表示挂载Pod所在宿主机的文件或目录
      path: string      　　  #在宿主机上文件或目录的路径
      type: [|DirectoryOrCreate|Directory|FileOrCreate|File] #空字符串（默认）用于向后兼容，这意味着在安装 hostPath 卷之前不会执行任何检查。DirectoryOrCreate：如果给定目录不存在则创建，权限设置为 0755，具有与 Kubelet 相同的组和所有权。Directory：给定目录必须存在。FileOrCreate：如果给定文件不存在，则创建空文件，权限设置为 0644，具有与 Kubelet 相同的组和所有权。File：给定文件必须存在。
    secret:       　　　　　  #类型为secret的存储卷，挂载集群预定义的secre对象到容器内部。Secret 是一种包含少量敏感信息例如密码、token 或 key 的对象。放在一个 secret 对象中可以更好地控制它的用途，并降低意外暴露的风险。
      secretName: string      #secret 对象的名字
      items:                  #可选，修改key 的目标路径
      - key: username         #username secret存储在/etc/foo/my-group/my-username 文件中而不是 /etc/foo/username 中。【此时存在spec.containers[].volumeMounts[].mountPath为/etc/foo】
        path: my-group/my-username
    configMap:      　　　　  #类型为configMap的存储卷，挂载预定义的configMap对象到容器内部。ConfigMap 允许您将配置文件与镜像文件分离，以使容器化的应用程序具有可移植性。
      name: string             #提供你想要挂载的 ConfigMap 的名字
</code></pre>
<blockquote>
<p>kubectl explain pod命令可以查看资源的模板</p>
<p>kubectl explain pod.apiVersion 查看详细字段</p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[k8s-ingress安装使用]]></title>
        <id>https://tinaxiawuhao.github.io/post/TX9ZIPxbq/</id>
        <link href="https://tinaxiawuhao.github.io/post/TX9ZIPxbq/">
        </link>
        <updated>2022-06-03T02:00:45.000Z</updated>
        <content type="html"><![CDATA[<h2 id="1nginx-ingress安装">1.Nginx ingress安装</h2>
<p>首先需要安装Nginx Ingress Controller控制器，控制器安装方式包含两种：DaemonSets和Deployments。</p>
<ul>
<li>DaemonSets通过hostPort的方式暴露80和443端口，可通过Node的调度由专门的节点实现部署</li>
<li>Deployments则通过NodePort的方式实现控制器端口的暴露，借助外部负载均衡实现高可用负载均衡</li>
</ul>
<p>除此之外，还需要部署Namespace，ServiceAccount，RBAC，Secrets，Custom Resource Definitions等资源，如下开始部署。</p>
<h3 id="11-基础依赖环境准备">1.1 基础依赖环境准备</h3>
<p><strong>1、github中下载源码包,安装部署文件在kubernetes-ingress/deployments/目录下</strong></p>
<pre><code class="language-shell">git clone https://github.com/nginxinc/kubernetes-ingress.git
</code></pre>
<pre><code class="language-js">kubernetes-ingress/deployments/
├── common
│   ├── custom-resource-definitions.yaml  自定义资源
│   ├── default-server-secret.yaml        Secrets
│   ├── nginx-config.yaml
│   └── ns-and-sa.yaml                    Namspace+ServiceAccount
├── daemon-set
│   ├── nginx-ingress.yaml                DaemonSets控制器
│   └── nginx-plus-ingress.yaml
├── deployment
│   ├── nginx-ingress.yaml                Deployments控制器
│   └── nginx-plus-ingress.yaml
├── helm-chart                            Helm安装包
│   ├── chart-icon.png
│   ├── Chart.yaml
│   ├── README.md
│   ├── templates
│   │   ├── controller-configmap.yaml
│   │   ├── controller-custom-resources.yaml
│   │   ├── controller-daemonset.yaml
│   │   ├── controller-deployment.yaml
│   │   ├── controller-leader-election-configmap.yaml
│   │   ├── controller-secret.yaml
│   │   ├── controller-serviceaccount.yaml
│   │   ├── controller-service.yaml
│   │   ├── controller-wildcard-secret.yaml
│   │   ├── _helpers.tpl
│   │   ├── NOTES.txt
│   │   └── rbac.yaml
│   ├── values-icp.yaml
│   ├── values-plus.yaml
│   └── values.yaml
├── rbac                                RBAC认证授权
│   └── rbac.yaml
├── README.md
└── service                            Service定义
    ├── loadbalancer-aws-elb.yaml
    ├── loadbalancer.yaml              DaemonSets暴露服务方式
    └── nodeport.yaml                  Deployments暴露服务方式
</code></pre>
<p>**2、创建Namespace和ServiceAccount **</p>
<pre><code class="language-yaml">cat common/ns-and-sa.yaml

apiVersion: v1
kind: Namespace
metadata:
  name: nginx-ingress 
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: nginx-ingress 
  namespace: nginx-ingress
</code></pre>
<pre><code class="language-shell">kubectl apply -f common/ns-and-sa.yaml
</code></pre>
<p><strong>3、创建Secrets自签名证书</strong></p>
<pre><code>kubectl apply -f common/default-server-secret.yaml
</code></pre>
<pre><code class="language-yaml">apiVersion: v1
kind: Secret
metadata:
  name: default-server-secret
  namespace: nginx-ingress
type: Opaque
data:
  tls.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN2akNDQWFZQ0NRREFPRjl0THNhWFhEQU5CZ2txaGtpRzl3MEJBUXNGQURBaE1SOHdIUVlEVlFRRERCWk8KUjBsT1dFbHVaM0psYzNORGIyNTBjbTlzYkdWeU1CNFhEVEU0TURreE1qRTRNRE16TlZvWERUSXpNRGt4TVRFNApNRE16TlZvd0lURWZNQjBHQTFVRUF3d1dUa2RKVGxoSmJtZHlaWE56UTI5dWRISnZiR3hsY2pDQ0FTSXdEUVlKCktvWklodmNOQVFFQkJRQURnZ0VQQURDQ0FRb0NnZ0VCQUwvN2hIUEtFWGRMdjNyaUM3QlBrMTNpWkt5eTlyQ08KR2xZUXYyK2EzUDF0azIrS3YwVGF5aGRCbDRrcnNUcTZzZm8vWUk1Y2Vhbkw4WGM3U1pyQkVRYm9EN2REbWs1Qgo4eDZLS2xHWU5IWlg0Rm5UZ0VPaStlM2ptTFFxRlBSY1kzVnNPazFFeUZBL0JnWlJVbkNHZUtGeERSN0tQdGhyCmtqSXVuektURXUyaDU4Tlp0S21ScUJHdDEwcTNRYzhZT3ExM2FnbmovUWRjc0ZYYTJnMjB1K1lYZDdoZ3krZksKWk4vVUkxQUQ0YzZyM1lma1ZWUmVHd1lxQVp1WXN2V0RKbW1GNWRwdEMzN011cDBPRUxVTExSakZJOTZXNXIwSAo1TmdPc25NWFJNV1hYVlpiNWRxT3R0SmRtS3FhZ25TZ1JQQVpQN2MwQjFQU2FqYzZjNGZRVXpNQ0F3RUFBVEFOCkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQWpLb2tRdGRPcEsrTzhibWVPc3lySmdJSXJycVFVY2ZOUitjb0hZVUoKdGhrYnhITFMzR3VBTWI5dm15VExPY2xxeC9aYzJPblEwMEJCLzlTb0swcitFZ1U2UlVrRWtWcitTTFA3NTdUWgozZWI4dmdPdEduMS9ienM3bzNBaS9kclkrcUI5Q2k1S3lPc3FHTG1US2xFaUtOYkcyR1ZyTWxjS0ZYQU80YTY3Cklnc1hzYktNbTQwV1U3cG9mcGltU1ZmaXFSdkV5YmN3N0NYODF6cFErUyt1eHRYK2VBZ3V0NHh3VlI5d2IyVXYKelhuZk9HbWhWNThDd1dIQnNKa0kxNXhaa2VUWXdSN0diaEFMSkZUUkk3dkhvQXprTWIzbjAxQjQyWjNrN3RXNQpJUDFmTlpIOFUvOWxiUHNoT21FRFZkdjF5ZytVRVJxbStGSis2R0oxeFJGcGZnPT0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
  tls.key: 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
</code></pre>
<p><strong>4、创建ConfigMap自定义配置文</strong></p>
<pre><code class="language-shell">kubectl apply -f common/nginx-config.yaml 
</code></pre>
<pre><code class="language-yaml">kind: ConfigMap
apiVersion: v1
metadata:
  name: nginx-config
  namespace: nginx-ingress
data:
</code></pre>
<p><strong>5、为主机和主机路由定义自定义资源，支持自定义主机和路由</strong></p>
<pre><code class="language-shell">kubectl apply -f common/custom-resource-definitions.yaml
</code></pre>
<pre><code class="language-yaml">apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: virtualservers.k8s.nginx.org
spec:
  group: k8s.nginx.org
  versions:
  - name: v1
    served: true
    storage: true
  scope: Namespaced
  names:
    plural: virtualservers
    singular: virtualserver
    kind: VirtualServer
    shortNames:
    - vs
---
apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: virtualserverroutes.k8s.nginx.org
spec:
  group: k8s.nginx.org
  versions:
  - name: v1
    served: true
    storage: true
  scope: Namespaced
  names:
    plural: virtualserverroutes
    singular: virtualserverroute
    kind: VirtualServerRoute
    shortNames:
    - vsr
</code></pre>
<p><strong>6、配置RBAC认证授权，实现ingress控制器访问集群中的其他资源</strong></p>
<pre><code class="language-shell">kubectl apply -f rbac/rbac.yaml
</code></pre>
<pre><code class="language-yaml">kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: nginx-ingress
rules:
- apiGroups:
  - &quot;&quot;
  resources:
  - services
  - endpoints
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - &quot;&quot;
  resources:
  - secrets
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - &quot;&quot;
  resources:
  - configmaps
  verbs:
  - get
  - list
  - watch
  - update
  - create
- apiGroups:
  - &quot;&quot;
  resources:
  - pods
  verbs:
  - list
  - watch
- apiGroups:
  - &quot;&quot;
  resources:
  - events
  verbs:
  - create
  - patch
- apiGroups:
  - extensions
  resources:
  - ingresses
  verbs:
  - list
  - watch
  - get
- apiGroups:
  - &quot;extensions&quot;
  resources:
  - ingresses/status
  verbs:
  - update
- apiGroups:
  - k8s.nginx.org
  resources:
  - virtualservers
  - virtualserverroutes
  verbs:
  - list
  - watch
  - get
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: nginx-ingress
subjects:
- kind: ServiceAccount
  name: nginx-ingress
  namespace: nginx-ingress
roleRef:
  kind: ClusterRole
  name: nginx-ingress
  apiGroup: rbac.authorization.k8s.io
</code></pre>
<h3 id="12-部署ingress控制器">1.2 部署Ingress控制器</h3>
<p><strong>1、 部署控制器，控制器可以DaemonSets和Deployment的形式部署，如下是DaemonSets的配置文件</strong></p>
<pre><code class="language-js">apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: nginx-ingress
  namespace: nginx-ingress
spec:
  selector:
    matchLabels:
      app: nginx-ingress
  template:
    metadata:
      labels:
        app: nginx-ingress
     #annotations:
       #prometheus.io/scrape: &quot;true&quot;
       #prometheus.io/port: &quot;9113&quot;
    spec:
      serviceAccountName: nginx-ingress
      containers:
      - image: nginx/nginx-ingress:edge
        imagePullPolicy: Always
        name: nginx-ingress
        ports:
        - name: http
          containerPort: 80
          hostPort: 80            #通过hostPort的方式暴露端口
        - name: https
          containerPort: 443
          hostPort: 443
       #- name: prometheus
         #containerPort: 9113
        securityContext:
          allowPrivilegeEscalation: true
          runAsUser: 101 #nginx
          capabilities:
            drop:
            - ALL
            add:
            - NET_BIND_SERVICE
        env:
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        args:
          - -nginx-configmaps=$(POD_NAMESPACE)/nginx-config
          - -default-server-tls-secret=$(POD_NAMESPACE)/default-server-secret
         #- -v=3 # Enables extensive logging. Useful for troubleshooting.
         #- -report-ingress-status
         #- -external-service=nginx-ingress
         #- -enable-leader-election
         #- -enable-prometheus-metrics
</code></pre>
<p><strong>Deployments的配置文件</strong></p>
<pre><code class="language-js">apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-ingress
  namespace: nginx-ingress
spec:
  replicas: 1                  #副本的个数
  selector:
    matchLabels:
      app: nginx-ingress
  template:
    metadata:
      labels:
        app: nginx-ingress
     #annotations:
       #prometheus.io/scrape: &quot;true&quot;
       #prometheus.io/port: &quot;9113&quot;
    spec:
      serviceAccountName: nginx-ingress
      containers:
      - image: nginx/nginx-ingress:edge
        imagePullPolicy: Always
        name: nginx-ingress
        ports:                #内部暴露的服务端口，需要通过NodePort的方式暴露给外部
        - name: http
          containerPort: 80
        - name: https
          containerPort: 443
       #- name: prometheus
         #containerPort: 9113
        securityContext:
          allowPrivilegeEscalation: true
          runAsUser: 101 #nginx
          capabilities:
            drop:
            - ALL
            add:
            - NET_BIND_SERVICE
        env:
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        args:
          - -nginx-configmaps=$(POD_NAMESPACE)/nginx-config
          - -default-server-tls-secret=$(POD_NAMESPACE)/default-server-secret
         #- -v=3 # Enables extensive logging. Useful for troubleshooting.
         #- -report-ingress-status
         #- -external-service=nginx-ingress
         #- -enable-leader-election
         #- -enable-prometheus-metrics
</code></pre>
<p><strong>2、我们以DaemonSets的方式部署，DaemonSet部署集群中各个节点都是对等，如果有外部LoadBalancer则通过外部负载均衡路由至Ingress中</strong></p>
<pre><code class="language-shell">[root@node-1 deployments]# kubectl apply -f daemon-set/nginx-ingress.yaml 
daemonset.apps/nginx-ingress created
[root@node-1 deployments]# kubectl get daemonsets -n nginx-ingress
NAME            DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE
nginx-ingress   3         3         3       3            3           &lt;none&gt;          15s

[root@node-1 ~]# kubectl get pods -n nginx-ingress -o wide 
NAME                  READY   STATUS    RESTARTS   AGE     IP             NODE     NOMINATED NODE   READINESS GATES
nginx-ingress-7mpfc   1/1     Running   0          2m44s   10.244.0.50    node-1   &lt;none&gt;           &lt;none&gt;
nginx-ingress-l2rtj   1/1     Running   0          2m44s   10.244.1.144   node-2   &lt;none&gt;           &lt;none&gt;
nginx-ingress-tgf6r   1/1     Running   0          2m44s   10.244.2.160   node-3   &lt;none&gt;           &lt;none&gt;
</code></pre>
<p><strong>3、校验Nginx Ingress安装情况</strong></p>
<p>此时三个节点均是对等，即访问任意一个节点均能实现相同的效果，统一入口则通过外部负载均衡，如果在云环境下执行<code>kubectl apply -f service/loadbalancer.yaml</code>创建外部负载均衡实现入口调度，自建的可以通过lvs或nginx等负载均衡实现接入。</p>
<figure data-type="image" tabindex="1"><img src="https://ask.qcloudimg.com/draft/4405893/88fb7v82cj.png?imageView2/2/w/1620" alt="img" loading="lazy"></figure>
<p><strong>备注说明</strong>：如果以Deployments的方式部署，则需要执行service/nodeport.yaml创建NodePort类型的Service，实现的效果和DaemonSets类似。</p>
<h2 id="2-ingress资源定义">2. Ingress资源定义</h2>
<p>上面的已安装了一个Nginx Ingress Controller控制器，有了Ingress控制器后，我们就可以定义Ingress资源来实现七层负载转发了，大体上Ingress支持三种使用方式：1. 基于虚拟主机转发，2. 基于虚拟机主机URI转发，3. 支持TLS加密转发。</p>
<h3 id="21-ingress定义">2.1 Ingress定义</h3>
<p><strong>1、环境准备，先创建一个nginx的Deployment应用，包含2个副本</strong></p>
<pre><code class="language-shell">[root@node-1 ~]# kubectl run ingress-demo --image=nginx:1.7.9 --port=80 --replicas=2
[root@node-1 ~]# kubectl get deployments
NAME           READY   UP-TO-DATE   AVAILABLE   AGE
ingress-demo   2/2     2            2           116s
</code></pre>
<p><strong>2、以service方式暴露服务端口</strong></p>
<pre><code class="language-shell">[root@node-1 ~]# kubectl expose deployment ingress-demo --port=80 --protocol=TCP --target-port=80
service/ingress-demo exposed
[root@node-1 ~]# kubectl get services 
NAME           TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE
ingress-demo   ClusterIP   10.109.33.91   &lt;none&gt;        80/TCP    2m15s
</code></pre>
<p><strong>3、上述两个步骤已创建了一个service，如下我们定义一个ingress对象将流量转发至ingress-demo这个service，通过ingress.class指定控制器的类型为nginx</strong></p>
<pre><code class="language-yaml">[root@node-1 nginx-ingress]# cat nginx-ingress-demo.yaml 
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: nginx-ingress-demo
  labels:
    ingres-controller: nginx
  annotations:
    kubernets.io/ingress.class: nginx
spec:
  rules:
  - host: www.test.cn
    http:
      paths:
      - path: /
        backend:
          serviceName: ingress-demo
          servicePort: 80
</code></pre>
<p><strong>4、创建ingress对象</strong></p>
<pre><code class="language-shell">[root@node-1 nginx-ingress]# kubectl apply -f nginx-ingress-demo.yaml 
ingress.extensions/nginx-ingress-demo created

查看ingress资源列表
[root@node-1 nginx-ingress]# kubectl get ingresses
NAME                 HOSTS                ADDRESS   PORTS   AGE
nginx-ingress-demo   www.test.cn             80      4m4s
</code></pre>
<p><strong>5、查看ingress详情，可以在Rules规则中看到后端Pod的列表，自动发现和关联相关Pod</strong></p>
<pre><code class="language-shell">[root@node-1 ~]# kubectl describe ingresses nginx-ingress-demo 
Name:             nginx-ingress-demo
Namespace:        default
Address:          
Default backend:  default-http-backend:80 (&lt;none&gt;)
Rules:
  Host                Path  Backends
  ----                ----  --------
  www.test.cn  
                      /   ingress-demo:80 (10.244.1.146:80,10.244.2.162:80)
Annotations:
  kubectl.kubernetes.io/last-applied-configuration:  {&quot;apiVersion&quot;:&quot;extensions/v1beta1&quot;,&quot;kind&quot;:&quot;Ingress&quot;,&quot;metadata&quot;:{&quot;annotations&quot;:{&quot;kubernets.io/ingress.class&quot;:&quot;nginx&quot;},&quot;labels&quot;:{&quot;ingres-controller&quot;:&quot;nginx&quot;},&quot;name&quot;:&quot;nginx-ingress-demo&quot;,&quot;namespace&quot;:&quot;default&quot;},&quot;spec&quot;:{&quot;rules&quot;:[{&quot;host&quot;:&quot;www.happylaulab.cn&quot;,&quot;http&quot;:{&quot;paths&quot;:[{&quot;backend&quot;:{&quot;serviceName&quot;:&quot;ingress-demo&quot;,&quot;servicePort&quot;:80},&quot;path&quot;:&quot;/&quot;}]}}]}}

  kubernets.io/ingress.class:  nginx
Events:
  Type    Reason          Age   From                      Message
  ----    ------          ----  ----                      -------
  Normal  AddedOrUpdated  9m7s  nginx-ingress-controller  Configuration for default/nginx-ingress-demo was added or updated
  Normal  AddedOrUpdated  9m7s  nginx-ingress-controller  Configuration for default/nginx-ingress-demo was added or updated
  Normal  AddedOrUpdated  9m7s  nginx-ingress-controller  Configuration for default/nginx-ingress-demo was added or updated
</code></pre>
<p><strong>6、测试验证</strong></p>
<p>ingress规则的配置信息已注入到Ingress Controller中，环境中Ingress Controller是以DaemonSets的方式部署在集群中，如果有外部的负载均衡，则将www.test.cn域名的地址解析为负载均衡VIP。由于测试环境没有搭建负载均衡，将hosts解析执行node-1，node-2或者node-3任意一个IP都能实现相同的功能。</p>
<figure data-type="image" tabindex="2"><img src="https://ask.qcloudimg.com/draft/4405893/47noa95oaa.png?imageView2/2/w/1620" alt="img" loading="lazy"></figure>
<p>上述测试解析正常，当然也可以解析为node-1和node-2的IP，如下：</p>
<pre><code class="language-shell">[root@node-1 ~]# curl -I http://www.happylau.cn --resolve www.happylau.cn:80:10.254.100.101
HTTP/1.1 200 OK
Server: nginx/1.17.6
Date: Tue, 24 Dec 2019 10:32:22 GMT
Content-Type: text/html
Content-Length: 612
Connection: keep-alive
Last-Modified: Tue, 23 Dec 2014 16:25:09 GMT
ETag: &quot;54999765-264&quot;
Accept-Ranges: bytes

[root@node-1 ~]# curl -I http://www.happylau.cn --resolve www.happylau.cn:80:10.254.100.102
HTTP/1.1 200 OK
Server: nginx/1.17.6
Date: Tue, 24 Dec 2019 10:32:24 GMT
Content-Type: text/html
Content-Length: 612
Connection: keep-alive
Last-Modified: Tue, 23 Dec 2014 16:25:09 GMT
ETag: &quot;54999765-264&quot;
Accept-Ranges: bytes
</code></pre>
<h2 id="3-ingress动态配置">3 Ingress动态配置</h2>
<p>上面介绍了ingress资源对象的申明配置，这里我们探究一下Nginx Ingress Controller的实现机制和动态配置更新机制，以方便了解Ingress控制器的工作机制。</p>
<p><strong>1、 查看Nginx Controller控制器的配置文件，在nginx-ingress pod中存储着ingress的配置文件</strong></p>
<pre><code class="language-shell">[root@node-1 ~]# kubectl get pods -n nginx-ingress 
NAME                  READY   STATUS    RESTARTS   AGE
nginx-ingress-7mpfc   1/1     Running   0          6h15m
nginx-ingress-l2rtj   1/1     Running   0          6h15m
nginx-ingress-tgf6r   1/1     Running   0          6h15m

#查看配置文件，每个ingress生成一个配置文件，文件名为：命名空间-ingres名称.conf
[root@node-1 ~]# kubectl exec -it nginx-ingress-7mpfc -n nginx-ingress -- ls -l /etc/nginx/conf.d
total 4
-rw-r--r-- 1 nginx nginx 1005 Dec 24 10:06 default-nginx-ingress-demo.conf

#查看配置文件
[root@node-1 ~]# kubectl exec -it nginx-ingress-7mpfc -n nginx-ingress -- cat /etc/nginx/conf.d/default-nginx-ingress-demo.conf
# configuration for default/nginx-ingress-demo

#upstream的配置，会用least_conn算法，通过service服务发现机制动态识别到后端的Pod
upstream default-nginx-ingress-demo-www.test.cn-ingress-demo-80 {
	zone default-nginx-ingress-demo-www.test.cn-ingress-demo-80 256k;
	random two least_conn;
	server 10.244.1.146:80 max_fails=1 fail_timeout=10s max_conns=0;
	server 10.244.2.162:80 max_fails=1 fail_timeout=10s max_conns=0;
}

server {
	listen 80;
	server_tokens on;
	server_name www.test.cn;
	location / {
		proxy_http_version 1.1;
		proxy_connect_timeout 60s;
		proxy_read_timeout 60s;
		proxy_send_timeout 60s;
		client_max_body_size 1m;
		proxy_set_header Host $host;
		proxy_set_header X-Real-IP $remote_addr;
		proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
		proxy_set_header X-Forwarded-Host $host;
		proxy_set_header X-Forwarded-Port $server_port;
		proxy_set_header X-Forwarded-Proto $scheme;
		proxy_buffering on;
		proxy_pass http://default-nginx-ingress-demo-www.test.cn-ingress-demo-80;	#调用upstream实现代理
	}
}
</code></pre>
<p>通过上述查看配置文件可得知，Nginx Ingress Controller实际是根据ingress规则生成对应的nginx配置文件，以实现代理转发的功能，加入Deployments的副本数变更后nginx的配置文件会发生什么改变呢？</p>
<p><strong>2、更新控制器的副本数，由2个Pod副本扩容至3个</strong></p>
<pre><code class="language-js">[root@node-1 ~]# kubectl scale --replicas=3 deployment ingress-demo 
deployment.extensions/ingress-demo scaled
[root@node-1 ~]# kubectl get deployments
NAME           READY   UP-TO-DATE   AVAILABLE   AGE
ingress-demo   3/3     3            3           123m
</code></pre>
<p><strong>3、再次查看nginx的配置文件，ingress借助于service的服务发现机制，将加入的Pod自动加入到nginx upstream中</strong></p>
<figure data-type="image" tabindex="3"><img src="https://ask.qcloudimg.com/draft/4405893/14725qbjdh.png?imageView2/2/w/1620" alt="img" loading="lazy"></figure>
<p><strong>4、查看nginx pod的日志（kubectl logs nginx-ingress-7mpfc -n nginx-ingress），有reload优雅重启的记录，即通过更新配置文件+reload实现配置动态更新。</strong></p>
<figure data-type="image" tabindex="4"><img src="https://ask.qcloudimg.com/draft/4405893/lilxwe1u13.png?imageView2/2/w/1620" alt="img" loading="lazy"></figure>
<p>通过上述的配置可知，ingress调用kubernetes api去感知kubernetes集群中的变化情况，Pod的增加或减少这些变化，然后动态更新nginx ingress controller的配置文件，并重新载入配置。当集群规模越大时，会频繁涉及到配置文件的变动和重载，因此nginx这方面会存在先天的劣势，专门为微服务负载均衡应运而生，如Traefik，Envoy，Istio，这些负载均衡工具能够提供大规模，频繁动态更新的场景，但性能相比Nginx，HAproxy还存在一定的劣势。</p>
<h2 id="4-ingress路径转发">4 Ingress路径转发</h2>
<p>Ingress支持URI格式的转发方式，同时支持URL重写，如下以两个service为例演示，service-1安装nginx，service-2安装httpd，分别用http://demo.happylau.cn/news和http://demo.happylau.cn/sports转发到两个不同的service</p>
<p><strong>1、环境准备，创建两个应用并实现service暴露，创建deployments时指定--explose创建service</strong></p>
<pre><code class="language-js">[root@node-1 ~]# kubectl run service-1 --image=nginx:1.7.9 --port=80 --replicas=1 --expose=true 
service/service-1 created
deployment.apps/service-1 created

[root@node-1 ~]# kubectl run service-2 --image=httpd --port=80 --replicas=1 --expose=true 
service/service-2 created
deployment.apps/service-2 created

查看deployment状态
[root@node-1 ~]# kubectl get deployments 
NAME           READY   UP-TO-DATE   AVAILABLE   AGE
ingress-demo   4/4     4            4           4h36m
service-1      1/1     1            1           65s
service-2      1/1     1            1           52s

查看service状态，服务已经正常
[root@node-1 ~]# kubectl get services 
NAME           TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE
ingress-demo   ClusterIP   10.109.33.91     &lt;none&gt;        80/TCP    4h36m
kubernetes     ClusterIP   10.96.0.1        &lt;none&gt;        443/TCP   101d
service-1      ClusterIP   10.106.245.71    &lt;none&gt;        80/TCP    68s
service-2      ClusterIP   10.104.204.158   &lt;none&gt;        80/TCP    55s
</code></pre>
<p><strong>2、创建ingress对象，通过一个域名将请求转发至后端两个service</strong></p>
<pre><code class="language-js">[root@node-1 nginx-ingress]# cat nginx-ingress-uri-demo.yaml 
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: nginx-ingress-uri-demo
  labels:
    ingres-controller: nginx
  annotations:
    kubernets.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
  - host: 
    http:
      paths:
      - path: /news
        backend:
          serviceName: service-1 
          servicePort: 80
      - path: /sports
        backend:
          serviceName: service-2
          servicePort: 80
</code></pre>
<p><strong>3、创建ingress规则，查看详情</strong></p>
<pre><code class="language-js">[root@node-1 nginx-ingress]# kubectl apply -f nginx-ingress-uri-demo.yaml 
ingress.extensions/nginx-ingress-uri-demo created

#查看详情
[root@node-1 nginx-ingress]# kubectl get ingresses.
NAME                     HOSTS              ADDRESS   PORTS   AGE
nginx-ingress-demo       www.happylau.cn              80      4h35m
nginx-ingress-uri-demo   demo.happylau.cn             80      4s
[root@node-1 nginx-ingress]# kubectl describe ingresses nginx-ingress-uri-demo 
Name:             nginx-ingress-uri-demo
Namespace:        default
Address:          
Default backend:  default-http-backend:80 (&lt;none&gt;)
Rules:              #对应的转发url规则
  Host              Path  Backends
  ----              ----  --------
  demo.happylau.cn  
                    /news     service-1:80 (10.244.2.163:80)
                    /sports   service-2:80 (10.244.1.148:80)
Annotations:
  kubectl.kubernetes.io/last-applied-configuration:  {&quot;apiVersion&quot;:&quot;extensions/v1beta1&quot;,&quot;kind&quot;:&quot;Ingress&quot;,&quot;metadata&quot;:{&quot;annotations&quot;:{&quot;kubernets.io/ingress.class&quot;:&quot;nginx&quot;,&quot;nginx.ingress.kubernetes.io/rewrite-target&quot;:&quot;/&quot;},&quot;labels&quot;:{&quot;ingres-controller&quot;:&quot;nginx&quot;},&quot;name&quot;:&quot;nginx-ingress-uri-demo&quot;,&quot;namespace&quot;:&quot;default&quot;},&quot;spec&quot;:{&quot;rules&quot;:[{&quot;host&quot;:&quot;demo.happylau.cn&quot;,&quot;http&quot;:{&quot;paths&quot;:[{&quot;backend&quot;:{&quot;serviceName&quot;:&quot;service-1&quot;,&quot;servicePort&quot;:80},&quot;path&quot;:&quot;/news&quot;},{&quot;backend&quot;:{&quot;serviceName&quot;:&quot;service-2&quot;,&quot;servicePort&quot;:80},&quot;path&quot;:&quot;/sports&quot;}]}}]}}

  kubernets.io/ingress.class:                  nginx
  nginx.ingress.kubernetes.io/rewrite-target:  /
Events:
  Type    Reason          Age   From                      Message
  ----    ------          ----  ----                      -------
  Normal  AddedOrUpdated  11s   nginx-ingress-controller  Configuration for default/nginx-ingress-uri-demo was added or updated
  Normal  AddedOrUpdated  11s   nginx-ingress-controller  Configuration for default/nginx-ingress-uri-demo was added or updated
  Normal  AddedOrUpdated  11s   nginx-ingress-controller  Configuration for default/nginx-ingress-uri-demo was added or updated
</code></pre>
<p><strong>4、准备测试，站点中创建对应的路径</strong></p>
<pre><code class="language-js">[root@node-1 ~]# kubectl exec -it service-1-7b66bf758f-xj9jh /bin/bash
root@service-1-7b66bf758f-xj9jh:/# echo &quot;service-1 website page&quot; &gt;/usr/share/nginx/html/news

[root@node-1 ~]# kubectl exec -it service-2-7c7444684d-w9cv9 /bin/bash
root@service-2-7c7444684d-w9cv9:/usr/local/apache2# echo &quot;service-2 website page&quot; &gt;/usr/local/apache2/htdocs/sports
</code></pre>
<p><strong>5、测试验证</strong></p>
<pre><code class="language-js">[root@node-1 ~]# curl http://demo.happylau.cn/news --resolve demo.happylau.cn:80:10.254.100.101
service-1 website page
[root@node-1 ~]# curl http://demo.happylau.cn/sports --resolve demo.happylau.cn:80:10.254.100.101
service-2 website page
</code></pre>
<p><strong>6、总结</strong></p>
<p>通过上述的验证测试可以得知，ingress支持URI的路由方式转发，其对应在ingress中的配置文件内容是怎样的呢，我们看下ingress controller生成对应的nginx配置文件内容，实际是通过ingress的location来实现，将不同的localtion转发至不同的upstream以实现service的关联，配置文件如下：</p>
<pre><code class="language-js">[root@node-1 ~]# kubectl exec -it nginx-ingress-7mpfc -n nginx-ingress /bin/bash
nginx@nginx-ingress-7mpfc:/$ cat /etc/nginx/conf.d/default-nginx-ingress-uri-demo.conf |grep -v &quot;^$&quot;
# configuration for default/nginx-ingress-uri-demo
#定义两个upstream和后端的service关联
upstream default-nginx-ingress-uri-demo-demo.happylau.cn-service-1-80 {
	zone default-nginx-ingress-uri-demo-demo.happylau.cn-service-1-80 256k;
	random two least_conn;
	server 10.244.2.163:80 max_fails=1 fail_timeout=10s max_conns=0;
}

upstream default-nginx-ingress-uri-demo-demo.happylau.cn-service-2-80 {
	zone default-nginx-ingress-uri-demo-demo.happylau.cn-service-2-80 256k;
	random two least_conn;
	server 10.244.1.148:80 max_fails=1 fail_timeout=10s max_conns=0;	
}

server {
	listen 80;
	server_tokens on;
	server_name demo.happylau.cn;
	
  #定义location实现代理，通过proxy_pass和后端的service关联
	location /news {
		proxy_http_version 1.1;
		proxy_connect_timeout 60s;
		proxy_read_timeout 60s;
		proxy_send_timeout 60s;
		client_max_body_size 1m;
		proxy_set_header Host $host;
		proxy_set_header X-Real-IP $remote_addr;
		proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
		proxy_set_header X-Forwarded-Host $host;
		proxy_set_header X-Forwarded-Port $server_port;
		proxy_set_header X-Forwarded-Proto $scheme;
		proxy_buffering on;
		proxy_pass http://default-nginx-ingress-uri-demo-demo.happylau.cn-service-1-80;
	}

	location /sports {
		proxy_http_version 1.1;
		proxy_connect_timeout 60s;
		proxy_read_timeout 60s;
		proxy_send_timeout 60s;
		client_max_body_size 1m;
		proxy_set_header Host $host;
		proxy_set_header X-Real-IP $remote_addr;
		proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
		proxy_set_header X-Forwarded-Host $host;
		proxy_set_header X-Forwarded-Port $server_port;
		proxy_set_header X-Forwarded-Proto $scheme;
		proxy_buffering on;
		proxy_pass http://default-nginx-ingress-uri-demo-demo.happylau.cn-service-2-80;	
	}	
}
</code></pre>
<h2 id="5-ingress虚拟主机">5 Ingress虚拟主机</h2>
<p>ingress支持基于名称的虚拟主机，实现单个IP多个域名转发的需求，通过请求头部携带主机名方式区分开，将上个章节的ingress删除，使用service-1和service-2两个service来做演示。</p>
<p><strong>1、创建ingress规则，通过主机名实现转发规则</strong></p>
<pre><code class="language-js">apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: nginx-ingress-virtualname-demo
  labels:
    ingres-controller: nginx
  annotations:
    kubernets.io/ingress.class: nginx
spec:
  rules:
  - host: news.happylau.cn
    http:
      paths:
      - path: /
        backend:
          serviceName: service-1 
          servicePort: 80
  - host: sports.happylau.cn
    http:
      paths:
      - path: /
        backend:
          serviceName: service-2 
          servicePort: 80
</code></pre>
<p><strong>2、生成ingress规则并查看详情，一个ingress对应两个HOSTS</strong></p>
<pre><code class="language-js">[root@node-1 nginx-ingress]# kubectl apply -f nginx-ingress-virtualname.yaml 
ingress.extensions/nginx-ingress-virtualname-demo created

#查看列表
[root@node-1 nginx-ingress]# kubectl get ingresses nginx-ingress-virtualname-demo 
NAME                             HOSTS                                 ADDRESS   PORTS   AGE
nginx-ingress-virtualname-demo   news.happylau.cn,sports.happylau.cn             80      12s

#查看详情
[root@node-1 nginx-ingress]# kubectl describe ingresses nginx-ingress-virtualname-demo
Name:             nginx-ingress-virtualname-demo
Namespace:        default
Address:          
Default backend:  default-http-backend:80 (&lt;none&gt;)
Rules:
  Host                Path  Backends
  ----                ----  --------
  news.happylau.cn    
                      /   service-1:80 (10.244.2.163:80)
  sports.happylau.cn  
                      /   service-2:80 (10.244.1.148:80)
Annotations:
  kubectl.kubernetes.io/last-applied-configuration:  {&quot;apiVersion&quot;:&quot;extensions/v1beta1&quot;,&quot;kind&quot;:&quot;Ingress&quot;,&quot;metadata&quot;:{&quot;annotations&quot;:{&quot;kubernets.io/ingress.class&quot;:&quot;nginx&quot;},&quot;labels&quot;:{&quot;ingres-controller&quot;:&quot;nginx&quot;},&quot;name&quot;:&quot;nginx-ingress-virtualname-demo&quot;,&quot;namespace&quot;:&quot;default&quot;},&quot;spec&quot;:{&quot;rules&quot;:[{&quot;host&quot;:&quot;news.happylau.cn&quot;,&quot;http&quot;:{&quot;paths&quot;:[{&quot;backend&quot;:{&quot;serviceName&quot;:&quot;service-1&quot;,&quot;servicePort&quot;:80},&quot;path&quot;:&quot;/&quot;}]}},{&quot;host&quot;:&quot;sports.happylau.cn&quot;,&quot;http&quot;:{&quot;paths&quot;:[{&quot;backend&quot;:{&quot;serviceName&quot;:&quot;service-2&quot;,&quot;servicePort&quot;:80},&quot;path&quot;:&quot;/&quot;}]}}]}}

  kubernets.io/ingress.class:  nginx
Events:
  Type    Reason          Age   From                      Message
  ----    ------          ----  ----                      -------
  Normal  AddedOrUpdated  28s   nginx-ingress-controller  Configuration for default/nginx-ingress-virtualname-demo was added or updated
  Normal  AddedOrUpdated  28s   nginx-ingress-controller  Configuration for default/nginx-ingress-virtualname-demo was added or updated
  Normal  AddedOrUpdated  28s   nginx-ingress-controller  Configuration for default/nginx-ingress-virtualname-demo was added or updated
</code></pre>
<p><strong>3、准备测试数据并测试</strong></p>
<pre><code class="language-js">[root@node-1 ~]# kubectl exec -it service-1-7b66bf758f-xj9jh /bin/bash
root@service-1-7b66bf758f-xj9jh:/# echo &quot;news demo&quot; &gt;/usr/share/nginx/html/index.html

[root@node-1 ~]# kubectl exec -it service-2-7c7444684d-w9cv9 /bin/bash  
root@service-2-7c7444684d-w9cv9:/usr/local/apache2# echo &quot;sports demo&quot;  &gt;/usr/local/apache2/htdocs/index.html
</code></pre>
<p><strong>测试：</strong></p>
<pre><code class="language-js">[root@node-1 ~]# curl http://news.happylau.cn --resolve news.happylau.cn:80:10.254.100.102
news demo
[root@node-1 ~]# curl http://sports.happylau.cn --resolve sports.happylau.cn:80:10.254.100.102
sports demo
</code></pre>
<p><strong>4、查看nginx的配置文件内容，通过在server中定义不同的server_name以区分，代理到不同的upstream以实现service的代理。</strong></p>
<pre><code class="language-js"># configuration for default/nginx-ingress-virtualname-demo
upstream default-nginx-ingress-virtualname-demo-news.happylau.cn-service-1-80 {
	zone default-nginx-ingress-virtualname-demo-news.happylau.cn-service-1-80 256k;
	random two least_conn;
	server 10.244.2.163:80 max_fails=1 fail_timeout=10s max_conns=0;
}

upstream default-nginx-ingress-virtualname-demo-sports.happylau.cn-service-2-80 {
	zone default-nginx-ingress-virtualname-demo-sports.happylau.cn-service-2-80 256k;
	random two least_conn;
	server 10.244.1.148:80 max_fails=1 fail_timeout=10s max_conns=0;
}

server {
	listen 80;
	server_tokens on;
	server_name news.happylau.cn;
	location / {
		proxy_http_version 1.1;
		proxy_connect_timeout 60s;
		proxy_read_timeout 60s;
		proxy_send_timeout 60s;
		client_max_body_size 1m;
		proxy_set_header Host $host;
		proxy_set_header X-Real-IP $remote_addr;
		proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
		proxy_set_header X-Forwarded-Host $host;
		proxy_set_header X-Forwarded-Port $server_port;
		proxy_set_header X-Forwarded-Proto $scheme;
		proxy_buffering on;
		
		proxy_pass http://default-nginx-ingress-virtualname-demo-news.happylau.cn-service-1-80;
	
  }
}
server {
	listen 80;	
	server_tokens on;
	server_name sports.happylau.cn;

	location / {
		proxy_http_version 1.1;
		proxy_connect_timeout 60s;
		proxy_read_timeout 60s;
		proxy_send_timeout 60s;
		client_max_body_size 1m;
		proxy_set_header Host $host;
		proxy_set_header X-Real-IP $remote_addr;
		proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
		proxy_set_header X-Forwarded-Host $host;
		proxy_set_header X-Forwarded-Port $server_port;
		proxy_set_header X-Forwarded-Proto $scheme;
		proxy_buffering on;
		
		proxy_pass http://default-nginx-ingress-virtualname-demo-sports.happylau.cn-service-2-80;	

	}	
}
</code></pre>
<h2 id="6-ingress-tls加密">6 Ingress TLS加密</h2>
<p>四层的负载均衡无法支持https请求，当前大部分业务都要求以https方式接入，Ingress能支持https的方式接入，通过Secrets存储证书+私钥，实现https接入，同时还能支持http跳转功能。对于用户的请求流量来说，客户端到ingress controller是https流量，ingress controller到后端service则是http，提高用户访问性能，如下介绍ingress TLS功能实现步骤。</p>
<p><strong>1、生成自签名证书和私钥</strong></p>
<pre><code class="language-js">[root@node-1 ~]# openssl req -x509 -newkey rsa:2048 -nodes -days 365 -keyout tls.key -out tls.crt
Generating a 2048 bit RSA private key
....................................................+++
........................................+++
writing new private key to 'tls.key'
-----
You are about to be asked to enter information that will be incorporated
into your certificate request.
What you are about to enter is what is called a Distinguished Name or a DN.
There are quite a few fields but you can leave some blank
For some fields there will be a default value,
If you enter '.', the field will be left blank.
-----
Country Name (2 letter code) [XX]:CN        #国家
State or Province Name (full name) []:GD    #省份
Locality Name (eg, city) [Default City]:ShenZhen  #城市
Organization Name (eg, company) [Default Company Ltd]:Tencent    #公司 
Organizational Unit Name (eg, section) []:HappyLau  #组织
Common Name (eg, your name or your server's hostname) []:www.happylau.cn  #域名
Email Address []:573302346@qq.com       #邮箱地址


#tls.crt为证书，tls.key为私钥
[root@node-1 ~]# ls tls.* -l
-rw-r--r-- 1 root root 1428 12月 26 13:21 tls.crt
-rw-r--r-- 1 root root 1708 12月 26 13:21 tls.key
</code></pre>
<p><strong>2、配置Secrets，将证书和私钥配置到Secrets中</strong></p>
<pre><code class="language-js">[root@node-1 ~]# kubectl create secret tls happylau-sslkey --cert=tls.crt --key=tls.key 
secret/happylau-sslkey created

查看Secrets详情,证书和私要包含在data中，文件名为两个不同的key：tls.crt和tls.key
[root@node-1 ~]# kubectl describe secrets happylau-sslkey 
Name:         happylau-sslkey
Namespace:    default
Labels:       &lt;none&gt;
Annotations:  &lt;none&gt;

Type:  kubernetes.io/tls

Data
====
tls.crt:  1428 bytes
tls.key:  1708 bytes
</code></pre>
<p><strong>3、配置ingress调用Secrets实现SSL证书加密</strong></p>
<pre><code class="language-js">apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: nginx-ingress-tls-demo
  labels:
    ingres-controller: nginx
  annotations:
    kubernets.io/ingress.class: nginx
spec:
  tls:
  - hosts:
    - news.happylau.cn
    - sports.happylau.cn
    secretName: happylau-sslkey
  rules:
  - host: news.happylau.cn
    http:
      paths:
      - path: /
        backend:
          serviceName: service-1 
          servicePort: 80
  - host: sports.happylau.cn
    http:
      paths:
      - path: /
        backend:
          serviceName: service-2 
          servicePort: 80
</code></pre>
<p><strong>4、创建ingress并查看ingress详情</strong></p>
<pre><code class="language-js">[root@node-1 nginx-ingress]# kubectl describe ingresses nginx-ingress-tls-demo 
Name:             nginx-ingress-tls-demo
Namespace:        default
Address:          
Default backend:  default-http-backend:80 (&lt;none&gt;)
TLS:
  happylau-sslkey terminates news.happylau.cn,sports.happylau.cn
Rules:
  Host                Path  Backends
  ----                ----  --------
  news.happylau.cn    
                      /   service-1:80 (10.244.2.163:80)
  sports.happylau.cn  
                      /   service-2:80 (10.244.1.148:80)
Annotations:
  kubectl.kubernetes.io/last-applied-configuration:  {&quot;apiVersion&quot;:&quot;extensions/v1beta1&quot;,&quot;kind&quot;:&quot;Ingress&quot;,&quot;metadata&quot;:{&quot;annotations&quot;:{&quot;kubernets.io/ingress.class&quot;:&quot;nginx&quot;},&quot;labels&quot;:{&quot;ingres-controller&quot;:&quot;nginx&quot;},&quot;name&quot;:&quot;nginx-ingress-tls-demo&quot;,&quot;namespace&quot;:&quot;default&quot;},&quot;spec&quot;:{&quot;rules&quot;:[{&quot;host&quot;:&quot;news.happylau.cn&quot;,&quot;http&quot;:{&quot;paths&quot;:[{&quot;backend&quot;:{&quot;serviceName&quot;:&quot;service-1&quot;,&quot;servicePort&quot;:80},&quot;path&quot;:&quot;/&quot;}]}},{&quot;host&quot;:&quot;sports.happylau.cn&quot;,&quot;http&quot;:{&quot;paths&quot;:[{&quot;backend&quot;:{&quot;serviceName&quot;:&quot;service-2&quot;,&quot;servicePort&quot;:80},&quot;path&quot;:&quot;/&quot;}]}}],&quot;tls&quot;:[{&quot;hosts&quot;:[&quot;news.happylau.cn&quot;,&quot;sports.happylau.cn&quot;],&quot;secretName&quot;:&quot;happylau-sslkey&quot;}]}}

  kubernets.io/ingress.class:  nginx
Events:
  Type    Reason          Age   From                      Message
  ----    ------          ----  ----                      -------
  Normal  AddedOrUpdated  22s   nginx-ingress-controller  Configuration for default/nginx-ingress-tls-demo was added or updated
  Normal  AddedOrUpdated  22s   nginx-ingress-controller  Configuration for default/nginx-ingress-tls-demo was added or updated
  Normal  AddedOrUpdated  22s   nginx-ingress-controller  Configuration for default/nginx-ingress-tls-demo was added or updated
</code></pre>
<p><strong>5、访问</strong></p>
<p>将news.happylau.cn和sports.happylau.cn写入到hosts文件中，并通过<a href="https://news.happylau.cn/">https://news.happylau.cn</a> 的方式访问，浏览器访问内容提示证书如下，信任证书即可访问到站点内容。</p>
<figure data-type="image" tabindex="5"><img src="https://ask.qcloudimg.com/draft/4405893/ijw044j6yx.png?imageView2/2/w/1620" alt="img" loading="lazy"></figure>
<p>查看证书详情，正是我们制作的自签名证书，生产实际使用时，推荐使用CA机构颁发签名证书。</p>
<figure data-type="image" tabindex="6"><img src="https://ask.qcloudimg.com/draft/4405893/t3clag54i5.png?imageView2/2/w/1620" alt="img" loading="lazy"></figure>
<p><strong>6、接下来查看一下tls配置https的nginx配置文件内容，可以看到在server块启用了https并配置证书，同时配置了http跳转，因此直接访问http也能够实现自动跳转到https功能。</strong></p>
<pre><code class="language-shell"># configuration for default/nginx-ingress-tls-demo
upstream default-nginx-ingress-tls-demo-news.happylau.cn-service-1-80 {
	zone default-nginx-ingress-tls-demo-news.happylau.cn-service-1-80 256k;
	random two least_conn;
	server 10.244.2.163:80 max_fails=1 fail_timeout=10s max_conns=0;	
}

upstream default-nginx-ingress-tls-demo-sports.happylau.cn-service-2-80 {
	zone default-nginx-ingress-tls-demo-sports.happylau.cn-service-2-80 256k;
	random two least_conn;
	server 10.244.1.148:80 max_fails=1 fail_timeout=10s max_conns=0;	
}

server {
	listen 80;

	listen 443 ssl;     #https监听端口，证书和key，实现和Secrets关联
	ssl_certificate /etc/nginx/secrets/default-happylau-sslkey;
	ssl_certificate_key /etc/nginx/secrets/default-happylau-sslkey;

	server_tokens on;
	server_name news.happylau.cn;
	
  #http跳转功能，即访问http会自动跳转至https
	if ($scheme = http) {
		return 301 https://$host:443$request_uri;
	}
	
	location / {
		proxy_http_version 1.1;
		proxy_connect_timeout 60s;
		proxy_read_timeout 60s;
		proxy_send_timeout 60s;
		client_max_body_size 1m;
		proxy_set_header Host $host;
		proxy_set_header X-Real-IP $remote_addr;
		proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
		proxy_set_header X-Forwarded-Host $host;
		proxy_set_header X-Forwarded-Port $server_port;
		proxy_set_header X-Forwarded-Proto $scheme;
		proxy_buffering on;
		
		proxy_pass http://default-nginx-ingress-tls-demo-news.happylau.cn-service-1-80;	
  }	
}

server {
	listen 80;
	listen 443 ssl;
	ssl_certificate /etc/nginx/secrets/default-happylau-sslkey;
	ssl_certificate_key /etc/nginx/secrets/default-happylau-sslkey;

	server_tokens on;
	server_name sports.happylau.cn;

	if ($scheme = http) {
		return 301 https://$host:443$request_uri;
	}

	location / {
		proxy_http_version 1.1;
		proxy_connect_timeout 60s;
		proxy_read_timeout 60s;
		proxy_send_timeout 60s;
		client_max_body_size 1m;
		proxy_set_header Host $host;
		proxy_set_header X-Real-IP $remote_addr;
		proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
		proxy_set_header X-Forwarded-Host $host;
		proxy_set_header X-Forwarded-Port $server_port;
		proxy_set_header X-Forwarded-Proto $scheme;
		proxy_buffering on;
		
		proxy_pass http://default-nginx-ingress-tls-demo-sports.happylau.cn-service-2-80;	
	}	
}
</code></pre>
<h2 id="7-nginx-ingress高级功能">7. Nginx Ingress高级功能</h2>
<h3 id="71-定制化参数">7.1 定制化参数</h3>
<p>ingress controller提供了基础反向代理的功能，如果需要定制化nginx的特性或参数，需要通过ConfigMap和Annotations来实现，两者实现的方式有所不同，ConfigMap用于指定整个ingress集群资源的基本参数，修改后会被所有的ingress对象所继承；Annotations则被某个具体的ingress对象所使用，修改只会影响某个具体的ingress资源，冲突时其优先级高于ConfigMap。</p>
<h4 id="711-configmap自定义参数">7.1.1 ConfigMap自定义参数</h4>
<p>安装nginx ingress controller时默认会包含一个空的ConfigMap，可以通过ConfigMap来自定义nginx controller的默认参数，如下以修改一些参数为例：</p>
<p><strong>1、 定义ConfigMap参数</strong></p>
<pre><code class="language-yaml">kind: ConfigMap
apiVersion: v1
metadata:
  name: nginx-config
  namespace: nginx-ingress
data:
  proxy-connect-timeout: &quot;10s&quot;
  proxy-read-timeout: &quot;10s&quot;
  proxy-send-timeout: &quot;10&quot;
  client-max-body-size: &quot;3m&quot;
</code></pre>
<p><strong>2、 应用配置并查看ConfigMap配置</strong></p>
<pre><code class="language-shell">[root@node-1 ~]# kubectl get configmaps -n nginx-ingress nginx-config -o yaml
apiVersion: v1
data:
  client-max-body-size: 3m
  proxy-connect-timeout: 10s
  proxy-read-timeout: 10s
  proxy-send-timeout: 10s
kind: ConfigMap
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {&quot;apiVersion&quot;:&quot;v1&quot;,&quot;data&quot;:{&quot;client-max-body-size&quot;:&quot;3m&quot;,&quot;proxy-connect-timeout&quot;:&quot;10s&quot;,&quot;proxy-read-timeout&quot;:&quot;10s&quot;,&quot;proxy-send-timeout&quot;:&quot;10&quot;},&quot;kind&quot;:&quot;ConfigMap&quot;,&quot;metadata&quot;:{&quot;annotations&quot;:{},&quot;name&quot;:&quot;nginx-config&quot;,&quot;namespace&quot;:&quot;nginx-ingress&quot;}}
  creationTimestamp: &quot;2019-12-24T04:39:23Z&quot;
  name: nginx-config
  namespace: nginx-ingress
  resourceVersion: &quot;13845543&quot;
  selfLink: /api/v1/namespaces/nginx-ingress/configmaps/nginx-config
  uid: 9313ae47-a0f0-463e-a25a-1658f1ca0d57
</code></pre>
<p><strong>3 、此时，ConfigMap定义的配置参数会被集群中所有的Ingress资源继承（除了annotations定义之外）</strong></p>
<figure data-type="image" tabindex="7"><img src="https://ask.qcloudimg.com/draft/4405893/w3dcxxnxfa.png?imageView2/2/w/1620" alt="img" loading="lazy"></figure>
<p>有很多参数可以定义，详情配置可参考方文档说明：https://github.com/nginxinc/kubernetes-ingress/blob/master/docs/configmap-and-annotations.md#Summary-of-ConfigMap-and-Annotations</p>
<h4 id="712-annotations自定义参数">7.1.2 Annotations自定义参数</h4>
<p>ConfigMap定义的是全局的配置参数，修改后所有的配置都会受影响，如果想针对某个具体的ingress资源自定义参数，则可以通过Annotations来实现，下面开始以实际的例子演示Annotations的使用。</p>
<p><strong>1、修改ingress资源，添加annotations的定义,通过nginx.org组修改了一些参数，如proxy-connect-timeout，调度算法为round_robin（默认为least _conn）</strong></p>
<pre><code class="language-yaml">apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: nginx-ingress-demo
  labels:
    ingres-controller: nginx
  annotations:
    kubernets.io/ingress.class: nginx
    nginx.org/proxy-connect-timeout: &quot;30s&quot;
    nginx.org/proxy-send-timeout: &quot;20s&quot;
    nginx.org/proxy-read-timeout: &quot;20s&quot;
    nginx.org/client-max-body-size: &quot;2m&quot;
    nginx.org/fail-timeout: &quot;5s&quot;
    nginx.org/lb-method: &quot;round_robin&quot; 
spec:
  rules:
  - host: www.happylau.cn
    http:
      paths:
      - path: /
        backend:
          serviceName: ingress-demo
          servicePort: 80
</code></pre>
<p><strong>2、 重新应用ingress对象并查看参数配置情况</strong></p>
<figure data-type="image" tabindex="8"><img src="https://ask.qcloudimg.com/draft/4405893/b02oqllujm.png?imageView2/2/w/1620" alt="img" loading="lazy"></figure>
<p>由上面的演示可得知，Annotations的优先级高于ConfigMapMap，Annotations修改参数只会影响到某一个具体的ingress资源，其定义的方法和ConfigMap相相近似，但又有差别，部分ConfigMap的参数Annotations无法支持，反过来Annotations定义的参数ConfigMap也不一定支持，下图列举一下常规支持参数情况：</p>
<p><img src="https://ask.qcloudimg.com/draft/4405893/9uco9v1rs6.png?imageView2/2/w/1620" alt="img" loading="lazy">通用参数</p>
<p><img src="https://ask.qcloudimg.com/draft/4405893/kvbsl1udm3.png?imageView2/2/w/1620" alt="img" loading="lazy">日志支持</p>
<p><img src="https://ask.qcloudimg.com/draft/4405893/2bexxnq0b4.png?imageView2/2/w/1620" alt="img" loading="lazy">请求头部</p>
<p><img src="https://ask.qcloudimg.com/draft/4405893/hbfmi960e9.png?imageView2/2/w/1620" alt="img" loading="lazy">认证和安全</p>
<p><img src="https://ask.qcloudimg.com/draft/4405893/0h2kio34c5.png?imageView2/2/w/1620" alt="img" loading="lazy">upstream支持</p>
<h3 id="72-虚拟主机和路由">7.2 虚拟主机和路由</h3>
<p>安装nginx ingress时我们安装了一个customresourcedefinitions自定义资源，其能够提供除了默认ingress功能之外的一些高级特性如</p>
<ul>
<li>虚拟主机VirtualServer</li>
<li>虚拟路由VirtualServerRoute</li>
<li>健康检查Healthcheck</li>
<li>流量切割Split</li>
<li>会话保持SessionCookie</li>
<li>重定向Redirect</li>
</ul>
<p>这些功能大部分依赖于Nginx Plus高级版本的支持，社区版本仅支持部分，对于企业级开发而言，丰富更多的功能可以购买企业级Nginx Plus版本。如下以通过VirtualServer和VirtualServerRoute定义upstream配置为例演示功能使用。</p>
<p><strong>1、定义VirtualServer资源,其配置和ingress资源对象类似，能支持的功能会更丰富一点</strong></p>
<pre><code class="language-yaml">apiVersion: k8s.nginx.org/v1
kind: VirtualServer
metadata:
  name: cafe
spec:
  host: cafe.example.com
  tls:
    secret: cafe-secret
  upstreams:
  - name: tea
    service: tea-svc
    port: 80
    name: tea
    service: ingress-demo 
    subselector:
    version: canary
    lb-method: round_robin
    fail-timeout: 10s
    max-fails: 1
    max-conns: 32
    keepalive: 32
    connect-timeout: 30s
    read-timeout: 30s
    send-timeout: 30s
    next-upstream: &quot;error timeout non_idempotent&quot;
    next-upstream-timeout: 5s
    next-upstream-tries: 10
    client-max-body-size: 2m
    tls:
      enable: true
  routes:
  - path: /tea
    action:
      pass: tea
</code></pre>
<p><strong>2、 应用资源并查看VirtualServer资源列表</strong></p>
<pre><code class="language-shell">[root@node-1 ~]# kubectl apply -f vs.yaml 
virtualserver.k8s.nginx.org/cafe unchanged
[root@node-1 ~]# kubectl get virtualserver
NAME                 AGE
cafe                 2m52s
</code></pre>
<p><strong>3、检查ingress控制器的配置文件情况,生成的配置和upstream定义一致</strong></p>
<pre><code class="language-shell">nginx@nginx-ingress-7mpfc:/etc/nginx/conf.d$ cat vs_default_cafe.conf 
upstream vs_default_cafe_tea {
    zone vs_default_cafe_tea 256k;
    server 10.244.0.51:80 max_fails=1 fail_timeout=10s max_conns=32;
    server 10.244.1.146:80 max_fails=1 fail_timeout=10s max_conns=32;
    server 10.244.1.147:80 max_fails=1 fail_timeout=10s max_conns=32;
    server 10.244.2.162:80 max_fails=1 fail_timeout=10s max_conns=32;
    keepalive 32;
}

server {
    listen 80;
    server_name cafe.example.com;
    listen 443 ssl;
    ssl_certificate /etc/nginx/secrets/default;
    ssl_certificate_key /etc/nginx/secrets/default;
    ssl_ciphers NULL;
    server_tokens &quot;on&quot;;

    location /tea {
        proxy_connect_timeout 30s;
        proxy_read_timeout 30s;
        proxy_send_timeout 30s;
        client_max_body_size 2m;
        proxy_max_temp_file_size 1024m;
        proxy_buffering on;
        proxy_http_version 1.1;
        set $default_connection_header &quot;&quot;;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection $vs_connection_header;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Host $host;
        proxy_set_header X-Forwarded-Port $server_port;
        proxy_set_header X-Forwarded-Proto $scheme;

        proxy_pass https://vs_default_cafe_tea;
        proxy_next_upstream error timeout non_idempotent;
        proxy_next_upstream_timeout 5s;
        proxy_next_upstream_tries 10;   
    }   
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[k8s界面kubesphere安装]]></title>
        <id>https://tinaxiawuhao.github.io/post/ULtZ5rQXA/</id>
        <link href="https://tinaxiawuhao.github.io/post/ULtZ5rQXA/">
        </link>
        <updated>2022-05-30T06:18:50.000Z</updated>
        <content type="html"><![CDATA[<p><strong>在 Kubernetes 上安装 KubeSphere 3.2.1，您的 Kubernetes 版本必须为：1.19.x、1.20.x、1.21.x 或 1.22.x（实验性支持）</strong></p>
<h3 id="1-搭建nfs作为默认sc主节点作为服务器主节点操作">1 搭建NFS作为默认sc（（主节点作为服务器，主节点操作）</h3>
<h4 id="11-配置nfs服务器">1.1   配置NFS服务器</h4>
<pre><code class="language-shell">yum install -y nfs-utils rpcbind  &amp;&amp; echo &quot;/nfs *(insecure,rw,sync,no_root_squash)&quot; &gt; /etc/exports
</code></pre>
<h4 id="12-创建nfs服务器目录">1.2   创建nfs服务器目录</h4>
<pre><code class="language-shell">mkdir -p /nfs
</code></pre>
<h4 id="13-启动rpcbindnfs服务命令">1.3   启动rpcbind,nfs服务命令</h4>
<pre><code class="language-shell">systemctl restart rpcbind &amp;&amp; systemctl enable rpcbind
systemctl restart nfs-server &amp;&amp; systemctl enable nfs-server
</code></pre>
<h4 id="14-检查配置是否生效">1.4   检查配置是否生效</h4>
<pre><code class="language-shell">exportfs -r
exportfs
</code></pre>
<h4 id="15-测试pod直接挂载nfs了主节点操作">1.5   测试Pod直接挂载NFS了（主节点操作）</h4>
<h5 id="151-在opt目录下创建一个nginxyaml的文件">1.5.1     在opt目录下创建一个nginx.yaml的文件</h5>
<pre><code class="language-shell">vi nginx.yaml
</code></pre>
<h5 id="152-写入以下的命令">1.5.2     写入以下的命令</h5>
<pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata:
  name: vol-nfs
  namespace: default
spec:
  volumes:
  - name: html
    nfs:
      path: /nfs   
      server: 192.168.40.131 #自己的nfs服务器地址
  containers:
  - name: myapp
    image: nginx
    volumeMounts:
    - name: html
      mountPath: /usr/share/nginx/html/
</code></pre>
<h5 id="153-应用该yaml的pod服务">1.5.3     应用该yaml的pod服务</h5>
<pre><code class="language-shell">kubectl apply -f nginx.yaml
</code></pre>
<h5 id="154-检查该pod是否允许状态">1.5.4     检查该pod是否允许状态</h5>
<pre><code class="language-shell">kubectl get pod
</code></pre>
<pre><code class="language-shell">kubectl get pods -A
</code></pre>
<p>这里需要注意的是，必须等所有的状态为Runing才能进行下一步操作。</p>
<h3 id="2-搭建nfs-clientnode节点操作">2   搭建NFS-Client（node节点操作）</h3>
<p>服务器端防火墙开放111、662、875、892、2049的 tcp / udp 允许，否则远端客户无法连接。</p>
<h4 id="21-安装客户端工具">2.1  安装客户端工具</h4>
<pre><code class="language-shell">yum install -y nfs-utils rpcbind
showmount -e 192.168.40.131
</code></pre>
<p>该IP地址是master的IP地址</p>
<h4 id="22-创建同步文件夹">2.2  创建同步文件夹</h4>
<pre><code class="language-shell">mkdir /nfs/data/
</code></pre>
<h4 id="23-将客户端的nfsdata和nfs做同步node节点操作">2.3  将客户端的/nfs/data和/nfs/做同步（node节点操作）</h4>
<pre><code class="language-shell">mount -t nfs 192.168.40.131:/nfs/ /nfs/data/
</code></pre>
<p>192.168.40.131：是nfs的服务器的地址，这里是master的IP地址。</p>
<h3 id="3-设置动态供应">3   设置动态供应</h3>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1653892179794.png" alt="" loading="lazy"></figure>
<h4 id="31-创建provisionernfs环境前面已经搭好">3.1  创建provisioner（NFS环境前面已经搭好）</h4>
<table>
<thead>
<tr>
<th>字段名称</th>
<th>填入内容</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td>名称</td>
<td>nfs-storage</td>
<td>自定义存储类名称</td>
</tr>
<tr>
<td>NFS Server</td>
<td>192.168.40.131</td>
<td>NFS服务的IP地址</td>
</tr>
<tr>
<td>NFS Path</td>
<td>/nfs</td>
<td>NFS服务所共享的路径</td>
</tr>
</tbody>
</table>
<h5 id="311-先创建授权master节点操作">3.1.1   先创建授权（master节点操作）</h5>
<pre><code class="language-shell">vim nfs-rbac.yaml  #在opt目录下
</code></pre>
<p>新建内容如下：</p>
<pre><code class="language-yaml">---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: nfs-provisioner
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
   name: nfs-provisioner-runner
rules:
   -  apiGroups: [&quot;&quot;]
      resources: [&quot;persistentvolumes&quot;]
      verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;delete&quot;]
   -  apiGroups: [&quot;&quot;]
      resources: [&quot;persistentvolumeclaims&quot;]
      verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;update&quot;]
   -  apiGroups: [&quot;storage.k8s.io&quot;]
      resources: [&quot;storageclasses&quot;]
      verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]
   -  apiGroups: [&quot;&quot;]
      resources: [&quot;events&quot;]
      verbs: [&quot;watch&quot;, &quot;create&quot;, &quot;update&quot;, &quot;patch&quot;]
   -  apiGroups: [&quot;&quot;]
      resources: [&quot;services&quot;, &quot;endpoints&quot;]
      verbs: [&quot;get&quot;,&quot;create&quot;,&quot;list&quot;, &quot;watch&quot;,&quot;update&quot;]
   -  apiGroups: [&quot;extensions&quot;]
      resources: [&quot;podsecuritypolicies&quot;]
      resourceNames: [&quot;nfs-provisioner&quot;]
      verbs: [&quot;use&quot;]
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: run-nfs-provisioner
subjects:
  - kind: ServiceAccount
    name: nfs-provisioner
    namespace: default
roleRef:
  kind: ClusterRole
  name: nfs-provisioner-runner
  apiGroup: rbac.authorization.k8s.io
---
kind: Deployment
apiVersion: apps/v1
metadata:
   name: nfs-client-provisioner
spec:
   replicas: 1
   strategy:
     type: Recreate
   selector:
     matchLabels:
        app: nfs-client-provisioner
   template:
      metadata:
         labels:
            app: nfs-client-provisioner
      spec:
         serviceAccount: nfs-provisioner
         containers:
            -  name: nfs-client-provisioner
               image: lizhenliang/nfs-client-provisioner
               volumeMounts:
                 -  name: nfs-client-root
                    mountPath:  /persistentvolumes
               env:
                 -  name: PROVISIONER_NAME
                    value: storage.pri/nfs
                 -  name: NFS_SERVER
                    value: 192.168.40.131
                 -  name: NFS_PATH
                    value: /nfs
         volumes:
           - name: nfs-client-root
             nfs:
               server: 192.168.40.131
               path: /nfs
</code></pre>
<p>这个镜像中volume的mountPath默认为/persistentvolumes，不能修改，否则运行时会报错。ip的必须是自己的master的IP地址。</p>
<h5 id="312-执行创建nfs的yaml文件信息">3.1.2   执行创建nfs的yaml文件信息</h5>
<pre><code class="language-shell">kubectl apply -f nfs-rbac.yaml
</code></pre>
<h5 id="313-如果发现pod有问题想删除pod进行重新kubectl-apply-f-nfs-rbacyaml的话可以参照这个博客文档">3.1.3   如果发现pod有问题，想删除pod进行重新kubectl apply-f nfs-rbac.yaml的话，可以参照这个博客文档：</h5>
<p>https://blog.csdn.net/qq_43542988/article/details/101277263?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&amp;depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param</p>
<h5 id="314-查看pod的状态信息">3.1.4   查看pod的状态信息</h5>
<pre><code class="language-shell">kubectl get pods -A
# 如果报错：查看报错信息，这个命令：
kubectl describe pod xxx -n kube-system
</code></pre>
<h5 id="315-创建storageclassmaster节点操作">3.1.5   创建storageclass（master节点操作）</h5>
<pre><code class="language-yaml">vim storageclass-nfs.yaml
 
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: storage-nfs
provisioner: storage.pri/nfs
reclaimPolicy: Delete
</code></pre>
<h5 id="316-应用storageclass-nfsyaml文件">3.1.6   应用storageclass-nfs.yaml文件</h5>
<pre><code class="language-shell">kubectl apply -f storageclass-nfs.yaml
</code></pre>
<h5 id="317-修改默认的驱动">3.1.7   修改默认的驱动</h5>
<pre><code class="language-shell">kubectl patch storageclass storage-nfs -p '{&quot;metadata&quot;: {&quot;annotations&quot;:{&quot;storageclass.kubernetes.io/is-default-class&quot;:&quot;true&quot;}}}'
</code></pre>
<pre><code>kubectl get sc
</code></pre>
<h3 id="4-安装metrics-server">4   安装metrics-server</h3>
<h4 id="41-准备metrics-serveryaml文件主节点操作">4.1  准备metrics-server.yaml文件（主节点操作）</h4>
<pre><code class="language-shell">vim metrics-server.yaml
</code></pre>
<h4 id="42-编写以下的内容">4.2  编写以下的内容</h4>
<pre><code class="language-yaml">---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: system:aggregated-metrics-reader
  labels:
    rbac.authorization.k8s.io/aggregate-to-view: &quot;true&quot;
    rbac.authorization.k8s.io/aggregate-to-edit: &quot;true&quot;
    rbac.authorization.k8s.io/aggregate-to-admin: &quot;true&quot;
rules:
- apiGroups: [&quot;metrics.k8s.io&quot;]
  resources: [&quot;pods&quot;, &quot;nodes&quot;]
  verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: metrics-server:system:auth-delegator
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: system:auth-delegator
subjects:
- kind: ServiceAccount
  name: metrics-server
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: metrics-server-auth-reader
  namespace: kube-system
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: extension-apiserver-authentication-reader
subjects:
- kind: ServiceAccount
  name: metrics-server
  namespace: kube-system
---
apiVersion: apiregistration.k8s.io/v1
kind: APIService
metadata:
  name: v1beta1.metrics.k8s.io
spec:
  service:
    name: metrics-server
    namespace: kube-system
  group: metrics.k8s.io
  version: v1beta1
  insecureSkipTLSVerify: true
  groupPriorityMinimum: 100
  versionPriority: 100
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: metrics-server
  namespace: kube-system
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: metrics-server
  namespace: kube-system
  labels:
    k8s-app: metrics-server
spec:
  selector:
    matchLabels:
      k8s-app: metrics-server
  template:
    metadata:
      name: metrics-server
      labels:
        k8s-app: metrics-server
    spec:
      serviceAccountName: metrics-server
      volumes:
      # mount in tmp so we can safely use from-scratch images and/or read-only containers
      - name: tmp-dir
        emptyDir: {}
      containers:
      - name: metrics-server
        image: mirrorgooglecontainers/metrics-server-amd64:v0.3.6
        imagePullPolicy: IfNotPresent
        args:
          - --cert-dir=/tmp
          - --secure-port=4443
          - --kubelet-insecure-tls
          - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
        ports:
        - name: main-port
          containerPort: 4443
          protocol: TCP
        securityContext:
          readOnlyRootFilesystem: true
          runAsNonRoot: true
          runAsUser: 1000
        volumeMounts:
        - name: tmp-dir
          mountPath: /tmp
      nodeSelector:
        kubernetes.io/os: linux
        kubernetes.io/arch: &quot;amd64&quot;
---
apiVersion: v1
kind: Service
metadata:
  name: metrics-server
  namespace: kube-system
  labels:
    kubernetes.io/name: &quot;Metrics-server&quot;
    kubernetes.io/cluster-service: &quot;true&quot;
spec:
  selector:
    k8s-app: metrics-server
  ports:
  - port: 443
    protocol: TCP
    targetPort: main-port
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: system:metrics-server
rules:
- apiGroups:
  - &quot;&quot;
  resources:
  - pods
  - nodes
  - nodes/stats
  - namespaces
  - configmaps
  verbs:
  - get
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: system:metrics-server
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: system:metrics-server
subjects:
- kind: ServiceAccount
  name: metrics-server
  namespace: kube-system
</code></pre>
<h4 id="43-应用该文件pod">4.3  应用该文件pod</h4>
<pre><code class="language-shell">kubectl apply -f metrics-server.yaml
</code></pre>
<h4 id="44-查看部署的应用信息状态">4.4  查看部署的应用信息状态</h4>
<pre><code class="language-shell">kubectl get pod -A
</code></pre>
<h4 id="45-查看系统的监控状态">4.5  查看系统的监控状态</h4>
<pre><code class="language-shell">kubectl top nodes
 
如果运行kubectl top nodes这个命令，爆metrics not available yet 这个命令还没有用，那就稍等一会，就能用了
</code></pre>
<p>这里，kubesphere3.0的前置环境全部结束。</p>
<h2 id="5-安装kubesphere-v300">5 安装kubesphere v3.0.0</h2>
<h3 id="51-文档地址">5.1 文档地址</h3>
<pre><code class="language-shell">https://kubesphere.com.cn/
</code></pre>
<h3 id="152-部署文档地址">1.5.2 部署文档地址</h3>
<pre><code class="language-shell">https://kubesphere.com.cn/docs/quick-start/minimal-kubesphere-on-k8s/
</code></pre>
<h3 id="153-安装步骤说明master节点">1.5.3 安装步骤说明（master节点）</h3>
<h4 id="1531-安装集群配置文件">1.5.3.1   安装集群配置文件</h4>
<h5 id="15311-准备配置文件cluster-configurationyaml">1.5.3.1.1     准备配置文件cluster-configuration.yaml</h5>
<pre><code class="language-shell">vim cluster-configuration.yaml
</code></pre>
<h5 id="15312-编写以下的内容配置">1.5.3.1.2     编写以下的内容配置</h5>
<pre><code class="language-yaml">---
apiVersion: installer.kubesphere.io/v1alpha1
kind: ClusterConfiguration
metadata:
  name: ks-installer
  namespace: kubesphere-system
  labels:
    version: v3.2.1
spec:
  persistence:
    storageClass: &quot;&quot;        # If there is no default StorageClass in your cluster, you need to specify an existing StorageClass here.
  authentication:
    jwtSecret: &quot;&quot;           # Keep the jwtSecret consistent with the Host Cluster. Retrieve the jwtSecret by executing &quot;kubectl -n kubesphere-system get cm kubesphere-config -o yaml | grep -v &quot;apiVersion&quot; | grep jwtSecret&quot; on the Host Cluster.
  local_registry: &quot;&quot;        # Add your private registry address if it is needed.
  # dev_tag: &quot;&quot;               # Add your kubesphere image tag you want to install, by default it's same as ks-install release version.
  etcd:
    monitoring: false       # Enable or disable etcd monitoring dashboard installation. You have to create a Secret for etcd before you enable it.
    endpointIps: localhost  # etcd cluster EndpointIps. It can be a bunch of IPs here.
    port: 2379              # etcd port.
    tlsEnable: true
  common:
    core:
      console:
        enableMultiLogin: true  # Enable or disable simultaneous logins. It allows different users to log in with the same account at the same time.
        port: 30880
        type: NodePort
    # apiserver:            # Enlarge the apiserver and controller manager's resource requests and limits for the large cluster
    #  resources: {}
    # controllerManager:
    #  resources: {}
    redis:
      enabled: false
      volumeSize: 2Gi # Redis PVC size.
    openldap:
      enabled: false
      volumeSize: 2Gi   # openldap PVC size.
    minio:
      volumeSize: 20Gi # Minio PVC size.
    monitoring:
      # type: external   # Whether to specify the external prometheus stack, and need to modify the endpoint at the next line.
      endpoint: http://prometheus-operated.kubesphere-monitoring-system.svc:9090 # Prometheus endpoint to get metrics data.
      GPUMonitoring:     # Enable or disable the GPU-related metrics. If you enable this switch but have no GPU resources, Kubesphere will set it to zero. 
        enabled: false
    gpu:                 # Install GPUKinds. The default GPU kind is nvidia.com/gpu. Other GPU kinds can be added here according to your needs. 
      kinds:         
      - resourceName: &quot;nvidia.com/gpu&quot;
        resourceType: &quot;GPU&quot;
        default: true
    es:   # Storage backend for logging, events and auditing.
      # master:
      #   volumeSize: 4Gi  # The volume size of Elasticsearch master nodes.
      #   replicas: 1      # The total number of master nodes. Even numbers are not allowed.
      #   resources: {}
      # data:
      #   volumeSize: 20Gi  # The volume size of Elasticsearch data nodes.
      #   replicas: 1       # The total number of data nodes.
      #   resources: {}
      logMaxAge: 7             # Log retention time in built-in Elasticsearch. It is 7 days by default.
      elkPrefix: logstash      # The string making up index names. The index name will be formatted as ks-&lt;elk_prefix&gt;-log.
      basicAuth:
        enabled: false
        username: &quot;&quot;
        password: &quot;&quot;
      externalElasticsearchUrl: &quot;&quot;
      externalElasticsearchPort: &quot;&quot;
  alerting:                # (CPU: 0.1 Core, Memory: 100 MiB) It enables users to customize alerting policies to send messages to receivers in time with different time intervals and alerting levels to choose from.
    enabled: false         # Enable or disable the KubeSphere Alerting System.
    # thanosruler:
    #   replicas: 1
    #   resources: {}
  auditing:                # Provide a security-relevant chronological set of records，recording the sequence of activities happening on the platform, initiated by different tenants.
    enabled: false         # Enable or disable the KubeSphere Auditing Log System.
    # operator:
    #   resources: {}
    # webhook:
    #   resources: {}
  devops:                  # (CPU: 0.47 Core, Memory: 8.6 G) Provide an out-of-the-box CI/CD system based on Jenkins, and automated workflow tools including Source-to-Image &amp; Binary-to-Image.
    enabled: false             # Enable or disable the KubeSphere DevOps System.
    # resources: {}
    jenkinsMemoryLim: 2Gi      # Jenkins memory limit.
    jenkinsMemoryReq: 1500Mi   # Jenkins memory request.
    jenkinsVolumeSize: 8Gi     # Jenkins volume size.
    jenkinsJavaOpts_Xms: 512m  # The following three fields are JVM parameters.
    jenkinsJavaOpts_Xmx: 512m
    jenkinsJavaOpts_MaxRAM: 2g
  events:                  # Provide a graphical web console for Kubernetes Events exporting, filtering and alerting in multi-tenant Kubernetes clusters.
    enabled: false         # Enable or disable the KubeSphere Events System.
    # operator:
    #   resources: {}
    # exporter:
    #   resources: {}
    # ruler:
    #   enabled: true
    #   replicas: 2
    #   resources: {}
  logging:                 # (CPU: 57 m, Memory: 2.76 G) Flexible logging functions are provided for log query, collection and management in a unified console. Additional log collectors can be added, such as Elasticsearch, Kafka and Fluentd.
    enabled: false         # Enable or disable the KubeSphere Logging System.
    containerruntime: docker
    logsidecar:
      enabled: true
      replicas: 2
      # resources: {}
  metrics_server:                    # (CPU: 56 m, Memory: 44.35 MiB) It enables HPA (Horizontal Pod Autoscaler).
    enabled: false                   # Enable or disable metrics-server.
  monitoring:
    storageClass: &quot;&quot;                 # If there is an independent StorageClass you need for Prometheus, you can specify it here. The default StorageClass is used by default.
    # kube_rbac_proxy:
    #   resources: {}
    # kube_state_metrics:
    #   resources: {}
    # prometheus:
    #   replicas: 1  # Prometheus replicas are responsible for monitoring different segments of data source and providing high availability.
    #   volumeSize: 20Gi  # Prometheus PVC size.
    #   resources: {}
    #   operator:
    #     resources: {}
    #   adapter:
    #     resources: {}
    # node_exporter:
    #   resources: {}
    # alertmanager:
    #   replicas: 1          # AlertManager Replicas.
    #   resources: {}
    # notification_manager:
    #   resources: {}
    #   operator:
    #     resources: {}
    #   proxy:
    #     resources: {}
    gpu:                           # GPU monitoring-related plug-in installation. 
      nvidia_dcgm_exporter:        # Ensure that gpu resources on your hosts can be used normally, otherwise this plug-in will not work properly.
        enabled: false             # Check whether the labels on the GPU hosts contain &quot;nvidia.com/gpu.present=true&quot; to ensure that the DCGM pod is scheduled to these nodes.
        # resources: {}
  multicluster:
    clusterRole: none  # host | member | none  # You can install a solo cluster, or specify it as the Host or Member Cluster.
  network:
    networkpolicy: # Network policies allow network isolation within the same cluster, which means firewalls can be set up between certain instances (Pods).
      # Make sure that the CNI network plugin used by the cluster supports NetworkPolicy. There are a number of CNI network plugins that support NetworkPolicy, including Calico, Cilium, Kube-router, Romana and Weave Net.
      enabled: false # Enable or disable network policies.
    ippool: # Use Pod IP Pools to manage the Pod network address space. Pods to be created can be assigned IP addresses from a Pod IP Pool.
      type: none # Specify &quot;calico&quot; for this field if Calico is used as your CNI plugin. &quot;none&quot; means that Pod IP Pools are disabled.
    topology: # Use Service Topology to view Service-to-Service communication based on Weave Scope.
      type: none # Specify &quot;weave-scope&quot; for this field to enable Service Topology. &quot;none&quot; means that Service Topology is disabled.
  openpitrix: # An App Store that is accessible to all platform tenants. You can use it to manage apps across their entire lifecycle.
    store:
      enabled: false # Enable or disable the KubeSphere App Store.
  servicemesh:         # (0.3 Core, 300 MiB) Provide fine-grained traffic management, observability and tracing, and visualized traffic topology.
    enabled: false     # Base component (pilot). Enable or disable KubeSphere Service Mesh (Istio-based).
  kubeedge:          # Add edge nodes to your cluster and deploy workloads on edge nodes.
    enabled: false   # Enable or disable KubeEdge.
    cloudCore:
      nodeSelector: {&quot;node-role.kubernetes.io/worker&quot;: &quot;&quot;}
      tolerations: []
      cloudhubPort: &quot;10000&quot;
      cloudhubQuicPort: &quot;10001&quot;
      cloudhubHttpsPort: &quot;10002&quot;
      cloudstreamPort: &quot;10003&quot;
      tunnelPort: &quot;10004&quot;
      cloudHub:
        advertiseAddress: # At least a public IP address or an IP address which can be accessed by edge nodes must be provided.
          - &quot;&quot;            # Note that once KubeEdge is enabled, CloudCore will malfunction if the address is not provided.
        nodeLimit: &quot;100&quot;
      service:
        cloudhubNodePort: &quot;30000&quot;
        cloudhubQuicNodePort: &quot;30001&quot;
        cloudhubHttpsNodePort: &quot;30002&quot;
        cloudstreamNodePort: &quot;30003&quot;
        tunnelNodePort: &quot;30004&quot;
    edgeWatcher:
      nodeSelector: {&quot;node-role.kubernetes.io/worker&quot;: &quot;&quot;}
      tolerations: []
      edgeWatcherAgent:
        nodeSelector: {&quot;node-role.kubernetes.io/worker&quot;: &quot;&quot;}
        tolerations: []

</code></pre>
<p>endpointIps: 192.168.40.131：master节点的地址。</p>
<h5 id="15313-准备配置文件kubesphere-installeryaml">1.5.3.1.3     准备配置文件kubesphere-installer.yaml</h5>
<pre><code class="language-shell">vim kubesphere-installer.yaml
</code></pre>
<h5 id="15314-编写以下的内容配置">1.5.3.1.4    编写以下的内容配置</h5>
<pre><code class="language-yaml">---
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: clusterconfigurations.installer.kubesphere.io
spec:
  group: installer.kubesphere.io
  versions:
    - name: v1alpha1
      served: true
      storage: true
      schema:
        openAPIV3Schema:
          type: object
          properties:
            spec:
              type: object
              x-kubernetes-preserve-unknown-fields: true
            status:
              type: object
              x-kubernetes-preserve-unknown-fields: true
  scope: Namespaced
  names:
    plural: clusterconfigurations
    singular: clusterconfiguration
    kind: ClusterConfiguration
    shortNames:
      - cc

---
apiVersion: v1
kind: Namespace
metadata:
  name: kubesphere-system

---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: ks-installer
  namespace: kubesphere-system

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: ks-installer
rules:
- apiGroups:
  - &quot;&quot;
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - apps
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - extensions
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - batch
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - rbac.authorization.k8s.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - apiregistration.k8s.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - apiextensions.k8s.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - tenant.kubesphere.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - certificates.k8s.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - devops.kubesphere.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - monitoring.coreos.com
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - logging.kubesphere.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - jaegertracing.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - storage.k8s.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - admissionregistration.k8s.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - policy
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - autoscaling
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - networking.istio.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - config.istio.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - iam.kubesphere.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - notification.kubesphere.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - auditing.kubesphere.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - events.kubesphere.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - core.kubefed.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - installer.kubesphere.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - storage.kubesphere.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - security.istio.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - monitoring.kiali.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - kiali.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - networking.k8s.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - kubeedge.kubesphere.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - types.kubefed.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - monitoring.kubesphere.io
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - application.kubesphere.io
  resources:
  - '*'
  verbs:
  - '*'


---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: ks-installer
subjects:
- kind: ServiceAccount
  name: ks-installer
  namespace: kubesphere-system
roleRef:
  kind: ClusterRole
  name: ks-installer
  apiGroup: rbac.authorization.k8s.io

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ks-installer
  namespace: kubesphere-system
  labels:
    app: ks-install
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ks-install
  template:
    metadata:
      labels:
        app: ks-install
    spec:
      serviceAccountName: ks-installer
      containers:
      - name: installer
        image: kubesphere/ks-installer:v3.2.1
        imagePullPolicy: &quot;Always&quot;
        resources:
          limits:
            cpu: &quot;1&quot;
            memory: 1Gi
          requests:
            cpu: 20m
            memory: 100Mi
        volumeMounts:
        - mountPath: /etc/localtime
          name: host-time
          readOnly: true
      volumes:
      - hostPath:
          path: /etc/localtime
          type: &quot;&quot;
        name: host-time
</code></pre>
<h5 id="15315-分别执行两个文件">1.5.3.1.5     分别执行两个文件</h5>
<pre><code class="language-shell">kubectl apply -f kubesphere-installer.yaml
kubectl apply -f cluster-configuration.yaml
#或者直接用网络文件安装
kubectl apply -f https://github.com/kubesphere/ks-installer/releases/download/v3.2.1/kubesphere-installer.yaml
   
kubectl apply -f https://github.com/kubesphere/ks-installer/releases/download/v3.2.1/cluster-configuration.yaml
</code></pre>
<h5 id="15316-监控安装的日志信息">1.5.3.1.6     监控安装的日志信息</h5>
<pre><code class="language-shell">kubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l app=ks-install -o jsonpath='{.items[0].metadata.name}') -f
</code></pre>
<h5 id="15317-查看pod启动状态信息">1.5.3.1.7     查看pod启动状态信息</h5>
<pre><code class="language-shell">kubectl get pods -A
</code></pre>
<p>需要等待漫长的时间。</p>
<h3 id="154-访问验证是否安装成功">1.5.4 访问验证是否安装成功</h3>
<p>访问地址：</p>
<p>http://192.168.40.131:30880/login</p>
<p>帐号：admin</p>
<p>密码：P@88w0rd</p>
<h3 id="155-harbor目录下重新启动harbor">1.5.5 harbor目录下重新启动harbor</h3>
<pre><code class="language-shell">docker-compose stop
docker-compose up -d
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[harbor自建镜像仓库]]></title>
        <id>https://tinaxiawuhao.github.io/post/WOO39eqh2/</id>
        <link href="https://tinaxiawuhao.github.io/post/WOO39eqh2/">
        </link>
        <updated>2022-05-29T13:51:16.000Z</updated>
        <content type="html"><![CDATA[<h2 id="centos网络配置">centos网络配置</h2>
<h3 id="1设置主机名">1.设置主机名</h3>
<pre><code class="language-shell">[root@localhost ~]# hostnamectl  set-hostname harbor
</code></pre>
<h3 id="2添加-host-解析">2.添加 Host 解析</h3>
<pre><code class="language-shell">[root@harbor ~]# cat /etc/hosts
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
192.168.40.131 k8s-master
192.168.40.132 k8s-node1
192.168.40.133 k8s-node2
192.168.40.150 hub.test.com
</code></pre>
<p><strong>k8s 集群每个节点添加解析（注意：K8s 每个节点，不是 Harbor）</strong></p>
<pre><code class="language-shell">[root@k8s-master ~]# echo &quot;192.168.40.150 hub.test.com&quot; &gt;&gt; /etc/hosts
[root@k8s-node1 ~]# echo &quot;192.168.40.150 hub.test.com&quot; &gt;&gt; /etc/hosts
[root@k8s-node2 ~]# echo &quot;192.168.40.150 hub.test.com&quot; &gt;&gt; /etc/hosts
</code></pre>
<h3 id="3网络环境设置">3.网络环境设置</h3>
<pre><code class="language-shell">vi /etc/sysconfig/network-scripts/ifcfg-ens33 
</code></pre>
<p><strong>内容替换如下：</strong></p>
<pre><code class="language-shell">BOOTPROTO=static #静态连接
ONBOOT=yes #网络设备开机启动
IPADDR=192.168.40.150 
NETMASK=255.255.255.0 #子网掩码
GATEWAY=192.168.40.2 #网关
DNS1=114.114.114.114 #DNS解析
</code></pre>
<p><strong>网络服务重启</strong></p>
<pre><code class="language-shell">service network restart
</code></pre>
<h2 id="安装环境">安装环境</h2>
<h3 id="1安装docker-ce">1.安装Docker-CE</h3>
<pre><code class="language-shell"># 卸载旧版本
yum remove docker docker-client docker-client-latest docker-common docker-latest docker-latest-logrotate docker-logrotate docker-engine  
# 安装所需的软件包
yum install -y yum-utils device-mapper-persistent-data lvm2    
# 添加docker存储库
yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo     
#安装最新版的docker-ce
yum install -y docker-ce docker-ce-cli containerd.io    
#启动docker并设置为开机自启动
systemctl enable --now docker    
</code></pre>
<h3 id="2配置docker镜像加速器">2.配置Docker镜像加速器</h3>
<pre><code class="language-bash">tee /etc/docker/daemon.json &lt;&lt;-'EOF'
{
  &quot;registry-mirrors&quot;: [&quot;https://hub-mirror.c.163.com/&quot;],
  &quot;insecure-registries&quot;: [&quot;https://hub.test.com&quot;]
}
EOF
# 重启
systemctl daemon-reload &amp;&amp; systemctl restart docker
</code></pre>
<h3 id="3安装docker-compose">3.安装docker-compose</h3>
<pre><code class="language-shell">#1、安装pip
yum -y install epel-release
yum install python3-pip
pip3 install --upgrade pip
#2、安装docker-compose
pip3 install docker-compose
#3、查看版本
docker-compose version
</code></pre>
<h3 id="4创建-https-证书">4.创建 https 证书</h3>
<p><strong>安装 openssl</strong></p>
<pre><code class="language-shell">[root@harbor]# yum install openssl -y
</code></pre>
<p><strong>创建证书目录，并赋予权限</strong></p>
<pre><code class="language-shell">[root@harbor ~]# mkdir -p /cert/harbor
[root@harbor ~]# chmod -R 777 /cert/harbor
[root@harbor ~]# cd /cert/harbor
</code></pre>
<p><strong>创建服务器证书密钥文件 harbor.key</strong></p>
<pre><code class="language-shell">[root@harbor harbor]# openssl genrsa -des3 -out harbor.key 2048
</code></pre>
<blockquote>
<p>输入密码，确认密码，自己随便定义，但是要记住，后面会用到。</p>
</blockquote>
<p><strong>创建服务器证书的申请文件 harbor.csr</strong></p>
<pre><code class="language-shell">[root@harbor harbor]# openssl req -new -key harbor.key -out harbor.csr
</code></pre>
<blockquote>
<p>输入密钥文件的密码, 然后一路回车。</p>
</blockquote>
<p><strong>备份一份服务器密钥文件</strong></p>
<pre><code class="language-shell">[root@harbor harbor]# cp harbor.key harbor.key.org
</code></pre>
<p><strong>去除文件口令</strong></p>
<pre><code class="language-shell">[root@harbor harbor]# openssl rsa -in harbor.key.org -out harbor.key
</code></pre>
<blockquote>
<p>输入密钥文件的密码</p>
</blockquote>
<p><strong>创建一个自当前日期起为期十年的证书 harbor.crt</strong></p>
<pre><code class="language-shell">[root@harbor harbor]# openssl x509 -req -days 3650 -in harbor.csr -signkey harbor.key -out harbor.crt
</code></pre>
<h3 id="5下载harbor安装包并解压">5.下载Harbor安装包并解压</h3>
<blockquote>
<p>链接：https://pan.baidu.com/s/1AUEw0Qw3w9lZP-rnAYaWjA<br>
提取码：qutg</p>
</blockquote>
<pre><code class="language-shell">wget https://github.com/goharbor/harbor/releases/download/v2.5.0/harbor-offline-installer-v2.5.0.tgz
tar zxvf harbor-offline-installer-v2.5.0.tgz
</code></pre>
<h3 id="6配置harborcfg和安装harbor">6.配置harbor.cfg和安装Harbor</h3>
<pre><code class="language-bash">vi harbor.yml
</code></pre>
<blockquote>
<p>将http端口改成10086，因为默认用的80端口已经被占用，http可以指定任意端口；</p>
</blockquote>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1654235318168.png" alt="" loading="lazy"></figure>
<p>接下来运行install.sh安装和启动harbor</p>
<pre><code class="language-shell">./prepare
./install.sh
</code></pre>
<h3 id="7测试-harbor">7.测试 Harbor</h3>
<pre><code class="language-shell">[root@k8s-master01 ~]# docker login https://hub.test.com
Username: admin
Password: Harbor12345 # 默认密码，可通过 harbor.yml 配置文件修改
</code></pre>
<p><strong>登录时报：Error response from daemon: Get https://hub.test.com/v2/: x509: certificate is not valid for any names, but wanted to match hub.test.com</strong><br>
解决：修改客户端（即需要登陆harbor的机器）的docker.service 文件</p>
<pre><code class="language-shell">vi /lib/systemd/system/docker.service
添加 --insecure-registry hub.test.com 
</code></pre>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1654236299657.png" alt="" loading="lazy"></figure>
<p>重新加载服务配置文件，并且重启docker服务</p>
<pre><code class="language-shell">systemctl daemon-reload &amp;&amp; systemctl restart docker
</code></pre>
<p>下载镜像推送到 Harbor</p>
<pre><code class="language-shell">[root@k8s-node01 ~]# docker pull nginx
[root@k8s-node01 ~]# docker tag nginx:latest hub.test.com/library/test:v1
[root@k8s-node01 ~]# docker push hub.test.com/library/test:v1
</code></pre>
<h3 id="8windows-访问-harbor-web界面">8.Windows 访问 Harbor Web界面</h3>
<p><strong>Windows 添加 hosts 解析路径</strong></p>
<pre><code class="language-shell">C:\Windows\System32\drivers\etc\hosts
</code></pre>
<p><strong>添加信息</strong></p>
<pre><code class="language-shell">192.168.40.150 hub.test.com
</code></pre>
<p><strong>浏览器访问测试</strong></p>
<blockquote>
<p><a href="https://hub.test.com/harbor/projects">https://hub.test.com</a></p>
</blockquote>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1654235306601.png" alt="" loading="lazy"></figure>
<blockquote>
<p>用户密码：admin / Harbor12345</p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[k8s1.24.1安装（基于Centos 7）]]></title>
        <id>https://tinaxiawuhao.github.io/post/oqAZb-4wU/</id>
        <link href="https://tinaxiawuhao.github.io/post/oqAZb-4wU/">
        </link>
        <updated>2022-05-28T09:26:47.000Z</updated>
        <content type="html"><![CDATA[<p><strong>注意：除了Master节点初始化及Node节点添加分别在Master节点和Node节点执行外，其余所有命令均在所有节点执行</strong></p>
<h2 id="整体环境">整体环境</h2>
<p>一台master节点，2台<a href="https://so.csdn.net/so/search?q=node&amp;spm=1001.2101.3001.7020">node</a>节点。采用了Centos 7，有网络，互相可以ping通。</p>
<h3 id="1内核升级可忽略">1.内核升级（可忽略）</h3>
<p>为避免出现不可预知的问题，提升centos 7内核到最新版本</p>
<h4 id="联网升级内核">联网升级内核</h4>
<h5 id="1-查看内核版本">1. 查看内核版本</h5>
<pre><code class="language-shell">uname -r
</code></pre>
<h5 id="2-导入elrepo软件仓库的公共秘钥">2. 导入ELRepo软件仓库的公共秘钥</h5>
<pre><code class="language-shell">rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org
</code></pre>
<h5 id="3-安装elrepo软件仓库的yum源">3. 安装ELRepo软件仓库的yum源</h5>
<pre><code class="language-shell">rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm
</code></pre>
<h5 id="4-启用-elrepo-软件源并下载安装最新稳定版内核">4. 启用 elrepo 软件源并下载安装最新稳定版内核</h5>
<pre><code class="language-shell">yum --enablerepo=elrepo-kernel install kernel-ml -y
</code></pre>
<h5 id="5-查看系统可用内核并设置内核启动顺序">5. 查看系统可用内核，并设置内核启动顺序</h5>
<pre><code class="language-shell">sudo awk -F\' '$1==&quot;menuentry &quot; {print i++ &quot; : &quot; $2}' /etc/grub2.cfg
</code></pre>
<h5 id="6-生成-grub-配置文件">6. 生成 grub 配置文件</h5>
<p>机器上存在多个内核，我们要使用最新版本，可以通过 grub2-set-default 0 命令生成 grub 配置文件</p>
<pre><code class="language-shell">grub2-set-default 0 　　#初始化页面的第一个内核将作为默认内核
grub2-mkconfig -o /boot/grub2/grub.cfg　　#重新创建内核配置
</code></pre>
<h5 id="7-重启系统并验证">7. 重启系统并验证</h5>
<pre><code class="language-shell">yum update
reboot
uname -r
</code></pre>
<h5 id="8-删除旧内核">8. 删除旧内核</h5>
<pre><code class="language-shell">yum -y remove kernel kernel-tools
</code></pre>
<h3 id="2centos网络配置文件">2.centos网络配置文件</h3>
<p>网络配置文件名可能会有不同，在输入到ifcfg时，可以连续按两下tab键，获取提示，比如我的机器 为 ifcfg-ens33</p>
<pre><code class="language-shell">vi /etc/sysconfig/network-scripts/ifcfg-ens33 
</code></pre>
<h4 id="1内容替换如下">1.内容替换如下：</h4>
<pre><code class="language-shell">BOOTPROTO=static #静态连接
ONBOOT=yes #网络设备开机启动
IPADDR=192.168.40.131 #192.168.40.132,192.168.40.133.
NETMASK=255.255.255.0 #子网掩码
GATEWAY=192.168.40.2 #网关
DNS1=114.114.114.114 #DNS解析
</code></pre>
<h4 id="2网络服务重启">2.网络服务重启</h4>
<pre><code class="language-shell">service network restart
</code></pre>
<h4 id="3查看ip地址">3.查看IP地址</h4>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1653818770568.png" alt="" loading="lazy"></figure>
<h3 id="3安装依赖包">3.安装依赖包</h3>
<pre><code class="language-shell">yum install -y  wget 
</code></pre>
<h3 id="4修改yum源视网络情况操作">4.修改yum源（视网络情况操作）</h3>
<h4 id="1备份">1.备份</h4>
<pre><code class="language-shell">cp /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup
</code></pre>
<h4 id="2下载">2.下载</h4>
<pre><code class="language-shell">wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo
</code></pre>
<p>或者使用清华大学站</p>
<pre><code class="language-shell">sudo sed -e 's|^mirrorlist=|#mirrorlist=|g' -e 's|^#baseurl=http://mirror.centos.org/$contentdir|baseurl=https://mirrors.tuna.tsinghua.edu.cn/centos|g' -i.bak /etc/yum.repos.d/CentOS-Base.repo
</code></pre>
<h4 id="3清除生成缓存">3.清除生成缓存</h4>
<pre><code class="language-shell">yum clean all     # 清除系统所有的yum缓存
yum makecache     # 生成yum缓存
</code></pre>
<h3 id="5修改主机名">5.修改主机名</h3>
<pre><code class="language-shell">hostnamectl set-hostname k8s-master
hostnamectl set-hostname k8s-node1
hostnamectl set-hostname k8s-node2
</code></pre>
<h4 id="查看主机名称">查看主机名称</h4>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1653818810010.png" alt="" loading="lazy"></figure>
<h3 id="6添加hosts解析">6.添加hosts解析</h3>
<pre><code class="language-shell">echo -e &quot;192.168.40.131 k8s-master\n192.168.40.132 k8s-node1\n192.168.40.133 k8s-node2&quot; &gt;&gt; /etc/hosts
</code></pre>
<h3 id="7关闭防火墙firewalld">7.关闭防火墙firewalld</h3>
<pre><code class="language-shell">systemctl stop firewalld &amp;&amp; systemctl disable firewalld
</code></pre>
<h3 id="8关闭selinux">8.关闭selinux</h3>
<pre><code class="language-shell">setenforce 0 &amp;&amp; sed -i 's/^SELINUX=.*/SELINUX=disabled/' /etc/selinux/config
</code></pre>
<h3 id="9关闭swap分区交换">9.关闭swap分区交换</h3>
<pre><code class="language-shell">swapoff -a &amp;&amp; sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab
</code></pre>
<h3 id="10配置内核参数">10.配置内核参数</h3>
<p><strong>将桥接的IPv4流量传递倒iptables的链</strong></p>
<h4 id="1设置内核参数">1.设置内核参数</h4>
<pre><code class="language-shell">cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt;EOF
net.bridge.bridge-nf-call-iptables=1
net.bridge.bridge-nf-call-ip6tables=1
net.ipv4.ip_forward=1
net.ipv4.tcp_tw_recycle=0
vm.swappiness=0 # 禁止使用swap空间，只有当系统00M时才允许使用它
vm.overcommit_memory=1 # 不检查物理内存是否够用
vm.panic_on_oom=0 # 开启oom
fs.inotify.max_user_instances=8192
fs.inotify.max_user_watches=1048576
fs.file-max=52786963
fs.nr_open=52706963
net.ipv6.conf.all.disable_ipv6=1
net.netfilter.nf_conntrack_max=2310720
EOF
</code></pre>
<h4 id="2加载内核模块">2.加载内核模块</h4>
<pre><code class="language-shell">modprobe br_netfilter &amp;&amp; echo &quot;modprobe br_netfilter&quot; &gt;&gt; /etc/rc.local
</code></pre>
<h4 id="3使内核参数生效">3.使内核参数生效</h4>
<pre><code class="language-shell">sysctl -p /etc/sysctl.d/k8s.conf
</code></pre>
<h3 id="11时间同步">11.时间同步</h3>
<pre><code class="language-shell">timedatectl set-timezone Asia/Shanghai &amp;&amp; timedatectl set-local-rtc 0
#重启依赖于系统时间的服务 
systemctl restart rsyslog &amp;&amp; systemctl restart crond
</code></pre>
<h3 id="12安装iptables设置空表">12.安装iptables，设置空表</h3>
<pre><code class="language-shell">yum -y install iptables-services &amp;&amp; systemctl start iptables &amp;&amp; systemctl enable iptables &amp;&amp; iptables -F &amp;&amp; service iptables save
</code></pre>
<p>检查服务的的规则：<code>iptables -L -n</code></p>
<h3 id="13开启ipvs">13.开启IPVS</h3>
<p><strong>由于ipvs已经加入到了内核的主干，所以为kube-proxy开启ipvs的前提需要加载以下的内核模块</strong></p>
<pre><code class="language-shell">cat &gt; /etc/sysconfig/modules/ipvs.modules &lt;&lt;EOF
#！/bin/bash
modprobe -- ip_vs
modprobe -- ip_vs_rr
modprobe -- ip_vs_wrr
modprobe -- ip_vs_sh
modprobe -- nf_conntrack_ipv4
EOF
</code></pre>
<h4 id="授权启动">授权启动</h4>
<pre><code class="language-shell">chmod 755 /etc/sysconfig/modules/ipvs.modules &amp;&amp; bash /etc/sysconfig/modules/ipvs.modules &amp;&amp; lsmod 
</code></pre>
<p><strong>接下来还需要确保各个节点上已经安装了ipset软件包。 为了便于查看ipvs的代理规则，最好安装一下管理工具ipvsadm。</strong></p>
<pre><code class="language-shell">yum install ipset ipvsadm -y
</code></pre>
<blockquote>
<p>service底层实现主要由两个网络模式组成：iptables与IPVS。他们都是有kube-proxy维护</p>
<p><strong>Iptables VS IPVS</strong></p>
<p><strong>Iptables：</strong></p>
<p><strong>• 灵活，功能强大</strong></p>
<p><strong>• 规则遍历匹配和更新，呈线性时延</strong></p>
<p><strong>IPVS：</strong></p>
<p><strong>• 工作在内核态，有更好的性能</strong></p>
<p><strong>• 调度算法丰富：rr，wrr，lc，wlc，ip hash</strong></p>
</blockquote>
<p>等集群部署成功，mode由空值修改成ipvs模式</p>
<pre><code>kubectl edit configmap kube-proxy -n kube-system configmap/kube-proxy edited
</code></pre>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1654316987021.png" alt="" loading="lazy"></figure>
<p><strong>删除所有kube-proxy的pod,等待重启</strong></p>
<pre><code>kubectl delete pod/kube-proxy-84p9n -n kube-system
# 查看ipvs相关规则
ipvsadm
</code></pre>
<h3 id="14安装docker软件">14.安装docker软件</h3>
<blockquote>
<p>自1.20版本被弃用之后，dockershim组件终于在1.24的kubelet中被删除。从1.24开始，大家需要使用其他受到支持的运行时选项（例如containerd或CRI-O）；如果您选择Docker Engine作为运行时，则需要使用cri-dockerd。</p>
</blockquote>
<h4 id="1删除自带的docker">1.删除自带的docker</h4>
<pre><code class="language-shell">yum remove docker \
                  docker-client \
                  docker-client-latest \
                  docker-common \
                  docker-latest \
                  docker-latest-logrotate \
                  docker-logrotate \
                  docker-selinux \
                  docker-engine-selinux \
                  docker-engine
</code></pre>
<h4 id="2安装依赖包">2.安装依赖包</h4>
<pre><code class="language-shell">yum install -y yum-utils device-mapper-persistent-data lvm2
</code></pre>
<h4 id="3安装yum源">3.安装yum源</h4>
<pre><code class="language-shell">yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
</code></pre>
<h4 id="4安装docker-ce">4.安装docker-ce</h4>
<pre><code class="language-shell">yum -y install docker-ce
</code></pre>
<h4 id="5设置docker">5.设置docker</h4>
<pre><code class="language-shell">cat &gt; /etc/docker/daemon.conf &lt;&lt;EOF
{
  &quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;,&quot;https://heusyzko.mirror.aliyuncs.com&quot;],
  &quot;insecure-registries&quot;: [&quot;https://hub.test.com&quot;],
  &quot;exec-opts&quot;:[&quot;native.cgroupdriver=systemd&quot;],
  &quot;log-driver&quot;:&quot;json-file&quot;,
  &quot;log-opts&quot;:{
    &quot;max-size&quot;: &quot;100m&quot;
    },
    &quot;storage-driver&quot;: &quot;overlay2&quot;
}
EOF

mkdir -p /etc/systemd/system/docker.service.d 
</code></pre>
<h4 id="6重启docker服务">6.重启docker服务</h4>
<pre><code class="language-shell">systemctl daemon-reload &amp;&amp; systemctl start docker &amp;&amp; systemctl enable docker
systemctl daemon-reload &amp;&amp; systemctl restart docker 
</code></pre>
<p>以下的NO_PROXY表示对这些网段的服务器不使用代理，如果不需要用到代理服务器，以下的配置可以不写，注意，以下的代理是不通的。不建议使用代理，因为国内有资源可以访问到gcr.io需要的镜像，下文会介绍</p>
<pre><code class="language-shell">#放在Type=notify下面
vi /usr/lib/systemd/system/docker.service
Environment=&quot;HTTPS_PROXY=http://www.ik8s.io:10080&quot;
Environment=&quot;HTTP_PROXY=http://www.ik8s.io:10080&quot;
Environment=&quot;NO_PROXY=127.0.0.0/8,172.20.0.0/16&quot;
#保存退出后，执行
systemctl  daemon-reload
#确保如下两个参数值为1，默认为1。
 cat /proc/sys/net/bridge/bridge-nf-call-ip6tables
 cat /proc/sys/net/bridge/bridge-nf-call-iptables
#启动docker-ce
systemctl restart docker
#设置开机启动
systemctl enable docker.service
</code></pre>
<pre><code class="language-shell">#想要删除容器，则要先停止所有容器（当然，也可以加-f强制删除，但是不推荐）：
docker stop $(docker ps -a -q)
#删除所有容器
docker  rm $(docker ps -a -q)
#.删除所有镜像（慎重）
docker rmi $(docker images -q)
</code></pre>
<h3 id="142cri-dockerd安装">14.2.cri-dockerd安装</h3>
<p><strong>CRI-Dockerd 其实就是从被移除的 Docker Shim 中，独立出来的一个项目，用于解决历史遗留的节点升级 Kubernetes 的问题。</strong></p>
<blockquote>
<p>kubelet并没有直接和dockerd交互，而是通过了一个dockershim的组件间接操作dockerd。dockershim提供了一个标准的接口，让kubelet能够专注于容器调度逻辑本身，而不用去适配dockerd的接口变动。而其他实现了相同标准接口的容器技术也可以被kubelet集成使用，这个接口称作CRI。dockershim和CRI的出现也是容器生态系统演化的历史产物。在k8s最早期的版本中是不存在dockershim的，kubelet直接和dockerd交互。但为了支持更多不同的容器技术（避免完全被docker控制容器技术市场），kubelet在之后的版本开始支持另一种容器技术rkt。这给kubelet的维护工作造成了巨大的挑战，因为两种容器技术没有统一的接口和使用逻辑，kubelet同时支持两种技术的使用还要保证一致的容器功能表现，对代码逻辑和功能可靠性都有很大的影响。为了解决这个问题，k8s提出了一个统一接口CRI，kubelet统一通过这个接口来调用容器功能。但是dockerd并不支持CRI，k8s就自己实现了配套的dockershim将CRI接口调用转换成dockerd接口调用来支持CRI。因此，dockershim并不是docker技术的一部分，而是k8s系统的一部分</p>
</blockquote>
<p><strong>使用 CRI-Dockerd 项目</strong></p>
<pre><code class="language-html">项目地址：https://github.com/Mirantis/cri-dockerd
</code></pre>
<h4 id="1下载cri-dockerd二进制包或者源码自己编译">1.下载cri-dockerd二进制包或者源码自己编译</h4>
<pre><code class="language-shell"># 下载文件
wget https://github.com/Mirantis/cri-dockerd/releases/download/v0.2.0/cri-dockerd-v0.2.0-linux-amd64.tar.gz
# 解压文件
tar -xvf cri-dockerd-v0.2.0-linux-amd64.tar.gz
# 复制二进制文件到指定目录
cp cri-dockerd /usr/bin/
</code></pre>
<h4 id="2配置启动文件">2.配置启动文件</h4>
<pre><code class="language-shell"># 配置启动文件
cat &lt;&lt;&quot;EOF&quot; &gt; /usr/lib/systemd/system/cri-docker.service
[Unit]
Description=CRI Interface for Docker Application Container Engine
Documentation=https://docs.mirantis.com
After=network-online.target firewalld.service docker.service
Wants=network-online.target
Requires=cri-docker.socket

[Service]
Type=notify

ExecStart=/usr/bin/cri-dockerd --container-runtime-endpoint=unix:///var/run/cri-docker.sock --network-plugin=cni --cni-bin-dir=/opt/cni/bin \
          --cni-conf-dir=/etc/cni/net.d --image-pull-progress-deadline=30s --pod-infra-container-image=registry.aliyuncs.com/google_containers/pause:3.7 \
          --docker-endpoint=unix:///var/run/docker.sock --cri-dockerd-root-directory=/var/lib/docker
ExecReload=/bin/kill -s HUP $MAINPID
TimeoutSec=0
RestartSec=2
Restart=always

# Note that StartLimit* options were moved from &quot;Service&quot; to &quot;Unit&quot; in systemd 229.
# Both the old, and new location are accepted by systemd 229 and up, so using the old location
# to make them work for either version of systemd.
StartLimitBurst=3

# Note that StartLimitInterval was renamed to StartLimitIntervalSec in systemd 230.
# Both the old, and new name are accepted by systemd 230 and up, so using the old name to make
# this option work for either version of systemd.
StartLimitInterval=60s

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Comment TasksMax if your systemd version does not support it.
# Only systemd 226 and above support this option.
TasksMax=infinity
Delegate=yes
KillMode=process

[Install]
WantedBy=multi-user.target

EOF
</code></pre>
<pre><code class="language-shell"># 生成socket 文件
cat &lt;&lt;&quot;EOF&quot; &gt; /usr/lib/systemd/system/cri-docker.socket
[Unit]
Description=CRI Docker Socket for the API
PartOf=cri-docker.service

[Socket]
ListenStream=/var/run/cri-dockerd.sock
SocketMode=0660
SocketUser=root
SocketGroup=docker

[Install]
WantedBy=sockets.target

EOF
</code></pre>
<pre><code class="language-shell"># 启动 cri-dockerd
systemctl daemon-reload
systemctl start cri-docker
#设置开机启动
systemctl enable cri-docker
# 查看启动状态
systemctl status cri-docker
</code></pre>
<h4 id="3下载cri-tools验证cri-docker-是否正常">3.下载cri-tools验证cri-docker 是否正常</h4>
<pre><code class="language-shell"># 下载二进制文件
wget https://github.com/kubernetes-sigs/cri-tools/releases/download/v1.24.0/crictl-v1.24.0-linux-amd64.tar.gz
# 解压
tar -xvf crictl-v1.24.0-linux-amd64.tar.gz
# 复制二进制文件到指定目录
cp crictl /usr/bin/
# 创建配置文件
vim /etc/crictl.yaml
runtime-endpoint: &quot;unix:///var/run/cri-docker.sock&quot;
image-endpoint: &quot;unix:///var/run/cri-docker.sock&quot;
timeout: 10
debug: false
pull-image-on-create: true
disable-pull-on-run: false
# 测试能否访问docker
# 查看运行的容器
crictl ps
# 查看拉取的镜像
 crictl images
 # 拉取镜像
 crictl pull busybox
 [root@k8s-node-4 ~]# crictl pull busybox
Image is up to date for busybox@sha256:5ecba83a746c7608ed511dc1533b87c737a0b0fb730301639a0179f9344b13448
返回一切正常cri-dockerd接入docker完整
</code></pre>
<h3 id="15部署-containerdk8s-124版本以上">15.部署 containerd(k8s-1.24版本以上)</h3>
<p><strong>服务版本</strong></p>
<table>
<thead>
<tr>
<th>服务名称</th>
<th>版本号</th>
</tr>
</thead>
<tbody>
<tr>
<td>内核</td>
<td>5.14.3-1.el7.elrepo.x86_64</td>
</tr>
<tr>
<td>containerd</td>
<td>v1.6.4（加入）</td>
</tr>
<tr>
<td>ctr</td>
<td>v1.6.4</td>
</tr>
<tr>
<td>k8s</td>
<td>1.24</td>
</tr>
</tbody>
</table>
<h4 id="1安装containerd">1.安装containerd</h4>
<p><strong>创建配置文件</strong></p>
<pre><code class="language-shell">mkdir /etc/modules-load.d/containerd.conf 
</code></pre>
<p><strong>创建完配置文件执行以下命令</strong></p>
<pre><code class="language-shell">modprobe overlay &amp;&amp; modprobe br_netfilter
</code></pre>
<p><strong>立即生效</strong></p>
<pre><code class="language-shell">sysctl --system
</code></pre>
<p><strong>下载 docker-ce 源</strong></p>
<pre><code class="language-shell">wget http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
或者
yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
</code></pre>
<p><strong>安装 containerd 服务并加入开机启动</strong></p>
<pre><code class="language-shell">yum install -y containerd.io
systemctl enable containerd &amp;&amp; systemctl start containerd
</code></pre>
<h4 id="2配置-containerd">2.配置 containerd</h4>
<p><strong>创建路径</strong></p>
<pre><code class="language-shell">mkdir -p /etc/containerd
</code></pre>
<p><strong>获取默认配置文件</strong></p>
<pre><code class="language-shell">containerd config default | sudo tee /etc/containerd/config.toml
</code></pre>
<p><strong>修改配置文件，新增 &quot;SystemdCgroup = true&quot;，使用 systemd 作为 cgroup 驱动程序</strong></p>
<pre><code class="language-shell">[root@master1 ~]# vi /etc/containerd/config.toml 
#修改以下内容
[plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.runc.options]
     SystemdCgroup = true                               ## 修改为true
</code></pre>
<p><strong>替换默认pause镜像地址</strong></p>
<p>默认情况下k8s.gcr.io无法访问，所以使用阿里云镜像仓库地址即可</p>
<pre><code class="language-shell"># 所有节点更换默认镜像地址
sed -i 's/k8s.gcr.io/registry.cn-beijing.aliyuncs.com\/abcdocker/' /etc/containerd/config.toml 
</code></pre>
<p><strong>重启 containerd</strong></p>
<pre><code class="language-shell">systemctl restart containerd
</code></pre>
<p><strong>查看 containerd 运行状态(以下状态视为正常)</strong></p>
<pre><code class="language-shell">[root@master1 ~]# systemctl status containerd
● containerd.service - containerd container runtime
   Loaded: loaded (/usr/lib/systemd/system/containerd.service; enabled; vendor preset: disabled)
   Active: active (running) since Sun 2022-03-06 08:09:00 CST; 1h 43min ago
     Docs: https://containerd.io
  Process: 931 ExecStartPre=/sbin/modprobe overlay (code=exited, status=0/SUCCESS)
 Main PID: 941 (containerd)
    Tasks: 11
   Memory: 61.4M
   CGroup: /system.slice/containerd.service
           └─941 /usr/bin/containerd
</code></pre>
<h3 id="16安装kubeadm-kubelet-kubectl">16.安装kubeadm、kubelet、kubectl</h3>
<h4 id="1配置文件修改">1.配置文件修改</h4>
<pre><code class="language-shell">cat &lt;&lt;EOF | sudo tee /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=0
repo_gpgcheck=0
gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF
</code></pre>
<h4 id="2安装启用">2.安装启用</h4>
<pre><code class="language-shell">sudo yum install -y kubelet-1.24.1 kubeadm-1.24.1 kubectl-1.24.1 --disableexcludes=kubernetes 
sudo systemctl enable kubelet &amp;&amp; systemctl start kubelet
</code></pre>
<h4 id="3修改kubelet的配置文件">3.修改kubelet的配置文件</h4>
<p>先查看配置文件位置</p>
<pre><code class="language-shell">systemctl status kubelet
</code></pre>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1653818855680.png" alt="" loading="lazy"></figure>
<pre><code class="language-shell">vi /usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf
</code></pre>
<p>并添加以下内容(使用和docker相同的cgroup-driver)。</p>
<pre><code class="language-shell">Environment=&quot;KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --cgroup-driver=systemd&quot;
</code></pre>
<h4 id="4重启kubelet">4.重启kubelet</h4>
<pre><code class="language-shell">systemctl daemon-reload &amp;&amp; systemctl restart kubelet
</code></pre>
<h3 id="17获取k8s镜像可忽略">17.获取K8S镜像（可忽略）</h3>
<h4 id="1获取镜像列表">1.获取镜像列表</h4>
<p><strong>使用阿里云镜像仓库下载（国内环境该命令可不执行，下步骤kubeadm init --image-repository registry.cn-hangzhou.aliyuncs.com/google_containers已经默认为国内环境）</strong></p>
<p>由于官方镜像地址被墙，所以我们需要首先获取所需镜像以及它们的版本。然后从国内镜像站获取。</p>
<pre><code class="language-bash">kubeadm config images list
</code></pre>
<p>获取镜像列表后可以通过下面的脚本从阿里云获取：</p>
<pre><code class="language-shell">vi /usr/local/k8s/k8s-images.sh
</code></pre>
<blockquote>
<p>下面的镜像应该去除&quot;k8s.gcr.io/&quot;的前缀，版本换成上面获取到的版本</p>
</blockquote>
<pre><code class="language-bash">images=(  
    kube-apiserver:v1.24.1
    kube-controller-manager:v1.24.1
    kube-scheduler:v1.24.1
    kube-proxy:v1.24.1
    pause:3.7
    etcd:3.5.3-0
    coredns:v1.8.6
)

for imageName in ${images[@]} ; do
    docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName
    docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName k8s.gcr.io/$imageName
    docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName
done
</code></pre>
<h4 id="2赋权执行">2.赋权执行</h4>
<pre><code class="language-shell">chmod +x k8s-images.sh &amp;&amp; ./k8s-images.sh
</code></pre>
<p><strong>以上操作在所有机器执行</strong></p>
<h3 id="18初始化环境master操作">18.初始化环境（master操作）</h3>
<h4 id="1安装镜像">1.安装镜像</h4>
<p><strong>采用模板配置文件加载</strong></p>
<pre><code class="language-shell">kubeadm config print init-defaults  &gt; kubeadm-config.yaml
</code></pre>
<pre><code class="language-yaml">
[root@master1 ~]# cat kubeadm-config.yaml 
apiVersion: kubeadm.k8s.io/v1beta2
bootstrapTokens:
- groups:
  - system:bootstrappers:kubeadm:default-node-token
  token: abcdef.0123456789abcdef
  ttl: 24h0m0s
  usages:
  - signing
  - authentication
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 192.168.40.131    # 本机IP
  bindPort: 6443
nodeRegistration:
  criSocket: unix:///var/run/cri-docker.sock  # 此处千万不要忘记修改，如果不修改等于没有替换。(此处已经更改完了)
  #criSocket: unix:///run/containerd/containerd.sock      # 此处千万不要忘记修改，如果不修改等于没有替换。(此处已经更改完了)
  name: master1        # 本主机名
  taints:
  - effect: NoSchedule
    key: node-role.kubernetes.io/master
---
apiServer:
  timeoutForControlPlane: 4m0s
apiVersion: kubeadm.k8s.io/v1beta2
certificatesDir: /etc/kubernetes/pki
clusterName: kubernetes
controlPlaneEndpoint: &quot;192.168.40.151:16443&quot;      # 虚拟IP和haproxy端口
controllerManager: {}
dns:
  type: CoreDNS
etcd:
  local:
    dataDir: /var/lib/etcd
imageRepository: registry.aliyuncs.com/google_containers    # 镜像仓库源要根据自己实际情况修改
kind: ClusterConfiguration
kubernetesVersion: v1.24.1     # k8s版本
networking:
  dnsDomain: cluster.local
  podSubnet: &quot;10.244.0.0/16&quot;   #设置网段，和下面网络插件对应
  serviceSubnet: 10.96.0.0/12
scheduler: {}
 
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
featureGates:
  SupportIPVSProxyMode: true
mode: ipvs
</code></pre>
<h4 id="2查看kubeadm版本修改命令参数">2.查看kubeadm版本，修改命令参数</h4>
<pre><code class="language-shell">kubeadm version
</code></pre>
<p>这个就很简单了，只需要简单的一个命令：</p>
<pre><code class="language-bash">#直接使用已经下载好的镜像
kubeadm init --kubernetes-version=v1.24.1 --apiserver-advertise-address=192.168.40.131 --pod-network-cidr=10.244.0.0/16 --service-cidr=10.96.0.0/12 --ignore-preflight-errors=Swap  --cri-socket unix:///var/run/cri-docker.sock | tee kubeadm-init.log
#或者采用aliyuncs镜像下载
kubeadm init --kubernetes-version=v1.24.1 --apiserver-advertise-address=192.168.40.131 --image-repository  registry.aliyuncs.com/google_containers  --service-cidr=10.1.0.0/16 --pod-network-cidr=10.244.0.0/16 --cri-socket unix:///var/run/cri-docker.sock| tee kubeadm-init.log
#使用上面系统生成配置文件加载
kubeadm init --config kubeadm-config.yaml
</code></pre>
<h4 id="3初始化命令说明">3.初始化命令说明：</h4>
<blockquote>
<p>指明用 Master 的哪个 interface 与 Cluster 的其他节点通信。如果 Master 有多个 interface，建议明确指定，如果不指定，kubeadm 会自动选择有默认网关的 interface。</p>
</blockquote>
<pre><code class="language-bash">--apiserver-advertise-address
</code></pre>
<blockquote>
<p>指定 Pod 网络的范围。Kubernetes 支持多种网络方案，而且不同网络方案对 --pod-network-cidr 有自己的要求，这里设置为 10.244.0.0/16 是因为我们将使用 flannel 网络方案，必须设置成这个 CIDR。</p>
</blockquote>
<pre><code class="language-bash">--pod-network-cidr
</code></pre>
<blockquote>
<p>Kubenetes默认Registries地址是 k8s.gcr.io，在国内并不能访问 gcr.io，在1.19.3版本中我们可以增加–image-repository参数，默认值是 k8s.gcr.io，将其指定为阿里云镜像地址：registry.aliyuncs.com/google_containers。</p>
</blockquote>
<pre><code class="language-bash">--image-repository
</code></pre>
<blockquote>
<p>关闭版本探测，因为它的默认值是stable-1，会导致从https://dl.k8s.io/release/stable-1.txt下载最新的版本号，我们可以将其指定为固定版本（最新版：v1.24.1）来跳过网络请求。</p>
</blockquote>
<pre><code class="language-bash">--kubernetes-version=v1.24.1 
</code></pre>
<blockquote>
<p>指定启动时使用cri-docker调用docker</p>
</blockquote>
<pre><code class="language-shell">--cri-socket unix:///var/run/cri-docker.sock 
</code></pre>
<h4 id="4错误启动重置">4.错误启动重置</h4>
<pre><code class="language-shell"># 重置 如果有需要
kubeadm reset --cri-socket unix:///var/run/cri-docker.sock
</code></pre>
<h4 id="5初始化成功后为顺利使用kubectl执行以下命令">5.初始化成功后，为顺利使用kubectl，执行以下命令：</h4>
<pre><code class="language-shell">mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
</code></pre>
<h4 id="6添加节点">6.添加节点</h4>
<pre><code class="language-shell">kubeadm join 192.168.40.131:6443 --token eyr8v6.j84sxak8aptse8j9 --discovery-token-ca-cert-hash sha256:c082f3c546bdbac02d0d0a3b696de4004b0d449e37838fa38d4752b39682676b --cri-socket unix:///var/run/cri-docker.sock 
</code></pre>
<h4 id="7执行kubectl-get-nodes查看master节点状态">7.执行kubectl get nodes，查看master节点状态：</h4>
<pre><code class="language-shell">kubectl get node
</code></pre>
<h4 id="8通过如下命令查看kubelet状态">8.通过如下命令查看kubelet状态：</h4>
<pre><code class="language-bash">journalctl -xef -u kubelet -n 20
</code></pre>
<p>提示未安装cni 网络插件。</p>
<h3 id="191安装flannel网络插件cni">19.1安装flannel网络插件(CNI)</h3>
<p>master执行以下命令安装flannel即可：</p>
<pre><code class="language-shell">kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
</code></pre>
<p>kube-flannel.yaml文件中的net-conf.json-&gt;Network地址默认为命令中–pod-network-cidr=值相同</p>
<p><strong>输入命令kubectl get pods -n kube-system,等待所有插件为running状态</strong>。</p>
<p><strong>待所有pod status为Running的时候，再次执行kubectl get nodes：</strong></p>
<pre><code class="language-shell">[root@k8s-master ~]# kubectl get node
NAME         STATUS   ROLES    AGE   VERSION
k8s-master   Ready    master   16m   v1.19.3
</code></pre>
<p><strong>如上所示，master状态变为，表明Master节点部署成功！</strong></p>
<h3 id="192安装calico网络功能更完善">19.2安装calico网络(功能更完善)</h3>
<h4 id="1在master上下载配置calico网络的yaml">1.在master上下载配置calico网络的yaml。</h4>
<pre><code class="language-shell">kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml
</code></pre>
<h4 id="2提前下载所需要的镜像">2.提前下载所需要的镜像。</h4>
<pre><code class="language-shell"># 查看此文件用哪些镜像：
[root@k8s-master ~]# grep image calico.yaml
image: docker.io/calico/cni:v3.23.1
image: docker.io/calico/node:v3.23.1
image: docker.io/calico/kube-controllers:v3.23.1
</code></pre>
<h4 id="3安装calico网络">3.安装calico网络。</h4>
<p>在master上执行如下命令：</p>
<pre><code class="language-csharp">kubectl apply -f calico.yaml
</code></pre>
<h4 id="5验证结果">5.验证结果。</h4>
<p>再次在master上运行命令 kubectl get nodes查看运行结果：</p>
<pre><code class="language-css">[root@k8s-master ~]# kubectl get nodes
NAME       STATUS   ROLES                  AGE   VERSION
master01   Ready    control-plane,master   21h   v1.23.4
worker01   Ready    &lt;none&gt;                 16h   v1.23.4
worker02   Ready    &lt;none&gt;                 16h   v1.23.4
</code></pre>
<h3 id="20部署k8s-node1-k8s-node2集群">20.部署k8s-node1、k8s-node2集群</h3>
<p><strong>1、在k8s-node1、k8s-node2等两台虚拟机中重复执行上面的步骤，安装好docker、kubelet、kubectl、kubeadm。</strong></p>
<h4 id="1node节点加入集群">1.node节点加入集群</h4>
<p>在上面第初始化master节点成功后，输出了下面的kubeadm join命令：</p>
<pre><code class="language-shell">kubeadm join 192.168.40.131:6443 --token zj0u08.ge77y7uv76flqgdk --discovery-token-ca-cert-hash sha256:7cd23cec6afb192b2d34c5c719b378082a6315a9d91a22d91b83066c870d4db5 --cri-socket unix:///var/run/cri-docker.sock 
</code></pre>
<p>该命令就是node加入集群的命令，分别在k8s-node1、k8s-node2上执行该命令加入集群。</p>
<p>如果忘记该命令，可以通过以下命令重新生成：</p>
<pre><code class="language-shell">kubeadm token create --print-join-command
</code></pre>
<h4 id="2在master节点执行下面命令查看集群状态">2.在master节点执行下面命令查看集群状态：</h4>
<pre><code class="language-shell">kubectl get nodes
</code></pre>
<pre><code class="language-shell">[root@k8s-master ~]# kubectl get node
NAME         STATUS   ROLES    AGE     VERSION
k8s-master   Ready    master   24m     v1.19.3
k8s-node1    Ready    &lt;none&gt;   5m50s   v1.19.3
k8s-node2    Ready    &lt;none&gt;   5m21s   v1.19.3

</code></pre>
<p>如上所示，所有节点都为ready，集群搭建成功。</p>
<h3 id="21安装ingress-nginx">21.安装ingress-nginx</h3>
<pre><code class="language-yaml">vi ingress-nginx-deploy.yaml
apiVersion: v1
kind: Namespace
metadata:
  labels:
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
  name: ingress-nginx
---
apiVersion: v1
automountServiceAccountToken: true
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.2.0
  name: ingress-nginx
  namespace: ingress-nginx
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/component: admission-webhook
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.2.0
  name: ingress-nginx-admission
  namespace: ingress-nginx
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.2.0
  name: ingress-nginx
  namespace: ingress-nginx
rules:
- apiGroups:
  - &quot;&quot;
  resources:
  - namespaces
  verbs:
  - get
- apiGroups:
  - &quot;&quot;
  resources:
  - configmaps
  - pods
  - secrets
  - endpoints
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - &quot;&quot;
  resources:
  - services
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - networking.k8s.io
  resources:
  - ingresses
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - networking.k8s.io
  resources:
  - ingresses/status
  verbs:
  - update
- apiGroups:
  - networking.k8s.io
  resources:
  - ingressclasses
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - &quot;&quot;
  resourceNames:
  - ingress-controller-leader
  resources:
  - configmaps
  verbs:
  - get
  - update
- apiGroups:
  - &quot;&quot;
  resources:
  - configmaps
  verbs:
  - create
- apiGroups:
  - &quot;&quot;
  resources:
  - events
  verbs:
  - create
  - patch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  labels:
    app.kubernetes.io/component: admission-webhook
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.2.0
  name: ingress-nginx-admission
  namespace: ingress-nginx
rules:
- apiGroups:
  - &quot;&quot;
  resources:
  - secrets
  verbs:
  - get
  - create
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.2.0
  name: ingress-nginx
rules:
- apiGroups:
  - &quot;&quot;
  resources:
  - configmaps
  - endpoints
  - nodes
  - pods
  - secrets
  - namespaces
  verbs:
  - list
  - watch
- apiGroups:
  - &quot;&quot;
  resources:
  - nodes
  verbs:
  - get
- apiGroups:
  - &quot;&quot;
  resources:
  - services
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - networking.k8s.io
  resources:
  - ingresses
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - &quot;&quot;
  resources:
  - events
  verbs:
  - create
  - patch
- apiGroups:
  - networking.k8s.io
  resources:
  - ingresses/status
  verbs:
  - update
- apiGroups:
  - networking.k8s.io
  resources:
  - ingressclasses
  verbs:
  - get
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app.kubernetes.io/component: admission-webhook
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.2.0
  name: ingress-nginx-admission
rules:
- apiGroups:
  - admissionregistration.k8s.io
  resources:
  - validatingwebhookconfigurations
  verbs:
  - get
  - update
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.2.0
  name: ingress-nginx
  namespace: ingress-nginx
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: ingress-nginx
subjects:
- kind: ServiceAccount
  name: ingress-nginx
  namespace: ingress-nginx
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  labels:
    app.kubernetes.io/component: admission-webhook
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.2.0
  name: ingress-nginx-admission
  namespace: ingress-nginx
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: ingress-nginx-admission
subjects:
- kind: ServiceAccount
  name: ingress-nginx-admission
  namespace: ingress-nginx
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.2.0
  name: ingress-nginx
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: ingress-nginx
subjects:
- kind: ServiceAccount
  name: ingress-nginx
  namespace: ingress-nginx
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app.kubernetes.io/component: admission-webhook
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.2.0
  name: ingress-nginx-admission
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: ingress-nginx-admission
subjects:
- kind: ServiceAccount
  name: ingress-nginx-admission
  namespace: ingress-nginx
---
apiVersion: v1
data:
  allow-snippet-annotations: &quot;true&quot;
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.2.0
  name: ingress-nginx-controller
  namespace: ingress-nginx
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.2.0
  name: ingress-nginx-controller
  namespace: ingress-nginx
spec:
  ports:
  - appProtocol: http
    name: http
    port: 80
    protocol: TCP
    targetPort: http
  - appProtocol: https
    name: https
    port: 443
    protocol: TCP
    targetPort: https
  selector:
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
  type: NodePort
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.2.0
  name: ingress-nginx-controller-admission
  namespace: ingress-nginx
spec:
  ports:
  - appProtocol: https
    name: https-webhook
    port: 443
    targetPort: webhook
  selector:
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
  type: ClusterIP
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.2.0
  name: ingress-nginx-controller
  namespace: ingress-nginx
spec:
  minReadySeconds: 0
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-nginx
      app.kubernetes.io/name: ingress-nginx
  template:
    metadata:
      labels:
        app.kubernetes.io/component: controller
        app.kubernetes.io/instance: ingress-nginx
        app.kubernetes.io/name: ingress-nginx
    spec:
      containers:
      - args:
        - /nginx-ingress-controller
        - --election-id=ingress-controller-leader
        - --controller-class=k8s.io/ingress-nginx
        - --ingress-class=nginx
        - --configmap=$(POD_NAMESPACE)/ingress-nginx-controller
        - --validating-webhook=:8443
        - --validating-webhook-certificate=/usr/local/certificates/cert
        - --validating-webhook-key=/usr/local/certificates/key
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: LD_PRELOAD
          value: /usr/local/lib/libmimalloc.so
        image: registry.aliyuncs.com/google_containers/nginx-ingress-controller:v1.2.0
        imagePullPolicy: IfNotPresent
        lifecycle:
          preStop:
            exec:
              command:
              - /wait-shutdown
        livenessProbe:
          failureThreshold: 5
          httpGet:
            path: /healthz
            port: 10254
            scheme: HTTP
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 1
        name: controller
        ports:
        - containerPort: 80
          name: http
          protocol: TCP
        - containerPort: 443
          name: https
          protocol: TCP
        - containerPort: 8443
          name: webhook
          protocol: TCP
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /healthz
            port: 10254
            scheme: HTTP
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 1
        resources:
          requests:
            cpu: 100m
            memory: 90Mi
        securityContext:
          allowPrivilegeEscalation: true
          capabilities:
            add:
            - NET_BIND_SERVICE
            drop:
            - ALL
          runAsUser: 101
        volumeMounts:
        - mountPath: /usr/local/certificates/
          name: webhook-cert
          readOnly: true
      dnsPolicy: ClusterFirst
      nodeSelector:
        kubernetes.io/os: linux
      serviceAccountName: ingress-nginx
      terminationGracePeriodSeconds: 300
      volumes:
      - name: webhook-cert
        secret:
          secretName: ingress-nginx-admission
---
apiVersion: batch/v1
kind: Job
metadata:
  labels:
    app.kubernetes.io/component: admission-webhook
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.2.0
  name: ingress-nginx-admission-create
  namespace: ingress-nginx
spec:
  template:
    metadata:
      labels:
        app.kubernetes.io/component: admission-webhook
        app.kubernetes.io/instance: ingress-nginx
        app.kubernetes.io/name: ingress-nginx
        app.kubernetes.io/part-of: ingress-nginx
        app.kubernetes.io/version: 1.2.0
      name: ingress-nginx-admission-create
    spec:
      containers:
      - args:
        - create
        - --host=ingress-nginx-controller-admission,ingress-nginx-controller-admission.$(POD_NAMESPACE).svc
        - --namespace=$(POD_NAMESPACE)
        - --secret-name=ingress-nginx-admission
        env:
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        image: registry.aliyuncs.com/google_containers/kube-webhook-certgen:v1.1.1
        imagePullPolicy: IfNotPresent
        name: create
        securityContext:
          allowPrivilegeEscalation: false
      nodeSelector:
        kubernetes.io/os: linux
      restartPolicy: OnFailure
      securityContext:
        fsGroup: 2000
        runAsNonRoot: true
        runAsUser: 2000
      serviceAccountName: ingress-nginx-admission
---
apiVersion: batch/v1
kind: Job
metadata:
  labels:
    app.kubernetes.io/component: admission-webhook
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.2.0
  name: ingress-nginx-admission-patch
  namespace: ingress-nginx
spec:
  template:
    metadata:
      labels:
        app.kubernetes.io/component: admission-webhook
        app.kubernetes.io/instance: ingress-nginx
        app.kubernetes.io/name: ingress-nginx
        app.kubernetes.io/part-of: ingress-nginx
        app.kubernetes.io/version: 1.2.0
      name: ingress-nginx-admission-patch
    spec:
      containers:
      - args:
        - patch
        - --webhook-name=ingress-nginx-admission
        - --namespace=$(POD_NAMESPACE)
        - --patch-mutating=false
        - --secret-name=ingress-nginx-admission
        - --patch-failure-policy=Fail
        env:
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        image: registry.aliyuncs.com/google_containers/kube-webhook-certgen:v1.1.1
        imagePullPolicy: IfNotPresent
        name: patch
        securityContext:
          allowPrivilegeEscalation: false
      nodeSelector:
        kubernetes.io/os: linux
      restartPolicy: OnFailure
      securityContext:
        fsGroup: 2000
        runAsNonRoot: true
        runAsUser: 2000
      serviceAccountName: ingress-nginx-admission
---
apiVersion: networking.k8s.io/v1
kind: IngressClass
metadata:
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.2.0
  name: nginx
spec:
  controller: k8s.io/ingress-nginx
---
apiVersion: admissionregistration.k8s.io/v1
kind: ValidatingWebhookConfiguration
metadata:
  labels:
    app.kubernetes.io/component: admission-webhook
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.2.0
  name: ingress-nginx-admission
webhooks:
- admissionReviewVersions:
  - v1
  clientConfig:
    service:
      name: ingress-nginx-controller-admission
      namespace: ingress-nginx
      path: /networking/v1/ingresses
  failurePolicy: Fail
  matchPolicy: Equivalent
  name: validate.nginx.ingress.kubernetes.io
  rules:
  - apiGroups:
    - networking.k8s.io
    apiVersions:
    - v1
    operations:
    - CREATE
    - UPDATE
    resources:
    - ingresses
  sideEffects: None
  
kubectl create -f ingress-nginx-deploy.yaml
</code></pre>
<h2 id="卸载集群命令">卸载集群命令</h2>
<pre><code class="language-shell">#建议所有服务器都执行
#!/bin/bash
kubeadm reset -f
modprobe -r ipip
lsmod
rm -rf ~/.kube/
rm -rf /etc/kubernetes/
rm -rf /etc/systemd/system/kubelet.service.d
rm -rf /etc/systemd/system/kubelet.service
rm -rf /usr/bin/kube*
rm -rf /etc/cni
rm -rf /opt/cni
rm -rf /var/lib/etcd
rm -rf /var/etcd
yum -y remove kubeadm* kubectl* kubelet* docker*
reboot
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[centos7安装Docker详细步骤]]></title>
        <id>https://tinaxiawuhao.github.io/post/4kG3rvwit/</id>
        <link href="https://tinaxiawuhao.github.io/post/4kG3rvwit/">
        </link>
        <updated>2022-05-26T12:28:21.000Z</updated>
        <content type="html"><![CDATA[<h2 id="一-安装前必读">一、安装前必读</h2>
<p>在安装 Docker 之前，先说一下配置，我这里是Centos7  Linux 内核：官方建议 3.10 以上，3.8以上貌似也可。</p>
<p>注意：本文的命令使用的是 root 用户登录执行，不是 root 的话所有命令前面要加 <code>sudo</code></p>
<p><strong>1.查看当前的内核版本</strong></p>
<pre><code class="language-javascript">uname -r
</code></pre>
<p><strong>2.使用 root 权限更新 yum 包（生产环境中此步操作需慎重，看自己情况，学习的话随便搞）</strong></p>
<pre><code class="language-javascript">yum -y update
</code></pre>
<p>这个命令不是必须执行的，看个人情况，后面出现不兼容的情况的话就必须update了</p>
<pre><code class="language-javascript">注意 
yum -y update：升级所有包同时也升级软件和系统内核； 
yum -y upgrade：只升级所有包，不升级软件和系统内核
</code></pre>
<p><strong>3.卸载旧版本（如果之前安装过的话）</strong></p>
<pre><code class="language-javascript">yum remove docker  docker-common docker-selinux docker-engine
</code></pre>
<h2 id="二-安装docker的详细步骤">二、安装Docker的详细步骤</h2>
<p><strong>1.安装需要的软件包， yum-util 提供yum-config-manager功能，另两个是devicemapper驱动依赖</strong></p>
<pre><code class="language-javascript">yum install -y yum-utils device-mapper-persistent-data lvm2
</code></pre>
<p><strong>2.设置 yum 源</strong></p>
<p>设置一个yum源，下面两个都可用</p>
<pre><code class="language-javascript">yum-config-manager --add-repo http://download.docker.com/linux/centos/docker-ce.repo（中央仓库）

yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo（阿里仓库）
</code></pre>
<p>3.选择docker版本并安装</p>
<p>（1）查看可用版本有哪些</p>
<pre><code class="language-javascript">yum list docker-ce --showduplicates | sort -r
</code></pre>
<p>（2）选择一个版本并安装：<code>yum install docker-ce-版本号</code></p>
<pre><code class="language-javascript">yum -y install docker-ce-18.03.1.ce
</code></pre>
<p>4.启动 Docker 并设置开机自启</p>
<pre><code class="language-javascript">systemctl start docker
systemctl enable docker
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[HTTP3]]></title>
        <id>https://tinaxiawuhao.github.io/post/Um_5N4eGG/</id>
        <link href="https://tinaxiawuhao.github.io/post/Um_5N4eGG/">
        </link>
        <updated>2022-05-10T10:52:43.000Z</updated>
        <content type="html"><![CDATA[<h3 id="http3协议发布">HTTP3协议发布</h3>
<p>自2017年起HTTP3协议已发布了29个Draft，推出在即，Chrome、Nginx等软件都在跟进实现最新的草案。本文将介绍HTTP3协议规范、应用场景及实现原理。</p>
<p>2015年HTTP2协议正式推出后，已经有接近一半的互联网站点在使用它：</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1657191233668.jpg" alt="" loading="lazy"></figure>
<p>HTTP2协议虽然大幅提升了HTTP/1.1的性能，然而，基于TCP实现的HTTP2遗留下3个问题：</p>
<blockquote>
<ul>
<li>有序字节流引出的<strong>队头阻塞</strong>（<a href="https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Head-of-line_blocking">Head-of-line blocking</a>），使得HTTP2的多路复用能力大打折扣；</li>
<li><strong>TCP与TLS叠加了握手时延</strong>，建链时长还有1倍的下降空间；</li>
<li>基于TCP四元组确定一个连接，这种诞生于有线网络的设计，并不适合移动状态下的无线网络，这意味着<strong>IP地址的频繁变动会导致TCP连接、TLS会话反复握手</strong>，成本高昂。</li>
</ul>
</blockquote>
<p>HTTP3协议解决了这些问题：</p>
<blockquote>
<ul>
<li>HTTP3基于UDP协议重新定义了连接，在QUIC层实现了无序、并发字节流的传输，解决了队头阻塞问题（包括基于QPACK解决了动态表的队头阻塞）；</li>
<li>HTTP3重新定义了TLS协议加密QUIC头部的方式，既提高了网络攻击成本，又降低了建立连接的速度（仅需1个RTT就可以同时完成建链与密钥协商）；</li>
<li>HTTP3 将Packet、QUIC Frame、HTTP3 Frame分离，实现了连接迁移功能，降低了5G环境下高速移动设备的连接维护成本。</li>
</ul>
</blockquote>
<p>本文将会从HTTP3协议的概念讲起，从连接迁移的实现上学习HTTP3的报文格式，再围绕着队头阻塞问题来分析多路复用与QPACK动态表的实现。虽然正式的RFC规范还未推出，但最近的草案Change只有微小的变化，所以现在学习HTTP3正当其时，这将是下一代互联网最重要的基础设施。</p>
<hr>
<h3 id="http3协议到底是什么">HTTP3协议到底是什么？</h3>
<p>就像HTTP2协议一样，HTTP3并没有改变HTTP1的语义。那什么是HTTP语义呢？在我看来，它包括以下3个点：</p>
<blockquote>
<ul>
<li>请求只能由客户端发起，而服务器针对每个请求返回一个响应；</li>
<li>请求与响应都由Header、Body（可选）组成，其中请求必须含有URL和方法，而响应必须含有响应码；</li>
<li>Header中各Name对应的含义保持不变。</li>
</ul>
</blockquote>
<p>HTTP3在保持HTTP1语义不变的情况下，更改了编码格式，这由2个原因所致：首先，是为了减少编码长度。下图中HTTP1协议的编码使用了ASCII码，用空格、冒号以及\r\n作为分隔符，编码效率很低：</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1657191244440.jpg" alt="" loading="lazy"></figure>
<p>HTTP2与HTTP3采用二进制、静态表、动态表与Huffman算法对HTTP Header编码，不只提供了高压缩率，还加快了发送端编码、接收端解码的速度。</p>
<p>其次，由于HTTP1协议不支持多路复用，这样高并发只能通过多开一些TCP连接实现。然而，通过TCP实现高并发有3个弊端：</p>
<blockquote>
<ul>
<li>实现成本高。TCP是由操作系统内核实现的，如果通过多线程实现并发，并发线程数不能太多，否则线程间切换成本会以指数级上升；如果通过异步、非阻塞socket实现并发，开发效率又太低；</li>
<li>每个TCP连接与TLS会话都叠加了2-3个RTT的建链成本；</li>
<li>TCP连接有一个防止出现拥塞的慢启动流程，它会对每个TCP连接都产生减速效果。</li>
</ul>
</blockquote>
<p>因此，HTTP2与HTTP3都在应用层实现了多路复用功能：</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1657191252726.jpg" alt="" loading="lazy"></figure>
<p>HTTP2协议基于TCP有序字节流实现，因此<strong>应用层的多路复用并不能做到无序地并发，在丢包场景下会出现队头阻塞问题</strong>。如下面的动态图片所示，服务器返回的绿色响应由5个TCP报文组成，而黄色响应由4个TCP报文组成，当第2个黄色报文丢失后，即使客户端接收到完整的5个绿色报文，但TCP层不会允许应用进程的read函数读取到最后5个报文，并发成了一纸空谈：</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1657191260722.gif" alt="" loading="lazy"></figure>
<p>当网络繁忙时，丢包概率会很高，多路复用受到了很大限制。因此，<strong>HTTP3采用UDP作为传输层协议，重新实现了无序连接，并在此基础上通过有序的QUIC Stream提供了多路复用</strong>，如下图所示：</p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1657191268463.jpg" alt="" loading="lazy"></figure>
<p>最早这一实验性协议由Google推出，并命名为gQUIC，因此，IETF草案中仍然保留了QUIC概念，用来描述HTTP3协议的传输层和表示层。HTTP3协议规范由以下5个部分组成：</p>
<blockquote>
<ul>
<li>QUIC层由<a href="https://link.zhihu.com/?target=https%3A//datatracker.ietf.org/doc/html/draft-ietf-quic-transport-29">https://tools.ietf.org/html/draft-ietf-quic-transport-29</a>描述，它定义了连接、报文的可靠传输、有序字节流的实现；</li>
<li>TLS协议会将QUIC层的部分报文头部暴露在明文中，方便代理服务器进行路由。<a href="https://link.zhihu.com/?target=https%3A//tools.ietf.org/html/draft-ietf-quic-tls-29%E8%A7%84%E8%8C%83%E5%AE%9A%E4%B9%89%E4%BA%86QUIC%E4%B8%8ETLS%E7%9A%84%E7%BB%93%E5%90%88%E6%96%B9%E5%BC%8F%EF%BC%9B">https://tools.ietf.org/html/draft-ietf-quic-tls-29规范定义了QUIC与TLS的结合方式；</a></li>
<li>丢包检测、RTO重传定时器预估等功能由<a href="https://link.zhihu.com/?target=https%3A//tools.ietf.org/html/draft-ietf-quic-recovery-29">https://tools.ietf.org/html/draft-ietf-quic-recovery-29</a>定义，目前拥塞控制使用了类似TCP New RENO的算法，未来有可能更换为基于带宽检测的算法（例如BBR）；</li>
<li>基于以上3个规范，<a href="https://link.zhihu.com/?target=https%3A//tools.ietf.org/html/draft-ietf-quic-http-29%E5%AE%9A%E4%B9%89%E4%BA%86HTTP%E8%AF%AD%E4%B9%89%E7%9A%84%E5%AE%9E%E7%8E%B0%EF%BC%8C%E5%8C%85%E6%8B%AC%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%8E%A8%E9%80%81%E3%80%81%E8%AF%B7%E6%B1%82%E5%93%8D%E5%BA%94%E7%9A%84%E4%BC%A0%E8%BE%93%E7%AD%89%EF%BC%9B">https://tools.ietf.org/html/draft-ietf-quic-http-29定义了HTTP语义的实现，包括服务器推送、请求响应的传输等；</a></li>
<li>在HTTP2中，由HPACK规范定义HTTP头部的压缩算法。由于HPACK动态表的更新具有时序性，无法满足HTTP3的要求。在HTTP3中，QPACK定义HTTP头部的编码：<a href="https://link.zhihu.com/?target=https%3A//datatracker.ietf.org/doc/html/draft-ietf-quic-qpack-16">https://tools.ietf.org/html/draft-ietf-quic-qpack-16</a>。注意，以上规范的最新草案都到了29，而QPACK相对简单，它目前更新到16。</li>
</ul>
</blockquote>
<p>自1991年诞生的HTTP/0.9协议已不再使用，<strong>但1996推出的HTTP/1.0、1999年推出的HTTP/1.1、2015年推出的HTTP2协议仍然共存于互联网中（HTTP/1.0在企业内网中还在广为使用，例如Nginx与上游的默认协议还是1.0版本），即将面世的HTTP3协议的加入，将会进一步增加协议适配的复杂度</strong>。接下来，我们将深入HTTP3协议的细节。</p>
<hr>
<h3 id="连接迁移功能是怎样实现的">连接迁移功能是怎样实现的？</h3>
<p>对于当下的HTTP1和HTTP2协议，传输请求前需要先完成耗时1个RTT的TCP三次握手、耗时1个RTT的TLS握手（TLS1.3），<strong>由于它们分属内核实现的传输层、openssl库实现的表示层，所以难以合并在一起</strong>，如下图所示：</p>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1657191282402.jpg" alt="" loading="lazy"></figure>
<p>在IoT时代，移动设备接入的网络会频繁变动，从而导致设备IP地址改变。<strong>对于通过四元组（源IP、源端口、目的IP、目的端口）定位连接的TCP协议来说，这意味着连接需要断开重连，所以上述2个RTT的建链时延、TCP慢启动都需要重新来过</strong>。而HTTP3的QUIC层实现了连接迁移功能，允许移动设备更换IP地址后，只要仍保有上下文信息（比如连接ID、TLS密钥等），就可以复用原连接。</p>
<p>在UDP报文头部与HTTP消息之间，共有3层头部，定义连接且实现了Connection Migration主要是在Packet Header中完成的，如下图所示：</p>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1657191289184.jpg" alt="" loading="lazy"></figure>
<p>这3层Header实现的功能各不相同：</p>
<blockquote>
<ul>
<li>Packet Header实现了可靠的连接。当UDP报文丢失后，通过Packet Header中的Packet Number实现报文重传。连接也是通过其中的Connection ID字段定义的；</li>
<li>QUIC Frame Header在无序的Packet报文中，基于QUIC Stream概念实现了有序的字节流，这允许HTTP消息可以像在TCP连接上一样传输；</li>
<li>HTTP3 Frame Header定义了HTTP Header、Body的格式，以及服务器推送、QPACK编解码流等功能。</li>
<li>为了进一步提升网络传输效率，Packet Header又可以细分为两种：</li>
<li>Long Packet Header用于首次建立连接；</li>
<li>Short Packet Header用于日常传输数据。</li>
</ul>
</blockquote>
<p>其中，Long Packet Header的格式如下图所示：</p>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1657191297461.jpg" alt="" loading="lazy"></figure>
<p>建立连接时，连接是由服务器通过Source Connection ID字段分配的，这样，后续传输时，双方只需要固定住Destination Connection ID，就可以在客户端IP地址、端口变化后，绕过UDP四元组（与TCP四元组相同），实现连接迁移功能。下图是Short Packet Header头部的格式，这里就不再需要传输Source Connection ID字段了：</p>
<figure data-type="image" tabindex="9"><img src="https://tinaxiawuhao.github.io/post-images/1657191304638.jpg" alt="" loading="lazy"></figure>
<p>上图中的Packet Number是每个报文独一无二的序号，基于它可以实现丢失报文的精准重发。如果你通过抓包观察Packet Header，会发现Packet Number被TLS层加密保护了，这是为了防范各类网络攻击的一种设计。下图给出了Packet Header中被加密保护的字段：</p>
<figure data-type="image" tabindex="10"><img src="https://tinaxiawuhao.github.io/post-images/1657191312018.jpg" alt="" loading="lazy"></figure>
<p>其中，显示为E（Encrypt）的字段表示被TLS加密过。当然，Packet Header只是描述了最基本的连接信息，其上的Stream层、HTTP消息也是被加密保护的：</p>
<figure data-type="image" tabindex="11"><img src="https://tinaxiawuhao.github.io/post-images/1657191318976.jpg" alt="" loading="lazy"></figure>
<p>现在我们已经对HTTP3协议的格式有了基本的了解，接下来我们通过队头阻塞问题，看看Packet之上的QUIC Frame、HTTP3 Frame帧格式。</p>
<hr>
<h3 id="stream多路复用时的队头阻塞是怎样解决的">Stream多路复用时的队头阻塞是怎样解决的？</h3>
<p>其实，解决队头阻塞的方案，就是允许微观上有序发出的Packet报文，在接收端无序到达后也可以应用于并发请求中。比如上文的动态图中，如果丢失的黄色报文对其后发出的绿色报文不造成影响，队头阻塞问题自然就得到了解决：</p>
<figure data-type="image" tabindex="12"><img src="https://tinaxiawuhao.github.io/post-images/1657191326006.gif" alt="" loading="lazy"></figure>
<p>在Packet Header之上的QUIC Frame Header，定义了有序字节流Stream，而且Stream之间可以实现真正的并发。HTTP3的Stream，借鉴了HTTP2中的部分概念，所以在讨论QUIC Frame Header格式之前，我们先来看看HTTP2中的Stream长成什么样子：</p>
<figure data-type="image" tabindex="13"><img src="https://tinaxiawuhao.github.io/post-images/1657191333124.jpg" alt="" loading="lazy"></figure>
<p>每个Stream就像HTTP1中的TCP连接，它保证了承载的HEADERS frame（存放HTTP Header）、DATA frame（存放HTTP Body）是有序到达的，多个Stream之间可以并行传输。在HTTP3中，上图中的HTTP2 frame会被拆解为两层，我们先来看底层的QUIC Frame。</p>
<p>一个Packet报文中可以存放多个QUIC Frame，当然所有Frame的长度之和不能大于PMTUD（Path Maximum Transmission Unit Discovery，这是大于1200字节的值），你可以把它与IP路由中的MTU概念对照理解：</p>
<figure data-type="image" tabindex="14"><img src="https://tinaxiawuhao.github.io/post-images/1657191340236.jpg" alt="" loading="lazy"></figure>
<p>每一个Frame都有明确的类型：</p>
<figure data-type="image" tabindex="15"><img src="https://tinaxiawuhao.github.io/post-images/1657191346617.jpg" alt="" loading="lazy"></figure>
<p>前4个字节的Frame Type字段描述的类型不同，接下来的编码也不相同，下表是各类Frame的16进制Type值：</p>
<figure data-type="image" tabindex="16"><img src="https://tinaxiawuhao.github.io/post-images/1657191354925.jpg" alt="" loading="lazy"></figure>
<p>在上表中，我们只要分析0x08-0x0f这8种STREAM类型的Frame，就能弄明白Stream流的实现原理，自然也就清楚队头阻塞是怎样解决的了。Stream Frame用于传递HTTP消息，它的格式如下所示：</p>
<figure data-type="image" tabindex="17"><img src="https://tinaxiawuhao.github.io/post-images/1657191362406.jpg" alt="" loading="lazy"></figure>
<p>可见，Stream Frame头部的3个字段，完成了多路复用、有序字节流以及报文段层面的二进制分隔功能，包括：</p>
<ul>
<li>Stream ID标识了一个有序字节流。当HTTP Body非常大，需要跨越多个Packet时，只要在每个Stream Frame中含有同样的Stream ID，就可以传输任意长度的消息。多个并发传输的HTTP消息，通过不同的Stream ID加以区别；</li>
<li>消息序列化后的“有序”特性，是通过Offset字段完成的，它类似于TCP协议中的Sequence序号，用于实现Stream内多个Frame间的累计确认功能；</li>
<li>Length指明了Frame数据的长度。</li>
</ul>
<p>你可能会奇怪，为什么会有8种Stream Frame呢？这是因为0x08-0x0f 这8种类型其实是由3个二进制位组成，它们实现了以下3 标志位的组合：</p>
<ul>
<li>第1位表示是否含有Offset，当它为0时，表示这是Stream中的起始Frame，这也是上图中Offset是可选字段的原因；</li>
<li>第2位表示是否含有Length字段；</li>
<li>第3位Fin，表示这是Stream中最后1个Frame，与HTTP2协议Frame帧中的FIN标志位相同。</li>
</ul>
<p>Stream数据中并不会直接存放HTTP消息，因为HTTP3还需要实现服务器推送、权重优先级设定、流量控制等功能，所以Stream Data中首先存放了HTTP3 Frame：</p>
<figure data-type="image" tabindex="18"><img src="https://tinaxiawuhao.github.io/post-images/1657191370693.jpg" alt="" loading="lazy"></figure>
<p>其中，Length指明了HTTP消息的长度，而Type字段（请注意，低2位有特殊用途，在QPACK章节中会详细介绍）包含了以下类型：</p>
<ul>
<li>0x00：DATA帧，用于传输HTTP Body包体；</li>
<li>0x01：HEADERS帧，通过QPACK 编码，传输HTTP Header头部；</li>
<li>0x03：CANCEL_PUSH控制帧，用于取消1次服务器推送消息，通常客户端在收到PUSH_PROMISE帧后，通过它告知服务器不需要这次推送；</li>
<li>0x04：SETTINGS控制帧，设置各类通讯参数；</li>
<li>0x05：PUSH_PROMISE帧，用于服务器推送HTTP Body前，先将HTTP Header头部发给客户端，流程与HTTP2相似；</li>
<li>0x07：GOAWAY控制帧，用于关闭连接（注意，不是关闭Stream）；</li>
<li>0x0d：MAX_PUSH_ID，客户端用来限制服务器推送消息数量的控制帧。</li>
</ul>
<p>总结一下，QUIC Stream Frame定义了有序字节流，且多个Stream间的传输没有时序性要求，这样，HTTP消息基于QUIC Stream就实现了真正的多路复用，队头阻塞问题自然就被解决掉了。</p>
<hr>
<h3 id="qpack编码是如何解决队头阻塞问题的">QPACK编码是如何解决队头阻塞问题的？</h3>
<p>最后，我们再看下HTTP Header头部的编码方式，它需要面对另一种队头阻塞问题。</p>
<p>与HTTP2中的HPACK编码方式相似，HTTP3中的QPACK也采用了静态表、动态表及Huffman编码：</p>
<figure data-type="image" tabindex="19"><img src="https://tinaxiawuhao.github.io/post-images/1657191378639.jpg" alt="" loading="lazy"></figure>
<p>先来看静态表的变化。在上图中，GET方法映射为数字2，这是通过客户端、服务器协议实现层的硬编码完成的。在HTTP2中，共有61个静态表项：</p>
<figure data-type="image" tabindex="20"><img src="https://tinaxiawuhao.github.io/post-images/1657191385740.jpg" alt="" loading="lazy"></figure>
<p>而在QPACK中，则上升为98个静态表项，比如Nginx上的ngx_htt_v3_static_table数组所示：</p>
<figure data-type="image" tabindex="21"><img src="https://tinaxiawuhao.github.io/post-images/1657191392331.jpg" alt="" loading="lazy"></figure>
<p>你也可以从<a href="https://link.zhihu.com/?target=https%3A//datatracker.ietf.org/doc/html/draft-ietf-quic-qpack-14%23appendix-A">这里</a>找到完整的HTTP3静态表。对于Huffman以及整数的编码，QPACK与HPACK并无多大不同，但动态表编解码方式差距很大。</p>
<p>所谓动态表，就是将未包含在静态表中的Header项，在其首次出现时加入动态表，这样后续传输时仅用1个数字表示，大大提升了编码效率。因此，动态表是天然具备时序性的，如果首次出现的请求出现了丢包，后续请求解码HPACK头部时，一定会被阻塞！</p>
<p>QPACK是如何解决队头阻塞问题的呢？事实上，QPACK将动态表的编码、解码独立在单向Stream中传输，仅当单向Stream中的动态表编码成功后，接收端才能解码双向Stream上HTTP消息里的动态表索引。</p>
<p>我们又引入了单向Stream和双向Stream概念，不要头疼，它其实很简单。单向指只有一端可以发送消息，双向则指两端都可以发送消息。还记得上一小节的QUIC Stream Frame头部吗？其中的Stream ID别有玄机，除了标识Stream外，它的低2位还可以表达以下组合：</p>
<figure data-type="image" tabindex="22"><img src="https://tinaxiawuhao.github.io/post-images/1657191400338.jpg" alt="" loading="lazy"></figure>
<p>因此，当Stream ID是0、4、8、12时，这就是客户端发起的双向Stream（HTTP3不支持服务器发起双向Stream），它用于传输HTTP请求与响应。单向Stream有很多用途，所以它在数据前又多出一个Stream Type字段：</p>
<figure data-type="image" tabindex="23"><img src="https://tinaxiawuhao.github.io/post-images/1657191471479.jpg" alt="" loading="lazy"></figure>
<p>Stream Type有以下取值：</p>
<blockquote>
<ul>
<li>0x00：控制Stream，传递各类Stream控制消息；</li>
<li>0x01：服务器推送消息；</li>
<li>0x02：用于编码QPACK动态表，比如面对不属于静态表的HTTP请求头部，客户端可以通过这个Stream发送动态表编码；</li>
<li>0x03：用于通知编码端QPACK动态表的更新结果。</li>
</ul>
</blockquote>
<p>由于HTTP3的STREAM之间是乱序传输的，因此，若先发送的编码Stream后到达，双向Stream中的QPACK头部就无法解码，此时传输HTTP消息的双向Stream就会进入Block阻塞状态（两端可以通过控制帧定义阻塞Stream的处理方式）。</p>
<hr>
<h3 id="小结">小结</h3>
<p>最后对本文内容做个小结。</p>
<p>基于四元组定义连接并不适用于下一代IoT网络，HTTP3创造出Connection ID概念实现了连接迁移，通过融合传输层、表示层，既缩短了握手时长，也加密了传输层中的绝大部分字段，提升了网络安全性。</p>
<p>HTTP3在Packet层保障了连接的可靠性，在QUIC Frame层实现了有序字节流，在HTTP3 Frame层实现了HTTP语义，这彻底解开了队头阻塞问题，真正实现了应用层的多路复用。</p>
<p>QPACK使用独立的单向Stream分别传输动态表编码、解码信息，这样乱序、并发传输HTTP消息的Stream既不会出现队头阻塞，也能基于时序性大幅压缩HTTP Header的体积。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[binlog、redolog、undolog]]></title>
        <id>https://tinaxiawuhao.github.io/post/HHdQUUQvV/</id>
        <link href="https://tinaxiawuhao.github.io/post/HHdQUUQvV/">
        </link>
        <updated>2022-04-30T14:08:02.000Z</updated>
        <content type="html"><![CDATA[<p>日志是 <code>mysql</code> 数据库的重要组成部分，记录着数据库运行期间各种状态信息。<code>mysql</code>日志主要包括错误日志、查询日志、慢查询日志、事务日志、二进制日志几大类。</p>
<p>作为开发，我们重点需要关注的是二进制日志( <code>binlog</code> )和事务日志(包括<code>redo log</code> 和 <code>undo log</code> )，本文接下来会详细介绍这三种日志。</p>
<h3 id="binlog">binlog</h3>
<p><code>binlog</code> 用于记录数据库执行的写入性操作(不包括查询)信息，以二进制的形式保存在磁盘中。<code>binlog</code> 是 <code>mysql</code>的逻辑日志，并且由 <code>Server</code> 层进行记录，使用任何存储引擎的 <code>mysql</code> 数据库都会记录 <code>binlog</code> 日志。</p>
<ul>
<li><strong>逻辑日志</strong>：可以简单理解为记录的就是sql语句 。</li>
<li><strong>物理日志</strong>：<code>mysql</code> 数据最终是保存在数据页中的，物理日志记录的就是数据页变更 。</li>
</ul>
<p><code>binlog</code> 是通过追加的方式进行写入的，可以通过<code>max_binlog_size</code> 参数设置每个 <code>binlog</code>文件的大小，当文件大小达到给定值之后，会生成新的文件来保存日志。</p>
<h4 id="binlog使用场景">binlog使用场景</h4>
<p>在实际应用中， <code>binlog</code> 的主要使用场景有两个，分别是 <strong>主从复制</strong> 和 <strong>数据恢复</strong> 。</p>
<ol>
<li><strong>主从复制</strong> ：在 <code>Master</code> 端开启 <code>binlog</code> ，然后将 <code>binlog</code>发送到各个 <code>Slave</code> 端， <code>Slave</code> 端重放 <code>binlog</code> 从而达到主从数据一致。</li>
<li><strong>数据恢复</strong> ：通过使用 <code>mysqlbinlog</code> 工具来恢复数据。</li>
</ol>
<h4 id="binlog刷盘时机">binlog刷盘时机</h4>
<p>对于 <code>InnoDB</code> 存储引擎而言，只有在事务提交时才会记录<code>binlog</code> ，此时记录还在内存中，那么 <code>binlog</code>是什么时候刷到磁盘中的呢？</p>
<p><code>mysql</code> 通过 <code>sync_binlog</code> 参数控制 <code>binlog</code> 的刷盘时机，取值范围是 <code>0-N</code>：</p>
<ul>
<li>0：不去强制要求，由系统自行判断何时写入磁盘；</li>
<li>1：每次 <code>commit</code> 的时候都要将 <code>binlog</code> 写入磁盘；</li>
<li>N：每N个事务，才会将 <code>binlog</code> 写入磁盘。</li>
</ul>
<p>从上面可以看出， <code>sync_binlog</code> 最安全的是设置是 <code>1</code> ，这也是<code>MySQL 5.7.7</code>之后版本的默认值。但是设置一个大一些的值可以提升数据库性能，因此实际情况下也可以将值适当调大，牺牲一定的一致性来获取更好的性能。</p>
<h4 id="binlog日志格式">binlog日志格式</h4>
<p><code>binlog</code> 日志有三种格式，分别为 <code>STATMENT</code> 、 <code>ROW</code> 和 <code>MIXED</code>。</p>
<blockquote>
<p>在 <code>MySQL 5.7.7</code> 之前，默认的格式是 <code>STATEMENT</code> ， <code>MySQL 5.7.7</code> 之后，默认值是 <code>ROW</code>。日志格式通过 <code>binlog-format</code> 指定。</p>
</blockquote>
<ul>
<li>
<p><code>STATMENT</code>：基于<code>SQL</code> 语句的复制( <code>statement-based replication, SBR</code> )，每一条会修改数据的sql语句会记录到<code>binlog</code> 中  。</p>
</li>
<li>
<ul>
<li>优点：不需要记录每一行的变化，减少了 binlog 日志量，节约了 IO  , 从而提高了性能；</li>
<li>缺点：在某些情况下会导致主从数据不一致，比如执行sysdate() 、  slepp()  等 。</li>
</ul>
</li>
<li>
<p><code>ROW</code>：基于行的复制(<code>row-based replication, RBR</code> )，不记录每条sql语句的上下文信息，仅需记录哪条数据被修改了 。</p>
</li>
<li>
<ul>
<li>优点：不会出现某些特定情况下的存储过程、或function、或trigger的调用和触发无法被正确复制的问题 ；</li>
<li>缺点：会产生大量的日志，尤其是<code>alter table</code> 的时候会让日志暴涨</li>
</ul>
</li>
<li>
<p><code>MIXED</code>：基于<code>STATMENT</code> 和 <code>ROW</code> 两种模式的混合复制(<code>mixed-based replication, MBR</code> )，一般的复制使用<code>STATEMENT</code> 模式保存 <code>binlog</code> ，对于 <code>STATEMENT</code> 模式无法复制的操作使用 <code>ROW</code> 模式保存 <code>binlog</code></p>
</li>
</ul>
<h3 id="redo-log">redo log</h3>
<p>我们都知道，事务的四大特性里面有一个是 <strong>持久性</strong> ，具体来说就是<strong>只要事务提交成功，那么对数据库做的修改就被永久保存下来了，不可能因为任何原因再回到原来的状态</strong> 。</p>
<p>那么 <code>mysql</code>是如何保证一致性的呢？</p>
<p>最简单的做法是在每次事务提交的时候，将该事务涉及修改的数据页全部刷新到磁盘中。但是这么做会有严重的性能问题，主要体现在两个方面：</p>
<ol>
<li>因为 <code>Innodb</code> 是以 <code>页</code> 为单位进行磁盘交互的，而一个事务很可能只修改一个数据页里面的几个字节，这个时候将完整的数据页刷到磁盘的话，太浪费资源了！</li>
<li>一个事务可能涉及修改多个数据页，并且这些数据页在物理上并不连续，使用随机IO写入性能太差！</li>
</ol>
<p>因此 <code>mysql</code> 设计了 <code>redo log</code> ， <strong>具体来说就是只记录事务对数据页做了哪些修改</strong>，这样就能完美地解决性能问题了(相对而言文件更小并且是顺序IO)。</p>
<h4 id="redo-log基本概念">redo log基本概念</h4>
<p><code>redo log</code> 包括两部分：一个是内存中的日志缓冲( <code>redo log buffer</code> )，另一个是磁盘上的日志文件( <code>redo logfile</code>)。</p>
<p><code>mysql</code> 每执行一条 <code>DML</code> 语句，先将记录写入 <code>redo log buffer</code>，后续某个时间点再一次性将多个操作记录写到 <code>redo log file</code>。这种 <strong>先写日志，再写磁盘</strong> 的技术就是 <code>MySQL</code>里经常说到的 <code>WAL(Write-Ahead Logging)</code> 技术。</p>
<p>在计算机操作系统中，用户空间( <code>user space</code> )下的缓冲区数据一般情况下是无法直接写入磁盘的，中间必须经过操作系统内核空间( <code>kernel space</code> )缓冲区( <code>OS Buffer</code> )。</p>
<p>因此， <code>redo log buffer</code> 写入 <code>redo logfile</code> 实际上是先写入 <code>OS Buffer</code> ，然后再通过系统调用 <code>fsync()</code> 将其刷到 <code>redo log file</code><br>
中，过程如下：</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1656857434307.png" alt="" loading="lazy"></figure>
<p><code>mysql</code> 支持三种将 <code>redo log buffer</code> 写入 <code>redo log file</code> 的时机，可以通过 <code>innodb_flush_log_at_trx_commit</code> 参数配置，各参数值含义如下：</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1656857376635.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1656857386706.png" alt="" loading="lazy"></figure>
<h4 id="redo-log记录形式">redo log记录形式</h4>
<p>前面说过， <code>redo log</code> 实际上记录数据页的变更，而这种变更记录是没必要全部保存，因此 <code>redo log</code>实现上采用了大小固定，循环写入的方式，当写到结尾时，会回到开头循环写日志。如下图：</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1656857394791.png" alt="" loading="lazy"></figure>
<p>同时我们很容易得知， 在innodb中，既有<code>redo log</code> 需要刷盘，还有 <code>数据页</code> 也需要刷盘， <code>redo log</code>存在的意义主要就是降低对 <code>数据页</code> 刷盘的要求  。</p>
<p>在上图中， <code>write pos</code> 表示 <code>redo log</code> 当前记录的 <code>LSN</code> (逻辑序列号)位置， <code>check point</code> 表示 <strong>数据页更改记录</strong> 刷盘后对应 <code>redo log</code> 所处的 <code>LSN</code>(逻辑序列号)位置。</p>
<p><code>write pos</code> 到 <code>check point</code> 之间的部分是 <code>redo log</code> 空着的部分，用于记录新的记录；<code>check point</code> 到 <code>write pos</code> 之间是 <code>redo log</code> 待落盘的数据页更改记录。当 <code>write pos</code>追上<code>check point</code> 时，会先推动 <code>check point</code> 向前移动，空出位置再记录新的日志。</p>
<p>启动 <code>innodb</code> 的时候，不管上次是正常关闭还是异常关闭，总是会进行恢复操作。因为 <code>redo log</code>记录的是数据页的物理变化，因此恢复的时候速度比逻辑日志(如 <code>binlog</code> )要快很多。</p>
<p>重启<code>innodb</code> 时，首先会检查磁盘中数据页的 <code>LSN</code> ，如果数据页的<code>LSN</code> 小于日志中的 <code>LSN</code> ，则会从 <code>checkpoint</code> 开始恢复。</p>
<p>还有一种情况，在宕机前正处于<code>checkpoint</code> 的刷盘过程，且数据页的刷盘进度超过了日志页的刷盘进度，此时会出现数据页中记录的 <code>LSN</code> 大于日志中的 <code>LSN</code>，这时超出日志进度的部分将不会重做，因为这本身就表示已经做过的事情，无需再重做。</p>
<h4 id="redo-log与binlog区别">redo log与binlog区别</h4>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1656857408492.png" alt="" loading="lazy"></figure>
<p>由 <code>binlog</code> 和 <code>redo log</code> 的区别可知：<code>binlog</code> 日志只用于归档，只依靠 <code>binlog</code> 是没有 <code>crash-safe</code> 能力的。</p>
<p>但只有 <code>redo log</code> 也不行，因为 <code>redo log</code> 是 <code>InnoDB</code>特有的，且日志上的记录落盘后会被覆盖掉。因此需要 <code>binlog</code>和 <code>redo log</code>二者同时记录，才能保证当数据库发生宕机重启时，数据不会丢失。</p>
<h3 id="undo-log">undo log</h3>
<p>数据库事务四大特性中有一个是 <strong>原子性</strong> ，具体来说就是 <strong>原子性是指对数据库的一系列操作，要么全部成功，要么全部失败，不可能出现部分成功的情况</strong>。</p>
<p>实际上， <strong>原子性</strong> 底层就是通过 <code>undo log</code> 实现的。<code>undo log</code>主要记录了数据的逻辑变化，比如一条 <code>INSERT</code> 语句，对应一条<code>DELETE</code> 的 <code>undo log</code> ，对于每个 <code>UPDATE</code> 语句，对应一条相反的 <code>UPDATE</code> 的 <code>undo log</code> ，这样在发生错误时，就能回滚到事务之前的数据状态。</p>
<p>同时， <code>undo log</code> 也是 <code>MVCC</code>(多版本并发控制)实现的关键。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[RocketMQ]]></title>
        <id>https://tinaxiawuhao.github.io/post/BvbuvYGnx/</id>
        <link href="https://tinaxiawuhao.github.io/post/BvbuvYGnx/">
        </link>
        <updated>2022-04-27T12:08:50.000Z</updated>
        <content type="html"><![CDATA[<h3 id="可用性评估">可用性评估</h3>
<p>系统可用性(Availability)是信息工业界用来衡量一个信息系统提供持续服务的能力，它表示的是在给定时间区间内系统或者系统某一能力在特定环境中能够正常工作的概率。</p>
<p>简单地说， 可用性是平均故障间隔时间(MTBF)除以平均故障间隔时间(MTBF)和平均故障修复时间(MTTR)之和所得的结果， 即：</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1657627908926.png" alt="" loading="lazy"></figure>
<p>通常业界习惯用N个9来表征系统可用性，表示系统可以正常使用时间与总时间(1年)之比，比如：</p>
<ul>
<li>99.9%代表3个9的可用性，意味着全年不可用时间在8.76小时以内，表示该系统在连续运行1年时间里最多可能的业务中断时间是8.76小时；</li>
<li>99.99%代表4个9的可用性，意味着全年不可用时间在52.6分钟以内,表示该系统在连续运行1年时间里最多可能的业务中断时间是52.6分钟；</li>
<li>99.999%代表5个9的可用性，意味着全年不可用时间必须保证在5.26分钟以内，缺少故障自动恢复机制的系统将很难达到5个9的高可用性。</li>
</ul>
<p>那么X个9里的X只代表数字35，为什么没有12，也没有大于6的呢？</p>
<p>我们接着往下计算：</p>
<pre><code>1个9：(1-90%)*365=36.5天 

*2个9：(1-99%)*365=3.65天 

6个9：(1-99.9999%)*365*24*60*60=31秒
</code></pre>
<p>可以看到1个9和、2个9分别表示一年时间内业务可能中断的时间是36.5天、3.65天，这种级别的可靠性或许还不配使用“可靠性”这个词；</p>
<p>而6个9则表示一年内业务中断时间最多是31秒，那么这个级别的可靠性并非实现不了，而是要做到从“5个9” 到“6个9”的可靠性提升的话，后者需要付出比前者几倍的成本。</p>
<h3 id="rocketmq架构设计">RocketMQ架构设计</h3>
<p>在介绍RocketMQ高可用之前，首先了解一下RocketMQ架构设计</p>
<ul>
<li>技术架构</li>
<li>部署架构</li>
</ul>
<h4 id="技术架构">技术架构</h4>
<p>RocketMQ架构上主要分为四部分，如图所示:</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1657627944749.png" alt="" loading="lazy"></figure>
<ul>
<li>Producer：消息发布的角色，支持分布式集群方式部署。Producer通过MQ的负载均衡模块选择相应的Broker集群队列进行消息投递，投递的过程支持快速失败并且低延迟。</li>
<li>Consumer：消息消费的角色，支持分布式集群方式部署。支持以push推，pull拉两种模式对消息进行消费。同时也支持集群方式和广播方式的消费，它提供实时消息订阅机制，可以满足大多数用户的需求。</li>
<li>NameServer：NameServer是一个非常简单的Topic路由注册中心，其角色类似Dubbo中的zookeeper，支持Broker的动态注册与发现。主要包括两个功能：Broker管理，NameServer接受Broker集群的注册信息并且保存下来作为路由信息的基本数据。然后提供心跳检测机制，检查Broker是否还存活；路由信息管理，每个NameServer将保存关于Broker集群的整个路由信息和用于客户端查询的队列信息。然后Producer和Conumser通过NameServer就可以知道整个Broker集群的路由信息，从而进行消息的投递和消费。NameServer通常也是集群的方式部署，各实例间相互不进行信息通讯。Broker是向每一台NameServer注册自己的路由信息，所以每一个NameServer实例上面都保存一份完整的路由信息。当某个NameServer因某种原因下线了，Broker仍然可以向其它NameServer同步其路由信息，Producer,Consumer仍然可以动态感知Broker的路由的信息。</li>
<li>BrokerServer：Broker主要负责消息的存储、投递和查询以及服务高可用保证，为了实现这些功能，Broker包含了以下几个重要子模块。
<ul>
<li>
<ol>
<li>Remoting Module：整个Broker的实体，负责处理来自clients端的请求。</li>
</ol>
</li>
<li>
<ol start="2">
<li>Client Manager：负责管理客户端(Producer/Consumer)和维护Consumer的Topic订阅信息</li>
</ol>
</li>
<li>
<ol start="3">
<li>Store Service：提供方便简单的API接口处理消息存储到物理硬盘和查询功能。</li>
</ol>
</li>
<li>
<ol start="4">
<li>HA Service：高可用服务，提供Master Broker 和 Slave Broker之间的数据同步功能。</li>
</ol>
</li>
<li>
<ol start="5">
<li>Index Service：根据特定的Message key对投递到Broker的消息进行索引服务，以提供消息的快速查询。</li>
</ol>
</li>
</ul>
</li>
</ul>
<h4 id="部署架构">部署架构</h4>
<p>RocketMQ的Broker有三种集群部署方式：</p>
<ul>
<li>1.单台Master部署；</li>
<li>2.多台Master部署；</li>
<li>3.多Master多Slave部署；</li>
</ul>
<p>基础的rocket高可用，主要采用第3种部署方式</p>
<p>下图是第3种部署方式的简单图：</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1657627968609.png" alt="" loading="lazy"></figure>
<p>第3种部署方式网络部署特点</p>
<ul>
<li>NameServer是一个几乎无状态节点，可集群部署，节点之间无任何信息同步。</li>
<li>Broker部署相对复杂，Broker分为Master与Slave，一个Master可以对应多个Slave，但是一个Slave只能对应一个Master，Master与Slave 的对应关系通过指定相同的BrokerName，不同的BrokerId 来定义，BrokerId为0表示Master，非0表示Slave。Master也可以部署多个。每个Broker与NameServer集群中的所有节点建立长连接，定时注册Topic信息到所有NameServer。 注意：当前RocketMQ版本在部署架构上支持一Master多Slave，但只有BrokerId=1的从服务器才会参与消息的读负载。</li>
<li>Producer与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从NameServer获取Topic路由信息，并向提供Topic 服务的Master建立长连接，且定时向Master发送心跳。Producer完全无状态，可集群部署。</li>
<li>Consumer与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从NameServer获取Topic路由信息，并向提供Topic服务的Master、Slave建立长连接，且定时向Master、Slave发送心跳。Consumer既可以从Master订阅消息，也可以从Slave订阅消息，消费者在向Master拉取消息时，Master服务器会根据拉取偏移量与最大偏移量的距离（判断是否读老消息，产生读I/O），以及从服务器是否可读等因素建议下一次是从Master还是Slave拉取。</li>
</ul>
<p>结合部署架构图，描述集群工作流程：</p>
<ul>
<li>启动NameServer，NameServer起来后监听端口，等待Broker、Producer、Consumer连上来，相当于一个路由控制中心。</li>
<li>Broker启动，跟所有的NameServer保持长连接，定时发送心跳包。心跳包中包含当前Broker信息(IP+端口等)以及存储所有Topic信息。注册成功后，NameServer集群中就有Topic跟Broker的映射关系。</li>
<li>收发消息前，先创建Topic，创建Topic时需要指定该Topic要存储在哪些Broker上，也可以在发送消息时自动创建Topic。</li>
<li>Producer发送消息，启动时先跟NameServer集群中的其中一台建立长连接，并从NameServer中获取当前发送的Topic存在哪些Broker上，轮询从队列列表中选择一个队列，然后与队列所在的Broker建立长连接从而向Broker发消息。</li>
<li>Consumer跟Producer类似，跟其中一台NameServer建立长连接，获取当前订阅Topic存在哪些Broker上，然后直接跟Broker建立连接通道，开始消费消息。</li>
</ul>
<h4 id="汇总rocketmq-集群部署模式">汇总：RocketMQ 集群部署模式</h4>
<p>前面介绍到，RocketMQ的Broker有三种集群部署方式：</p>
<ul>
<li>1.单台Master部署；</li>
<li>2.多台Master部署；</li>
<li>3.多Master多Slave部署；</li>
</ul>
<p>第三种模式，根据Master和Slave之节的数据同步方式可以分为：</p>
<ul>
<li>多 master 多 slave 异步复制模式</li>
<li>多 master 多 slave 同步复制模式</li>
</ul>
<blockquote>
<p>同步方式：同步复制和异步复制（指的一组 master 和 slave 之间数据的同步）</p>
</blockquote>
<p>所以，总体来说，RocketMQ 集群部署模式为四种：</p>
<ul>
<li>
<p>1.<strong>单 master 模式</strong> 也就是只有一个 master 节点，如果master节点挂掉了，会导致整个服务不可用，线上不宜使用，适合个人学习使用。</p>
</li>
<li>
<p>2.<strong>多 master 模式</strong> 多个 master 节点组成集群，单个 master 节点宕机或者重启对应用没有影响。 优点：所有模式中性能最高 缺点：单个 master 节点宕机期间，未被消费的消息在节点恢复之前不可用，消息的实时性就受到影响。 注意：使用同步刷盘可以保证消息不丢失，同时 Topic 相对应的 queue 应该分布在集群中各个 master 节点，而不是只在某各 master 节点上，否则，该节点宕机会对订阅该 topic 的应用造成影响。</p>
</li>
<li>
<p>3.<strong>多 master 多 slave 异步复制模式</strong> 在多 master 模式的基础上，每个 master 节点都有至少一个对应的 slave。</p>
<p>master 节点可读可写，但是 slave 只能读不能写，类似于 mysql 的主备模式。 优点： 在 master 宕机时，消费者可以从 slave 读取消息，消息的实时性不会受影响，性能几乎和多 master 一样。 缺点：使用异步复制的同步方式有可能会有消息丢失的问题。</p>
</li>
<li>
<p>4.<strong>多 master 多 slave 同步双写模式</strong> 同多 master 多 slave 异步复制模式类似，区别在于 master 和 slave 之间的数据同步方式。 优点：同步双写的同步模式能保证数据不丢失。 缺点：发送单个消息 RT 会略长，性能相比异步复制低10%左右。 刷盘策略：同步刷盘和异步刷盘（指的是节点自身数据是同步还是异步存储） 注意：要保证数据可靠，需采用同步刷盘和同步双写的方式，但性能会较其他方式低。</p>
</li>
</ul>
<h3 id="rocketmq与zookeeper的爱恨纠葛">RocketMQ与ZooKeeper的爱恨纠葛</h3>
<p>说到高性能消息中间件，第一个想到的肯定是LinkedIn开源的Kafka，虽然最初Kafka是为日志传输而生，但也非常适合互联网公司消息服务的应用场景，他们不要求数据实时的强一致性（事务），更多是希望达到数据的最终一致性。</p>
<p>RocketMQ是MetaQ的3.0版本，而MetaQ最初的设计又参考了Kafka。最初的MetaQ 1.x版本由阿里的原作者庄晓丹开发，后面的MetaQ 2.x版本才进行了开源。</p>
<p>MetaQ 1.x和MetaQ 2.x是依赖ZooKeeper的，但RocketMQ（即MetaQ 3.x）却去掉了ZooKeeper依赖，转而采用自己的NameServer。</p>
<p>ZooKeeper是著名的分布式协作框架，提供了Master选举、分布式锁、数据的发布和订阅等诸多功能。为什么RocketMQ没有选择ZooKeeper，而是自己开发了NameServer，我们来具体看看NameServer在RocketMQ集群中的作用就明了了。</p>
<h4 id="rocketmq的broker有三种集群部署方式">RocketMQ的Broker有三种集群部署方式</h4>
<p>RocketMQ的Broker有三种集群部署方式：</p>
<ul>
<li>1.单台Master部署；</li>
<li>2.多台Master部署；</li>
<li>3.多Master多Slave部署；</li>
</ul>
<p>采用第3种部署方式时，Master和Slave可以采用同步复制和异步复制两种方式。</p>
<p>下图是第3种部署方式的简单图：</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1657628006696.png" alt="" loading="lazy"></figure>
<p>当采用多Master方式时，Master与Master之间是不需要知道彼此的，这样的设计直接降低了Broker实现的复杂性。</p>
<p>你可以试想，如果Master与Master之间需要知道彼此的存在，这会需要在Master之中维护一个网络的Master列表，而且必然设计到Master发现和活跃Master数量变更等诸多状态更新问题，所以最简单也最可靠的做法就是Master只做好自己的事情（比如和Slave进行数据同步）即可。</p>
<blockquote>
<p>这样，在分布式环境中，某台Master宕机或上线，不会对其他Master造成任何影响。</p>
</blockquote>
<p>那么怎么才能知道网络中有多少台Master和Slave呢？</p>
<p>你会很自然想到用ZooKeeper，每个活跃的Master或Slave都去约定的ZooKeeper节点下注册一个状态节点，但RocketMQ没有使用ZooKeeper，所以这件事就交给了NameServer来做了（看上图）。</p>
<h4 id="nameserver的功能">NameServer的功能</h4>
<p>功能一：NameServer用来保存活跃的broker列表，包括Master和Slave。</p>
<p>功能二：NameServer用来保存所有topic和该topic所有队列的列表。</p>
<p>功能三：NameServer用来保存所有broker的Filter列表。</p>
<p>功能四：NameServer可以理解承担了注册中心的职能</p>
<h4 id="nameserver注册中心职能">NameServer注册中心职能</h4>
<p>NameServer是一个非常简单的路由注册中心，其角色类似Dubbo中的zookeeper，支持Broker的动态注册与发现。</p>
<ul>
<li>Broker管理，NameServer接受Broker集群的注册信息并且保存下来作为路由信息的基本数据。然后提供心跳检测机制，检查Broker是否还存活；</li>
<li>路由信息管理，每个NameServer将保存关于Broker集群的整个路由信息和用于客户端查询的队列信息。然后Producer和Conumser通过NameServer就可以知道整个Broker集群的路由信息，从而进行消息的投递和消费</li>
</ul>
<p>整个Rocketmq集群的工作原理如下图所示：</p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1657628018847.png" alt="" loading="lazy"></figure>
<p>可以看到，Broker集群、Producer集群、Consumer集群都需要与NameServer集群进行通信：</p>
<p><strong>Broker集群:</strong></p>
<p>Broker用于接收生产者发送消息，或者消费者消费消息的请求。一个Broker集群由多组Master/Slave组成，Master可写可读，Slave只可以读，Master将写入的数据同步给Slave。</p>
<p>每个Broker节点，在启动时，都会遍历NameServer列表，与每个NameServer建立长连接，注册自己的信息，之后定时上报。</p>
<p><strong>Producer集群:</strong></p>
<p>消息的生产者，通过NameServer集群获得Topic的路由信息，包括Topic下面有哪些Queue，这些Queue分布在哪些Broker上等。Producer只会将消息发送到Master节点上，因此只需要与Master节点建立连接。</p>
<p><strong>Consumer集群:</strong></p>
<p>消息的消费者，通过NameServer集群获得Topic的路由信息，连接到对应的Broker上消费消息。注意，由于Master和Slave都可以读取消息，因此Consumer会与Master和Slave都建立连接。</p>
<p>总之：</p>
<p>Name Server 是专为 RocketMQ 设计的轻量级注册中心，具有简单、可集群横吐扩展、无状态，节点之间互不通信等特点。</p>
<h4 id="rocketmq为什么不使用zookeeper">RocketMQ为什么不使用ZooKeeper</h4>
<p>来看看RocketMQ为什么不使用ZooKeeper？</p>
<p>ZooKeeper可以提供Master选举功能。比如Kafka用来给每个分区选一个broker作为leader。</p>
<p>但对于RocketMQ来说，topic的数据在每个Master上是对等的，没有哪个Master上有topic上的全部数据，所以这里选举leader没有意义；</p>
<p>RockeqMQ集群中，需要有构件来处理一些通用数据，比如broker列表，broker刷新时间。</p>
<p>虽然ZooKeeper也能存放数据，并有一致性保证。但处理数据之间的一些逻辑关系却比较麻烦，而且数据的逻辑解析操作得交给ZooKeeper客户端来做，如果有多种角色的客户端存在，自己解析多级数据确实是个麻烦事情；</p>
<p>既然RocketMQ集群中没有用到ZooKeeper的一些重量级的功能，只是使用ZooKeeper的数据一致性和发布订阅的话，与其依赖重量级的ZooKeeper，还不如写个轻量级的NameServer，NameServer也可以集群部署，NameServer与NameServer之间无任何信息同步，不需要保障数据一致性， 比zk简单太多。</p>
<h4 id="nameserver特性">NameServer特性</h4>
<ul>
<li>NameServer通常也是集群的方式部署，各实例间相互不进行信息通讯。Broker是向每一台NameServer注册自己的路由信息，所以每一个NameServer实例上面都保存一份完整的路由信息。当某个NameServer因某种原因下线了，Broker仍然可以向其它NameServer同步其路由信息，Producer，Consumer仍然可以动态感知Broker的路由的信息。</li>
<li>NameServer实例时间互不通信，这本身也是其设计亮点之一，即允许不同NameServer之间数据不同步(像Zookeeper那样保证各节点数据强一致性会带来额外的性能消耗)</li>
</ul>
<h3 id="rocketmq-的消息类型">RocketMQ 的消息类型</h3>
<p>RocketMQ 支持普通消息，顺序消息、事务消息，等等多种消息类型：</p>
<ul>
<li>普通消息：没有特殊功能的消息。</li>
<li>分区顺序消息：以分区纬度保持顺序进行消费的消息。</li>
<li>全局顺序消息：全局顺序消息可以看作是只分一个区，始终在同一个分区上进行消费。</li>
<li>定时/延时消息：消息可以延迟一段特定时间进行消费。</li>
<li>事务消息：二阶段事务消息，先进行prepare投递消息，此时不能进行消息消费，当二阶段发出commit或者rollback的时候才会进行消息的消费或者回滚。</li>
</ul>
<p>虽然配置种类比较繁多，但是使用的还是普通消息和分区顺序消息。</p>
<p>本文的主要介绍高可用，主要介绍普通消息，其他消息的高可用策略，也是类似侧。</p>
<h3 id="rocketmq高可用">RocketMQ高可用</h3>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1657628078933.png" alt="" loading="lazy"></figure>
<h4 id="nameserver-高可用">NameServer 高可用</h4>
<p>由于 NameServer 节点是无状态的，且各个节点直接的数据是一致的，故存在多个 NameServer 节点的情况下，部分 NameServer 不可用也可以保证 MQ 服务正常运行</p>
<h4 id="brokerserver-高可用">BrokerServer 高可用</h4>
<p>RocketMQ是通过 Master 和 Slave 的配合达到 BrokerServer 模块的高可用性的</p>
<p>一个 Master 可以配置多个 Slave，同时也支持配置多个 Master-Slave 组。</p>
<p><strong>当其中一个 Master 出现问题时：</strong></p>
<ul>
<li>由于Slave只负责读，当 Master 不可用，它对应的 Slave 仍能保证消息被正常消费</li>
<li>由于配置多组 Master-Slave 组，其他的 Master-Slave 组也会保证消息的正常发送和消费</li>
</ul>
<p>老版本的RocketMQ不支持把Slave自动转成Master，如果机器资源不足， 需要把Slave转成Master，则要手动停止Slave角色的Broker，更改配置文 件，用新的配置文件启动Broker。</p>
<p>新版本的RocketMQ，支持Slave自动转成Master。</p>
<h4 id="consumer高可用">consumer高可用</h4>
<p>Consumer 的高可用是依赖于 Master-Slave 配置的，由于 Master 能够支持读写消息，Slave 支持读消息，当 Master 不可用或繁忙时， Consumer 会被自动切换到从 Slave 读取(自动切换，无需配置)。</p>
<p>故当 Master 的机器故障后，消息仍可从 Slave 中被消费</p>
<h4 id="producer高可用">producer高可用</h4>
<p>在创建Topic的时候，把Topic的多个Message Queue创建在多个Broker组上（相同Broker名称，不同 brokerId的机器组成一个Broker组）.</p>
<p>这样当一个Broker组的Master不可用后，其他组的Master仍然可用，Producer仍然可以发送消息。</p>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1657628094386.png" alt="" loading="lazy"></figure>
<h3 id="实现分布式集群多副本的三种方式">实现分布式集群多副本的三种方式</h3>
<h4 id="ms模式">M/S模式</h4>
<p>即Master/Slaver模式。</p>
<p>该模式在过去使用的最多，RocketMq之前也是使用这样的主从模式来实现的。</p>
<p>主从模式分为同步模式和异步模式，区别是在同步模式下只有主从复制完毕才会返回给客户端；而在异步模式中，主从的复制是异步的，不用等待即可返回。</p>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1657628109179.png" alt="" loading="lazy"></figure>
<p>同步模式</p>
<p><strong>同步模式特点</strong></p>
<figure data-type="image" tabindex="9"><img src="https://tinaxiawuhao.github.io/post-images/1657628128161.png" alt="" loading="lazy"></figure>
<p>异步模式</p>
<p><strong>异步模式特点</strong></p>
<h4 id="基于zookeeper服务">基于zookeeper服务</h4>
<figure data-type="image" tabindex="10"><img src="https://tinaxiawuhao.github.io/post-images/1657628139871.png" alt="" loading="lazy"></figure>
<p>和M/S模式相比zookeeper模式是自动选举的主节点，新版本rocketMq暂时不支持zookeeper。</p>
<h4 id="基于raft">基于raft</h4>
<figure data-type="image" tabindex="11"><img src="https://tinaxiawuhao.github.io/post-images/1657628150637.png" alt="" loading="lazy"></figure>
<p>相比zookeeper，raft自身就可以实现选举，raft通过投票的方式实现自身选举leader。去除额外依赖。目前RocketMq 4.5.0已经支持</p>
<h3 id="可用性与可靠性">可用性与可靠性</h3>
<p><strong>可用性</strong></p>
<p>由于消息分布在各个broker上，一旦某个broker宕机，则该broker上的消息读写都会受到影响。所以rocketmq提供了master/slave的结构，salve定时从master同步数据，如果master宕机，则slave提供消费服务，但是不能写入消息，此过程对应用透明，由rocketmq内部解决。</p>
<p>这里有两个关键点：</p>
<ul>
<li>一旦某个broker master宕机，生产者和消费者多久才能发现？受限于rocketmq的网络连接机制，默认情况下，最多需要30秒，但这个时间可由应用设定参数来缩短时间。这个时间段内，发往该broker的消息都是失败的，而且该broker的消息无法消费，因为此时消费者不知道该broker已经挂掉。</li>
<li>消费者得到master宕机通知后，转向slave消费，但是slave不能保证master的消息100%都同步过来了，因此会有少量的消息丢失。但是消息最终不会丢的，一旦master恢复，未同步过去的消息会被消费掉。</li>
</ul>
<p><strong>可靠性</strong></p>
<ul>
<li>所有发往broker的消息，有同步刷盘和异步刷盘机制，总的来说，可靠性非常高</li>
<li>同步刷盘时，消息写入物理文件才会返回成功，因此非常可靠</li>
<li>异步刷盘时，只有机器宕机，才会产生消息丢失，broker挂掉可能会发生，但是机器宕机崩溃是很少发生的，除非突然断电</li>
</ul>
<h3 id="broker消息的零丢失方案">Broker消息的零丢失方案</h3>
<h4 id="同步刷盘-异步刷盘">同步刷盘、异步刷盘</h4>
<p>RocketMQ的消息是存储到磁盘上的，这样既能保证断电后恢复，又可以让存储的消息量超出内存的限制。RocketMQ为了提高性能，会尽可能地保证磁盘的顺序写。</p>
<p>消息在通过Producer写入RocketMQ的时候，有两种写磁盘方式：</p>
<ul>
<li>异步刷盘方式：</li>
</ul>
<p>在返回写成功状态时，消息可能只是被写入了内存的PAGECACHE，写操作的返回快，吞吐量大；当内存里的消息量积累到一定程度时，统一触发写磁盘操作，快速写入<br>
优点：性能高<br>
缺点：Master宕机，磁盘损坏的情况下，会丢失少量的消息, 导致MQ的消息状态和生产者/消费者的消息状态不一致</p>
<ul>
<li>同步刷盘方式：</li>
</ul>
<p>在返回应用写成功状态前，消息已经被写入磁盘。</p>
<p>具体流程是，消息写入内存的PAGECACHE后，立刻通知刷盘线程刷盘，然后等待刷盘完成，刷盘线程执行完成后唤醒等待的线程，给应用返回消息写成功的状态。</p>
<p>优点：可以保持MQ的消息状态和生产者/消费者的消息状态一致<br>
缺点：性能比异步的低<br>
同步刷盘还是异步刷盘，是通过Broker配置文件里的flushDiskType参数设置的，这个参数被设置成SYNC_FLUSH, ASYNC_FLUSH中的一个。</p>
<h4 id="同步复制-异步复制">同步复制、异步复制</h4>
<p>如果一个broker组有Master和Slave，消息需要从Master复制到Slave上，有同步和异步两种复制方式。</p>
<ul>
<li>同步复制方式：</li>
</ul>
<p>等Master和Slave均写成功后才反馈给客户端写成功状态<br>
优点：如果Master出故障，Slave上有全部的备份数据，容易恢复，消费者仍可以从Slave消费, 消息不丢失<br>
缺点：增大数据写入延迟，降低系统吞吐量，性能比异步复制模式略低，大约低10%左右，发送单个Master的响应时间会略高</p>
<ul>
<li>异步复制方式：</li>
</ul>
<p>只要Master写成功即可反馈给客户端写成功状态<br>
优点：系统拥有较低的延迟和较高的吞吐量. Master宕机之后，消费者仍可以从Slave消费，此过程对应用透明，不需要人工干预，性能同多个Master模式几乎一样<br>
缺点：如果Master出了故障，有些数据因为没有被写入Slave，而丢失少量消息。</p>
<p>若一个 Broker 组有一个 Master 和 Slave，消息需要从 Master 复制到 Slave 上，有同步复制和异步复制两种方式</p>
<table>
<thead>
<tr>
<th></th>
<th><strong>同步复制</strong></th>
<th><strong>异步复制</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>概念</strong></td>
<td>即等 Master 和 Slave 均写成功后才反馈给客户端写成功状态</td>
<td>只要 Master 写成功，就反馈客户端写成功状态</td>
</tr>
<tr>
<td><strong>可靠性</strong></td>
<td>可靠性高，若 Master 出现故障，Slave 上有全部的备份数据，容易恢复</td>
<td>若 Master 出现故障，可能存在一些数据还没来得及写入 Slave，可能会丢失</td>
</tr>
<tr>
<td><strong>效率</strong></td>
<td>由于是同步复制，会增加数据写入延迟，降低系统吞吐量</td>
<td>由于只要写入 Master 即可，故数据写入延迟较低，吞吐量较高</td>
</tr>
</tbody>
</table>
<p>同步复制和异步复制是通过Broker配置文件里的brokerRole参数进行设置的，这个参数可以被设置成ASYNC_MASTER、SYNC_MASTER、SLAVE三个值中的一个。</p>
<p>三个值的说明：</p>
<ul>
<li>sync_master是同步方式，Master角色Broker中的消息要立刻同步过去。</li>
<li>async_master是异步方式，Master角色Broker中的消息通过异步处理的方式同步到Slave角色的机器上。</li>
<li>SLAVE 表明当前是从节点，无需配置 brokerRole</li>
</ul>
<h4 id="消息零丢失方案">消息零丢失方案</h4>
<p>消息零丢失是一把双刃剑，要想用好，还是要视具体的业务场景，在性能和消息零丢失上做平衡。</p>
<p>实际应用中的推荐把Master和Slave设置成ASYNC_FLUSH的异步刷盘方式，主从之间配置成SYNC_MASTER的同步复制方式，这样即使有一台机器出故障，仍然可以保证数据不丢。</p>
<ul>
<li>刷盘方式</li>
</ul>
<p>Master和Slave都设置成ASYNC_FLUSH的异步刷盘</p>
<ul>
<li>复制方式</li>
</ul>
<p>Master配置成SYNC_MASTER 同步复制</p>
<p>异步刷盘能够避免频繁触发磁盘写操作，除非服务器宕机，否则不会造成消息丢失。</p>
<p>主从同步复制能够保证消息不丢失，即使 Master 节点异常，也能保证 Slave 节点存储所有消息并被正常消费掉。</p>
<h3 id="producer高可用-2">producer高可用</h3>
<p>producer具备发送到全部master的能力，如果有多个master，消息会发送到所有的master</p>
<figure data-type="image" tabindex="12"><img src="https://tinaxiawuhao.github.io/post-images/1657628176572.png" alt="" loading="lazy"></figure>
<p>另外，在topic的不同的queue之间，producer还具备负载均衡能力。</p>
<p>在实例发送消息时，默认会轮询所有订阅了改 Topic 的 broker 节点上的 message queue，让消息平均落在不同的 queue 上，而由于这些 queue 散落在不同的 broker 节点中，即使某个 broker 节点异常，其他存在订阅了这个 Topic 的 message queue 的 broker 依然能消费消息</p>
<h3 id="消息者业务代码出现异常怎么办">消息者业务代码出现异常怎么办？</h3>
<p>再来看一下消费者的代码中监听器的部分，它说如果消息处理成功，那么就返回消息状态为 CONSUME_SUCCESS，也有可能发放优惠券、积分等操作出现了异常，比如说数据库挂掉了。这个时候应该怎么处理呢？</p>
<pre><code class="language-java">consumer.registerMessageListener(new MessageListenerConcurrently() {
    @Override
    public ConsumeConcurrentlyStatus consumeMessage(List &lt;MessageExt&gt; list, ConsumeConcurrentlyContext consumeConcurrentlyContext) {
        // 对消息的处理，比如发放优惠券、积分等
        return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
    }
});
</code></pre>
<p>我们可以把代码改一改，捕获异常之后返回消息的状态为 RECONSUME_LATER 表示稍后重试。</p>
<pre><code class="language-java">// 这次回调接口，接收消息
consumer.registerMessageListener(new MessageListenerConcurrently() {
    @Override
    public ConsumeConcurrentlyStatus consumeMessage(List &lt;MessageExt&gt; list, ConsumeConcurrentlyContext consumeConcurrentlyContext) {
        try {
            // 对消息的处理，比如发放优惠券、积分等
            return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
        } catch (Exception e) {
            // 万一发生数据库宕机等异常，返回稍后重试消息的状态
            return ConsumeConcurrentlyStatus.RECONSUME_LATER;
        }

    }
});
</code></pre>
<p>这个时候，消息会进入到 RocketMQ 的重试队列中。</p>
<h4 id="重试队列">重试队列</h4>
<p>比如说消费者所属的消息组名称为<strong>AAAConsumerGroup</strong><br>
其重试队列名称就叫做**%RETRY%AAAConsumerGroup**<br>
重试队列中的消息过一段时间会再次发送给消费者，如果还是无法正常执行会再次进入重试队列<br>
默认重试16次，还是无法执行，消息就会从重试队列进入到死信队列</p>
<h4 id="死信队列">死信队列</h4>
<p>重试队列中的消息重试16次任然无法执行，将会进入到死信队列<br>
死信队列的名字是 <strong>%DLQ%AAAConsumerGroup</strong><br>
死信队列中的消息可以后台开一个线程，订阅**%DLQ%AAAConsumerGroup**，并不停重试</p>
<h3 id="customer-负载均衡">Customer 负载均衡</h3>
<h4 id="集群模式">集群模式</h4>
<p>在集群消费模式下，存在多个消费者同时消费消息，同一条消息只会被某一个消费者获取。即消息只需要被投递到订阅了这个 Topic 的消费者Group下的一个实例中即可。</p>
<p>消费者采用主动拉去的方式拉去并消费，在拉取的时候需要明确指定拉取那一条消息队列中的消息。</p>
<p>每当有实例变更，都会触发一次所有消费者实例的负载均衡，这是会按照queue的数量和实例的数量平均分配 queue 给每个消费者实例。</p>
<figure data-type="image" tabindex="13"><img src="https://tinaxiawuhao.github.io/post-images/1657628194080.png" alt="" loading="lazy"></figure>
<p><strong>注意：</strong></p>
<p>1）在集群模式下，一个 queue 只允许分配给一个消费者实例，这是由于若多个实例同时消费一个 queue 的小，由于拉取操作是由 consumer 主动发生的，可能导致同一个消息在不同的 consumer 实例中被消费。故算法保证了一个 queue 只会被一个 consumer 实例消费，但一个 consumer 实例能够消费多个 queue</p>
<p>2）控制 consumer 数量，应小于 queue 数量。这是由于一个 queue 只允许分配给一个 consumer 实例，若 consumer 实例数量多于 queue，则多出的 consumer 实例无法分配到 queue消费，会浪费系统资源</p>
<h4 id="广播模式">广播模式</h4>
<p>广播模式其实不是负载均衡，由于每个消费者都能够拿到所有消息，故不能达到负载均衡的要求</p>
<figure data-type="image" tabindex="14"><img src="https://tinaxiawuhao.github.io/post-images/1657628208176.png" alt="" loading="lazy"></figure>
<h3 id="消费者的消息重试">消费者的消息重试</h3>
<h3 id="顺序消息重试">顺序消息重试</h3>
<p>对于顺序消息，为了保证消息消费的顺序性，当consumer消费失败后，消息队列会自动不断进行消息重试(每次间隔时间为1s)，</p>
<p>这时会导致consumer消费被阻塞的情况，故必须保证应用能够及时监控并处理消费失败的情况，避免阻塞现象的发生</p>
<h3 id="无序消息重试">无序消息重试</h3>
<h4 id="概述">概述</h4>
<p>无序消息即普通、定时、延时、事务消息，当consumer消费消息失败时，可以通过设置返回状态实现消息重试</p>
<blockquote>
<p>注意：无序消息的重试只针对集群消费方式（非广播方式）生效</p>
</blockquote>
<p>广播方式不提供失败重试特性，即消费失败后，失败的消息不再重试，而是继续消费新消息</p>
<h4 id="重试次数">重试次数</h4>
<p>消息队列 RocketMQ 默认允许每条消息最多重试 16 次，每次重试的间隔时间如下：</p>
<table>
<thead>
<tr>
<th style="text-align:left">第几次重试</th>
<th style="text-align:left">与上次重试的间隔时间</th>
<th style="text-align:left">第几次重试</th>
<th style="text-align:left">与上次重试的间隔时间</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">1</td>
<td style="text-align:left">10 秒</td>
<td style="text-align:left">9</td>
<td style="text-align:left">7 分钟</td>
</tr>
<tr>
<td style="text-align:left">2</td>
<td style="text-align:left">30 秒</td>
<td style="text-align:left">10</td>
<td style="text-align:left">8 分钟</td>
</tr>
<tr>
<td style="text-align:left">3</td>
<td style="text-align:left">1 分钟</td>
<td style="text-align:left">11</td>
<td style="text-align:left">9 分钟</td>
</tr>
<tr>
<td style="text-align:left">4</td>
<td style="text-align:left">2 分钟</td>
<td style="text-align:left">12</td>
<td style="text-align:left">10 分钟</td>
</tr>
<tr>
<td style="text-align:left">5</td>
<td style="text-align:left">3 分钟</td>
<td style="text-align:left">13</td>
<td style="text-align:left">20 分钟</td>
</tr>
<tr>
<td style="text-align:left">6</td>
<td style="text-align:left">4 分钟</td>
<td style="text-align:left">14</td>
<td style="text-align:left">30 分钟</td>
</tr>
<tr>
<td style="text-align:left">7</td>
<td style="text-align:left">5 分钟</td>
<td style="text-align:left">15</td>
<td style="text-align:left">1 小时</td>
</tr>
<tr>
<td style="text-align:left">8</td>
<td style="text-align:left">6 分钟</td>
<td style="text-align:left">16</td>
<td style="text-align:left">2 小时</td>
</tr>
</tbody>
</table>
<blockquote>
<p>如果消息重试 16 次后仍然失败，消息将不再投递。</p>
</blockquote>
<p>如果严格按照上述重试时间间隔计算，某条消息在一直消费失败的前提下，将会在接下来的 4 小时 46 分钟之内进行 16 次重试，超过这个时间范围消息将不再重试投递。</p>
<p><strong>注意：</strong> 一条消息无论重试多少次，这些重试消息的 Message ID 不会改变。</p>
<h4 id="消息重试相关的处理方式">消息重试相关的处理方式</h4>
<h5 id="消费失败后需要重试的处理方式">消费失败后，需要重试的处理方式</h5>
<p>集群消费方式（非广播方式）下，消息消费失败后期望消息重试，需要在消息监听器接口的实现中明确进行配置（三种方式任选一种）：</p>
<ul>
<li>方式 1：返回 Action.ReconsumeLater（推荐）</li>
<li>方式 2：返回 Null</li>
<li>方式 3：抛出异常</li>
</ul>
<p>示例代码</p>
<pre><code class="language-java">public class MessageListenerImpl implements MessageListener {

    @Override
    public Action consume(Message message, ConsumeContext context) {
        //消息处理逻辑抛出异常，消息将重试
        doConsumeMessage(message);
   
       //方式 1：返回 Action.ReconsumeLater，消息将重试
        return Action.ReconsumeLater;
     
        //方式 2：返回 null，消息将重试
        return null;
   
        //方式 3：直接抛出异常，消息将重试
        throw new RuntimeException(&quot;Consumer Message exception&quot;);
    }
}
</code></pre>
<p>集群消费方式下，消息消费失败后期望消息重试，需要在消息监听器接口的实现中明确进行配置</p>
<h5 id="消费失败后无需重试的处理方式">消费失败后，无需重试的处理方式</h5>
<p>集群消费方式下，消息失败后期望消息不重试，需要捕获消费逻辑中可能抛出的异常，最终返回 Action.CommitMessage，此后这条消息将不会再重试。</p>
<pre><code class="language-java">public class MessageListenerImpl implements MessageListener {

    @Override
    public Action consume(Message message, ConsumeContext context) {
        try {
            doConsumeMessage(message);
        } catch (Throwable e) {
            //捕获消费逻辑中的所有异常，并返回 Action.CommitMessage;
            return Action.CommitMessage;
        }
        //消息处理正常，直接返回 Action.CommitMessage;
        return Action.CommitMessage;
    }
}
</code></pre>
<p><strong>3）自定义消息最大重试次数</strong></p>
<p>消息队列 RocketMQ 允许 Consumer 启动的时候设置最大重试次数，重试时间间隔将按照如下策略：</p>
<ul>
<li>最大重试次数小于等于 16 次，则重试时间间隔同上表描述。</li>
<li>最大重试次数大于 16 次，超过 16 次的重试时间间隔均为每次 2 小时。</li>
</ul>
<p><strong>设置方式：</strong></p>
<pre><code class="language-java">consumer.setMaxReconsumeTimes(20);
</code></pre>
<p>或者：</p>
<pre><code class="language-java">Properties properties = new Properties();
//配置对应 Group ID 的最大消息重试次数为 20 次，最大重试次数为字符串类型
properties.put(PropertyKeyConst.MaxReconsumeTimes,&quot;20&quot;);
Consumer consumer =ONSFactory.createConsumer(properties);
</code></pre>
<p><strong>注意：</strong></p>
<ul>
<li>消息最大重试次数设置，对相同 Group ID 下的所有 Consumer 实例有效。</li>
<li>如果只对相同 Group ID 下两个 Consumer 实例中的其中一个设置了 MaxReconsumeTimes，那么该配置对两个 Consumer 实例均生效。</li>
<li>配置采用覆盖的方式生效，即最后启动的 Consumer 实例会覆盖之前的启动实例的配置</li>
</ul>
<h5 id="获取消息重试次数">获取消息重试次数</h5>
<p>消费者收到消息后，可以获取到消息的重试次数</p>
<p><strong>设置方式：</strong></p>
<pre><code class="language-java">public class MessageListenerImpl implements MessageListener {
 
    @Override
    public Action consume(Message message, ConsumeContext context) {
        //获取消息的重试次数
        System.out.println(message.getReconsumeTimes());
        return Action.CommitMessage;
    }
}
</code></pre>
<h3 id="死信队列-2">死信队列</h3>
<h4 id="死信队列概念">死信队列概念</h4>
<blockquote>
<p>在正常情况下无法被消费(超过最大重试次数)的消息称为死信消息(Dead-Letter Message)，存储死信消息的特殊队列就称为死信队列(Dead-Letter Queue)</p>
</blockquote>
<p>当一条消息初次消费失败，消息队列 RocketMQ 会自动进行消息重试；</p>
<p>达到最大重试次数后，若消费依然失败，则表明消费者在正常情况下无法正确地消费该消息，此时，消息队列 RocketMQ 不会立刻将消息丢弃，而是将其发送到该<strong>消费者对应的死信队列</strong>中。</p>
<p>代码正常执行返回消息状态为CONSUME_SUCCESS，执行异常返回RECONSUME_LATER<br>
状态为RECONSUME_LATER的消息会进入到重试队列，重试队列的名称为 <code>%RETRY% + ConsumerGroupName</code>；<br>
重试16次消息任然没有处理成功，消息就会进入到死信队列<code>%DLQ% + ConsumerGroupName</code>;</p>
<h3 id="死信特性">死信特性</h3>
<p><strong>死信消息有以下特点：</strong></p>
<ul>
<li>不会再被消费者正常消费</li>
<li>有效期与正常消息相同，均为 3 天，3 天后会被自动删除。故死信消息应在产生的 3 天内及时处理</li>
</ul>
<p><strong>死信队列有以下特点：</strong></p>
<ul>
<li>一个死信队列对应一个消费者组，而不是对应单个消费者实例</li>
<li>一个死信队列包含了对应的 Group ID 所产生的所有死信消息，不论该消息属于哪个 Topic</li>
<li>若一个 Group ID 没有产生过死信消息，则 RocketMQ 不会为其创建相应的死信队列</li>
</ul>
<h3 id="查看死信信息和重发">查看死信信息和重发</h3>
<p>在控制台查看死信队列的主题信息</p>
<figure data-type="image" tabindex="15"><img src="https://tinaxiawuhao.github.io/post-images/1657628232656.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="16"><img src="https://tinaxiawuhao.github.io/post-images/1657628246206.png" alt="" loading="lazy"></figure>
<p><strong>重发消息</strong></p>
<figure data-type="image" tabindex="17"><img src="https://tinaxiawuhao.github.io/post-images/1657628261517.png" alt="" loading="lazy"></figure>
<h3 id="消息幂等性">消息幂等性</h3>
<h4 id="消费幂等">消费幂等</h4>
<p>消费幂等即无论消费者消费多少次，其结果都是一样的。</p>
<p>RocketMQ 是通过业务上的唯一 Key 来对消息做幂等处理</p>
<h4 id="消费幂等的必要性">消费幂等的必要性</h4>
<p>在网络环境中，由于网络不稳定等因素，消息队列的消息有可能出现重复，大概有以下几种：</p>
<ul>
<li>
<p><strong>发送时消息重复</strong></p>
<p>当一条消息已被成功发送到服务端并完成持久化，此时出现了网络闪断或者客户端宕机，导致服务端对客户端应答失败。 如果此时生产者意识到消息发送失败并尝试再次发送消息，消费者后续会收到两条内容相同并且 Message ID 也相同的消息。</p>
</li>
<li>
<p><strong>投递时消息重复</strong></p>
<p>消息消费的场景下，消息已投递到消费者并完成业务处理，当客户端给服务端反馈应答的时候网络闪断。 为了保证消息至少被消费一次，消息队列 RocketMQ 的服务端将在网络恢复后再次尝试投递之前已被处理过的消息，消费者后续会收到两条内容相同并且 Message ID 也相同的消息。</p>
</li>
<li>
<p><strong>负载均衡时消息重复</strong>（包括但不限于网络抖动、Broker 重启以及订阅方应用重启）</p>
<p>当消息队列 RocketMQ 的 Broker 或客户端重启、扩容或缩容时，会触发 Rebalance，此时消费者可能会收到重复消息。</p>
</li>
</ul>
<p>结合三种情况，可以发现消息重发的最后结果都是，消费者接收到了重复消息，那么，我们只需要在消费者端统一进行幂等处理就能够实现消息幂等。</p>
<h4 id="处理方式">处理方式</h4>
<h5 id="消费端实现消息幂等性">消费端实现消息幂等性</h5>
<p>RocketMQ 只能够保证消息丢失，但不能保证消息不重复投递，且由于高可用和高性能的考虑，应该在消费端实现消息幂等性。</p>
<p>那么 RocketMQ 是怎样解决消息重复的问题呢？还是“恰好”不解决。</p>
<p>造成消息重复的根本原因是：网络不可达。只要通过网络交换数据，就无法避免这个问题。所以解决这个问题的办法就是绕过这个问题。那么问题就变成了：如果消费端收到两条一样的消息，应该怎样处理？</p>
<blockquote>
<ul>
<li>消费端处理消息的业务逻辑保持幂等性</li>
<li>保证每条消息都有唯一编号且保证消息处理成功与去重表的日志同时出现</li>
</ul>
</blockquote>
<ul>
<li>第1条很好理解，只要保持幂等性，不管来多少条重复消息，最后处理的结果都一样。</li>
<li>第2条原理就是利用一张日志表来记录已经处理成功的消息的ID，如果新到的消息ID已经在日志表中，那么就不再处理这条消息。</li>
</ul>
<p>第1条解决方案，很明显应该在消费端实现，不属于消息系统要实现的功能。第2条可以消息系统实现，也可以业务端实现。正常情况下出现重复消息的概率其实很小，如果由消息系统来实现的话，肯定会对消息系统的吞吐量和高可用有影响，所以最好还是由业务端自己处理消息重复的问题，这也是 RocketMQ 不解决消息重复的问题的原因。</p>
<p><strong>RocketMQ 不保证消息不重复，如果你的业务需要保证严格的不重复消息，需要你自己在业务端去重。</strong></p>
<p>在消费端通过业务逻辑实现幂等性操作，最常用的方式就是唯一ID的形式，若已经消费过的消息就不进行处理。例如在秒杀系统中使用订单ID作为关键ID，分布式系统中常用雪花算法生成ID。</p>
<blockquote>
<p>注：如果需要彻底了解雪花算法，以及里边的位运算逻辑，请参见尼恩的秒杀视频。</p>
</blockquote>
<p>在发送消息时，可以对 Message 设置标识唯一标识：</p>
<pre><code class="language-java">Message message = new Message(); # 设置唯一标识，标识由雪花算法生成message.setKey(idWorker.nextId());
</code></pre>
<p>订阅方收到消息时，可以获取到这个 Key</p>
<pre><code class="language-java">consumer.registerMessageListener(new MessageListenerConcurrently()
{
    @Override
    public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context)
    {
        System.out.printf(&quot;%s Receive New Messages: %s %n&quot;, Thread.currentThread().getName(), msgs);
        for (MessageExt ext : msgs)
        {
            System.out.println(ext.getKeys());
        }
        return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
    }
});
</code></pre>
<h3 id="一-顺序消息">一、顺序消息</h3>
<p>顺序消息（FIFO 消息）是消息队列 RocketMQ 提供的一种严格按照顺序来发布和消费的消息。顺序发布和顺序消费是指对于指定的一个 Topic，生 产者按照一定的先后顺序发布消息；消费者按照既定的先后顺序订阅消息，即先发布的消息一定会先被客户端接收到。</p>
<blockquote>
<p>顺序消息分为全局顺序消息和分区顺序消息。</p>
</blockquote>
<h4 id="11-全局顺序消息">1.1、全局顺序消息</h4>
<p>RocketMQ 在默认情况下不保证顺序，要保证全局顺序，需要把 Topic 的读写队列数设置为 1，然后生产者和消费者的并发设置也是 1。所以这样的话 高并发，高吞吐量的功能完全用不上。<br>
<img src="https://tinaxiawuhao.github.io/post-images/1657628280551.png" alt="" loading="lazy"></p>
<h5 id="111-适用场景">1.1.1、适用场景</h5>
<p>适用于性能要求不高，所有的消息严格按照 FIFO 原则来发布和消费的场景。</p>
<h5 id="112-示例">1.1.2、示例</h5>
<p>要确保全局顺序消息，需要先把 Topic 的读写队列数设置为 1，然后生产者和消费者的并发设置也是 1。</p>
<pre><code class="language-shell">mqadmin update Topic -t AllOrder -c DefaultCluster -r 1 -w 1 -n 127.0.0.1:9876
</code></pre>
<p>在证券处理中，以人民币兑换美元为 Topic，在价格相同的情况下，先出价者优先处理，则可以按照 FIFO 的方式发布和消费全局顺序消息。</p>
<h4 id="12-部分顺序消息">1.2、部分顺序消息</h4>
<p>对于指定的一个 Topic，所有消息根据 Sharding Key 进行区块分区。同一个分区内的消息按照严格的 FIFO 顺序进行发布和消费。Sharding Key 是顺 序消息中用来区分不同分区的关键字段，和普通消息的 Key 是完全不同的概念。</p>
<h3 id="二-延时消息">二、延时消息</h3>
<h4 id="21-概念介绍">2.1、概念介绍</h4>
<p><strong>延时消息</strong>：Producer 将消息发送到消息队列 RocketMQ 服务端，但并不期望这条消息立马投递，而是延迟一定时间后才投递到 Consumer 进行消费， 该消息即延时消息。</p>
<h4 id="22-适用场景">2.2、适用场景</h4>
<p>消息生产和消费有时间窗口要求：比如在电商交易中超时未支付关闭订单的场景，在订单创建时会发送一条延时消息。这条消息将会在 30 分钟以 后投递给消费者，消费者收到此消息后需要判断对应的订单是否已完成支付。 如支付未完成，则关闭订单。如已完成支付则忽略。</p>
<h4 id="23-使用方式">2.3、使用方式</h4>
<p>Apache RocketMQ 目前只支持固定精度的定时消息，因为如果要支持任意的时间精度，在 Broker 层面，必须要做消息排序，如果再涉及到持久化， 那么消息排序要不可避免的产生巨大性能开销。<strong>（阿里云 RocketMQ 提供了任意时刻的定时消息功能，Apache 的 RocketMQ 并没有,阿里并没有开源）</strong><br>
发送延时消息时需要设定一个延时时间长度，消息将从当前发送时间点开始延迟固定时间之后才开始投递。<br>
延迟消息是根据延迟队列的 level 来的，延迟队列默认是<br>
**msg.setDelayTimeLevel(5)**代表延迟一分钟<br>
<strong>&quot;1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h&quot;</strong><br>
是这 18 个等级（秒（s）、分（m）、小时（h）），level 为 1，表示延迟 1 秒后消费，level 为 5 表示延迟 1 分钟后消费，level 为 18 表示延迟 2 个 小时消费。生产消息跟普通的生产消息类似，只需要在消息上设置延迟队列的 level 即可。消费消息跟普通的消费消息一致。</p>
<h3 id="三-死信队列">三、死信队列</h3>
<h4 id="31-概念介绍">3.1、概念介绍</h4>
<p>死信队列用于处理无法被正常消费的消息。当一条消息初次消费失败，消息队列 <strong>MQ</strong> 会自动进行消息重试；达到最大重试次数后，若消费依然失败， 则表明<strong>Consumer</strong> 在正常情况下无法正确地消费该消息。此时，消息队列<strong>MQ</strong>不会立刻将消息丢弃，而是将这条消息发送到该 <strong>Consumer</strong> 对应的特殊队列中。<br>
消息队列 <strong>MQ <strong>将这种正常情况下无法被消费的消息称为死信消息</strong>（Dead-Letter Message）</strong>，将存储死信消息的特殊队列称为死信队列 <strong>（Dead-Letter Queue)</strong>。</p>
<h4 id="32适用场景">3.2适用场景</h4>
<h5 id="321-死信消息的特性">3.2.1、死信消息的特性</h5>
<p>不会再被消费者正常消费。 有效期与正常消息相同，均为 3 天，3 天后会被自动删除。因此，请在死信消息产生后的 3 天内及时处理。</p>
<h5 id="322-死信队列的特性">3.2.2、死信队列的特性</h5>
<p>一个死信队列对应一个 Group ID， 而不是对应单个消费者实例。<br>
如果一个 <strong>Group ID</strong> 未产生死信消息，消息队列 <strong>MQ</strong> 不会为其创建相应的死信队列。<br>
一个死信队列包含了对应 Group ID 产生的所有死信消息，不论该消息属于哪个 <strong>Topic</strong>。<br>
消息队列 MQ 控制台提供对死信消息的查询的功能。</p>
<p>一般控制台直接查看死信消息会报错。<br>
<img src="https://tinaxiawuhao.github.io/post-images/1657628298619.png" alt="" loading="lazy"></p>
<p>进入<strong>RocketMQ</strong>中服务器对应的 <strong>RocketMQ</strong> 中的/bin 目录，执行以下脚本</p>
<pre><code class="language-shell">sh mqadmin updateTopic -b 192.168.0.128:10911 -n 192.168.0.128:9876 -t %DLQ%group1 -p 6
</code></pre>
<p><img src="https://tinaxiawuhao.github.io/post-images/1657628311169.png" alt="" loading="lazy"><br>
<img src="https://tinaxiawuhao.github.io/post-images/1657628322848.png" alt="" loading="lazy"></p>
<h3 id="四-消费幂等">四、消费幂等</h3>
<p>为了防止消息重复消费导致业务处理异常，消息队列 MQ 的消费者在接收到消息后，有必要根据业务上的唯一 Key 对消息做幂等处理。本文介绍消息幂 等的概念、适用场景以及处理方法。</p>
<h4 id="41-什么是消息幂等">4.1、什么是消息幂等</h4>
<p>当出现消费者对某条消息重复消费的情况时，重复消费的结果与消费一次的结果是相同的，并且多次消费并未对业务系统产生任何负面影响，那么 这整个过程就实现可消息幂等。<br>
例如，在支付场景下，消费者消费扣款消息，对一笔订单执行扣款操作，扣款金额为 100 元。如果因网络不稳定等原因导致扣款消息重复投递，消 费者重复消费了该扣款消息，但最终的业务结果是只扣款一次，扣费 100 元，且用户的扣款记录中对应的订单只有一条扣款流水，不会多次扣除费用。 那么这次扣款操作是符合要求的，整个消费过程实现了消费幂等。</p>
<h4 id="42-需要处理的场景">4.2、需要处理的场景</h4>
<p>在互联网应用中，尤其在网络不稳定的情况下，消息队列 MQ 的消息有可能会出现重复。如果消息重复会影响您的业务处理，请对消息做幂等处理。 消息重复的场景如下：<br>
**1. 发送时消息重复 **<br>
当一条消息已被成功发送到服务端并完成持久化，此时出现了网络闪断或者客户端宕机，导致服务端对客户端应答失败。 如果此时生产者意识到消 息发送失败并尝试再次发送消息，消费者后续会收到两条内容相同并且 Message ID 也相同的消息。<br>
**2. 投递时消息重复 **<br>
消息消费的场景下，消息已投递到消费者并完成业务处理，当客户端给服务端反馈应答的时候网络闪断。为了保证消息至少被消费一次，消息队列 MQ 的服务端将在网络恢复后再次尝试投递之前已被处理过的消息，消费者后续会收到两条内容相同并且 Message ID 也相同的消息。<br>
<strong>3. 负载均衡时消息重复（包括但不限于网络抖动、Broker 重启以及消费者应用重启）</strong><br>
当消息队列 MQ 的 Broker 或客户端重启、扩容或缩容时，会触发 Rebalance，此时消费者可能会收到重复消息。</p>
<h4 id="43-处理方法">4.3、处理方法</h4>
<p>因为 Message ID 有可能出现冲突（重复）的情况，所以真正安全的幂等处理，不建议以 Message ID 作为处理依据。最好的方式是以业务唯一标识 作为幂等处理的关键依据，而业务的唯一标识可以通过消息 Key 设置。<br>
以支付场景为例，可以将消息的 Key 设置为订单号，作为幂等处理的依据。具体代码示例如下：</p>
<pre><code class="language-java"> Message message = new Message();
  message.setKey(&quot;ORDERID_100&quot;); 
  SendResult sendResult = producer.send(message); 
</code></pre>
<p>消费者收到消息时可以根据消息的 Key，即订单号来实现消息幂等：</p>
<pre><code class="language-java"> consumer.subscribe(&quot;ons_test&quot;, &quot;*&quot;, new MessageListener() {
    
    
  public Action consume(Message message, ConsumeContext context) {
    
     
  String key = message.getKey()
   // 根据业务唯一标识的 Key 做幂等处理
    } });
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[CountDownLatch,CyclicBarrier,Semaphore的用法和区别]]></title>
        <id>https://tinaxiawuhao.github.io/post/bPYM5y-vS/</id>
        <link href="https://tinaxiawuhao.github.io/post/bPYM5y-vS/">
        </link>
        <updated>2022-04-20T11:55:53.000Z</updated>
        <content type="html"><![CDATA[<h3 id="countdownlatch">CountDownLatch</h3>
<blockquote>
<p>CountDownLatch（也叫闭锁）是一个同步协助类，允许一个或多个线程等待，直到其他线程完成操作集。</p>
</blockquote>
<p>CountDownLatch 使用给定的计数值（count）初始化。await 方法会阻塞直到当前的计数值（count）由于 countDown 方法的调用达到 0，count 为 0 之后所有等待的线程都会被释放，并且随后对await方法的调用都会立即返回。</p>
<h4 id="构造方法">构造方法</h4>
<pre><code class="language-java">//参数count为计数值
public CountDownLatch(int count) {}; 
</code></pre>
<h4 id="常用方法">常用方法</h4>
<pre><code class="language-java">// 调用 await() 方法的线程会被挂起，它会等待直到 count 值为 0 才继续执行
public void await() throws InterruptedException {};

// 和 await() 类似，若等待 timeout 时长后，count 值还是没有变为 0，不再等待，继续执行
public boolean await(long timeout, TimeUnit unit) throws InterruptedException {};

// 会将 count 减 1，直至为 0
public void countDown() {};
</code></pre>
<h4 id="使用案例">使用案例</h4>
<blockquote>
<p>首先是创建实例 CountDownLatch countDown = new CountDownLatch(2)；<br>
需要同步的线程执行完之后，计数 -1， countDown.countDown()；<br>
需要等待其他线程执行完毕之后，再运行的线程，调用 countDown.await()实现阻塞同步。</p>
</blockquote>
<p><strong>应用场景</strong><br>
CountDownLatch 一般用作多线程倒计时计数器，强制它们等待其他一组（CountDownLatch的初始化决定）任务执行完成。</p>
<p>CountDownLatch的两种使用场景：</p>
<blockquote>
<p>让多个线程等待，模拟并发。<br>
让单个线程等待，多个线程（任务）完成后，进行汇总合并。</p>
</blockquote>
<p><strong>场景 1：模拟并发</strong></p>
<pre><code class="language-java">import java.util.concurrent.CountDownLatch;

/**
 * 让多个线程等待：模拟并发，让并发线程一起执行
 */
public class CountDownLatchTest {
    public static void main(String[] args) throws InterruptedException {

        CountDownLatch countDownLatch = new CountDownLatch(1);
        
        for (int i = 0; i &lt; 5; i++) {
            new Thread(() -&gt; {
                try {
                    // 等待
                    countDownLatch.await();
                    String parter = &quot;【&quot; + Thread.currentThread().getName() + &quot;】&quot;;
                    System.out.println(parter + &quot;开始执行……&quot;);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }).start();
        }

        Thread.sleep(2000);
       
        countDownLatch.countDown();
    }
}
</code></pre>
<p><strong>场景 2：多个线程完成后，进行汇总合并</strong></p>
<p>很多时候，我们的并发任务，存在前后依赖关系；比如数据详情页需要同时调用多个接口获取数据，并发请求获取到数据后、需要进行结果合并；或者多个数据操作完成后，需要数据 check；这其实都是：在多个线程(任务)完成后，进行汇总合并的场景。</p>
<pre><code class="language-java">import java.util.Map;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.CountDownLatch;

/**
 * 让单个线程等待：多个线程(任务)完成后，进行汇总合并
 */
public class CountDownLatchTest3 {

    //用于聚合所有的统计指标
    private static Map map = new ConcurrentHashMap();
    //创建计数器，这里需要统计4个指标
    private static CountDownLatch countDownLatch = new CountDownLatch(4);

    public static void main(String[] args) throws Exception {

        //记录开始时间
        long startTime = System.currentTimeMillis();

        Thread countUserThread = new Thread(() -&gt; {
            try {
                System.out.println(&quot;正在统计新增用户数量&quot;);
                Thread.sleep(3000);//任务执行需要3秒
                map.put(&quot;userNumber&quot;, 100);//保存结果值
                System.out.println(&quot;统计新增用户数量完毕&quot;);
                countDownLatch.countDown();//标记已经完成一个任务
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        });
        Thread countOrderThread = new Thread(() -&gt; {
            try {
                System.out.println(&quot;正在统计订单数量&quot;);
                Thread.sleep(3000);//任务执行需要3秒
                map.put(&quot;countOrder&quot;, 20);//保存结果值
                System.out.println(&quot;统计订单数量完毕&quot;);
                countDownLatch.countDown();//标记已经完成一个任务
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        });

        Thread countGoodsThread = new Thread(() -&gt; {
            try {
                System.out.println(&quot;正在商品销量&quot;);
                Thread.sleep(3000);//任务执行需要3秒
                map.put(&quot;countGoods&quot;, 300);//保存结果值
                System.out.println(&quot;统计商品销量完毕&quot;);
                countDownLatch.countDown();//标记已经完成一个任务
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        });

        Thread countmoneyThread = new Thread(() -&gt; {
            try {
                System.out.println(&quot;正在总销售额&quot;);
                Thread.sleep(3000);//任务执行需要3秒
                map.put(&quot;countMoney&quot;, 40000);//保存结果值
                System.out.println(&quot;统计销售额完毕&quot;);
                countDownLatch.countDown();//标记已经完成一个任务
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        });
        
        //启动子线程执行任务
        countUserThread.start();
        countGoodsThread.start();
        countOrderThread.start();
        countmoneyThread.start();

        try {
            //主线程等待所有统计指标执行完毕
            countDownLatch.await();
            long endTime = System.currentTimeMillis();//记录结束时间
            System.out.println(&quot;------统计指标全部完成--------&quot;);
            System.out.println(&quot;统计结果为：&quot; + map);
            System.out.println(&quot;任务总执行时间为&quot; + (endTime - startTime) + &quot;ms&quot;);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }

    }
}
</code></pre>
<h3 id="cylicbarrier">CylicBarrier</h3>
<p>从字面上的意思可以知道，这个类的中文意思是“循环栅栏”。大概的意思就是一个可循环利用的屏障。</p>
<p>它的作用就是会让所有线程都等待完成后才会继续下一步行动。</p>
<p>现实生活中我们经常会遇到这样的情景，在进行某个活动前需要等待人全部都齐了才开始。例如吃饭时要等全家人都上座了才动筷子，旅游时要等全部人都到齐了才出发，比赛时要等运动员都上场后才开始。</p>
<p>在<code>JUC</code>包中为我们提供了一个同步工具类能够很好的模拟这类场景，它就是<code>CyclicBarrier</code>类。利用<code>CyclicBarrier</code>类可以实现一组线程相互等待，当所有线程都到达某个屏障点后再进行后续的操作。</p>
<p><code>CyclicBarrier</code>字面意思是“可重复使用的栅栏”，<code>CyclicBarrier</code>相比 <code>CountDownLatch</code>来说，要简单很多，其源码没有什么高深的地方，它是 <code>ReentrantLock</code> 和 <code>Condition</code> 的组合使用。</p>
<p>看如下示意图，<code>CyclicBarrier</code> 和 <code>CountDownLatch</code> 是不是很像，只是 <code>CyclicBarrier</code> 可以有不止一个栅栏，因为它的栅栏（Barrier）可以重复使用（Cyclic）。</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1656504599018.png" alt="" loading="lazy"></figure>
<p>就好比以前的那种客车一样，当第一轮车坐满之后发车，然后接着等第二辆车坐满之后在发车。</p>
<h4 id="构造方法-2">构造方法</h4>
<pre><code class="language-java">// parties表示屏障拦截的线程数量，每个线程调用 await 方法告诉 CyclicBarrier 我已经到达了屏障，然后当前线程被阻塞。
public CyclicBarrier(int parties)
    
// 用于在线程到达屏障时，优先执行 barrierAction，方便处理更复杂的业务场景(该线程的执行时机是在到达屏障之后再执行)
public CyclicBarrier(int parties, Runnable barrierAction)
</code></pre>
<h4 id="常用方法-2">常用方法</h4>
<pre><code class="language-java">//屏障 指定数量的线程全部调用await()方法时，这些线程不再阻塞
// BrokenBarrierException 表示栅栏已经被破坏，破坏的原因可能是其中一个线程 await() 时被中断或者超时
public int await() throws InterruptedException, BrokenBarrierException
    
public int await(long timeout, TimeUnit unit) throws InterruptedException, B
rokenBarrierException, TimeoutException
    
//循环 通过reset()方法可以进行重置
public void reset()
</code></pre>
<h4 id="使用案例-2">使用案例</h4>
<pre><code class="language-java">import java.util.concurrent.CyclicBarrier;

/**
 * CyclicBarrier(回环栅栏)允许一组线程互相等待，直到到达某个公共屏障点 (Common Barrier Point)
 * CountDownLatch 用于等待countDown事件，而栅栏用于等待其他线程。
 */
public class CyclicBarrierTest {

    public static void main(String[] args) {

        CyclicBarrier cyclicBarrier = new CyclicBarrier(3);

        for (int i = 0; i &lt; 5; i++) {
            new Thread(new Runnable() {
                @Override
                public void run() {
                    try {
                        System.out.println(Thread.currentThread().getName()
                                + &quot;开始等待其他线程&quot;);
                        cyclicBarrier.await();
                        System.out.println(Thread.currentThread().getName() + &quot;开始执行&quot;);
                        //TODO 模拟业务处理
                        Thread.sleep(5000);
                        System.out.println(Thread.currentThread().getName() + &quot;执行完毕&quot;);

                    } catch (Exception e) {
                        e.printStackTrace();
                    }
                }
            }).start();
        }
    }
}
</code></pre>
<p><strong>应用场景</strong><br>
可以用于多线程计算数据，最后合并计算结果的场景。</p>
<pre><code class="language-java">import java.util.Set;
import java.util.concurrent.*;

public class CyclicBarrierTest2 {

    //保存每个学生的平均成绩
    private ConcurrentHashMap&lt;String, Integer&gt; map = new ConcurrentHashMap&lt;String, Integer&gt;();

    private ExecutorService threadPool = Executors.newFixedThreadPool(3);

    private CyclicBarrier cb = new CyclicBarrier(3, () -&gt; {
        int result = 0;
        Set&lt;String&gt; set = map.keySet();
        for (String s : set) {
            result += map.get(s);
        }
        System.out.println(&quot;三人平均成绩为:&quot; + (result / 3) + &quot;分&quot;);
    });


    public void count() {
        for (int i = 0; i &lt; 3; i++) {
            threadPool.execute(new Runnable() {

                @Override
                public void run() {
                    //获取学生平均成绩
                    int score = (int) (Math.random() * 40 + 60);
                    map.put(Thread.currentThread().getName(), score);
                    System.out.println(Thread.currentThread().getName() + &quot;同学的平均成绩为：&quot; + score);
                    try {
                        //执行完运行await(),等待所有学生平均成绩都计算完毕
                        cb.await();
                    } catch (InterruptedException | BrokenBarrierException e) {
                        e.printStackTrace();
                    }
                }
            });
        }
    }


    public static void main(String[] args) {
        CyclicBarrierTest2 cb = new CyclicBarrierTest2();
        cb.count();
    }
}
</code></pre>
<p>测试结果：</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1656504516218.png" alt="" loading="lazy"></figure>
<h3 id="semaphore">Semaphore</h3>
<p>Semaphore，俗称信号量，基于 AbstractQueuedSynchronizer 实现。使用 Semaphore 可以控制同时访问资源的线程个数。</p>
<p>比如：停车场入口立着的那个显示屏，每有一辆车进入停车场显示屏就会显示剩余车位减 1，每有一辆车从停车场出去，显示屏上显示的剩余车辆就会加 1，当显示屏上的剩余车位为 0 时，停车场入口的栏杆就不会再打开，车辆就无法进入停车场了，直到有一辆车从停车场出去为止。</p>
<p>比如：在学生时代都去餐厅打过饭，假如有 3 个窗口可以打饭，同一时刻也只能有 3 名同学打饭。第 4 个人来了之后就必须在外面等着，只要有打饭的同学好了，就可以去相应的窗口了 。</p>
<h4 id="构造方法-3">构造方法</h4>
<pre><code class="language-java">//创建具有给定的许可数和非公平的公平设置的 Semaphore。  
Semaphore(int permits)   

//创建具有给定的许可数和给定的公平设置的 Semaphore。  
Semaphore(int permits, boolean fair)   
</code></pre>
<blockquote>
<p>permits 表示许可证的数量（资源数），就好比一个学生可以占用 3 个打饭窗口。<br>
fair 表示公平性，如果这个设为 true 的话，下次执行的线程会是等待最久的线程。</p>
</blockquote>
<h4 id="常用方法-3">常用方法</h4>
<pre><code class="language-java">public void acquire() throws InterruptedException
public boolean tryAcquire()
public void release()
public int availablePermits()
public final int getQueueLength()
public final boolean hasQueuedThreads()
protected void reducePermits(int reduction)
protected Collection&lt;Thread&gt; getQueuedThreads()
</code></pre>
<blockquote>
<p>acquire()：表示阻塞并获取许可。<br>
tryAcquire()：方法在没有许可的情况下会立即返回 false，要获取许可的线程不会阻塞。<br>
release()：表示释放许可。<br>
int availablePermits()：返回此信号量中当前可用的许可证数。<br>
int getQueueLength()：返回正在等待获取许可证的线程数。<br>
boolean hasQueuedThreads()：是否有线程正在等待获取许可证。<br>
void reducePermit(int reduction)：减少 reduction 个许可证。<br>
Collection getQueuedThreads()：返回所有等待获取许可证的线程集合。</p>
</blockquote>
<h4 id="使用案例-3">使用案例</h4>
<p>我们可以模拟车站买票，假如车站有 3 个窗口售票，那么同一时刻每个窗口只能存在一个人买票，其他人则等待前面的人完成后才可以去买票。</p>
<pre><code class="language-java">import java.util.concurrent.Semaphore;

public class SemaphoreTest {

    public static void main(String[] args) {
        // 3 个窗口
        Semaphore windows = new Semaphore(3);
        // 模拟 5 个人购票
        for (int i = 0; i &lt; 5; i++) {
            new Thread(new Runnable() {
                @Override
                public void run() {
                    // 占用窗口，加锁
                    try {
                        windows.acquire();
                        System.out.println(Thread.currentThread().getName() + &quot;：开始购票&quot;);
                        // 买票
                        Thread.sleep(5000);
                        System.out.println(Thread.currentThread().getName() + &quot;：购票成功&quot;);
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    } finally {
                        // 释放许可，释放窗口
                        windows.release();
                    }
                }
            }, &quot;Thread&quot; + i).start();
        }
    }
}
</code></pre>
<p>测试结果如下：</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1656504535515.png" alt="" loading="lazy"></figure>
<p>很明显可以看到当前面 3 个线程购票成功之后，剩余的线程再开始购票。</p>
<p><strong>应用场景</strong><br>
可以用于做流量控制，特别是公用资源有限的应用场景。</p>
<p>如我们实现一个同时只能处理 5 个请求的限流器。</p>
<pre><code class="language-java">import java.util.concurrent.LinkedBlockingDeque;
import java.util.concurrent.Semaphore;
import java.util.concurrent.ThreadPoolExecutor;
import java.util.concurrent.TimeUnit;

public class SemaphoneTest2 {

    /**
     * 实现一个同时只能处理5个请求的限流器
     */
    private static Semaphore semaphore = new Semaphore(5);

    /**
     * 定义一个线程池
     * 0
     */
    private static ThreadPoolExecutor executor = new ThreadPoolExecutor(10, 50, 1
            , TimeUnit.SECONDS, new LinkedBlockingDeque&lt;&gt;(200));

    /**
     * 模拟执行方法
     */
    public static void exec() {
        try {
            semaphore.acquire(1);
            // 模拟真实方法执行
            System.out.println(&quot;执行exec方法&quot;);
            Thread.sleep(2000);
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            semaphore.release(1);
        }
    }

    public static void main(String[] args) throws InterruptedException {
        {
            for (;;) {
                Thread.sleep(100);
                // 模拟请求以10个/s的速度
                executor.execute(() -&gt; exec());
            }
        }
    }
}
</code></pre>
<h3 id="总结">总结</h3>
<h4 id="1-countdownlatch-cyclicbarrier-semaphore的区别">1、CountDownLatch、CyclicBarrier、Semaphore的区别</h4>
<p><code>CountDownLatch</code> 和 <code>CyclicBarrier</code> 都能够实现线程之间的等待，只不过它们侧重点不同：</p>
<p><code>CountDownLatch</code> 一般用于某个线程 A 等待若干个其他线程执行完任务之后，它才执行；<br>
而<code>CyclicBarrier</code>一般用于一组线程互相等待至某个状态，然后这一组线程再同时执行；<br>
另外，<code>CountDownLatch</code>是不能够重用的，而 <code>CyclicBarrier</code> 是可以重用的（reset）。<br>
<code>Semaphore</code>和锁有点类似，它一般用于控制对某组资源的访问权限。</p>
<h4 id="2-countdownlatch-与-threadjoin-的区别">2、CountDownLatch 与 Thread.join 的区别</h4>
<p><code>CountDownLatch</code> 的作用就是允许一个或多个线程等待其他线程完成操作，看起来有点类似 join() 方法，但其提供了比 <code>join()</code> 更加灵活的API。<br>
<code>CountDownLatch</code> 可以手动控制在n个线程里调用 n 次 <code>countDown()</code>方法使计数器进行减一操作，也可以在一个线程里调用 n 次执行减一操作。<br>
而 join() 的实现原理是不停检查 join 线程是否存活，如果 join 线程存活则让当前线程永远等待。所以两者之间相对来说还是 <code>CountDownLatch</code> 使用起来较为灵活。</p>
<h4 id="3-cyclicbarrier-与-countdownlatch-区别">3、CyclicBarrier 与 CountDownLatch 区别</h4>
<p><code>CountDownLatch</code>的计数器只能使用一次，而<code>CyclicBarrier</code>的计数器可以使用reset()方法重置。所以<code>CyclicBarrier</code>能处理更为复杂的业务场景，比如如果计算发生错误，可以重置计数器，并让线程们重新执行一次。<br>
<code>CyclicBarrier</code>还提供<code>getNumberWaiting</code>(可以获得CyclicBarrier阻塞的线程数量)、<code>isBroken</code>(用来知道阻塞的线程是否被中断)等方法。<br>
<code>CountDownLatch</code>会阻塞主线程，<code>CyclicBarrier</code>不会阻塞主线程，只会阻塞子线程。<br>
<code>CountDownLatch</code>和<code>CyclicBarrier</code>都能够实现线程之间的等待，只不过它们侧重点不同。<code>CountDownLatch</code>一般用于一个或多个线程，等待其他线程执行完任务后，再执行。<code>CyclicBarrier</code>一般用于一组线程互相等待至某个状态，然后这一组线程再同时执行。<br>
<code>CyclicBarrier</code> 还可以提供一个 <code>barrierAction</code>，合并多线程计算结果。<br>
<code>CyclicBarrier</code>是通过<code>ReentrantLock</code>的&quot;独占锁&quot;和<code>Conditon</code>来实现一组线程的阻塞唤醒的，而<code>CountDownLatch</code>则是通过<code>AQS</code>的“共享锁”实现。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[异步编程的 7 种实现方式]]></title>
        <id>https://tinaxiawuhao.github.io/post/9hE3Lg3SU/</id>
        <link href="https://tinaxiawuhao.github.io/post/9hE3Lg3SU/">
        </link>
        <updated>2022-04-09T14:06:23.000Z</updated>
        <content type="html"><![CDATA[<p>早期的系统是同步的，容易理解，我们来看个例子</p>
<p><strong>同步编程</strong></p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1656857458145.png" alt="" loading="lazy"></figure>
<p>当用户创建一笔电商交易订单时，要经历的业务逻辑流程还是很长的，每一步都要耗费一定的时间，那么整体的RT就会比较长。</p>
<p>于是，聪明的人们开始思考能不能将一些非核心业务从主流程中剥离出来，于是有了<code>异步编程</code>雏形。</p>
<blockquote>
<p>异步编程是让程序并发运行的一种手段。它允许多个事件同时发生，当程序调用需要长时间运行的方法时，它不会阻塞当前的执行流程，程序可以继续运行。</p>
</blockquote>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1656857467980.png" alt="" loading="lazy"></figure>
<p>核心思路：采用多线程优化性能，将串行操作变成并行操作。异步模式设计的程序可以显著减少线程等待，从而在高吞吐量场景中，极大提升系统的整体性能，显著降低时延。</p>
<p>接下来，我们来讲下异步有哪些编程实现方式</p>
<h3 id="一-线程-thread">一、线程 Thread</h3>
<p>直接继承 <code>Thread类</code> 是创建异步线程最简单的方式。</p>
<p>首先，创建Thread子类，普通类或匿名内部类方式；然后创建子类实例；最后通过start()方法启动线程。</p>
<pre><code class="language-java">public class AsyncThread extends Thread{
    @Override
    public void run() {
        System.out.println(&quot;当前线程名称:&quot; + this.getName() + &quot;, 执行线程名称:&quot; + Thread.currentThread().getName() + &quot;-hello&quot;);
    }
}
public static void main(String[] args) {

  // 模拟业务流程
  // .......
  
    // 创建异步线程 
    AsyncThread asyncThread = new AsyncThread();

    // 启动异步线程
    asyncThread.start();
}
</code></pre>
<p>当然如果每次都创建一个 <code>Thread线程</code>，频繁的创建、销毁，浪费系统资源。我们可以采用线程池</p>
<pre><code class="language-java">@Bean(name = &quot;executorService&quot;)
public ExecutorService downloadExecutorService() {
    return new ThreadPoolExecutor(20, 40, 60, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(2000),
            new ThreadFactoryBuilder().setNameFormat(&quot;defaultExecutorService-%d&quot;).build(),
            (r, executor) -&gt; log.error(&quot;defaultExecutor pool is full! &quot;));
}
</code></pre>
<p>将业务逻辑封装到 <code>Runnable</code> 或 <code>Callable</code> 中，交由 <code>线程池</code> 来执行</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1656857480787.png" alt="" loading="lazy"></figure>
<h3 id="二-future">二、Future</h3>
<p>上述方式虽然达到了多线程并行处理，但有些业务不仅仅要执行过程，还要获取执行结果。</p>
<p>Java 从1.5版本开始，提供了 <code>Callable</code> 和 <code>Future</code>，可以在任务执行完毕之后得到任务执行结果。</p>
<p>当然也提供了其他功能，如：取消任务、查询任务是否完成等</p>
<p>Future类位于java.util.concurrent包下，接口定义：</p>
<pre><code class="language-java">public interface Future&lt;V&gt; {
    boolean cancel(boolean mayInterruptIfRunning);
    boolean isCancelled();
    boolean isDone();
    V get() throws InterruptedException, ExecutionException;
    V get(long timeout, TimeUnit unit)
        throws InterruptedException, ExecutionException, TimeoutException;
}
</code></pre>
<p><strong>方法描述：</strong></p>
<ul>
<li>cancel()：取消任务，如果取消任务成功返回true，如果取消任务失败则返回false</li>
<li>isCancelled()：表示任务是否被取消成功，如果在任务正常完成前被取消成功，则返回 true</li>
<li>isDone()：表示任务是否已经完成，如果完成，返回true</li>
<li>get()：获取执行结果，这个方法会产生阻塞，会一直等到任务执行完毕才返回</li>
<li>get(long timeout, TimeUnit unit)：用来获取执行结果，如果在指定时间内，还没获取到结果，就直接返回null</li>
</ul>
<p><strong>代码示例：</strong></p>
<pre><code class="language-java">public class CallableAndFuture {

    public static ExecutorService executorService = new ThreadPoolExecutor(4, 40,
            0L, TimeUnit.MILLISECONDS,
            new LinkedBlockingQueue&lt;Runnable&gt;(1024), new ThreadFactoryBuilder()
            .setNameFormat(&quot;demo-pool-%d&quot;).build(), new ThreadPoolExecutor.AbortPolicy());


    static class MyCallable implements Callable&lt;String&gt; {
        @Override
        public String call() throws Exception {
            return &quot;异步处理，Callable 返回结果&quot;;
        }
    }

    public static void main(String[] args) {
        Future&lt;String&gt; future = executorService.submit(new MyCallable());
        try {
            System.out.println(future.get());
        } catch (Exception e) {
            // nodo
        } finally {
            executorService.shutdown();
        }
    }
}
</code></pre>
<p>Future 表示一个可能还没有完成的异步任务的结果，通过 <code>get</code> 方法获取执行结果，该方法会阻塞直到任务返回结果。</p>
<h3 id="三-futuretask">三、FutureTask</h3>
<p><code>FutureTask</code> 实现了 <code>RunnableFuture</code> 接口，则 <code>RunnableFuture</code> 接口继承了 <code>Runnable</code> 接口和 <code>Future</code> 接口，所以可以将 <code>FutureTask</code> 对象作为任务提交给 <code>ThreadPoolExecutor</code> 去执行，也可以直接被 <code>Thread</code> 执行；又因为实现了 <code>Future</code> 接口，所以也能用来获得任务的执行结果。</p>
<p><strong>FutureTask 构造函数：</strong></p>
<pre><code class="language-java">public FutureTask(Callable&lt;V&gt; callable)
public FutureTask(Runnable runnable, V result)
</code></pre>
<p>FutureTask 常用来封装 <code>Callable</code> 和 <code>Runnable</code>，可以作为一个任务提交到线程池中执行。除了作为一个独立的类之外，也提供了一些功能性函数供我们创建自定义 task 类使用。</p>
<p>FutureTask 线程安全由CAS来保证。</p>
<pre><code class="language-java">ExecutorService executor = Executors.newCachedThreadPool();
// FutureTask包装callbale任务，再交给线程池执行
FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;&gt;(() -&gt; {
    System.out.println(&quot;子线程开始计算：&quot;);
    Integer sum = 0;
    for (int i = 1; i &lt;= 100; i++)
        sum += i;
    return sum;
});

// 线程池执行任务， 运行结果在 futureTask 对象里面
executor.submit(futureTask);

try {
    System.out.println(&quot;task运行结果计算的总和为：&quot; + futureTask.get());
} catch (Exception e) {
    e.printStackTrace();
}
executor.shutdown();
</code></pre>
<blockquote>
<p>Callable 和 Future 的区别：Callable 用于产生结果，Future 用于获取结果</p>
</blockquote>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1656857496532.png" alt="" loading="lazy"></figure>
<p>如果是对多个任务多次自由串行、或并行组合，涉及多个线程之间同步阻塞获取结果，Future 代码实现会比较繁琐，需要我们手动处理各个交叉点，很容易出错。</p>
<h3 id="四-异步框架-completablefuture">四、异步框架 CompletableFuture</h3>
<p>Future 类通过 <code>get()</code> 方法阻塞等待获取异步执行的运行结果，性能比较差。</p>
<p>JDK1.8 中，Java 提供了 <code>CompletableFuture</code> 类，它是基于异步函数式编程。相对阻塞式等待返回结果，<code>CompletableFuture</code> 可以通过回调的方式来处理计算结果，实现了异步非阻塞，性能更优。</p>
<p><strong>优点</strong>：</p>
<ul>
<li>异步任务结束时，会自动回调某个对象的方法</li>
<li>异步任务出错时，会自动回调某个对象的方法</li>
<li>主线程设置好回调后，不再关心异步任务的执行</li>
</ul>
<p><strong>泡茶示例：</strong></p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1656857505924.png" alt="" loading="lazy"></figure>
<p>(内容摘自：极客时间的《Java 并发编程实战》)</p>
<pre><code class="language-java">//任务1：洗水壶-&gt;烧开水
CompletableFuture&lt;Void&gt; f1 =
        CompletableFuture.runAsync(() -&gt; {
            System.out.println(&quot;T1:洗水壶...&quot;);
            sleep(1, TimeUnit.SECONDS);

            System.out.println(&quot;T1:烧开水...&quot;);
            sleep(15, TimeUnit.SECONDS);
        });

//任务2：洗茶壶-&gt;洗茶杯-&gt;拿茶叶
CompletableFuture&lt;String&gt; f2 =
        CompletableFuture.supplyAsync(() -&gt; {
            System.out.println(&quot;T2:洗茶壶...&quot;);
            sleep(1, TimeUnit.SECONDS);

            System.out.println(&quot;T2:洗茶杯...&quot;);
            sleep(2, TimeUnit.SECONDS);

            System.out.println(&quot;T2:拿茶叶...&quot;);
            sleep(1, TimeUnit.SECONDS);
            return &quot;龙井&quot;;
        });

//任务3：任务1和任务2完成后执行：泡茶
CompletableFuture&lt;String&gt; f3 =
        f1.thenCombine(f2, (__, tf) -&gt; {
            System.out.println(&quot;T1:拿到茶叶:&quot; + tf);
            System.out.println(&quot;T1:泡茶...&quot;);
            return &quot;上茶:&quot; + tf;
        });

//等待任务3执行结果
System.out.println(f3.join());

}
</code></pre>
<p>CompletableFuture 提供了非常丰富的API，大约有50种处理串行，并行，组合以及处理错误的方法。</p>
<h3 id="五-springboot-注解-async">五、 SpringBoot 注解 @Async</h3>
<p>除了硬编码的异步编程处理方式，SpringBoot 框架还提供了 <code>注解式</code> 解决方案，以 <code>方法体</code> 为边界，方法体内部的代码逻辑全部按异步方式执行。</p>
<p>首先，使用 <code>@EnableAsync</code> 启用异步注解</p>
<pre><code class="language-java">@SpringBootApplication
@EnableAsync
public class StartApplication {

    public static void main(String[] args) {
        SpringApplication.run(StartApplication.class, args);
    }
}
</code></pre>
<p>自定义线程池：</p>
<pre><code class="language-java">@Configuration
@Slf4j
public class ThreadPoolConfiguration {

    @Bean(name = &quot;defaultThreadPoolExecutor&quot;, destroyMethod = &quot;shutdown&quot;)
    public ThreadPoolExecutor systemCheckPoolExecutorService() {

        return new ThreadPoolExecutor(3, 10, 60, TimeUnit.SECONDS,
                new LinkedBlockingQueue&lt;Runnable&gt;(10000),
                new ThreadFactoryBuilder().setNameFormat(&quot;default-executor-%d&quot;).build(),
                (r, executor) -&gt; log.error(&quot;system pool is full! &quot;));
    }
}
</code></pre>
<p>在异步处理的方法上添加注解 <code>@Async</code> ，当对 <code>execute 方法</code> 调用时，通过自定义的线程池 <code>defaultThreadPoolExecutor</code> 异步化执行  <code>execute 方法</code></p>
<pre><code class="language-java">@Service
public class AsyncServiceImpl implements AsyncService {

    @Async(&quot;defaultThreadPoolExecutor&quot;)
    public Boolean execute(Integer num) {
        System.out.println(&quot;线程：&quot; + Thread.currentThread().getName() + &quot; , 任务：&quot; + num);
        return true;
    }

}
</code></pre>
<p>用 @Async 注解标记的方法，称为异步方法。在spring boot应用中使用 @Async 很简单：</p>
<ul>
<li>调用异步方法类上或者启动类加上注解 @EnableAsync</li>
<li>在需要被异步调用的方法外加上 @Async</li>
<li>所使用的 @Async 注解方法的类对象应该是Spring容器管理的bean对象；</li>
</ul>
<h3 id="六-spring-applicationevent-事件">六、Spring ApplicationEvent 事件</h3>
<p>事件机制在一些大型项目中被经常使用，Spring 专门提供了一套事件机制的接口，满足了架构原则上的解耦。</p>
<p><code>ApplicationContext</code> 通过 <code>ApplicationEvent</code> 类和 <code>ApplicationListener</code> 接口进行事件处理。如果将实现 <code>ApplicationListener</code> 接口的 bean 注入到上下文中，则每次使用 <code>ApplicationContext</code> 发布 <code>ApplicationEvent</code> 时，都会通知该 bean。本质上，这是标准的<code>观察者设计模式</code>。</p>
<blockquote>
<p>ApplicationEvent 是由 Spring 提供的所有 Event 类的基类</p>
</blockquote>
<p>首先，自定义业务事件子类，继承自 <code>ApplicationEvent</code>，通过泛型注入业务模型参数类。相当于 MQ 的消息体。</p>
<pre><code class="language-java">public class OrderEvent extends AbstractGenericEvent&lt;OrderModel&gt; {
    public OrderEvent(OrderModel source) {
        super(source);
    }
}
</code></pre>
<p>然后，编写事件监听器。<code>ApplicationListener</code> 接口是由 Spring 提供的事件订阅者必须实现的接口，我们需要定义一个子类，继承 <code>ApplicationListener</code>。相当于 MQ 的消费端</p>
<pre><code class="language-java">@Component
public class OrderEventListener implements ApplicationListener&lt;OrderEvent&gt; {
    @Override
    public void onApplicationEvent(OrderEvent event) {

        System.out.println(&quot;【OrderEventListener】监听器处理！&quot; + JSON.toJSONString(event.getSource()));

    }
}
</code></pre>
<p>最后，发布事件，把某个事件告诉所有与这个事件相关的监听器。相当于 MQ 的生产端。</p>
<pre><code class="language-java">OrderModel orderModel = new OrderModel();
orderModel.setOrderId((long) i);
orderModel.setBuyerName(&quot;Tom-&quot; + i);
orderModel.setSellerName(&quot;judy-&quot; + i);
orderModel.setAmount(100L);
// 发布Spring事件通知
SpringUtils.getApplicationContext().publishEvent(new OrderEvent(orderModel));
</code></pre>
<p><strong>加个餐：</strong></p>
<pre><code class="language-java">[消费端]线程：http-nio-8090-exec-1，消费事件 {&quot;amount&quot;:100.0,&quot;buyerName&quot;:&quot;Tom-1&quot;,&quot;orderId&quot;:1,&quot;sellerName&quot;:&quot;judy-1&quot;}
[生产端]线程：http-nio-8090-exec-1，发布事件 1
[消费端]线程：http-nio-8090-exec-1，消费事件 {&quot;amount&quot;:100.0,&quot;buyerName&quot;:&quot;Tom-2&quot;,&quot;orderId&quot;:2,&quot;sellerName&quot;:&quot;judy-2&quot;}
[生产端]线程：http-nio-8090-exec-1，发布事件 2
[消费端]线程：http-nio-8090-exec-1，消费事件 {&quot;amount&quot;:100.0,&quot;buyerName&quot;:&quot;Tom-3&quot;,&quot;orderId&quot;:3,&quot;sellerName&quot;:&quot;judy-3&quot;}
[生产端]线程：http-nio-8090-exec-1，发布事件 3
</code></pre>
<p>上面是跑了个demo的运行结果，我们发现无论生产端还是消费端，使用了同一个线程 <code>http-nio-8090-exec-1</code>，Spring 框架的事件机制默认是同步阻塞的。只是在代码规范方面做了解耦，有较好的扩展性，但底层还是采用同步调用方式。</p>
<p><strong>那么问题来了，如果想实现异步调用，如何处理？</strong></p>
<p>我们需要手动创建一个 <code>SimpleApplicationEventMulticaster</code>，并设置 <code>TaskExecutor</code>，此时所有的消费事件采用异步线程执行。</p>
<pre><code class="language-java">@Component
public class SpringConfiguration {

    @Bean
    public SimpleApplicationEventMulticaster applicationEventMulticaster(@Qualifier(&quot;defaultThreadPoolExecutor&quot;) ThreadPoolExecutor defaultThreadPoolExecutor) {
        SimpleApplicationEventMulticaster simpleApplicationEventMulticaster = new SimpleApplicationEventMulticaster();
        simpleApplicationEventMulticaster.setTaskExecutor(defaultThreadPoolExecutor);
        return simpleApplicationEventMulticaster;
    }

}
</code></pre>
<p>我们看下改造后的运行结果：</p>
<pre><code class="language-java">[生产端]线程：http-nio-8090-exec-1，发布事件 1
[生产端]线程：http-nio-8090-exec-1，发布事件 2
[生产端]线程：http-nio-8090-exec-1，发布事件 3
[消费端]线程：default-executor-1，消费事件 {&quot;amount&quot;:100.0,&quot;buyerName&quot;:&quot;Tom-2&quot;,&quot;orderId&quot;:2,&quot;sellerName&quot;:&quot;judy-2&quot;}
[消费端]线程：default-executor-2，消费事件 {&quot;amount&quot;:100.0,&quot;buyerName&quot;:&quot;Tom-1&quot;,&quot;orderId&quot;:1,&quot;sellerName&quot;:&quot;judy-1&quot;}
[消费端]线程：default-executor-0，消费事件 {&quot;amount&quot;:100.0,&quot;buyerName&quot;:&quot;Tom-3&quot;,&quot;orderId&quot;:3,&quot;sellerName&quot;:&quot;judy-3&quot;}
</code></pre>
<p><strong><code>SimpleApplicationEventMulticaster</code> 这个我们自己实例化的 Bean 与系统默认的加载顺序如何？会不会有冲突？</strong></p>
<p>查了下 Spring 源码，处理逻辑在 <code>AbstractApplicationContext#initApplicationEventMulticaster</code> 方法中，通过 beanFactory 查找是否有自定义的 Bean，如果没有，容器会自己 new 一个 <code>SimpleApplicationEventMulticaster</code> 对象注入到容器中。</p>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1656857527673.png" alt="" loading="lazy"></figure>
<blockquote>
<p>代码地址：https://github.com/aalansehaiyang/wx-project</p>
</blockquote>
<h3 id="七-消息队列">七、消息队列</h3>
<p>异步架构是互联网系统中一种典型架构模式，与同步架构相对应。而消息队列天生就是这种异步架构，具有超高吞吐量和超低时延。</p>
<p>消息队列异步架构的主要角色包括消息生产者、消息队列和消息消费者。</p>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1656857533663.png" alt="" loading="lazy"></figure>
<p>消息生产者就是主应用程序，生产者将调用请求封装成消息发送给消息队列。</p>
<p>消息队列的职责就是缓冲消息，等待消费者消费。根据消费方式又分为<code>点对点模式</code>和<code>发布订阅模式</code>两种。</p>
<p>消息消费者，用来从消息队列中拉取、消费消息，完成业务逻辑处理。</p>
<p>当然市面上消息队列框架非常多，常见的有RabbitMQ、Kafka、RocketMQ、ActiveMQ 和 Pulsar 等</p>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1656857542660.png" alt="" loading="lazy"></figure>
<p>不同的消息队列的功能特性会略有不同，但整体架构类似，这里就不展开了。</p>
<p>我们只需要记住一个关键点，借助消息队列这个中间件可以高效的实现异步编程。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[RabbitMQ]]></title>
        <id>https://tinaxiawuhao.github.io/post/olBu0Tj_j/</id>
        <link href="https://tinaxiawuhao.github.io/post/olBu0Tj_j/">
        </link>
        <updated>2022-04-01T12:19:14.000Z</updated>
        <content type="html"><![CDATA[<h1 id="思维导图">思维导图：</h1>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1657628837809.png" alt="" loading="lazy"></figure>
<h1 id="1-消息队列">1. 消息队列</h1>
<h2 id="11-消息队列模式">1.1 消息队列模式</h2>
<p>消息队列目前主要 2 种模式，分别为“点对点模式”和“发布/订阅模式”。</p>
<h4 id="111-点对点模式">1.1.1 点对点模式</h4>
<p>一个具体的消息只能由一个消费者消费，多个生产者可以向同一个消息队列发送消息，但是一个消息在被一个消息者处理的时候，这个消息在队列上会被锁住或者被移除并且其他消费者无法处理该消息。</p>
<p>需要额外注意的是，如果消费者处理一个消息失败了，消息系统一般会把这个消息放回队列，这样其他消费者可以继续处理。</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1657628845595.png" alt="" loading="lazy"></figure>
<h4 id="112-发布订阅模式">1.1.2 发布/订阅模式</h4>
<p>单个消息可以被多个订阅者并发的获取和处理。一般来说，订阅有两种类型：</p>
<ul>
<li><strong>临时（ephemeral）订阅</strong>：这种订阅只有在消费者启动并且运行的时候才存在。一旦消费者退出，相应的订阅以及尚未处理的消息就会丢失。</li>
<li><strong>持久（durable）订阅</strong>：这种订阅会一直存在，除非主动去删除。消费者退出后，消息系统会继续维护该订阅，并且后续消息可以被继续处理。</li>
</ul>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1657628852760.png" alt="" loading="lazy"></figure>
<h2 id="12-衡量标准">1.2 衡量标准</h2>
<p>对消息队列进行技术选型时，需要通过以下指标衡量你所选择的消息队列，是否可以满足你的需求：</p>
<ul>
<li><strong>消息顺序</strong>：发送到队列的消息，消费时是否可以保证消费的顺序，比如A先下单，B后下单，应该是A先去扣库存，B再去扣，顺序不能反。</li>
<li><strong>消息路由</strong>：根据路由规则，只订阅匹配路由规则的消息，比如有A/B两者规则的消息，消费者可以只订阅A消息，B消息不会消费。</li>
<li>消息可靠性：是否会存在丢消息的情况，比如有A/B两个消息，最后只有B消息能消费，A消息丢失。</li>
<li><strong>消息时序</strong>：主要包括“消息存活时间”和“延迟/预定的消息”，“消息存活时间”表示生产者可以对消息设置TTL，如果超过该TTL，消息会自动消失；“延迟/预定的消息”指的是可以延迟或者预订消费消息，比如延时5分钟，那么消息会5分钟后才能让消费者消费，时间未到的话，是不能消费的。</li>
<li><strong>消息留存</strong>：消息消费成功后，是否还会继续保留在消息队列。</li>
<li><strong>容错性</strong>：当一条消息消费失败后，是否有一些机制，保证这条消息是一种能成功，比如异步第三方退款消息，需要保证这条消息消费掉，才能确定给用户退款成功，所以必须保证这条消息消费成功的准确性。</li>
<li><strong>伸缩</strong>：当消息队列性能有问题，比如消费太慢，是否可以快速支持库容；当消费队列过多，浪费系统资源，是否可以支持缩容。</li>
<li><strong>吞吐量</strong>：支持的最高并发数。</li>
</ul>
<h1 id="2-rabbitmq-原理初探">2. RabbitMQ 原理初探</h1>
<p>RabbitMQ 2007 年发布，是使用 Erlang 语言开发的开源消息队列系统，基于 AMQP 协议来实现。</p>
<h2 id="21-基本概念">2.1 基本概念</h2>
<p>提到RabbitMQ，就不得不提AMQP协议。AMQP协议是具有现代特征的二进制协议。是一个提供统一消息服务的应用层标准高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。</p>
<p>先了解一下AMQP协议中间的几个重要概念：</p>
<ul>
<li>Server：接收客户端的连接，实现AMQP实体服务。</li>
<li>Connection：连接，应用程序与Server的网络连接，TCP连接。</li>
<li>Channel：信道，消息读写等操作在信道中进行。客户端可以建立多个信道，每个信道代表一个会话任务。</li>
<li>Message：消息，应用程序和服务器之间传送的数据，消息可以非常简单，也可以很复杂。由Properties和Body组成。Properties为外包装，可以对消息进行修饰，比如消息的优先级、延迟等高级特性；Body就是消息体内容。</li>
<li>Virtual Host：虚拟主机，用于逻辑隔离。一个虚拟主机里面可以有若干个Exchange和Queue，同一个虚拟主机里面不能有相同名称的Exchange或Queue。</li>
<li>Exchange：交换器，接收消息，按照路由规则将消息路由到一个或者多个队列。如果路由不到，或者返回给生产者，或者直接丢弃。RabbitMQ常用的交换器常用类型有direct、topic、fanout、headers四种，后面详细介绍。</li>
<li>Binding：绑定，交换器和消息队列之间的虚拟连接，绑定中可以包含一个或者多个RoutingKey。</li>
<li>RoutingKey：路由键，生产者将消息发送给交换器的时候，会发送一个RoutingKey，用来指定路由规则，这样交换器就知道把消息发送到哪个队列。路由键通常为一个“.”分割的字符串，例如“com.rabbitmq”。</li>
<li>Queue：消息队列，用来保存消息，供消费者消费。</li>
</ul>
<h2 id="22-工作原理">2.2 工作原理</h2>
<p>AMQP 协议模型由三部分组成：生产者、消费者和服务端，执行流程如下：</p>
<ol>
<li>生产者是连接到 Server，建立一个连接，开启一个信道。</li>
<li>生产者声明交换器和队列，设置相关属性，并通过路由键将交换器和队列进行绑定。</li>
<li>消费者也需要进行建立连接，开启信道等操作，便于接收消息。</li>
<li>生产者发送消息，发送到服务端中的虚拟主机。</li>
<li>虚拟主机中的交换器根据路由键选择路由规则，发送到不同的消息队列中。</li>
<li>订阅了消息队列的消费者就可以获取到消息，进行消费。</li>
</ol>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1657628882128.png" alt="" loading="lazy"></figure>
<h2 id="23-常用交换器">2.3 常用交换器</h2>
<p>RabbitMQ常用的交换器类型有direct、topic、fanout、headers四种：</p>
<ul>
<li>Direct Exchange：见文知意，直连交换机意思是此交换机需要绑定一个队列，要求该消息与一个特定的路由键完全匹配。简单点说就是一对一的，点对点的发送。</li>
</ul>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1657628894550.png" alt="" loading="lazy"></figure>
<ul>
<li>Fanout Exchange：这种类型的交换机需要将队列绑定到交换机上。一个发送到交换机的消息都会被转发到与该交换机绑定的所有队列上。很像子网广播，每台子网内的主机都获得了一份复制的消息。简单点说就是发布订阅。</li>
</ul>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1657628908018.png" alt="" loading="lazy"></figure>
<ul>
<li>
<p>Topic Exchange：直接翻译的话叫做主题交换机，如果从用法上面翻译可能叫通配符交换机会更加贴切。这种交换机是使用通配符去匹配，路由到对应的队列。通配符有两种：&quot;*&quot; 、 &quot;#&quot;。需要注意的是通配符前面必须要加上&quot;.&quot;符号。</p>
</li>
<li>
<ul>
<li>*符号：有且只匹配一个词。比如 a.*可以匹配到&quot;a.b&quot;、&quot;a.c&quot;，但是匹配不了&quot;a.b.c&quot;。</li>
<li>#符号：匹配一个或多个词。比如&quot;rabbit.#&quot;既可以匹配到&quot;rabbit.a.b&quot;、&quot;rabbit.a&quot;，也可以匹配到&quot;rabbit.a.b.c&quot;。</li>
</ul>
</li>
</ul>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1657628921955.png" alt="" loading="lazy"></figure>
<ul>
<li>Headers Exchange：这种交换机用的相对没这么多。它跟上面三种有点区别，它的路由不是用routingKey进行路由匹配，而是在匹配请求头中所带的键值进行路由。创建队列需要设置绑定的头部信息，有两种模式：全部匹配和部分匹配。如上图所示，交换机会根据生产者发送过来的头部信息携带的键值去匹配队列绑定的键值，路由到对应的队列。</li>
</ul>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1657628934149.png" alt="" loading="lazy"></figure>
<h2 id="24-消费原理">2.4 消费原理</h2>
<p>我们先看几个基本概念：</p>
<ul>
<li>broker：每个节点运行的服务程序，功能为维护该节点的队列的增删以及转发队列操作请求。</li>
<li>master queue：每个队列都分为一个主队列和若干个镜像队列。</li>
<li>mirror queue：镜像队列，作为master queue的备份。在master queue所在节点挂掉之后，系统把mirror queue提升为master queue，负责处理客户端队列操作请求。注意，mirror queue只做镜像，设计目的不是为了承担客户端读写压力。</li>
</ul>
<p>集群中有两个节点，每个节点上有一个broker，每个broker负责本机上队列的维护，并且borker之间可以互相通信。集群中有两个队列A和B，每个队列都分为master queue和mirror queue（备份）。那么队列上的生产消费怎么实现的呢？</p>
<figure data-type="image" tabindex="9"><img src="https://tinaxiawuhao.github.io/post-images/1657628950134.png" alt="" loading="lazy"></figure>
<p>对于消费队列，如下图有两个consumer消费队列A，这两个consumer连在了集群的不同机器上。RabbitMQ集群中的任何一个节点都拥有集群上所有队列的元信息，所以连接到集群中的任何一个节点都可以，主要区别在于有的consumer连在master queue所在节点，有的连在非master queue节点上。</p>
<p>因为mirror queue要和master queue保持一致，故需要同步机制，正因为一致性的限制，导致所有的读写操作都必须都操作在master queue上（想想，为啥读也要从master queue中读？和数据库读写分离是不一样的），然后由master节点同步操作到mirror queue所在的节点。即使consumer连接到了非master queue节点，该consumer的操作也会被路由到master queue所在的节点上，这样才能进行消费。</p>
<figure data-type="image" tabindex="10"><img src="https://tinaxiawuhao.github.io/post-images/1657628963515.png" alt="" loading="lazy"></figure>
<p>对于生成队列，原理和消费一样，如果连接到非 master queue 节点，则路由过去。</p>
<figure data-type="image" tabindex="11"><img src="https://tinaxiawuhao.github.io/post-images/1657628975743.png" alt="" loading="lazy"></figure>
<blockquote>
<p>所以，到这里小伙伴们就可以看到 RabbitMQ的不足：由于master queue单节点，导致性能瓶颈，吞吐量受限。虽然为了提高性能，内部使用了Erlang这个语言实现，但是终究摆脱不了架构设计上的致命缺陷。</p>
</blockquote>
<h2 id="25-高级特性">2.5 高级特性</h2>
<h4 id="251-过期时间">2.5.1 过期时间</h4>
<p>Time To Live，也就是生存时间，是一条消息在队列中的最大存活时间，单位是毫秒，下面看看RabbitMQ过期时间特性：</p>
<ul>
<li>RabbitMQ可以对消息和队列设置TTL。</li>
<li>RabbitMQ支持设置消息的过期时间，在消息发送的时候可以进行指定，每条消息的过期时间可以不同。</li>
<li>RabbitMQ支持设置队列的过期时间，从消息入队列开始计算，直到超过了队列的超时时间配置，那么消息会变成死信，自动清除。</li>
<li>如果两种方式一起使用，则过期时间以两者中较小的那个数值为准。</li>
<li>当然也可以不设置TTL，不设置表示消息不会过期；如果设置为0，则表示除非此时可以直接将消息投递到消费者，否则该消息将被立即丢弃。</li>
</ul>
<h4 id="252-消息确认">2.5.2 消息确认</h4>
<p>为了保证消息从队列可靠地到达消费者，RabbitMQ提供了消息确认机制。</p>
<p>消费者订阅队列的时候，可以指定autoAck参数，当autoAck为true的时候，RabbitMQ采用自动确认模式，RabbitMQ自动把发送出去的消息设置为确认，然后从内存或者硬盘中删除，而不管消费者是否真正消费到了这些消息。</p>
<p>当autoAck为false的时候，RabbitMQ会等待消费者回复的确认信号，收到确认信号之后才从内存或者磁盘中删除消息。</p>
<p>消息确认机制是RabbitMQ消息可靠性投递的基础，只要设置autoAck参数为false，消费者就有足够的时间处理消息，不用担心处理消息的过程中消费者进程挂掉后消息丢失的问题。</p>
<h4 id="253-持久化">2.5.3 持久化</h4>
<p>消息的可靠性是RabbitMQ的一大特色，那么RabbitMQ是如何保证消息可靠性的呢？答案就是消息持久化。持久化可以防止在异常情况下丢失数据。RabbitMQ的持久化分为三个部分：交换器持久化、队列持久化和消息的持久化。</p>
<p>交换器持久化可以通过在声明队列时将durable参数设置为true。如果交换器不设置持久化，那么在RabbitMQ服务重启之后，相关的交换器元数据会丢失，不过消息不会丢失，只是不能将消息发送到这个交换器了。</p>
<p>队列的持久化能保证其本身的元数据不会因异常情况而丢失，但是不能保证内部所存储的消息不会丢失。要确保消息不会丢失，需要将其设置为持久化。队列的持久化可以通过在声明队列时将durable参数设置为true。</p>
<p>设置了队列和消息的持久化，当RabbitMQ服务重启之后，消息依然存在。如果只设置队列持久化或者消息持久化，重启之后消息都会消失。</p>
<p>当然，也可以将所有的消息都设置为持久化，但是这样做会影响RabbitMQ的性能，因为磁盘的写入速度比内存的写入要慢得多。</p>
<p>对于可靠性不是那么高的消息可以不采用持久化处理以提高整体的吞吐量。鱼和熊掌不可兼得，关键在于选择和取舍。在实际中，需要根据实际情况在可靠性和吞吐量之间做一个权衡。</p>
<h4 id="254-死信队列">2.5.4 死信队列</h4>
<p>当消息在一个队列中变成死信之后，他能被重新发送到另一个交换器中，这个交换器成为死信交换器，与该交换器绑定的队列称为死信队列。</p>
<p>消息变成死信有下面几种情况：</p>
<ul>
<li>消息被拒绝。</li>
<li>消息过期</li>
<li>队列达到最大长度</li>
</ul>
<p>DLX也是一个正常的交换器，和一般的交换器没有区别，他能在任何的队列上面被指定，实际上就是设置某个队列的属性。当这个队列中有死信的时候，RabbitMQ会自动将这个消息重新发送到设置的交换器上，进而被路由到另一个队列，我们可以监听这个队列中消息做相应的处理。</p>
<p>死信队列有什么用？当发生异常的时候，消息不能够被消费者正常消费，被加入到了死信队列中。后续的程序可以根据死信队列中的内容分析当时发生的异常，进而改善和优化系统。</p>
<h4 id="255-延迟队列">2.5.5 延迟队列</h4>
<p>一般的队列，消息一旦进入队列就会被消费者立即消费。延迟队列就是进入该队列的消息会被消费者延迟消费，延迟队列中存储的对象是的延迟消息，“延迟消息”是指当消息被发送以后，等待特定的时间后，消费者才能拿到这个消息进行消费。</p>
<p>延迟队列用于需要延迟工作的场景。最常见的使用场景：淘宝或者天猫我们都使用过，用户在下单之后通常有30分钟的时间进行支付，如果这30分钟之内没有支付成功，那么订单就会自动取消。</p>
<p>除了延迟消费，延迟队列的典型应用场景还有延迟重试。比如消费者从队列里面消费消息失败了，可以延迟一段时间以后进行重试。</p>
<h2 id="26-特性分析">2.6 特性分析</h2>
<p>这里才是内容的重点，不仅需要知道Rabbit的特性，还需要知道支持这些特性的原因：</p>
<ul>
<li><strong>消息路由（支持）</strong>：RabbitMQ可以通过不同的交换器支持不同种类的消息路由；</li>
<li><strong>消息有序（不支持）</strong>：当消费消息时，如果消费失败，消息会被放回队列，然后重新消费，这样会导致消息无序；</li>
<li><strong>消息时序（非常好）</strong>：通过延时队列，可以指定消息的延时时间，过期时间TTL等；</li>
<li><strong>容错处理（非常好）</strong>：通过交付重试和死信交换器（DLX）来处理消息处理故障；</li>
<li><strong>伸缩（一般）</strong>：伸缩其实没有非常智能，因为即使伸缩了，master queue还是只有一个，负载还是只有这一个master queue去抗，所以我理解RabbitMQ的伸缩很弱（个人理解）。</li>
<li><strong>持久化（不太好）</strong>：没有消费的消息，可以支持持久化，这个是为了保证机器宕机时消息可以恢复，但是消费过的消息，就会被马上删除，因为RabbitMQ设计时，就不是为了去存储历史数据的。</li>
<li><strong>消息回溯（不支持）</strong>：因为消息不支持永久保存，所以自然就不支持回溯。</li>
<li><strong>高吞吐（中等）</strong>：因为所有的请求的执行，最后都是在master queue，它的这个设计，导致单机性能达不到十万级的标准。</li>
</ul>
<h1 id="3-rabbitmq环境搭建">3. RabbitMQ环境搭建</h1>
<p>因为我用的是Mac，所以直接可以参考官网：</p>
<blockquote>
<p>https://www.rabbitmq.com/install-homebrew.html</p>
</blockquote>
<p>需要注意的是，一定需要先执行：</p>
<pre><code class="language-shell">brew update
</code></pre>
<p>然后再执行：</p>
<pre><code class="language-shell">brew install rabbitmq
</code></pre>
<blockquote>
<p>之前没有执行brew update，直接执行brew install rabbitmq时，会报各种各样奇怪的错误，其中“403 Forbidde”居多。</p>
</blockquote>
<p>但是在执行“brew install rabbitmq”，会自动安装其它的程序，如果你使用源码安装Rabbitmq，因为启动该服务依赖erlang环境，所以你还需手动安装erlang，但是目前官方已经一键给你搞定，会自动安装Rabbitmq依赖的所有程序，是不是很棒！</p>
<figure data-type="image" tabindex="12"><img src="https://tinaxiawuhao.github.io/post-images/1657628995936.png" alt="" loading="lazy"></figure>
<p>最后执行成功的输出如下：</p>
<figure data-type="image" tabindex="13"><img src="https://tinaxiawuhao.github.io/post-images/1657629007811.png" alt="" loading="lazy"></figure>
<p>启动服务：</p>
<pre><code class="language-shell"># 启动方式1：后台启动
brew services start rabbitmq
# 启动方式2：当前窗口启动
cd /usr/local/Cellar/rabbitmq/3.8.19
rabbitmq-server
</code></pre>
<p>在浏览器输入：</p>
<pre><code class="language-java">http://localhost:15672/
</code></pre>
<p>会出现RabbitMQ后台管理界面（用户名和密码都为guest）：</p>
<figure data-type="image" tabindex="14"><img src="https://tinaxiawuhao.github.io/post-images/1657629021755.png" alt="" loading="lazy"></figure>
<p>通过brew安装，一行命令搞定，真香！</p>
<h1 id="4-rabbitmq测试">4. RabbitMQ测试</h1>
<h2 id="41-添加账号">4.1 添加账号</h2>
<p>首先得启动mq</p>
<pre><code class="language-java">## 添加账号
./rabbitmqctl add_user admin admin
## 添加访问权限
./rabbitmqctl set_permissions -p &quot;/&quot; admin &quot;.*&quot; &quot;.*&quot; &quot;.*&quot;
## 设置超级权限
./rabbitmqctl set_user_tags admin administrator
</code></pre>
<h2 id="42-编码实测">4.2 编码实测</h2>
<p>因为代码中引入了java 8的特性，pom引入依赖：</p>
<pre><code class="language-java">&lt;dependency&gt;
    &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt;
    &lt;artifactId&gt;amqp-client&lt;/artifactId&gt;
    &lt;version&gt;5.5.1&lt;/version&gt;
&lt;/dependency&gt;

&lt;plugins&gt;
    &lt;plugin&gt;
        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
        &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
        &lt;configuration&gt;
            &lt;source&gt;8&lt;/source&gt;
            &lt;target&gt;8&lt;/target&gt;
        &lt;/configuration&gt;
    &lt;/plugin&gt;
&lt;/plugins&gt;
</code></pre>
<p>开始写代码：</p>
<pre><code class="language-java">public class RabbitMqTest {
    //消息队列名称
    private final static String QUEUE_NAME = &quot;hello&quot;;

    @Test
    public void send() throws java.io.IOException, TimeoutException {
        //创建连接工程
        ConnectionFactory factory = new ConnectionFactory();
        factory.setHost(&quot;127.0.0.1&quot;);
        factory.setPort(5672);
        factory.setUsername(&quot;admin&quot;);
        factory.setPassword(&quot;admin&quot;);
        //创建连接
        Connection connection = factory.newConnection();
        //创建消息通道
        Channel channel = connection.createChannel();
        //生成一个消息队列
        channel.queueDeclare(QUEUE_NAME, true, false, false, null);

        for (int i = 0; i &lt; 10; i++) {
            String message = &quot;Hello World RabbitMQ count: &quot; + i;
            //发布消息，第一个参数表示路由（Exchange名称），为&quot;&quot;则表示使用默认消息路由
            channel.basicPublish(&quot;&quot;, QUEUE_NAME, null, message.getBytes());
            System.out.println(&quot; [x] Sent '&quot; + message + &quot;'&quot;);
        }
        //关闭消息通道和连接
        channel.close();
        connection.close();
    }

    @Test
    public void consumer() throws java.io.IOException, TimeoutException {
        //创建连接工厂
        ConnectionFactory factory = new ConnectionFactory();
        factory.setHost(&quot;127.0.0.1&quot;);
        factory.setPort(5672);
        factory.setUsername(&quot;admin&quot;);
        factory.setPassword(&quot;admin&quot;);
        //创建连接
        Connection connection = factory.newConnection();
        //创建消息信道
        final Channel channel = connection.createChannel();
        //消息队列
        channel.queueDeclare(QUEUE_NAME, true, false, false, null);
        System.out.println(&quot;[*] Waiting for message. To exist press CTRL+C&quot;);

        DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; {
            String message = new String(delivery.getBody(), &quot;UTF-8&quot;);
            System.out.println(&quot; [x] Received '&quot; + message + &quot;'&quot;);
        };
        channel.basicConsume(QUEUE_NAME, true, deliverCallback, consumerTag -&gt; {});
    }
}
</code></pre>
<p>执行send()后控制台输出：</p>
<pre><code class="language-java">[x] Sent 'Hello World RabbitMQ count: 0'
[x] Sent 'Hello World RabbitMQ count: 1'
[x] Sent 'Hello World RabbitMQ count: 2'
[x] Sent 'Hello World RabbitMQ count: 3'
[x] Sent 'Hello World RabbitMQ count: 4'
[x] Sent 'Hello World RabbitMQ count: 5'
[x] Sent 'Hello World RabbitMQ count: 6'
[x] Sent 'Hello World RabbitMQ count: 7'
[x] Sent 'Hello World RabbitMQ count: 8'
[x] Sent 'Hello World RabbitMQ count: 9'
</code></pre>
<figure data-type="image" tabindex="15"><img src="https://tinaxiawuhao.github.io/post-images/1657629041941.png" alt="" loading="lazy"></figure>
<p>执行consumer()后：</p>
<figure data-type="image" tabindex="16"><img src="https://tinaxiawuhao.github.io/post-images/1657629056060.png" alt="" loading="lazy"></figure>
<blockquote>
<p>示例中的代码讲解，可以直接参考官网：https://www.rabbitmq.com/tutorials/tutorial-one-java.html</p>
</blockquote>
<h1 id="5-基本使用姿势">5. 基本使用姿势</h1>
<h2 id="51-公共代码封装">5.1 公共代码封装</h2>
<p>封装工厂类：</p>
<pre><code class="language-java">public class RabbitUtil {
    public static ConnectionFactory getConnectionFactory() {
        //创建连接工程，下面给出的是默认的case
        ConnectionFactory factory = new ConnectionFactory();
        factory.setHost(&quot;127.0.0.1&quot;);
        factory.setPort(5672);
        factory.setUsername(&quot;admin&quot;);
        factory.setPassword(&quot;admin&quot;);
        factory.setVirtualHost(&quot;/&quot;);
        return factory;
    }
}
</code></pre>
<p>封装生成者：</p>
<pre><code class="language-java">public class MsgProducer {
    public static void publishMsg(String exchange, BuiltinExchangeType exchangeType, String toutingKey, String message) throws IOException, TimeoutException {
        ConnectionFactory factory = RabbitUtil.getConnectionFactory();
        //创建连接
        Connection connection = factory.newConnection();
        //创建消息通道
        Channel channel = connection.createChannel();
        // 声明exchange中的消息为可持久化，不自动删除
        channel.exchangeDeclare(exchange, exchangeType, true, false, null);
        // 发布消息
        channel.basicPublish(exchange, toutingKey, null, message.getBytes());
        System.out.println(&quot;Sent '&quot; + message + &quot;'&quot;);
        channel.close();
        connection.close();
    }
}
</code></pre>
<p>封装消费者：</p>
<pre><code class="language-java">public class MsgConsumer {
    public static void consumerMsg(String exchange, String queue, String routingKey)
            throws IOException, TimeoutException {
        ConnectionFactory factory = RabbitUtil.getConnectionFactory();
        //创建连接
        Connection connection = factory.newConnection();
        //创建消息信道
        final Channel channel = connection.createChannel();
        //消息队列
        channel.queueDeclare(queue, true, false, false, null);
        //绑定队列到交换机
        channel.queueBind(queue, exchange, routingKey);
        System.out.println(&quot;[*] Waiting for message. To exist press CTRL+C&quot;);

        Consumer consumer = new DefaultConsumer(channel) {
            @Override
            public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties,
                                       byte[] body) throws IOException {
                String message = new String(body, &quot;UTF-8&quot;);
                try {
                    System.out.println(&quot; [x] Received '&quot; + message);
                } finally {
                    System.out.println(&quot; [x] Done&quot;);
                    channel.basicAck(envelope.getDeliveryTag(), false);
                }
            }
        };
        // 取消自动ack
        channel.basicConsume(queue, false, consumer);
    }
}
</code></pre>
<h2 id="52-direct方式">5.2 Direct方式</h2>
<figure data-type="image" tabindex="17"><img src="https://tinaxiawuhao.github.io/post-images/1657629073366.png" alt="" loading="lazy"></figure>
<h4 id="521-direct示例">5.2.1 Direct示例</h4>
<p>生产者：</p>
<pre><code class="language-java">public class DirectProducer {
    private static final String EXCHANGE_NAME = &quot;direct.exchange&quot;;
    public void publishMsg(String routingKey, String msg) {
        try {
            MsgProducer.publishMsg(EXCHANGE_NAME, BuiltinExchangeType.DIRECT, routingKey, msg);
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
    public static void main(String[] args) throws InterruptedException {
        DirectProducer directProducer = new DirectProducer();
        String[] routingKey = new String[]{&quot;aaa&quot;, &quot;bbb&quot;, &quot;ccc&quot;};
        String msg = &quot;hello &gt;&gt;&gt; &quot;;
        for (int i = 0; i &lt; 10; i++) {
            directProducer.publishMsg(routingKey[i % 3], msg + i);
        }
        System.out.println(&quot;----over-------&quot;);
        Thread.sleep(1000 * 60 * 100);
    }
}
</code></pre>
<p>执行生产者，往消息队列中放入10条消息，其中key分别为“aaa”、“bbb”和“ccc”，分别放入qa、qb、qc三个队列：</p>
<figure data-type="image" tabindex="18"><img src="https://tinaxiawuhao.github.io/post-images/1657629087994.png" alt="" loading="lazy"></figure>
<p>下面是qa队列的信息：</p>
<figure data-type="image" tabindex="19"><img src="https://tinaxiawuhao.github.io/post-images/1657629101075.png" alt="" loading="lazy"></figure>
<p>消费者：</p>
<pre><code class="language-java">public class DirectConsumer {
    private static final String exchangeName = &quot;direct.exchange&quot;;
    public void msgConsumer(String queueName, String routingKey) {
        try {
            MsgConsumer.consumerMsg(exchangeName, queueName, routingKey);
        } catch (IOException e) {
            e.printStackTrace();
        } catch (TimeoutException e) {
            e.printStackTrace();
        }
    }
    public static void main(String[] args) throws InterruptedException {
        DirectConsumer consumer = new DirectConsumer();
        String[] routingKey = new String[]{&quot;aaa&quot;, &quot;bbb&quot;, &quot;ccc&quot;};
        String[] queueNames = new String[]{&quot;qa&quot;, &quot;qb&quot;, &quot;qc&quot;};

        for (int i = 0; i &lt; 3; i++) {
            consumer.msgConsumer(queueNames[i], routingKey[i]);
        }
        Thread.sleep(1000 * 60 * 100);
    }
}
</code></pre>
<p>执行后的输出：</p>
<pre><code class="language-java">[*] Waiting for message. To exist press CTRL+C
 [x] Received 'hello &gt;&gt;&gt; 0
 [x] Done
 [x] Received 'hello &gt;&gt;&gt; 3
 [x] Done
 [x] Received 'hello &gt;&gt;&gt; 6
 [x] Done
 [x] Received 'hello &gt;&gt;&gt; 9
 [x] Done
[*] Waiting for message. To exist press CTRL+C
 [x] Received 'hello &gt;&gt;&gt; 1
 [x] Done
 [x] Received 'hello &gt;&gt;&gt; 4
 [x] Done
 [x] Received 'hello &gt;&gt;&gt; 7
 [x] Done
[*] Waiting for message. To exist press CTRL+C
 [x] Received 'hello &gt;&gt;&gt; 2
 [x] Done
 [x] Received 'hello &gt;&gt;&gt; 5
 [x] Done
 [x] Received 'hello &gt;&gt;&gt; 8
 [x] Done
</code></pre>
<p>可以看到，分别从qa、qb、qc中将不同的key的数据消费掉。</p>
<h4 id="522-问题探讨">5.2.2 问题探讨</h4>
<blockquote>
<p>有个疑问：这个队列的名称qa、qb和qc是RabbitMQ自动生成的么，我们可以指定队列名称么？</p>
</blockquote>
<p>我做了个简单的实验，我把消费者代码修改了一下：</p>
<pre><code class="language-java">public static void main(String[] args) throws InterruptedException {
    DirectConsumer consumer = new DirectConsumer();
    String[] routingKey = new String[]{&quot;aaa&quot;, &quot;bbb&quot;, &quot;ccc&quot;};
    String[] queueNames = new String[]{&quot;qa&quot;, &quot;qb&quot;, &quot;qc1&quot;}; // 将qc修改为qc1

    for (int i = 0; i &lt; 3; i++) {
        consumer.msgConsumer(queueNames[i], routingKey[i]);
    }
    Thread.sleep(1000 * 60 * 100);
}
</code></pre>
<p>执行后如下图所示：</p>
<figure data-type="image" tabindex="20"><img src="https://tinaxiawuhao.github.io/post-images/1657629118045.png" alt="" loading="lazy"></figure>
<p>我们可以发现，多了一个qc1，所以可以判断这个界面中的queues，是消费者执行时，会将消费者指定的队列名称和direct.exchange绑定，绑定的依据就是key。</p>
<p>当我们把队列中的数据全部消费掉，然后重新执行生成者后，会发现qc和qc1中都有3条待消费的数据，因为绑定的key都是“ccc”，所以两者的数据是一样的：</p>
<figure data-type="image" tabindex="21"><img src="https://tinaxiawuhao.github.io/post-images/1657629135755.png" alt="" loading="lazy"></figure>
<p>绑定关系如下：</p>
<figure data-type="image" tabindex="22"><img src="https://tinaxiawuhao.github.io/post-images/1657629148741.png" alt="" loading="lazy"></figure>
<blockquote>
<p>注意：当没有Queue绑定到Exchange时，往Exchange中写入的消息也不会重新分发到之后绑定的queue上。</p>
</blockquote>
<blockquote>
<p>思考：不执行消费者，看不到这个Queres中信息，我其实可以把这个界面理解为消费者信息界面。不过感觉还是怪怪的，这个queues如果是消费者信息，就不应该叫queues，我理解queues应该是RabbitMQ中实际存放数据的queues，难道是我理解错了？</p>
</blockquote>
<h2 id="53-fanout方式指定队列">5.3 Fanout方式（指定队列）</h2>
<figure data-type="image" tabindex="23"><img src="https://tinaxiawuhao.github.io/post-images/1657629161615.png" alt="" loading="lazy"></figure>
<p>生产者封装：</p>
<pre><code class="language-java">public class FanoutProducer {
    private static final String EXCHANGE_NAME = &quot;fanout.exchange&quot;;
    public void publishMsg(String routingKey, String msg) {
        try {
            MsgProducer.publishMsg(EXCHANGE_NAME, BuiltinExchangeType.FANOUT, routingKey, msg);
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
    public static void main(String[] args) {
        FanoutProducer directProducer = new FanoutProducer();
        String msg = &quot;hello &gt;&gt;&gt; &quot;;
        for (int i = 0; i &lt; 10; i++) {
            directProducer.publishMsg(&quot;&quot;, msg + i);
        }
    }
}
</code></pre>
<p>消费者：</p>
<pre><code class="language-java">public class FanoutConsumer {
    private static final String EXCHANGE_NAME = &quot;fanout.exchange&quot;;
    public void msgConsumer(String queueName, String routingKey) {
        try {
            MsgConsumer.consumerMsg(EXCHANGE_NAME, queueName, routingKey);
        } catch (IOException e) {
            e.printStackTrace();
        } catch (TimeoutException e) {
            e.printStackTrace();
        }
    }
    public static void main(String[] args) {
        FanoutConsumer consumer = new FanoutConsumer();
        String[] queueNames = new String[]{&quot;qa-2&quot;, &quot;qb-2&quot;, &quot;qc-2&quot;};
        for (int i = 0; i &lt; 3; i++) {
            consumer.msgConsumer(queueNames[i], &quot;&quot;);
        }
    }
}
</code></pre>
<p>执行生成者，结果如下：</p>
<figure data-type="image" tabindex="24"><img src="https://tinaxiawuhao.github.io/post-images/1657629177410.png" alt="" loading="lazy"></figure>
<p>我们发现，生产者生产的10条数据，在每个消费者中都可以消费，这个是和Direct不同的地方，但是使用Fanout方式时，有几个点需要注意一下：</p>
<ul>
<li>生产者的routkey可以为空，因为生产者的所有数据，会下放到每一个队列，所以不会通过routkey去路由；</li>
<li>消费者需要指定queues，因为消费者需要绑定到指定的queues才能消费。</li>
</ul>
<figure data-type="image" tabindex="25"><img src="https://tinaxiawuhao.github.io/post-images/1657629197886.png" alt="" loading="lazy"></figure>
<p>这幅图就画出了Fanout的精髓之处，exchange会和所有的queue进行绑定，不区分路由，消费者需要绑定指定的queue才能发起消费。</p>
<blockquote>
<p>注意：往队列塞数据时，可能通过界面看不到消息个数的增加，可能是你之前已经开启了消费进程，导致增加的消息马上被消费了。</p>
</blockquote>
<h2 id="54-fanout方式随机获取队列">5.4 Fanout方式（随机获取队列）</h2>
<p>上面我们是指定了队列，这个方式其实很不友好，比如对于Fanout，我其实根本无需关心队列的名字，如果还指定对应队列进行消费，感觉这个很冗余，所以我们这里就采用随机获取队列名字的方式，下面代码直接Copy官网。</p>
<p>生成者封装：</p>
<pre><code class="language-java">public static void publishMsgV2(String exchange, BuiltinExchangeType exchangeType, String message) throws IOException, TimeoutException {
    ConnectionFactory factory = RabbitUtil.getConnectionFactory();
    //创建连接
    Connection connection = factory.newConnection();
    //创建消息通道
    Channel channel = connection.createChannel();

    // 声明exchange中的消息
    channel.exchangeDeclare(exchange, exchangeType);

    // 发布消息
    channel.basicPublish(exchange, &quot;&quot;, null, message.getBytes(&quot;UTF-8&quot;));

    System.out.println(&quot;Sent '&quot; + message + &quot;'&quot;);
    channel.close();
    connection.close();
}
</code></pre>
<p>消费者封装：</p>
<pre><code class="language-java">public static void consumerMsgV2(String exchange) throws IOException, TimeoutException {
    ConnectionFactory factory = RabbitUtil.getConnectionFactory();
    Connection connection = factory.newConnection();
    final Channel channel = connection.createChannel();

    channel.exchangeDeclare(exchange, &quot;fanout&quot;);
    String queueName = channel.queueDeclare().getQueue();
    channel.queueBind(queueName, exchange, &quot;&quot;);

    System.out.println(&quot; [*] Waiting for messages. To exit press CTRL+C&quot;);

    DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; {
        String message = new String(delivery.getBody(), &quot;UTF-8&quot;);
        System.out.println(&quot; [x] Received '&quot; + message + &quot;'&quot;);
    };
    channel.basicConsume(queueName, true, deliverCallback, consumerTag -&gt; { });
}
</code></pre>
<p>生产者：</p>
<pre><code class="language-java">public class FanoutProducer {
    private static final String EXCHANGE_NAME = &quot;fanout.exchange.v2&quot;;
    public void publishMsg(String msg) {
        try {
            MsgProducer.publishMsgV2(EXCHANGE_NAME, BuiltinExchangeType.FANOUT, msg);
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
    public static void main(String[] args) {
        FanoutProducer directProducer = new FanoutProducer();
        String msg = &quot;hello &gt;&gt;&gt; &quot;;
        for (int i = 0; i &lt; 10000; i++) {
            directProducer.publishMsg(msg + i);
        }
    }
}
</code></pre>
<p>消费者：</p>
<pre><code class="language-java">public class FanoutConsumer {
    private static final String EXCHANGE_NAME = &quot;fanout.exchange.v2&quot;;
    public void msgConsumer() {
        try {
            MsgConsumer.consumerMsgV2(EXCHANGE_NAME);
        } catch (IOException e) {
            e.printStackTrace();
        } catch (TimeoutException e) {
            e.printStackTrace();
        }
    }
    public static void main(String[] args) {
        FanoutConsumer consumer = new FanoutConsumer();
        for (int i = 0; i &lt; 3; i++) {
            consumer.msgConsumer();
        }
    }
}
</code></pre>
<p>执行后，管理界面如下：</p>
<figure data-type="image" tabindex="26"><img src="https://tinaxiawuhao.github.io/post-images/1657629216023.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="27"><img src="https://tinaxiawuhao.github.io/post-images/1657629228908.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="28"><img src="https://tinaxiawuhao.github.io/post-images/1657629242632.png" alt="" loading="lazy"></figure>
<h2 id="55-topic方式">5.5 Topic方式</h2>
<figure data-type="image" tabindex="29"><img src="https://tinaxiawuhao.github.io/post-images/1657629257404.png" alt="" loading="lazy"></figure>
<p>代码详见官网：https://www.rabbitmq.com/tutorials/tutorial-five-java.html</p>
<blockquote>
<p>更多方式，请直接查看官网：https://www.rabbitmq.com/getstarted.html</p>
</blockquote>
<figure data-type="image" tabindex="30"><img src="https://tinaxiawuhao.github.io/post-images/1657629270305.png" alt="" loading="lazy"></figure>
<h1 id="6-rabbitmq-进阶">6. RabbitMQ 进阶</h1>
<h2 id="61-durable-和-autodeleted">6.1 durable 和 autoDeleted</h2>
<p>在定义Queue时，可以指定这两个参数：</p>
<pre><code class="language-java">/**
 * Declare an exchange.
 * @see com.rabbitmq.client.AMQP.Exchange.Declare
 * @see com.rabbitmq.client.AMQP.Exchange.DeclareOk
 * @param exchange the name of the exchange
 * @param type the exchange type
 * @param durable true if we are declaring a durable exchange (the exchange will survive a server restart)
 * @param autoDelete true if the server should delete the exchange when it is no longer in use
 * @param arguments other properties (construction arguments) for the exchange
 * @return a declaration-confirm method to indicate the exchange was successfully declared
 * @throws java.io.IOException if an error is encountered
 */
Exchange.DeclareOk exchangeDeclare(String exchange, BuiltinExchangeType type, boolean durable, boolean autoDelete,
    Map&lt;String, Object&gt; arguments) throws IOException;
    
/**
* Declare a queue
* @see com.rabbitmq.client.AMQP.Queue.Declare
* @see com.rabbitmq.client.AMQP.Queue.DeclareOk
* @param queue the name of the queue
* @param durable true if we are declaring a durable queue (the queue will survive a server restart)
* @param exclusive true if we are declaring an exclusive queue (restricted to this connection)
* @param autoDelete true if we are declaring an autodelete queue (server will delete it when no longer in use)
* @param arguments other properties (construction arguments) for the queue
* @return a declaration-confirm method to indicate the queue was successfully declared
* @throws java.io.IOException if an error is encountered
*/
Queue.DeclareOk queueDeclare(String queue, boolean durable, boolean exclusive, boolean autoDelete,
    Map&lt;String, Object&gt; arguments) throws IOException;
</code></pre>
<h4 id="611-durable">6.1.1 durable</h4>
<p>持久化，保证RabbitMQ在退出或者crash等异常情况下数据没有丢失，需要将queue，exchange和Message都持久化。</p>
<p>若是将queue的持久化标识durable设置为true，则代表是一个持久的队列，那么在服务重启之后，会重新读取之前被持久化的queue。</p>
<p>虽然队列可以被持久化，但是里面的消息是否为持久化，还要看消息的持久化设置。即重启queue，但是queue里面还没有发出去的消息，那队列里面还存在该消息么？这个取决于该消息的设置。</p>
<h4 id="612-autodeleted">6.1.2 autoDeleted</h4>
<p>自动删除，如果该队列没有任何订阅的消费者的话，该队列会被自动删除。这种队列适用于临时队列。</p>
<p>当一个Queue被设置为自动删除时，当消费者断掉之后，queue会被删除，这个主要针对的是一些不是特别重要的数据，不希望出现消息积累的情况。</p>
<h4 id="613-小节">6.1.3 小节</h4>
<ul>
<li>当一个Queue已经声明好了之后，不能更新durable或者autoDelted值；当需要修改时，需要先删除再重新声明</li>
<li>消费的Queue声明应该和投递的Queue声明的 durable,autoDelted属性一致，否则会报错</li>
<li>对于重要的数据，一般设置 durable=true, autoDeleted=false</li>
<li>对于设置 autoDeleted=true 的队列，当没有消费者之后，队列会自动被删除</li>
</ul>
<h2 id="64-ack">6.4 ACK</h2>
<p>执行一个任务可能需要花费几秒钟，你可能会担心如果一个消费者在执行任务过程中挂掉了。一旦RabbitMQ将消息分发给了消费者，就会从内存中删除。在这种情况下，如果正在执行任务的消费者宕机，会丢失正在处理的消息和分发给这个消费者但尚未处理的消息。</p>
<p>但是，我们不想丢失任何任务，如果有一个消费者挂掉了，那么我们应该将分发给它的任务交付给另一个消费者去处理。</p>
<p>为了确保消息不会丢失，RabbitMQ支持消息应答。消费者发送一个消息应答，告诉RabbitMQ这个消息已经接收并且处理完毕了。RabbitMQ就可以删除它了。</p>
<p>因此手动ACK的常见手段：</p>
<pre><code class="language-java">// 接收消息之后，主动ack/nak
Consumer consumer = new DefaultConsumer(channel) {
    @Override
    public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties,
            byte[] body) throws IOException {
        String message = new String(body, &quot;UTF-8&quot;);
        try {
            System.out.println(&quot; [ &quot; + queue + &quot; ] Received '&quot; + message);
            channel.basicAck(envelope.getDeliveryTag(), false);
        } catch (Exception e) {
            channel.basicNack(envelope.getDeliveryTag(), false, true);
        }
    }
};
// 取消自动ack
channel.basicConsume(queue, false, consumer);
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ExecutorCompletionService]]></title>
        <id>https://tinaxiawuhao.github.io/post/wT9gsiZx3/</id>
        <link href="https://tinaxiawuhao.github.io/post/wT9gsiZx3/">
        </link>
        <updated>2022-03-19T14:16:10.000Z</updated>
        <content type="html"><![CDATA[<h3 id="future">Future</h3>
<p>Future模式是多线程设计常用的一种设计模式。Future模式可以理解成：我有一个任务，提交给了Future，Future替我完成这个任务。期间我自己可以去做任何想做的事情。一段时间之后，我就便可以从Future那儿取出结果。</p>
<h4 id="future提供了三种功能">Future提供了三种功能：</h4>
<ul>
<li>判断任务是否完成</li>
<li>能够中断任务</li>
<li>能够获取任务执行的结果<br>
向线程池中提交任务的<strong>submit方法不是阻塞方法，而Future.get方法是一个阻塞方法</strong>，当submit提交多个任务时，只有所有任务都完成后，才能使用get按照任务的提交顺序得到返回结果，所以一般需要使用future.isDone先判断任务是否全部执行完成，完成后再使用future.get得到结果。（也可以用get (long timeout, TimeUnit unit)方法可以设置超时时间，防止无限时间的等待）<br>
三段式的编程：1.启动多线程任务2.处理其他事3.收集多线程任务结果，Future虽然可以实现获取异步执行结果的需求，但是它没有提供通知的机制，要么使用阻塞，在future.get()的地方等待future返回的结果，这时又变成同步操作；要么使用isDone()轮询地判断Future是否完成，这样会耗费CPU的资源。<br>
<strong>解决方法：CompletionService和CompletableFuture（按照任务完成的先后顺序获取任务的结果）</strong></li>
</ul>
<h3 id="executorservice">ExecutorService</h3>
<p>创建线程池，多线程功能调用</p>
<pre><code class="language-java">public static void test1() throws Exception {
    ExecutorService executorService = Executors.newCachedThreadPool();
    ArrayList&lt;Future&lt;String&gt;&gt; futureArrayList = new ArrayList&lt;&gt;();
    System.out.println(&quot;公司让你通知大家聚餐 你开车去接人&quot;);

    Future&lt;String&gt; future10 = executorService.submit(() -&gt; {
        System.out.println(&quot;总裁：我在家上大号 我最近拉肚子比较慢 要蹲1个小时才能出来 你等会来接我吧&quot;);
        TimeUnit.SECONDS.sleep(10);
        System.out.println(&quot;总裁：1小时了 我上完大号了。你来接吧&quot;);
        return &quot;总裁上完大号了&quot;;
    });
    futureArrayList.add(future10);

    Future&lt;String&gt; future6 = executorService.submit(() -&gt; {
        System.out.println(&quot;中层管理：我在家上大号  要蹲10分钟就可以出来 你等会来接我吧&quot;);
        TimeUnit.SECONDS.sleep(6);
        System.out.println(&quot;中层管理：10分钟 我上完大号了。你来接吧&quot;);
        return &quot;中层管理上完大号了&quot;;
    });
    futureArrayList.add(future6);

    Future&lt;String&gt; future3 = executorService.submit(() -&gt; {
        System.out.println(&quot;研发：我在家上大号 我比较快 要蹲3分钟就可以出来 你等会来接我吧&quot;);
        TimeUnit.SECONDS.sleep(3);
        System.out.println(&quot;研发：3分钟 我上完大号了。你来接吧&quot;);
        return &quot;研发上完大号了&quot;;
    });
    futureArrayList.add(future3);

    TimeUnit.SECONDS.sleep(1);
    System.out.println(&quot;都通知完了,等着接吧。&quot;);
    try {
        for (Future&lt;String&gt; future : futureArrayList) {
            String returnStr = future.get();
            System.out.println(returnStr + &quot;，你去接他&quot;);
        }
    } catch (Exception e) {
        e.printStackTrace();
    }finally {
        executorService.shutdown();
    }

}
</code></pre>
<p><strong>结果</strong></p>
<pre><code class="language-java">公司让你通知大家聚餐 你开车去接人
研发：我在家上大号 我比较快 要蹲3分钟就可以出来 你等会来接我吧
总裁：我在家上大号 我最近拉肚子比较慢 要蹲1个小时才能出来 你等会来接我吧
中层管理：我在家上大号  要蹲10分钟就可以出来 你等会来接我吧
都通知完了,等着接吧。
研发：3分钟 我上完大号了。你来接吧
研发上完大号了，你去接他
中层管理：10分钟 我上完大号了。你来接吧
总裁：1小时了 我上完大号了。你来接吧
总裁上完大号了，你去接他
中层管理上完大号了，你去接他
</code></pre>
<h3 id="executorcompletionservice">ExecutorCompletionService</h3>
<pre><code class="language-java">public static void test2() throws Exception {
    ExecutorService executorService = Executors.newCachedThreadPool();
    ExecutorCompletionService&lt;String&gt; completionService = new ExecutorCompletionService&lt;&gt;(executorService);
    System.out.println(&quot;公司让你通知大家聚餐 你开车去接人&quot;);
    completionService.submit(() -&gt; {
        System.out.println(&quot;总裁：我在家上大号 我最近拉肚子比较慢 要蹲1个小时才能出来 你等会来接我吧&quot;);
        TimeUnit.SECONDS.sleep(10);
        System.out.println(&quot;总裁：1小时了 我上完大号了。你来接吧&quot;);
        return &quot;总裁上完大号了&quot;;
    });
     completionService.submit(() -&gt; {
        System.out.println(&quot;中层管理：我在家上大号  要蹲10分钟就可以出来 你等会来接我吧&quot;);
        TimeUnit.SECONDS.sleep(6);
        System.out.println(&quot;中层管理：10分钟 我上完大号了。你来接吧&quot;);
        return &quot;中层管理上完大号了&quot;;
    });
    completionService.submit(() -&gt; {
        System.out.println(&quot;研发：我在家上大号 我比较快 要蹲3分钟就可以出来 你等会来接我吧&quot;);
        TimeUnit.SECONDS.sleep(3);
        System.out.println(&quot;研发：3分钟 我上完大号了。你来接吧&quot;);
        return &quot;研发上完大号了&quot;;
    });
   
    TimeUnit.SECONDS.sleep(1);
    System.out.println(&quot;都通知完了,等着接吧。&quot;);
    //提交了3个异步任务）
    try {
        for (int i = 0; i &lt; 3; i++) {
            String returnStr = completionService.take().get();
            System.out.println(returnStr + &quot;，你去接他&quot;);
        }
        Thread.currentThread().join();
    } catch (Exception e) {
        e.printStackTrace();
    }finally {
        executorService.shutdown();
    }

}
</code></pre>
<p><strong>结果</strong></p>
<pre><code class="language-java">公司让你通知大家聚餐 你开车去接人
总裁：我在家上大号 我最近拉肚子比较慢 要蹲1个小时才能出来 你等会来接我吧
研发：我在家上大号 我比较快 要蹲3分钟就可以出来 你等会来接我吧
中层管理：我在家上大号  要蹲10分钟就可以出来 你等会来接我吧
都通知完了,等着接吧。
研发：3分钟 我上完大号了。你来接吧
研发上完大号了，你去接他
中层管理：10分钟 我上完大号了。你来接吧
中层管理上完大号了，你去接他
总裁：1小时了 我上完大号了。你来接吧
总裁上完大号了，你去接他
</code></pre>
<h3 id="源码分析">源码分析</h3>
<p>completionService是JUC里的线程池ExecutorCompletionService</p>
<h4 id="初始化线程池">初始化线程池</h4>
<ol>
<li>
<p>同步初始化一个完成队列completionQueue</p>
<pre><code class="language-java">public ExecutorCompletionService(Executor executor) {
    if (executor == null)
        throw new NullPointerException();
    this.executor = executor;
    this.aes = (executor instanceof AbstractExecutorService) ?
        (AbstractExecutorService) executor : null;
    this.completionQueue = new LinkedBlockingQueue&lt;Future&lt;V&gt;&gt;();
}
</code></pre>
</li>
</ol>
<h4 id="执行submit方法">执行submit方法</h4>
<ol>
<li>
<p>线程池执行的时候传入了自己的内部类QueueingFuture</p>
<pre><code class="language-java">public Future&lt;V&gt; submit(Callable&lt;V&gt; task) {
    if (task == null) throw new NullPointerException();
    RunnableFuture&lt;V&gt; f = newTaskFor(task);
    executor.execute(new QueueingFuture&lt;V&gt;(f, completionQueue));
    return f;
}
</code></pre>
</li>
<li>
<p>QueueingFuture构造函数，需要关注这里重写了done方法，向阻塞队列里添加task</p>
<pre><code class="language-java">private static class QueueingFuture&lt;V&gt; extends FutureTask&lt;Void&gt; {
    QueueingFuture(RunnableFuture&lt;V&gt; task,
                   BlockingQueue&lt;Future&lt;V&gt;&gt; completionQueue) {
        super(task, null);
        this.task = task;
        this.completionQueue = completionQueue;
    }
    private final Future&lt;V&gt; task;
    private final BlockingQueue&lt;Future&lt;V&gt;&gt; completionQueue;
    protected void done() { completionQueue.add(task); } //往completionQueue里面存值
}
</code></pre>
</li>
<li>
<p>执行FutureTask的run方法</p>
<pre><code class="language-java">public void run() {
    if (state != NEW ||
        !RUNNER.compareAndSet(this, null, Thread.currentThread()))
        return;
    try {
        Callable&lt;V&gt; c = callable;
        if (c != null &amp;&amp; state == NEW) {
            V result;
            boolean ran;
            try {
                result = c.call();
                ran = true;
            } catch (Throwable ex) {
                result = null;
                ran = false;
                setException(ex);
            }
            if (ran)
                set(result); //设置值
        }
    } finally {
        // runner must be non-null until state is settled to
        // prevent concurrent calls to run()
        runner = null;
        // state must be re-read after nulling runner to prevent
        // leaked interrupts
        int s = state;
        if (s &gt;= INTERRUPTING)
            handlePossibleCancellationInterrupt(s);
    }
}
</code></pre>
</li>
<li>
<p>set方法</p>
<pre><code class="language-java">protected void set(V v) {
    if (STATE.compareAndSet(this, NEW, COMPLETING)) {
        outcome = v;
        STATE.setRelease(this, NORMAL); // final state
        finishCompletion(); 
    }
}
</code></pre>
</li>
<li>
<p>在finishCompletion方法中执行了done方法</p>
<pre><code class="language-java">private void finishCompletion() {
    // assert state &gt; COMPLETING;
    for (WaitNode q; (q = waiters) != null;) {
        if (WAITERS.weakCompareAndSet(this, q, null)) {
            for (;;) {
                Thread t = q.thread;
                if (t != null) {
                    q.thread = null;
                    LockSupport.unpark(t);
                }
                WaitNode next = q.next;
                if (next == null)
                    break;
                q.next = null; // unlink to help gc
                q = next;
            }
            break;
        }
    }

    done();             //执行done方法-completionQueue.add(task);

    callable = null;        // to reduce footprint
}
</code></pre>
</li>
</ol>
<p>所以每次线程完成任务，都会往completionQueue中新增一条记录。completionQueue中的记录需要通过别的方式取：ExecutorCompletionService.take()。<br>
ExecutorCompletionService的实际用法应该是这样的：CompletionService一边执行任务，一边处理完成的任务结果，这样可以将执行的任务与处理任务隔离开来进行处理，使用submit执行任务，使用take获取已完成的任务，先完成的任务结果先加入队列。获取的结果，跟提交给线程池的任务是无关联的。</p>
<pre><code class="language-java">Future&lt;String&gt; submit = completionService.submit(() -&gt; {
    return &quot;假装有返回&quot;;
});
submit.get();//直接获取返回值
</code></pre>
<p>如上如果我们在使用过程中由于需要的是当前线程任务的返回值，所以没有调用take方法，而是通过get方法获取到当前线程调用的返回值，会导致task任务在队列中一直增加，从而造成OOM</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[消息队列选型]]></title>
        <id>https://tinaxiawuhao.github.io/post/DyzAzkEVU/</id>
        <link href="https://tinaxiawuhao.github.io/post/DyzAzkEVU/">
        </link>
        <updated>2022-03-15T11:56:34.000Z</updated>
        <content type="html"><![CDATA[<h3 id="消息队列">消息队列</h3>
<p>常用的消息队列主要这 4 种，分别为 Kafka、RabbitMQ、RocketMQ 和 ActiveMQ，主要介绍前三，不BB，上思维导图！</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1657627504417.png" alt="" loading="lazy"></figure>
<h3 id="消息队列基础">消息队列基础</h3>
<h4 id="什么是消息队列">什么是消息队列？</h4>
<p>消息队列是在消息的传输过程中保存消息的容器，用于接收消息并以文件的方式存储，一个消息队列可以被一个也可以被多个消费者消费，包含以下 3 元素：</p>
<ul>
<li>Producer：消息生产者，负责产生和发送消息到 Broker；</li>
<li>Broker：消息处理中心，负责消息存储、确认、重试等，一般其中会包含多个 Queue；</li>
<li>Consumer：消息消费者，负责从 Broker 中获取消息，并进行相应处理。</li>
</ul>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1657627512680.png" alt="" loading="lazy"></figure>
<h4 id="消息队列模式">消息队列模式</h4>
<ul>
<li>点对点模式：多个生产者可以向同一个消息队列发送消息，一个具体的消息只能由一个消费者消费。</li>
</ul>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1657627520099.png" alt="" loading="lazy"></figure>
<ul>
<li>发布/订阅模式：单个消息可以被多个订阅者并发的获取和处理。</li>
</ul>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1657627527080.png" alt="" loading="lazy"></figure>
<h4 id="消息队列应用场景">消息队列应用场景</h4>
<ul>
<li><strong>应用解耦</strong>：消息队列减少了服务之间的耦合性，不同的服务可以通过消息队列进行通信，而不用关心彼此的实现细节。</li>
<li><strong>异步处理</strong>：消息队列本身是异步的，它允许接收者在消息发送很长时间后再取回消息。</li>
<li><strong>流量削锋</strong>：当上下游系统处理能力存在差距的时候，利用消息队列做一个通用的”载体”，在下游有能力处理的时候，再进行分发与处理。</li>
<li><strong>日志处理</strong>：日志处理是指将消息队列用在日志处理中，比如 Kafka 的应用，解决大量日志传输的问题。</li>
<li><strong>消息通讯</strong>：消息队列一般都内置了高效的通信机制，因此也可以用在纯的消息通讯，比如实现点对点消息队列，或者聊天室等。</li>
<li><strong>消息广播</strong>：如果没有消息队列，每当一个新的业务方接入，我们都要接入一次新接口。有了消息队列，我们只需要关心消息是否送达了队列，至于谁希望订阅，是下游的事情，无疑极大地减少了开发和联调的工作量。</li>
</ul>
<h3 id="常用消息队列">常用消息队列</h3>
<p>由于官方社区现在对 ActiveMQ 5.x 维护越来越少，较少在大规模吞吐的场景中使用，所以我们主要讲解 Kafka、RabbitMQ 和 RocketMQ。</p>
<h4 id="kafka">Kafka</h4>
<p>Apache Kafka 最初由 LinkedIn 公司基于独特的设计实现为一个分布式的提交日志系统，之后成为 Apache 项目的一部分，<strong>号称大数据的杀手锏，在数据采集、传输、存储的过程中发挥着举足轻重的作用。</strong></p>
<p><strong>它是一个分布式的，支持多分区、多副本，基于 Zookeeper 的分布式消息流平台</strong>，它同时也是一款开源的基于发布订阅模式的消息引擎系统。</p>
<h5 id="重要概念">重要概念</h5>
<ul>
<li><strong>主题（Topic）</strong>：消息的种类称为主题，可以说一个主题代表了一类消息，相当于是对消息进行分类，主题就像是数据库中的表。</li>
<li><strong>分区（partition）</strong>：主题可以被分为若干个分区，同一个主题中的分区可以不在一个机器上，有可能会部署在多个机器上，由此来实现 kafka 的伸缩性。</li>
<li><strong>批次</strong>：为了提高效率， 消息会分批次写入 Kafka，批次就代指的是一组消息。</li>
<li><strong>消费者群组（Consumer Group）</strong>：消费者群组指的就是由一个或多个消费者组成的群体。</li>
<li><strong>Broker</strong>: 一个独立的 Kafka 服务器就被称为 broker，broker 接收来自生产者的消息，为消息设置偏移量，并提交消息到磁盘保存。</li>
<li><strong>Broker 集群</strong>：broker 集群由一个或多个 broker 组成。</li>
<li><strong>重平衡（Rebalance）</strong>：消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。</li>
</ul>
<h5 id="kafka-架构">Kafka 架构</h5>
<p>一个典型的 Kafka 集群中包含 Producer、broker、Consumer Group、Zookeeper 集群。</p>
<p>Kafka 通过 Zookeeper 管理集群配置，选举 leader，以及在 Consumer Group 发生变化时进行 rebalance。Producer 使用 push 模式将消息发布到 broker，Consumer 使用 pull 模式从 broker 订阅并消费消息。</p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1657627597961.png" alt="" loading="lazy"></figure>
<h5 id="kafka-工作原理">Kafka 工作原理</h5>
<p>消息经过序列化后，通过不同的分区策略，找到对应的分区。</p>
<p><strong>相同主题和分区的消息，会被存放在同一个批次里</strong>，然后由一个独立的线程负责把它们发到 Kafka Broker 上。</p>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1657627604741.png" alt="" loading="lazy"></figure>
<p>分区的策略包括顺序轮询、随机轮询和 key hash 这 3 种方式，那什么是分区呢？</p>
<p>分区是 Kafka 读写数据的最小粒度，比如主题 A 有 15 条消息，有 5 个分区，如果采用顺序轮询的方式，15 条消息会顺序分配给这 5 个分区，后续消费的时候，也是按照分区粒度消费。</p>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1657627611867.png" alt="" loading="lazy"></figure>
<p>由于分区可以部署在多个不同的机器上，所以可以通过分区实现 Kafka 的伸缩性，比如主题 A 的 5 个分区，分别部署在 5 台机器上，如果下线一台，分区就变为 4。</p>
<p>Kafka 消费是通过消费群组完成，同一个消费者群组，<strong>一个消费者可以消费多个分区，但是一个分区，只能被一个消费者消费。</strong></p>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1657627618721.png" alt="" loading="lazy"></figure>
<p><strong>如果消费者增加，会触发 Rebalance，也就是分区和消费者需要重新配对</strong>。</p>
<p><strong>不同的消费群组互不干涉</strong>，比如下图的 2 个消费群组，可以分别消费这 4 个分区的消息，互不影响。</p>
<figure data-type="image" tabindex="9"><img src="https://tinaxiawuhao.github.io/post-images/1657627625216.png" alt="" loading="lazy"></figure>
<blockquote>
<p>更多知识，详见<a href="https://tinaxiawuhao.github.io/post/KM-0yw6ab/">Kafka 架构深入</a></p>
</blockquote>
<h4 id="rocketmq">RocketMQ</h4>
<p>RocketMQ 是阿里开源的消息中间件，它是纯 Java 开发，<strong>具有高性能、高可靠、高实时、适合大规模分布式系统应用的特点。</strong></p>
<p>RocketMQ 思路起源于 Kafka，但并不是 Kafka 的一个 Copy，<strong>它对消息的可靠传输及事务性做了优化</strong>，目前在阿里集团被广泛应用于交易、充值、流计算、消息推送、日志流式处理、binlog 分发等场景。</p>
<h5 id="重要概念-2">重要概念</h5>
<ul>
<li><strong>Name 服务器（NameServer）</strong>：充当注册中心，类似 Kafka 中的 Zookeeper。</li>
<li><strong>Broker</strong>: 一个独立的 RocketMQ 服务器就被称为 broker，broker 接收来自生产者的消息，为消息设置偏移量。</li>
<li><strong>主题（Topic）</strong>：消息的第一级类型，一条消息必须有一个 Topic。</li>
<li><strong>子主题（Tag）</strong>：消息的第二级类型，同一业务模块不同目的的消息就可以用相同 Topic 和不同的 Tag 来标识。</li>
<li><strong>分组（Group）</strong>：一个组可以订阅多个 Topic，包括生产者组（Producer Group）和消费者组（Consumer Group）。</li>
<li><strong>队列（Queue）</strong>：可以类比 Kafka 的分区 Partition。</li>
</ul>
<h5 id="rocketmq-工作原理">RocketMQ 工作原理</h5>
<p>RockerMQ 中的消息模型就是按照主题模型所实现的，包括 Producer Group、Topic、Consumer Group 三个角色。</p>
<p><strong>为了提高并发能力，一个 Topic 包含多个 Queue</strong>，生产者组根据主题将消息放入对应的 Topic，下图是采用轮询的方式找到里面的 Queue。</p>
<p>RockerMQ 中的消费群组和 Queue，可以类比 Kafka 中的消费群组和 Partition：<strong>不同的消费者组互不干扰，一个 Queue 只能被一个消费者消费，一个消费者可以消费多个 Queue。</strong></p>
<p>消费 Queue 的过程中，通过偏移量记录消费的位置。</p>
<figure data-type="image" tabindex="10"><img src="https://tinaxiawuhao.github.io/post-images/1657627636503.png" alt="" loading="lazy"></figure>
<h5 id="rocketmq-架构">RocketMQ 架构</h5>
<p>RocketMQ 技术架构中有四大角色 NameServer、Broker、Producer 和 Consumer，下面主要介绍 Broker。</p>
<p><strong>Broker 用于存放 Queue，一个 Broker 可以配置多个 Topic，一个 Topic 中存在多个 Queue。</strong></p>
<p>如果某个 Topic 消息量很大，应该给它多配置几个 Queue，并且尽量多分布在不同 broker 上，以减轻某个 broker 的压力。Topic 消息量都比较均匀的情况下，如果某个 broker 上的队列越多，则该 broker 压力越大。</p>
<figure data-type="image" tabindex="11"><img src="https://tinaxiawuhao.github.io/post-images/1657627647064.png" alt="" loading="lazy"></figure>
<p>简单提一下，Broker 通过集群部署，并且提供了 master/slave 的结构，slave 定时从 master 同步数据（同步刷盘或者异步刷盘），如果 master 宕机，则 slave 提供消费服务，但是不能写入消息。</p>
<p>看到这里，大家应该可以发现，RocketMQ 的设计和 Kafka 真的很像！</p>
<blockquote>
<p>更多知识，详见</p>
</blockquote>
<h4 id="rabbitmq">RabbitMQ</h4>
<p>RabbitMQ 2007 年发布，是使用 Erlang 语言开发的开源消息队列系统，基于 AMQP 协议来实现。</p>
<p>AMQP 的主要特征是面向消息、队列、路由、可靠性、安全。<strong>AMQP 协议更多用在企业系统内，对数据一致性、稳定性和可靠性要求很高的场景，对性能和吞吐量的要求还在其次。</strong></p>
<h5 id="重要概念-3">重要概念</h5>
<ul>
<li><strong>信道（Channel）</strong>：消息读写等操作在信道中进行，客户端可以建立多个信道，每个信道代表一个会话任务。</li>
<li><strong>交换器（Exchange）</strong>：接收消息，按照路由规则将消息路由到一个或者多个队列；如果路由不到，或者返回给生产者，或者直接丢弃。</li>
<li><strong>路由键（RoutingKey）</strong>：生产者将消息发送给交换器的时候，会发送一个 RoutingKey，用来指定路由规则，这样交换器就知道把消息发送到哪个队列。</li>
<li><strong>绑定（Binding）</strong>：交换器和消息队列之间的虚拟连接，绑定中可以包含一个或者多个 RoutingKey。</li>
</ul>
<h5 id="rabbitmq-工作原理">RabbitMQ 工作原理</h5>
<p>AMQP 协议模型由三部分组成：生产者、消费者和服务端，执行流程如下：</p>
<ol>
<li>生产者是连接到 Server，建立一个连接，开启一个信道。</li>
<li>生产者声明交换器和队列，设置相关属性，并通过路由键将交换器和队列进行绑定。</li>
<li>消费者也需要进行建立连接，开启信道等操作，便于接收消息。</li>
<li>生产者发送消息，发送到服务端中的虚拟主机。</li>
<li>虚拟主机中的交换器根据路由键选择路由规则，发送到不同的消息队列中。</li>
<li>订阅了消息队列的消费者就可以获取到消息，进行消费。</li>
</ol>
<figure data-type="image" tabindex="12"><img src="https://tinaxiawuhao.github.io/post-images/1657627658105.png" alt="" loading="lazy"></figure>
<h5 id="常用交换器">常用交换器</h5>
<p>RabbitMQ 常用的交换器类型有 direct、topic、fanout、headers 四种</p>
<p>具体的使用方法，可以参考官网：</p>
<ul>
<li>官网入口：https://www.rabbitmq.com/getstarted.html</li>
</ul>
<figure data-type="image" tabindex="13"><img src="https://tinaxiawuhao.github.io/post-images/1657627665439.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="14"><img src="https://tinaxiawuhao.github.io/post-images/1657627671336.png" alt="" loading="lazy"></figure>
<blockquote>
<p>更多知识，详见</p>
</blockquote>
<h3 id="消息队列对比选型">消息队列对比&amp;选型</h3>
<figure data-type="image" tabindex="15"><img src="https://tinaxiawuhao.github.io/post-images/1657627677983.png" alt="" loading="lazy"></figure>
<h4 id="消息队列对比">消息队列对比</h4>
<h5 id="kafka-2">Kafka</h5>
<p><strong>优点：</strong></p>
<ul>
<li><strong>高吞吐、低延迟</strong>：Kafka 最大的特点就是收发消息非常快，Kafka 每秒可以处理几十万条消息，它的最低延迟只有几毫秒；</li>
<li><strong>高伸缩性</strong>：每个主题（topic）包含多个分区（partition），主题中的分区可以分布在不同的主机（broker）中；</li>
<li><strong>高稳定性</strong>：Kafka 是分布式的，一个数据多个副本，某个节点宕机，Kafka 集群能够正常工作；</li>
<li><strong>持久性、可靠性、可回溯</strong>：Kafka 能够允许数据的持久化存储，消息被持久化到磁盘，并支持数据备份防止数据丢失，支持消息回溯；</li>
<li>消息有序：通过控制能够保证所有消息被消费且仅被消费一次；</li>
<li>有优秀的第三方 Kafka Web 管理界面 Kafka-Manager，在日志领域比较成熟，被多家公司和多个开源项目使用。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>Kafka 单机超过 64 个队列/分区，Load 会发生明显的飙高现象，队列越多，load 越高，发送消息响应时间变长；</li>
<li><strong>不支持消息路由，不支持延迟发送，不支持消息重试；</strong></li>
<li><strong>社区更新较慢。</strong></li>
</ul>
<h5 id="rocketmq-2">RocketMQ</h5>
<p><strong>优点：</strong></p>
<ul>
<li><strong>高吞吐</strong>：借鉴 Kafka 的设计，单一队列百万消息的堆积能力；</li>
<li><strong>高伸缩性</strong>：灵活的分布式横向扩展部署架构，整体架构其实和 kafka 很像；</li>
<li><strong>高容错性</strong>：通过ACK机制，保证消息一定能正常消费；</li>
<li><strong>持久化、可回溯</strong>：消息可以持久化到磁盘中，支持消息回溯；</li>
<li>消息有序：在一个队列中可靠的先进先出（FIFO）和严格的顺序传递；</li>
<li>支持发布/订阅和点对点消息模型，支持拉、推两种消息模式；</li>
<li>提供 docker 镜像用于隔离测试和云集群部署，提供配置、指标和监控等功能丰富的 Dashboard。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>不支持消息路由，<strong>支持的客户端语言不多，目前是 java 及 c++，其中 c++ 不成熟</strong>；</li>
<li>部分支持消息有序：需要将同一类的消息 hash 到同一个队列 Queue 中，才能支持消息的顺序，如果同一类消息散落到不同的 Queue中，就不能支持消息的顺序。</li>
<li><strong>社区活跃度一般。</strong></li>
</ul>
<h5 id="rabbitmq-2">RabbitMQ</h5>
<p><strong>优点：</strong></p>
<ul>
<li><strong>支持几乎所有最受欢迎的编程语言</strong>：Java，C，C ++，C＃，Ruby，Perl，Python，PHP等等；</li>
<li><strong>支持消息路由</strong>：RabbitMQ 可以通过不同的交换器支持不同种类的消息路由；</li>
<li><strong>消息时序</strong>：通过延时队列，可以指定消息的延时时间，过期时间TTL等；</li>
<li>支持容错处理：通过交付重试和死信交换器（DLX）来处理消息处理故障；</li>
<li>提供了一个易用的用户界面，使得用户可以监控和管理消息 Broker；</li>
<li><strong>社区活跃度高。</strong></li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li><strong>Erlang 开发，很难去看懂源码，不利于做二次开发和维护</strong>，基本只能依赖于开源社区的快速维护和修复 bug；</li>
<li><strong>RabbitMQ 吞吐量会低一些</strong>，这是因为他做的实现机制比较重；</li>
<li>不支持消息有序、持久化不好、不支持消息回溯、伸缩性一般。</li>
</ul>
<h4 id="消息队列选型">消息队列选型</h4>
<ul>
<li>Kafka：追求高吞吐量，一开始的目的就是用于日志收集和传输，<strong>适合产生大量数据的互联网服务的数据收集业务</strong>，大型公司建议可以选用，<strong>如果有日志采集功能，肯定是首选 kafka。</strong></li>
<li>RocketMQ：<strong>天生为金融互联网领域而生，对于可靠性要求很高的场景</strong>，尤其是电商里面的订单扣款，以及业务削峰，在大量交易涌入时，后端可能无法及时处理的情况。RocketMQ 在稳定性上可能更值得信赖，这些业务场景在阿里双 11 已经经历了多次考验，<strong>如果你的业务有上述并发场景，建议可以选择 RocketMQ。</strong></li>
<li>RabbitMQ：结合 erlang 语言本身的并发优势，性能较好，社区活跃度也比较高，但是不利于做二次开发和维护，不过 RabbitMQ 的社区十分活跃，可以解决开发过程中遇到的 bug。<strong>如果你的数据量没有那么大，小公司优先选择功能比较完备的 RabbitMQ。</strong></li>
<li>ActiveMQ：官方社区现在对 ActiveMQ 5.x 维护越来越少，<strong>较少在大规模吞吐的场景中使用。</strong></li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[easyExcel]]></title>
        <id>https://tinaxiawuhao.github.io/post/T8lb37RDN/</id>
        <link href="https://tinaxiawuhao.github.io/post/T8lb37RDN/">
        </link>
        <updated>2022-03-10T10:50:56.000Z</updated>
        <content type="html"><![CDATA[<h3 id="读excel">读Excel</h3>
<h4 id="注解">注解</h4>
<p>使用注解很简单，只要在对应的实体类上面加上注解即可。</p>
<h5 id="excelproperty"><code>ExcelProperty</code></h5>
<p>用于匹配excel和实体类的匹配,参数如下：</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>默认值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>value</td>
<td>空</td>
<td>用于匹配excel中的头，必须全匹配,如果有多行头，会匹配最后一行头</td>
</tr>
<tr>
<td>order</td>
<td>Integer.MAX_VALUE</td>
<td>优先级高于<code>value</code>，会根据<code>order</code>的顺序来匹配实体和excel中数据的顺序</td>
</tr>
<tr>
<td>index</td>
<td>-1</td>
<td>优先级高于<code>value</code>和<code>order</code>，会根据<code>index</code>直接指定到excel中具体的哪一列</td>
</tr>
<tr>
<td>converter</td>
<td>自动选择</td>
<td>指定当前字段用什么转换器，默认会自动选择。读的情况下只要实现<code>com.alibaba.excel.converters.Converter#convertToJavaData(com.alibaba.excel.converters.ReadConverterContext&lt;?&gt;)</code> 方法即可</td>
</tr>
</tbody>
</table>
<h5 id="excelignore"><code>ExcelIgnore</code></h5>
<p>默认所有字段都会和excel去匹配，加了这个注解会忽略该字段</p>
<h5 id="excelignoreunannotated"><code>ExcelIgnoreUnannotated</code></h5>
<p>默认不加<code>ExcelProperty</code> 的注解的都会参与读写，加了不会参与</p>
<h5 id="datetimeformat"><code>DateTimeFormat</code></h5>
<p>日期转换，用<code>String</code>去接收excel日期格式的数据会调用这个注解,参数如下：</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>默认值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>value</td>
<td>空</td>
<td>参照<code>java.text.SimpleDateFormat</code>书写即可</td>
</tr>
<tr>
<td>use1904windowing</td>
<td>自动选择</td>
<td>excel中时间是存储1900年起的一个双精度浮点数，但是有时候默认开始日期是1904，所以设置这个值改成默认1904年开始</td>
</tr>
</tbody>
</table>
<h5 id="numberformat"><code>NumberFormat</code></h5>
<p>数字转换，用<code>String</code>去接收excel数字格式的数据会调用这个注解。</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>默认值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>value</td>
<td>空</td>
<td>参照<code>java.text.DecimalFormat</code>书写即可</td>
</tr>
<tr>
<td>roundingMode</td>
<td>RoundingMode.HALF_UP</td>
<td>格式化的时候设置舍入模式</td>
</tr>
</tbody>
</table>
<h4 id="参数">参数</h4>
<h5 id="概念介绍">概念介绍</h5>
<ul>
<li><code>ReadWorkbook</code> 可以理解成一个excel</li>
<li><code>ReadSheet</code> 理解成一个excel里面的一个表单</li>
</ul>
<h5 id="通用参数">通用参数</h5>
<p><code>ReadWorkbook</code>,<code>ReadSheet</code> 都会有的参数，如果为空，默认使用上级。</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>默认值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>converter</td>
<td>空</td>
<td>默认加载了很多转换器，这里可以加入不支持的字段</td>
</tr>
<tr>
<td>readListener</td>
<td>空</td>
<td>可以注册多个监听器，读取excel的时候会不断的回调监听器中的方法</td>
</tr>
<tr>
<td>headRowNumber</td>
<td>1</td>
<td>excel中头的行数，默认1行</td>
</tr>
<tr>
<td>head</td>
<td>空</td>
<td>与<code>clazz</code>二选一。读取文件头对应的列表，会根据列表匹配数据，建议使用class</td>
</tr>
<tr>
<td>clazz</td>
<td>空</td>
<td>与<code>head</code>二选一。读取文件的头对应的class，也可以使用注解。如果两个都不指定，则会读取全部数据</td>
</tr>
<tr>
<td>autoTrim</td>
<td>true</td>
<td>会对头、读取数据等进行自动trim</td>
</tr>
<tr>
<td>use1904windowing</td>
<td>false</td>
<td>excel中时间是存储1900年起的一个双精度浮点数，但是有时候默认开始日期是1904，所以设置这个值改成默认1904年开始</td>
</tr>
<tr>
<td>useScientificFormat</td>
<td>false</td>
<td>数字转文本的时候在较大的数值的是否是否采用科学计数法</td>
</tr>
</tbody>
</table>
<h5 id="readworkbook">ReadWorkbook</h5>
<p>设置方法如下，找不到参数的看下通用参数里面是否存在。</p>
<pre><code class="language-java"> EasyExcel.read(fileName, DemoData.class, new DemoDataListener())
 // 在 read 方法之后， 在 sheet方法之前都是设置ReadWorkbook的参数
 .sheet()
 .doRead();
</code></pre>
<table>
<thead>
<tr>
<th>名称</th>
<th>默认值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>excelType</td>
<td>空</td>
<td>当前excel的类型,支持XLS、XLSX、CSV</td>
</tr>
<tr>
<td>inputStream</td>
<td>空</td>
<td>与<code>file</code>二选一。读取文件的流，如果接收到的是流就只用，不用流建议使用<code>file</code>参数。因为使用了<code>inputStream</code> easyexcel会帮忙创建临时文件，最终还是<code>file</code></td>
</tr>
<tr>
<td>file</td>
<td>空</td>
<td>与<code>inputStream</code>二选一。读取文件的文件。</td>
</tr>
<tr>
<td>mandatoryUseInputStream</td>
<td>false</td>
<td>强制使用 <code>inputStream</code> 来创建对象，性能会变差，但是不会创建临文件。</td>
</tr>
<tr>
<td>charset</td>
<td>Charset#defaultCharset</td>
<td>只有csv文件有用，读取文件的时候使用的编码</td>
</tr>
<tr>
<td>autoCloseStream</td>
<td>true</td>
<td>自动关闭读取的流。</td>
</tr>
<tr>
<td>readCache</td>
<td>空</td>
<td>默认小于5M用 内存，超过5M会使用 <code>EhCache</code>,这里不建议使用这个参数。</td>
</tr>
<tr>
<td>readCacheSelector</td>
<td>SimpleReadCacheSelector</td>
<td>用于选择什么时候用内存去存储临时数据，什么时候用磁盘存储临时数据</td>
</tr>
<tr>
<td>ignoreEmptyRow</td>
<td>true</td>
<td>忽略空的行</td>
</tr>
<tr>
<td>password</td>
<td>空</td>
<td>读取文件的密码</td>
</tr>
<tr>
<td>xlsxSAXParserFactoryName</td>
<td>空</td>
<td>指定sax读取使用的class的名称，例如：<code>com.sun.org.apache.xerces.internal.jaxp.SAXParserFactoryImpl</code></td>
</tr>
<tr>
<td>useDefaultListener</td>
<td>true</td>
<td><code>@since 2.1.4</code> 默认会加入<code>ModelBuildEventListener</code> 来帮忙转换成传入<code>class</code>的对象，设置成<code>false</code>后将不会协助转换对象，自定义的监听器会接收到<code>Map&lt;Integer,CellData&gt;</code>对象，如果还想继续接听到<code>class</code>对象，请调用<code>readListener</code>方法，加入自定义的<code>beforeListener</code>、 <code>ModelBuildEventListener</code>、 自定义的<code>afterListener</code>即可。</td>
</tr>
<tr>
<td>extraReadSet</td>
<td>空</td>
<td>额外需要读取内容的set，默认不读取这些数据</td>
</tr>
</tbody>
</table>
<h5 id="readsheet">ReadSheet</h5>
<p>设置方法如下，找不到参数的看下通用参数里面是否存在。</p>
<pre><code class="language-java"> EasyExcel.read(fileName, DemoData.class, new DemoDataListener())
 .sheet()
  // 在 sheet 方法之后， 在 doRead方法之前都是设置ReadSheet的参数
 .doRead();
</code></pre>
<table>
<thead>
<tr>
<th>名称</th>
<th>默认值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>sheetNo</td>
<td>0</td>
<td>需要读取Sheet的编码，建议使用这个来指定读取哪个Sheet</td>
</tr>
<tr>
<td>sheetName</td>
<td>空</td>
<td>根据名字去匹配Sheet</td>
</tr>
</tbody>
</table>
<h3 id="写excel">写Excel</h3>
<h4 id="注解-2">注解</h4>
<p>使用注解很简单，只要在对应的实体类上面加上注解即可。</p>
<h5 id="excelproperty-2"><code>ExcelProperty</code></h5>
<p>用于匹配excel和实体类的匹配,参数如下：</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>默认值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>value</td>
<td>空</td>
<td>用于匹配excel中的头，必须全匹配,如果有多行头，会匹配最后一行头</td>
</tr>
<tr>
<td>order</td>
<td>Integer.MAX_VALUE</td>
<td>优先级高于<code>value</code>，会根据<code>order</code>的顺序来匹配实体和excel中数据的顺序</td>
</tr>
<tr>
<td>index</td>
<td>-1</td>
<td>优先级高于<code>value</code>和<code>order</code>，会根据<code>index</code>直接指定到excel中具体的哪一列</td>
</tr>
<tr>
<td>converter</td>
<td>自动选择</td>
<td>指定当前字段用什么转换器，默认会自动选择。写的情况下只要实现<code>com.alibaba.excel.converters.Converter#convertToExcelData(com.alibaba.excel.converters.WriteConverterContext&lt;T&gt;)</code> 方法即可</td>
</tr>
</tbody>
</table>
<h5 id="excelignore-2"><code>ExcelIgnore</code></h5>
<p>默认所有字段都会和excel去匹配，加了这个注解会忽略该字段</p>
<h5 id="excelignoreunannotated-2"><code>ExcelIgnoreUnannotated</code></h5>
<p>默认不加<code>ExcelProperty</code> 的注解的都会参与读写，加了不会参与</p>
<h5 id="datetimeformat-2"><code>DateTimeFormat</code></h5>
<p>日期转换，用<code>String</code>去接收excel日期格式的数据会调用这个注解,参数如下：</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>默认值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>value</td>
<td>空</td>
<td>参照<code>java.text.SimpleDateFormat</code>书写即可</td>
</tr>
<tr>
<td>use1904windowing</td>
<td>自动选择</td>
<td>excel中时间是存储1900年起的一个双精度浮点数，但是有时候默认开始日期是1904，所以设置这个值改成默认1904年开始</td>
</tr>
</tbody>
</table>
<h5 id="numberformat-2"><code>NumberFormat</code></h5>
<p>数字转换，用<code>String</code>去接收excel数字格式的数据会调用这个注解。</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>默认值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>value</td>
<td>空</td>
<td>参照<code>java.text.DecimalFormat</code>书写即可</td>
</tr>
<tr>
<td>roundingMode</td>
<td>RoundingMode.HALF_UP</td>
<td>格式化的时候设置舍入模式</td>
</tr>
</tbody>
</table>
<h4 id="参数-2">参数</h4>
<h5 id="概念介绍-2">概念介绍</h5>
<ul>
<li><code>WriteWorkbook</code> 可以理解成一个excel</li>
<li><code>WriteSheet</code> 理解成一个excel里面的一个表单</li>
<li><code>WriteTable</code> 一个表单里面如果有多个实际用的表格，则可以用<code>WriteTable</code></li>
</ul>
<h5 id="通用参数-2">通用参数</h5>
<p><code>WriteWorkbook</code>,<code>WriteSheet</code> ,<code>WriteTable</code>都会有的参数，如果为空，默认使用上级。</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>默认值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>converter</td>
<td>空</td>
<td>默认加载了很多转换器，这里可以加入不支持的字段</td>
</tr>
<tr>
<td>writeHandler</td>
<td>空</td>
<td>写的处理器。可以实现<code>WorkbookWriteHandler</code>,<code>SheetWriteHandler</code>,<code>RowWriteHandler</code>,<code>CellWriteHandler</code>，在写入excel的不同阶段会调用</td>
</tr>
<tr>
<td>relativeHeadRowIndex</td>
<td>0</td>
<td>写入到excel和上面空开几行</td>
</tr>
<tr>
<td>head</td>
<td>空</td>
<td>与<code>clazz</code>二选一。读取文件头对应的列表，会根据列表匹配数据，建议使用class</td>
</tr>
<tr>
<td>clazz</td>
<td>空</td>
<td>与<code>head</code>二选一。读取文件的头对应的class，也可以使用注解。如果两个都不指定，则会读取全部数据</td>
</tr>
<tr>
<td>autoTrim</td>
<td>true</td>
<td>会对头、读取数据等进行自动trim</td>
</tr>
<tr>
<td>use1904windowing</td>
<td>false</td>
<td>excel中时间是存储1900年起的一个双精度浮点数，但是有时候默认开始日期是1904，所以设置这个值改成默认1904年开始</td>
</tr>
<tr>
<td>useScientificFormat</td>
<td>false</td>
<td>数字转文本的时候在较大的数值的是否是否采用科学计数法</td>
</tr>
<tr>
<td>needHead</td>
<td>true</td>
<td>是否需要写入头到excel</td>
</tr>
<tr>
<td>useDefaultStyle</td>
<td>true</td>
<td>是否使用默认的样式</td>
</tr>
<tr>
<td>automaticMergeHead</td>
<td>true</td>
<td>自动合并头，头中相同的字段上下左右都会去尝试匹配</td>
</tr>
<tr>
<td>excludeColumnIndexes</td>
<td>空</td>
<td>需要排除对象中的index的数据</td>
</tr>
<tr>
<td>excludeColumnFieldNames</td>
<td>空</td>
<td>需要排除对象中的字段的数据</td>
</tr>
<tr>
<td>includeColumnIndexes</td>
<td>空</td>
<td>只要导出对象中的index的数据</td>
</tr>
<tr>
<td>includeColumnFieldNames</td>
<td>空</td>
<td>只要导出对象中的字段的数据</td>
</tr>
</tbody>
</table>
<h5 id="writeworkbook">WriteWorkbook</h5>
<p>设置方法如下，找不到参数的看下通用参数里面是否存在。</p>
<pre><code class="language-java"> EasyExcel.write(fileName, DemoData.class)
            // 在 write 方法之后， 在 sheet方法之前都是设置WriteWorkbook的参数
            .sheet(&quot;模板&quot;)
            .doWrite(() -&gt; {
                // 分页查询数据
                return data();
            });
</code></pre>
<table>
<thead>
<tr>
<th>名称</th>
<th>默认值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>excelType</td>
<td>空</td>
<td>当前excel的类型,支持XLS、XLSX、CSV</td>
</tr>
<tr>
<td>outputStream</td>
<td>空</td>
<td>与<code>file</code>二选一。写入文件的流</td>
</tr>
<tr>
<td>file</td>
<td>空</td>
<td>与<code>outputStream</code>二选一。写入的文件</td>
</tr>
<tr>
<td>templateInputStream</td>
<td>空</td>
<td>模板的文件流</td>
</tr>
<tr>
<td>templateFile</td>
<td>空</td>
<td>模板文件</td>
</tr>
<tr>
<td>charset</td>
<td>Charset#defaultCharset</td>
<td>只有csv文件有用，写入文件的时候使用的编码</td>
</tr>
<tr>
<td>autoCloseStream</td>
<td>true</td>
<td>自动关闭写入的流。</td>
</tr>
<tr>
<td>password</td>
<td>空</td>
<td>读取文件的密码</td>
</tr>
<tr>
<td>inMemory</td>
<td>false</td>
<td>是否在内存处理，默认会生成临时文件以节约内存。内存模式效率会更好，但是容易OOM</td>
</tr>
<tr>
<td>writeExcelOnException</td>
<td>false</td>
<td>写入过程中抛出异常了，是否尝试把数据写入到excel</td>
</tr>
</tbody>
</table>
<h5 id="writesheet">WriteSheet</h5>
<p>设置方法如下，找不到参数的看下通用参数里面是否存在。</p>
<pre><code class="language-java"> EasyExcel.write(fileName, DemoData.class)
            .sheet(&quot;模板&quot;)
             // 在 sheet 方法之后， 在 doWrite方法之前都是设置WriteSheet的参数
            .doWrite(() -&gt; {
                // 分页查询数据
                return data();
            });
</code></pre>
<table>
<thead>
<tr>
<th>名称</th>
<th>默认值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>sheetNo</td>
<td>0</td>
<td>需要写入的编码</td>
</tr>
<tr>
<td>sheetName</td>
<td>空</td>
<td>需要些的Sheet名称，默认同<code>sheetNo</code></td>
</tr>
</tbody>
</table>
<h5 id="writetable">WriteTable</h5>
<p>设置方法如下，找不到参数的看下通用参数里面是否存在。</p>
<pre><code class="language-java">        EasyExcel.write(fileName, DemoData.class)
            .sheet(&quot;模板&quot;)
            .table()
            // 在 table 方法之后， 在 doWrite方法之前都是设置WriteTable的参数
            .doWrite(() -&gt; {
                // 分页查询数据
                return data();
            });
</code></pre>
<table>
<thead>
<tr>
<th>名称</th>
<th>默认值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>tableNo</td>
<td>0</td>
<td>需要写入的编码</td>
</tr>
</tbody>
</table>
<pre><code class="language-java">&lt;dependency&gt;
    &lt;groupId&gt;com.alibaba&lt;/groupId&gt;
    &lt;artifactId&gt;easyexcel&lt;/artifactId&gt;
    &lt;version&gt;3.1.1&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<h3 id="webtest">WebTest</h3>
<pre><code class="language-java">import java.io.IOException;
import java.net.URLEncoder;
import java.util.Date;
import java.util.List;
import java.util.Map;

import javax.servlet.http.HttpServletResponse;

import com.alibaba.excel.EasyExcel;
import com.alibaba.excel.util.ListUtils;
import com.alibaba.excel.util.MapUtils;
import com.alibaba.fastjson.JSON;

import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Controller;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PostMapping;
import org.springframework.web.bind.annotation.ResponseBody;
import org.springframework.web.multipart.MultipartFile;

/**
 * web读写案例
 *
 **/
@Controller
public class WebTest {

    @Autowired
    private UploadDAO uploadDAO;

    /**
     * 文件下载（失败了会返回一个有部分数据的Excel）
     * &lt;p&gt;
     * 1. 创建excel对应的实体对象 参照{@link DownloadData}
     * &lt;p&gt;
     * 2. 设置返回的 参数
     * &lt;p&gt;
     * 3. 直接写，这里注意，finish的时候会自动关闭OutputStream,当然你外面再关闭流问题不大
     */
    @GetMapping(&quot;download&quot;)
    public void download(HttpServletResponse response) throws IOException {
        // 这里注意 有同学反应使用swagger 会导致各种问题，请直接用浏览器或者用postman
        response.setContentType(&quot;application/vnd.openxmlformats-officedocument.spreadsheetml.sheet&quot;);
        response.setCharacterEncoding(&quot;utf-8&quot;);
        // 这里URLEncoder.encode可以防止中文乱码 当然和easyexcel没有关系
        String fileName = URLEncoder.encode(&quot;测试&quot;, &quot;UTF-8&quot;).replaceAll(&quot;\\+&quot;, &quot;%20&quot;);
        response.setHeader(&quot;Content-disposition&quot;, &quot;attachment;filename*=utf-8''&quot; + fileName + &quot;.xlsx&quot;);

        EasyExcel.write(response.getOutputStream(), DownloadData.class).sheet(&quot;模板&quot;).doWrite(data());
    }

    /**
     * 文件下载并且失败的时候返回json（默认失败了会返回一个有部分数据的Excel）
     *
     * @since 2.1.1
     */
    @GetMapping(&quot;downloadFailedUsingJson&quot;)
    public void downloadFailedUsingJson(HttpServletResponse response) throws IOException {
        // 这里注意 有同学反应使用swagger 会导致各种问题，请直接用浏览器或者用postman
        try {
            response.setContentType(&quot;application/vnd.openxmlformats-officedocument.spreadsheetml.sheet&quot;);
            response.setCharacterEncoding(&quot;utf-8&quot;);
            // 这里URLEncoder.encode可以防止中文乱码 当然和easyexcel没有关系
            String fileName = URLEncoder.encode(&quot;测试&quot;, &quot;UTF-8&quot;).replaceAll(&quot;\\+&quot;, &quot;%20&quot;);
            response.setHeader(&quot;Content-disposition&quot;, &quot;attachment;filename*=utf-8''&quot; + fileName + &quot;.xlsx&quot;);
            // 这里需要设置不关闭流
            EasyExcel.write(response.getOutputStream(), DownloadData.class).autoCloseStream(Boolean.FALSE).sheet(&quot;模板&quot;)
                .doWrite(data());
        } catch (Exception e) {
            // 重置response
            response.reset();
            response.setContentType(&quot;application/json&quot;);
            response.setCharacterEncoding(&quot;utf-8&quot;);
            Map&lt;String, String&gt; map = MapUtils.newHashMap();
            map.put(&quot;status&quot;, &quot;failure&quot;);
            map.put(&quot;message&quot;, &quot;下载文件失败&quot; + e.getMessage());
            response.getWriter().println(JSON.toJSONString(map));
        }
    }

    /**
     * 文件上传
     * &lt;p&gt;
     * 1. 创建excel对应的实体对象 参照{@link UploadData}
     * &lt;p&gt;
     * 2. 由于默认一行行的读取excel，所以需要创建excel一行一行的回调监听器，参照{@link UploadDataListener}
     * &lt;p&gt;
     * 3. 直接读即可
     */
    @PostMapping(&quot;upload&quot;)
    @ResponseBody
    public String upload(MultipartFile file) throws IOException {
        EasyExcel.read(file.getInputStream(), UploadData.class, new UploadDataListener(uploadDAO)).sheet().doRead();
        return &quot;success&quot;;
    }

    private List&lt;DownloadData&gt; data() {
        List&lt;DownloadData&gt; list = ListUtils.newArrayList();
        for (int i = 0; i &lt; 10; i++) {
            DownloadData data = new DownloadData();
            data.setString(&quot;字符串&quot; + 0);
            data.setDate(new Date());
            data.setDoubleData(0.56);
            list.add(data);
        }
        return list;
    }
}
</code></pre>
<h3 id="downloaddata">DownloadData</h3>
<pre><code class="language-java">import java.util.Date;

import com.alibaba.excel.annotation.ExcelProperty;

import lombok.EqualsAndHashCode;
import lombok.Getter;
import lombok.Setter;

/**
 * 基础数据类
 *
 **/
@Getter
@Setter
@EqualsAndHashCode
public class DownloadData {
    @ExcelProperty(&quot;字符串标题&quot;)
    private String string;
    @ExcelProperty(&quot;日期标题&quot;)
    private Date date;
    @ExcelProperty(&quot;数字标题&quot;)
    private Double doubleData;
}
</code></pre>
<h3 id="uploaddao">UploadDAO</h3>
<pre><code class="language-java">import java.util.List;

import org.springframework.stereotype.Repository;

/**
 * 假设这个是你的DAO存储。当然还要这个类让spring管理，当然你不用需要存储，也不需要这个类。
 *
 **/
@Repository
public class UploadDAO {

    public void save(List&lt;UploadData&gt; list) {
        // 如果是mybatis,尽量别直接调用多次insert,自己写一个mapper里面新增一个方法batchInsert,所有数据一次性插入
    }
}
</code></pre>
<h3 id="uploaddata">UploadData</h3>
<pre><code class="language-java">import java.util.Date;

import lombok.EqualsAndHashCode;
import lombok.Getter;
import lombok.Setter;

/**
 * 基础数据类
 *
 **/
@Getter
@Setter
@EqualsAndHashCode
public class UploadData {
    private String string;
    private Date date;
    private Double doubleData;
}
</code></pre>
<h3 id="uploaddatalistener">UploadDataListener</h3>
<pre><code class="language-java">import java.util.List;

import com.alibaba.excel.context.AnalysisContext;
import com.alibaba.excel.read.listener.ReadListener;
import com.alibaba.excel.util.ListUtils;
import com.alibaba.fastjson.JSON;

import lombok.extern.slf4j.Slf4j;

/**
 * 模板的读取类
 *
 */
// 有个很重要的点 DemoDataListener 不能被spring管理，要每次读取excel都要new,然后里面用到spring可以构造方法传进去
@Slf4j
public class UploadDataListener implements ReadListener&lt;UploadData&gt; {
    /**
     * 每隔5条存储数据库，实际使用中可以100条，然后清理list ，方便内存回收
     */
    private static final int BATCH_COUNT = 5;
    private List&lt;UploadData&gt; cachedDataList = ListUtils.newArrayListWithExpectedSize(BATCH_COUNT);
    /**
     * 假设这个是一个DAO，当然有业务逻辑这个也可以是一个service。当然如果不用存储这个对象没用。
     */
    private UploadDAO uploadDAO;

    public UploadDataListener() {
        // 这里是demo，所以随便new一个。实际使用如果到了spring,请使用下面的有参构造函数
        uploadDAO = new UploadDAO();
    }

    /**
     * 如果使用了spring,请使用这个构造方法。每次创建Listener的时候需要把spring管理的类传进来
     *
     * @param uploadDAO
     */
    public UploadDataListener(UploadDAO uploadDAO) {
        this.uploadDAO = uploadDAO;
    }

    /**
     * 这个每一条数据解析都会来调用
     *
     * @param data    one row value. Is is same as {@link AnalysisContext#readRowHolder()}
     * @param context
     */
    @Override
    public void invoke(UploadData data, AnalysisContext context) {
        log.info(&quot;解析到一条数据:{}&quot;, JSON.toJSONString(data));
        cachedDataList.add(data);
        // 达到BATCH_COUNT了，需要去存储一次数据库，防止数据几万条数据在内存，容易OOM
        if (cachedDataList.size() &gt;= BATCH_COUNT) {
            saveData();
            // 存储完成清理 list
            cachedDataList = ListUtils.newArrayListWithExpectedSize(BATCH_COUNT);
        }
    }

    /**
     * 所有数据解析完成了 都会来调用
     *
     * @param context
     */
    @Override
    public void doAfterAllAnalysed(AnalysisContext context) {
        // 这里也要保存数据，确保最后遗留的数据也存储到数据库
        saveData();
        log.info(&quot;所有数据解析完成！&quot;);
    }

    /**
     * 加上存储数据库
     */
    private void saveData() {
        log.info(&quot;{}条数据，开始存储数据库！&quot;, cachedDataList.size());
        uploadDAO.save(cachedDataList);
        log.info(&quot;存储数据库成功！&quot;);
    }
}
</code></pre>
<h3 id="excelutil">ExcelUtil</h3>
<pre><code class="language-java">import com.alibaba.excel.EasyExcelFactory;
import com.alibaba.excel.ExcelWriter;
import com.alibaba.excel.context.AnalysisContext;
import com.alibaba.excel.event.AnalysisEventListener;
import com.alibaba.excel.metadata.BaseRowModel;
import com.alibaba.excel.metadata.Sheet;
import lombok.Data;
import lombok.Getter;
import lombok.Setter;
import lombok.extern.slf4j.Slf4j;
import org.springframework.util.CollectionUtils;
import org.springframework.util.StringUtils;

import java.io.*;
import java.util.ArrayList;
import java.util.Collections;
import java.util.List;

@Slf4j
public class ExcelUtil {

   private static Sheet initSheet;

   static {
      initSheet = new Sheet(1, 0);
      initSheet.setSheetName(&quot;sheet&quot;);
      //设置自适应宽度
      initSheet.setAutoWidth(Boolean.TRUE);
   }

   /**
    * 读取少于1000行数据
    * @param filePath 文件绝对路径
    * @return
    */
   public static List&lt;Object&gt; readLessThan1000Row(String filePath){
      return readLessThan1000RowBySheet(filePath,null);
   }

   /**
    * 读小于1000行数据, 带样式
    * filePath 文件绝对路径
    * initSheet ：
    *      sheetNo: sheet页码，默认为1
    *      headLineMun: 从第几行开始读取数据，默认为0, 表示从第一行开始读取
    *      clazz: 返回数据List&lt;Object&gt; 中Object的类名
    */
   public static List&lt;Object&gt; readLessThan1000RowBySheet(String filePath, Sheet sheet){
      if(!StringUtils.hasText(filePath)){
         return null;
      }

      sheet = sheet != null ? sheet : initSheet;

      InputStream fileStream = null;
      try {
         fileStream = new FileInputStream(filePath);
         return EasyExcelFactory.read(fileStream, sheet);
      } catch (FileNotFoundException e) {
         log.info(&quot;找不到文件或文件路径错误, 文件：{}&quot;, filePath);
      }finally {
         try {
            if(fileStream != null){
               fileStream.close();
            }
         } catch (IOException e) {
            log.info(&quot;excel文件读取失败, 失败原因：{}&quot;, e);
         }
      }
      return null;
   }

   /**
    * 读大于1000行数据
    * @param filePath 文件觉得路径
    * @return
    */
   public static List&lt;Object&gt; readMoreThan1000Row(String filePath){
      return readMoreThan1000RowBySheet(filePath,null);
   }

   /**
    * 读大于1000行数据, 带样式
    * @param filePath 文件觉得路径
    * @return
    */
   public static List&lt;Object&gt; readMoreThan1000RowBySheet(String filePath, Sheet sheet){
      if(!StringUtils.hasText(filePath)){
         return null;
      }

      sheet = sheet != null ? sheet : initSheet;

      InputStream fileStream = null;
      try {
         fileStream = new FileInputStream(filePath);
         ExcelListener excelListener = new ExcelListener();
         EasyExcelFactory.readBySax(fileStream, sheet, excelListener);
         return excelListener.getDatas();
      } catch (FileNotFoundException e) {
         log.error(&quot;找不到文件或文件路径错误, 文件：{}&quot;, filePath);
      }finally {
         try {
            if(fileStream != null){
               fileStream.close();
            }
         } catch (IOException e) {
            log.error(&quot;excel文件读取失败, 失败原因：{}&quot;, e);
         }
      }
      return null;
   }

   /**
    * 生成excle
    * @param filePath  绝对路径, 如：/home/chenmingjian/Downloads/aaa.xlsx
    * @param data 数据源
    * @param head 表头
    */
   public static void writeBySimple(String filePath, List&lt;List&lt;Object&gt;&gt; data, List&lt;String&gt; head){
      writeSimpleBySheet(filePath,data,head,null);
   }

   /**
    * 生成excle
    * @param filePath 绝对路径, 如：/home/chenmingjian/Downloads/aaa.xlsx
    * @param data 数据源
    * @param sheet excle页面样式
    * @param head 表头
    */
   public static void writeSimpleBySheet(String filePath, List&lt;List&lt;Object&gt;&gt; data, List&lt;String&gt; head, Sheet sheet){
      sheet = (sheet != null) ? sheet : initSheet;

      if(head != null){
         List&lt;List&lt;String&gt;&gt; list = new ArrayList&lt;&gt;();
         head.forEach(h -&gt; list.add(Collections.singletonList(h)));
         sheet.setHead(list);
      }

      OutputStream outputStream = null;
      ExcelWriter writer = null;
      try {
         outputStream = new FileOutputStream(filePath);
         writer = EasyExcelFactory.getWriter(outputStream);
         writer.write1(data,sheet);
      } catch (FileNotFoundException e) {
         log.error(&quot;找不到文件或文件路径错误, 文件：{}&quot;, filePath);
      }finally {
         try {
            if(writer != null){
               writer.finish();
            }

            if(outputStream != null){
               outputStream.close();
            }

         } catch (IOException e) {
            log.error(&quot;excel文件导出失败, 失败原因：{}&quot;, e);
         }
      }

   }

   /**
    * 生成excle
    * @param filePath 绝对路径, 如：/home/chenmingjian/Downloads/aaa.xlsx
    * @param data 数据源
    */
   public static void writeWithTemplate(String filePath, List&lt;? extends BaseRowModel&gt; data){
      writeWithTemplateAndSheet(filePath,data,null);
   }

   /**
    * 生成excle
    * @param filePath 绝对路径, 如：/home/chenmingjian/Downloads/aaa.xlsx
    * @param data 数据源
    * @param sheet excle页面样式
    */
   public static void writeWithTemplateAndSheet(String filePath, List&lt;? extends BaseRowModel&gt; data, Sheet sheet){
      if(CollectionUtils.isEmpty(data)){
         return;
      }

      sheet = (sheet != null) ? sheet : initSheet;
      sheet.setClazz(data.get(0).getClass());

      OutputStream outputStream = null;
      ExcelWriter writer = null;
      try {
         outputStream = new FileOutputStream(filePath);
         writer = EasyExcelFactory.getWriter(outputStream);
         writer.write(data,sheet);
      } catch (FileNotFoundException e) {
         log.error(&quot;找不到文件或文件路径错误, 文件：{}&quot;, filePath);
      }finally {
         try {
            if(writer != null){
               writer.finish();
            }

            if(outputStream != null){
               outputStream.close();
            }
         } catch (IOException e) {
            log.error(&quot;excel文件导出失败, 失败原因：{}&quot;, e);
         }
      }

   }

   /**
    * 生成多Sheet的excle
    * @param filePath 绝对路径, 如：/home/chenmingjian/Downloads/aaa.xlsx
    * @param multipleSheelPropetys
    */
   public static void writeWithMultipleSheel(String filePath,List&lt;MultipleSheelPropety&gt; multipleSheelPropetys){
      if(CollectionUtils.isEmpty(multipleSheelPropetys)){
         return;
      }

      OutputStream outputStream = null;
      ExcelWriter writer = null;
      try {
         outputStream = new FileOutputStream(filePath);
         writer = EasyExcelFactory.getWriter(outputStream);
         for (MultipleSheelPropety multipleSheelPropety : multipleSheelPropetys) {
            Sheet sheet = multipleSheelPropety.getSheet() != null ? multipleSheelPropety.getSheet() : initSheet;
            if(!CollectionUtils.isEmpty(multipleSheelPropety.getData())){
               sheet.setClazz(multipleSheelPropety.getData().get(0).getClass());
            }
            writer.write(multipleSheelPropety.getData(), sheet);
         }

      } catch (FileNotFoundException e) {
         log.error(&quot;找不到文件或文件路径错误, 文件：{}&quot;, filePath);
      }finally {
         try {
            if(writer != null){
               writer.finish();
            }

            if(outputStream != null){
               outputStream.close();
            }
         } catch (IOException e) {
            log.error(&quot;excel文件导出失败, 失败原因：{}&quot;, e);
         }
      }

   }


   /*********************匿名内部类开始，可以提取出去******************************/

   @Data
   public static class MultipleSheelPropety{

      private List&lt;? extends BaseRowModel&gt; data;

      private Sheet sheet;
   }

   /**
    * 解析监听器，
    * 每解析一行会回调invoke()方法。
    * 整个excel解析结束会执行doAfterAllAnalysed()方法
    */
   @Getter
   @Setter
   public static class ExcelListener extends AnalysisEventListener {

      private List&lt;Object&gt; datas = new ArrayList&lt;&gt;();

      /**
       * 逐行解析
       * object : 当前行的数据
       */
      @Override
      public void invoke(Object object, AnalysisContext context) {
         //当前行
         // context.getCurrentRowNum()
         if (object != null) {
            datas.add(object);
         }
      }


      /**
       * 解析完所有数据后会调用该方法
       */
      @Override
      public void doAfterAllAnalysed(AnalysisContext context) {
         //解析结束销毁不用的资源
      }

   }

   /************************匿名内部类结束，可以提取出去***************************/

}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ES6新语法]]></title>
        <id>https://tinaxiawuhao.github.io/post/MKTk7DnaM/</id>
        <link href="https://tinaxiawuhao.github.io/post/MKTk7DnaM/">
        </link>
        <updated>2022-03-01T02:22:06.000Z</updated>
        <content type="html"><![CDATA[<h3 id="const-与-let-变量">const 与 let 变量</h3>
<p>使用var带来的麻烦:</p>
<pre><code class="language-js">function getClothing(isCold) {
  if (isCold) {
    var freezing = 'Grab a jacket!';
  } else {
    var hot = 'It's a shorts kind of day.';
    console.log(freezing);
  }
}
</code></pre>
<p>运行getClothing(false)后输出的是undefined,这是因为执行function函数之前,所有变量都会被提升, 提升到函数作用域顶部.</p>
<p>let与const声明的变量解决了这种问题,因为他们是块级作用域, 在代码块(用{}表示)中使用let或const声明变量, 该变量会陷入暂时性死区直到该变量的声明被处理.</p>
<pre><code class="language-js">function getClothing(isCold) {
  if (isCold) {
    const freezing = 'Grab a jacket!';
  } else {
    const hot = 'It's a shorts kind of day.';
    console.log(freezing);
  }
}
</code></pre>
<p>运行getClothing(false)后输出的是ReferenceError: freezing is not defined,因为 freezing 没有在 else 语句、函数作用域或全局作用域内声明，所以抛出 ReferenceError。</p>
<p><strong>关于使用let与const规则:</strong></p>
<p>使用let声明的变量可以重新赋值,但是不能在同一作用域内重新声明<br>
使用const声明的变量必须赋值初始化,但是不能在同一作用域类重新声明也无法重新赋值.</p>
<h3 id="模板字面量">模板字面量</h3>
<p>在ES6之前,将字符串连接到一起的方法是+或者concat()方法,如</p>
<pre><code class="language-js">const student = {
  name: 'Richard Kalehoff',
  guardian: 'Mr. Kalehoff'
};
const teacher = {
  name: 'Mrs. Wilson',
  room: 'N231'
}
let message = student.name + ' please see ' + teacher.name + ' in ' + teacher.room + ' to pick up your report card.';
</code></pre>
<p>模板字面量本质上是包含嵌入式表达式的字符串字面量.<br>
模板字面量用倒引号 ( `` )（而不是单引号 ( '' ) 或双引号( &quot;&quot; )）表示，可以包含用 ${expression} 表示的占位符</p>
<pre><code class="language-js">let message = `${student.name} please see ${teacher.name} in ${teacher.room} to pick up your report card.`;
</code></pre>
<h3 id="解构">解构</h3>
<p>在ES6中,可以使用解构从数组和对象提取值并赋值给独特的变量</p>
<p>解构数组的值:</p>
<pre><code class="language-js">const point = [10, 25, -34];
const [x, y, z] = point;
console.log(x, y, z);
Prints: 10 25 -34
</code></pre>
<p>[]表示被解构的数组, x,y,z表示要将数组中的值存储在其中的变量, 在解构数组是, 还可以忽略值, 例如const[x,,z]=point,忽略y坐标.</p>
<p>解构对象中的值:</p>
<pre><code class="language-js">const gemstone = {
  type: 'quartz',
  color: 'rose',
  karat: 21.29
};
const {type, color, karat} = gemstone;
console.log(type, color, karat);
</code></pre>
<p>花括号 { } 表示被解构的对象，type、color 和 karat 表示要将对象中的属性存储到其中的变量</p>
<p>对象字面量简写法</p>
<pre><code class="language-js">let type = 'quartz';
let color = 'rose';
let carat = 21.29;
const gemstone = {
  type: type,
  color: color,
  carat: carat
};
console.log(gemstone);
</code></pre>
<p>使用和所分配的变量名称相同的名称初始化对象时如果属性名称和所分配的变量名称一样，那么就可以从对象属性中删掉这些重复的变量名称。</p>
<pre><code class="language-js">let type = 'quartz';
let color = 'rose';
let carat = 21.29;
const gemstone = {type,color,carat};
console.log(gemstone);
</code></pre>
<p>简写方法的名称:</p>
<pre><code class="language-js">const gemstone = {
  type,
  color,
  carat,
  calculateWorth: function() {
    // 将根据类型(type)，颜色(color)和克拉(carat)计算宝石(gemstone)的价值
  }
};
</code></pre>
<p>匿名函数被分配给属性 calculateWorth，但是真的需要 function 关键字吗？在 ES6 中不需要！</p>
<pre><code class="language-js">let gemstone = {
  type,
  color,
  carat,
  calculateWorth() { ... }
};
</code></pre>
<h3 id="forof循环">for...of循环</h3>
<p>for...of循环是最新添加到 JavaScript 循环系列中的循环。<br>
它结合了其兄弟循环形式 for 循环和 for...in 循环的优势，可以循环任何可迭代（也就是遵守可迭代协议）类型的数据。默认情况下，包含以下数据类型：String、Array、Map 和 Set，注意不包含 Object 数据类型（即 {}）。默认情况下，对象不可迭代。</p>
<h4 id="for循环">for循环</h4>
<pre><code class="language-js">const digits = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9];
for (let i = 0; i &lt; digits.length; i++) {
  console.log(digits[i]);
}
</code></pre>
<p>for 循环的最大缺点是需要跟踪计数器和退出条件。<br>
虽然 for 循环在循环数组时的确具有优势，但是某些数据结构不是数组，因此并非始终适合使用 loop 循环。</p>
<h4 id="forin循环">for...in循环</h4>
<pre><code class="language-js">const digits = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9];
for (const index in digits) {
  console.log(digits[index]);
}
</code></pre>
<p>依然需要使用 index 来访问数组的值<br>
当你需要向数组中添加额外的方法（或另一个对象）时，for...in 循环会带来很大的麻烦。因为 for...in 循环循环访问所有可枚举的属性，意味着如果向数组的原型中添加任何其他属性，这些属性也会出现在循环中。</p>
<pre><code class="language-js">Array.prototype.decimalfy = function() {
  for (let i = 0; i &lt; this.length; i++) {
    this[i] = this[i].toFixed(2);
  }
};
const digits = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9];
for (const index in digits) {
  console.log(digits[index]);
}
</code></pre>
<h4 id="foreach-循环">forEach 循环</h4>
<p>forEach 循环是另一种形式的 JavaScript 循环。但是，forEach() 实际上是数组方法，因此只能用在数组中。也无法停止或退出 forEach 循环。如果希望你的循环中出现这种行为，则需要使用基本的 for 循环。</p>
<h4 id="forof循环-2">for...of循环</h4>
<p>for...of 循环用于循环访问任何可迭代的数据类型。<br>
for...of 循环的编写方式和 for...in 循环的基本一样，只是将 in 替换为 of，可以忽略索引。</p>
<pre><code class="language-js">const digits = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9];
for (const digit of digits) {
  console.log(digit);
}
</code></pre>
<p>建议使用复数对象名称来表示多个值的集合。这样，循环该集合时，可以使用名称的单数版本来表示集合中的单个值。例如，for (const button of buttons) {…}。</p>
<p>for...of 循环还具有其他优势，解决了 for 和 for...in 循环的不足之处。你可以随时停止或退出 for...of 循环。</p>
<pre><code class="language-js">for (const digit of digits) {
  if (digit % 2 === 0) {
    continue;
  }
  console.log(digit);
}
</code></pre>
<p>不用担心向对象中添加新的属性。for...of 循环将只循环访问对象中的值。</p>
<pre><code class="language-js">Array.prototype.decimalfy = function() {
  for (i = 0; i &lt; this.length; i++) {
    this[i] = this[i].toFixed(2);
  }
};
const digits = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9];
for (const digit of digits) {
  console.log(digit);
}

</code></pre>
<h3 id="展开运算符">展开运算符</h3>
<p>展开运算符（用三个连续的点 (...) 表示）是 ES6 中的新概念，使你能够将字面量对象展开为多个元素</p>
<pre><code class="language-js">const books = [&quot;Don Quixote&quot;, &quot;The Hobbit&quot;, &quot;Alice in Wonderland&quot;, &quot;Tale of Two Cities&quot;];
console.log(...books);
Prints: Don Quixote The Hobbit Alice in Wonderland Tale of Two Cities
</code></pre>
<p>展开运算符的一个用途是结合数组。</p>
<p>如果你需要结合多个数组，在有展开运算符之前，必须使用 Array的 concat() 方法。</p>
<pre><code class="language-js">const fruits = [&quot;apples&quot;, &quot;bananas&quot;, &quot;pears&quot;];
const vegetables = [&quot;corn&quot;, &quot;potatoes&quot;, &quot;carrots&quot;];
const produce = fruits.concat(vegetables);
console.log(produce);
Prints: [&quot;apples&quot;, &quot;bananas&quot;, &quot;pears&quot;, &quot;corn&quot;, &quot;potatoes&quot;, &quot;carrots&quot;]
</code></pre>
<p>使用展开符来结合数组</p>
<pre><code class="language-js">const fruits = [&quot;apples&quot;, &quot;bananas&quot;, &quot;pears&quot;];
const vegetables = [&quot;corn&quot;, &quot;potatoes&quot;, &quot;carrots&quot;];
const produce = [...fruits,...vegetables];
console.log(produce);
</code></pre>
<p><strong>剩余参数(可变参数)</strong><br>
使用展开运算符将数组展开为多个元素, 使用剩余参数可以将多个元素绑定到一个数组中.<br>
剩余参数也用三个连续的点 ( ... ) 表示，使你能够将不定数量的元素表示为数组.</p>
<p><strong>用途1: 将变量赋数组值时:</strong></p>
<pre><code class="language-js">const order = [20.17, 18.67, 1.50, &quot;cheese&quot;, &quot;eggs&quot;, &quot;milk&quot;, &quot;bread&quot;];
const [total, subtotal, tax, ...items] = order;
console.log(total, subtotal, tax, items);
</code></pre>
<p><strong>用途2: 可变参数函数</strong><br>
对于参数不固定的函数,ES6之前是使用参数对象(arguments)处理:</p>
<pre><code class="language-js">function sum() {
  let total = 0;  
  for(const argument of arguments) {
    total += argument;
  }
  return total;
}
</code></pre>
<p>在ES6中使用剩余参数运算符则更为简洁,可读性提高:</p>
<pre><code class="language-js">function sum(...nums) {
  let total = 0;  
  for(const num of nums) {
    total += num;
  }
  return total;
}
</code></pre>
<h3 id="es6箭头函数">ES6箭头函数</h3>
<p>ES6之前,使用普通函数把其中每个名字转换为大写形式：</p>
<pre><code class="language-js">const upperizedNames = ['Farrin', 'Kagure', 'Asser'].map(function(name) { 
  return name.toUpperCase();
});
</code></pre>
<p>箭头函数表示:</p>
<pre><code class="language-js">const upperizedNames = ['Farrin', 'Kagure', 'Asser'].map(
  name =&gt; name.toUpperCase()
);
</code></pre>
<p>普通函数可以是函数声明或者函数表达式, 但是箭头函数始终都是表达式, 全程是箭头函数表达式, 因此因此仅在表达式有效时才能使用，包括：</p>
<p>存储在变量中，<br>
当做参数传递给函数，<br>
存储在对象的属性中。</p>
<pre><code class="language-js">const greet = name =&gt; `Hello ${name}!`;
</code></pre>
<p>可以如下调用:</p>
<pre><code class="language-js">greet('Asser');
</code></pre>
<p>如果函数的参数只有一个,不需要使用()包起来,但是只有一个或者多个, 则必须需要将参数列表放在圆括号内:</p>
<pre><code class="language-js">// 空参数列表需要括号
const sayHi = () =&gt; console.log('Hello Udacity Student!');
// 多个参数需要括号
const orderIceCream = (flavor, cone) =&gt; console.log(`Here's your ${flavor} ice cream in a ${cone} cone.`);
orderIceCream('chocolate', 'waffle');
</code></pre>
<p>一般箭头函数都只有一个表达式作为函数主题:</p>
<pre><code class="language-js">const upperizedNames = ['Farrin', 'Kagure', 'Asser'].map(
  name =&gt; name.toUpperCase()
);
</code></pre>
<p>这种函数表达式形式称为简写主体语法:</p>
<p>1,在函数主体周围没有花括号,<br>
2,自动返回表达式<br>
3,但是如果箭头函数的主体内需要多行代码, 则需要使用常规主体语法:</p>
<p>它将函数主体放在花括号内<br>
需要使用 return 语句来返回内容。</p>
<pre><code class="language-js">const upperizedNames = ['Farrin', 'Kagure', 'Asser'].map( name =&gt; {
  name = name.toUpperCase();
  return `${name} has ${name.length} characters in their name`;
});

</code></pre>
<h3 id="javascript标准函数this">javascript标准函数this</h3>
<p><strong>new 对象</strong></p>
<pre><code class="language-js">const mySundae = new Sundae('Chocolate', ['Sprinkles', 'Hot Fudge']);
</code></pre>
<p>sundae这个构造函数内的this的值是实例对象, 因为他使用new被调用.</p>
<p><strong>指定的对象</strong></p>
<pre><code class="language-js">const result = obj1.printName.call(obj2);
</code></pre>
<p>函数使用call/apply被调用,this的值指向指定的obj2,因为call()第一个参数明确设置this的指向</p>
<p><strong>上下文对象</strong></p>
<pre><code class="language-js">data.teleport();
</code></pre>
<p>函数是对象的方法, this指向就是那个对象,此处this就是指向data.</p>
<p><strong>全局对象或 undefined</strong></p>
<pre><code class="language-js">teleport();
</code></pre>
<p>此处是this指向全局对象,在严格模式下,指向undefined.</p>
<p>javascript中this是很复杂的概念, 要详细判断this,请参考this豁然开朗</p>
<h4 id="箭头函数和this">箭头函数和this</h4>
<p>对于普通函数, this的值基于函数如何被调用, 对于箭头函数,this的值基于函数周围的上下文, 换句话说,this的值和函数外面的this的值是一样的.</p>
<pre><code class="language-js">function IceCream() {
    this.scoops = 0;
}
// 为 IceCream 添加 addScoop 方法
IceCream.prototype.addScoop = function() {
    setTimeout(function() {
        this.scoops++;
        console.log('scoop added!');
        console.log(this.scoops); // undefined+1=NaN
        console.log(dessert.scoops); //0
    }, 500);
};
</code></pre>
<pre><code class="language-js">const dessert = new IceCream();
dessert.addScoop();
</code></pre>
<p>传递给 setTimeout() 的函数被调用时没用到 new、call() 或 apply()，也没用到上下文对象。意味着函数内的 this 的值是全局对象，不是 dessert 对象。实际上发生的情况是，创建了新的 scoops 变量（默认值为 undefined），然后递增（undefined + 1 结果为 NaN）;</p>
<p>解决此问题的方式之一是使用闭包(closure):</p>
<pre><code class="language-js">// 构造函数
function IceCream() {
  this.scoops = 0;
}
// 为 IceCream 添加 addScoop 方法
IceCream.prototype.addScoop = function() {
  const cone = this; // 设置 `this` 给 `cone`变量
  setTimeout(function() {
    cone.scoops++; // 引用`cone`变量
    console.log('scoop added!'); 
    console.log(dessert.scoops);//1
  }, 0.5);
};
const dessert = new IceCream();
dessert.addScoop();
</code></pre>
<p>箭头函数的作用正是如此, 将setTimeOut()的函数改为剪头函数:</p>
<pre><code class="language-js">// 构造函数
function IceCream() {
  this.scoops = 0;
}
// 为 IceCream 添加 addScoop 方法
IceCream.prototype.addScoop = function() {
  setTimeout(() =&gt; { // 一个箭头函数被传递给setTimeout
    this.scoops++;
    console.log('scoop added!');
    console.log(dessert.scoops);//1
  }, 0.5);
};
const dessert = new IceCream();
dessert.addScoop();
</code></pre>
<p><strong>默认参数函数</strong></p>
<pre><code class="language-js">function greet(name, greeting) {
  name = (typeof name !== 'undefined') ?  name : 'Student';
  greeting = (typeof greeting !== 'undefined') ?  greeting : 'Welcome';
  return `${greeting} ${name}!`;
}
greet(); // Welcome Student!
greet('James'); // Welcome James!
greet('Richard', 'Howdy'); // Howdy Richard!

</code></pre>
<p>greet() 函数中混乱的前两行的作用是什么？它们的作用是当所需的参数未提供时，为函数提供默认的值。但是看起来很麻烦, ES6引入一种新的方式创建默认值, 他叫默认函数参数:</p>
<pre><code class="language-js">function greet(name = 'Student', greeting = 'Welcome') {
  return `${greeting} ${name}!`;
}
greet(); // Welcome Student!
greet('James'); // Welcome James!
greet('Richard', 'Howdy'); // Howdy Richard!

</code></pre>
<h3 id="默认值与解构">默认值与解构</h3>
<p><strong>默认值与解构数组</strong></p>
<pre><code class="language-js">function createGrid([width = 5, height = 5]) {
  return `Generates a ${width} x ${height} grid`;
}
createGrid([]); // Generates a 5 x 5 grid
createGrid([2]); // Generates a 2 x 5 grid
createGrid([2, 3]); // Generates a 2 x 3 grid
createGrid([undefined, 3]); // Generates a 5 x 3 grid
</code></pre>
<p>createGrid() 函数预期传入的是数组。它通过解构将数组中的第一项设为 width，第二项设为 height。如果数组为空，或者只有一项，那么就会使用默认参数，并将缺失的参数设为默认值 5。</p>
<p>但是存在一个问题:</p>
<pre><code class="language-js">createGrid(); // throws an error
Uncaught TypeError: Cannot read property 'Symbol(Symbol.iterator)' of undefined
</code></pre>
<p>出现错误，因为 createGrid() 预期传入的是数组，然后对其进行解构。因为函数被调用时没有传入数组，所以出现问题。但是，我们可以使用默认的函数参数！</p>
<pre><code class="language-js">function createGrid([width = 5, height = 5] = []) {
  return `Generating a grid of ${width} by ${height}`;
}
createGrid(); // Generates a 5 x 5 grid
Returns: Generates a 5 x 5 grid
</code></pre>
<p><strong>默认值与解构函数</strong><br>
就像使用数组默认值解构数组一样，函数可以让对象成为一个默认参数，并使用对象解构：</p>
<pre><code class="language-js">function createSundae({scoops = 1, toppings = ['Hot Fudge']}={}) {
  const scoopText = scoops === 1 ? 'scoop' : 'scoops';
  return `Your sundae has ${scoops} ${scoopText} with ${toppings.join(' and ')} toppings.`;
}
createSundae({}); // Your sundae has 1 scoop with Hot Fudge toppings.
createSundae({scoops: 2}); // Your sundae has 2 scoops with Hot Fudge toppings.
createSundae({scoops: 2, toppings: ['Sprinkles']}); // Your sundae has 2 scoops with Sprinkles toppings.
createSundae({toppings: ['Cookie Dough']}); // Your sundae has 1 scoop with Cookie Dough toppings.
createSundae(); // Your sundae has 1 scoop with Hot Fudge toppings.
</code></pre>
<p><strong>数组默认值与对象默认值</strong><br>
默认函数参数只是个简单的添加内容，但是却带来很多便利！与数组默认值相比，对象默认值具备的一个优势是能够处理跳过的选项。看看下面的代码：</p>
<pre><code class="language-js">function createSundae({scoops = 1, toppings = ['Hot Fudge']} = {}) { … }
</code></pre>
<p>在 createSundae() 函数使用对象默认值进行解构时，如果你想使用 scoops 的默认值，但是更改 toppings，那么只需使用 toppings 传入一个对象：</p>
<pre><code class="language-js">createSundae({toppings: ['Hot Fudge', 'Sprinkles', 'Caramel']});
</code></pre>
<p>将上述示例与使用数组默认值进行解构的同一函数相对比。</p>
<pre><code class="language-js">function createSundae([scoops = 1, toppings = ['Hot Fudge']] = []) { … }
</code></pre>
<p>对于这个函数，如果想使用 scoops 的默认数量，但是更改 toppings，则必须以这种奇怪的方式调用你的函数：</p>
<pre><code class="language-js">createSundae([undefined, ['Hot Fudge', 'Sprinkles', 'Caramel']]);
</code></pre>
<p>因为数组是基于位置的，我们需要传入 undefined 以跳过第一个参数（并使用默认值）来到达第二个参数。</p>
<h3 id="javascript类">Javascript类</h3>
<p><strong>ES5创建类:</strong></p>
<pre><code class="language-js">function Plane(numEngines) {
  this.numEngines = numEngines;
  this.enginesActive = false;
}
// 由所有实例 &quot;继承&quot; 的方法
Plane.prototype.startEngines = function () {
  console.log('starting engines...');
  this.enginesActive = true;
};
</code></pre>
<p><strong>ES6创建类</strong><br>
ES6类只是一个语法糖,原型继续实际上在底层隐藏起来, 与传统类机制语言有些区别.</p>
<pre><code class="language-js">class Plane {
  //constructor方法虽然在类中,但不是原型上的方法,只是用来生成实例的.
  constructor(numEngines) {
    this.numEngines = numEngines;
    this.enginesActive = false;
  }
  //原型上的方法, 由所有实例对象共享.
  startEngines() {
    console.log('starting engines…');
    this.enginesActive = true;
  }
}
console.log(typeof Plane); //function

</code></pre>
<p>javascript中类其实只是function, 方法之间不能使用,,不用逗号区分属性和方法.</p>
<h3 id="静态方法">静态方法</h3>
<p>要添加静态方法，请在方法名称前面加上关键字 static</p>
<pre><code class="language-js">class Plane {
  constructor(numEngines) {
    this.numEngines = numEngines;
    this.enginesActive = false;
  }
  static badWeather(planes) {
    for (plane of planes) {
      plane.enginesActive = false;
    }
  }
  startEngines() {
    console.log('starting engines…');
    this.enginesActive = true;
  }
}
</code></pre>
<p>关键字class带来其他基于类的语言的很多思想,但是没有向javascript中添加此功能<br>
javascript类实际上还是原型继承<br>
创建javascript类的新实例时必须使用new关键字</p>
<h3 id="super-和-extends">super 和 extends</h3>
<p>使用新的super和extends关键字扩展类:</p>
<pre><code class="language-js">class Tree {
  constructor(size = '10', leaves = {spring: 'green', summer: 'green', fall: 'orange', winter: null}) {
    this.size = size;
    this.leaves = leaves;
    this.leafColor = null;
  }
  changeSeason(season) {
    this.leafColor = this.leaves[season];
    if (season === 'spring') {
      this.size += 1;
    }
  }
}
class Maple extends Tree {
  constructor(syrupQty = 15, size, leaves) {
    super(size, leaves); //super用作函数
    this.syrupQty = syrupQty;
  }
  changeSeason(season) {
    super.changeSeason(season);//super用作对象
    if (season === 'spring') {
      this.syrupQty += 1;
    }
  }
  gatherSyrup() {
    this.syrupQty -= 3;
  }
}
</code></pre>
<p>使用ES5编写同样功能的类:</p>
<pre><code class="language-js">function Tree(size, leaves) {
  this.size = size || 10;
  this.leaves = leaves || {spring: 'green', summer: 'green', fall: 'orange', winter: null};
  this.leafColor;
}
Tree.prototype.changeSeason = function(season) {
  this.leafColor = this.leaves[season];
  if (season === 'spring') {
    this.size += 1;
  }
}
function Maple (syrupQty, size, leaves) {
  Tree.call(this, size, leaves);
  this.syrupQty = syrupQty || 15;
}
Maple.prototype = Object.create(Tree.prototype);
Maple.prototype.constructor = Maple;
Maple.prototype.changeSeason = function(season) {
  Tree.prototype.changeSeason.call(this, season);
  if (season === 'spring') {
    this.syrupQty += 1;
  }
}
Maple.prototype.gatherSyrup = function() {
  this.syrupQty -= 3;
}
</code></pre>
<p>super 必须在 this 之前被调用</p>
<p>在子类构造函数中，在使用 this 之前，必须先调用超级类。</p>
<pre><code class="language-js">class Apple {}
class GrannySmith extends Apple {
  constructor(tartnessLevel, energy) {
    this.tartnessLevel = tartnessLevel; // 在 'super' 之前会抛出一个错误！
    super(energy); 
  }
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[springBoot参数和业务校验]]></title>
        <id>https://tinaxiawuhao.github.io/post/d4XUQj9K0/</id>
        <link href="https://tinaxiawuhao.github.io/post/d4XUQj9K0/">
        </link>
        <updated>2022-02-25T03:05:50.000Z</updated>
        <content type="html"><![CDATA[<h2 id="为什么需要参数校验">为什么需要参数校验</h2>
<p>在日常的接口开发中，为了防止非法参数对业务造成影响，经常需要对接口的参数做校验，例如登录的时候需要校验用户名密码是否为空，创建用户的时候需要校验邮件、手机号码格式是否准确。靠代码对接口参数一个个校验的话就太繁琐了，代码可读性极差。</p>
<p>Validator框架就是为了解决开发人员在开发的时候少写代码，提升开发效率</p>
<blockquote>
<p>Validator校验框架遵循了JSR-303验证规范（参数校验规范）, JSR是<code>Java Specification Requests</code>的缩写。</p>
</blockquote>
<p>接下来我们看看在SpringbBoot中如何集成参数校验框架。</p>
<h2 id="springboot中集成参数校验">SpringBoot中集成参数校验</h2>
<h3 id="第一步引入依赖">第一步，引入依赖</h3>
<pre><code>&lt;dependency&gt;
  &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
  &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
&lt;/dependency&gt;

&lt;dependency&gt;
  &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
  &lt;artifactId&gt;spring-boot-starter-validation&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<blockquote>
<p>注：从<code>springboot-2.3</code>开始，校验包被独立成了一个<code>starter</code>组件，所以需要引入validation和web，而<code>springboot-2.3</code>之前的版本只需要引入 web 依赖就可以了。</p>
</blockquote>
<h3 id="第二步定义要参数校验的实体类">第二步，定义要参数校验的实体类</h3>
<pre><code>@Data
public class ValidVO {
    private String id;

    @Length(min = 6,max = 12,message = &quot;appId长度必须位于6到12之间&quot;)
    private String appId;

    @NotBlank(message = &quot;名字为必填项&quot;)
    private String name;

    @Email(message = &quot;请填写正确的邮箱地址&quot;)
    private String email;

    private String sex;

    @NotEmpty(message = &quot;级别不能为空&quot;)
    private String level;
}
</code></pre>
<p>在实际开发中对于需要校验的字段都需要设置对应的业务提示，即message属性。</p>
<p>常见的约束注解如下：</p>
<table>
<thead>
<tr>
<th style="text-align:left">注解</th>
<th style="text-align:left">功能</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">@AssertFalse</td>
<td style="text-align:left">可以为null,如果不为null的话必须为false</td>
</tr>
<tr>
<td style="text-align:left">@AssertTrue</td>
<td style="text-align:left">可以为null,如果不为null的话必须为true</td>
</tr>
<tr>
<td style="text-align:left">@DecimalMax</td>
<td style="text-align:left">设置不能超过最大值</td>
</tr>
<tr>
<td style="text-align:left">@DecimalMin</td>
<td style="text-align:left">设置不能超过最小值</td>
</tr>
<tr>
<td style="text-align:left">@Digits</td>
<td style="text-align:left">设置必须是数字且数字整数的位数和小数的位数必须在指定范围内</td>
</tr>
<tr>
<td style="text-align:left">@Future</td>
<td style="text-align:left">日期必须在当前日期的未来</td>
</tr>
<tr>
<td style="text-align:left">@Past</td>
<td style="text-align:left">日期必须在当前日期的过去</td>
</tr>
<tr>
<td style="text-align:left">@Max</td>
<td style="text-align:left">最大不得超过此最大值</td>
</tr>
<tr>
<td style="text-align:left">@Min</td>
<td style="text-align:left">最大不得小于此最小值</td>
</tr>
<tr>
<td style="text-align:left">@NotNull</td>
<td style="text-align:left">不能为null，可以是空</td>
</tr>
<tr>
<td style="text-align:left">@Null</td>
<td style="text-align:left">必须为null</td>
</tr>
<tr>
<td style="text-align:left">@Pattern</td>
<td style="text-align:left">必须满足指定的正则表达式</td>
</tr>
<tr>
<td style="text-align:left">@Size</td>
<td style="text-align:left">集合、数组、map等的size()值必须在指定范围内</td>
</tr>
<tr>
<td style="text-align:left">@Email</td>
<td style="text-align:left">必须是email格式</td>
</tr>
<tr>
<td style="text-align:left">@Length</td>
<td style="text-align:left">长度必须在指定范围内</td>
</tr>
<tr>
<td style="text-align:left">@NotBlank</td>
<td style="text-align:left">字符串不能为null,字符串trim()后也不能等于“”</td>
</tr>
<tr>
<td style="text-align:left">@NotEmpty</td>
<td style="text-align:left">不能为null，集合、数组、map等size()不能为0；字符串trim()后可以等于“”</td>
</tr>
<tr>
<td style="text-align:left">@Range</td>
<td style="text-align:left">值必须在指定范围内</td>
</tr>
<tr>
<td style="text-align:left">@URL</td>
<td style="text-align:left">必须是一个URL</td>
</tr>
</tbody>
</table>
<p>注：此表格只是简单的对注解功能的说明，并没有对每一个注解的属性进行说明；可详见源码。</p>
<h3 id="第三步定义校验类进行测试">第三步，定义校验类进行测试</h3>
<pre><code>@RestController
@Slf4j
@Validated
public class ValidController {

    @ApiOperation(&quot;RequestBody校验&quot;)
    @PostMapping(&quot;/valid/test1&quot;)   
    public String test1(@Validated @RequestBody ValidVO validVO){
        log.info(&quot;validEntity is {}&quot;, validVO);
        return &quot;test1 valid success&quot;;
    }

    @ApiOperation(&quot;Form校验&quot;)
    @PostMapping(value = &quot;/valid/test2&quot;)
    public String test2(@Validated ValidVO validVO){
        log.info(&quot;validEntity is {}&quot;, validVO);
        return &quot;test2 valid success&quot;;
    }
  
   @ApiOperation(&quot;单参数校验&quot;)
    @PostMapping(value = &quot;/valid/test3&quot;)
    public String test3(@Email String email){
        log.info(&quot;email is {}&quot;, email);
        return &quot;email valid success&quot;;
    }
}
</code></pre>
<p>这里我们先定义三个方法test1，test2，test3，test1使用了<code>@RequestBody</code>注解，用于接受前端发送的json数据，test2模拟表单提交，test3模拟单参数提交。<strong>注意，当使用单参数校验时需要在Controller上加上@Validated注解，否则不生效</strong>。</p>
<h3 id="第四步体验效果">第四步，体验效果</h3>
<ol>
<li>调用test1方法，提示的是<code>org.springframework.web.bind.MethodArgumentNotValidException</code>异常</li>
</ol>
<pre><code>POST http://localhost:8080/valid/test1
Content-Type: application/json

{
  &quot;id&quot;: 1,
  &quot;level&quot;: &quot;12&quot;,
  &quot;email&quot;: &quot;47693899&quot;,
  &quot;appId&quot;: &quot;ab1c&quot;
}
{
  &quot;status&quot;: 500,
  &quot;message&quot;: &quot;Validation failed for argument [0] in public java.lang.String com.jianzh5.blog.valid.ValidController.test1(com.jianzh5.blog.valid.ValidVO) with 3 errors: [Field error in object 'validVO' on field 'email': rejected value [47693899]; codes [Email.validVO.email,Email.email,Email.java.lang.String,Email]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [validVO.email,email]; arguments []; default message [email],[Ljavax.validation.constraints.Pattern$Flag;@26139123,.*]; default message [不是一个合法的电子邮件地址]]...&quot;,
  &quot;data&quot;: null,
  &quot;timestamp&quot;: 1628239624332
}
</code></pre>
<ol>
<li>调用test2方法，提示的是<code>org.springframework.validation.BindException</code>异常</li>
</ol>
<pre><code>POST http://localhost:8080/valid/test2
Content-Type: application/x-www-form-urlencoded

id=1&amp;level=12&amp;email=476938977&amp;appId=ab1c
{
  &quot;status&quot;: 500,
  &quot;message&quot;: &quot;org.springframework.validation.BeanPropertyBindingResult: 3 errors\nField error in object 'validVO' on field 'name': rejected value [null]; codes [NotBlank.validVO.name,NotBlank.name,NotBlank.java.lang.String,NotBlank]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [validVO.name,name]; arguments []; default message [name]]; default message [名字为必填项]...&quot;,
  &quot;data&quot;: null,
  &quot;timestamp&quot;: 1628239301951
}
</code></pre>
<ol>
<li>调用test3方法，提示的是<code>javax.validation.ConstraintViolationException</code>异常</li>
</ol>
<pre><code>POST http://localhost:8080/valid/test3
Content-Type: application/x-www-form-urlencoded

email=476938977
{
  &quot;status&quot;: 500,
  &quot;message&quot;: &quot;test3.email: 不是一个合法的电子邮件地址&quot;,
  &quot;data&quot;: null,
  &quot;timestamp&quot;: 1628239281022
}
</code></pre>
<p>通过加入<code>Validator</code>校验框架可以帮助我们自动实现参数的校验。</p>
<h2 id="参数异常加入全局异常处理器">参数异常加入全局异常处理器</h2>
<p><code>Validator</code>校验框架返回的错误提示太臃肿了，不便于阅读，为了方便前端提示，我们需要将其简化一下。</p>
<p>创建<code>RestExceptionHandler</code>，单独拦截参数校验的三个异常：<code>javax.validation.ConstraintViolationException</code>，<code>org.springframework.validation.BindException</code>，<code>org.springframework.web.bind.MethodArgumentNotValidException</code>，代码如下：</p>
<pre><code>@ExceptionHandler(value = {BindException.class, ValidationException.class, MethodArgumentNotValidException.class})
public ResponseEntity&lt;ResultData&lt;String&gt;&gt; handleValidatedException(Exception e) {
  ResultData&lt;String&gt; resp = null;

  if (e instanceof MethodArgumentNotValidException) {
    // BeanValidation exception
    MethodArgumentNotValidException ex = (MethodArgumentNotValidException) e;
    resp = ResultData.fail(HttpStatus.BAD_REQUEST.value(),
                           ex.getBindingResult().getAllErrors().stream()
                           .map(ObjectError::getDefaultMessage)
                           .collect(Collectors.joining(&quot;; &quot;))
                          );
  } else if (e instanceof ConstraintViolationException) {
    // BeanValidation GET simple param
    ConstraintViolationException ex = (ConstraintViolationException) e;
    resp = ResultData.fail(HttpStatus.BAD_REQUEST.value(),
                           ex.getConstraintViolations().stream()
                           .map(ConstraintViolation::getMessage)
                           .collect(Collectors.joining(&quot;; &quot;))
                          );
  } else if (e instanceof BindException) {
    // BeanValidation GET object param
    BindException ex = (BindException) e;
    resp = ResultData.fail(HttpStatus.BAD_REQUEST.value(),
                           ex.getAllErrors().stream()
                           .map(ObjectError::getDefaultMessage)
                           .collect(Collectors.joining(&quot;; &quot;))
                          );
  }

  return new ResponseEntity&lt;&gt;(resp,HttpStatus.BAD_REQUEST);
}
</code></pre>
<h3 id="体验效果">体验效果</h3>
<pre><code>POST http://localhost:8080/valid/test1
Content-Type: application/json

{
  &quot;id&quot;: 1,
  &quot;level&quot;: &quot;12&quot;,
  &quot;email&quot;: &quot;47693899&quot;,
  &quot;appId&quot;: &quot;ab1c&quot;
}
{
  &quot;status&quot;: 400,
  &quot;message&quot;: &quot;名字为必填项; 不是一个合法的电子邮件地址; appId长度必须位于6到12之间&quot;,
  &quot;data&quot;: null,
  &quot;timestamp&quot;: 1628435116680
}
</code></pre>
<p>是不是感觉清爽多了？</p>
<h2 id="自定义参数校验">自定义参数校验</h2>
<p>虽然Spring Validation 提供的注解基本上够用，但是面对复杂的定义，我们还是需要自己定义相关注解来实现自动校验。</p>
<p>比如上面实体类中的sex性别属性，只允许前端传递传 M，F 这2个枚举值，如何实现呢？</p>
<h3 id="第一步创建自定义注解">第一步，创建自定义注解</h3>
<pre><code>@Target({METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER, TYPE_USE})
@Retention(RUNTIME)
@Repeatable(EnumString.List.class)
@Documented
@Constraint(validatedBy = EnumStringValidator.class)//标明由哪个类执行校验逻辑
public @interface EnumString {
    String message() default &quot;value not in enum values.&quot;;

    Class&lt;?&gt;[] groups() default {};

    Class&lt;? extends Payload&gt;[] payload() default {};

    /**
     * @return date must in this value array
     */
    String[] value();

    /**
     * Defines several {@link EnumString} annotations on the same element.
     *
     * @see EnumString
     */
    @Target({METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER, TYPE_USE})
    @Retention(RUNTIME)
    @Documented
    @interface List {

        EnumString[] value();
    }
}
</code></pre>
<h3 id="第二步自定义校验逻辑">第二步，自定义校验逻辑</h3>
<pre><code>public class EnumStringValidator implements ConstraintValidator&lt;EnumString, String&gt; {
    private List&lt;String&gt; enumStringList;

    @Override
    public void initialize(EnumString constraintAnnotation) {
        enumStringList = Arrays.asList(constraintAnnotation.value());
    }

    @Override
    public boolean isValid(String value, ConstraintValidatorContext context) {
        if(value == null){
            return true;
        }
        return enumStringList.contains(value);
    }
}
</code></pre>
<h3 id="第三步在字段上增加注解">第三步，在字段上增加注解</h3>
<pre><code>@ApiModelProperty(value = &quot;性别&quot;)
@EnumString(value = {&quot;F&quot;,&quot;M&quot;}, message=&quot;性别只允许为F或M&quot;)
private String sex;
</code></pre>
<h3 id="第四步体验效果-2">第四步，体验效果</h3>
<pre><code>POST http://localhost:8080/valid/test2
Content-Type: application/x-www-form-urlencoded

id=1&amp;name=javadaily&amp;level=12&amp;email=476938977@qq.com&amp;appId=ab1cdddd&amp;sex=N
{
  &quot;status&quot;: 400,
  &quot;message&quot;: &quot;性别只允许为F或M&quot;,
  &quot;data&quot;: null,
  &quot;timestamp&quot;: 1628435243723
}
</code></pre>
<h2 id="分组校验">分组校验</h2>
<p>一个VO对象在新增的时候某些字段为必填，在更新的时候又非必填。如上面的<code>ValidVO</code>中 id 和 appId 属性在新增操作时都是<strong>非必填</strong>，而在编辑操作时都为<strong>必填</strong>，name在新增操作时为<strong>必填</strong>，面对这种场景你会怎么处理呢？</p>
<p>在实际开发中我见到很多同学都是建立两个VO对象，<code>ValidCreateVO</code>，<code>ValidEditVO</code>来处理这种场景，这样确实也能实现效果，但是会造成类膨胀，而且极其容易被开发老鸟们嘲笑。</p>
<p>其实<code>Validator</code>校验框架已经考虑到了这种场景并且提供了解决方案，就是<strong>分组校验</strong>，只不过很多同学不知道而已。要使用分组校验，只需要三个步骤：</p>
<h3 id="第一步定义分组接口">第一步：定义分组接口</h3>
<pre><code>public interface ValidGroup extends Default {
  
    interface Crud extends ValidGroup{
        interface Create extends Crud{

        }

        interface Update extends Crud{

        }

        interface Query extends Crud{

        }

        interface Delete extends Crud{

        }
    }
}
</code></pre>
<p>这里我们定义一个分组接口ValidGroup让其继承<code>javax.validation.groups.Default</code>，再在分组接口中定义出多个不同的操作类型，Create，Update，Query，Delete。至于为什么需要继承Default我们稍后再说。</p>
<h3 id="第二步在模型中给参数分配分组">第二步，在模型中给参数分配分组</h3>
<pre><code>@Data
@ApiModel(value = &quot;参数校验类&quot;)
public class ValidVO {
    @ApiModelProperty(&quot;ID&quot;)
    @Null(groups = ValidGroup.Crud.Create.class)
    @NotNull(groups = ValidGroup.Crud.Update.class, message = &quot;应用ID不能为空&quot;)
    private String id;

    @Null(groups = ValidGroup.Crud.Create.class)
    @NotNull(groups = ValidGroup.Crud.Update.class, message = &quot;应用ID不能为空&quot;)
    @ApiModelProperty(value = &quot;应用ID&quot;,example = &quot;cloud&quot;)
    private String appId;

    @ApiModelProperty(value = &quot;名字&quot;)
    @NotBlank(groups = ValidGroup.Crud.Create.class,message = &quot;名字为必填项&quot;)
    private String name;
  
   @ApiModelProperty(value = &quot;邮箱&quot;)
    @Email(message = &quot;请填写正取的邮箱地址&quot;)
    privte String email;

    ...

}
</code></pre>
<p>给参数指定分组，对于未指定分组的则使用的是默认分组。</p>
<h3 id="第三步给需要参数校验的方法指定分组">第三步，给需要参数校验的方法指定分组</h3>
<pre><code>@RestController
@Api(&quot;参数校验&quot;)
@Slf4j
@Validated
public class ValidController {

    @ApiOperation(&quot;新增&quot;)
    @PostMapping(value = &quot;/valid/add&quot;)
    public String add(@Validated(value = ValidGroup.Crud.Create.class) ValidVO validVO){
        log.info(&quot;validEntity is {}&quot;, validVO);
        return &quot;test3 valid success&quot;;
    }


    @ApiOperation(&quot;更新&quot;)
    @PostMapping(value = &quot;/valid/update&quot;)
    public String update(@Validated(value = ValidGroup.Crud.Update.class) ValidVO validVO){
        log.info(&quot;validEntity is {}&quot;, validVO);
        return &quot;test4 valid success&quot;;
    }
}
</code></pre>
<p>这里我们通过<code>value</code>属性给<code>add()</code>和<code>update()</code>方法分别指定Create和Update分组。</p>
<h3 id="第四步体验效果-3">第四步，体验效果</h3>
<pre><code>POST http://localhost:8080/valid/add
Content-Type: application/x-www-form-urlencoded

name=javadaily&amp;level=12&amp;email=476938977@qq.com&amp;sex=F
</code></pre>
<p>在Create时我们没有传递id和appId参数，校验通过。</p>
<p>当我们使用同样的参数调用update方法时则提示参数校验错误。</p>
<pre><code>{
  &quot;status&quot;: 400,
  &quot;message&quot;: &quot;ID不能为空; 应用ID不能为空&quot;,
  &quot;data&quot;: null,
  &quot;timestamp&quot;: 1628492514313
}
</code></pre>
<p>由于email属于默认分组，而我们的分组接口<code>ValidGroup</code>已经继承了<code>Default</code>分组，所以也是可以对email字段作参数校验的。如：</p>
<pre><code>POST http://localhost:8080/valid/add
Content-Type: application/x-www-form-urlencoded

name=javadaily&amp;level=12&amp;email=476938977&amp;sex=F
{
  &quot;status&quot;: 400,
  &quot;message&quot;: &quot;请填写正取的邮箱地址&quot;,
  &quot;data&quot;: null,
  &quot;timestamp&quot;: 1628492637305
}
</code></pre>
<p>当然如果你的ValidGroup没有继承Default分组，那在代码属性上就需要加上<code>@Validated(value = {ValidGroup.Crud.Create.class, Default.class}</code>才能让<code>email</code>字段的校验生效。</p>
<h2 id="业务规则校验">业务规则校验</h2>
<p>业务规则校验指接口需要满足某些特定的业务规则，举个例子：业务系统的用户需要保证其唯一性，用户属性不能与其他用户产生冲突，不允许与数据库中任何已有用户的用户名称、手机号码、邮箱产生重复。</p>
<p>这就要求在<strong>创建用户时需要校验用户名称、手机号码、邮箱是否被注册</strong>；<strong>编辑用户时不能将信息修改成已有用户的属性</strong>。</p>
<p>95%的程序员当面对这种业务规则校验时往往选择写在service逻辑中，常见的代码逻辑如下：</p>
<pre><code>public void create(User user) {
    Account account = accountDao.queryByUserNameOrPhoneOrEmail(user.getName(),user.getPhone(),user.getEmail());
    if (account != null) {
        throw new IllegalArgumentException(&quot;用户已存在，请重新输入&quot;);
    }
}
</code></pre>
<p><strong>最优雅的实现方法应该是参考 Bean Validation 的标准方式，借助自定义校验注解完成业务规则校验。</strong></p>
<p>接下来我们通过上面提到的用户接口案例，通过自定义注解完成业务规则校验。</p>
<h2 id="代码实战">代码实战</h2>
<p>需求很容易理解，注册新用户时，应约束不与任何已有用户的关键信息重复；而修改自己的信息时，只能与自己的信息重复，不允许修改成已有用户的信息。</p>
<p>这些约束规则不仅仅为这两个方法服务，它们可能会在用户资源中的其他入口被使用到，乃至在其他分层的代码中被使用到，在 Bean 上做校验就能全部覆盖上述这些使用场景。</p>
<h3 id="自定义注解">自定义注解</h3>
<p>首先我们需要创建两个自定义注解，用于业务规则校验：</p>
<ul>
<li><code>UniqueUser</code>:表示一个用户是唯一的，唯一性包含：用户名，手机号码、邮箱</li>
</ul>
<pre><code>@Documented
@Retention(RUNTIME)
@Target({FIELD, METHOD, PARAMETER, TYPE})
@Constraint(validatedBy = UserValidation.UniqueUserValidator.class)
public @interface UniqueUser {

    String message() default &quot;用户名、手机号码、邮箱不允许与现存用户重复&quot;;

    Class&lt;?&gt;[] groups() default {};

    Class&lt;? extends Payload&gt;[] payload() default {};
}
</code></pre>
<ul>
<li><code>NotConflictUser</code>:表示一个用户的信息是无冲突的，无冲突是指该用户的敏感信息与其他用户不重合</li>
</ul>
<pre><code>@Documented
@Retention(RUNTIME)
@Target({FIELD, METHOD, PARAMETER, TYPE})
@Constraint(validatedBy = UserValidation.NotConflictUserValidator.class)
public @interface NotConflictUser {
    String message() default &quot;用户名称、邮箱、手机号码与现存用户产生重复&quot;;

    Class&lt;?&gt;[] groups() default {};

    Class&lt;? extends Payload&gt;[] payload() default {};
}
</code></pre>
<h3 id="实现业务校验规则">实现业务校验规则</h3>
<p>想让自定义验证注解生效，需要实现 <code>ConstraintValidator</code> 接口。接口的第一个参数是 <strong>自定义注解类型</strong>，第二个参数是 <strong>被注解字段的类</strong>，因为需要校验多个参数，我们直接传入用户对象。需要提到的一点是 <code>ConstraintValidator</code> 接口的实现类无需添加 <code>@Component</code> 它在启动的时候就已经被加载到容器中了。</p>
<pre><code>@Slf4j
public class UserValidation&lt;T extends Annotation&gt; implements ConstraintValidator&lt;T, User&gt; {

    protected Predicate&lt;User&gt; predicate = c -&gt; true;

    @Resource
    protected UserRepository userRepository;

    @Override
    public boolean isValid(User user, ConstraintValidatorContext constraintValidatorContext) {
        return userRepository == null || predicate.test(user);
    }

    /**
     * 校验用户是否唯一
     * 即判断数据库是否存在当前新用户的信息，如用户名，手机，邮箱
     */
    public static class UniqueUserValidator extends UserValidation&lt;UniqueUser&gt;{
        @Override
        public void initialize(UniqueUser uniqueUser) {
            predicate = c -&gt; !userRepository.existsByUserNameOrEmailOrTelphone(c.getUserName(),c.getEmail(),c.getTelphone());
        }
    }

    /**
     * 校验是否与其他用户冲突
     * 将用户名、邮件、电话改成与现有完全不重复的，或者只与自己重复的，就不算冲突
     */
    public static class NotConflictUserValidator extends UserValidation&lt;NotConflictUser&gt;{
        @Override
        public void initialize(NotConflictUser notConflictUser) {
            predicate = c -&gt; {
                log.info(&quot;user detail is {}&quot;,c);
                Collection&lt;User&gt; collection = userRepository.findByUserNameOrEmailOrTelphone(c.getUserName(), c.getEmail(), c.getTelphone());
                // 将用户名、邮件、电话改成与现有完全不重复的，或者只与自己重复的，就不算冲突
                return collection.isEmpty() || (collection.size() == 1 &amp;&amp; collection.iterator().next().getId().equals(c.getId()));
            };
        }
    }

}
</code></pre>
<p>这里使用Predicate函数式接口对业务规则进行判断。</p>
<h3 id="使用">使用</h3>
<pre><code>@RestController
@RequestMapping(&quot;/senior/user&quot;)
@Slf4j
@Validated
public class UserController {
    @Autowired
    private UserRepository userRepository;
    

    @PostMapping
    public User createUser(@UniqueUser @Valid User user){
        User savedUser = userRepository.save(user);
        log.info(&quot;save user id is {}&quot;,savedUser.getId());
        return savedUser;
    }

    @SneakyThrows
    @PutMapping
    public User updateUser(@NotConflictUser @Valid @RequestBody User user){
        User editUser = userRepository.save(user);
        log.info(&quot;update user is {}&quot;,editUser);
        return editUser;
    }
}
</code></pre>
<p>使用很简单，只需要在方法上加入自定义注解即可，业务逻辑中不需要添加任何业务规则的代码。</p>
<h3 id="测试">测试</h3>
<p>调用接口后出现如下错误，说明业务规则校验生效。</p>
<pre><code>{
  &quot;status&quot;: 400,
  &quot;message&quot;: &quot;用户名、手机号码、邮箱不允许与现存用户重复&quot;,
  &quot;data&quot;: null,
  &quot;timestamp&quot;: 1644309081037
}
</code></pre>
<h3 id="小结">小结</h3>
<p>通过上面几步操作，业务校验便和业务逻辑就完全分离开来，在需要校验时用<code>@Validated</code>注解自动触发，或者通过代码手动触发执行，可根据你们项目的要求，将这些注解应用于控制器、服务层、持久层等任何层次的代码之中。</p>
<p>这种方式比任何业务规则校验的方法都优雅，推荐大家在项目中使用。在开发时可以将不带业务含义的格式校验注解放到 Bean 的类定义之上，将带业务逻辑的校验放到 Bean 的类定义的外面。<strong>这两者的区别是放在类定义中的注解能够自动运行，而放到类外面则需要像前面代码那样，明确标出注解时才会运行。</strong></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[WebFlux与WebMVC区别]]></title>
        <id>https://tinaxiawuhao.github.io/post/OoSJ8O7Jf/</id>
        <link href="https://tinaxiawuhao.github.io/post/OoSJ8O7Jf/">
        </link>
        <updated>2022-02-24T02:30:44.000Z</updated>
        <content type="html"><![CDATA[<p>在构建响应式 Web 服务上，Spring 5 中引入了全新的编程框架，那就是 Spring WebFlux。作为一款新型的 Web 服务开发框架，它与传统的 WebMVC 相比具体有哪些优势呢？</p>
<h2 id="spring-webflux-的应用场景">Spring WebFlux 的应用场景</h2>
<p>WebFlux 用于构建响应式 Web 服务。在详细介绍 WebFlux 之前，我们先梳理一下这个新框架的应用场景，了解应用场景才能帮助我们对所要采用的技术体系做出正确的选择。</p>
<p>微服务架构的兴起为 WebFlux 的应用提供了一个很好的场景。我们知道在一个微服务系统中，存在数十乃至数百个独立的微服务，它们相互通信以完成复杂的业务流程。这个过程势必会涉及大量的 I/O 操作，尤其是阻塞式 I/O 操作会整体增加系统的延迟并降低吞吐量。如果能够在复杂的流程中集成非阻塞、异步通信机制，我们就可以高效处理跨服务之间的网络请求。针对这种场景，WebFlux 是一种非常有效的解决方案。</p>
<h3 id="从-webmvc-到-webflux">从 WebMVC 到 WebFlux</h3>
<p>接下来，我们将讨论 WebMVC 与 WebFlux 之间的差别，而这些差别实际上正是体现在从 WebMVC 到 WebFlux 的演进过程中。让我们先从传统的 Spring WebMVC 技术栈开始说起。</p>
<h4 id="spring-webmvc技术栈">Spring WebMVC技术栈</h4>
<p>一般而言，Web 请求处理机制都会使用“管道-过滤器（Pipe-Filter）”架构模式，而 Spring WebMVC 作为一种处理 Web 请求的典型实现方案，同样使用了 Servlet 中的过滤器链（FilterChain）来对请求进行拦截，如下图所示。</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1645756459790.jpg" alt="" loading="lazy"></figure>
<p>我们知道 WebMVC 运行在 Servlet 容器上，这些容器常用的包括 Tomcat、JBoss 等。当 HTTP 请求通过 Servlet 容器时就会被转换为一个 ServletRequest 对象，而最终返回一个 ServletResponse 对象，FilterChain 的定义如下所示。</p>
<pre><code>public interface FilterChain {    
    public void doFilter (ServletRequest request, ServletResponse response ) throws IOException, ServletException; 
}
</code></pre>
<p>当 ServletRequest 通过过滤器链中所包含的一系列过滤器之后，最终就会到达作为前端控制器的 DispatcherServlet。DispatcherServlet 是 WebMVC 的核心组件，扩展了 Servlet 对象，并持有一组 HandlerMapping 和 HandlerAdapter。</p>
<p>当 ServletRequest 请求到达时，DispatcherServlet 负责搜索 HandlerMapping 实例并使用合适的 HandlerAdapter 对其进行适配。其中，HandlerMapping 的作用是根据当前请求找到对应的处理器 Handler，它只定义了一个方法，如下所示。</p>
<pre><code>public interface HandlerMapping {
 
    //找到与请求对应的 Handler，封装为一个 HandlerExecutionChain 返回
 HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception;
}
</code></pre>
<p>而 HandlerAdapter 根据给定的 HttpServletRequest 和 HttpServletResponse 对象真正调用给定的 Handler，核心方法如下所示。</p>
<pre><code>public interface HandlerAdapter { 
  //针对给定的请求/响应对象调用目标 Handler
  ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception;
}
</code></pre>
<p>在执行过程中，DispatcherServlet 会在应用上下文中搜索所有 HandlerMapping。日常开发过程中，最常用的 HandlerMapping 包含 BeanNameUrlHandlerMapping 和 RequestMappingHandlerMapping，前者负责检测所有 Controller 并根据请求 URL 的匹配规则映射到具体的 Controller 实例上，而后者基于 @RequestMapping 注解来找到目标 Controller。</p>
<p>如果我们使用了 RequestMappingHandlerMapping，那么对应的 HandlerAdapter 就是 RequestMappingHandlerAdapter，它负责将传入的 ServletRequest 绑定到添加了 @RequestMapping 注解的控制器方法上，从而实现对请求的正确响应。同时， HandlerAdapter 还提供请求验证和响应转换等辅助性功能，使得 Spring WebMVC 框架在日常 Web 开发中非常实用。</p>
<p>作为总结，我梳理了 Spring WebMVC 的整体架构，如下图所示。</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1645756470064.jpg" alt="" loading="lazy"></figure>
<p>一直以来，Spring WebMVC 是我们开发 Web 服务的主流框架。但要注意的是，尽管 Servlet 本身在新版本中提供了异步非阻塞的通信机制，但 Spring WebMVC 在实现上并不允许在整个请求生命周期中都采用非阻塞式的操作方式。因此，Spring 在尽量沿用原有的开发模式以及 API 设计上提供了支持异步非阻塞的 Spring WebFlux 框架。</p>
<h4 id="spring-webflux-技术栈">Spring WebFlux 技术栈</h4>
<p>介绍完 Spring WebMVC，我们来说说 Spring WebFlux。事实上，前面介绍的 HandlerMapping、HandlerAdapter 等组件在 WebFlux 里都有同名的响应式版本，这是 WebFlux 的一种设计理念，即在既有设计的基础上，提供新的实现版本，只对部分需要增强和弱化的地方做了调整。</p>
<p>我们先来看第一个需要调整的地方，显然，我们应该替换掉原有的 Servlet API 以便融入响应式流。因此，在 WebFlux 中，代表请求和响应的是全新的 ServerHttpRequest 和 ServerHttpResponse 对象。</p>
<p>同样，WebFlux 中同样提供了一个过滤器链 WebFilterChain，定义如下。</p>
<pre><code>public interface WebFilterChain {
    Mono&lt;Void&gt; filter(ServerWebExchange exchange);
}
</code></pre>
<p>这里的 ServerWebExchange 相当于一个上下文容器，保存了 ServerHttpRequest、ServerHttpResponse 以及一些框架运行时状态信息。</p>
<p>在 WebFlux 中，和 WebMVC 中的 DispatcherServlet 相对应的组件是 DispatcherHandler。与 DispatcherServlet 类似，DispatcherHandler 同样使用了一套响应式版本的 HandlerMapping 和 HandlerAdapter 完成对请求的处理。请注意，这两个接口是定义在 org.springframework.web.reactive 包中，而不是在原有的 org.springframework.web 包中。响应式版本的 HandlerMapping 接口定义如下，可以看到这里返回的是一个 Mono 对象，从而启用了响应式行为模式。</p>
<pre><code>public interface HandlerMapping {  
 Mono&lt;Object&gt; getHandler(ServerWebExchange exchange);
}
</code></pre>
<p>同样，我们找到响应式版本的 HandlerAdapter，如下所示。</p>
<pre><code>public interface HandlerAdapter {
    Mono&lt;HandlerResult&gt; handle(ServerWebExchange exchange, Object handler);
}
</code></pre>
<p>对比非响应式版本的 HandlerAdapter，这里的 ServerWebExchange 中同时包含了 ServerHttpRequest 和 ServerHttpResponse 对象，而 HandlerResult 则代表了处理结果。相比 WebMVC 中 ModelAndView 这种比较模糊的返回结果，HandlerResult 更加直接和明确。</p>
<p>在 WebFlux 中，同样实现了响应式版本的 RequestMappingHandlerMapping 和 RequestMappingHandlerAdapter，因此我们仍然可以采用注解的方法来构建 Controller。另一方面，WebFlux 中还提供了 RouterFunctionMapping 和 HandlerFunctionAdapter 组合，专门用来提供基于函数式编程的开发模式。这样 Spring WebFlux 的整体架构图就演变成这样。</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1645756480125.jpg" alt="" loading="lazy"></figure>
<p>请注意，在处理 HTTP 请求上，我们需要使用支持异步非阻塞的响应式服务器引擎，常见的包括 Netty、Undertow 以及支持 Servlet 3.1 及以上版本的 Servlet 容器。</p>
<h3 id="对比-webflux-和-webmvc-的处理模型">对比 WebFlux 和 WebMVC 的处理模型</h3>
<p>现在我们已经明确了 WebMVC 到 WebFlux 的演进过程，但你可能会问，新的 WebFlux 要比传统 WebMVC 好在哪里呢？从两者的处理模型上入手可以帮助你很好地理解这个问题，我们一起来看一下。</p>
<h4 id="webflux-和-web-mvc-中的处理模型">WebFlux 和 Web MVC 中的处理模型</h4>
<p>通过前面的讨论你已经知道 Servlet 是阻塞式的，所以 WebMVC 建立在阻塞 I/O 之上，我们来分析这种模型下线程处理请求的过程。假设有一个工作线程会处理来自客户端的请求，所有请求构成一个请求队列，并由一个线程按顺序进行处理。针对一个请求，线程需要执行两部分工作，首先是接受请求，然后再对其进行处理，如下图所示。</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1645756487462.jpg" alt="" loading="lazy"></figure>
<p>在前面的示例中，正如你可能注意到的，工作线程的实际处理时间远小于花费在阻塞操作上的时间。这意味着工作线程会被 I/O 读取或写入数据这一操作所阻塞。从这个简单的图中，<strong>我们可以得出结论，线程效率低下</strong>。同时，因为所有请求是排队的，相当于一个请求队列，所以接受请求和处理请求这两部分操作实际上是可以共享等待时间的。</p>
<p>相比之下，WebFlux 构建在非阻塞 API 之上，这意味着没有操作需要与 I/O 阻塞线程进行交互。接受和处理请求的效率很高，如下图所示。</p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1645756494658.jpg" alt="" loading="lazy"></figure>
<p>将上图中所展示的异步非阻塞请求处理与前面的阻塞过程进行比较，我们会注意到，现在没有在读取请求数据时发生等待，工作线程高效接受新连接。然后，提供了非阻塞 I/O 机制的底层操作系统会告诉我们请求数据是否已经接收完成，并且处理器可以在不阻塞的情况下进行处理。</p>
<p>类似的，写入响应结果时同样不需要阻塞，操作系统会在准备好将一部分数据非阻塞地写入 I/O 时通知我们。这样，我们就拥有了最佳的 CPU 利用率。</p>
<p>前面的示例展示了 WebFlux 比 WebMVC 更有效地利用一个工作线程，因此可以在相同的时间内处理更多的请求。那么，如果是在多线程的场景下会发生什么呢？我们来看下面这张图。</p>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1645756501100.jpg" alt="" loading="lazy"></figure>
<p>从上图中可以看出，多线程模型允许更快地处理排队请求，能够同时接受、处理和响应几乎相同数量的请求。当然，我们明白多线程技术有利有弊。当处理用户请求涉及太多的线程实例时，相互之间就需要协调资源，这是由于它们之间的不一致性会导致性能下降。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Spring Boot 自带 Buff 工具类]]></title>
        <id>https://tinaxiawuhao.github.io/post/I1j63ouUN/</id>
        <link href="https://tinaxiawuhao.github.io/post/I1j63ouUN/">
        </link>
        <updated>2022-01-23T07:28:20.000Z</updated>
        <content type="html"><![CDATA[<h2 id="断言">断言</h2>
<ol>
<li>断言是一个逻辑判断，用于检查不应该发生的情况</li>
<li>Assert 关键字在 JDK1.4 中引入，可通过 JVM 参数<code>-enableassertions</code>开启</li>
<li>SpringBoot 中提供了 Assert 断言工具类，通常用于数据合法性检查</li>
</ol>
<pre><code class="language-java">// 要求参数 object 必须为非空（Not Null），否则抛出异常，不予放行
// 参数 message 参数用于定制异常信息。
void notNull(Object object, String message)
// 要求参数必须空（Null），否则抛出异常，不予『放行』。
// 和 notNull() 方法断言规则相反
void isNull(Object object, String message)
// 要求参数必须为真（True），否则抛出异常，不予『放行』。
void isTrue(boolean expression, String message)
// 要求参数（List/Set）必须非空（Not Empty），否则抛出异常，不予放行
void notEmpty(Collection collection, String message)
// 要求参数（String）必须有长度（即，Not Empty），否则抛出异常，不予放行
void hasLength(String text, String message)
// 要求参数（String）必须有内容（即，Not Blank），否则抛出异常，不予放行
void hasText(String text, String message)
// 要求参数是指定类型的实例，否则抛出异常，不予放行
void isInstanceOf(Class type, Object obj, String message)
// 要求参数 `subType` 必须是参数 superType 的子类或实现类，否则抛出异常，不予放行
void isAssignable(Class superType, Class subType, String message)
</code></pre>
<h2 id="对象-数组-集合">对象、数组、集合</h2>
<h3 id="objectutils">ObjectUtils</h3>
<ol>
<li>获取对象的基本信息</li>
</ol>
<pre><code class="language-java">// 获取对象的类名。参数为 null 时，返回字符串：&quot;null&quot; 
String nullSafeClassName(Object obj)
// 参数为 null 时，返回 0
int nullSafeHashCode(Object object)
// 参数为 null 时，返回字符串：&quot;null&quot;
String nullSafeToString(boolean[] array)
// 获取对象 HashCode（十六进制形式字符串）。参数为 null 时，返回 0 
String getIdentityHexString(Object obj)
// 获取对象的类名和 HashCode。 参数为 null 时，返回字符串：&quot;&quot; 
String identityToString(Object obj)
// 相当于 toString()方法，但参数为 null 时，返回字符串：&quot;&quot;
String getDisplayString(Object obj)
</code></pre>
<ol>
<li>判断工具</li>
</ol>
<pre><code class="language-java">// 判断数组是否为空
boolean isEmpty(Object[] array)
// 判断参数对象是否是数组
boolean isArray(Object obj)
// 判断数组中是否包含指定元素
boolean containsElement(Object[] array, Object element)
// 相等，或同为 null时，返回 true
boolean nullSafeEquals(Object o1, Object o2)
/*
判断参数对象是否为空，判断标准为：
   Optional: Optional.empty()
      Array: length == 0
CharSequence: length == 0
 Collection: Collection.isEmpty()
        Map: Map.isEmpty()
*/
boolean isEmpty(Object obj)
</code></pre>
<ol>
<li>其他工具方法</li>
</ol>
<pre><code class="language-java">// 向参数数组的末尾追加新元素，并返回一个新数组
&lt;A, O extends A&gt; A[] addObjectToArray(A[] array, O obj)
// 原生基础类型数组 --&gt; 包装类数组
Object[] toObjectArray(Object source)
</code></pre>
<h3 id="stringutils">StringUtils</h3>
<ol>
<li>字符串判断工具</li>
</ol>
<pre><code class="language-java">// 判断字符串是否为 null，或 &quot;&quot;。注意，包含空白符的字符串为非空
boolean isEmpty(Object str)
// 判断字符串是否是以指定内容结束。忽略大小写
boolean endsWithIgnoreCase(String str, String suffix)
// 判断字符串是否已指定内容开头。忽略大小写
boolean startsWithIgnoreCase(String str, String prefix) 
// 是否包含空白符
boolean containsWhitespace(String str)
// 判断字符串非空且长度不为 0，即，Not Empty
boolean hasLength(CharSequence str)
// 判断字符串是否包含实际内容，即非仅包含空白符，也就是 Not Blank
boolean hasText(CharSequence str)
// 判断字符串指定索引处是否包含一个子串。
boolean substringMatch(CharSequence str, int index, CharSequence substring)
// 计算一个字符串中指定子串的出现次数
int countOccurrencesOf(String str, String sub)
</code></pre>
<ol>
<li>字符串操作工具</li>
</ol>
<pre><code class="language-java">// 查找并替换指定子串
String replace(String inString, String oldPattern, String newPattern)
// 去除尾部的特定字符
String trimTrailingCharacter(String str, char trailingCharacter) 
// 去除头部的特定字符
String trimLeadingCharacter(String str, char leadingCharacter)
// 去除头部的空白符
String trimLeadingWhitespace(String str)
// 去除头部的空白符
String trimTrailingWhitespace(String str)
// 去除头部和尾部的空白符
String trimWhitespace(String str)
// 删除开头、结尾和中间的空白符
String trimAllWhitespace(String str)
// 删除指定子串
String delete(String inString, String pattern)
// 删除指定字符（可以是多个）
String deleteAny(String inString, String charsToDelete)
// 对数组的每一项执行 trim() 方法
String[] trimArrayElements(String[] array)
// 将 URL 字符串进行解码
String uriDecode(String source, Charset charset)
</code></pre>
<ol>
<li>路径相关工具方法</li>
</ol>
<pre><code class="language-java">// 解析路径字符串，优化其中的 “..” 
String cleanPath(String path)
// 解析路径字符串，解析出文件名部分
String getFilename(String path)
// 解析路径字符串，解析出文件后缀名
String getFilenameExtension(String path)
// 比较两个两个字符串，判断是否是同一个路径。会自动处理路径中的 “..” 
boolean pathEquals(String path1, String path2)
// 删除文件路径名中的后缀部分
String stripFilenameExtension(String path) 
// 以 “. 作为分隔符，获取其最后一部分
String unqualify(String qualifiedName)
// 以指定字符作为分隔符，获取其最后一部分
String unqualify(String qualifiedName, char separator)
</code></pre>
<h3 id="collectionutils">CollectionUtils</h3>
<ol>
<li>集合判断工具</li>
</ol>
<pre><code class="language-java">// 判断 List/Set 是否为空
boolean isEmpty(Collection&lt;?&gt; collection)
// 判断 Map 是否为空
boolean isEmpty(Map&lt;?,?&gt; map)
// 判断 List/Set 中是否包含某个对象
boolean containsInstance(Collection&lt;?&gt; collection, Object element)
// 以迭代器的方式，判断 List/Set 中是否包含某个对象
boolean contains(Iterator&lt;?&gt; iterator, Object element)
// 判断 List/Set 是否包含某些对象中的任意一个
boolean containsAny(Collection&lt;?&gt; source, Collection&lt;?&gt; candidates)
// 判断 List/Set 中的每个元素是否唯一。即 List/Set 中不存在重复元素
boolean hasUniqueObject(Collection&lt;?&gt; collection)
</code></pre>
<ol>
<li>集合操作工具</li>
</ol>
<pre><code class="language-java">// 将 Array 中的元素都添加到 List/Set 中
&lt;E&gt; void mergeArrayIntoCollection(Object array, Collection&lt;E&gt; collection)  
// 将 Properties 中的键值对都添加到 Map 中
&lt;K,V&gt; void mergePropertiesIntoMap(Properties props, Map&lt;K,V&gt; map)
// 返回 List 中最后一个元素
&lt;T&gt; T lastElement(List&lt;T&gt; list)  
// 返回 Set 中最后一个元素
&lt;T&gt; T lastElement(Set&lt;T&gt; set) 
// 返回参数 candidates 中第一个存在于参数 source 中的元素
&lt;E&gt; E findFirstMatch(Collection&lt;?&gt; source, Collection&lt;E&gt; candidates)
// 返回 List/Set 中指定类型的元素。
&lt;T&gt; T findValueOfType(Collection&lt;?&gt; collection, Class&lt;T&gt; type)
// 返回 List/Set 中指定类型的元素。如果第一种类型未找到，则查找第二种类型，以此类推
Object findValueOfType(Collection&lt;?&gt; collection, Class&lt;?&gt;[] types)
// 返回 List/Set 中元素的类型
Class&lt;?&gt; findCommonElementType(Collection&lt;?&gt; collection)
</code></pre>
<h2 id="文件-资源-io-流">文件、资源、IO 流</h2>
<h3 id="filecopyutils">FileCopyUtils</h3>
<ol>
<li>输入</li>
</ol>
<pre><code class="language-java">// 从文件中读入到字节数组中
byte[] copyToByteArray(File in)
// 从输入流中读入到字节数组中
byte[] copyToByteArray(InputStream in)
// 从输入流中读入到字符串中
String copyToString(Reader in)
</code></pre>
<ol>
<li>输出</li>
</ol>
<pre><code class="language-java">// 从字节数组到文件
void copy(byte[] in, File out)
// 从文件到文件
int copy(File in, File out)
// 从字节数组到输出流
void copy(byte[] in, OutputStream out) 
// 从输入流到输出流
int copy(InputStream in, OutputStream out) 
// 从输入流到输出流
int copy(Reader in, Writer out)
// 从字符串到输出流
void copy(String in, Writer out)
</code></pre>
<h3 id="resourceutils">ResourceUtils</h3>
<ol>
<li>从资源路径获取文件</li>
</ol>
<pre><code class="language-java">// 判断字符串是否是一个合法的 URL 字符串。
static boolean isUrl(String resourceLocation)
// 获取 URL
static URL getURL(String resourceLocation) 
// 获取文件（在 JAR 包内无法正常使用，需要是一个独立的文件）
static File getFile(String resourceLocation)
</code></pre>
<ol>
<li>Resource</li>
</ol>
<pre><code class="language-java">// 文件系统资源 D:\...
FileSystemResource
// URL 资源，如 file://... http://...
UrlResource
// 类路径下的资源，classpth:...
ClassPathResource
// Web 容器上下文中的资源（jar 包、war 包）
ServletContextResource
复制代码
// 判断资源是否存在
boolean exists()
// 从资源中获得 File 对象
File getFile()
// 从资源中获得 URI 对象
URI getURI()
// 从资源中获得 URI 对象
URL getURL()
// 获得资源的 InputStream
InputStream getInputStream()
// 获得资源的描述信息
String getDescription()
</code></pre>
<h3 id="streamutils">StreamUtils</h3>
<ol>
<li>输入</li>
</ol>
<pre><code class="language-java">void copy(byte[] in, OutputStream out)
int copy(InputStream in, OutputStream out)
void copy(String in, Charset charset, OutputStream out)
long copyRange(InputStream in, OutputStream out, long start, long end)
</code></pre>
<ol>
<li>输出</li>
</ol>
<pre><code class="language-java">byte[] copyToByteArray(InputStream in)
String copyToString(InputStream in, Charset charset)
// 舍弃输入流中的内容
int drain(InputStream in) 
</code></pre>
<h2 id="反射-aop">反射、AOP</h2>
<h3 id="reflectionutils">ReflectionUtils</h3>
<ol>
<li>获取方法</li>
</ol>
<pre><code class="language-java">// 在类中查找指定方法
Method findMethod(Class&lt;?&gt; clazz, String name) 
// 同上，额外提供方法参数类型作查找条件
Method findMethod(Class&lt;?&gt; clazz, String name, Class&lt;?&gt;... paramTypes) 
// 获得类中所有方法，包括继承而来的
Method[] getAllDeclaredMethods(Class&lt;?&gt; leafClass) 
// 在类中查找指定构造方法
Constructor&lt;T&gt; accessibleConstructor(Class&lt;T&gt; clazz, Class&lt;?&gt;... parameterTypes) 
// 是否是 equals() 方法
boolean isEqualsMethod(Method method) 
// 是否是 hashCode() 方法 
boolean isHashCodeMethod(Method method) 
// 是否是 toString() 方法
boolean isToStringMethod(Method method) 
// 是否是从 Object 类继承而来的方法
boolean isObjectMethod(Method method) 
// 检查一个方法是否声明抛出指定异常
boolean declaresException(Method method, Class&lt;?&gt; exceptionType) 
</code></pre>
<ol>
<li>执行方法</li>
</ol>
<pre><code class="language-java">// 执行方法
Object invokeMethod(Method method, Object target)  
// 同上，提供方法参数
Object invokeMethod(Method method, Object target, Object... args) 
// 取消 Java 权限检查。以便后续执行该私有方法
void makeAccessible(Method method) 
// 取消 Java 权限检查。以便后续执行私有构造方法
void makeAccessible(Constructor&lt;?&gt; ctor) 
</code></pre>
<ol>
<li>获取字段</li>
</ol>
<pre><code class="language-java">// 在类中查找指定属性
Field findField(Class&lt;?&gt; clazz, String name) 
// 同上，多提供了属性的类型
Field findField(Class&lt;?&gt; clazz, String name, Class&lt;?&gt; type) 
// 是否为一个 &quot;public static final&quot; 属性
boolean isPublicStaticFinal(Field field) 
</code></pre>
<ol>
<li>设置字段</li>
</ol>
<pre><code class="language-java">// 获取 target 对象的 field 属性值
Object getField(Field field, Object target) 
// 设置 target 对象的 field 属性值，值为 value
void setField(Field field, Object target, Object value) 
// 同类对象属性对等赋值
void shallowCopyFieldState(Object src, Object dest)
// 取消 Java 的权限控制检查。以便后续读写该私有属性
void makeAccessible(Field field) 
// 对类的每个属性执行 callback
void doWithFields(Class&lt;?&gt; clazz, ReflectionUtils.FieldCallback fc) 
// 同上，多了个属性过滤功能。
void doWithFields(Class&lt;?&gt; clazz, ReflectionUtils.FieldCallback fc, 
                 ReflectionUtils.FieldFilter ff) 
// 同上，但不包括继承而来的属性
void doWithLocalFields(Class&lt;?&gt; clazz, ReflectionUtils.FieldCallback fc) 
</code></pre>
<h3 id="aoputils">AopUtils</h3>
<ol>
<li>判断代理类型</li>
</ol>
<pre><code class="language-java">// 判断是不是 Spring 代理对象
boolean isAopProxy()
// 判断是不是 jdk 动态代理对象
isJdkDynamicProxy()
// 判断是不是 CGLIB 代理对象
boolean isCglibProxy()
</code></pre>
<ol>
<li>获取被代理对象的 class</li>
</ol>
<pre><code class="language-java">// 获取被代理的目标 class
Class&lt;?&gt; getTargetClass()
</code></pre>
<h3 id="aopcontext">AopContext</h3>
<ol>
<li>获取当前对象的代理对象</li>
</ol>
<pre><code class="language-java">Object currentProxy()
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[nginx.conf中文详解]]></title>
        <id>https://tinaxiawuhao.github.io/post/yRJDaVAsJ/</id>
        <link href="https://tinaxiawuhao.github.io/post/yRJDaVAsJ/">
        </link>
        <updated>2022-01-18T09:17:06.000Z</updated>
        <content type="html"><![CDATA[<pre><code class="language-js">#定义Nginx运行的用户和用户组
user www www;

#nginx进程数，建议设置为等于CPU总核心数。
worker_processes 8;

#全局错误日志定义类型，[ debug | info | notice | warn | error | crit ]
error_log /usr/local/nginx/logs/error.log info;

#进程pid文件
pid /usr/local/nginx/logs/nginx.pid;

#指定进程可以打开的最大描述符：数目
#工作模式与连接数上限
#这个指令是指当一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（ulimit -n）与nginx进程数相除，但是nginx分配请求并不是那么均匀，所以最好与ulimit -n 的值保持一致。
#现在在linux 2.6内核下开启文件打开数为65535，worker_rlimit_nofile就相应应该填写65535。
#这是因为nginx调度时分配请求到进程并不是那么的均衡，所以假如填写10240，总并发量达到3-4万时就有进程可能超过10240了，这时会返回502错误。
worker_rlimit_nofile 65535;

events{
​    #参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型
​    #是Linux 2.6以上版本内核中的高性能网络I/O模型，linux建议epoll，如果跑在FreeBSD上面，就用kqueue模型。
​    #补充说明：
​    #与apache相类，nginx针对不同的操作系统，有不同的事件模型
​    #A）标准事件模型
​    #Select、poll属于标准事件模型，如果当前系统不存在更有效的方法，nginx会选择select或poll
​    #B）高效事件模型
​    #Kqueue：使用于FreeBSD 4.1+, OpenBSD 2.9+, NetBSD 2.0 和 MacOS X.使用双处理器的MacOS X系统使用kqueue可能会造成内核崩溃。
​    #Epoll：使用于Linux内核2.6版本及以后的系统。
​    #/dev/poll：使用于Solaris 7 11/99+，HP/UX 11.22+ (eventport)，IRIX 6.5.15+ 和 Tru64 UNIX 5.1A+。
​    #Eventport：使用于Solaris 10。 为了防止出现内核崩溃的问题， 有必要安装安全补丁。
​    use epoll;

​    #单个进程最大连接数（最大连接数=连接数*进程数）
​    #根据硬件调整，和前面工作进程配合起来用，尽量大，但是别把cpu跑到100%就行。每个进程允许的最多连接数，理论上每台nginx服务器的最大连接数为。
​    worker_connections 65535;

​    #keepalive超时时间。
​    keepalive_timeout 60;

​    #客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求头的大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。
​    #分页大小可以用命令getconf PAGESIZE 取得。
​    #[root@web001 ~]# getconf PAGESIZE
​    #4096
​    #但也有client_header_buffer_size超过4k的情况，但是client_header_buffer_size该值必须设置为“系统分页大小”的整倍数。
​    client_header_buffer_size 4k;

​    #这个将为打开文件指定缓存，默认是没有启用的，max指定缓存数量，建议和打开文件数一致，inactive是指经过多长时间文件没被请求后删除缓存。
​    open_file_cache max=65535 inactive=60s;

​    #这个是指多长时间检查一次缓存的有效信息。
​    #语法:open_file_cache_valid time 默认值:open_file_cache_valid 60 使用字段:http, server, location 这个指令指定了何时需要检查open_file_cache中缓存项目的有效信息.
​    open_file_cache_valid 80s;

​    #open_file_cache指令中的inactive参数时间内文件的最少使用次数，如果超过这个数字，文件描述符一直是在缓存中打开的，如上例，如果有一个文件在inactive时间内一次没被使用，它将被移除。
​    #语法:open_file_cache_min_uses number 默认值:open_file_cache_min_uses 1 使用字段:http, server, location  这个指令指定了在open_file_cache指令无效的参数中一定的时间范围内可以使用的最小文件数,如果使用更大的值,文件描述符在cache中总是打开状态.
​    open_file_cache_min_uses 1;

​    #语法:open_file_cache_errors on | off 默认值:open_file_cache_errors off 使用字段:http, server, location 这个指令指定是否在搜索一个文件时记录cache错误.
​    open_file_cache_errors on;

}

#设定http服务器，利用它的反向代理功能提供负载均衡支持
http{

​    #文件扩展名与文件类型映射表
​    include mime.types;

​    #默认文件类型
​    default_type application/octet-stream;

​    #默认编码
​    #charset utf-8;
​    #服务器名字的hash表大小
​    #保存服务器名字的hash表是由指令server_names_hash_max_size 和server_names_hash_bucket_size所控制的。参数hash bucket size总是等于hash表的大小，并且是一路处理器缓存大小的倍数。在减少了在内存中的存取次数后，使在处理器中加速查找hash表键值成为可能。如果hash bucket size等于一路处理器缓存的大小，那么在查找键的时候，最坏的情况下在内存中查找的次数为2。第一次是确定存储单元的地址，第二次是在存储单元中查找键 值。因此，如果Nginx给出需要增大hash max size 或 hash bucket size的提示，那么首要的是增大前一个参数的大小.
​    server_names_hash_bucket_size 128;

​    #客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求的头部大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。分页大小可以用命令getconf PAGESIZE取得。
​    client_header_buffer_size 32k;

​    #客户请求头缓冲大小。nginx默认会用client_header_buffer_size这个buffer来读取header值，如果header过大，它会使用large_client_header_buffers来读取。
​    large_client_header_buffers 4 64k;

​    #设定通过nginx上传文件的大小
​    client_max_body_size 8m;

​    #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。
​    #sendfile指令指定 nginx 是否调用sendfile 函数（zero copy 方式）来输出文件，对于普通应用，必须设为on。如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络IO处理速度，降低系统uptime。
​    sendfile on;

​    #开启目录列表访问，合适下载服务器，默认关闭。
​    autoindex on;

​    #此选项允许或禁止使用socke的TCP_CORK的选项，此选项仅在使用sendfile的时候使用
​    tcp_nopush on;

​    tcp_nodelay on;

​    #长连接超时时间，单位是秒
​    keepalive_timeout 120;

​    #FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解。
​    fastcgi_connect_timeout 300;
​    fastcgi_send_timeout 300;
​    fastcgi_read_timeout 300;
​    fastcgi_buffer_size 64k;
​    fastcgi_buffers 4 64k;
​    fastcgi_busy_buffers_size 128k;
​    fastcgi_temp_file_write_size 128k;

​    #gzip模块设置
​    gzip on; #开启gzip压缩输出
​    gzip_min_length 1k;    #最小压缩文件大小
​    gzip_buffers 4 16k;    #压缩缓冲区
​    gzip_http_version 1.0;    #压缩版本（默认1.1，前端如果是squid2.5请使用1.0）
​    gzip_comp_level 2;    #压缩等级
​    gzip_types text/plain application/x-javascript text/css application/xml;    #压缩类型，默认就已经包含textml，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn。
​    gzip_vary on;

​    #开启限制IP连接数的时候需要使用
​    #limit_zone crawler $binary_remote_addr 10m;
​    #负载均衡配置
​    upstream jh.w3cschool.cn {

​        #upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。
​        server 192.168.80.121:80 weight=3;
​        server 192.168.80.122:80 weight=2;
​        server 192.168.80.123:80 weight=3;

​        #nginx的upstream目前支持4种方式的分配
​        #1、轮询（默认）
​        #每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。
​        #2、weight
​        #指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。
​        #例如：
​        #upstream bakend {
​        #    server 192.168.0.14 weight=10;
​        #    server 192.168.0.15 weight=10;
​        #}
​        #2、ip_hash
​        #每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。
​        #例如：
​        #upstream bakend {
​        #    ip_hash;
​        #    server 192.168.0.14:88;
​        #    server 192.168.0.15:80;
​        #}
​        #3、fair（第三方）
​        #按后端服务器的响应时间来分配请求，响应时间短的优先分配。
​        #upstream backend {
​        #    server server1;
​        #    server server2;
​        #    fair;
​        #}
​        #4、url_hash（第三方）
​        #按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。
​        #例：在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法
​        #upstream backend {
​        #    server squid1:3128;
​        #    server squid2:3128;
​        #    hash $request_uri;
​        #    hash_method crc32;
​        #}
​        #tips:
​        #upstream bakend{#定义负载均衡设备的Ip及设备状态}{
​        #    ip_hash;
​        #    server 127.0.0.1:9090 down;
​        #    server 127.0.0.1:8080 weight=2;
​        #    server 127.0.0.1:6060;
​        #    server 127.0.0.1:7070 backup;
​        #}
​        #在需要使用负载均衡的server中增加 proxy_pass http://bakend/;
​        #每个设备的状态设置为:
​        #1.down表示单前的server暂时不参与负载
​        #2.weight为weight越大，负载的权重就越大。
​        #3.max_fails：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream模块定义的错误
​        #4.fail_timeout:max_fails次失败后，暂停的时间。
​        #5.backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。
​        #nginx支持同时设置多组的负载均衡，用来给不用的server来使用。
​        #client_body_in_file_only设置为On 可以讲client post过来的数据记录到文件中用来做debug
​        #client_body_temp_path设置记录文件的目录 可以设置最多3层目录
​        #location对URL进行匹配.可以进行重定向或者进行新的代理 负载均衡
​    }

​    #虚拟主机的配置
​    server{

​        #监听端口
​        listen 80;

​        #域名可以有多个，用空格隔开
​        server_name www.w3cschool.cn w3cschool.cn;
​        index index.html index.htm index.php;
​        root /data/www/w3cschool;

​        #对******进行负载均衡
​        location ~ .*.(php|php5)?${
​            fastcgi_pass 127.0.0.1:9000;
​            fastcgi_index index.php;
​            include fastcgi.conf;
​        }

​        #图片缓存时间设置
​        location ~ .*.(gif|jpg|jpeg|png|bmp|swf)${
​            expires 10d;
​        }

​        #JS和CSS缓存时间设置

​        location ~ .*.(js|css)?${
​            expires 1h;
​        }

​        #日志格式设定
​        #$remote_addr与$http_x_forwarded_for用以记录客户端的ip地址；
​        #$remote_user：用来记录客户端用户名称；
​        #$time_local： 用来记录访问时间与时区；
​        #$request： 用来记录请求的url与http协议；
​        #$status： 用来记录请求状态；成功是200，
​        #$body_bytes_sent ：记录发送给客户端文件主体内容大小；
​        #$http_referer：用来记录从那个页面链接访问过来的；
​        #$http_user_agent：记录客户浏览器的相关信息；
​        #通常web服务器放在反向代理的后面，这样就不能获取到客户的IP地址了，通过$remote_add拿到的IP地址是反向代理服务器的iP地址。反向代理服务器在转发请求的http头信息中，可以增加x_forwarded_for信息，用以记录原有客户端的IP地址和原来客户端的请求的服务器地址。
​        log_format access '$remote_addr - $remote_user [$time_local] &quot;$request&quot; '
​        '$status $body_bytes_sent &quot;$http_referer&quot; '
​        '&quot;$http_user_agent&quot; $http_x_forwarded_for';

​        #定义本虚拟主机的访问日志
​        access_log  /usr/local/nginx/logs/host.access.log  main;
​        access_log  /usr/local/nginx/logs/host.access.404.log  log404;

​        #对 &quot;/&quot; 启用反向代理
​        location / {
​            proxy_pass http://127.0.0.1:88;
​            proxy_redirect off;
​            proxy_set_header X-Real-IP $remote_addr;

​            #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP
​            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

​            #以下是一些反向代理的配置，可选。
​            proxy_set_header Host $host;

​            #允许客户端请求的最大单文件字节数
​            client_max_body_size 10m;

​            #缓冲区代理缓冲用户端请求的最大字节数，
​            #如果把它设置为比较大的数值，例如256k，那么，无论使用firefox还是IE浏览器，来提交任意小于256k的图片，都很正常。如果注释该指令，使用默认的client_body_buffer_size设置，也就是操作系统页面大小的两倍，8k或者16k，问题就出现了。
​            #无论使用firefox4.0还是IE8.0，提交一个比较大，200k左右的图片，都返回500 Internal Server Error错误
​            client_body_buffer_size 128k;

​            #表示使nginx阻止HTTP应答代码为400或者更高的应答。
​            proxy_intercept_errors on;

​            #后端服务器连接的超时时间_发起握手等候响应超时时间
​            #nginx跟后端服务器连接超时时间(代理连接超时)
​            proxy_connect_timeout 90;

​            #后端服务器数据回传时间(代理发送超时)
​            #后端服务器数据回传时间_就是在规定时间之内后端服务器必须传完所有的数据
​            proxy_send_timeout 90;

​            #连接成功后，后端服务器响应时间(代理接收超时)
​            #连接成功后_等候后端服务器响应时间_其实已经进入后端的排队之中等候处理（也可以说是后端服务器处理请求的时间）
​            proxy_read_timeout 90;

​            #设置代理服务器（nginx）保存用户头信息的缓冲区大小
​            #设置从被代理服务器读取的第一部分应答的缓冲区大小，通常情况下这部分应答中包含一个小的应答头，默认情况下这个值的大小为指令proxy_buffers中指定的一个缓冲区的大小，不过可以将其设置为更小
​            proxy_buffer_size 4k;

​            #proxy_buffers缓冲区，网页平均在32k以下的设置
​            #设置用于读取应答（来自被代理服务器）的缓冲区数目和大小，默认情况也为分页大小，根据操作系统的不同可能是4k或者8k
​            proxy_buffers 4 32k;

​            #高负荷下缓冲大小（proxy_buffers*2）
​            proxy_busy_buffers_size 64k;

​            #设置在写入proxy_temp_path时数据的大小，预防一个工作进程在传递文件时阻塞太长
​            #设定缓存文件夹大小，大于这个值，将从upstream服务器传
​            proxy_temp_file_write_size 64k;
​        }   

​        #设定查看Nginx状态的地址
​        location /NginxStatus {
​            stub_status on;
​            access_log on;
​            auth_basic &quot;NginxStatus&quot;;
​            auth_basic_user_file confpasswd;
​            #htpasswd文件的内容可以用apache提供的htpasswd工具来产生。
​        }

​        #本地动静分离反向代理配置
​        #所有jsp的页面均交由tomcat或resin处理
​        location ~ .(jsp|jspx|do)?$ {
​            proxy_set_header Host $host;
​            proxy_set_header X-Real-IP $remote_addr;
​            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
​            proxy_pass http://127.0.0.1:8080;
​        }

​        #所有静态文件由nginx直接读取不经过tomcat或resin
​        location ~ .*.(htm|html|gif|jpg|jpeg|png|bmp|swf|ioc|rar|zip|txt|flv|mid|doc|ppt|
​        pdf|xls|mp3|wma)${
​            expires 15d; 
​        }

​        location ~ .*.(js|css)?${
​            expires 1h;
​        }
​    }
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[docker 宿主机定时清除容器的运行日志]]></title>
        <id>https://tinaxiawuhao.github.io/post/KW_02xshc/</id>
        <link href="https://tinaxiawuhao.github.io/post/KW_02xshc/">
        </link>
        <updated>2022-01-17T03:35:08.000Z</updated>
        <content type="html"><![CDATA[<p>一般docker容器都是最小化安装，不仅如此系统定时器相关的服务也不存在，自己去安装也很麻烦，故此直接使用宿主机的定时器即可。</p>
<h4 id="一-在容器中编写清除日志脚本">一、在容器中编写清除日志脚本</h4>
<p>这一部分不论你是把定时器加在宿主机或者是容器都必须要去做的 ；</p>
<p>网上随意一搜就可以看到如下的删除模板：</p>
<pre><code class="language-shell">find 对应目录 -mtime +天数 -name &quot;文件名&quot; -exec rm -rf {} \;
</code></pre>
<p>因为本人的日志目录层级比较深 所以改良了如下：</p>
<pre><code class="language-shell">1. -- /opt/auto-del-log.sh 
2. \#!/bin/sh
3. find /home/schedule_log/ -mtime -5 -type f -iname &quot;*.log&quot; -exec rm -rf {} \;
</code></pre>
<p>一定记得加可执行权限</p>
<pre><code class="language-shell">chmod +777 /opt/auto-del-log.sh
</code></pre>
<p>后面经过验证 其实效果是一样的! 重点就是你要去验证你的脚本有无效！ 你可以这样直接输入验证</p>
<pre><code class="language-shell">1. find /home/schedule_log/  -type f -iname &quot;*.log&quot;
2. 或者
3. find /home/schedule_log/  -name &quot;*.log&quot;
</code></pre>
<p>如果能查出你想删除的文件那么后面就可以开始套模板了。</p>
<pre><code class="language-shell">-mtime：标准语句写法；
+30：查找30天前的文件，这里用数字代表天数；
&quot;*.log&quot;：希望查找的数据类型，&quot;*.jpg&quot;表示查找扩展名为jpg的所有文件，&quot;*&quot;表示查找所有文件，这个可以灵活运用，举一反三；
-exec：固定写法；
rm -rf：强制删除文件，包括目录；
{} \; ：固定写法，一对大括号+空格+\+; 
</code></pre>
<h4 id="二-宿主机加入定时器">二、宿主机加入定时器</h4>
<p>使用docker exec 命令校验之前写的脚本是否有效 如下：</p>
<pre><code class="language-shell">docker exec -it tomcat8002 /opt/auto-del-log.sh
tomcat8002 ： 容器名称或者ID
/opt/auto-del-log.sh :脚本在容器中的位置
</code></pre>
<p>如果此命令有效那么就可以编辑定时器了 本人采用的是centos7 具体可以参看网上介绍的挺全的一篇博客如下： <a href="https://blog.csdn.net/xudailong_blog/article/details/79303785">centos7 linux定时任务详解</a></p>
<pre><code class="language-shell">crontab -e
02 4 * * *  docker exec -it tomcat8002 /opt/auto-del-log.sh
</code></pre>
<p>接下来就OK啦！</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[docker安装elasticsearch]]></title>
        <id>https://tinaxiawuhao.github.io/post/2K9TL16e1/</id>
        <link href="https://tinaxiawuhao.github.io/post/2K9TL16e1/">
        </link>
        <updated>2022-01-16T03:27:56.000Z</updated>
        <content type="html"><![CDATA[<pre><code class="language-shell">docker search elasticsearch
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1641958220593.png" alt="" loading="lazy"></figure>
<p>选择一个版本，拉取镜像</p>
<pre><code class="language-shell">docker pull elasticsearch:2.4.4
</code></pre>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1641958232628.png" alt="" loading="lazy"></figure>
<p>查看镜像</p>
<pre><code class="language-shell">docker images
</code></pre>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1641958242342.png" alt="" loading="lazy"></figure>
<p>通过镜像，启动一个容器，并将9200和9300端口映射到本机</p>
<pre><code class="language-shell">docker run -d -p 9200:9200 -p 9300:9300 -e ES_JAVA_OPTS=&quot;-Xms512m -Xmx512m&quot; --name elasticsearch elasticsearch:2.4.4
</code></pre>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1641958249892.png" alt="" loading="lazy"></figure>
<p>查看已启动容器</p>
<pre><code class="language-shell">docker ps
</code></pre>
<p>验证是否安装成功？访问：</p>
<p>http://localhost:9200/</p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1641958263133.png" alt="" loading="lazy"></figure>
<p>安装插件，先进入容器：</p>
<pre><code class="language-shell">docker exec -it 4d34fbf944a5 /bin/bash
</code></pre>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1641958286588.png" alt="" loading="lazy"></figure>
<p>进入容器bin目录，并执行安装插件命令：</p>
<pre><code class="language-shell">cd bin ls
</code></pre>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1641958295695.png" alt="" loading="lazy"></figure>
<pre><code class="language-shell"> plugin install mobz/elasticsearch-head /**（低版本执行命令有所不同）**/ plugin -install mobz/elasticsearch-head
</code></pre>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1641958307262.png" alt="" loading="lazy"></figure>
<p>访问：</p>
<p>http://localhost:9200/_plugin/head/</p>
<figure data-type="image" tabindex="9"><img src="https://tinaxiawuhao.github.io/post-images/1641958315308.png" alt="" loading="lazy"></figure>
<p>插件安装成功</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[使用docker搭建FastDFS文件系统]]></title>
        <id>https://tinaxiawuhao.github.io/post/yIe_yl-14/</id>
        <link href="https://tinaxiawuhao.github.io/post/yIe_yl-14/">
        </link>
        <updated>2022-01-15T03:20:42.000Z</updated>
        <content type="html"><![CDATA[<h3 id="1首先下载fastdfs文件系统的docker镜像">1.首先下载FastDFS文件系统的docker镜像</h3>
<p>查询镜像</p>
<pre><code class="language-shell">[root@localhost /]# docker search fastdfs
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1641957924999.png" alt="" loading="lazy"></figure>
<p>安装镜像</p>
<pre><code class="language-shell">[root@localhost ~]# docker pull season/fastdfs [root@localhost ~]# docker images
</code></pre>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1641957936532.png" alt="" loading="lazy"></figure>
<h3 id="2使用docker镜像构建tracker容器跟踪服务器起到调度的作用">2.使用docker镜像构建tracker容器（跟踪服务器，起到调度的作用）：</h3>
<p>创建tracker容器</p>
<pre><code class="language-shell">[root@localhost /]# docker run -ti -d --name trakcer -v ~/tracker_data:/fastdfs/tracker/data --net=host season/fastdfs tracker
</code></pre>
<p>Tracker服务器的端口默认是22122，你可以查看是否启用端口</p>
<pre><code class="language-shell">[root@localhost /]# netstat -aon | grep 22122
</code></pre>
<h3 id="3使用docker镜像构建storage容器存储服务器提供容量和备份服务">3.使用docker镜像构建storage容器（存储服务器，提供容量和备份服务）：</h3>
<pre><code class="language-shell">docker run -tid --name storage -v ~/storage_data:/fastdfs/storage/data -v ~/store_path:/fastdfs/store_path --net=host -e TRACKER_SERVER:192.168.115.130:22122 -e GROUP_NAME=group1 season/fastdfs storage
</code></pre>
<h3 id="4此时两个服务都以启动进行服务的配置">4.此时两个服务都以启动，进行服务的配置。</h3>
<p>进入storage容器，到storage的配置文件中配置http访问的端口，配置文件在<strong>fdfs_conf</strong>目录下的<strong>storage.conf。</strong></p>
<pre><code class="language-shell">[root@localhost /]# docker exec -it storage bash root@localhost:/# cd fdfs_conf root@localhost:/fdfs_conf# more storage.conf
</code></pre>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1641957952610.png" alt="" loading="lazy"></figure>
<p>往下拉，你会发现storage容器的ip不是你linux的ip，如下：</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1641957960584.png" alt="" loading="lazy"></figure>
<p>接下来，退出storage容器，并将配置文件拷贝一份出来：</p>
<pre><code class="language-shell">[root@localhost ~]# docker cp storage:/fdfs_conf/storage.conf ~/ [root@localhost ~]# vi ~/storage.conf
</code></pre>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1641957970483.png" alt="" loading="lazy"></figure>
<p>将修改后的配置文件拷贝到storagee的配置目录下：</p>
<pre><code class="language-shell">[root@localhost ~]# docker cp ~/storage.conf storage:/fdfs_conf/
</code></pre>
<p>重新启动storage容器</p>
<pre><code class="language-shell">[root@localhost ~]# docker stop storage [root@localhost ~]# docker start storage
</code></pre>
<p>查看tracker容器和storage容器的关联</p>
<pre><code class="language-shell">[root@localhost ~]# docker exec -it storage bash root@localhost:/# cd fdfs_conf root@localhost:/fdfs_conf# fdfs_monitor storage.conf
</code></pre>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1641957980436.png" alt="" loading="lazy"></figure>
<h3 id="5在docker模拟客户端上传文件到storage容器">5.在docker模拟客户端上传文件到storage容器</h3>
<p>开启一个客户端</p>
<pre><code class="language-shell">[root@localhost 00]# docker run -tid --name fdfs_sh --net=host season/fastdfs sh
</code></pre>
<p>更改配置文件，因为之前已经改过一次了，所以现在直接拷贝</p>
<pre><code class="language-shell">[root@localhost 00]# docker cp ~/storage.conf  fdfs_sh:/fdfs_conf/
</code></pre>
<p>创建一个txt文件</p>
<pre><code class="language-shell">[root@localhost 00]# docker exec -it fdfs_sh bash root@localhost:/# echo hello&gt;a.txt
</code></pre>
<p>进入<strong>fdfs_conf</strong>目录，并将文件上传到<strong>storage</strong>容器</p>
<pre><code class="language-shell">root@localhost:/# cd fdfs_conf root@localhost:/fdfs_conf# fdfs_upload_file storage.conf /a.txt
</code></pre>
<p><strong>/a.txt</strong>：指要上传的文件</p>
<p>上传之后，根据返回的路径去找<strong>a.txt</strong></p>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1641957990375.png" alt="" loading="lazy"></figure>
<p>退出去查看上传的txt文件</p>
<p>[root@localhost ~]# cd ~/store_path/data/00/00 [root@localhost 00]# ls</p>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1641958001513.png" alt="" loading="lazy"></figure>
<p>查看是否和输入的值是否相同</p>
<pre><code class="language-shell">[root@localhost 00]# more wKhzg1wGsieAL-3RAAAABncc3SA337.txt
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dockerfile详解]]></title>
        <id>https://tinaxiawuhao.github.io/post/jw7hb2R8R/</id>
        <link href="https://tinaxiawuhao.github.io/post/jw7hb2R8R/">
        </link>
        <updated>2022-01-14T03:00:49.000Z</updated>
        <content type="html"><![CDATA[<p><strong>Dockerfile详解</strong></p>
<h2 id="环境介绍">环境介绍</h2>
<ol>
<li>
<p>Dockerfile中所用的所有文件一定要和Dockerfile文件在同一级父目录下，可以为Dockerfile父目录的子目录</p>
</li>
<li>
<p>Dockerfile中相对路径默认都是Dockerfile所在的目录</p>
</li>
<li>
<p>Dockerfile中一定要惜字如金，能写到一行的指令，一定要写到一行，原因是分层构建，联合挂载这个特性。</p>
<p>Dockerfile中每一条指令被视为一层</p>
</li>
<li>
<p>Dockerfile中指明大写（约定俗成）</p>
</li>
</ol>
<h2 id="指令介绍">指令介绍</h2>
<h3 id="from">FROM</h3>
<blockquote>
<p>功能为指定基础镜像，并且必须是第一条指令。</p>
</blockquote>
<p>如果不以任何镜像为基础，那么写法为：<code>FROM scratch</code>。</p>
<p>同时意味着接下来所写的指令将作为镜像的第一层开始</p>
<p>语法：</p>
<pre><code class="language-shell">FROM &lt;image&gt;
FROM &lt;image&gt;:&lt;tag&gt;
FROM &lt;image&gt;:&lt;digest&gt; 
三种写法，其中&lt;tag&gt;和&lt;digest&gt; 是可选项，如果没有选择，那么默认值为latest
</code></pre>
<h3 id="maintainer">MAINTAINER</h3>
<blockquote>
<p>指定作者</p>
</blockquote>
<p>语法：</p>
<pre><code class="language-shell">MAINTAINER &lt;name&gt;
</code></pre>
<ul>
<li>新版docker中使用LABEL指明</li>
</ul>
<h3 id="label">LABEL</h3>
<blockquote>
<p>功能是为镜像指定标签</p>
</blockquote>
<p>语法：</p>
<pre><code class="language-shell">LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; ...
 一个Dockerfile种可以有多个LABEL，如下：

LABEL &quot;com.example.vendor&quot;=&quot;ACME Incorporated&quot;
LABEL com.example.label-with-value=&quot;foo&quot;
LABEL version=&quot;1.0&quot;
LABEL description=&quot;This text illustrates 
that label-values can span multiple lines.&quot;
 但是并不建议这样写，最好就写成一行，如太长需要换行的话则使用\符号

如下：

LABEL multi.label1=&quot;value1&quot; 
multi.label2=&quot;value2&quot; 
other=&quot;value3&quot;
</code></pre>
<p>说明：LABEL会继承基础镜像种的LABEL，如遇到key相同，则值覆盖</p>
<h3 id="add">ADD</h3>
<blockquote>
<p>一个复制命令，把文件复制到镜像中。</p>
</blockquote>
<p>如果把虚拟机与容器想象成两台linux服务器的话，那么这个命令就类似于scp，只是scp需要加用户名和密码的权限验证，而ADD不用。</p>
<p>语法如下：</p>
<pre><code class="language-shell">1. ADD &lt;src&gt;... &lt;dest&gt;
2. ADD [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;]
</code></pre>
<ul>
<li>路径的填写可以是容器内的绝对路径，也可以是相对于工作目录的相对路径，推荐写成绝对路径</li>
<li>可以是一个本地文件或者是一个本地压缩文件，还可以是一个url</li>
<li>如果把写成一个url，那么ADD就类似于wget命令</li>
</ul>
<p>示例</p>
<pre><code class="language-shell">ADD test relativeDir/ 
ADD test /relativeDir
ADD http://example.com/foobar/ 
</code></pre>
<p>注意事项</p>
<ul>
<li>src为一个目录的时候，会自动把目录下的文件复制过去，目录本身不会复制</li>
<li>如果src为多个文件，dest一定要是一个目录</li>
</ul>
<h3 id="copy">COPY</h3>
<blockquote>
<p>看这个名字就知道，又是一个复制命令</p>
</blockquote>
<p>语法如下：</p>
<pre><code class="language-shell">COPY &lt;src&gt;... &lt;dest&gt;
COPY [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;]
</code></pre>
<p>与ADD的区别</p>
<ul>
<li>COPY的只能是本地文件，其他用法一致</li>
</ul>
<h3 id="expose">EXPOSE</h3>
<blockquote>
<p>功能为暴漏容器运行时的监听端口给外部</p>
</blockquote>
<blockquote>
<p>但是EXPOSE并不会使容器访问主机的端口</p>
</blockquote>
<blockquote>
<p>如果想使得容器与主机的端口有映射关系，必须在容器启动的时候加上 -P参数</p>
</blockquote>
<p>语法：</p>
<pre><code class="language-shell">EXPOSE &lt;port&gt;/&lt;tcp/udp&gt;
</code></pre>
<h3 id="env">ENV</h3>
<blockquote>
<p>功能为设置环境变量</p>
</blockquote>
<p>语法有两种</p>
<pre><code class="language-shell"> ENV &lt;key&gt; &lt;value&gt;
 ENV &lt;key&gt;=&lt;value&gt; ...
</code></pre>
<p>两者的区别就是第一种是一次设置一个，第二种是一次设置多个</p>
<p><strong>在Dockerfile中使用变量的方式</strong></p>
<ul>
<li>$varname</li>
<li>${varname}</li>
<li>${varname:-default value}</li>
<li>$(varname:+default value}</li>
</ul>
<p>第一种和第二种相同</p>
<p>第三种表示当变量不存在使用-号后面的值</p>
<p>第四种表示当变量存在时使用+号后面的值（当然不存在也是使用后面的值）</p>
<h3 id="run">RUN</h3>
<blockquote>
<p>功能为运行指定的命令</p>
</blockquote>
<p>RUN命令有两种格式</p>
<pre><code class="language-shell">1. RUN &lt;command&gt;
2. RUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]
</code></pre>
<p>第一种后边直接跟shell命令</p>
<ul>
<li>在linux操作系统上默认 /bin/sh -c</li>
<li>在windows操作系统上默认 cmd /S /C</li>
</ul>
<p>第二种是类似于函数调用。</p>
<ul>
<li>可将executable理解成为可执行文件，后面就是两个参数。</li>
</ul>
<h3 id="cmd">CMD</h3>
<blockquote>
<p>功能为容器启动时默认命令或参数</p>
</blockquote>
<p>语法有三种写法</p>
<pre><code class="language-shell">CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;]
CMD [&quot;param1&quot;,&quot;param2&quot;]
CMD command param1 param2
</code></pre>
<p>第三种比较好理解了，就时shell这种执行方式和写法</p>
<p>第一种和第二种其实都是可执行文件加上参数的形式</p>
<p>举例说明两种写法：</p>
<pre><code class="language-shell">CMD [ &quot;sh&quot;, &quot;-c&quot;, &quot;echo $HOME&quot; 
CMD [ &quot;echo&quot;, &quot;$HOME&quot; ]
</code></pre>
<p>补充细节：这里边包括参数的一定要用双引号，就是&quot;,不能是单引号。千万不能写成单引号。</p>
<p>原因是参数传递后，docker解析的是一个JSON array</p>
<p><strong>RUN&amp;&amp;CMD</strong></p>
<blockquote>
<p>不要把RUN和CMD搞混了。 RUN是构件容器时就运行的命令以及提交运行结果 CMD是容器启动时执行的命令，在构件时并不运行，构件时紧紧指定了这个命令到底是个什么样子</p>
</blockquote>
<h3 id="entrypoint">ENTRYPOINT</h3>
<blockquote>
<p>功能是：容器启动时运行得启动命令</p>
</blockquote>
<p>语法如下：</p>
<pre><code class="language-shell">ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]  
ENTRYPOINT command param1 param2
</code></pre>
<p>如果从上到下看到这里的话，那么你应该对这两种语法很熟悉啦。</p>
<ul>
<li>第二种就是写shell</li>
<li>第一种就是可执行文件加参数</li>
</ul>
<p>与CMD比较说明（这俩命令太像了，而且还可以配合使用）：</p>
<ol>
<li>相同点：</li>
</ol>
<ul>
<li>只能写一条，如果写了多条，那么只有最后一条生效</li>
</ul>
<p>容器启动时才运行，运行时机相同</p>
<ol>
<li>不同点：</li>
</ol>
<ul>
<li>ENTRYPOINT不会被运行的command覆盖，而CMD则会被覆盖</li>
<li>如果我们在Dockerfile种同时写了ENTRYPOINT和CMD，并且CMD指令不是一个完整的可执行命令，那么CMD指定的内容将会作为ENTRYPOINT的参数</li>
</ul>
<p>如下：</p>
<pre><code class="language-shell">FROM ubuntu
ENTRYPOINT [&quot;top&quot;, &quot;-b&quot;]
CMD [&quot;-c&quot;]
</code></pre>
<p>如果我们在Dockerfile种同时写了ENTRYPOINT和CMD，并且CMD是一个完整的指令，那么它们两个会互相覆盖，谁在最后谁生效</p>
<p>如下：</p>
<pre><code class="language-shell">FROM ubuntu
ENTRYPOINT [&quot;top&quot;, &quot;-b&quot;]
CMD ls -al
</code></pre>
<p>那么将执行ls -al ,top -b不会执行。</p>
<p>Docker官方使用一张表格来展示了ENTRYPOINT 和</p>
<p>CMD不同组合的执行情况</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1645236614794.jpeg" alt="" loading="lazy"></figure>
<h3 id="volume">VOLUME</h3>
<blockquote>
<p>可实现挂载功能，可以将宿主机目录挂载到容器中</p>
</blockquote>
<p>说的这里大家都懂了，可用专用的文件存储当作Docker容器的数据存储部分</p>
<p>语法如下：</p>
<pre><code class="language-shell">VOLUME [&quot;/data&quot;]
</code></pre>
<p>说明：</p>
<p>[&quot;/data&quot;]可以是一个JsonArray ，也可以是多个值。所以如下几种写法都是正确的</p>
<pre><code class="language-shell">VOLUME [&quot;/var/log/&quot;]
VOLUME /var/log
VOLUME /var/log /var/db
</code></pre>
<p>一般的使用场景为需要持久化存储数据时</p>
<p>容器使用的是AUFS，这种文件系统不能持久化数据，当容器关闭后，所有的更改都会丢失。</p>
<h3 id="user">USER</h3>
<blockquote>
<p>设置启动容器的用户，可以是用户名或UID，所以，只有下面的两种写法是正确的</p>
</blockquote>
<pre><code class="language-shell">USER daemo
USER UID
</code></pre>
<p>注意：如果设置了容器以daemon用户去运行，那么RUN, CMD 和 ENTRYPOINT 都会以这个用户去运行,</p>
<p>使用这个命令一定要确认容器中拥有这个用户，并且拥有足够权限</p>
<h3 id="workdir">WORKDIR</h3>
<blockquote>
<p>设置工作目录</p>
</blockquote>
<p>语法：</p>
<pre><code class="language-shell">WORKDIR /path/to/workdir
</code></pre>
<p>设置工作目录，对RUN,CMD,ENTRYPOINT,COPY,ADD生效。如果不存在则会创建，也可以设置多次。</p>
<p>如：</p>
<pre><code class="language-shell">WORKDIR /a
WORKDIR b
WORKDIR c
RUN pwd
</code></pre>
<p>pwd执行的结果是/a/b/c</p>
<p>WORKDIR也可以解析环境变量</p>
<p>如：</p>
<pre><code class="language-shell">ENV DIRPATH /path
WORKDIR $DIRPATH/$DIRNAME
RUN pwd
</code></pre>
<p>pwd的执行结果是/path/$DIRNAME</p>
<h3 id="arg">ARG</h3>
<blockquote>
<p>设置变量命令</p>
</blockquote>
<p>语法：</p>
<pre><code class="language-shell">ARG &lt;name&gt;[=&lt;default value&gt;]
</code></pre>
<p>设置变量命令，ARG命令定义了一个变量，在docker build创建镜像的时候，使用 --build-arg =来指定参数</p>
<p>如果用户在build镜像时指定了一个参数没有定义在Dockerfile种，那么将有一个Warning</p>
<p>提示如下：</p>
<pre><code class="language-shell">[Warning] One or more build-args [foo] were not consumed.
</code></pre>
<p>我们可以定义一个或多个参数，如下：</p>
<pre><code class="language-shell">FROM busybox
ARG user1
ARG buildno
</code></pre>
<p>也可以给参数一个默认值：</p>
<pre><code class="language-shell">FROM busybox
ARG user1=someuser
ARG buildno=1
</code></pre>
<p>如果我们给了ARG定义的参数默认值，那么当build镜像时没有指定参数值，将会使用这个默认值</p>
<h3 id="onbuild">ONBUILD</h3>
<p>语法：</p>
<pre><code class="language-shell">ONBUILD [INSTRUCTION]
</code></pre>
<p>这个命令只对当前镜像的子镜像生效。</p>
<p>比如当前镜像为A，在Dockerfile种添加：</p>
<pre><code class="language-shell">ONBUILD RUN ls -al
</code></pre>
<ul>
<li>这个 ls -al 命令不会在A镜像构建或启动的时候执行</li>
</ul>
<p>此时有一个镜像B是基于A镜像构建的，那么这个ls -al 命令会在B镜像构建的时候被执行。</p>
<h3 id="stopsignal">STOPSIGNAL</h3>
<p>语法：</p>
<pre><code class="language-shell">STOPSIGNAL signal
</code></pre>
<p>STOPSIGNAL命令是的作用是当容器停止时给系统发送什么样的指令，默认是15</p>
<h3 id="healthcheck">HEALTHCHECK</h3>
<blockquote>
<p>容器健康状况检查命令</p>
</blockquote>
<p>语法有两种：</p>
<pre><code class="language-shell"> HEALTHCHECK [OPTIONS] CMD command
 HEALTHCHECK NONE
</code></pre>
<p>第一个的功能是在容器内部运行一个命令来检查容器的健康状况</p>
<p>第二个的功能是在基础镜像中取消健康检查命令</p>
<p>[OPTIONS]的选项支持以下三中选项：</p>
<ul>
<li>–interval=DURATION 两次检查默认的时间间隔为30秒</li>
<li>–timeout=DURATION 健康检查命令运行超时时长，默认30秒</li>
<li>–retries=N 当连续失败指定次数后，则容器被认为是不健康的，状态为unhealthy，默认次数是3</li>
</ul>
<p>注意：</p>
<p>HEALTHCHECK命令只能出现一次，如果出现了多次，只有最后一个生效。</p>
<p>CMD后边的命令的返回值决定了本次健康检查是否成功，具体的返回值如下：</p>
<ul>
<li>0: success - 表示容器是健康的</li>
<li>1: unhealthy - 表示容器已经不能工作了</li>
<li>2: reserved - 保留值</li>
</ul>
<p>例子：</p>
<pre><code class="language-shell">HEALTHCHECK --interval=5m --timeout=3s 
CMD curl -f http://localhost/ || exit 1
</code></pre>
<p>健康检查命令是：curl -f http://localhost/ || exit 1</p>
<p>两次检查的间隔时间是5秒</p>
<p>命令超时时间为3秒</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Docker ]]></title>
        <id>https://tinaxiawuhao.github.io/post/VSWRPm3xo/</id>
        <link href="https://tinaxiawuhao.github.io/post/VSWRPm3xo/">
        </link>
        <updated>2022-01-13T02:37:47.000Z</updated>
        <content type="html"><![CDATA[<h1 id="docker">Docker</h1>
<p>学习目标：</p>
<ul>
<li>
<p>掌握Docker基础知识，能够理解Docker镜像与容器的概念</p>
</li>
<li>
<p>完成Docker安装与启动</p>
</li>
<li>
<p>掌握Docker镜像与容器相关命令</p>
</li>
<li>
<p>掌握Tomcat Nginx 等软件的常用应用的安装</p>
</li>
<li>
<p>掌握docker迁移与备份相关命令</p>
</li>
<li>
<p>能够运用Dockerfile编写创建容器的脚本</p>
</li>
<li>
<p>能够搭建与使用docker私有仓库</p>
</li>
</ul>
<h1 id="1-docker简介">1 Docker简介</h1>
<h2 id="11-什么是虚拟化">1.1 什么是虚拟化</h2>
<p>​	在计算机中，虚拟化（英语：Virtualization）是一种资源管理技术，是将计算机的各种实体资源，如服务器、网络、内存及存储等，予以抽象、转换后呈现出来，打破实体结构间的不可切割的障碍，使用户可以比原本的组态更好的方式来应用这些资源。这些资源的新虚拟部份是不受现有资源的架设方式，地域或物理组态所限制。一般所指的虚拟化资源包括计算能力和资料存储。</p>
<p>​	在实际的生产环境中，虚拟化技术主要用来解决高性能的物理硬件产能过剩和老的旧的硬件产能过低的重组重用，透明化底层物理硬件，从而最大化的利用物理硬件   对资源充分利用</p>
<p>​	虚拟化技术种类很多，例如：软件虚拟化、硬件虚拟化、内存虚拟化、网络虚拟化(vip)、桌面虚拟化、服务虚拟化、虚拟机等等。</p>
<h2 id="12-什么是docker">1.2 什么是Docker</h2>
<p>​	Docker 是一个开源项目，诞生于 2013 年初，最初是 dotCloud 公司内部的一个业余项目。它基于 Google 公司推出的 Go 语言实现。 项目后来加入了 Linux 基金会，遵从了 Apache 2.0 协议，项目代码在 <a href="https://github.com/docker/docker">GitHub</a> 上进行维护。</p>
<p>​	<img src="https://tinaxiawuhao.github.io/post-images/1641955175988.png" alt="" loading="lazy"></p>
<p>​	Docker 自开源后受到广泛的关注和讨论，以至于 dotCloud 公司后来都改名为 Docker Inc。Redhat 已经在其 RHEL6.5 中集中支持 Docker；Google 也在其 PaaS 产品中广泛应用。</p>
<p>​	Docker 项目的目标是实现轻量级的操作系统虚拟化解决方案。 Docker 的基础是 Linux 容器（LXC）等技术。</p>
<p>​	在 LXC 的基础上 Docker 进行了进一步的封装，让用户不需要去关心容器的管理，使得操作更为简便。用户操作 Docker 的容器就像操作一个快速轻量级的虚拟机一样简单。</p>
<p>为什么选择Docker?</p>
<p>（1）上手快。</p>
<p>​	用户只需要几分钟，就可以把自己的程序“Docker化”。Docker依赖于“写时复制”（copy-on-write）模型，使修改应用程序也非常迅速，可以说达到“随心所致，代码即改”的境界。</p>
<p>随后，就可以创建容器来运行应用程序了。大多数Docker容器只需要不到1秒中即可启动。由于去除了管理程序的开销，Docker容器拥有很高的性能，同时同一台宿主机中也可以运行更多的容器，使用户尽可能的充分利用系统资源。</p>
<p>（2）职责的逻辑分类</p>
<p>​	使用Docker，开发人员只需要关心容器中运行的应用程序，而运维人员只需要关心如何管理容器。Docker设计的目的就是要加强开发人员写代码的开发环境与应用程序要部署的生产环境一致性。从而降低那种“开发时一切正常，肯定是运维的问题（测试环境都是正常的，上线后出了问题就归结为肯定是运维的问题）”</p>
<p>（3）快速高效的开发生命周期</p>
<p>​	Docker的目标之一就是缩短代码从开发、测试到部署、上线运行的周期，让你的应用程序具备可移植性，易于构建，并易于协作。（通俗一点说，Docker就像一个盒子，里面可以装很多物件，如果需要这些物件的可以直接将该大盒子拿走，而不需要从该盒子中一件件的取。）</p>
<p>（4）鼓励使用面向服务的架构</p>
<p>​	Docker还鼓励面向服务的体系结构和微服务架构。Docker推荐单个容器只运行一个应用程序或进程，这样就形成了一个分布式的应用程序模型，在这种模型下，应用程序或者服务都可以表示为一系列内部互联的容器，从而使分布式部署应用程序，扩展或调试应用程序都变得非常简单，同时也提高了程序的内省性。（当然，可以在一个容器中运行多个应用程序）</p>
<h2 id="13-容器与虚拟机比较">1.3 容器与虚拟机比较</h2>
<p>​	下面的图片比较了 Docker 和传统虚拟化方式的不同之处，可见容器是在操作系统层面上实现虚拟化，直接复用本地主机的操作系统，而传统方式则是在硬件层面实现。</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1641955189369.png" alt="" loading="lazy"></figure>
<p>与传统的虚拟机相比，Docker优势体现为启动速度快、占用体积小。</p>
<h2 id="14-docker-组件">1.4 Docker 组件</h2>
<h3 id="141-docker服务器与客户端">1.4.1 Docker服务器与客户端</h3>
<p>​	Docker是一个客户端-服务器（C/S）架构程序。Docker客户端只需要向Docker服务器或者守护进程发出请求，服务器或者守护进程将完成所有工作并返回结果。Docker提供了一个命令行工具Docker以及一整套RESTful API。你可以在同一台宿主机上运行Docker守护进程和客户端，也可以从本地的Docker客户端连接到运行在另一台宿主机上的远程Docker守护进程。</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1641955202177.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1645597883819.png" alt="" loading="lazy"></figure>
<h3 id="142-docker镜像与容器">1.4.2 Docker镜像与容器</h3>
<p>​	镜像是构建Docker的基石。用户基于镜像来运行自己的容器。镜像也是Docker生命周期中的“构建”部分。镜像是基于联合文件系统的一种层式结构，由一系列指令一步一步构建出来。例如：</p>
<p>添加一个文件；</p>
<p>执行一个命令；</p>
<p>打开一个窗口。</p>
<p>也可以将镜像当作容器的“源代码”。镜像体积很小，非常“便携”，易于分享、存储和更新。</p>
<p>​	Docker可以帮助你构建和部署容器，你只需要把自己的应用程序或者服务打包放进容器即可。容器是基于镜像启动起来的，容器中可以运行一个或多个进程。我们可以认为，镜像是Docker生命周期中的构建或者打包阶段，而容器则是启动或者执行阶段。  容器基于镜像启动，一旦容器启动完成后，我们就可以登录到容器中安装自己需要的软件或者服务。</p>
<p>所以Docker容器就是：</p>
<p>​	一个镜像格式；</p>
<p>​	一些列标准操作；</p>
<p>​	一个执行环境。</p>
<p>​	Docker借鉴了标准集装箱的概念。标准集装箱将货物运往世界各地，Docker将这个模型运用到自己的设计中，唯一不同的是：集装箱运输货物，而Docker运输软件。</p>
<p>和集装箱一样，Docker在执行上述操作时，并不关心容器中到底装了什么，它不管是web服务器，还是数据库，或者是应用程序服务器什么的。所有的容器都按照相同的方式将内容“装载”进去。</p>
<p>Docker也不关心你要把容器运到何方：我们可以在自己的笔记本中构建容器，上传到Registry，然后下载到一个物理的或者虚拟的服务器来测试，在把容器部署到具体的主机中。像标准集装箱一样，Docker容器方便替换，可以叠加，易于分发，并且尽量通用。</p>
<h3 id="143-registry注册中心">1.4.3 Registry（注册中心）</h3>
<p>​	Docker用Registry来保存用户构建的镜像。Registry分为公共和私有两种。Docker公司运营公共的Registry叫做Docker Hub。用户可以在Docker Hub注册账号，分享并保存自己的镜像（说明：在Docker Hub下载镜像巨慢，可以自己构建私有的Registry）。</p>
<p>​	https://hub.docker.com/</p>
<h1 id="2-docker安装与启动">2 Docker安装与启动</h1>
<h2 id="21-安装docker">2.1 安装Docker</h2>
<p>​	Docker官方建议在Ubuntu中安装，因为Docker是基于Ubuntu发布的，而且一般Docker出现的问题Ubuntu是最先更新或者打补丁的。在很多版本的CentOS中是不支持更新最新的一些补丁包的。</p>
<p>​	由于我们学习的环境都使用的是CentOS，因此这里我们将Docker安装到CentOS上。注意：这里建议安装在CentOS7.x以上的版本，在CentOS6.x的版本中，安装前需要安装其他很多的环境而且Docker很多补丁不支持更新。</p>
<p>​	请直接挂载课程配套的Centos7.x镜像</p>
<p>（1）yum 包更新到最新</p>
<pre><code class="language-shell">sudo yum update
</code></pre>
<p>（2）安装需要的软件包， yum-util 提供yum-config-manager功能，另外两个是devicemapper驱动依赖的</p>
<pre><code class="language-shell">sudo yum install -y yum-utils device-mapper-persistent-data lvm2
</code></pre>
<p>（3）设置yum源为阿里云</p>
<pre><code class="language-shell">sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
</code></pre>
<p>（4）安装docker</p>
<pre><code class="language-shell">sudo yum install docker-ce
</code></pre>
<p>（5）安装后查看docker版本</p>
<pre><code class="language-shell">docker -v
</code></pre>
<h2 id="22-设置ustc的镜像">2.2 设置ustc的镜像</h2>
<p>ustc是老牌的linux镜像服务提供者了，还在遥远的ubuntu 5.04版本的时候就在用。ustc的docker镜像加速器速度很快。ustc docker mirror的优势之一就是不需要注册，是真正的公共服务。</p>
<p><a href="https://lug.ustc.edu.cn/wiki/mirrors/help/docker">https://lug.ustc.edu.cn/wiki/mirrors/help/docker</a></p>
<p>编辑该文件：</p>
<pre><code class="language-shell">vi /etc/docker/daemon.json  
</code></pre>
<p>在该文件中输入如下内容：</p>
<pre><code class="language-shell">{
&quot;registry-mirrors&quot;: [&quot;https://docker.mirrors.ustc.edu.cn&quot;]
}
</code></pre>
<h2 id="23-docker的启动与停止">2.3 Docker的启动与停止</h2>
<p><strong>systemctl</strong>命令是系统服务管理器指令</p>
<p>启动docker：</p>
<pre><code class="language-shell">systemctl start docker
</code></pre>
<p>停止docker：</p>
<pre><code class="language-shell">systemctl stop docker
</code></pre>
<p>重启docker：</p>
<pre><code class="language-shell">systemctl restart docker
</code></pre>
<p>查看docker状态：</p>
<pre><code class="language-shell">systemctl status docker
</code></pre>
<p>开机启动：</p>
<pre><code class="language-shell">systemctl enable docker
</code></pre>
<p>查看docker概要信息</p>
<pre><code class="language-shell">docker info
</code></pre>
<p>查看docker帮助文档</p>
<pre><code class="language-shell">docker --help
</code></pre>
<h1 id="3-常用命令">3 常用命令</h1>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1645597935806.png" alt="" loading="lazy"></figure>
<h2 id="31-镜像相关命令">3.1 镜像相关命令</h2>
<h3 id="311-查看镜像">3.1.1 查看镜像</h3>
<pre><code class="language-shell">docker images
</code></pre>
<p>REPOSITORY：镜像名称</p>
<p>TAG：镜像标签</p>
<p>IMAGE ID：镜像ID</p>
<p>CREATED：镜像的创建日期（不是获取该镜像的日期）</p>
<p>SIZE：镜像大小</p>
<p>这些镜像都是存储在Docker宿主机的/var/lib/docker目录下</p>
<h3 id="312-搜索镜像">3.1.2 搜索镜像</h3>
<p>如果你需要从网络中查找需要的镜像，可以通过以下命令搜索</p>
<pre><code class="language-shell">docker search 镜像名称
</code></pre>
<p>NAME：仓库名称</p>
<p>DESCRIPTION：镜像描述</p>
<p>STARS：用户评价，反应一个镜像的受欢迎程度</p>
<p>OFFICIAL：是否官方</p>
<p>AUTOMATED：自动构建，表示该镜像由Docker Hub自动构建流程创建的</p>
<h3 id="313-拉取镜像">3.1.3 拉取镜像</h3>
<p>拉取镜像就是从中央仓库中下载镜像到本地</p>
<pre><code class="language-shell">docker pull 镜像名称
</code></pre>
<p>例如，我要下载centos7镜像</p>
<pre><code class="language-shell">docker pull centos:7
</code></pre>
<p>Docker采用联合文件系统，不同镜像的相同文件无需再次下载：<br>
<img src="https://tinaxiawuhao.github.io/post-images/1645597963050.png" alt="" loading="lazy"></p>
<h3 id="4-删除镜像">4 删除镜像</h3>
<p>按镜像ID删除镜像</p>
<pre><code class="language-shell">docker rmi 镜像ID
</code></pre>
<p>删除所有镜像</p>
<pre><code class="language-shell">docker rmi `docker images -q`
</code></pre>
<h2 id="32-容器相关命令">3.2 容器相关命令</h2>
<h3 id="321-查看容器">3.2.1 查看容器</h3>
<p>查看正在运行的容器</p>
<pre><code class="language-shell">docker ps
</code></pre>
<p>查看所有容器</p>
<pre><code class="language-shell">docker ps –a
</code></pre>
<p>查看最后一次运行的容器</p>
<pre><code class="language-shell">docker ps –l
</code></pre>
<p>查看停止的容器</p>
<pre><code class="language-shell">docker ps -f status=exited
</code></pre>
<h3 id="322-创建与启动容器">3.2.2 创建与启动容器</h3>
<p>创建容器常用的参数说明：</p>
<p>创建容器命令：docker run</p>
<p>-i：表示运行容器</p>
<p>-t：表示容器启动后会进入其命令行。加入这两个参数后，容器创建就能登录进去。即分配一个伪终端。</p>
<p>--name :为创建的容器命名。</p>
<p>-v：表示目录映射关系（前者是宿主机目录，后者是映射到宿主机上的目录），可以使用多个－v做多个目录或文件映射。注意：最好做目录映射，在宿主机上做修改，然后共享到容器上。</p>
<p>-d：在run后面加上-d参数,则会创建一个守护式容器在后台运行（这样创建容器后不会自动登录容器，如果只加-i -t两个参数，创建后就会自动进去容器）。</p>
<p>-p：表示端口映射，前者是宿主机端口，后者是容器内的映射端口。可以使用多个-p做多个端口映射</p>
<p>（1）交互式方式创建容器</p>
<pre><code class="language-shell">docker run -it --name=容器名称 镜像名称:标签 /bin/bash
</code></pre>
<p>这时我们通过ps命令查看，发现可以看到启动的容器，状态为启动状态</p>
<p>退出当前容器</p>
<pre><code class="language-shell">exit
</code></pre>
<p>（2）守护式方式创建容器：</p>
<pre><code class="language-shell">docker run -di --name=容器名称 镜像名称:标签
</code></pre>
<p>登录守护式容器方式：</p>
<pre><code class="language-shell">docker exec -it 容器名称 (或者容器ID)  /bin/bash
</code></pre>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1645598588933.jpg" alt="" loading="lazy"></figure>
<pre><code class="language-bash">Exit                         # 从容器中退回主机 
CTRL+Q+P                     # 容器不停止退出
</code></pre>
<h3 id="323-停止与启动容器">3.2.3 停止与启动容器</h3>
<p>停止容器：</p>
<pre><code class="language-shell">docker stop 容器名称（或者容器ID）
</code></pre>
<p>启动容器：</p>
<pre><code class="language-shell">docker start 容器名称（或者容器ID）
</code></pre>
<h3 id="324-文件拷贝">3.2.4 文件拷贝</h3>
<p>如果我们需要将文件拷贝到容器内可以使用cp命令</p>
<pre><code class="language-shell">docker cp 需要拷贝的文件或目录 容器名称:容器目录
</code></pre>
<p>也可以将文件从容器内拷贝出来</p>
<pre><code class="language-shell">docker cp 容器名称:容器目录 需要拷贝的文件或目录
</code></pre>
<h3 id="325-目录挂载">3.2.5 目录挂载</h3>
<p>我们可以在创建容器的时候，将宿主机的目录与容器内的目录进行映射，这样我们就可以通过修改宿主机某个目录的文件从而去影响容器。<br>
创建容器 添加-v参数 后边为   宿主机目录:容器目录，例如：</p>
<pre><code class="language-shell">docker run -di -v /usr/local/myhtml:/usr/local/myhtml --name=mycentos3 centos:7
</code></pre>
<p>如果你共享的是多级的目录，可能会出现权限不足的提示。</p>
<p>这是因为CentOS7中的安全模块selinux把权限禁掉了，我们需要添加参数  --privileged=true  来解决挂载的目录没有权限的问题</p>
<h4 id="匿名挂载">匿名挂载</h4>
<pre><code class="language-bash">docker run -d  -v 容器内目录  镜像名/id  # 匿名挂载
</code></pre>
<p>匿名挂载后，使用<strong>docker volume ls</strong>命令查看所有挂载的卷：</p>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1645598000069.png" alt="" loading="lazy"></figure>
<p>每一个VOLUME NAME对应一个挂载的卷，由于挂载时未指定主机目录，因此无法直接找到目录。</p>
<h4 id="具名挂载">具名挂载</h4>
<pre><code class="language-bash">docker run -d  -v 卷名：容器内目录  镜像名/id  # 具名挂载
</code></pre>
<p><img src="https://tinaxiawuhao.github.io/post-images/1645598609101.png" alt="" loading="lazy"><br>
可以发现挂载的卷：volume01，并通过<strong>docker volume inspect 卷名</strong> 命令找到主机内目录：<br>
<img src="https://tinaxiawuhao.github.io/post-images/1645598023382.png" alt="" loading="lazy"></p>
<p>所有docker容器内的卷，在未指定主机内目录时，都在：<em>/var/lib/docker/volumes/卷名/_data</em> 下，可通过具名挂载可以方便的找到卷，因此广泛使用这种方式进行挂载。</p>
<h4 id="数据卷容器">数据卷容器</h4>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1645598045974.png" alt="" loading="lazy"></figure>
<pre><code class="language-bash">docker run -it --name container02 --volumes from container01 镜像名/id  # 将两个容器进行挂载
</code></pre>
<h3 id="326-查看容器ip地址">3.2.6 查看容器IP地址</h3>
<p>我们可以通过以下命令查看容器运行的各种数据</p>
<pre><code class="language-shell">docker inspect 容器名称（容器ID） 
</code></pre>
<p>也可以直接执行下面的命令直接输出IP地址</p>
<pre><code class="language-shell">docker inspect --format='{{.NetworkSettings.IPAddress}}' 容器名称（容器ID）
</code></pre>
<h3 id="327-删除容器">3.2.7 删除容器</h3>
<p>删除指定的容器：</p>
<pre><code class="language-shell">docker rm 容器名称（容器ID）
</code></pre>
<h3 id="328-其他命令">3.2.8 其他命令</h3>
<pre><code class="language-bash">docker start/restart/stop/kill 容器名/id               
docker logs -tf --tail 显示的日志条数 容器名/id  # 查看日志
docker top 容器名/id                 # 查看容器中的进程信息
docker inspect 容器名/id             # 查看镜像的元数据
docker exec -it 容器名/id /bin/bash  # 通常容器以后台方式运行，需要进入其中修改配置：进入容器后开启一个新终端         
docker attach 容器名/id              # 进入容器正在执行的终端
docker cp 容器名/id:容器内路径 主机文件路径       # 从容器内拷贝文件到主机上
</code></pre>
<h1 id="4-docker镜像详解">4  Docker镜像详解</h1>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1645598065040.png" alt="" loading="lazy"></figure>
<h2 id="unionfs联合文件系统">UnionFS（联合文件系统）</h2>
<ul>
<li>联合文件系统（UnionFS）是一种分层、轻量级并且高性能的文件系统，它支持对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下。联合文件系统是 Docker 镜像的基础。镜像可以通过分层来进行继承，基于基础镜像（没有父镜像），可以制作各种具体的应用镜像。</li>
<li>特性：一次同时加载多个文件系统，但从外面看起来只能看到一个文件系统。联合加载会把各层文件系统叠加起来，这样最终的文件系统会包含所有底层的文件和目录。</li>
</ul>
<h2 id="镜像加载原理">镜像加载原理</h2>
<p>Docker的镜像实际由一层一层的文件系统组成：</p>
<ul>
<li>bootfs（boot file system）主要包含bootloader和kernel。bootloader主要是引导加载kernel，完成后整个内核就都在内存中了。此时内存的使用权已由bootfs转交给内核，系统卸载bootfs。可以被不同的Linux发行版公用。</li>
<li>rootfs（root file system），包含典型Linux系统中的/dev，/proc，/bin，/etc等标准目录和文件。rootfs就是各种不同操作系统发行版（Ubuntu，Centos等）。因为底层直接用Host的kernel，rootfs只包含最基本的命令，工具和程序就可以了。</li>
<li>分层理解<br>
所有的Docker镜像都起始于一个基础镜像层，当进行修改或增加新的内容时，就会在当前镜像层之上，创建新的容器层。<br>
容器在启动时会在镜像最外层上建立一层可读写的容器层（R/W），而镜像层是只读的（R/O）。<br>
<img src="https://tinaxiawuhao.github.io/post-images/1645598082318.png" alt="" loading="lazy"></li>
</ul>
<pre><code class="language-bash">docker commit -m=&quot;描述信息&quot; -a=&quot;作者&quot; 容器id 目标镜像名:[tag]  # 编辑容器后提交容器成为一个新镜像
</code></pre>
<h1 id="4-应用部署">4 应用部署</h1>
<h2 id="41-mysql部署">4.1 MySQL部署</h2>
<p>（1）拉取mysql镜像</p>
<pre><code class="language-shell">docker pull centos/mysql-57-centos7
</code></pre>
<p>（2）创建容器</p>
<pre><code class="language-shell">docker run -di --name=tensquare_mysql -p 33306:3306 -e MYSQL_ROOT_PASSWORD=123456 mysql
</code></pre>
<p>-p 代表端口映射，格式为  宿主机映射端口:容器运行端口</p>
<p>-e 代表添加环境变量  MYSQL_ROOT_PASSWORD  是root用户的登陆密码</p>
<p>（3）远程登录mysql</p>
<p>连接宿主机的IP  ,指定端口为33306</p>
<h2 id="42-tomcat部署">4.2 tomcat部署</h2>
<p>（1）拉取镜像</p>
<pre><code class="language-shell">docker pull tomcat:7-jre7
</code></pre>
<p>（2）创建容器</p>
<p>创建容器  -p表示地址映射</p>
<pre><code class="language-shell">docker run -di --name=mytomcat -p 9000:8080 
-v /usr/local/webapps:/usr/local/tomcat/webapps tomcat:7-jre7
</code></pre>
<h2 id="43-nginx部署">4.3 Nginx部署</h2>
<p>（1）拉取镜像</p>
<pre><code class="language-shell">docker pull nginx
</code></pre>
<p>（2）创建Nginx容器</p>
<pre><code class="language-shell">docker run -di --name=mynginx -p 80:80 nginx
</code></pre>
<h2 id="44-redis部署">4.4 Redis部署</h2>
<p>（1）拉取镜像</p>
<pre><code class="language-shell">docker pull redis
</code></pre>
<p>（2）创建容器</p>
<pre><code class="language-shell">docker run -di --name=myredis -p 6379:6379 redis
</code></pre>
<h2 id="45-redis集群部署">4.5 Redis集群部署</h2>
<pre><code class="language-shell"># 创建网卡
docker network create redis --subnet 172.38.0.0/16
# 通过脚本创建六个redis配置
for port in $(seq 1 6);\
do \
mkdir -p /mydata/redis/node-${port}/conf
touch /mydata/redis/node-${port}/conf/redis.conf
cat &lt;&lt; EOF &gt;&gt; /mydata/redis/node-${port}/conf/redis.conf
port 6379
bind 0.0.0.0
cluster-enabled yes
cluster-config-file nodes.conf
cluster-node-timeout 5000
cluster-announce-ip 172.38.0.1${port}
cluster-announce-port 6379
cluster-announce-bus-port 16379
appendonly yes
EOF
done

# 通过脚本运行六个redis
for port in $(seq 1 6);\
docker run -p 637${port}:6379 -p 1667${port}:16379 --name redis-${port} \
-v /mydata/redis/node-${port}/data:/data \
-v /mydata/redis/node-${port}/conf/redis.conf:/etc/redis/redis.conf \
-d --net redis --ip 172.38.0.1${port} redis:5.0.9-alpine3.11 redis-server /etc/redis/redis.conf
docker exec -it redis-1 /bin/sh #redis默认没有bash
redis-cli --cluster create 172.38.0.11:6379 172.38.0.12:6379 172.38.0.13:6379 172.38.0.14:6379 172.38.0.15:6379 172.38.0.16:6379  --cluster-replicas 1
</code></pre>
<h1 id="5-迁移与备份">5 迁移与备份</h1>
<h2 id="51-容器保存为镜像">5.1 容器保存为镜像</h2>
<p>我们可以通过以下命令将容器保存为镜像</p>
<pre><code class="language-shell">docker commit mynginx mynginx_i
</code></pre>
<h2 id="52-镜像备份">5.2 镜像备份</h2>
<p>我们可以通过以下命令将镜像保存为tar 文件</p>
<pre><code class="language-shell">docker  save -o mynginx.tar mynginx_i
</code></pre>
<h2 id="53-镜像恢复与迁移">5.3 镜像恢复与迁移</h2>
<p>首先我们先删除掉mynginx_img镜像  然后执行此命令进行恢复</p>
<pre><code class="language-shell">docker load -i mynginx.tar
</code></pre>
<p>-i 输入的文件</p>
<p>执行后再次查看镜像，可以看到镜像已经恢复</p>
<h1 id="6-dockerfile">6 Dockerfile</h1>
<h2 id="61-什么是dockerfile">6.1 什么是Dockerfile</h2>
<p>Dockerfile是由一系列命令和参数构成的脚本，这些命令应用于基础镜像并最终创建一个新的镜像。</p>
<p>1、对于开发人员：可以为开发团队提供一个完全一致的开发环境；<br>
2、对于测试人员：可以直接拿开发时所构建的镜像或者通过Dockerfile文件构建一个新的镜像开始工作了；<br>
3、对于运维人员：在部署时，可以实现应用的无缝移植。</p>
<h2 id="62-常用命令">6.2 常用命令</h2>
<table>
<thead>
<tr>
<th>命令</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr>
<td>FROM image_name:tag</td>
<td>定义了使用哪个基础镜像启动构建流程</td>
</tr>
<tr>
<td>MAINTAINER user_name</td>
<td>声明镜像的创建者</td>
</tr>
<tr>
<td>ENV key value</td>
<td>设置环境变量 (可以写多条)</td>
</tr>
<tr>
<td>RUN command</td>
<td>是Dockerfile的核心部分(可以写多条)</td>
</tr>
<tr>
<td>ADD source_dir/file dest_dir/file</td>
<td>将宿主机的文件复制到容器内，如果是一个压缩文件，将会在复制后自动解压</td>
</tr>
<tr>
<td>COPY source_dir/file dest_dir/file</td>
<td>和ADD相似，但是如果有压缩文件并不能解压</td>
</tr>
<tr>
<td>WORKDIR path_dir</td>
<td>设置工作目录</td>
</tr>
</tbody>
</table>
<h2 id="63-使用脚本创建镜像">6.3 使用脚本创建镜像</h2>
<p>步骤：</p>
<p>（1）创建目录</p>
<pre><code class="language-shell">mkdir –p /usr/local/dockerjdk8
</code></pre>
<p>（2）下载jdk-8u171-linux-x64.tar.gz并上传到服务器（虚拟机）中的/usr/local/dockerjdk8目录</p>
<p>（3）创建文件Dockerfile  <code>vi Dockerfile</code></p>
<pre><code class="language-shell">#依赖镜像名称和ID
FROM centos:7
#指定镜像创建者信息
MAINTAINER ITCAST
#切换工作目录
WORKDIR /usr
RUN mkdir  /usr/local/java
#ADD 是相对路径jar,把java添加到容器中
ADD jdk-8u171-linux-x64.tar.gz /usr/local/java/

#配置java环境变量
ENV JAVA_HOME /usr/local/java/jdk1.8.0_171
ENV JRE_HOME $JAVA_HOME/jre
ENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib:$CLASSPATH
ENV PATH $JAVA_HOME/bin:$PATH
</code></pre>
<p>（4）执行命令构建镜像</p>
<pre><code class="language-shell">docker build -t='jdk1.8' .
</code></pre>
<p>注意后边的空格和点，不要省略</p>
<p>（5）查看镜像是否建立完成</p>
<pre><code class="language-shell">docker images
</code></pre>
<h1 id="7-docker私有仓库">7 Docker私有仓库</h1>
<h2 id="71-私有仓库搭建与配置">7.1 私有仓库搭建与配置</h2>
<p>（1）拉取私有仓库镜像（此步省略）</p>
<pre><code class="language-shell">docker pull registry
</code></pre>
<p>（2）启动私有仓库容器</p>
<pre><code class="language-shell">docker run -di --name=registry -p 5000:5000 registry
</code></pre>
<p>（3）打开浏览器 输入地址http://192.168.184.141:5000/v2/_catalog看到<code>{&quot;repositories&quot;:[]}</code> 表示私有仓库搭建成功并且内容为空</p>
<p>（4）修改daemon.json</p>
<pre><code class="language-shell">vi /etc/docker/daemon.json
</code></pre>
<p>添加以下内容，保存退出。</p>
<pre><code class="language-json">{&quot;insecure-registries&quot;:[&quot;192.168.184.141:5000&quot;]} 
</code></pre>
<p>此步用于让 docker信任私有仓库地址</p>
<p>（5）重启docker 服务</p>
<pre><code class="language-shell">systemctl restart docker
</code></pre>
<h2 id="72-镜像上传至私有仓库">7.2 镜像上传至私有仓库</h2>
<p>（1）标记此镜像为私有仓库的镜像</p>
<pre><code class="language-shell">docker tag jdk1.8 192.168.184.141:5000/jdk1.8
</code></pre>
<p>（2）再次启动私服容器</p>
<pre><code class="language-shell">docker start registry
</code></pre>
<p>（3）上传标记的镜像</p>
<pre><code class="language-shell">docker push 192.168.184.141:5000/jdk1.8
</code></pre>
<h1 id="8-docker网络">8 Docker网络</h1>
<h2 id="81-理解doker0">8.1 理解Doker0</h2>
<p>通过命令<strong>ip addr</strong>查看本地ip地址，我们发现除了本机回环地址和埃里远的内网地址外，还多了一个网卡：Docker0，这是Docker服务启动后自动生成的。<br>
<img src="https://tinaxiawuhao.github.io/post-images/1645598117584.png" alt="" loading="lazy"><br>
而如果进入一个正在后台运行的tomcat容器，同样使用<strong>ip addr</strong>命令，发现容器得到了一个新的网络：<strong>12: eth@if13</strong>，ip地址：<strong>172.17.0.2</strong>。这是Docker在容器启动时为其分配的。<br>
<img src="https://tinaxiawuhao.github.io/post-images/1645598157386.png" alt="" loading="lazy"><br>
思考一个问题：此时我们的linux主机可以ping通容器内部（<strong>172.17.0.2</strong>）吗？（<strong>注意与容器暴露端口相区分</strong>)<br>
<img src="https://tinaxiawuhao.github.io/post-images/1645598173437.png" alt="" loading="lazy"></p>
<ul>
<li>linux可以ping通docker容器内部，因为docker0的ip地址为<strong>172.17.0.1</strong>，容器为<strong>172.17.0.2</strong>。</li>
<li>原理：我们每启动一个docker容器，docker就会给容器分配一个默认的可用ip，我们只要安装了docker，就会有一个网卡docker0(bridge)。网卡采用桥接模式，并使用veth-pair技术（veth-pair就是一堆虚拟设备接口，成对出现，一段连着协议，一段彼此相连，充当一个桥梁。）。</li>
<li>这时我们退出容器，回到主机再次观察主机的ip地址：<br>
<img src="https://tinaxiawuhao.github.io/post-images/1645598197831.png" alt="" loading="lazy"><br>
我们惊奇地发现了一个新网络<strong>13: vethda1df4b@if12</strong>，对应容器内网络地址的<strong>12: eth@if13</strong>。</li>
<li>容器和容器之间是可以互相ping通的：容器1→Docker0→容器2<br>
<img src="https://tinaxiawuhao.github.io/post-images/1645598226949.png" alt="" loading="lazy"><br>
docker中的所有网络接口都是虚拟的 ，转发效率高。删除容器后，对应的网桥也随之删除。</li>
</ul>
<h2 id="82-link">8.2 --link</h2>
<p>若编写一个微服务并连接数据库，如果数据库ip改变，如何根据容器名而不是ip访问容器？显然，直接使用容器名是无法ping通容器内部的：<br>
<img src="https://tinaxiawuhao.github.io/post-images/1645598261672.png" alt="" loading="lazy"><br>
这时我们可以在容器启动命令中加入一个选项：<strong>--link</strong>，使得我们可以根据容器名来访问容器。</p>
<pre><code class="language-bash">docker run -d -P --link 容器名/id 镜像名/id
</code></pre>
<p><img src="https://tinaxiawuhao.github.io/post-images/1645598278472.png" alt="" loading="lazy"><br>
然而反向就不可以ping通，这是因为--link的本质是把需要连接的容器名/id写入启动容器的配置文件中，即增加了一个ip和容器名/id的映射：<br>
<img src="https://tinaxiawuhao.github.io/post-images/1645598294726.png" alt="" loading="lazy"><br>
目前已经不建议使用这种方式。</p>
<h2 id="83-自定义网络">8.3 自定义网络</h2>
<p>我们使用命令：</p>
<pre><code class="language-bash">docker network ls    # 查看所有的docker网络
</code></pre>
<p><img src="https://tinaxiawuhao.github.io/post-images/1645598309260.png" alt="" loading="lazy"><br>
docker中的网络模式有：</p>
<ul>
<li>bridge：桥接（docker默认）/</li>
<li>none：不配置网络 /</li>
<li>host：和宿主机共享网络</li>
</ul>
<p><strong>docker run</strong> 命令默认带有一个参数--net bridge，此处的bridge指的就是docker0。如果我们不想使用docker0，那如何创建一个新的网络呢？</p>
<pre><code class="language-bash">docker  network create --driver 网络模式 --subnet 子网ip --gateway 网关 网络名         
</code></pre>
<p><img src="https://tinaxiawuhao.github.io/post-images/1645598354804.png" alt="" loading="lazy"><br>
我们不仅在<strong>docker network ls</strong>命令下发现了这个新创建的网络newnet，还可以使用<strong>docker network inspect</strong>命令查看其详细信息，包括了我们创建时定义的子网ip和网关：<br>
<img src="https://tinaxiawuhao.github.io/post-images/1645598372176.png" alt="" loading="lazy"><br>
只要两个容器启动时都通过 <strong>--net</strong>，选用了同一个已创建的网络，不同容器间即可通过ip地址或容器名/id连通:<br>
<img src="https://tinaxiawuhao.github.io/post-images/1645598422921.png" alt="" loading="lazy"></p>
<h2 id="84-网络连通">8.4 网络连通</h2>
<p><img src="https://tinaxiawuhao.github.io/post-images/1645598436013.png" alt="" loading="lazy"><br>
对于建立在不同网络下(docker0, newnet)的两个容器tomcat01和tomcat02，他们的网段不同，因此是无法彼此ping通容器内部的：<br>
<img src="https://tinaxiawuhao.github.io/post-images/1645598445887.png" alt="" loading="lazy"><br>
这时我们需要通过<strong>docker network connect</strong>命令打通容器与网络之间的连接：</p>
<pre><code class="language-bash">docker network connect 网络名 容器名/id
</code></pre>
<p><img src="https://tinaxiawuhao.github.io/post-images/1645598457014.png" alt="" loading="lazy"><br>
这个功能类似于将一个容器赋予多个ip地址，同样可以用<strong>docker network inspect</strong>命令查看网络连通后，该网络的变化：<br>
<img src="https://tinaxiawuhao.github.io/post-images/1645598464633.png" alt="" loading="lazy"><br>
原本newnet网络中只含有tomcat02，现在增加了tomcat01，因此可以连通。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Git 操作命令清单]]></title>
        <id>https://tinaxiawuhao.github.io/post/awhwcpAEp/</id>
        <link href="https://tinaxiawuhao.github.io/post/awhwcpAEp/">
        </link>
        <updated>2022-01-12T02:26:35.000Z</updated>
        <content type="html"><![CDATA[<p>git工作流程图</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1641954851042.jpg" alt="" loading="lazy"></figure>
<p>下面是常用 的Git 命令清单。几个专用名词的译名如下：</p>
<ul>
<li>Workspace：工作区</li>
<li>Index / Stage：暂存区</li>
<li>Repository：仓库区（或本地仓库）</li>
<li>Remote：远程仓库</li>
</ul>
<h3 id="一-新建代码库">一、新建代码库</h3>
<pre><code class="language-shell"># 在当前目录新建一个Git代码库
$ git init

# 新建一个目录，将其初始化为Git代码库
$ git init [project-name]

# 下载一个项目和它的整个代码历史
$ git clone [url]
</code></pre>
<h3 id="二-配置">二、配置</h3>
<p>Git的设置文件为<code>.gitconfig</code>，它可以在用户主目录下（全局配置），也可以在项目目录下（项目配置）。</p>
<pre><code class="language-shell"># 显示当前的Git配置
$ git config --list

# 编辑Git配置文件
$ git config -e [--global]

# 设置提交代码时的用户信息
$ git config [--global] user.name &quot;[name]&quot;
$ git config [--global] user.email &quot;[email address]&quot;
</code></pre>
<h3 id="三-增加删除文件">三、增加/删除文件</h3>
<pre><code class="language-shell"># 添加指定文件到暂存区
$ git add [file1] [file2] ...

# 添加指定目录到暂存区，包括子目录
$ git add [dir]

# 添加当前目录的所有文件到暂存区
$ git add .

# 添加每个变化前，都会要求确认
# 对于同一个文件的多处变化，可以实现分次提交
$ git add -p

# 删除工作区文件，并且将这次删除放入暂存区
$ git rm [file1] [file2] ...

# 停止追踪指定文件，但该文件会保留在工作区
$ git rm --cached [file]

# 改名文件，并且将这个改名放入暂存区
$ git mv [file-original] [file-renamed]
</code></pre>
<h3 id="四-代码提交">四、代码提交</h3>
<pre><code class="language-shell"># 提交暂存区到仓库区
$ git commit -m [message]

# 提交暂存区的指定文件到仓库区
$ git commit [file1] [file2] ... -m [message]

# 提交工作区自上次commit之后的变化，直接到仓库区
$ git commit -a

# 提交时显示所有diff信息
$ git commit -v

# 使用一次新的commit，替代上一次提交
# 如果代码没有任何新变化，则用来改写上一次commit的提交信息
$ git commit --amend -m [message]

# 重做上一次commit，并包括指定文件的新变化
$ git commit --amend [file1] [file2] ...
</code></pre>
<h3 id="五-分支">五、分支</h3>
<pre><code class="language-shell"># 列出所有本地分支
$ git branch

# 列出所有远程分支
$ git branch -r

# 列出所有本地分支和远程分支
$ git branch -a

# 新建一个分支，但依然停留在当前分支
$ git branch [branch-name]

# 新建一个分支，并切换到该分支
$ git checkout -b [branch]

# 新建一个分支，指向指定commit
$ git branch [branch] [commit]

# 新建一个分支，与指定的远程分支建立追踪关系
$ git branch --track [branch] [remote-branch]

# 切换到指定分支，并更新工作区
$ git checkout [branch-name]

# 切换到上一个分支
$ git checkout -

# 建立追踪关系，在现有分支与指定的远程分支之间
$ git branch --set-upstream [branch] [remote-branch]

# 合并指定分支到当前分支
$ git merge [branch]

# 选择一个commit，合并进当前分支
$ git cherry-pick [commit]

# 删除分支
$ git branch -d [branch-name]

# 删除远程分支
$ git push origin --delete [branch-name]
$ git branch -dr [remote/branch]
</code></pre>
<h3 id="六-标签">六、标签</h3>
<pre><code class="language-shell"># 列出所有tag
$ git tag

# 新建一个tag在当前commit
$ git tag [tag]

# 新建一个tag在指定commit
$ git tag [tag] [commit]

# 删除本地tag
$ git tag -d [tag]

# 删除远程tag
$ git push origin :refs/tags/[tagName]

# 查看tag信息
$ git show [tag]

# 提交指定tag
$ git push [remote] [tag]

# 提交所有tag
$ git push [remote] --tags

# 新建一个分支，指向某个tag
$ git checkout -b [branch] [tag]
</code></pre>
<h3 id="七-查看信息">七、查看信息</h3>
<pre><code class="language-shell"># 显示有变更的文件
$ git status

# 显示当前分支的版本历史
$ git log

# 显示commit历史，以及每次commit发生变更的文件
$ git log --stat

# 搜索提交历史，根据关键词
$ git log -S [keyword]

# 显示某个commit之后的所有变动，每个commit占据一行
$ git log [tag] HEAD --pretty=format:%s

# 显示某个commit之后的所有变动，其&quot;提交说明&quot;必须符合搜索条件
$ git log [tag] HEAD --grep feature

# 显示某个文件的版本历史，包括文件改名
$ git log --follow [file]
$ git whatchanged [file]

# 显示指定文件相关的每一次diff
$ git log -p [file]

# 显示过去5次提交
$ git log -5 --pretty --oneline

# 显示所有提交过的用户，按提交次数排序
$ git shortlog -sn

# 显示指定文件是什么人在什么时间修改过
$ git blame [file]

# 显示暂存区和工作区的差异
$ git diff

# 显示暂存区和上一个commit的差异
$ git diff --cached [file]

# 显示工作区与当前分支最新commit之间的差异
$ git diff HEAD

# 显示两次提交之间的差异
$ git diff [first-branch]...[second-branch]

# 显示今天你写了多少行代码
$ git diff --shortstat &quot;@{0 day ago}&quot;

# 显示某次提交的元数据和内容变化
$ git show [commit]

# 显示某次提交发生变化的文件
$ git show --name-only [commit]

# 显示某次提交时，某个文件的内容
$ git show [commit]:[filename]

# 显示当前分支的最近几次提交
$ git reflog
</code></pre>
<h3 id="八-远程同步">八、远程同步</h3>
<pre><code class="language-shell"># 下载远程仓库的所有变动
$ git fetch [remote]

# 显示所有远程仓库
$ git remote -v

# 显示某个远程仓库的信息
$ git remote show [remote]

# 增加一个新的远程仓库，并命名
$ git remote add [shortname] [url]

# 取回远程仓库的变化，并与本地分支合并
$ git pull [remote] [branch]

# 上传本地指定分支到远程仓库
$ git push [remote] [branch]

# 强行推送当前分支到远程仓库，即使有冲突
$ git push [remote] --force

# 推送所有分支到远程仓库
$ git push [remote] --all
</code></pre>
<h3 id="九-撤销">九、撤销</h3>
<pre><code class="language-shell"># 恢复暂存区的指定文件到工作区
$ git checkout [file]

# 恢复某个commit的指定文件到暂存区和工作区
$ git checkout [commit] [file]

# 恢复暂存区的所有文件到工作区
$ git checkout .

# 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变
$ git reset [file]

# 重置暂存区与工作区，与上一次commit保持一致
$ git reset --hard

# 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变
$ git reset [commit]

# 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致
$ git reset --hard [commit]

# 重置当前HEAD为指定commit，但保持暂存区和工作区不变
$ git reset --keep [commit]

# 新建一个commit，用来撤销指定commit
# 后者的所有变化都将被前者抵消，并且应用到当前分支
$ git revert [commit]

# 暂时将未提交的变化移除，稍后再移入
$ git stash
$ git stash pop
</code></pre>
<h3 id="十-其他">十、其他</h3>
<pre><code class="language-shell"># 生成一个可供发布的压缩包
$ git archive
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[jar包内类动态加载]]></title>
        <id>https://tinaxiawuhao.github.io/post/E2kaihQ5a/</id>
        <link href="https://tinaxiawuhao.github.io/post/E2kaihQ5a/">
        </link>
        <updated>2022-01-04T03:13:15.000Z</updated>
        <content type="html"><![CDATA[<h3 id="实体对象">实体对象</h3>
<pre><code class="language-java">public class CmptDef {
    private String idCmptDef; //组件在DB里的唯一ID号
    private String name;//组件的唯一名称，只能是字母、数字、下划线组成，大于1小雨50，通常为Jar的名字
    private CmptCategory cmptCategory; //种类
    private String fullQualifiedName; //组件入口类全限定名
    private String extraParas; //组件额外参数
    private String formUrl; //组件自定义表单
    private Float version = 1.0f; //组件版本
    private CmptExecutePos executePos = CmptExecutePos.PRE; //组件在网关中执行的位置
    private Integer priority = 100; //组件在相同位置的执行优先级，数字越小越高
    private Integer timeout = 1000;//组件执行超时时间，单位毫秒
    private String description; //组件描述
    private Boolean defaultVersion; //是否是默认有效版本
    private CmptStatus cmptStatus = CmptStatus.editing; // 组件状态
    private String remarks; // 组件发布时需要填写备注信息
    private String code; // 组件code，同一个组件的多个版本的code是一样的
    private Date releaseTime; // 组件发布时间
    private CustomFormCode customFormCode; // 自定义表单里类型
    private String cmptType; //组件类型（特殊组件|普通组件|默认组件）
}
/**
 * 组件类型。
 */
public enum CmptCategory {
    AUTHENTICATION, //认证
    AUTHORIZATION, //鉴权
    FLOW_MANAGEMENT, //流量管理
    REQUEST_COUNT_MANAGEMENT, //请求次数管理
    CACHE, //缓存
    ROUTER, //路由
    TRANSFORM, //数据转换
    LOGGER, //日志
    OTHER//其它
}
/**
 * 组件执行的位置。
 */
public enum CmptExecutePos {
    PRE, //调用上游服务前
    ROUTING, //调用中
    AFTER //调用后
}
public enum CmptStatus {
    editing, //编辑中
    published, //已经发布
    offline //已经下线
}
/**
 * 组件风格。
 */
public enum CustomFormCode {
    RESTFUL_FORM,
    SQL_FORM,
    DUBBO_FORM,
    OTHER,
    MQ_FORM,
    WEBSERVICE_FORM
}
</code></pre>
<h3 id="方法接口">方法接口</h3>
<pre><code class="language-java">public interface ICmptService {
    /**
     * 根据组件类名和版本从缓存中获取组件,如果不存在则尝试动态加载组件类，实例化并刷新缓存后再获取，还是不存在则返回null；
     * 另外配置更新会有单独的线程刷新缓存。
     *
     * @return
     */
    ICmpt getCmptInstance(final CmptDef cmptDef);

    /**
     * 刷新API关联的组件配置信息
     *
     * @param apis
     * @param ignoreRefreshTime
     * @return
     */
    boolean refreshCmptInstanceCache(List&lt;Api&gt; apis, boolean ignoreRefreshTime);

    /**
     * 删除组件实例缓存
     *
     * @param fullQualifiedName
     * @param code
     */
    void removeCmpt(final String fullQualifiedName, final Float version, final String code);
}
</code></pre>
<h3 id="方法实现">方法实现</h3>
<pre><code class="language-java">@Service
public class CmptServiceImpl implements ICmptService {
    private static Logger logger = LoggerFactory.getLogger(CmptServiceImpl.class);

    @Value(&quot;${cmpt.dynamicLoadCmptClass}&quot;)
    private boolean dynamicLoadCmptClass;

    @Autowired
    private ICmptDefService cmptDefService;

    @Override
    public synchronized ICmpt getCmptInstance(final CmptDef cmptDef) {
        ICmpt cmpt = CmptInstanceHolder.getInstance().getCmpt(cmptDef.getFullQualifiedName(), cmptDef.getVersion(), cmptDef.getCode());
        if (null == cmpt) {
            if (logger.isDebugEnabled()) {
                logger.debug(&quot;反射拿到实例&gt;&gt;&gt; &quot; + cmptDef.getFullQualifiedName());
            }
            if (this.dynamicLoadCmptClass) {
                cmpt = CmptClassLoaderUtil.newInstance(cmptDef);
            } else {
                try {
                    Class clazz = Class.forName(cmptDef.getFullQualifiedName());
                    cmpt = (ICmpt) clazz.newInstance();
                } catch (Exception e) {
                    e.printStackTrace();
                }
            }
            if (null != cmpt) {
                if (cmpt instanceof AbstractCmpt) {
                    //设置版本号
                    ((AbstractCmpt) cmpt).setVersion(cmptDef.getVersion());
                    ((AbstractCmpt) cmpt).setIdCmptDef(cmptDef.getIdCmptDef());
                }
                CmptInstanceHolder.getInstance().addEntry(cmpt, cmptDef.getFullQualifiedName(), cmptDef.getVersion(), cmptDef.getCode());
            }
        } else {
            if (logger.isDebugEnabled()) {
                logger.debug(&quot;缓存拿到实例&gt;&gt;&gt; &quot; + cmptDef.getFullQualifiedName());
            }
        }
        if (null != cmpt) {
            ApplicationContext context = SpringContextHolder.getContext();
            if (null != context) {
                ZkClient zkClient = context.getBean(ZkClient.class);
                if (null != zkClient) {
                    BaseListener listener = zkClient.getListener();
                    listener.addObserver((AbstractCmpt) cmpt);
                }
            }
        }
        return cmpt;
    }

    @Override
    public boolean refreshCmptInstanceCache(List&lt;Api&gt; apis, boolean ignoreRefreshTime) {
        return false;
    }

    @Override
    public synchronized void removeCmpt(final String fullQualifiedName, final Float version, final String code) {
        ICmpt cmpt = CmptInstanceHolder.getInstance().getCmpt(fullQualifiedName, version, code);
        if (null != cmpt) {
            ApplicationContext context = SpringContextHolder.getContext();
            if (null != context) {
                ZkClient zkClient = context.getBean(ZkClient.class);
                if (null != zkClient) {
                    BaseListener listener = zkClient.getListener();
                    listener.deleteObserver((AbstractCmpt) cmpt);
                }
            }
            cmpt.destroy();
            CmptDef cmptDef = CmptDefHolder.getInstance().getCmptDef(fullQualifiedName, version, code);
            if (null == cmptDef) {
                cmptDef = new CmptDef();
                cmptDef.setFullQualifiedName(fullQualifiedName);
                cmptDef.setVersion(version);
                cmptDef.setCode(code);
            }
            //删除引用实体
            CmptInstanceHolder.getInstance().removeEntry(fullQualifiedName, version, code);
            cmpt = null;

            String jarPath = CmptClassLoaderUtil.getJarPath(cmptDef);
            if (logger.isDebugEnabled()) {
                logger.debug(&quot;尝试卸载jar包: &quot; + jarPath);
            }
            CmptClassLoaderManager.unLoadJar(jarPath);
        }
        CmptInstanceHolder.getInstance().removeEntry(fullQualifiedName, version, code);
    }
}
</code></pre>
<h3 id="工具类">工具类</h3>
<pre><code class="language-java">/**
 * 组件配置缓存持有者
 */
public class CmptInstanceHolder {
    private static CmptInstanceHolder cmptInstanceHolder = new CmptInstanceHolder();
    //API所关联的组件配置缓存 key: fullQualifiedName    value: ICmpt
    private Map&lt;String, ICmpt&gt; cmpts = new ConcurrentHashMap&lt;&gt;();

    private CmptInstanceHolder() {
    }

    public static CmptInstanceHolder getInstance() {
        return CmptInstanceHolder.cmptInstanceHolder;
    }

    /**
     * 根据类名加版本从缓存中获取组件实例,如果不存在直接返回null；
     *
     * @return
     */
    public ICmpt getCmpt(final String fullQualifiedName, final Float version, String code) {
        final String key = buildKey(fullQualifiedName, version, code);
        return this.cmpts.get(key);
    }

    /**
     * 添加对象
     */
    public void addEntry(final ICmpt cmpt, final String fullQualifiedName, final Float version, final String code) {
        if (cmpt == null || StringUtils.isEmpty(fullQualifiedName) || StringUtils.isEmpty(code)) {
            return;
        }
        final String key = buildKey(fullQualifiedName, version, code);
        removeEntry(fullQualifiedName, version, code);
        this.cmpts.put(key, cmpt);
    }

    private String buildKey(final String fullQualifiedName, Float version, final String code) {
        return fullQualifiedName + &quot;.&quot; + version + code;
    }

    public void removeEntry(final String fullQualifiedName, final Float version, final String code) {
        ICmpt remove = this.cmpts.remove(buildKey(fullQualifiedName, version, code));
        if (null != remove) {
            remove.destroy();
        }
    }

    /**
     * 获取所有的组件实例
     * @return
     */
    public Map&lt;String, ICmpt&gt; getAllCmpts(){
        return this.cmpts;
    }
}
</code></pre>
<pre><code class="language-java">public class CmptClassLoaderUtil {

    private static Logger logger = LoggerFactory.getLogger(CmptClassLoaderUtil.class);

    public static ICmpt newInstance(final CmptDef cmptDef) {
        ICmpt cmpt = null;
        try {
            final String jarPath = getJarPath(cmptDef);
            logger.info(&quot;尝试载入jar包,jar包路径: &quot; + jarPath);
            //加载依赖jar
            CmptClassLoader cmptClassLoader = CmptClassLoaderManager.loadJar(cmptDef.getIdCmptDef(), jarPath, true);
            // 创建实例
            if (null != cmptClassLoader) {
                cmpt = LoadClassUtil.newObject(cmptDef, ICmpt.class, cmptClassLoader);
            } else {
                logger.error(&quot;加载组件jar包失败! jarPath: &quot; + jarPath);
            }
        } catch (Exception e) {
            logger.error(&quot;组件类加载失败，请检查类名和版本是否正确。ClassName=&quot; + cmptDef.getFullQualifiedName() + &quot;, Version=&quot; + cmptDef.getVersion());
            e.printStackTrace();
        }
        return cmpt;
    }

    public static String getJarPath(final CmptDef cmptDef) {
        StringBuffer sb = new StringBuffer();
        sb.append(AppConfigUtil.getValue(&quot;app.home&quot;));
        sb.append(AppConfigUtil.getValue(&quot;cmpt.location&quot;));
        sb.append(&quot;/&quot;);
        //开发中关闭多级目录,不好部署
        sb.append(cmptDef.getCode());
        sb.append(&quot;/&quot;);
        sb.append(cmptDef.getVersion());
        sb.append(&quot;/&quot;);
        String[] split = cmptDef.getFullQualifiedName().split(&quot;\\.&quot;);
        sb.append(split[split.length - 1]);
        sb.append(&quot;_&quot;);
        sb.append(cmptDef.getVersion());
        sb.append(&quot;.jar&quot;);
        if (logger.isDebugEnabled()) {
            logger.debug(&quot;构建jar包路径: &quot; + sb.toString());
        }
        return sb.toString();
    }

}
</code></pre>
<pre><code class="language-shell">#linux版home目录
app.home=/work/sharestore
#组件资源存放路径，&lt;home&gt;/cmpt/&lt;code&gt;/&lt;version&gt;/&lt;name&gt;_&lt;version&gt;.jar,html
cmpt.location=/cmpt
</code></pre>
<pre><code class="language-java">/**
 * 类加载器管理, 加载, 卸载jar包
 */
public class CmptClassLoaderManager {

    private static final Logger logger = Logger.getLogger(CmptClassLoaderManager.class);

    private static Map&lt;String, CmptClassLoader&gt; classLoaderMap = new ConcurrentHashMap&lt;&gt;();

    private CmptClassLoaderManager() {
    }

    /**
     * 载入Jar包, 判断是否重新载入Jar包
     *
     * @param fileName
     * @param isReloadJar
     * @return
     */
    public static CmptClassLoader loadJar(String IdCmptDef, String fileName, boolean isReloadJar) {
        fileName = FileUtil.fixFileName(fileName);
        CmptClassLoader cmptClassLoader = classLoaderMap.get(IdCmptDef);
        if (isReloadJar || null == cmptClassLoader) {
            if (logger.isDebugEnabled()) {
                logger.debug(&quot;从文件载入jar组件&quot;);
            }
            return loadJar(IdCmptDef, fileName);
        } else {
            if (logger.isDebugEnabled()) {
                logger.debug(&quot;从缓存载入jar组件&quot;);
            }
            return cmptClassLoader;
        }
    }

    /**
     * 载入Jar包, 以新Jar包载入
     *
     * @param fileName
     * @return 返回一个类加载器
     */
    private static CmptClassLoader loadJar(String IdCmptDef, String fileName) {
        CmptClassLoader loader;
        try {
            boolean exists = new File(fileName).exists();
            if (exists) {
                if (null == classLoaderMap.get(IdCmptDef) || unLoadJar(IdCmptDef)) {
                    loader = new CmptClassLoader();
                    boolean loadJar = loader.addURL(fileName);
                    if (loadJar) {
                        classLoaderMap.put(IdCmptDef, loader);
                        return loader;
                    } else {
                        loader.close();
                    }
                }
            } else {
                throw new IllegalArgumentException(&quot;传入参数错误,文件不存在! file: &quot; + fileName);
            }
        } catch (Exception e) {
            logger.error(&quot;&quot;,e);
        }
        return null;
    }

    public static boolean unLoadJar(String IdCmptDef) {
        boolean unLoadJar = false;
        if (logger.isDebugEnabled()) {
            logger.debug(&quot;请求卸载jar包: &quot; + IdCmptDef);
        }
        try {
            CmptClassLoader loader = classLoaderMap.remove(IdCmptDef);
            if (null != loader) {
                loader.close();
            }
            unLoadJar = true;
        } catch (Exception e) {
            logger.error(&quot;&quot;,e);
        }
        return unLoadJar;
    }

    /**
     * 获取组件定义对应的实例的类加载器
     *
     * @param idCmptDef
     * @return
     */
    public static ClassLoader getCmptClassLoader(String idCmptDef) {
        return classLoaderMap.get(idCmptDef);
    }
}
</code></pre>
<pre><code class="language-java">public class FileUtil {
	public static String fixFileName(String fileName) {
        if (null == fileName) fileName = &quot;&quot;;
        fileName = fileName.replaceAll(&quot;\\\\&quot;, &quot;/&quot;);
        fileName = fileName.replaceAll(&quot;//&quot;, &quot;/&quot;);
        return fileName;
    }
}
</code></pre>
<pre><code class="language-java">/**
 * 类加载器终极版, 加载, 卸载jar包
 */
public class CmptClassLoader extends URLClassLoader {

    private static final Logger logger = Logger.getLogger(CmptClassLoader.class);

    CmptClassLoader(URL[] urls, ClassLoader parent) {
        super(urls, parent);
    }

    CmptClassLoader(URL[] urls) {
        super(urls);
    }

    CmptClassLoader(URL[] urls, ClassLoader parent, URLStreamHandlerFactory factory) {
        super(urls, parent, factory);
    }

    CmptClassLoader() {
        super(new URL[]{}, findParentClassLoader());
    }

    /**
     * 载入Jar
     *
     * @param fileName
     * @return
     */
    boolean addURL(String fileName) {
        try {
            URL url = new File(fileName).toURL();
            URLClassPath ucp = this.getUCP();
            ucp.addURL(url);
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
        return true;
    }

    /**
     * 定位当前父类加载器
     *
     * @return
     */
    private static ClassLoader findParentClassLoader() {
        ClassLoader parent = logger.getClass().getClassLoader();
        if (parent == null) {
            throw new RuntimeException(&quot;无法获取当前父加载器!&quot;);
        }
        return parent;
    }

    private URLClassPath getUCP() {
        URLClassPath ucp = null;
        try {
            Field declaredField = URLClassLoader.class.getDeclaredField(&quot;ucp&quot;);
            declaredField.setAccessible(true);
            Object o = declaredField.get(this);
            ucp = (URLClassPath) o;
        } catch (IllegalAccessException e) {
            e.printStackTrace();
        } catch (NoSuchFieldException e) {
            e.printStackTrace();
        }
        return ucp;
    }

    @Override
    protected void finalize() throws Throwable {
        super.finalize();
        this.close();
    }
}
</code></pre>
<pre><code class="language-java">/**
 * 类加载器工具类
 */
public class LoadClassUtil {
    private final static LoadClassUtil LOAD_JAR_UTIL = new LoadClassUtil();
    private static Logger logger = LoggerFactory.getLogger(LoadClassUtil.class);

    private LoadClassUtil() {
    }

    /**
     * 载入jar包
     * 将jar包路径添加到系统类加载器扫描类和资源的文件列表里
     *
     * @param fileName jar绝对路径
     * @return
     */
    public static boolean loadJar(String fileName) {
        try {
            if (strNotNull(fileName) &amp;&amp; fileExists(fileName)) {//(ClassLoader要与当前程序同一个loader)
                getMethod().invoke(LOAD_JAR_UTIL.getClass().getClassLoader(), getURL(fileName));//添加路径URL
                //getMethod().invoke(Launcher.getLauncher().getClassLoader(), getURL(fileName));//添加路径URL
                return true;
            } else {
                throw new IllegalArgumentException(&quot;传入参数错误,文件或不存在! file: &quot; + fileName);
            }
        } catch (Exception e) {
            logger.error(&quot;&quot;,e);
        }
        return false;
    }

    /**
     * 判断字符串不为空
     *
     * @param str
     * @return
     */
    private static boolean strNotNull(String str) {
        return null != str &amp;&amp; !str.equals(&quot;&quot;);
    }

    private static boolean fileExists(String fileName) {
        return new File(fileName).exists();
    }

    /**
     * 拿到添加扫描类和资源的路径URL的方法
     *
     * @return
     * @throws NoSuchMethodException
     */
    private static Method getMethod() throws NoSuchMethodException {
        Method method = URLClassLoader.class.getDeclaredMethod(&quot;addURL&quot;, URL.class);
        // 破解方法的访问权限
        method.setAccessible(true);
        return method;
    }

    /**
     * 得到一个URL
     *
     * @param fileName
     * @return
     * @throws MalformedURLException
     */
    private static URL getURL(String fileName) throws MalformedURLException {
        return new File(fileName).toURI().toURL();
    }

    /**
     * 创建对象实例
     *
     * @param className 全限定名
     * @return
     */
    public static Object newObject(String className) {
        try {
            return Class.forName(className).newInstance();
        } catch (Exception e) {
            logger.error(&quot;&quot;,e);
        }
        return null;
    }

    /**
     * 创建转换类型后的对象实例
     *
     * @param className 全限定名
     * @param tClass    返回类型
     * @param &lt;T&gt;
     * @return
     */
    public static &lt;T&gt; T newObject(String className, Class&lt;T&gt; tClass) {
        try {
            return (T) Class.forName(className).newInstance();
        } catch (Exception e) {
            logger.error(&quot;&quot;,e);
        }
        return null;
    }

    /**
     * 创建转换类型后的对象实例
     *
     * @param cmptDef 组件定义-&gt;全限定名
     * @param tClass    返回类型
     * @param loader    类加载器
     * @param &lt;T&gt;
     * @return
     */
    public static &lt;T&gt; T newObject(CmptDef cmptDef, Class&lt;T&gt; tClass, ClassLoader loader) {
        try {
            String className = cmptDef.getFullQualifiedName();
            Object newInstance = Class.forName(className, true, loader).newInstance();
            return (T) newInstance;
        } catch (Exception e) {
            String jarPath = CmptClassLoaderUtil.getJarPath(cmptDef);
            logger.error(&quot;创建组件实例失败! className=&quot; + cmptDef.getFullQualifiedName() + &quot; jarPath=&quot; + jarPath);
            logger.error(&quot;创建出错组件:&quot; + cmptDef.getName() + cmptDef.getVersion() + &quot; ,文件信息:&quot; + FileUtil.fileInfo(jarPath));
            try {
                Class&lt;?&gt; aClass = loader.loadClass(cmptDef.getFullQualifiedName());
            } catch (ClassNotFoundException e1) {
                e1.printStackTrace();
                logger.error(&quot;类未载入:&quot; + cmptDef.getFullQualifiedName());
            }
        }
        return null;
    }

    /**
     * 执行对象的方法
     *
     * @param o          实例对象
     * @param methodName 方法名称
     * @param args       形参
     * @return
     */
    public static Object invokeMethod(Object o, String methodName, Object... args) {
        try {
            Object invoke;
            if (null == args || args.length == 0) {//有缺陷,如果形参是任意Object,但传入参数是null,无法得到形参类型,得到有参的方法.
                Method method = o.getClass().getMethod(methodName);
                invoke = method.invoke(o);
            } else {
                Method method = o.getClass().getMethod(methodName, args.getClass());
                invoke = method.invoke(o, args);
            }
            return invoke;
        } catch (Exception e) {
            logger.error(&quot;&quot;,e);
        }
        return null;
    }

}
</code></pre>
<h3 id="组件实现公共接口类">组件实现公共接口类</h3>
<pre><code class="language-java">public interface ICmpt {

    /**
     * 组件执行入口
     *
     * @param request
     * @param config，组件实例的参数配置
     * @param actionNode,      当前执行的流程节点
     * @param procContextDTO,     流程引擎实例上下文
     * @return
     */
    CmptResult execute(CmptRequest request, Map&lt;String, FieldDTO&gt; config, ActionNode actionNode, ProcContextDTO procContextDTO);

    /**
     * 销毁组件持有的特殊资源，比如线程。
     */
    void destroy();
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[mybatis级联查询]]></title>
        <id>https://tinaxiawuhao.github.io/post/hIydIZSN1/</id>
        <link href="https://tinaxiawuhao.github.io/post/hIydIZSN1/">
        </link>
        <updated>2021-12-27T03:17:49.000Z</updated>
        <content type="html"><![CDATA[<h2 id="modelmapperxml">ModelMapper.xml</h2>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;
&lt;mapper namespace=&quot;com.haier.biz.mapper.ModelMapper&quot;&gt;
    &lt;resultMap id=&quot;BaseResultMap&quot; type=&quot;com.haier.biz.entity.Model&quot;&gt;
        &lt;id column=&quot;model_id&quot; jdbcType=&quot;BIGINT&quot; property=&quot;modelId&quot;/&gt;
        &lt;result column=&quot;equipment_model_mark&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;equipmentModelMark&quot;/&gt;
        &lt;result column=&quot;equipment_name&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;equipmentName&quot;/&gt;
        &lt;result column=&quot;specification_model&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;specificationModel&quot;/&gt;
        &lt;result column=&quot;model_description&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;modelDescription&quot;/&gt;
        &lt;result column=&quot;model_sort_key&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;modelSortKey&quot;/&gt;
        &lt;result column=&quot;model_classification_label&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;modelClassificationLabel&quot;/&gt;
        &lt;result column=&quot;tenant_product_id&quot; jdbcType=&quot;BIGINT&quot; property=&quot;tenantProductId&quot;/&gt;
        &lt;result column=&quot;tenant_product_name&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;tenantProductName&quot;/&gt;
        &lt;result column=&quot;manufacturer&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;manufacturer&quot;/&gt;
        &lt;result column=&quot;create_by&quot; jdbcType=&quot;BIGINT&quot; property=&quot;createBy&quot;/&gt;
        &lt;result column=&quot;create_time&quot; jdbcType=&quot;TIMESTAMP&quot; property=&quot;createTime&quot;/&gt;
        &lt;result column=&quot;update_by&quot; jdbcType=&quot;BIGINT&quot; property=&quot;updateBy&quot;/&gt;
        &lt;result column=&quot;update_time&quot; jdbcType=&quot;TIMESTAMP&quot; property=&quot;updateTime&quot;/&gt;
    &lt;/resultMap&gt;
    &lt;!--级联查询--&gt;
    &lt;resultMap id=&quot;BaseResultInstanceMap&quot; type=&quot;com.haier.biz.entity.DTO.ModelDTO&quot; extends=&quot;BaseResultMap&quot;&gt;
        &lt;result column=&quot;publishNumber&quot; jdbcType=&quot;BIGINT&quot; property=&quot;publishNumber&quot;/&gt;
        &lt;result column=&quot;customer_id&quot; jdbcType=&quot;BIGINT&quot; property=&quot;customerId&quot;/&gt;
        &lt;result column=&quot;topic&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;topic&quot;/&gt;
        &lt;!--property来源ModelDTO属性，column来源于selectInstancelList查询--&gt;
        &lt;!--查询单条--&gt;
        &lt;association property=&quot;equipmentPicture&quot; column=&quot;equipment_model_mark&quot;
                     select=&quot;getEquipmentPicture&quot;&gt;&lt;/association&gt;
        &lt;association property=&quot;instanceNumber&quot; column=&quot;{equipmentModelMark=equipment_model_mark,customerId=customer_id}&quot;
                     select=&quot;getCustomerInstanceNumber&quot;&gt;&lt;/association&gt;
        &lt;!--查询列表--&gt;
        &lt;collection property=&quot;equipmentPictures&quot; column=&quot;equipment_model_mark&quot;
                    select=&quot;getEquipmentPictures&quot;&gt;&lt;/collection&gt;
    &lt;/resultMap&gt;
    &lt;select id=&quot;selectInstancelList&quot; parameterType=&quot;com.haier.biz.entity.VO.InstanceSelectVo&quot;
            resultMap=&quot;BaseResultInstanceMap&quot;&gt;
        SELECT
        distinct model.model_id,
        equipment_model_mark,
        equipment_name,
        specification_model,
        model_description,
        model_sort_key,
        model_classification_label,
        tenant_product_id,
        tenant_product_name,
        manufacturer,
        model.create_by,
        model.create_time,
        model.update_by,
        model.update_time,
        0 as publishNumber,
        relation_model_customer.customer_id,
        relation_model_customer.topic
        FROM
        model
        LEFT JOIN relation_model_customer on relation_model_customer.model_id=model.model_id
        &lt;where&gt;
            &lt;if test=&quot;customerId != null&quot;&gt;
                and relation_model_customer.customer_id = #{customerId}
            &lt;/if&gt;
            &lt;if test=&quot;modelSortKey != null and modelSortKey!=''&quot;&gt;
                and `model`.model_sort_key = #{modelSortKey}
            &lt;/if&gt;
            &lt;if test=&quot;equipmentName != null and equipmentName!=''&quot;&gt;
                and `model`.equipment_name like CONCAT('%', #{equipmentName,jdbcType=VARCHAR},'%')
            &lt;/if&gt;
        &lt;/where&gt;
    &lt;/select&gt;
    &lt;select id=&quot;getEquipmentPicture&quot; parameterType=&quot;java.lang.String&quot; resultType=&quot;java.lang.String&quot;&gt;
        SELECT model_instance_file_associate.file_object_key as equipmentPicture
        from model_instance_file_associate
        where model_instance_file_associate.file_type=4
            and model_instance_file_associate.type=0
            and model_instance_file_associate.del_flag=0
            and model_instance_file_associate.model_or_instance_mark = #{equipmentModelMark,jdbcType=VARCHAR}
        limit 1
    &lt;/select&gt;
    &lt;select id=&quot;getCustomerInstanceNumber&quot; parameterType=&quot;java.util.Map&quot; resultType=&quot;java.lang.Long&quot;&gt;
        SELECT count(*)
        from model_instance_associate
        left join `instance` on model_instance_associate.instance_mark=`instance`.instance_mark
        where model_instance_associate.equipment_model_mark = #{equipmentModelMark,jdbcType=VARCHAR}
            and `instance`.customer_id=#{customerId}
    &lt;/select&gt;
    &lt;select id=&quot;getEquipmentPictures&quot; parameterType=&quot;java.lang.String&quot; resultType=&quot;java.lang.String&quot;&gt;
       SELECT model_instance_file_associate.file_object_key as equipmentPictures
        from model_instance_file_associate
        where model_instance_file_associate.file_type=4
            and model_instance_file_associate.type=0
            and model_instance_file_associate.del_flag=0
            and model_instance_file_associate.model_or_instance_mark = #{equipmentModelMark,jdbcType=VARCHAR}
    &lt;/select&gt;
&lt;/mapper&gt;
</code></pre>
<h2 id="modelmapper">ModelMapper</h2>
<pre><code class="language-java">@Repository
public interface ModelMapper extends BaseMapper&lt;Model&gt; {

    List&lt;ModelDTO&gt; selectInstancelList(InstanceSelectVo instanceSelectVo);

    List&lt;String&gt; getEquipmentPictures(@Param(&quot;equipmentModelMark&quot;) String equipmentModelMark);

}
</code></pre>
<h2 id="modeldto">ModelDTO</h2>
<pre><code class="language-java">@Data
@EqualsAndHashCode(callSuper = false)
@Accessors(chain = true)
@AllArgsConstructor
@NoArgsConstructor
public class ModelDTO extends Model {

    @ApiModelProperty(value = &quot;产品(模型)图片(取第一张)&quot;)
    private String equipmentPicture;

    @ApiModelProperty(value = &quot;产品(模型)图片&quot;)
    private List&lt;String&gt; equipmentPictures;

    @ApiModelProperty(value = &quot;发布客户数&quot;)
    private Long publishNumber;

    @ApiModelProperty(value = &quot;实例设备数&quot;)
    private Long instanceNumber;

    @ApiModelProperty(value = &quot;使用方Id&quot;)
    private Long customerId;

    @ApiModelProperty(value = &quot;实例设备运行情况&quot;)
    private List&lt;NumberDTO&gt; equipmentList;

    @ApiModelProperty(value = &quot;kafka实时推送的topic&quot;)
    private String topic;
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[mysql 简单导入 clickhouse]]></title>
        <id>https://tinaxiawuhao.github.io/post/BHjbgcFm-/</id>
        <link href="https://tinaxiawuhao.github.io/post/BHjbgcFm-/">
        </link>
        <updated>2021-12-15T07:12:02.000Z</updated>
        <content type="html"><![CDATA[<p>数据迁移需要从 mysql 导入 clickhouse, clickhouse 自身支持的三种方式 。</p>
<h2 id="create-table-engin-mysql">create table engin mysql</h2>
<pre><code>CREATE TABLE [IF NOT EXISTS] [db.]table_name [ON CLUSTER cluster]
(
    name1 [type1] [DEFAULT|MATERIALIZED|ALIAS expr1] [TTL expr1],
    name2 [type2] [DEFAULT|MATERIALIZED|ALIAS expr2] [TTL expr2],
    ...
    INDEX index_name1 expr1 TYPE type1(...) GRANULARITY value1,
    INDEX index_name2 expr2 TYPE type2(...) GRANULARITY value2
) ENGINE = MySQL('host:port', 'database', 'table', 'user', 'password'[, replace_query, 'on_duplicate_clause']);
</code></pre>
<blockquote>
<p>官方文档: https://clickhouse.yandex/docs/en/operations/table_engines/mysql/</p>
</blockquote>
<p>注意，实际数据存储在远端 mysql 数据库中，可以理解成外表。<br>
可以通过在 mysql 增删数据进行验证。</p>
<h2 id="insert-into-select-from">insert into select from</h2>
<pre><code>-- 先建表
CREATE TABLE [IF NOT EXISTS] [db.]table_name [ON CLUSTER cluster]
(
    name1 [type1] [DEFAULT|MATERIALIZED|ALIAS expr1],
    name2 [type2] [DEFAULT|MATERIALIZED|ALIAS expr2],
    ...
) ENGINE = engine
-- 导入数据
INSERT INTO [db.]table [(c1, c2, c3)] select 列或者* from mysql('host:port', 'db', 'table_name', 'user', 'password')
</code></pre>
<p>可以自定义列类型，列数，使用 clickhouse 函数对数据进行处理，比如 <code>select toDate(xx) from mysql(&quot;host:port&quot;,&quot;db&quot;,&quot;table_name&quot;,&quot;user_name&quot;,&quot;password&quot;)</code></p>
<h2 id="create-table-as-select-from">create table as select from</h2>
<pre><code>CREATE TABLE [IF NOT EXISTS] [db.]table_name
ENGINE =Log
AS
SELECT *
FROM mysql('host:port', 'db', 'article_clientuser_sum', 'user', 'password')
</code></pre>
<blockquote>
<p>网友文章: http://jackpgao.github.io/2018/02/04/ClickHouse-Use-MySQL-Data/</p>
</blockquote>
<p>不支持自定义列，参考资料里的博主写的 <code>ENGIN=MergeTree</code> 测试失败。<br>
可以理解成 create table 和 insert into select 的组合</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Thingsboard源码编译]]></title>
        <id>https://tinaxiawuhao.github.io/post/DseKIIHw3/</id>
        <link href="https://tinaxiawuhao.github.io/post/DseKIIHw3/">
        </link>
        <updated>2021-12-02T07:49:30.000Z</updated>
        <content type="html"><![CDATA[<h2 id="环境安装">环境安装</h2>
<p>开发环境要求： Jdk 1.11 版本 Postgresql 9 以上 Node.js Npm Maven 3.6 以上 Git 工具 Idea 开发工具 Redis</p>
<h3 id="jdk">JDK</h3>
<p><strong>下载安装</strong></p>
<p>JDK 官方下载地址： <a href="https://www.oracle.com/java/technologies/downloads/#java11-windows">Java Downloads | Oracle</a></p>
<p>JDK 版本选择 JDK11，我本地环境是 Windos10 64 位，所以选择 jdk-11.0.13-windows-x64.exe</p>
<p><img src="https://tinaxiawuhao.github.io/post-images/1638431548398.png" alt="" loading="lazy"><br>
下载好了之后直接默认安装就行</p>
<p><strong>免安装版本</strong></p>
<p>下载jdk11<br>
http://openjdk.java.net/install/index.html</p>
<p>这个页面大部分都是linux系统的；</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1638431591806.png" alt="" loading="lazy"></figure>
<p>然后我们点击jdk.java.net ，接着我们选择下载Java SE 11；</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1638431626019.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1638431650013.png" alt="" loading="lazy"></figure>
<p>下好了后，我们得到这样的文件：openjdk-11+28_windows-x64_bin.zip，解压后得到：jdk-11这样的文件夹；将该文件夹放到你习惯的地方；</p>
<p><strong>配置环境变量</strong></p>
<p><strong>步骤 1：</strong> 在 JAVA_HOME 中增加 JDK 的安装地址：C:\Program Files\Java\jdk1.8.0_221 <img src="https://tinaxiawuhao.github.io/post-images/1638431720261.png" alt="" loading="lazy"></p>
<p><strong>步骤 2：</strong> 在 CLASSPATH 中增加 JDK 的安装地址中的文件：.;%JAVA_HOME%\lib;%JAVA_HOME%\lib\dt.jar;%JAVA_HOME%\lib\tools.jar <img src="https://tinaxiawuhao.github.io/post-images/1638431747039.png" alt="" loading="lazy"></p>
<p><strong>步骤 3：</strong> 在 Path 中增加 JDK 的地址：%JAVA_HOME%\bin;%JAVA_HOME%\jre\bin; <img src="https://tinaxiawuhao.github.io/post-images/1638431804325.png" alt="" loading="lazy"></p>
<p><strong>步骤 4</strong> 输入以下命令</p>
<pre><code class="language-shell">java -version
</code></pre>
<p>如果能出现以下的提示信息，就算安装成功了<img src="https://tinaxiawuhao.github.io/post-images/1638431854451.png" alt="" loading="lazy"></p>
<h3 id="安装-idea">安装 IDEA</h3>
<p>参考：<a href="https://www.iotschool.com/topics/72">IDEA 安装教程</a></p>
<h3 id="安装-maven">安装 Maven</h3>
<p>步骤 1：下载 maven，进入地址：http://maven.apache.org/download.cgi <img src="https://tinaxiawuhao.github.io/post-images/1638431903988.png" alt="" loading="lazy"></p>
<p>步骤 2：下载到本地 <img src="https://tinaxiawuhao.github.io/post-images/1638431943007.png" alt="" loading="lazy"></p>
<p>步骤 3：配置环境变量 增加 MAVEN_HOME，即 maven 的地址：D:\tb\apache-maven-3.6.1-bin，请注意，如果直接解压，有可能会有两个 apache-maven-3.6.1-bin<img src="https://tinaxiawuhao.github.io/post-images/1638432216067.png" alt="" loading="lazy"></p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1638432310973.png" alt="" loading="lazy"></figure>
<p>MAVEN_OPTS，参数是 -Xms128m -Xmx1024m<img src="https://tinaxiawuhao.github.io/post-images/1638432342300.png" alt="" loading="lazy"></p>
<p>修改 Path，增加 Maven 的地址%MAVEN_HOME%\bin; <img src="https://tinaxiawuhao.github.io/post-images/1638432408010.png" alt="" loading="lazy"></p>
<p>测试 Maven 安装，打开命令行工具。使用命令 mvn -v，如果能出现以下提示，即安装成功 <img src="https://tinaxiawuhao.github.io/post-images/1638432460487.png" alt="" loading="lazy"></p>
<h3 id="nodejs-安装">Nodejs 安装</h3>
<p>步骤 1：下载 Nodejs 安装包，Nodejs 官网地址：https://nodejs.org/en/download/ <img src="https://tinaxiawuhao.github.io/post-images/1638432643509.png" alt="" loading="lazy"></p>
<p>步骤 2：安装完成后，使用命令查看 Nodejs 是否已经安装完成，能出现以下提示说明已经安装成功 !<img src="https://tinaxiawuhao.github.io/post-images/1638432779272.png" alt="" loading="lazy"></p>
<h3 id="安装-git">安装 git</h3>
<p>步骤 1：下载 git 安装包，git 官网地址是：https://git-scm.com/download/win<img src="https://tinaxiawuhao.github.io/post-images/1638433242163.png" alt="" loading="lazy"></p>
<p>步骤 2：安装完成后，使用命令行测试 git <img src="https://tinaxiawuhao.github.io/post-images/1638433294783.png" alt="" loading="lazy"></p>
<h3 id="安装-npm-全局依赖">安装 npm 全局依赖</h3>
<p>步骤 1：使用管理员 CMD 命令行，执行下面命令</p>
<pre><code class="language-shell">#npm 环境读取环境变量包
npm install -g cross-env
#webpack打包工具
npm install -g webpack
</code></pre>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1638433336020.png" alt="" loading="lazy"></figure>
<h3 id="安装-redis">安装 redis</h3>
<p>Redis 安装参考：https://www.iotschool.com/wiki/redis</p>
<p>环境安装到此结束，接下来是通过 Git 拉取代码。</p>
<h2 id="克隆-thingsboard-代码">克隆 thingsboard 代码</h2>
<h3 id="确定代码存放位置">确定代码存放位置</h3>
<p>在本地创建代码存放位置的文件目录，然后进入当前目录点击鼠标右键，选择 Git Bash Here <img src="https://tinaxiawuhao.github.io/post-images/1638433373069.png" alt="" loading="lazy"></p>
<h3 id="输入-git-命令克隆源代码">输入 git 命令克隆源代码</h3>
<pre><code class="language-shell">git clone https://github.com/thingsboard/thingsboard.git
</code></pre>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1638433403642.png" alt="" loading="lazy"></figure>
<p>耐心等待一段时间后，看到以下界面就算下载成功 <img src="https://tinaxiawuhao.github.io/post-images/1638433434959.png" alt="" loading="lazy"></p>
<h3 id="切换-git-分支">切换 git 分支</h3>
<p>默认下载的代码是 master 主分支的，我们开发需要切换到最新版本的分支。</p>
<p>查看项目源码的所有分支，下载源码后，需要进入到 thingsboard 文件夹 <img src="https://tinaxiawuhao.github.io/post-images/1638433484980.png" alt="" loading="lazy"></p>
<p>发现最新发布的版本是 2.4，所以我这里选择 2.4，当然你可以根据自己的情况进行分支选择</p>
<p>输入命令以下，即可切换至 2.4 的分支</p>
<pre><code class="language-shell">git checkout release-2.4
</code></pre>
<p>看到下图这样，即切换成成功 <img src="https://tinaxiawuhao.github.io/post-images/1638433523862.png" alt="" loading="lazy"></p>
<h2 id="准备工作">准备工作</h2>
<h3 id="外网连接">外网连接</h3>
<p>因为 TB 在编译过程中需要依赖很多国外的包，那么需要外网才能连接，有连接外网支持，可以到社区求助：https://www.iotschool.com/topics/node8</p>
<h3 id="设置-maven-为淘宝镜像">设置 Maven 为淘宝镜像</h3>
<p>工程是基于 Maven 管理，直接通过 idea open，之后会自动下载各种依赖包。依赖包的默认存储地址为：C:\Users\用户名.m2\repository，内容如下：</p>
<pre><code class="language-shell">$tree ~/.m2 -L 2
/home/jay/.m2
└── repository
    ├── antlr
    ├── aopalliance
    ├── asm
    ├── backport-util-concurrent
    ├── ch
    ...
</code></pre>
<p>一般情况下，使用官方镜像更新依赖包，网速不稳定，可将 Maven 镜像源设置为淘宝的，在 maven 安装包目录下找到 settings.xml 设置</p>
<p>大概位置截图：</p>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1638433563017.png" alt="" loading="lazy"></figure>
<p>把 settings.xml 里面内容设置成以下：</p>
<pre><code class="language-xml">&lt;mirrors&gt;
  &lt;mirror&gt;
       &lt;!--This sends everything else to /public --&gt;
       &lt;id&gt;aliyun_nexus&lt;/id&gt;
       &lt;mirrorOf&gt;*,!maven_nexus_201&lt;/mirrorOf&gt; 
       &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt;
   &lt;/mirror&gt;
&lt;/mirrors&gt;
</code></pre>
<p>不会设置的，可以参考这个文件：https://cdn.iotschool.com/iotschool/settings.xml</p>
<p>thingsboard QQ 群也有这个资源：121202538</p>
<h3 id="设置-npm-为淘宝镜像">设置 npm 为淘宝镜像</h3>
<p>同上，网速不好 npm 过程中也会下载失败，这是导致很多同学 thingsboard 编译失败的主要原因，所以我们在进行编译之前，也将 npm 替换为淘宝镜像：</p>
<pre><code class="language-shell">npm install -g mirror-config-china --registry=http://registry.npm.taobao.org        #使用淘宝镜像
npm config get registry                                                             #查询当前镜像
npm config rm registry                                                              #删除自定义镜像，使用官方镜像
npm info express
</code></pre>
<h3 id="设置-idea-管理员启动">设置 IDEA 管理员启动</h3>
<p>我本地开发环境编译项目使用 IDEA 工具进行编译，所以需要设置管理员启动，这样才有所有的权限执行编译命令。 步骤 1：点击 IDEA 图标右键，选择属性。<img src="https://tinaxiawuhao.github.io/post-images/1638433591413.png" alt="" loading="lazy"></p>
<p>步骤 2：点击兼容性 - 更改所有用户设置 - 以管理员身份运行此程序<img src="https://tinaxiawuhao.github.io/post-images/1638433662301.png" alt="" loading="lazy"></p>
<h2 id="开始编译">开始编译</h2>
<p>编译项目跟网速有关，最好连接上外网进行编译，一般 5~30 分钟都有可能，超过 30 分钟要检查你的网络。</p>
<h3 id="清理项目编译文件">清理项目编译文件</h3>
<p>使用 IDEA Maven 工具进行清理 <img src="https://tinaxiawuhao.github.io/post-images/1638433705438.png" alt="" loading="lazy"></p>
<h3 id="输入编译命令开始编译">输入编译命令开始编译</h3>
<p>在 IDEA 控制台（左下方）Terminal 输入以下命令进行编译：</p>
<pre><code class="language-shell">mvn clean install -DskipTests
</code></pre>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1638433732682.png" alt="" loading="lazy"></figure>
<p>等一段时间后，看到下面这张图就算编译成功，如果没有编译成功请按照本教程最后的常见问题进行排查，一般都是网络问题。如果还有问题，请到社区<a href="https://www.iotschool.com/topics/node8">thingsboard 专题</a>中提问。</p>
<figure data-type="image" tabindex="9"><img src="https://tinaxiawuhao.github.io/post-images/1638433762968.png" alt="" loading="lazy"></figure>
<h2 id="常见问题">常见问题</h2>
<h3 id="pom包pkgname等标签未定义">pom包pkg.name等标签未定义</h3>
<pre><code class="language-xml">    &lt;properties&gt;
        &lt;pkg.name&gt;thingsboard&lt;/pkg.name&gt;
        &lt;main.dir&gt;${basedir}&lt;/main.dir&gt;
        &lt;pkg.type&gt;java&lt;/pkg.type&gt;
        &lt;pkg.mainClass&gt;org.thingsboard.server.ThingsboardServerApplication&lt;/pkg.mainClass&gt;
        &lt;pkg.copyInstallScripts&gt;true&lt;/pkg.copyInstallScripts&gt;


        &lt;main.dir&gt;${basedir}&lt;/main.dir&gt;
        &lt;pkg.disabled&gt;true&lt;/pkg.disabled&gt;
        &lt;pkg.process-resources.phase&gt;none&lt;/pkg.process-resources.phase&gt;
        &lt;pkg.package.phase&gt;none&lt;/pkg.package.phase&gt;
        &lt;pkg.user&gt;thingsboard&lt;/pkg.user&gt;
        &lt;pkg.implementationTitle&gt;${project.name}&lt;/pkg.implementationTitle&gt;
        &lt;pkg.unixLogFolder&gt;/var/log/${pkg.name}&lt;/pkg.unixLogFolder&gt;
        &lt;pkg.installFolder&gt;/usr/share/${pkg.name}&lt;/pkg.installFolder&gt;
  &lt;/properties&gt;
</code></pre>
<h3 id="缓存导致编译失败">缓存导致编译失败</h3>
<p>每次编译失败进行二次编译时，要清理缓存，并杀死遗留进程 步骤 1：执行下面命令，杀死遗留进程</p>
<pre><code class="language-shell">taskkill /f /im java.exe
</code></pre>
<p>步骤 2：使用 IDEA Maven 工具进行清理 <img src="https://tinaxiawuhao.github.io/post-images/1638433793132.png" alt="" loading="lazy"></p>
<p><strong>温馨提示：要进行二次编译前，最好重启一次电脑！</strong></p>
<h3 id="server-ui-编译失败">Server UI 编译失败</h3>
<pre><code class="language-java">[ERROR] Failed to execute goal com.github.eirslett:frontend-maven-plugin:1.0:npm (npm install) on project ui: Failed to run task: 'npm install' failed. (error code 1) -&gt; [Help 1]
</code></pre>
<figure data-type="image" tabindex="10"><img src="https://tinaxiawuhao.github.io/post-images/1638433824944.png" alt="" loading="lazy"></figure>
<p>如果遇到这个问题，可从以下几个原因进行分析：</p>
<h4 id="原因-1node-npm-版本号问题">原因 1：node、npm 版本号问题</h4>
<p>本地环境安装的 node、npm 版本号与源码中 pom.xml 文件配置的版本号不一致。</p>
<p>解决方案： 步骤 1：使用 node -v、npm -v 查看安装的 node 和 npm 版本号 <img src="https://tinaxiawuhao.github.io/post-images/1638433858043.png" alt="" loading="lazy"></p>
<p>步骤 2：修改源码中 pom.xml 文件中的版本号</p>
<pre><code class="language-xml">&lt;configuration&gt;
   &lt;nodeVersion&gt;v12.13.1&lt;/nodeVersion&gt;
   &lt;npmVersion&gt;6.12.1&lt;/npmVersion&gt;
&lt;/configuration&gt;
</code></pre>
<p>需要修改的文件有三处，位置如下： <img src="https://tinaxiawuhao.github.io/post-images/1638433897767.png" alt="" loading="lazy"></p>
<h4 id="原因-2node-sass-下载失败">原因 2：node-sass 下载失败</h4>
<p>编译 Server UI 时，会下载 node-sass 依赖，如果因为网络原因没有下载成功，也会编译失败。如果你是按照本本教材一步一步来的，应该不会有问题，上面准备工作中，将 npm 镜像源切换为淘宝，那么下载会很快的。</p>
<pre><code class="language-shell">[INFO] Downloading binary from https://github.com/sass/node-sass/releases/download/v4.12.0/win32-x64-72_binding.node
[ERROR] Cannot download &quot;https://github.com/sass/node-sass/releases/download/v4.12.0/win32-x64-72_binding.node&quot;:
[ERROR]
[ERROR] ESOCKETTIMEDOUT
[ERROR]
[ERROR] Hint: If github.com is not accessible in your location
[ERROR]       try setting a proxy via HTTP_PROXY, e.g.
[ERROR]
[ERROR]       export HTTP_PROXY=http://example.com:1234
[ERROR]
[ERROR] or configure npm proxy via
[ERROR]
[ERROR]       npm config set proxy http://example.com:8080
[INFO]
[INFO] &gt; node-sass@4.12.0 postinstall F:\workspace\thingsboard\thingsboard\ui\node_modules\node-sass
[INFO] &gt; node scripts/build.js
[INFO]
</code></pre>
<figure data-type="image" tabindex="11"><img src="https://tinaxiawuhao.github.io/post-images/1638433935418.png" alt="" loading="lazy"></figure>
<p>解决方案：<a href="https://www.iotschool.com/wiki/tbinstall#%E8%AE%BE%E7%BD%AEnpm%E4%B8%BA%E6%B7%98%E5%AE%9D%E9%95%9C%E5%83%8F">切换镜像源为淘宝</a></p>
<p>解决方案：重启电脑，清理缓存</p>
<h4 id="原因-3thingsboard-30-版本编译遇到的问题">原因 3：Thingsboard 3.0 版本编译遇到的问题</h4>
<p>亲测：2.4 版本也可以通过这种方式来解决</p>
<pre><code class="language-shell">Failed to execute goal com.github.eirslett:frontend-maven-plugin:1.7.5:npm (npm install) on project ui-ngx: Failed to run task: 'npm install' failed. org.apache.commons.exec.ExecuteException: Process exited with an error: -4048 (Exit value: -4048) -&gt; [Help 1]
</code></pre>
<p>解决方案：https://www.iotschool.com/topics/84</p>
<h4 id="原因-4二次编译导致残留进程">原因 4：二次编译导致残留进程</h4>
<p>报错：</p>
<pre><code class="language-shell">[ERROR] Failed to execute goal org.apache.maven.plugins:maven-clean-plugin:2.5:clean (default-clean) on project ui: Failed to clean project: Failed to delete F:\workspace\thingsboard\thingsboard\ui\target\node\node.exe -&gt; [Help 1]
</code></pre>
<figure data-type="image" tabindex="12"><img src="https://tinaxiawuhao.github.io/post-images/1638433961674.png" alt="" loading="lazy"></figure>
<h3 id="server-tool-编译失败">Server Tool 编译失败</h3>
<figure data-type="image" tabindex="13"><img src="https://tinaxiawuhao.github.io/post-images/1638433985854.png" alt="" loading="lazy"></figure>
<pre><code class="language-shell">[ERROR] Failed to execute goal on project tools: Could not resolve dependencies for project org.thingsboard:tools:jar:2.4.3: Failed to collect dependencies at org.eclipse.paho:org.eclipse.paho.client.mqttv3:jar:1.1.0: Failed to read artifact descriptor for org.eclipse.paho:org.eclipse.paho.clien
t.mqttv3:jar:1.1.0: Could not transfer artifact org.eclipse.paho:org.eclipse.paho.client.mqttv3:pom:1.1.0 from/to aliyun_nexus (http://maven.aliyun.com/nexus/content/groups/public/): Failed to transfer file http://maven.aliyun.com/nexus/content/groups/public/org/eclipse/paho/org.eclipse.paho.cli
ent.mqttv3/1.1.0/org.eclipse.paho.client.mqttv3-1.1.0.pom with status code 502 -&gt; [Help 1]
</code></pre>
<p>一般由于网络原因，IoTSchool 小编至少编译了 3 次才成功，每次编译都重启电脑，并清理环境。</p>
<p>解决方案：如果使用的是 mvn clean install -DskipTests 命令进行编译，那么就多尝试几次，每次编译前，要清理环境。</p>
<p>参考：https://github.com/thingsboard/performance-tests/issues/10</p>
<h3 id="javascript-executor-编译失败">JavaScript Executor 编译失败</h3>
<p>JavaScript Executor Microservice 编译失败 <img src="https://tinaxiawuhao.github.io/post-images/1638434020950.png" alt="" loading="lazy"></p>
<pre><code class="language-shell">[ERROR] Failed to execute goal com.github.eirslett:frontend-maven-plugin:1.0:npm (npm install) on project js-executor: Failed to run task: 'npm install' failed. (error code 2) -&gt; [Help 1]
[ERROR]
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR]
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR]
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn &lt;goals&gt; -rf :js-executor
</code></pre>
<p>原因：本地缓存缺少 fetched-v10.15.3-linux-x64 和 fetched-v10.15.3-win-x64 这两个文件。</p>
<p>解决方案： 步骤 1：下载这两个文件到本地，下载后记得重命名，下载地址：https://github.com/zeit/pkg-fetch/releases <img src="https://tinaxiawuhao.github.io/post-images/1638434130104.png" alt="" loading="lazy"></p>
<p>步骤 2: 将下载的两个文件放到：放到：C:\Users\你的用户名 \ .pkg-cache\v2.6。并将名字分别修改为：fetched-v10.15.3-linux-x64 和 fetched-v10.15.3-win-x64</p>
<p>参考：https://github.com/thingsboard/thingsboard/issues/2084</p>
<h3 id="license-检查不通过">License 检查不通过</h3>
<pre><code class="language-shell">[ERROR] Failed to execute goal com.mycila:license-maven-plugin:3.0:check (default) on project thingsboard: Some files do not have the expected license header -&gt; [Help 1]
</code></pre>
<p>解决方案：在根目录 pom.xml 中屏蔽 license-maven-plugin</p>
<figure data-type="image" tabindex="14"><img src="https://tinaxiawuhao.github.io/post-images/1638434154303.png" alt="" loading="lazy"></figure>
<p>搜索 license-maven-plugin，将整个 plugin 都注释掉 <img src="https://tinaxiawuhao.github.io/post-images/1638434302255.png" alt="" loading="lazy"></p>
<h3 id="web-ui-编译失败">Web UI 编译失败</h3>
<p>Web UI 编译失败请参考[Server UI 编译失败第一个原因](https://www.iotschool.com/wiki/tbinstall#Server Tool编译失败)</p>
<h3 id="mavencould-not-resolve-dependencies-for-project-orgthingsboardapplication">maven:Could not resolve dependencies for project org.thingsboard:application:</h3>
<p>错误信息</p>
<pre><code class="language-shell">[ERROR] Failed to execute goal on project application: Could not resolve dependencies for project org.thingsboard:application:jar:2.4.1: The following artifacts could not be resolved: org.thingsboard.rule-engine:rule-engine-components:jar:2.4.1, org.thingsboard:dao:jar:2.4.1: Could not find artifact org.thingsboard.rule-engine:rule-engine-components:jar:2.4.1 in jenkins (http://repo.jenkins-ci.org/releases) -&gt; [Help 1]
</code></pre>
<p>解决方案：根目录下去 maven 编译，不要在每个单独编译，否则不能自动解决依赖，如果你已经在子模块进行了编译，请回到根目录先 clean 一下，再重新编译。</p>
<h3 id="mavenfailed-to-delete-tb-http-transportrpm">maven:Failed to delete tb-http-transport.rpm</h3>
<p>错误信息：</p>
<pre><code class="language-shell">[ERROR] Failed to execute goal org.apache.maven.plugins:maven-clean-plugin:2.5:clean (default-clean) on project http: Failed to clean project: Failed to delete D:\my_project\thingsboard\transport\http\target\tb-http-transport.rpm -&gt; [Help 1]
</code></pre>
<p>解决方案：第一次编译失败，再次编译可能会提示该错误，可以手动到报错路径删除，如果提示文件正在使用，需要在任务管理器杀死 java 进程后再手动删除。</p>
<h3 id="npmnpmcb-never-called">npm:npm:cb() never called!</h3>
<p>错误信息：</p>
<pre><code class="language-shell">npm ERR! cb() never called!
npm ERR! This is an error with npm itself. Please report this error at:
npm ERR!     &lt;https://npm.community&gt;
npm ERR! A complete log of this run can be found in:
npm ERR!     C:\Users\yuren\AppData\Roaming\npm-cache\_logs\2019-11-06T10_55_28_258Z-debug.log
</code></pre>
<p>解决方案： 尝试 npm cache clean --force 后再次 npm install 无果； 尝试更换淘宝镜像源后再次 npm install 无果； 怀疑有些包下载需要翻墙，全局代理翻墙后问题依然存在； 参考网上关闭所有代理后问题依然存在； 通过 log 日志分析最后一个解包报错的地方，屏蔽需要的 material-design-icons，新 modules rxjs 仍然报错；</p>
<pre><code class="language-shell">extract material-design-icons@3.0.1 extracted to node_modules\.staging\material-design-icons-61b4d55e (72881ms)
extract rxjs@6.5.2 extracted to node_modules\.staging\rxjs-e901ba4c (24280ms)
</code></pre>
<p>参考 npm ERR cb() never called 执行</p>
<pre><code class="language-shell">npm install --no-package-lock
</code></pre>
<p>之后提示 npm ERR! path git，添加 git 到环境变量后正常。</p>
<h3 id="npmnpm-err-path-git">npm:npm ERR! path git</h3>
<p>错误信息</p>
<pre><code class="language-shell">npm ERR! path git
npm ERR! code ENOENT
npm ERR! errno ENOENT
npm ERR! syscall spawn git
npm ERR! enoent Error while executing:
npm ERR! enoent undefined ls-remote -h -t git://github.com/fabiobiondi/angular-
</code></pre>
<p>解决方案：添加 git 到环境变量。</p>
<h3 id="no-compiler-is-provided-in-this-environment">No compiler is provided in this environment</h3>
<p>错误信息：</p>
<pre><code class="language-shell">[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.
1:compile (default-compile) on project netty-mqtt: Compilation failure
[ERROR] No compiler is provided in this environment. Perhaps you are running on
a JRE rather than a JDK?
</code></pre>
<p>需要在环境变量中设置 java，包含%JAVA_HOME%bin;%JAVA_HOME%lib;</p>
<h3 id="failed-to-execute-goal-orgthingsboardgradle-maven-plugin1010invoke-default-on-project-http-orggradletoolingbuildexception-could-not-execute-build-using-gradle-distribution-httpsservicesgradleorgdistributionsgradle-63-binzip">Failed to execute goal org.thingsboard:gradle-maven-plugin:1.0.10:invoke (default) on project http: org.gradle.tooling.BuildException: Could not execute build using Gradle distribution 'https://services.gradle.org/distributions/gradle-6.3-bin.zip'.</h3>
<h3 id="failed-to-execute-goal-orgapachemavenpluginsmaven-compiler-plugin381compile-default-compile-on-project-rest-client-compilation-failure">Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.8.1:compile (default-compile) on project rest-client: Compilation failure</h3>
<p>An unknown compilation problem occurred</p>
<p>这个问题主要是jdk版本跟项目不一致导致的，如果项目的版本是大于(不含！)3.2.1，则需要JDK11，反之JDK8</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ClickHouse-8分片集群]]></title>
        <id>https://tinaxiawuhao.github.io/post/vuilLU8qj/</id>
        <link href="https://tinaxiawuhao.github.io/post/vuilLU8qj/">
        </link>
        <updated>2021-11-19T11:49:19.000Z</updated>
        <content type="html"><![CDATA[<h3 id="clickhouse-分片集群">ClickHouse-分片集群</h3>
<p>副本虽然能够提高数据的可用性，降低丢失风险，但是每台服务器实际上必须容纳全量数据，对数据的横向扩容没有解决。 要解决数据水平切分的问题，需要引入分片的概念。通过分片把一份完整的数据进行切分，不同的分片分布到不同的节点上，再通过 Distributed 表引擎把数据拼接起来一同使用。</p>
<p>Distributed 表引擎本身不存储数据，有点类似于 MyCat 之于 MySql，成为一种中间件，通过分布式逻辑表来写入、分发、路由来操作多台节点不同分片的分布式数据。</p>
<p>注意：ClickHouse 的集群是表级别的，实际企业中，大部分做了高可用，但是没有用分片，避免降低查询性能以及操作集群的复杂性。</p>
<h4 id="1集群写入流程3-分片-2-副本共-6-个节点">1.集群写入流程（3 分片 2 副本共 6 个节点）</h4>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1656505247965.png" alt="" loading="lazy"></figure>
<p>internal_replication:内部副本同步 true：由分片自己同步 false：由distribute表同步，压力大</p>
<h4 id="2集群读取流程3-分片-2-副本共-6-个节点">2.集群读取流程（3 分片 2 副本共 6 个节点）</h4>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1656505265680.png" alt="" loading="lazy"></figure>
<h4 id="3-分片-2-副本共-6-个节点集群配置供参考">3 分片 2 副本共 6 个节点集群配置（供参考）</h4>
<p>配置的位置还是在之前的/etc/clickhouse-server/config.d/metrika.xml，内容如下 注：也可以不创建外部文件，直接在 config.xml 的&lt;remote_servers&gt;中指定</p>
<pre><code class="language-xml">&lt;yandex&gt;
    &lt;remote_servers&gt;
        &lt;fz_cluster&gt; &lt;!-- 集群名称--&gt;
            &lt;shard&gt; &lt;!--集群的第一个分片--&gt;
                &lt;internal_replication&gt;true&lt;/internal_replication&gt;
                &lt;!--该分片的第一个副本--&gt;
                &lt;replica&gt;
                    &lt;host&gt;node01&lt;/host&gt;
                    &lt;port&gt;9000&lt;/port&gt;
                &lt;/replica&gt;
                &lt;!--该分片的第二个副本--&gt;
                &lt;replica&gt;
                    &lt;host&gt;node02&lt;/host&gt;
                    &lt;port&gt;9000&lt;/port&gt;
                &lt;/replica&gt;
            &lt;/shard&gt;
            &lt;shard&gt; &lt;!--集群的第二个分片--&gt;
                &lt;internal_replication&gt;true&lt;/internal_replication&gt;
                &lt;replica&gt; &lt;!--该分片的第一个副本--&gt;
                    &lt;host&gt;node03&lt;/host&gt;
                    &lt;port&gt;9000&lt;/port&gt;
                &lt;/replica&gt;
                &lt;replica&gt; &lt;!--该分片的第二个副本--&gt;
                    &lt;host&gt;node04&lt;/host&gt;
                    &lt;port&gt;9000&lt;/port&gt;
                &lt;/replica&gt;
            &lt;/shard&gt;
            &lt;shard&gt; &lt;!--集群的第三个分片--&gt;
                &lt;internal_replication&gt;true&lt;/internal_replication&gt;
                &lt;replica&gt; &lt;!--该分片的第一个副本--&gt;
                    &lt;host&gt;node05&lt;/host&gt;
                    &lt;port&gt;9000&lt;/port&gt;
                &lt;/replica&gt;
                &lt;replica&gt; &lt;!--该分片的第二个副本--&gt;
                    &lt;host&gt;node06&lt;/host&gt;
                    &lt;port&gt;9000&lt;/port&gt;
                &lt;/replica&gt;
            &lt;/shard&gt;
        &lt;/fz_cluster&gt;
    &lt;/remote_servers&gt;
&lt;/yandex&gt;
</code></pre>
<h4 id="4-配置三节点版本集群及副本">4 .配置三节点版本集群及副本</h4>
<h5 id="41-集群及副本规划2-个分片只有第一个分片有副本">4.1 集群及副本规划（2 个分片，只有第一个分片有副本）</h5>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1656505279732.png" alt="" loading="lazy"></figure>
<h5 id="42-配置步骤">4.2 配置步骤</h5>
<p>1）在 Node01 的/etc/clickhouse-server/config.d 目录下创建 metrika-shard.xml 文件 vim /etc/clickhouse-server/config.d/metrika-shard.xml 注：也可以不创建外部文件，直接在 config.xml 的&lt;remote_servers&gt;中指定</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot;?&gt; 
&lt;yandex&gt;     
    &lt;remote_servers&gt;         
        &lt;gmall_cluster&gt; &lt;!-- 集群名称--&gt;             
            &lt;shard&gt; &lt;!--集群的第一个分片--&gt;                 
                &lt;internal_replication&gt;true&lt;/internal_replication&gt;                 
                &lt;replica&gt; &lt;!--该分片的第一个副本--&gt;                     
                    &lt;host&gt;Node01&lt;/host&gt;                     
                    &lt;port&gt;9000&lt;/port&gt;                     
                    &lt;user&gt;default&lt;/user&gt;                     
                    &lt;password&gt;1234qwer&lt;/password&gt;                 
                &lt;/replica&gt;                 
                &lt;replica&gt; &lt;!--该分片的第二个副本--&gt;                     
                    &lt;host&gt;Node02&lt;/host&gt;                     
                    &lt;port&gt;9000&lt;/port&gt;                     
                    &lt;user&gt;default&lt;/user&gt;                     
                    &lt;password&gt;1234qwer&lt;/password&gt;                 
                &lt;/replica&gt;             
            &lt;/shard&gt;             
            &lt;shard&gt; &lt;!--集群的第二个分片--&gt;                 
                &lt;internal_replication&gt;true&lt;/internal_replication&gt;                 
                &lt;replica&gt; &lt;!--该分片的第一个副本--&gt;                    
                    &lt;host&gt;Node03&lt;/host&gt;                     
                    &lt;port&gt;9000&lt;/port&gt;                     
                    &lt;user&gt;default&lt;/user&gt;                     
                    &lt;password&gt;1234qwer&lt;/password&gt;                 
                &lt;/replica&gt;             
            &lt;/shard&gt;         
        &lt;/gmall_cluster&gt;     
    &lt;/remote_servers&gt;          
    &lt;zookeeper-servers&gt;         
        &lt;node index=&quot;1&quot;&gt;             
            &lt;host&gt;Node01&lt;/host&gt;             
            &lt;port&gt;2181&lt;/port&gt;         
        &lt;/node&gt;         
        &lt;node index=&quot;2&quot;&gt;             
            &lt;host&gt;Node02&lt;/host&gt;             
            &lt;port&gt;2181&lt;/port&gt;         
        &lt;/node&gt;         
        &lt;node index=&quot;3&quot;&gt;             
            &lt;host&gt;Node03&lt;/host&gt;             
            &lt;port&gt;2181&lt;/port&gt;         
        &lt;/node&gt;     
    &lt;/zookeeper-servers&gt;     
    &lt;macros&gt;         
        &lt;shard&gt;01&lt;/shard&gt; &lt;!--不同机器放的分片数不一样--&gt;         
        &lt;replica&gt;rep_1_1&lt;/replica&gt; &lt;!--不同机器放的副本数不一样--&gt;     
    &lt;/macros&gt; 
&lt;/yandex&gt;
</code></pre>
<p>2）将 Node01 的 metrika-shard.xml 同步到 Node02 和 Node03</p>
<pre><code class="language-shell">scp /etc/clickhouse-server/config.d/metrika-shard.xml root@Node02:/etc/clickhouse-server/config.d/
scp /etc/clickhouse-server/config.d/metrika-shard.xml root@Node03:/etc/clickhouse-server/config.d/
</code></pre>
<p>3）修改 Node02 和 Node03 中 metrika-shard.xml 宏的配置</p>
<p>（1）Node02</p>
<pre><code class="language-xml">&lt;macros&gt;
        &lt;shard&gt;01&lt;/shard&gt; &lt;!--不同机器放的分片数不一样--&gt;
        &lt;replica&gt;rep_1_2&lt;/replica&gt; &lt;!--不同机器放的副本数不一样--&gt;
&lt;/macros&gt;1.2.3.4.
</code></pre>
<p>（2）Node03</p>
<pre><code class="language-xml">&lt;macros&gt;
        &lt;shard&gt;02&lt;/shard&gt; &lt;!--不同机器放的分片数不一样--&gt;
        &lt;replica&gt;rep_2_1&lt;/replica&gt; &lt;!--不同机器放的副本数不一样--&gt;
&lt;/macros&gt;1.2.3.4.
</code></pre>
<p>4）在 Node01 上修改/etc/clickhouse-server/config.xml</p>
<pre><code class="language-shell">vim /etc/clickhouse-server/config.xml 
 
&lt;zookeeper incl=&quot;zookeeper-servers&quot; optional=&quot;true&quot; /&gt;
&lt;include_from&gt;/etc/clickhouse-server/config.d/metrika-shard.xml&lt;/include_from&gt;
</code></pre>
<p>5）同步/etc/clickhouse-server/config.xml 到 Node02 和 Node03</p>
<pre><code class="language-shell">scp /etc/clickhouse-server/config.xml root@Node02:/etc/clickhouse-server/
scp /etc/clickhouse-server/config.xml root@Node03:/etc/clickhouse-server/
</code></pre>
<p>6）重启三台服务器上的 ClickHouse 服务 sudo clickhouse restart  查看集群</p>
<pre><code>superset-BI :) show clusters;
SHOW CLUSTERS
Query id: 391735d2-bf74-43f5-aa86-b6d203c357cd
┌─cluster─────────────────────────────────────────┐
│ gmall_cluster                                   │
│ test_cluster_one_shard_three_replicas_localhost │
│ test_cluster_two_shards                         │
│ test_cluster_two_shards_internal_replication    │
│ test_cluster_two_shards_localhost               │
│ test_shard_localhost                            │
│ test_shard_localhost_secure                     │
│ test_unavailable_shard                          │
└─────────────────────────────────────────────────┘
8 rows in set. Elapsed: 0.002 sec.
</code></pre>
<p>7）在 Node01 上执行建表语句 ➢ 会自动同步到 Node02 和 Node03 上 ➢ 集群名字要和配置文件中的一致 ➢ 分片和副本名称从配置文件的宏定义中获取</p>
<pre><code class="language-sql">create table st_fz_order_mt_01 on cluster gmall_cluster ( 
    id UInt32, 
    sku_id String, 
    total_amount Decimal(16,2), 
    create_time Datetime 
) engine =ReplicatedMergeTree('/clickhouse/tables/{shard}/st_fz_order_mt_01','{replica}') 
partition by toYYYYMMDD(create_time) 
primary key (id) 
order by (id,sku_id);  
</code></pre>
<pre><code class="language-sql">create table st_fz_order_mt_01 on cluster gmall_cluster (  
	id UInt32,        
    sku_id String,         
    total_amount Decimal(16,2),         
    create_time Datetime         
) engine =ReplicatedMergeTree('/clickhouse/tables/{shard}/st_fz_order_mt_01','{replica}')         
partition by toYYYYMMDD(create_time)         
primary key (id)         
order by (id,sku_id); 
</code></pre>
<pre><code class="language-sql">CREATE TABLE st_fz_order_mt_01 ON CLUSTER gmall_cluster (  
	`id` UInt32,   
    `sku_id` String,   
    `total_amount` Decimal(16, 2),   
    `create_time` Datetime 
) ENGINE = ReplicatedMergeTree('/clickhouse/tables/{shard}/st_fz_order_mt_01', '{replica}') 
PARTITION BY toYYYYMMDD(create_time) 
PRIMARY KEY id 
ORDER BY (id, sku_id) 
</code></pre>
<p>在Node02和Node03上查看表是否创建成功 show tables;</p>
<p>8）在 Node02 上创建 Distribute 分布式表</p>
<pre><code class="language-sql">create table st_fz_order_mt_all2 on cluster gmall_cluster (      
    id UInt32,       
    sku_id String,       
    total_amount Decimal(16,2),       
    create_time Datetime       
)engine = Distributed(gmall_cluster,default, st_fz_order_mt_01,hiveHash(sku_id)); 
CREATE TABLE st_fz_order_mt_all2 ON CLUSTER gmall_cluster (   
    `id` UInt32,   
    `sku_id` String,   
    `total_amount` Decimal(16, 2),   
    `create_time` Datetime 
) ENGINE = Distributed(gmall_cluster, default, st_fz_order_mt_01, hiveHash(sku_id)) 
</code></pre>
<p>参数含义： Distributed（集群名称，库名，本地表名，分片键） 分片键必须是整型数字，所以用 hiveHash 函数转换，也可以 rand()</p>
<p>9）在 Node01 上插入测试数据</p>
<pre><code class="language-sql">insert into st_order_mt_all2 values
(201,'sku_001',1000.00,'2020-06-01 12:00:00') ,
(202,'sku_002',2000.00,'2020-06-01 12:00:00'),
(203,'sku_004',2500.00,'2020-06-01 12:00:00'),
(204,'sku_002',2000.00,'2020-06-01 12:00:00'),
(205,'sku_003',600.00,'2020-06-02 12:00:00');1.2.3.4.5.6.
</code></pre>
<p>10）通过查询分布式表和本地表观察输出结果 （1）分布式表</p>
<pre><code class="language-sql">select * From st_fz_order_mt_all2;

Query id: d8b676e9-c119-4483-8ca2-f0b5cd150a61
┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐
│ 202 │ sku_002 │         2000 │ 2020-06-01 12:00:00 │
│ 203 │ sku_004 │         2500 │ 2020-06-01 12:00:00 │
│ 204 │ sku_002 │         2000 │ 2020-06-01 12:00:00 │
└─────┴─────────┴──────────────┴─────────────────────┘
┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐
│ 205 │ sku_003 │          600 │ 2020-06-02 12:00:00 │
└─────┴─────────┴──────────────┴─────────────────────┘
┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐
│ 201 │ sku_001 │         1000 │ 2020-06-01 12:00:00 │
└─────┴─────────┴──────────────┴─────────────────────┘
</code></pre>
<p>（2）本地表</p>
<pre><code class="language-sql">Node1:
SELECT *
FROM st_fz_order_mt_01
Query id: ddcb5176-e443-4253-9877-57fec8f57311
┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐
│ 202 │ sku_002 │         2000 │ 2020-06-01 12:00:00 │
│ 203 │ sku_004 │         2500 │ 2020-06-01 12:00:00 │
│ 204 │ sku_002 │         2000 │ 2020-06-01 12:00:00 │
└─────┴─────────┴──────────────┴─────────────────────┘
3 rows in set. Elapsed: 0.002 sec. 


Node3:
SELECT *
FROM st_fz_order_mt_01
Query id: 7a336004-7040-4098-948e-1e7c5d983edb
┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐
│ 205 │ sku_003 │          600 │ 2020-06-02 12:00:00 │
└─────┴─────────┴──────────────┴─────────────────────┘
┌──id─┬─sku_id──┬─total_amount─┬─────────create_time─┐
│ 201 │ sku_001 │         1000 │ 2020-06-01 12:00:00 │
└─────┴─────────┴──────────────┴─────────────────────┘
2 rows in set. Elapsed: 0.002 sec.
</code></pre>
<p>可以看到数据分布在Node1和Node3两个节点上。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ClickHouse-7副本]]></title>
        <id>https://tinaxiawuhao.github.io/post/bps7a3f5p/</id>
        <link href="https://tinaxiawuhao.github.io/post/bps7a3f5p/">
        </link>
        <updated>2021-11-18T11:48:12.000Z</updated>
        <content type="html"><![CDATA[<h3 id="1-副本写入流程">1 副本写入流程</h3>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1656505319411.png" alt="" loading="lazy"></figure>
<h3 id="2-配置步骤">2 配置步骤</h3>
<ol>
<li>
<p>启动 zookeeper 集群</p>
</li>
<li>
<p>在 hadoop102 的/etc/clickhouse-server/config.d 目录下创建一个名为 metrika.xml 的配置文件,内容如下：<br>
注：也可以不创建外部文件，直接在 config.xml 中指定</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot;?&gt;
&lt;yandex&gt;
	&lt;zookeeper-servers&gt;
	&lt;node index=&quot;1&quot;&gt;
		&lt;host&gt;hadoop102&lt;/host&gt;
		&lt;port&gt;2181&lt;/port&gt;
	&lt;/node&gt;
	&lt;node index=&quot;2&quot;&gt;
		&lt;host&gt;hadoop103&lt;/host&gt;
		&lt;port&gt;2181&lt;/port&gt;
	&lt;/node&gt;
	&lt;node index=&quot;3&quot;&gt;
		&lt;host&gt;hadoop104&lt;/host&gt;
		&lt;port&gt;2181&lt;/port&gt;
	&lt;/node&gt;
	&lt;/zookeeper-servers&gt;
&lt;/yandex&gt;
</code></pre>
</li>
<li>
<p>同步到 hadoop103 和 hadoop104 上</p>
<pre><code class="language-shell">sudo /home/atguigu/bin/xsync /etc/clickhouse-server/config.d/metrika.xml
</code></pre>
</li>
<li>
<p>在 hadoop102 的/etc/clickhouse-server/config.xml 中增加</p>
<pre><code class="language-shell">&lt;zookeeper incl=&quot;zookeeper-servers&quot; optional=&quot;true&quot; /&gt;
&lt;include_from&gt;/etc/clickhouse-server/config.d/metrika.xml&lt;/include_from&gt;
</code></pre>
</li>
<li>
<p>同步到 hadoop103 和 hadoop104 上</p>
<pre><code class="language-shell">sudo /home/atguigu/bin/xsync /etc/clickhouse-server/config.xml
</code></pre>
<p>分别在 hadoop102 和 hadoop103 上启动 ClickHouse 服务</p>
<p><strong>注意：因为修改了配置文件，如果以前启动了服务需要重启</strong></p>
<pre><code class="language-shell">sudo clickhouse restart
</code></pre>
<p>注意：我们演示副本操作只需要在 hadoop102 和 hadoop103 两台服务器即可，上面的<br>
操作，我们 hadoop104 可以你不用同步，我们这里为了保证集群中资源的一致性，做了同<br>
步。</p>
</li>
<li>
<p>在 hadoop102 和 hadoop103 上分别建表<br>
副本只能同步数据，不能同步表结构，所以我们需要在每台机器上自己手动建表</p>
<pre><code class="language-shell">create table t_order_rep2 (
    id UInt32,
    sku_id String,
    total_amount Decimal(16,2),
    create_time
    Datetime
) engine = ReplicatedMergeTree('/clickhouse/table/01/t_order_rep','rep_102')
partition by toYYYYMMDD(create_time)
primary key (id)
order by (id,sku_id);
</code></pre>
<blockquote>
<p>ReplicatedMergeTree(‘/clickhouse/table/01/t_order_rep’,‘rep_102’)中，</p>
<p>第一个参数是分片的 zk_path ， 一般按照：/clickhouse/table/{shard}/{table_name} 的格式写，如果只有一个分片就写 01 即可。<br>
第二个参数是副本名称，相同的分片副本名称不能相同。</p>
</blockquote>
</li>
<li>
<p>在 hadoop102 上执行 insert 语句</p>
<pre><code class="language-shell">insert into t_order_rep2 values
(101,'sku_001',1000.00,'2020-06-01 12:00:00'),
(102,'sku_002',2000.00,'2020-06-01 12:00:00'),
(103,'sku_004',2500.00,'2020-06-01 12:00:00'),
(104,'sku_002',2000.00,'2020-06-01 12:00:00'),
(105,'sku_003',600.00,'2020-06-02 12:00:00');
</code></pre>
</li>
<li>
<p>在 hadoop103 上执行 select，可以查询出结果，说明副本配置正确</p>
</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ClickHouse-6sql操作]]></title>
        <id>https://tinaxiawuhao.github.io/post/3wkSNwWQy/</id>
        <link href="https://tinaxiawuhao.github.io/post/3wkSNwWQy/">
        </link>
        <updated>2021-11-17T11:46:57.000Z</updated>
        <content type="html"><![CDATA[<h3 id="1-insert">1 Insert</h3>
<p>基本与标准 SQL（MySQL）基本一致</p>
<p><strong>标准</strong></p>
<pre><code class="language-sql">insert into [table_name] values(…),(….) 
</code></pre>
<p><strong>从表到表的插入</strong></p>
<pre><code class="language-sql">insert into [table_name] select a,b,c from [table_name_2]
</code></pre>
<h3 id="2-update-和-delete">2 Update 和 Delete</h3>
<p>ClickHouse 提供了 Delete 和 Update 的能力，这类操作被称为 Mutation 查询，它可以看做 Alter 的一种。<br>
虽然可以实现修改和删除，但是和一般的 OLTP 数据库不一样，Mutation 语句是一种很“重”的操作，而且不支持事务。<br>
“重”的原因主要是每次修改或者删除都会导致放弃目标数据的原有分区，重建新分区。所以尽量做批量的变更，不要进行频繁小数据的操作。</p>
<p><strong>删除操作</strong></p>
<pre><code class="language-sql">alter table t_order_smt delete where sku_id ='sku_001';
</code></pre>
<p><strong>修改操作</strong></p>
<pre><code class="language-sql">alter table t_order_smt update total_amount=toDecimal32(2000.00,2) where id =102;
</code></pre>
<p>由于操作比较“重”，所以 Mutation 语句分两步执行，同步执行的部分其实只是进行新增数据新增分区和并把旧分区打上逻辑上的失效标记。直到触发分区合并的时候，才会删除旧数据释放磁盘空间，一般不会开放这样的功能给用户，由管理员完成。</p>
<h3 id="3-查询操作">3 查询操作</h3>
<p>ClickHouse 基本上与标准 SQL 差别不大</p>
<blockquote>
<p>支持子查询<br>
支持 CTE(Common Table Expression 公用表表达式 with 子句)<br>
支持各种 JOIN，但是 JOIN 操作无法使用缓存, 尽量避免使用 JOIN，所以即使是两次相同的 JOIN 语句，ClickHouse 也会视为两条新 SQL<br>
窗口函数<br>
不支持自定义函数<br>
GROUP BY 操作增加了 with rollup \ with cube \ with total 用来计算小计和总计。</p>
</blockquote>
<p><strong>插入数据</strong></p>
<pre><code class="language-sql">alter table t_order_mt delete where 1=1;
insert into t_order_mt values
(101,'sku_001',1000.00,'2020-06-01 12:00:00'),
(101,'sku_002',2000.00,'2020-06-01 12:00:00'),
(103,'sku_004',2500.00,'2020-06-01 12:00:00'),
(104,'sku_002',2000.00,'2020-06-01 12:00:00'),
(105,'sku_003',600.00,'2020-06-02 12:00:00'),
(106,'sku_001',1000.00,'2020-06-04 12:00:00'),
(107,'sku_002',2000.00,'2020-06-04 12:00:00'),
(108,'sku_004',2500.00,'2020-06-04 12:00:00'),
(109,'sku_002',2000.00,'2020-06-04 12:00:00'),
(110,'sku_003',600.00,'2020-06-01 12:00:00');
</code></pre>
<p><strong>with rollup</strong>：上卷，从右至左去掉维度进行小计</p>
<pre><code class="language-sql">select id , sku_id,sum(total_amount) from t_order_mt group by id,sku_id with rollup;
</code></pre>
<p><strong>with cube</strong> : 多维分析， 从右至左去掉维度进行小计，再从左至右去掉维度进行小计</p>
<pre><code class="language-sql">select id , sku_id,sum(total_amount) from t_order_mt group by id,sku_id with cube;
</code></pre>
<p><strong>with totals</strong>: 只计算合计</p>
<pre><code class="language-sql">select id , sku_id,sum(total_amount) from t_order_mt group by id,sku_id with totals;
</code></pre>
<h3 id="4-alter-操作">4 alter 操作</h3>
<p>同 MySQL 的修改字段基本一致</p>
<p><strong>新增字段</strong></p>
<pre><code class="language-sql">alter table tableName add column newcolname String after col1;
</code></pre>
<p><strong>修改字段类型</strong></p>
<pre><code class="language-sql">alter table tableName modify column newcolname String;
</code></pre>
<p><strong>删除字段</strong></p>
<pre><code class="language-sql">alter table tableName drop column newcolname;
</code></pre>
<h3 id="5-导出数据">5 导出数据</h3>
<p>这个用的比较少</p>
<pre><code>clickhouse-client --query &quot;select * from t_order_mt where create_time='2020-06-01 12:00:00'&quot; --format CSVWithNames&gt; /opt/module/data/rs1.csv
</code></pre>
<p>更多支持格式参照：https://clickhouse.com/docs/en/interfaces/formats/</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Clickhouse-5数据分区]]></title>
        <id>https://tinaxiawuhao.github.io/post/hle1ZXFqv/</id>
        <link href="https://tinaxiawuhao.github.io/post/hle1ZXFqv/">
        </link>
        <updated>2021-11-16T07:16:43.000Z</updated>
        <content type="html"><![CDATA[<h2 id="mergetree-数据分区规则">MergeTree 数据分区规则</h2>
<p>创建按照月份为分区条件的表 <strong>tab_partition</strong></p>
<pre><code class="language-csharp">CREATE TABLE tab_partition(`dt` Date, `v` UInt8) 
ENGINE = MergeTree PARTITION BY toYYYYMM(dt) ORDER BY v;
insert into tab_partition(dt,v) values ('2020-02-11',1),('2020-02-13',2);
insert into tab_partition(dt,v) values ('2020-04-11',3),('2020-04-13',4);
insert into tab_partition(dt,v) values ('2020-09-11',5),('2020-09-10',6);
insert into tab_partition(dt,v) values ('2020-10-12',7),('2020-10-09',8);
insert into tab_partition(dt,v) values ('2020-02-14',9),('2020-02-15',10);
insert into tab_partition(dt,v) values ('2020-02-11',23),('2020-02-13',45);
</code></pre>
<p>MergeTree 存储引擎在写入数据之后生成对应的分区文件为：</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1639552667308.webp" alt="" loading="lazy"></figure>
<p>MergeTree 的分区目录是在写入数据的过程中被创建出来，每 insert 一次，就会创建一批次分区目录。也就是说如果仅创建表结构，是不会创建分区目录的，因为木有数据。</p>
<p>MergeTree 数据分区目录命名规则其规则为：<strong>PartitionID_MinBlockNum_MaxBlockNum_Level</strong><br>
比如 <strong>202002_4_4_0</strong> 其中 202002 是分区ID ，<strong>4_4</strong> 对应的是<br>
最小的数据块编号和最大的数据块编号，最后的 _0 表示目前分区合并的层级。<br>
各部分的含义及命名规则如下：<br>
PartitionID：该值由 insert 数据时分区键的值来决定。分区键支持使用任何一个或者多个字段组合表达式，针对取值数据类型的不同，分区 ID 的生成逻辑目前有四种规则：</p>
<blockquote>
<p>不指定分区键：如果建表时未指定分区键，则分区 ID 默认使用 all，所有数据都被写入 all 分区中。</p>
<p>整型字段：如果分区键取值是整型字段，并且无法转换为 YYYYMMDD 的格式，则会按照该整型字段的字符形式输出，作为分区 ID 取值。</p>
<p>日期类型：如果分区键属于日期格式，或可以转换为 YYYYMMDD 格式的整型，则按照 YYYYMMDD 格式化后的字符形式输出，作为分区 ID 取值。</p>
<p>其他类型：如果使用其他类似 Float、String 等类型作为分区键，会通过对其插入数据的 128 位 Hash 值作为分区 ID 的取值。</p>
</blockquote>
<p>MinBlockNum 和 MaxBlockNum：BlockNum 是一个整型的自增长型编号，该编号在单张 MergeTree 表中从 1 开始全局累加，当有新的分区目录创建后，该值就加 1，对新的分区目录来讲，MinBlockNum 和 MaxBlockNum 取值相同。例如上面示例数据为 202002_1_1_0  202002_1_5_1，但当分区目录进行合并后，取值规则会发生变化，MinBlockNum 取同一分区所欲目录中最新的 MinBlockNum 值。MaxBlockNum 取同一分区内所有目录中的最大值。<br>
Level：表示合并的层级。相当于某个分区被合并的次数，它不是以表全局累加，而是以分区为单位，初始创建的分区，初始值为 0，相同分区 ID 发生合并动作时，在相应分区内累计加 1。</p>
<h2 id="mergetree-数据分区合并规则">MergeTree 数据分区合并规则</h2>
<p>随着数据的写入 MergeTree 存储引擎会很多分区目录。如果分区目录数太多怎么办？因为 Clickhouse 的 MergeTree 存储引擎是基于 LSM 实现的。MergeTree 可以通过分区合并将属于相同分区的多个目录合并为一个新的目录（官方描述在 10 到 15 分钟内会进行合并，也可直接执行 optimize 语句），已经存在的旧目录（也即 system.parts 表中 activie 为 0 的分区）在之后某个时刻通过后台任务删除（默认 8 分钟）。</p>
<h3 id="分区合并">分区合并</h3>
<p>我们回顾之前创建的表的分区目录</p>
<pre><code class="language-bash"># ls 
202002_1_1_0  202004_2_2_0  202009_3_3_0
202002_4_4_0  202002_5_5_0
</code></pre>
<p>手工触发分区合并</p>
<pre><code class="language-csharp">qabb-qa-ch00 :) optimize table tab_partition;
OPTIMIZE TABLE tab_partition
Ok.
0 rows in set. Elapsed: 0.003 sec.

qabb-qa-ch00 :) select partition,name,part_type, active from system.parts where  table ='tab_partition';
┌─partition─┬─name─────────┬─part_type─┬─active─┐
│ 202002    │ 202002_1_1_0 │ Wide      │      0 │
│ 202002    │ 202002_1_5_1 │ Wide      │      1 │
│ 202002    │ 202002_4_4_0 │ Wide      │      0 │
│ 202002    │ 202002_5_5_0 │ Wide      │      0 │
│ 202004    │ 202004_2_2_0 │ Wide      │      1 │
│ 202009    │ 202009_3_3_0 │ Wide      │      1 │
└───────────┴──────────────┴───────────┴────────┘

6 rows in set. Elapsed: 0.003 sec.
</code></pre>
<p>其中 active 为 1 表示经过合并之后的最新分区，为 0 则表示旧分区，查询时会自动过滤 active=0 的分区。<br>
我们通过分区 202002 最新的分区目录 <strong>202002_1_5_1</strong> 看到合并分区新目录的命名规则如下：</p>
<blockquote>
<p>PartitionID：分区 ID 保持不变<br>
MinBlockNum：取同一个分区内所有目录中最小的 MinBlockNum 值<br>
MaxBlockNUm：取同一个分区内所有目录中最大的 MaxBlockNum 值<br>
Level：取同一个分区内最大 Level 值并加 1</p>
</blockquote>
<p>合并之后的目录结构如下：</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1639552681661.webp" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ClickHouse-4表引擎]]></title>
        <id>https://tinaxiawuhao.github.io/post/XvNkKhwMg/</id>
        <link href="https://tinaxiawuhao.github.io/post/XvNkKhwMg/">
        </link>
        <updated>2021-11-15T11:44:27.000Z</updated>
        <content type="html"><![CDATA[<h3 id="1-表引擎的使用">1 表引擎的使用</h3>
<p>表引擎是 ClickHouse 的一大特色。可以说，表引擎决定了如何存储表的数据。包括：</p>
<blockquote>
<p>数据的存储方式和位置，写到哪里以及从哪里读取数据。(默认是在安装路径下的 data 路径)<br>
支持哪些查询以及如何支持。（有些语法只有在特定的引擎下才能用）<br>
并发数据访问。<br>
索引的使用（如果存在）。<br>
是否可以执行多线程请求。<br>
数据复制参数。<br>
表引擎的使用方式就是必须显式在创建表时定义该表使用的引擎，以及引擎使用的相关参数。</p>
<p>特别注意：引擎的名称大小写敏感, 驼峰命名</p>
</blockquote>
<h3 id="2-tinylog">2 TinyLog</h3>
<p>以列文件的形式保存在磁盘上，不支持索引，没有并发控制。一般保存少量数据的小表，生产环境上作用有限。可以用于平时练习测试用。</p>
<p>如：</p>
<pre><code class="language-sql">create table t_tinylog ( id String, name String) engine=TinyLog;
</code></pre>
<h3 id="3-memory">3 Memory</h3>
<p>内存引擎，数据以未压缩的原始形式直接保存在内存当中，服务器重启数据就会消失。读写操作不会相互阻塞，不支持索引。简单查询下有非常非常高的性能表现（超过 10G/s）。<br>
一般用到它的地方不多，除了用来测试，就是在需要非常高的性能，同时数据量又不太大（上限大概 1 亿行）的场景。</p>
<h3 id="4-mergetree">4 MergeTree</h3>
<p>ClickHouse 中最强大的表引擎当属 MergeTree（合并树）引擎及该系列（*MergeTree）中的其他引擎，支持索引和分区，地位可以相当于 innodb 之于 Mysql。而且基于 MergeTree，还衍生除了很多小弟，也是非常有特色的引擎。</p>
<p><strong>建表语句</strong></p>
<pre><code class="language-sql">create table t_order_mt(
    id UInt32,
    sku_id String,
    total_amount Decimal(16,2),
    create_time Datetime
) engine =MergeTree
partition by toYYYYMMDD(create_time)
primary key (id)
order by (id,sku_id);
</code></pre>
<p><strong>插入数据</strong></p>
<pre><code class="language-sql">insert into t_order_mt values
(101,'sku_001',1000.00,'2020-06-01 12:00:00') ,
(102,'sku_002',2000.00,'2020-06-01 11:00:00'),
(102,'sku_004',2500.00,'2020-06-01 12:00:00'),
(102,'sku_002',2000.00,'2020-06-01 13:00:00'),
(102,'sku_002',12000.00,'2020-06-01 13:00:00'),
(102,'sku_002',600.00,'2020-06-02 12:00:00');
</code></pre>
<p>MergeTree 其实还有很多参数(绝大多数用默认值即可)，但是三个参数是更加重要的，也涉及了关于 MergeTree 的很多概念。</p>
<h4 id="41-partition-by-分区可选">4.1 partition by 分区(可选)</h4>
<p><strong>作用</strong><br>
学过 hive 的应该都不陌生，分区的目的主要是降低扫描的范围，优化查询速度，如果不填,只会使用一个分区 —— all。</p>
<p><strong>分区目录</strong><br>
MergeTree 是以列文件+索引文件+表定义文件组成的，但是如果设定了分区那么这些文件就会保存到不同的分区目录中。目录保存在本地磁盘</p>
<p><strong>并行</strong><br>
分区后，面对涉及跨分区的查询统计，ClickHouse 会以分区为单位并行处理， 即一个线程处理一个分区内的数据。</p>
<p><strong>数据写入与分区合并</strong><br>
任何一个批次的数据写入都会产生一个临时分区，不会纳入任何一个已有的分区。写入后的某个时刻（大概 10-15 分钟后），ClickHouse 会自动执行合并操作（等不及也可以手动通过 optimize 执行），把临时分区的数据，合并到已有分区中。</p>
<pre><code class="language-sql">optimize table xxxx final;
</code></pre>
<p><strong>例如</strong><br>
再次执行上面的插入操作</p>
<pre><code class="language-sql">insert into t_order_mt values
(101,'sku_001',1000.00,'2020-06-01 12:00:00') ,
(102,'sku_002',2000.00,'2020-06-01 11:00:00'),
(102,'sku_004',2500.00,'2020-06-01 12:00:00'),
(102,'sku_002',2000.00,'2020-06-01 13:00:00'),
(102,'sku_002',12000.00,'2020-06-01 13:00:00'),
(102,'sku_002',600.00,'2020-06-02 12:00:00');
</code></pre>
<p>查看数据并没有纳入任何分区</p>
<p>手动 <code>optimize</code> 之后</p>
<pre><code class="language-sql">optimize table t_order_mt final;
</code></pre>
<h4 id="42-primary-key-主键可选">4.2 primary key 主键(可选)</h4>
<p>ClickHouse 中的主键，和其他数据库不太一样，它只提供了数据的一级索引，但是却不是唯一约束。这就意味着是可以存在相同 primary key 的数据的。<br>
主键的设定主要依据是查询语句中的 where 条件。<br>
根据条件通过对主键进行某种形式的二分查找，能够定位到对应的 index granularity,避免了全表扫描。<br>
index granularity： 直接翻译的话就是索引粒度，指在稀疏索引中两个相邻索引对应数据的间隔。ClickHouse 中的 MergeTree 默认是 8192。官方不建议修改这个值，除非该列存在大量重复值，比如在一个分区中几万行才有一个不同数据。</p>
<p>稀疏索引：</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1656505152575.png" alt="" loading="lazy"></figure>
<p>稀疏索引的好处就是可以用很少的索引数据，定位更多的数据，代价就是只能定位到索引粒度的第一行，然后再进行进行一点扫描。</p>
<h4 id="43-order-by必选">4.3 order by（必选）</h4>
<p>order by 设定了分区内的数据按照哪些字段顺序进行有序保存。<br>
order by 是 MergeTree 中唯一一个必填项，甚至比 primary key 还重要，因为当用户不设置主键的情况，很多处理会依照 order by 的字段进行处理（比如后面会讲的去重和汇总）。<br>
要求：主键必须是 order by 字段的前缀字段。有点类似 SQL 索引中的最左前缀。<br>
比如 order by 字段是 (id,sku_id) 那么主键必须是 id 或者(id,sku_id)</p>
<h4 id="44-二级索引跳数索引">4.4 二级索引(跳数索引)</h4>
<p>目前在 ClickHouse 的官网上二级索引的功能在 v20.1.2.4 之前是被标注为实验性的，在这个版本之后默认是开启的。</p>
<p>老版本使用二级索引前需要增加设置<br>
是否允许使用实验性的二级索引（v20.1.2.4 开始，这个参数已被删除，默认开启）</p>
<pre><code class="language-sql">set allow_experimental_data_skipping_indices=1;
</code></pre>
<p><strong>创建测试表</strong></p>
<pre><code class="language-sql">create table t_order_mt2(
    id UInt32,
    sku_id String,
    total_amount Decimal(16,2),
    create_time Datetime,
    INDEX a total_amount TYPE minmax GRANULARITY 5
) engine =MergeTree
partition by toYYYYMMDD(create_time)
primary key (id)
order by (id, sku_id);
</code></pre>
<p>最主要的是需要加上这一句：<code>INDEX a total_amount TYPE minmax GRANULARITY 5</code><br>
其中：</p>
<blockquote>
<p>INDEX a： 定义一个索引，并命名为 a<br>
total_amount： 索引字段名称<br>
TYPE minmax： 定义类型， 保存最大最小值<br>
GRANULARITY N：是设定二级索引对于一级索引粒度的粒度。一级索引会记录每个分区的最大最小值，二级索引就是在一级索引的基础上，取每 N 个分区合在一起的最大最小值。</p>
</blockquote>
<p><strong>插入数据</strong></p>
<pre><code class="language-sql">insert into t_order_mt2 values
(101,'sku_001',1000.00,'2020-06-01 12:00:00') ,
(102,'sku_002',2000.00,'2020-06-01 11:00:00'),
(102,'sku_004',2500.00,'2020-06-01 12:00:00'),
(102,'sku_002',2000.00,'2020-06-01 13:00:00'),
(102,'sku_002',12000.00,'2020-06-01 13:00:00'),
(102,'sku_002',600.00,'2020-06-02 12:00:00');
</code></pre>
<p><strong>对比效果</strong><br>
那么在使用下面语句进行测试，可以看出二级索引能够为非主键字段的查询发挥作用。</p>
<pre><code class="language-shell">clickhouse-client --send_logs_level=trace &lt;&lt;&lt; 'select * from t_order_mt2 where total_amount &gt; toDecimal32(900., 2)';
</code></pre>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1656505167546.png" alt="" loading="lazy"></figure>
<h4 id="45-数据-ttl数据存活时间">4.5 数据 TTL（数据存活时间）</h4>
<p>TTL 即 Time To Live，MergeTree 提供了可以管理数据表或者列的生命周期的功能。过期的数据不会立马处理，只是会做标记，等到合并时一起处理。</p>
<p><strong>列级别 TTL</strong><br>
（1）创建测试表</p>
<pre><code class="language-sql">create table t_order_mt3(
    id UInt32,
    sku_id String,
    total_amount Decimal(16,2) TTL create_time+interval 10 SECOND,
    create_time Datetime 
) engine =MergeTree
partition by toYYYYMMDD(create_time)
primary key (id)
order by (id, sku_id);
</code></pre>
<p>在列后加上： <code>TTL create_time+interval 10 SECOND</code><br>
其中：</p>
<blockquote>
<p>TTL：定义一个过期时间<br>
create_time：使用了当前表中的一个 Datetime 类型的列，TTL 中引用的字段不能是主键字段，且类型必须是 日期类型<br>
± interval 10 SECOND：需要增加/减少的 时间长度 时间单位</p>
</blockquote>
<p>注：如果在建表时没有加 TTL 配置，需要在建表之后加，那么则需要使用如下语法：</p>
<pre><code class="language-sql">ALTER TABLE 表名
    MODIFY COLUMN
    列名 列数据类型 TTL d + INTERVAL 10 SECOND;
</code></pre>
<p>（2）插入数据（注意：根据实际时间改变）</p>
<pre><code class="language-sql">insert into t_order_mt3 values
(106,'sku_001',1000.00,'2020-06-12 22:52:30'),
(107,'sku_002',2000.00,'2020-06-12 22:52:30'),
(110,'sku_003',600.00,'2020-06-13 12:00:00');
</code></pre>
<p>（3）手动合并，查看效果,到期后，指定的字段数据归 0；如果执行合并后还是可以看到数据，可能是需要设置时区，或者需要重启。</p>
<p><strong>表级 TTL</strong><br>
与列级相同，在建表时与建表之后都有对应的语法进行设置<br>
（1）在建表时，写在 Order By 的后面</p>
<pre><code class="language-sql">CREATE TABLE example_table
(
    d DateTime,
    a Int
)
ENGINE = MergeTree
PARTITION BY toYYYYMM(d)
ORDER BY d
TTL d + INTERVAL 1 MONTH [DELETE],
    d + INTERVAL 1 WEEK TO VOLUME 'aaa',
    d + INTERVAL 2 WEEK TO DISK 'bbb';
</code></pre>
<p>该示例中的 [DELETE]、TO VOLUME……在下文&quot;注意&quot;中说明<br>
（2）在建表之后，使用 alter</p>
<pre><code class="language-sql">alter table t_order_mt3 MODIFY TTL create_time + INTERVAL 10 SECOND;
</code></pre>
<p>表级的 TTL ，如果是按照表中字段值判断是否过期，那么不会整表删除，只会是某一行数据到期删某一行。</p>
<p>注意</p>
<blockquote>
<p>涉及判断的字段必须是 Date 或者 Datetime 类型，推荐使用分区的日期字段。</p>
</blockquote>
<blockquote>
<p>能够使用的时间单位：</p>
<p>SECOND<br>
MINUTE<br>
HOUR<br>
DAY<br>
WEEK<br>
MONTH<br>
QUARTER YEAR</p>
</blockquote>
<blockquote>
<p>上文提到的 [DELETE]、TO VOLUME…… 表示的是过期之后，需要做的操作。可选的配置如下</p>
<p>DELETE - 删除数据 （默认，不配置则删除）;<br>
RECOMPRESS codec_name - 使用codec_name重新压缩数据部分；<br>
TO DISK ‘aaa’ - 将数据移动到磁盘 aaa 上<br>
TO VOLUME ‘bbb’ - 将数据移动到磁盘 bbb 上<br>
GROUP BY - 聚合过期行</p>
</blockquote>
<h3 id="5-replacingmergetree">5 ReplacingMergeTree</h3>
<p>ReplacingMergeTree 是 MergeTree 的一个变种，它存储特性完全继承 MergeTree，只是多了一个去重的功能。 尽管 MergeTree 可以设置主键，但是 primary key 其实没有唯一约束的功能。如果你想处理掉重复的数据，可以借助这个 ReplacingMergeTree。去重按照order by的字段去重</p>
<p><strong>去重时机</strong><br>
数据的去重只会在合并的过程中出现。合并会在未知的时间在后台进行，所以你无法预先作出计划。有一些数据可能仍未被处理。</p>
<p><strong>去重范围</strong><br>
如果表经过了分区，去重只会在分区内部进行去重，不能执行跨分区的去重。</p>
<p>所以 ReplacingMergeTree 能力有限， ReplacingMergeTree 适用于在后台清除重复的数据以节省空间，但是它不保证没有重复的数据出现。</p>
<p><strong>案例演示</strong><br>
（1）创建表</p>
<pre><code class="language-sql">create table t_order_rmt(
    id UInt32,
    sku_id String,
    total_amount Decimal(16,2) ,
    create_time Datetime 
) engine =ReplacingMergeTree(create_time)
partition by toYYYYMMDD(create_time)
primary key (id)
order by (id, sku_id);
</code></pre>
<p>ReplacingMergeTree() 填入的参数为版本字段，重复数据保留版本字段值最大的。<br>
如果不填版本字段，默认按照插入顺序保留最后一条。<br>
（2）向表中插入数据</p>
<pre><code class="language-sql">insert into t_order_rmt values
(101,'sku_001',1000.00,'2020-06-01 12:00:00') ,
(102,'sku_002',2000.00,'2020-06-01 11:00:00'),
(102,'sku_004',2500.00,'2020-06-01 12:00:00'),
(102,'sku_002',2000.00,'2020-06-01 13:00:00'),
(102,'sku_002',12000.00,'2020-06-01 13:00:00'),
(102,'sku_002',600.00,'2020-06-02 12:00:00');
</code></pre>
<p>（3）执行第一次查询</p>
<pre><code class="language-sql">select * from t_order_rmt;
</code></pre>
<p>（4）手动合并</p>
<pre><code class="language-sql">OPTIMIZE TABLE t_order_rmt FINAL;
</code></pre>
<p>（5）再执行一次查询</p>
<pre><code class="language-sql">select * from t_order_rmt;
</code></pre>
<p>通过测试得到结论</p>
<blockquote>
<p>实际上是使用 order by 字段作为唯一键<br>
去重不能跨分区<br>
只有同一批插入（新版本）或合并分区时才会进行去重<br>
认定重复的数据保留，版本字段值最大的<br>
如果版本字段相同则按插入顺序保留最后一笔</p>
</blockquote>
<h3 id="6-summingmergetree">6 SummingMergeTree</h3>
<p>对于不查询明细，只关心以维度进行汇总聚合结果的场景。如果只使用普通的MergeTree的话，无论是存储空间的开销，还是查询时临时聚合的开销都比较大。<br>
ClickHouse 为了这种场景，提供了一种能够“预聚合”的引擎 SummingMergeTree。该引擎聚合的依据依然是 order by 的字段，相当于按照 order by 的字段做了一次 Group By。</p>
<p><strong>案例演示</strong><br>
（1）创建表</p>
<pre><code class="language-sql">create table t_order_smt(
    id UInt32,
    sku_id String,
    total_amount Decimal(16,2) ,
    create_time Datetime 
) engine =SummingMergeTree(total_amount)
partition by toYYYYMMDD(create_time)
primary key (id)
order by (id,sku_id );
</code></pre>
<p>（2）插入数据</p>
<pre><code class="language-sql">insert into t_order_smt values
(101,'sku_001',1000.00,'2020-06-01 12:00:00'),
(102,'sku_002',2000.00,'2020-06-01 11:00:00'),
(102,'sku_004',2500.00,'2020-06-01 12:00:00'),
(102,'sku_002',2000.00,'2020-06-01 13:00:00'),
(102,'sku_002',12000.00,'2020-06-01 13:00:00'),
(102,'sku_002',600.00,'2020-06-02 12:00:00');
</code></pre>
<p>（3）执行第一次查询</p>
<pre><code class="language-sql">select * from t_order_smt;
</code></pre>
<p>（4）手动合并</p>
<pre><code class="language-sql">OPTIMIZE TABLE t_order_smt FINAL;
</code></pre>
<p>（5）再执行一次查询</p>
<pre><code class="language-sql">select * from t_order_smt;
</code></pre>
<p>通过结果可以得到以下结论</p>
<blockquote>
<p>以 SummingMergeTree（）中指定的列作为汇总数据列<br>
可以填写多列必须数字列，如果不填，以所有非维度列且为数字列的字段为汇总数据列<br>
以 order by 的列为准，作为维度列<br>
其他的列按插入顺序保留第一行<br>
不在一个分区的数据不会被聚合<br>
只有在同一批次插入(新版本)或分片合并时才会进行聚合<br>
开发建议<br>
设计聚合表的话，唯一键值、流水号可以去掉，所有字段全部是维度、度量或者时间戳。</p>
</blockquote>
<p><strong>问题</strong><br>
能不能直接执行以下 SQL 得到汇总值</p>
<pre><code class="language-sql">select total_amount from XXX where province_name=’’ and create_date=’xxx’
</code></pre>
<p><strong>答：</strong><br>
不行，可能会包含一些还没来得及聚合的临时明细<br>
如果要是获取汇总值，还是需要使用 sum 进行聚合，这样效率会有一定的提高，但本身 ClickHouse 是列式存储的，效率提升有限，不会特别明显。</p>
<pre><code class="language-sql">select sum(total_amount) from province_name=’’ and create_date=‘xxx’
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ClickHouse-3数据类型]]></title>
        <id>https://tinaxiawuhao.github.io/post/1h169zkFb/</id>
        <link href="https://tinaxiawuhao.github.io/post/1h169zkFb/">
        </link>
        <updated>2021-11-14T11:42:36.000Z</updated>
        <content type="html"><![CDATA[<h3 id="1-整型">1. 整型</h3>
<p>固定长度的整型，包括 有符号整型(有正有负) 或 无符号整型。</p>
<p><strong>类比 Java 类型：</strong></p>
<table>
<thead>
<tr>
<th>CH类型</th>
<th>Java类型</th>
</tr>
</thead>
<tbody>
<tr>
<td>整型范围（-2n-1~2n-1-1）</td>
<td></td>
</tr>
<tr>
<td>Int8 - [-128 : 127]</td>
<td>Byte</td>
</tr>
<tr>
<td>Int16 - [-32768 : 32767]</td>
<td>Short</td>
</tr>
<tr>
<td>Int32 - [-2147483648 : 2147483647]</td>
<td>Int</td>
</tr>
<tr>
<td>Int64 - [-9223372036854775808 : 9223372036854775807]</td>
<td>Long</td>
</tr>
<tr>
<td>无符号整型范围（0~2n-1）</td>
<td></td>
</tr>
<tr>
<td>UInt8 - [0 : 255]</td>
<td></td>
</tr>
<tr>
<td>UInt16 - [0 : 65535]</td>
<td></td>
</tr>
<tr>
<td>UInt32 - [0 : 4294967295]</td>
<td></td>
</tr>
<tr>
<td>UInt64 - [0 : 18446744073709551615]</td>
<td></td>
</tr>
</tbody>
</table>
<p>后面的数组就代表位数</p>
<p>使用场景： 个数、数量、也可以存储型 id。</p>
<h3 id="2-浮点型">2. 浮点型</h3>
<p><strong>类比 Java 类型：</strong></p>
<table>
<thead>
<tr>
<th>CH类型</th>
<th>Java类型</th>
</tr>
</thead>
<tbody>
<tr>
<td>Float32</td>
<td>float</td>
</tr>
<tr>
<td>Float64</td>
<td>double</td>
</tr>
</tbody>
</table>
<p>建议尽可能以整数形式存储数据。例如，将固定精度的数字转换为整数值，如时间用毫秒为单位表示，因为浮点型进行计算时可能引起四舍五入的误差。</p>
<p>使用场景：一般数据值比较小，不涉及大量的统计计算，精度要求不高的时候。比如保存商品的重量。</p>
<h3 id="3-布尔型">3. 布尔型</h3>
<p>没有单独的类型来存储布尔值。可以使用 UInt8 类型，取值限制为 0 或 1。</p>
<h3 id="4-decimal-型">4. Decimal 型</h3>
<p>有符号的浮点数，可在加、减和乘法运算过程中保持精度。对于除法，最低有效数字会被丢弃（不四舍五入）。</p>
<blockquote>
<p>有三种声明 (s 标识小数位)：</p>
<p>Decimal32(s)， 即 一共有 8 位，其中小数部分占 s 位，相当于 Mysql - Decimal(9-s,s)<br>
Decimal64(s)， 即 一共有 18 位，其中小数部分占 s 位，相当于 Decimal(18-s,s)<br>
Decimal128(s)， 即 一共有 38位，其中小数部分占 s 位，相当于 Decimal(38-s,s)<br>
使用场景： 一般金额字段、汇率、利率等字段为了保证小数点精度，都使用 Decimal进行存储。</p>
</blockquote>
<h3 id="5-字符串">5. 字符串</h3>
<p><strong>String - 对应 Mysql - Varchar</strong><br>
字符串可以任意长度的。它可以包含任意的字节集，包含空字节。</p>
<p><strong>FixedString(N)</strong><br>
固定长度 N 的字符串，N 必须是严格的正自然数。当服务端读取长度小于 N 的字符串时候，通过在字符串末尾添加空字节来达到 N 字节长度。 当服务端读取长度大于 N 的字符串时候，将返回错误消息。<br>
与 String 相比，极少会使用 FixedString，因为使用起来不是很方便。</p>
<p>使用场景：名称、文字描述、字符型编码。 固定长度的可以保存一些定长的内容，比如一些编码，性别等但是考虑到一定的变化风险，带来收益不够明显，所以定长字符串使用意义有限。</p>
<h3 id="6-枚举类型">6. 枚举类型</h3>
<p>包括 Enum8 和 Enum16 类型。Enum 保存 ‘string’= integer 的对应关系。</p>
<blockquote>
<p>Enum8 用 ‘String’= Int8 对描述。<br>
Enum16 用 ‘String’= Int16 对描述。</p>
</blockquote>
<p>创建一个带有一个枚举 Enum8(‘hello’ = 1, ‘world’ = 2) 类型的列</p>
<pre><code class="language-sql">CREATE TABLE t_enum
(
	x Enum8('hello' = 1, 'world' = 2)
)
ENGINE = TinyLog;
</code></pre>
<p>这个 x 列只能存储类型定义中列出的值：‘hello’或’world’</p>
<pre><code class="language-shell">INSERT INTO t_enum VALUES ('hello'), ('world'), ('hello');
</code></pre>
<p>如果尝试保存任何其他值，ClickHouse 抛出异常</p>
<pre><code class="language-shell">insert into t_enum values('a')
</code></pre>
<p>如果需要看到对应行的数值，则必须将 Enum 值转换为整数类型</p>
<pre><code class="language-shell">SELECT CAST(x, 'Int8') FROM t_enum;
</code></pre>
<p>使用场景：对一些状态、类型的字段算是一种空间优化，也算是一种数据约束。但是实际使用中往往因为一些数据内容的变化增加一定的维护成本，甚至是数据丢失问题。所以谨慎使用。</p>
<h3 id="7-时间类型">7. 时间类型</h3>
<p>目前 ClickHouse 有三种时间类型</p>
<blockquote>
<p>Date 接受年-月-日的字符串比如 ‘2019-12-16’<br>
Datetime 接受年-月-日 时:分:秒的字符串比如 ‘2019-12-16 20:50:10’<br>
Datetime64 接受年-月-日 时:分:秒.亚秒的字符串比如‘2019-12-16 20:50:10.66’<br>
日期类型，用两个字节存储，表示从 1970-01-01 (无符号) 到当前的日期值。</p>
</blockquote>
<h3 id="8-数组">8. 数组</h3>
<p>Array(T)：由 T 类型元素组成的数组。<br>
T 可以是任意类型，包含数组类型。 但不推荐使用多维数组，ClickHouse 对多维数组的支持有限。例如，不能在 MergeTree 表中存储多维数组。</p>
<p><strong>创建数组方式 1，使用 array 函数array(T)</strong></p>
<pre><code class="language-shell">SELECT array(1, 2) AS x, toTypeName(x) ;
</code></pre>
<p><strong>创建数组方式 2：使用方括号[]</strong></p>
<pre><code class="language-shell">SELECT [1, 2] AS x, toTypeName(x);
</code></pre>
<h3 id="9-其他">9. 其他</h3>
<p>还有很多数据结构，可以参考官方文档：https://clickhouse.com/docs/zh/sql-reference/data-types/</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Docker安装clickhouse]]></title>
        <id>https://tinaxiawuhao.github.io/post/BBgY7nkHa/</id>
        <link href="https://tinaxiawuhao.github.io/post/BBgY7nkHa/">
        </link>
        <updated>2021-11-13T05:45:31.000Z</updated>
        <content type="html"><![CDATA[<p>ClickHouse 很多大厂都在用，本篇主要使用Docker进行安装</p>
<h3 id="安装配置">安装配置</h3>
<p>创建目录并更改权限</p>
<pre><code class="language-shell">mkdir -p /app/cloud/clickhouse/data
mkdir -p /app/cloud/clickhouse/conf
mkdir -p /app/cloud/clickhouse/log

chmod -R 777 /app/cloud/clickhouse/data
chmod -R 777 /app/cloud/clickhouse/conf
chmod -R 777 /app/cloud/clickhouse/log
</code></pre>
<h3 id="拉取镜像">拉取镜像</h3>
<pre><code class="language-shell">docker pull yandex/clickhouse-server:20.3.5.21
docker pull yandex/clickhouse-client:20.3.5.21
</code></pre>
<p>查看 <a href="https://hub.docker.com/r/yandex/clickhouse-server/dockerfile">https://hub.docker.com/r/yandex/clickhouse-server/dockerfile</a> 文件，EXPOSE  9000  8123  9009 了三个端口</p>
<h3 id="创建临时容器">创建临时容器</h3>
<pre><code class="language-shell">docker run --rm -d --name=clickhouse-server --ulimit nofile=262144:262144 -p 8123:8123 -p 9009:9009 -p 9000:9000 yandex/clickhouse-server:20.3.5.21
</code></pre>
<h3 id="复制临时容器内配置文件到宿主机">复制临时容器内配置文件到宿主机</h3>
<pre><code class="language-shell">docker cp clickhouse-server:/etc/clickhouse-server/config.xml D:/clickhouse/conf/config.xml
docker cp clickhouse-server:/etc/clickhouse-server/users.xml D:/clickhouse/conf/users.xml
</code></pre>
<h3 id="停掉临时容器">停掉临时容器</h3>
<pre><code class="language-shell">docker stop clickhouse-server
</code></pre>
<h3 id="创建default账号密码">创建default账号密码</h3>
<pre><code class="language-shell">PASSWORD=$(base64 &lt; /dev/urandom | head -c8); echo &quot;$PASSWORD&quot;; echo -n &quot;$PASSWORD&quot; | sha256sum | tr -d '-'
</code></pre>
<pre><code class="language-shell">SEGByR98
211371f5bc54970907173acf6facb35f0acbc17913e1b71b814117667c01d96d
</code></pre>
<p>会输出明码和SHA256密码</p>
<h3 id="创建root账号密码">创建root账号密码</h3>
<pre><code class="language-shell">PASSWORD=$(base64 &lt; /dev/urandom | head -c8); echo &quot;$PASSWORD&quot;; echo -n &quot;$PASSWORD&quot; | sha256sum | tr -d '-'
</code></pre>
<pre><code class="language-shell">092j3AnV
35542ded44184b1b4b6cd621e052662578025b58b4187176a3ad2b9548c8356e
</code></pre>
<p>会输出明码和SHA256密码</p>
<p>修改 D:/clickhouse/conf/users.xml<br>
把default账号设为只读权限，并设置密码yandex--&gt;users--&gt;default--&gt;profile节点设为 <code>readonly</code> 注释掉 yandex--&gt;users--&gt;default--&gt;password 节点 新增  yandex--&gt;users--&gt;default--&gt;password_sha256_hex 节点，填入生成的密码</p>
<p>修改default账号</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot;?&gt;
&lt;yandex&gt;
    &lt;users&gt;
        &lt;default&gt;
            &lt;password_sha256_hex&gt;211371f5bc54970907173acf6facb35f0acbc17913e1b71b814117667c01d96d&lt;/password_sha256_hex&gt;
            &lt;networks incl=&quot;networks&quot; replace=&quot;replace&quot;&gt;
                &lt;ip&gt;::/0&lt;/ip&gt;
            &lt;/networks&gt;
            &lt;profile&gt;readonly&lt;/profile&gt;
            &lt;quota&gt;default&lt;/quota&gt;
        &lt;/default&gt;
	&lt;/users&gt;
&lt;/yandex&gt;
</code></pre>
<p>新增root账号</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot;?&gt;
&lt;yandex&gt;
    &lt;users&gt;
        &lt;root&gt;
                    &lt;password_sha256_hex&gt;35542ded44184b1b4b6cd621e052662578025b58b4187176a3ad2b9548c8356e&lt;/password_sha256_hex&gt;
             &lt;networks incl=&quot;networks&quot; replace=&quot;replace&quot;&gt;
                &lt;ip&gt;::/0&lt;/ip&gt;
            &lt;/networks&gt;
            &lt;profile&gt;default&lt;/profile&gt;
            &lt;quota&gt;default&lt;/quota&gt;
        &lt;/root&gt;
	&lt;/users&gt;
&lt;/yandex&gt;
</code></pre>
<h3 id="创建容器">创建容器</h3>
<pre><code class="language-shell">docker run -d --name=clickhouse-server -p 8123:8123 -p 9009:9009 -p 9000:9000 --ulimit nofile=262144:262144 -v D:/clickhouse/data:/var/lib/clickhouse:rw -v D:/clickhouse/conf/config.xml:/etc/clickhouse-server/config.xml -v D:/clickhouse/conf/users.xml:/etc/clickhouse-server/users.xml -v D:/clickhouse/log:/var/log/clickhouse-server:rw yandex/clickhouse-server
</code></pre>
<h3 id="操作">操作</h3>
<ol>
<li>docker exec -it docker-clickhouse /bin/bash 进入容器</li>
<li>clickhouse-client 进入clickhouse命令行</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ClickHouse-2初识]]></title>
        <id>https://tinaxiawuhao.github.io/post/GwxNFXsxh/</id>
        <link href="https://tinaxiawuhao.github.io/post/GwxNFXsxh/">
        </link>
        <updated>2021-11-13T03:00:13.000Z</updated>
        <content type="html"><![CDATA[<h3 id="一-简介">一、简介</h3>
<h4 id="11-clickhouse-是什么">1.1 ClickHouse 是什么？</h4>
<p>ClickHouse 是 Yandex（俄罗斯最大的搜索引擎）开源的一个用于实时数据分析的基于列存储的数据库，其处理数据的速度比传统方法快 100-1000 倍。ClickHouse 的性能超过了目前市场上可比的面向列的 DBMS，每秒钟每台服务器每秒处理数亿至十亿多行和数十千兆字节的数据。</p>
<h4 id="12-clickhouse的一些特性">1.2 ClickHouse的一些特性：</h4>
<ol>
<li>快速：ClickHouse 会充分利用所有可用的硬件，以尽可能快地处理每个查询。单个查询的峰值处理性能超过每秒 2 TB（解压缩后，仅使用的列）。在分布式设置中，读取是在健康副本之间自动平衡的，以避免增加延迟。</li>
<li>容错：ClickHouse 支持多主机异步复制，并且可以跨多个数据中心进行部署。所有节点都相等，这可以避免出现单点故障。单个节点或整个数据中心的停机时间不会影响系统的读写可用性。</li>
<li>可伸缩：ClickHouse 可以在垂直和水平方向上很好地缩放。ClickHouse 易于调整以在具有数百或数千个节点的群集上或在单个服务器上，甚至在小型虚拟机上执行。当前，每个单节点安装的数据量超过数万亿行或数百兆兆字节。</li>
<li>易用：ClickHouse 简单易用，开箱即用。它简化了所有数据处理：将所有结构化数据吸收到系统中，并且立即可用于构建报告。SQL 允许表达期望的结果，而无需涉及某些 DBMS 中可以找到的任何自定义非标准 API。</li>
<li>充分利用硬件：ClickHouse 与具有相同的可用 I/O 吞吐量和 CPU 容量的传统的面向行的系统相比，其处理典型的分析查询要快两到三个数量级。列式存储格式允许在 RAM 中容纳更多热数据，从而缩短了响应时间。</li>
<li>提高 CPU 效率：向量化查询执行涉及相关的 SIMD 处理器指令和运行时代码生成。处理列中的数据会提高 CPU 行缓存的命中率。</li>
<li>优化磁盘访问：ClickHouse 可以最大程度地减少范围查询的次数，从而提高了使用旋转磁盘驱动器的效率，因为它可以保持连续存储数据。</li>
<li>最小化数据传输：ClickHouse 使公司无需使用专门针对高性能计算的专用网络即可管理其数据。</li>
</ol>
<p><strong>何时使用 ClickHouse：</strong><br>
用于分析结构良好且不可变的事件或日志流，建议将每个此类流放入具有预连接维度的单个宽表中。<br>
<strong>何时不使用 ClickHouse：</strong><br>
不适合事务性工作负载（OLTP）、高价值的键值请求、Blob 或文档存储。</p>
<h4 id="13-为什么-clickhouse-速度这么快">1.3 为什么 ClickHouse 速度这么快？</h4>
<p>首先我们了解一下 OLAP 场景的特点：</p>
<ol>
<li>读多于写。</li>
<li>大宽表，读大量行但是少量列，结果集较小。</li>
<li>数据批量写入，且数据不更新或少更新。</li>
</ol>
<p>针对分析类查询，通常只需要读取表的一小部分列。在列式数据库中你可以只读取你需要的数据。例如，如果只需要读取 100 列中的 5 列，这将帮助你最少减少 20 倍的 I/O 消耗。</p>
<p>由于数据总是打包成批量读取的，所以压缩是非常容易的。同时数据按列分别存储这也更容易压缩。这进一步降低了 I/O 的体积。由于 I/O 的降低，这将帮助更多的数据被系统缓存。</p>
<p>例如，查询《统计每个广告平台的记录数量》需要读取《广告平台 ID》这一列，它在未压缩的情况下需要 1 个字节进行存储。如果大部分流量不是来自广告平台，那么这一列至少可以以十倍的压缩率被压缩。当采用快速压缩算法，它的解压速度最少在十亿字节（未压缩数据）每秒。换句话说，这个查询可以在单个服务器上以每秒大约几十亿行的速度进行处理。这实际上是当前实现的速度。</p>
<p>ClickHouse 从 OLAP 场景需求出发，定制开发了一套全新的高效列式存储引擎</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1639537283959.webp" alt="" loading="lazy"></figure>
<p><code>column-oriented</code>  图片来源见水印相比于行式存储，列式存储在分析场景下有着许多优良的特性。</p>
<ol>
<li>如前所述，分析场景中往往需要读大量行但是少数几个列。在行存模式下，数据按行连续存储，所有列的数据都存储在一个 block 中，不参与计算的列在 IO 时也要全部读出，读取操作被严重放大。而列存模式下，只需要读取参与计算的列即可，极大的减低了 IO cost，加速了查询。</li>
<li>同一列中的数据属于同一类型，压缩效果显著。列存往往有着高达十倍甚至更高的压缩比，节省了大量的存储空间，降低了存储成本。</li>
<li>更高的压缩比意味着更小的 data size，从磁盘中读取相应数据耗时更短。</li>
<li>自由的压缩算法选择。不同列的数据具有不同的数据类型，适用的压缩算法也就不尽相同。可以针对不同列类型，选择最合适的压缩算法。</li>
<li>高压缩比，意味着同等大小的内存能够存放更多数据，系统 cache 效果更好。</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Clickhouse-1安装]]></title>
        <id>https://tinaxiawuhao.github.io/post/r2VmiGgor/</id>
        <link href="https://tinaxiawuhao.github.io/post/r2VmiGgor/">
        </link>
        <updated>2021-11-12T01:50:16.000Z</updated>
        <content type="html"><![CDATA[<h1 id="1clickhouse的安装">1.ClickHouse的安装</h1>
<h2 id="11-准备工作">1.1    准备工作</h2>
<p>下载RPM包:</p>
<p><a href="https://repo.yandex.ru/clickhouse/rpm/stable/x86_64/">https://repo.yandex.ru/clickhouse/rpm/stable/x86_64/</a></p>
<p>下载完毕如下:</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1638237245375.png" alt="" loading="lazy"></figure>
<p>​</p>
<h3 id="111-确定防火墙处于关闭状态">1.1.1 确定防火墙处于关闭状态</h3>
<p>相关命令:</p>
<pre><code class="language-shell">sudo systemctl status firewalld

sudo systemctl start firewalld

sudo systemctl stop firewalld

sudo systemctl restart firewalld
</code></pre>
<h3 id="112-centos取消打开文件数限制">1.1.2 CentOS取消打开文件数限制</h3>
<p>Ø 在 /etc/security/limits.conf文件的末尾加入以下内容</p>
<pre><code class="language-shell">vim /etc/security/limits.conf

* soft nofile 65536
* hard nofile 65536
* soft nproc 131072
* hard nproc 131072
</code></pre>
<p>Ø 在/etc/security/limits.d/20-nproc.conf文件的末尾加入以下内容</p>
<pre><code class="language-shell">vim /etc/security/limits.d/20-nproc.conf

* soft nofile 65536
* hard nofile 65536
* soft nproc 131072
* hard nproc 131072
</code></pre>
<p>Ø 执行同步操作(同步到集群其他机器)</p>
<pre><code class="language-shell">xsync /etc/security/limits.conf
xsync /etc/security/limits.d/20-nproc.conf
</code></pre>
<h3 id="113-安装依赖">1.1.3 安装依赖</h3>
<pre><code class="language-shell">sudo yum install -y libtool
</code></pre>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1638237268510.png" alt="" loading="lazy"></figure>
<pre><code class="language-shell">sudo yum install -y *unixODBC*
</code></pre>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1638237282605.png" alt="" loading="lazy"></figure>
<p>同样在集群其他机器上执行以上操作</p>
<h3 id="114-centos取消selinux">1.1.4 CentOS取消SELINUX</h3>
<p>SELINUX(美国开源的linux安全增强功能)</p>
<p>Ø 修改/etc/selinux/config中的SELINUX=disabled</p>
<pre><code class="language-shell">sudo vim /etc/selinux/config

SELINUX=disabled
</code></pre>
<p>Ø 执行同步操作</p>
<pre><code class="language-shell">sudo /home/atguigu/bin/xsync /etc/selinux/config
</code></pre>
<p>Ø 重启三台服务器</p>
<h3 id="115-将安装文件同步到其他两个服务器">1.1.5 将安装文件同步到其他两个服务器</h3>
<h3 id="116-分别在三台机子上安装这4个rpm文件">1.1.6 分别在三台机子上安装这4个rpm文件</h3>
<pre><code class="language-shell">sudo rpm -ivh *.rpm(提前把四个*.rpm放在一个目录下)
</code></pre>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1638237307245.png" alt="" loading="lazy"></figure>
<pre><code class="language-shell">sudo rpm -qa|grep clickhouse查看安装情况
</code></pre>
<h3 id="117-修改配置文件">1.1.7 修改配置文件</h3>
<pre><code class="language-shell">vim /etc/clickhouse-server/config.xml
</code></pre>
<p>把 <strong>&lt;listen_host&gt;::&lt;/listen_host&gt;</strong> 的注释打开，这样的话才能让ClickHouse被除本机以外的服务器访问</p>
<pre><code class="language-shell">#分发配置文件

xsync /etc/clickhouse-server/config.xml
</code></pre>
<h3 id="118-启动server">1.1.8 启动Server</h3>
<pre><code class="language-shell">sudo systemctl start clickhouse-server
</code></pre>
<h3 id="119-三台机器上关闭开机自启">1.1.9 三台机器上关闭开机自启</h3>
<pre><code class="language-shell">systemctl disable clickhouse-server
</code></pre>
<h3 id="1110-使用client连接server">1.1.10    使用client连接server</h3>
<pre><code class="language-shell">clickhouse-client -m
</code></pre>
<p>Clickhouse常用端口号:</p>
<p><img src="https://tinaxiawuhao.github.io/post-images/1638237372637.png" alt="" loading="lazy"><br>
<img src="https://tinaxiawuhao.github.io/post-images/1638237379416.png" alt="" loading="lazy"><br>
<img src="https://tinaxiawuhao.github.io/post-images/1638237384947.png" alt="" loading="lazy"><br>
<img src="https://tinaxiawuhao.github.io/post-images/1638237390491.png" alt="" loading="lazy"></p>
<h1 id="第2章-副本">第2章  副本</h1>
<p>副本的目的主要是保障数据的高可用性，即使一台ClickHouse节点宕机，那么也可以从其他服务器获得相同的数据。</p>
<h2 id="21-副本写入流程">2.1    副本写入流程</h2>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1638237403217.png" alt="" loading="lazy"></figure>
<h2 id="22-配置步骤">2.2    配置步骤</h2>
<p>Ø 启动zookeeper集群</p>
<p>Ø 注意:服务器的hostname需要改成对应的ck101、ck102、ck103</p>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1638237417573.png" alt="" loading="lazy"></figure>
<p>Ø 在/etc/clickhouse-server/config.d目录下创建一个名为metrika.xml的配置文件,内容如下：</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot;?&gt;
&lt;yandex&gt;
	&lt;zookeeper-servers&gt;
		&lt;node index=&quot;1&quot;&gt;
			&lt;host&gt;ck101&lt;/host&gt;
			&lt;port&gt;2181&lt;/port&gt;
		&lt;/node&gt;
		&lt;node index=&quot;2&quot;&gt;
            &lt;host&gt;ck102&lt;/host&gt;
            &lt;port&gt;2181&lt;/port&gt;
        &lt;/node&gt;
        &lt;node index=&quot;3&quot;&gt;
            &lt;host&gt;ck103&lt;/host&gt;
            &lt;port&gt;2181&lt;/port&gt;
        &lt;/node&gt;
	&lt;/zookeeper-servers&gt;
&lt;/yandex&gt;
</code></pre>
<p>Ø 同步到另外两个机器上</p>
<pre><code class="language-shell">xsync /etc/clickhouse-server/config.d/metrika.xml
</code></pre>
<p>Ø 在 /etc/clickhouse-server/config.xml中增加</p>
<pre><code class="language-xml">&lt;zookeeper incl=&quot;zookeeper-servers&quot; optional=&quot;true&quot; /&gt;
&lt;include_from&gt;/etc/clickhouse-server/config.d/metrika.xml&lt;/include_from&gt;
</code></pre>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1638237432131.png" alt="" loading="lazy"></figure>
<p>Ø 同步到另外两个机器上</p>
<pre><code class="language-shell">xsync /etc/clickhouse-server/config.xml
</code></pre>
<p>Ø 分别在另外两个机器上启动ClickHouse服务</p>
<p>注意：因为修改了配置文件，如果以前启动了服务需要重启</p>
<pre><code class="language-shell">systemctl start clickhouse-server
</code></pre>
<p>Ø 在另外两个机器上分别建表</p>
<p><strong>副本只能同步数据，不能同步表结构，所以我们需要在每台机器上自己手动建表</strong></p>
<p>Ck101</p>
<pre><code class="language-sql">create table t_order_rep (
  id UInt32,
  sku_id String,
  total_amount Decimal(16,2),
  create_time Datetime
 ) engine =ReplicatedMergeTree('/clickhouse/table/01/t_order_rep','rep_102')
  partition by toYYYYMMDD(create_time)
  primary key (id)
  order by (id,sku_id);
</code></pre>
<p>Ck102</p>
<pre><code class="language-sql">create table t_order_rep (
  id UInt32,
  sku_id String,
  total_amount Decimal(16,2),
  create_time Datetime
 ) engine =ReplicatedMergeTree('/clickhouse/table/01/t_order_rep','rep_103')
  partition by toYYYYMMDD(create_time)
  primary key (id)
  order by (id,sku_id);
</code></pre>
<p>参数解释</p>
<p>ReplicatedMergeTree 中，</p>
<p><strong>第一个参数是</strong>分片的zk_path一般按照： /clickhouse/table/{shard}/{table_name} 的格式写，如果只有一个分片就写01即可。</p>
<p><strong>第二个参数是</strong>副本名称，相同的分片副本名称不能相同。</p>
<p>Ø 在ck101上执行insert语句</p>
<pre><code class="language-sql">insert into t_order_rep values
(101,'sku_001',1000.00,'2020-06-01 12:00:00'),
(102,'sku_002',2000.00,'2020-06-01 12:00:00'),
(103,'sku_004',2500.00,'2020-06-01 12:00:00'),
(104,'sku_002',2000.00,'2020-06-01 12:00:00'),
(105,'sku_003',600.00,'2020-06-02 12:00:00');
</code></pre>
<p>Ø 在<strong>ck102</strong>上执行select，可以查询出结果，说明副本配置正确</p>
<h1 id="第3章-分片集群">第3章  分片集群</h1>
<p>副本虽然能够提高数据的可用性，降低丢失风险，但是每台服务器实际上必须容纳全量数据，对数据的横向扩容没有解决。</p>
<p>要解决数据水平切分的问题，需要引入分片的概念。通过分片把一份完整的数据进行切分，不同的分片分布到不同的节点上，再通过Distributed表引擎把数据拼接起来一同使用。</p>
<p>Distributed表引擎本身不存储数据，有点类似于MyCat之于MySql，成为一种中间件，通过分布式逻辑表来写入、分发、路由来操作多台节点不同分片的分布式数据。</p>
<p>注意：ClickHouse的集群是表级别的，实际企业中，大部分做了高可用，但是没有用分片，避免降低查询性能以及操作集群的复杂性。</p>
<h2 id="31-集群写入流程3分片2副本共6个节点">3.1    集群写入流程（3分片2副本共6个节点）</h2>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1638237448353.png" alt="" loading="lazy"></figure>
<h2 id="32-集群读取流程3分片2副本共6个节点">3.2    集群读取流程（3分片2副本共6个节点）</h2>
<figure data-type="image" tabindex="9"><img src="https://tinaxiawuhao.github.io/post-images/1638237458923.png" alt="" loading="lazy"></figure>
<h2 id="33-配置三节点版本集群及副本">3.3    配置三节点版本集群及副本</h2>
<figure data-type="image" tabindex="10"><img src="https://tinaxiawuhao.github.io/post-images/1638237469738.png" alt="" loading="lazy"></figure>
<h3 id="331-集群及副本规划2个分片只有第一个分片有副本">3.3.1 集群及副本规划（2个分片，只有第一个分片有副本）</h3>
<table>
<thead>
<tr>
<th><strong>ck101</strong></th>
<th><strong>ck102</strong></th>
<th><strong>ck103</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><macros>  <shard>01</shard>    <replica>rep_1_1</replica>  </macros></td>
<td><macros>  <shard>01</shard>    <replica>rep_1_2</replica>  </macros></td>
<td><macros>  <shard>02</shard>    <replica>rep_2_1</replica>  </macros></td>
</tr>
</tbody>
</table>
<h3 id="332-配置步骤">3.3.2 配置步骤</h3>
<h4 id="1-在ck101的etcclickhouse-serverconfigd目录下创建metrika-shardxml文件">(1) 在ck101的/etc/clickhouse-server/config.d目录下创建metrika-shard.xml文件</h4>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot;?&gt;
&lt;yandex&gt;
    &lt;remote_servers&gt;
        &lt;my_cluster&gt; &lt;!-- 集群名称--&gt; 
            &lt;shard&gt;     &lt;!--集群的第一个分片--&gt;
                &lt;internal_replication&gt;true&lt;/internal_replication&gt;
                &lt;replica&gt;  &lt;!--该分片的第一个副本--&gt;
                &lt;host&gt;ck101&lt;/host&gt;
                &lt;port&gt;9000&lt;/port&gt;
                &lt;/replica&gt;
                &lt;replica&gt;  &lt;!--该分片的第二个副本--&gt;
                &lt;host&gt;ck102&lt;/host&gt;
                &lt;port&gt;9000&lt;/port&gt;
                &lt;/replica&gt;
            &lt;/shard&gt;

            &lt;shard&gt; &lt;!--集群的第二个分片--&gt;
                &lt;internal_replication&gt;true&lt;/internal_replication&gt;
                &lt;replica&gt;  &lt;!--该分片的第一个副本--&gt;
                &lt;host&gt;ck103&lt;/host&gt;
                &lt;port&gt;9000&lt;/port&gt;
                &lt;/replica&gt;
            &lt;/shard&gt;
        &lt;/my_cluster&gt;
    &lt;/remote_servers&gt;

    &lt;zookeeper-servers&gt;
        &lt;node index=&quot;1&quot;&gt;
            &lt;host&gt; ck101&lt;/host&gt;
            &lt;port&gt;2181&lt;/port&gt;
        &lt;/node&gt;
        &lt;node index=&quot;2&quot;&gt;
            &lt;host&gt; ck102&lt;/host&gt;
            &lt;port&gt;2181&lt;/port&gt;
        &lt;/node&gt;
        &lt;node index=&quot;3&quot;&gt;
            &lt;host&gt; ck103&lt;/host&gt;
            &lt;port&gt;2181&lt;/port&gt;
        &lt;/node&gt;
    &lt;/zookeeper-servers&gt;

    &lt;macros&gt;
        &lt;shard&gt;01&lt;/shard&gt;  &lt;!--不同机器放的分片数不一样--&gt;
        &lt;replica&gt;rep_1_1&lt;/replica&gt; &lt;!--不同机器放的副本数不一样--&gt;
    &lt;/macros&gt;
&lt;/yandex&gt;
</code></pre>
<h4 id="2-将ck101的metrika-shardxml同步到102和103">(2) 将ck101的metrika-shard.xml同步到102和103</h4>
<pre><code class="language-shell">xsync /etc/clickhouse-server/config.d/metrika-shard.xml
</code></pre>
<h4 id="3-修改102和103中metrika-shardxml宏的配置">(3) 修改102和103中metrika-shard.xml宏的配置</h4>
<p>Ø <strong>102</strong></p>
<pre><code class="language-shell">vim /etc/clickhouse-server/config.d/metrika-shard.xml
</code></pre>
<figure data-type="image" tabindex="11"><img src="https://tinaxiawuhao.github.io/post-images/1638237484666.png" alt="" loading="lazy"></figure>
<p>Ø <strong>103</strong></p>
<pre><code class="language-shell">vim /etc/clickhouse-server/config.d/metrika-shard.xml
</code></pre>
<figure data-type="image" tabindex="12"><img src="https://tinaxiawuhao.github.io/post-images/1638237492998.png" alt="" loading="lazy"></figure>
<h4 id="4-在hadoop102上修改etcclickhouse-serverconfigxml">(4) 在hadoop102上修改/etc/clickhouse-server/config.xml</h4>
<figure data-type="image" tabindex="13"><img src="https://tinaxiawuhao.github.io/post-images/1638237502544.png" alt="" loading="lazy"></figure>
<h4 id="5-同步etcclickhouse-serverconfigxml到103和104">(5) 同步/etc/clickhouse-server/config.xml到103和104</h4>
<pre><code class="language-shell">sudo /home/atguigu/bin/xsync /etc/clickhouse-server/config.xml
</code></pre>
<h4 id="6-重启三台服务器上的clickhouse服务">(6) 重启三台服务器上的ClickHouse服务</h4>
<pre><code class="language-shell">systemctl stop clickhouse-server
systemctl start clickhouse-server
systemctl status clickhouse-server
</code></pre>
<h4 id="7-在ck101上执行建表语句">(7) 在ck101上执行建表语句</h4>
<p>Ø 会自动同步到ck102和ck103上</p>
<p>Ø 集群名字要和配置文件中的一致</p>
<p>Ø 分片和副本名称从配置文件的宏定义中获取</p>
<pre><code class="language-sql">create table st_order_mt on cluster my_cluster (
  id UInt32,
  sku_id String,
  total_amount Decimal(16,2),
  create_time Datetime
 ) engine =ReplicatedMergeTree('/clickhouse/tables/{shard}/st_order_mt','{replica}')
  partition by toYYYYMMDD(create_time)
  primary key (id)
  order by (id,sku_id);
</code></pre>
<p>可以到ck102和ck103上查看表是否创建成功</p>
<h4 id="8-在ck101上创建distribute-分布式表">(8) 在ck101上创建Distribute 分布式表</h4>
<pre><code class="language-sql">create table st_order_mt_all on cluster my_cluster
(
  id UInt32,
  sku_id String,
  total_amount Decimal(16,2),
  create_time Datetime
)engine = Distributed(my_cluster,default, st_order_mt,hiveHash(sku_id));
</code></pre>
<p><strong>参数含义</strong></p>
<p>​    Distributed(集群名称，库名，本地表名，分片键)</p>
<p>分片键必须是整型数字，所以用hiveHash函数转换，也可以rand()</p>
<h4 id="9-在ck101上插入测试数据">(9) 在ck101上插入测试数据</h4>
<pre><code class="language-sql">insert into st_order_mt_all values
(201,'sku_001',1000.00,'2020-06-01 12:00:00') ,
(202,'sku_002',2000.00,'2020-06-01 12:00:00'),
(203,'sku_004',2500.00,'2020-06-01 12:00:00'),
(204,'sku_002',2000.00,'2020-06-01 12:00:00'),
(205,'sku_003',600.00,'2020-06-02 12:00:00');
</code></pre>
<h4 id="10-通过查询分布式表和本地表观察输出结果">(10)   通过查询分布式表和本地表观察输出结果</h4>
<p>Ø <strong>分布式表</strong></p>
<pre><code class="language-sql">SELECT *  FROM st_order_mt_all;
</code></pre>
<p>Ø <strong>本地表</strong></p>
<pre><code class="language-sql">select * from st_order_mt;
</code></pre>
<p>Ø 观察数据的分布</p>
<table>
<thead>
<tr>
<th>st_order_mt_all</th>
<th><img src="https://tinaxiawuhao.github.io/post-images/1638237523851.png" alt="" loading="lazy"></th>
</tr>
</thead>
<tbody>
<tr>
<td>Ck101:  st_order_mt</td>
<td><img src="https://tinaxiawuhao.github.io/post-images/1638237534695.png" alt="" loading="lazy"></td>
</tr>
<tr>
<td>Ck102:  st_order_mt</td>
<td><img src="https://tinaxiawuhao.github.io/post-images/1638237544313.png" alt="" loading="lazy"></td>
</tr>
<tr>
<td>Ck103:  st_order_mt</td>
<td><img src="https://tinaxiawuhao.github.io/post-images/1638237554783.png" alt="" loading="lazy"></td>
</tr>
</tbody>
</table>
<h1 id="第4章-版本信息">第4章  版本信息</h1>
<p>Clickhouse: clickhouse-21.9.4.35</p>
<p>Zookeeper: zookeeper-3.4.6</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Kafka 架构深入]]></title>
        <id>https://tinaxiawuhao.github.io/post/KM-0yw6ab/</id>
        <link href="https://tinaxiawuhao.github.io/post/KM-0yw6ab/">
        </link>
        <updated>2021-11-01T05:59:18.000Z</updated>
        <content type="html"><![CDATA[<h2 id="31-kafka-工作流程及文件存储机制">3.1 Kafka 工作流程及文件存储机制</h2>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1635746429452.png" alt="" loading="lazy"></figure>
<p>Kafka 中消息是以 topic 进行分类的， 生产者生产消息，消费者消费消息，都是面向 <strong>topic</strong><br>
的。</p>
<p><strong>topic 是逻辑上的概念，而 partition 是物理上的概念</strong>，每个 partition 对应于一个 log 文件，该 log 文件中存储的就是 producer 生产的数据。 Producer 生产的数据会被不断追加到该 log 文件末端，且每条数据都有自己的 offset。 消费者组中的每个消费者， 都会实时记录自己消费到了哪个 offset，以便出错恢复时，从上次的位置继续消费 。</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1635746436346.png" alt="" loading="lazy"></figure>
<p>由于生产者生产的消息会不断追加到 log 文件末尾， 为防止 log 文件过大导致数据定位效率低下， Kafka 采取了分片和索引机制，将每个 partition 分为多个 segment。 每个 segment 对应两个文件——“.index”文件和“.log”文件。 这些文件位于一个文件夹下， 该文件夹的命名规则为： topic名称+分区序号。例如， first 这个 topic 有三个分区，则其对应的文件夹为 first-0,first-1,first-2。</p>
<pre><code class="language-java">00000000000000000000.index
00000000000000000000.log
00000000000000170410.index
00000000000000170410.log
00000000000000239430.index
00000000000000239430.log
</code></pre>
<p>index 和 log 文件以当前 segment 的第一条消息的 offset 命名。下图为 index 文件和 log文件的结构示意图。</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1635746443977.png" alt="" loading="lazy"></figure>
<p><strong>“.index”文件存储大量的索引信息，“.log”文件存储大量的数据</strong>，索引文件中的元数据指向对应数据文件中 message 的物理偏移地址。</p>
<h2 id="32-kafka-生产者">3.2 Kafka 生产者</h2>
<h3 id="321-分区策略">3.2.1 分区策略</h3>
<ol>
<li>
<p>分区的原因</p>
<p>（1） <strong>方便在集群中扩展</strong>，每个 Partition 可以通过调整以适应它所在的机器，而一个 topic<br>
又可以有多个 Partition 组成，因此整个集群就可以适应任意大小的数据了；<br>
（2） <strong>可以提高并发</strong>，因为可以以 Partition 为单位读写了。</p>
</li>
<li>
<p>分区的原则</p>
<p>我们需要将 producer 发送的数据封装成一个 <code>ProducerRecord</code> 对象。</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1635746457132.png" alt="" loading="lazy"></figure>
<p>（1） 指明 partition 的情况下，直接将指明的值直接作为 partiton 值；<br>
（2）没有指明 partition 值但有 key 的情况下，将 key 的 hash 值与 topic 的 partition<br>
数进行取余得到 partition 值；<br>
（3） 既没有 partition 值又没有 key 值的情况下，第一次调用时随机生成一个整数（后<br>
面每次调用在这个整数上自增），将这个值与 topic 可用的 partition 总数取余得到 partition<br>
值，也就是常说的 round-robin 算法。</p>
</li>
</ol>
<h3 id="322-数据可靠性保证">3.2.2 数据可靠性保证</h3>
<p>为保证 producer 发送的数据，能可靠的发送到指定的 topic， topic 的每个 partition 收到<br>
producer 发送的数据后， 都需要向 producer 发送 <strong>ack</strong>（acknowledgement 确认收到） ，如果<br>
producer 收到 ack， 就会进行下一轮的发送，否则重新发送数据。</p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1635746468488.png" alt="" loading="lazy"></figure>
<h4 id="1-副本数据同步策略">1） 副本数据同步策略</h4>
<table>
<thead>
<tr>
<th>方案</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody>
<tr>
<td>半数以上完成同步， 就发 送 ack</td>
<td>延迟低</td>
<td>选举新的 leader 时， 容忍 n 台 节点的故障，需要 2n+1 个副 本</td>
</tr>
<tr>
<td>全部完成同步，才发送 ack</td>
<td>选举新的 leader 时， 容忍 n 台 节点的故障，需要 n+1 个副 本</td>
<td>延迟高</td>
</tr>
</tbody>
</table>
<p>Kafka 选择了<strong>第二种方案</strong>，原因如下：</p>
<ol>
<li>同样为了容忍 n 台节点的故障，第一种方案需要 2n+1 个副本，而第二种方案只需要 n+1<br>
个副本，而 Kafka 的每个分区都有大量的数据， 第一种方案会造成大量数据的冗余。</li>
<li>虽然第二种方案的网络延迟会比较高，但网络延迟对 Kafka 的影响较小。</li>
</ol>
<h4 id="2-isr">2） ISR</h4>
<p>采用第二种方案之后，设想以下情景： leader 收到数据，所有 follower 都开始同步数据，<br>
但有一个 follower，因为某种故障，迟迟不能与 leader 进行同步，那 leader 就要一直等下去，<br>
直到它完成同步，才能发送 ack。这个问题怎么解决呢？</p>
<p>Leader 维护了一个动态的 in-sync replica set (ISR)，意为和 leader 保持同步的 follower 集<br>
合。当 ISR 中的 follower 完成数据的同步之后， leader 就会给 follower 发送 ack。如果 follower<br>
长 时 间 未 向 leader 同 步 数 据 ， 则 该 follower 将 被 踢 出 ISR ， 该 时 间 阈 值 由<code>replica.lag.time.max.ms</code> 参数设定。 Leader 发生故障之后，就会从 ISR 中选举新的 leader。</p>
<h4 id="3-ack-应答机制">3） ack 应答机制</h4>
<p>对于某些不太重要的数据，对数据的可靠性要求不是很高，能够容忍数据的少量丢失，<br>
所以没必要等 ISR 中的 follower 全部接收成功。</p>
<p>所以 Kafka 为用户提供了三种可靠性级别，用户根据对可靠性和延迟的要求进行权衡，<br>
选择以下的配置。</p>
<p><strong>acks 参数配置</strong>：</p>
<p>acks：</p>
<p><code>0</code>： producer 不等待 broker 的 ack，这一操作提供了一个最低的延迟， broker 一接收到还<br>
没有写入磁盘就已经返回，当 broker 故障时有可能<strong>丢失数据</strong>；</p>
<p><code>1</code>： producer 等待 broker 的 ack， partition 的 leader 落盘成功后返回 ack，如果在 follower<br>
同步成功之前 leader 故障，那么将会<strong>丢失数据</strong>；</p>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1635746480264.png" alt="" loading="lazy"></figure>
<p><code>-1</code>（all） ： producer 等待 broker 的 ack， partition 的 leader 和 follower 全部落盘成功后才<br>
返回 ack。但是如果在 follower 同步完成后， broker 发送 ack 之前， leader 发生故障，那么会<br>
造成<strong>数据重复</strong>。</p>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1635746490157.png" alt="" loading="lazy"></figure>
<h4 id="4-故障处理细节">4） 故障处理细节</h4>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1635746502677.png" alt="" loading="lazy"></figure>
<p><code>LEO</code>：指的是每个副本最大的 offset；<br>
<code>HW</code>：指的是消费者能见到的最大的 offset， ISR 队列中最小的 LEO。</p>
<p>（1） follower 故障</p>
<p>follower 发生故障后会被临时踢出 ISR，待该 follower 恢复后， follower 会读取本地磁盘记录的上次的 HW，并将 log 文件高于 HW 的部分截取掉，从 HW 开始向 leader 进行同步。等该 <strong>follower 的 LEO 大于等于该 Partition 的 HW</strong>，即 follower 追上 leader 之后，就可以重新加入 ISR 了。</p>
<p>（2） leader 故障</p>
<p>leader 发生故障之后，会从 ISR 中选出一个新的 leader，之后，为保证多个副本之间的 数据一致性， 其余的 follower 会先将各自的 log 文件<strong>高于 HW 的部分截掉</strong>，然后从新的 leader同步数据。</p>
<p><strong>注意</strong>： 这只能保证副本之间的数据一致性，并不能保证数据不丢失或者不重复。</p>
<h3 id="323-exactly-once-语义">3.2.3 Exactly Once 语义</h3>
<p>将服务器的 ACK 级别设置为<code>-1</code>，可以保证 Producer 到 Server 之间不会丢失数据，即 <code>At</code><br>
<code>Least Once</code> 语义。相对的，将服务器 ACK 级别设置为 <code>0</code>，可以保证生产者每条消息只会被<br>
发送一次，即 <code>At Most Once</code> 语义。</p>
<p>At Least Once 可以保证数据不丢失，但是不能保证数据不重复；相对的， At Most Once<br>
可以保证数据不重复，但是不能保证数据不丢失。 但是，对于一些非常重要的信息，比如说<br>
交易数据，下游数据消费者要求数据既不重复也不丢失，即 <code>Exactly Once</code> 语义。 在 0.11 版<br>
本以前的 Kafka，对此是无能为力的，只能保证数据不丢失，再在下游消费者对数据做全局<br>
去重。对于多个下游应用的情况，每个都需要单独做全局去重，这就对性能造成了很大影响。<br>
0.11 版本的 Kafka，引入了一项重大特性：<strong>幂等性</strong>。所谓的幂等性就是指 Producer 不论向 Server 发送多少次重复数据， Server 端都只会持久化一条。幂等性结合 At Least Once 语义，就构成了 Kafka 的 Exactly Once 语义。即：</p>
<pre><code>At Least Once + 幂等性 = Exactly Once
</code></pre>
<p>要启用幂等性，只需要将 Producer 的参数中 <code>enable.idompotence</code> 设置为 <code>true</code> 即可。 Kafka<br>
的幂等性实现其实就是将原来下游需要做的去重放在了数据上游。开启幂等性的 Producer 在<br>
初始化的时候会被分配一个 <code>PID</code>，发往同一 <code>Partition</code> 的消息会附带 <code>Sequence Number</code>。而<br>
Broker 端会对<code>&lt;PID, Partition, SeqNumber&gt;</code>做缓存，当具有相同主键的消息提交时， Broker 只<br>
会持久化一条。</p>
<p>但是 PID 重启就会变化，同时不同的 Partition 也具有不同主键，所以<strong>幂等性无法保证跨</strong><br>
<strong>分区跨会话的 Exactly Once</strong>。</p>
<h2 id="33-kafka-消费者">3.3 Kafka 消费者</h2>
<h3 id="331-消费方式">3.3.1 消费方式</h3>
<p><strong>consumer 采用 pull（拉） 模式从 broker 中读取数据</strong>。</p>
<p><strong>push（推）模式很难适应消费速率不同的消费者，因为消息发送速率是由 broker 决定的</strong>。<br>
它的目标是尽可能以最快速度传递消息，但是这样很容易造成 consumer 来不及处理消息， 典型的表现就是拒绝服务以及网络拥塞。而 pull 模式则可以根据 consumer 的消费能力以适<br>
当的速率消费消息。</p>
<p><strong>pull 模式不足之处是，如果 kafka 没有数据，消费者可能会陷入循环中， 一直返回空数</strong><br>
<strong>据</strong>。 针对这一点， Kafka 的消费者在消费数据时会传入一个时长参数 timeout，如果当前没有<br>
数据可供消费， consumer 会等待一段时间之后再返回，这段时长即为 timeout。</p>
<h3 id="332-分区分配策略">3.3.2 分区分配策略</h3>
<p>一个 consumer group 中有多个 consumer，一个 topic 有多个 partition，所以必然会涉及<br>
到 partition 的分配问题，即确定那个 partition 由哪个 consumer 来消费。</p>
<p>Kafka 有两种分配策略，一是 RoundRobin，一是 Range。</p>
<p>当消费者个数改变时，会用到分区分配策略</p>
<p>1） RoundRobin</p>
<p><code>RoundRobinAssignor</code>策略的原理是将消费组内所有消费者以及消费者所订阅的所有topic的partition按照字典序排序，然后通过轮询方式逐个将分区以此分配给每个消费者。<code>RoundRobinAssignor</code>策略对应的<code>partition.assignment.strategy</code>参数值为：<code>org.apache.kafka.clients.consumer.RoundRobinAssignor</code>。</p>
<p>使用RoundRobin策略有两个前提条件必须满足：</p>
<ol>
<li>同一个消费者组里面的所有消费者的num.streams（消费者消费线程数）必须相等；</li>
<li>每个消费者订阅的主题必须相同。</li>
</ol>
<p>所以这里假设前面提到的2个消费者的num.streams = 2。RoundRobin策略的工作原理：将所有主题的分区组成 TopicAndPartition 列表，然后对 TopicAndPartition 列表按照 hashCode 进行排序,在我们的例子里面，按照 hashCode 排序完的topic-partitions组依次为T1-5, T1-3, T1-0, T1-8, T1-2, T1-1, T1-4, T1-7, T1-6, T1-9，我们的消费者线程排序为C1-0, C1-1, C2-0, C2-1，最后分区分配的结果为：</p>
<pre><code class="language-java">C1-0 将消费 T1-5, T1-2, T1-6 分区；
C1-1 将消费 T1-3, T1-1, T1-9 分区；
C2-0 将消费 T1-0, T1-4 分区；
C2-1 将消费 T1-8, T1-7 分区；
</code></pre>
<p>2） <strong>Range（默认策略）</strong></p>
<p>Range是<strong>对每个Topic而言</strong>的（即一个Topic一个Topic分），首先对同一个Topic里面的分区按照序号进行排序，并对消费者按照字母顺序进行排序。然后用Partitions分区的个数除以消费者线程的总数来决定每个消费者线程消费几个分区。如果除不尽，那么前面几个消费者线程将会多消费一个分区。</p>
<p>假设n=分区数/消费者数量，m=分区数%消费者数量，那么前m个消费者每个分配n+1个分区，后面的（消费者数量-m）个消费者每个分配n个分区。</p>
<p>假如有10个分区，3个消费者线程，把分区按照序号排列0，1，2，3，4，5，6，7，8，9；消费者线程为C1-0，C2-0，C2-1，那么用partition数除以消费者线程的总数来决定每个消费者线程消费几个partition，如果除不尽，前面几个消费者将会多消费一个分区。在我们的例子里面，我们有10个分区，3个消费者线程，10/3 = 3，而且除除不尽，那么消费者线程C1-0将会多消费一个分区，所以最后分区分配的结果看起来是这样的：</p>
<pre><code class="language-java">C1-0：0，1，2，3
C2-0：4，5，6
C2-1：7，8，9
</code></pre>
<h3 id="333-offset-的维护">3.3.3 offset 的维护</h3>
<p>由于 consumer 在消费过程中可能会出现断电宕机等故障， consumer 恢复后，需要从故<br>
障前的位置的继续消费，所以 consumer 需要实时记录自己消费到了哪个 offset，以便故障恢<br>
复后继续消费。</p>
<figure data-type="image" tabindex="9"><img src="https://tinaxiawuhao.github.io/post-images/1635746518265.png" alt="" loading="lazy"></figure>
<p><strong>Kafka 0.9 版本之前， consumer 默认将 offset 保存在 Zookeeper 中，从 0.9 版本开始，</strong><br>
<strong>consumer 默认将 offset 保存在 Kafka 一个内置的 topic 中，该 topic 为__consumer_offsets。</strong></p>
<p>1）修改配置文件 consumer.properties</p>
<pre><code>exclude.internal.topics=false
</code></pre>
<p>2）读取 offset</p>
<p>0.11.0.0 之前版本:</p>
<pre><code>bin/kafka-console-consumer.sh --topic __consumer_offsets --zookeeper hadoop102:2181 --formatter &quot;kafka.coordinator.GroupMetadataManager\$OffsetsMessageFormatter&quot; --consumer.config config/consumer.properties --from-beginning
</code></pre>
<p>0.11.0.0 之后版本(含):</p>
<pre><code>bin/kafka-console-consumer.sh --topic __consumer_offsets --
zookeeper hadoop102:2181 --formatter
&quot;kafka.coordinator.group.GroupMetadataManager\$OffsetsMessageForm
atter&quot; --consumer.config config/consumer.properties --frombeginning
</code></pre>
<h3 id="334-消费者组案例">3.3.4 消费者组案例</h3>
<p>1） 需求：测试同一个消费者组中的消费者， 同一时刻只能有一个消费者消费。</p>
<p>2） 案例实操</p>
<p>（1）在 hadoop102、 hadoop103 上修改<code>/opt/module/kafka/config/consumer.properties</code> 配置<br>
文件中的 <code>group.id</code> 属性为任意组名。</p>
<pre><code>[atguigu@hadoop103 config]$ vi consumer.properties
group.id=atguigu
</code></pre>
<p>（2）在 hadoop102、 hadoop103 上分别启动消费者</p>
<pre><code>[atguigu@hadoop102 kafka]$ bin/kafka-console-consumer.sh \
--zookeeper hadoop102:2181 --topic first --consumer.config config/consumer.properties

[atguigu@hadoop103 kafka]$ bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic first --consumer.config config/consumer.properties
</code></pre>
<p>（3）在 hadoop104 上启动生产者</p>
<pre><code>[atguigu@hadoop104 kafka]$ bin/kafka-console-producer.sh \
--broker-list hadoop102:9092 --topic first
&gt;hello world
</code></pre>
<p>（4）查看 hadoop102 和 hadoop103 的接收者。</p>
<p>同一时刻消费组内只有一个消费者接收到消息。</p>
<h2 id="34-kafka-高效读写数据">3.4 Kafka 高效读写数据</h2>
<p>1）顺序写磁盘</p>
<p>Kafka 的 producer 生产数据，要写入到 log 文件中，写的过程是一直追加到文件末端，<br>
为顺序写。 官网有数据表明，同样的磁盘，顺序写能到 600M/s，而随机写只有 100K/s。这<br>
与磁盘的机械机构有关，顺序写之所以快，是因为其省去了大量磁头寻址的时间。</p>
<p>2）零复制技术</p>
<figure data-type="image" tabindex="10"><img src="https://tinaxiawuhao.github.io/post-images/1635746530028.png" alt="" loading="lazy"></figure>
<p>3）分布式</p>
<h2 id="35-zookeeper-在-kafka-中的作用">3.5 Zookeeper 在 Kafka 中的作用</h2>
<p>Kafka 集群中有一个 broker 会被选举为 Controller，负责管理集群 broker 的上下线，所有 topic 的分区副本分配和 leader 选举等工作。Controller 的管理工作都是依赖于 Zookeeper 的。</p>
<p>以下为 partition 的 leader 选举过程：</p>
<figure data-type="image" tabindex="11"><img src="https://tinaxiawuhao.github.io/post-images/1635746537395.png" alt="" loading="lazy"></figure>
<h2 id="36-kafka-事务">3.6 Kafka 事务</h2>
<p>Kafka 从 0.11 版本开始引入了事务支持。事务可以保证 Kafka 在 Exactly Once 语义的基<br>
础上，生产和消费可以跨分区和会话，要么全部成功，要么全部失败。</p>
<h3 id="361-producer-事务">3.6.1 Producer 事务</h3>
<p>为了实现跨分区跨会话的事务，需要引入一个全局唯一的 Transaction ID，并将 Producer<br>
获得的PID 和Transaction ID 绑定。这样当Producer 重启后就可以通过正在进行的 Transaction ID 获得原来的 PID。</p>
<p>为了管理 Transaction， Kafka 引入了一个新的组件 <strong>Transaction Coordinator</strong>。 Producer 就是通过和 Transaction Coordinator 交互获得 Transaction ID 对应的任务状态。 Transaction Coordinator 还负责将事务所有写入 Kafka 的一个内部 Topic，这样即使整个服务重启，由于事务状态得到保存，进行中的事务状态可以得到恢复，从而继续进行。</p>
<h3 id="362-consumer-事务">3.6.2 Consumer 事务</h3>
<p>上述事务机制主要是从 Producer 方面考虑，对于 Consumer 而言，事务的保证就会相对<br>
较弱，尤其时无法保证 Commit 的信息被精确消费。这是由于 Consumer 可以通过 offset 访<br>
问任意信息，而且不同的 Segment File 生命周期不同，同一事务的消息可能会出现重启后被<br>
删除的情况。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[kafka常用命令]]></title>
        <id>https://tinaxiawuhao.github.io/post/cvzf4T4Wn/</id>
        <link href="https://tinaxiawuhao.github.io/post/cvzf4T4Wn/">
        </link>
        <updated>2021-10-29T07:15:38.000Z</updated>
        <content type="html"><![CDATA[<h3 id="管理">管理</h3>
<pre><code class="language-shell">## 创建topic（4个分区，2个副本）
bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 2 --partitions 4 --topic test

### kafka版本 &gt;= 2.2
bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic test

## 分区扩容
### kafka版本 &lt; 2.2
bin/kafka-topics.sh --zookeeper localhost:2181 --alter --topic topic1 --partitions 2

### kafka版本 &gt;= 2.2
bin/kafka-topics.sh --bootstrap-server broker_host:port --alter --topic topic1 --partitions 2

## 删除topic
bin/kafka-topics.sh --zookeeper localhost:2181 --delete --topic test
</code></pre>
<h3 id="查询">查询</h3>
<pre><code class="language-shell">## 查询集群描述
bin/kafka-topics.sh --describe --zookeeper 127.0.0.1:2181

## 查询集群描述（新）
bin/kafka-topics.sh --bootstrap-server localhost:9092 --topic foo --describe

## topic列表查询
bin/kafka-topics.sh --zookeeper 127.0.0.1:2181 --list

## topic列表查询（支持0.9版本+）
bin/kafka-topics.sh --list --bootstrap-server localhost:9092

## 消费者列表查询（存储在zk中的）
bin/kafka-consumer-groups.sh --zookeeper localhost:2181 --list

## 消费者列表查询（支持0.9版本+）
bin/kafka-consumer-groups.sh --new-consumer --bootstrap-server localhost:9092 --list

## 消费者列表查询（支持0.10版本+）
bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list

## 显示某个消费组的消费详情（仅支持offset存储在zookeeper上的）
bin/kafka-run-class.sh kafka.tools.ConsumerOffsetChecker --zookeeper localhost:2181 --group test

## 显示某个消费组的消费详情（0.9版本 - 0.10.1.0 之前）
bin/kafka-consumer-groups.sh --new-consumer --bootstrap-server localhost:9092 --describe --group test-consumer-group

## 显示某个消费组的消费详情（0.10.1.0版本+）
bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group my-group
</code></pre>
<h3 id="发送和消费">发送和消费</h3>
<pre><code class="language-shell">## 生产者
bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test

## 消费者（已失效）
bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test

## 生产者（支持0.9版本+）
bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test --producer.config config/producer.properties

## 消费者（支持0.9版本+，已失效）
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --new-consumer --from-beginning --consumer.config config/consumer.properties

## 消费者（最新）
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning --consumer.config config/consumer.properties


## kafka-verifiable-consumer.sh（消费者事件，例如：offset提交等）
bin/kafka-verifiable-consumer.sh --broker-list localhost:9092 --topic test --group-id groupName

## 高级点的用法
bin/kafka-simple-consumer-shell.sh --brist localhost:9092 --topic test --partition 0 --offset 1234  --max-messages 10
</code></pre>
<h3 id="切换leader">切换leader</h3>
<pre><code class="language-shell">## kafka版本 &lt;= 2.4
bin/kafka-preferred-replica-election.sh --zookeeper zk_host:port/chroot

## kafka新版本
bin/kafka-preferred-replica-election.sh --bootstrap-server broker_host:port
</code></pre>
<h3 id="kafka自带压测命令">kafka自带压测命令</h3>
<pre><code class="language-shell">bin/kafka-producer-perf-test.sh --topic test --num-records 100 --record-size 1 --throughput 100  --producer-props bootstrap.servers=localhost:9092
</code></pre>
<h3 id="kafka持续发送消息">kafka持续发送消息</h3>
<p>持续发送消息到指定的topic中，且每条发送的消息都会有响应信息：</p>
<pre><code class="language-shell">kafka-verifiable-producer.sh --broker-list $(hostname -i):9092 --topic test --max-messages 100000
</code></pre>
<h3 id="zookeeper-shellsh">zookeeper-shell.sh</h3>
<p>如果kafka集群的zk配置了chroot路径，那么需要加上<code>/path</code>。</p>
<pre><code class="language-shell">bin/zookeeper-shell.sh localhost:2181[/path]
ls /brokers/ids
get /brokers/ids/0
</code></pre>
<h3 id="迁移分区">迁移分区</h3>
<ol>
<li>
<p>创建规则json</p>
<pre><code class="language-shell">cat &gt; increase-replication-factor.json &lt;&lt;EOF
{&quot;version&quot;:1, &quot;partitions&quot;:[
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:3,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:4,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:5,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:6,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:7,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:8,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:9,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:10,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:11,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:12,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:13,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:14,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:15,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:16,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:17,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:18,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:19,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:20,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:21,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:22,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:23,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:24,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:25,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:26,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:27,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:28,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:29,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:30,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:31,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:32,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:33,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:34,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:35,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:36,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:37,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:38,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:39,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:40,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:41,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:42,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:43,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:44,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:45,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:46,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:47,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:48,&quot;replicas&quot;:[0,1]},
{&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:49,&quot;replicas&quot;:[0,1]}]
}
EOF
</code></pre>
</li>
<li>
<p>执行</p>
<pre><code class="language-shell">bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 --reassignment-json-file increase-replication-factor.json --execute
</code></pre>
</li>
<li>
<p>验证</p>
<pre><code class="language-shell">bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 --reassignment-json-file increase-replication-factor.json --verify
</code></pre>
</li>
</ol>
<h3 id="删除消费者组">删除消费者组</h3>
<p>查询消费者组列表：</p>
<pre><code class="language-shell">kafka-consumer-groups.sh --bootstrap-server 172.31.1.245:9092 --list
</code></pre>
<p>查询消费者组明细：</p>
<pre><code class="language-shell">kafka-consumer-groups.sh --bootstrap-server {Kafka instance connection address} --describe --group {consumer group name}
</code></pre>
<p>删除消费者组：</p>
<pre><code class="language-shell">kafka-consumer-groups.sh --bootstrap-server {Kafka instance connection address} --delete --group {consumer group name}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[zookeeper选举过程]]></title>
        <id>https://tinaxiawuhao.github.io/post/Rz0qPOGXr/</id>
        <link href="https://tinaxiawuhao.github.io/post/Rz0qPOGXr/">
        </link>
        <updated>2021-10-22T08:02:27.000Z</updated>
        <content type="html"><![CDATA[<h3 id="初始化选举">初始化选举</h3>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1634890367738.png" alt="" loading="lazy"></figure>
<h3 id="运行期间选举">运行期间选举</h3>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1634890194753.png" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ReentrantLock源码详解]]></title>
        <id>https://tinaxiawuhao.github.io/post/CxCcIUkNX/</id>
        <link href="https://tinaxiawuhao.github.io/post/CxCcIUkNX/">
        </link>
        <updated>2021-10-21T06:20:51.000Z</updated>
        <content type="html"><![CDATA[<p><code>ReentrantLock</code>重入锁，是实现Lock接口的一个类，也是在实际编程中使用频率很高的一个锁，支持重入性，表示能够对共享资源能够重复加锁，即当前线程获取该锁再次获取不会被阻塞。</p>
<p>ReentrantLock还支持公平锁和非公平锁两种方式。那么，要想完完全全的弄懂ReentrantLock的话，主要也就是ReentrantLock同步语义的学习：</p>
<ol>
<li>重入性的实现原理；</li>
<li>公平锁和非公平锁</li>
</ol>
<h3 id="reentrantlock源码解析">ReentrantLock源码解析</h3>
<h4 id="加锁">加锁</h4>
<pre><code class="language-java">//使用案例
class Bank{
      /**
       * volatile实现
       */
      private  int count=0;
      /**
       * 使用可重入锁
       */
      private Lock lock=new ReentrantLock();

      public void getCount(){
            System.out.println(&quot;账户余额为：&quot;+count);
      }
      /**
       * 同步方法实现存钱
       * @param money
       */
      public void save(int money){
            lock.lock();
            try {
                  count+=money;
                  System.out.println(System.currentTimeMillis()+&quot;存进：&quot;+money);
            } catch (Exception e) {
                  // TODO Auto-generated catch block
                  e.printStackTrace();
            }finally {
                  lock.unlock();//释放锁
            }
      }
      /**
       * 同步代码块实现取钱
       * @param money
       */
      public  void remove(int money){
            if (count-money&lt;0) {
                  System.err.println(&quot;余额不足。&quot;);
                  return;
            }
                lock.lock();
                  try {
                        count-=money;
                        System.err.println(System.currentTimeMillis()+&quot;取出：&quot;+money);
                  } catch (Exception e) {
                        // TODO Auto-generated catch block
                        e.printStackTrace();
                  }finally {
                        lock.unlock();
                  }

      }
}
</code></pre>
<pre><code class="language-java">	/**
     * Creates an instance of {@code ReentrantLock}.
     * This is equivalent to using {@code ReentrantLock(false)}.
     */
    public ReentrantLock() {
        sync = new NonfairSync();
    }

    /**
     * Creates an instance of {@code ReentrantLock} with the
     * given fairness policy.
     *
     * @param fair {@code true} if this lock should use a fair ordering policy
     */
    public ReentrantLock(boolean fair) {
        sync = fair ? new FairSync() : new NonfairSync();
    }
</code></pre>
<p>初始化默认使用非公平锁</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1634801159801.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1634801206315.png" alt="" loading="lazy"></figure>
<p>公平锁和非公平锁继承AbstractQueuedSynchronizer接口（抽象的队列式的同步器，AQS定义了一套多线程访问共享资源的同步器框架）</p>
<p>AQS框架</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1634801241636.png" alt="" loading="lazy"></figure>
<ul>
<li>NonfairSync的类继承关系<br>
<img src="https://tinaxiawuhao.github.io/post-images/1634801286878.png" alt="" loading="lazy"></li>
<li>FairSync的类继承关系<br>
<img src="https://tinaxiawuhao.github.io/post-images/1634801320830.png" alt="" loading="lazy"></li>
</ul>
<p>下面以非公平锁为例</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1634801531856.png" alt="" loading="lazy"></figure>
<pre><code class="language-java">/**
 * Performs lock.  Try immediate barge, backing up to normal
 * acquire on failure.
 */
//加锁流程真正意义上的入口
final void lock() {
    //以cas方式尝试将AQS中的state从0更新为1
    if (compareAndSetState(0, 1))
        setExclusiveOwnerThread(Thread.currentThread());//获取锁成功则将当前线程标记为持有锁的线程,然后直接返回
    else
        acquire(1);//获取锁失败则执行该方法
}

</code></pre>
<p>加锁时调用lock方法，首先判断AQS中的sate参数是否被标记,尝试以cas方式尝试将AQS中的state从0更新为1，成功将当前线程赋予AQS</p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1634801522921.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1634801553641.png" alt="" loading="lazy"></figure>
<p>失败则调用AQS类的acquire(1)方法</p>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1634801668520.png" alt="" loading="lazy"></figure>
<pre><code class="language-java">//非公平模式下尝试获取锁的方法
protected final boolean tryAcquire(int acquires) {
    return nonfairTryAcquire(acquires);
}
</code></pre>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1634801709991.png" alt="" loading="lazy"></figure>
<pre><code class="language-java">/**
 * Performs non-fair tryLock.  tryAcquire is implemented in
 * subclasses, but both need nonfair try for trylock method.
 */
final boolean nonfairTryAcquire(int acquires) {
    final Thread current = Thread.currentThread();//获取当前线程实例
    int c = getState();//获取state变量的值,即当前锁被重入的次数
    if (c == 0) {   //state为0,说明当前锁未被任何线程持有
        if (compareAndSetState(0, acquires)) { //以cas方式获取锁
            setExclusiveOwnerThread(current);  //将当前线程标记为持有锁的线程
            return true;//获取锁成功,非重入
        }
    }
    else if (current == getExclusiveOwnerThread()) { //当前线程就是持有锁的线程,说明该锁被重入了
        int nextc = c + acquires;//计算state变量要更新的值
        if (nextc &lt; 0) // overflow
            throw new Error(&quot;Maximum lock count exceeded&quot;);
        setState(nextc);//非同步方式更新state值
        return true;  //获取锁成功,重入
    }
    return false;     //走到这里说明尝试获取锁失败
}
</code></pre>
<p>这是非公平模式下获取锁的通用方法。它囊括了当前线程在尝试获取锁时的所有可能情况：</p>
<ul>
<li>1.当前锁未被任何线程持有(state=0),则以cas方式获取锁,若获取成功则设置exclusiveOwnerThread为当前线程,然后返回成功的结果；若cas失败,说明在得到state=0和cas获取锁之间有其他线程已经获取了锁,返回失败结果。</li>
<li>2.若锁已经被当前线程获取(state&gt;0,exclusiveOwnerThread为当前线程),则将锁的重入次数加1(state+1),然后返回成功结果。因为该线程之前已经获得了锁,所以这个累加操作不用同步。</li>
<li>3.若当前锁已经被其他线程持有(state&gt;0,exclusiveOwnerThread不为当前线程),则直接返回失败结果</li>
</ul>
<p>因为我们用state来统计锁被线程重入的次数,所以当前线程尝试获取锁的操作是否成功可以简化为:state值是否成功累加1,是则尝试获取锁成功,否则尝试获取锁失败。</p>
<p>其实这里还可以思考一个问题:nonfairTryAcquire已经实现了一个囊括所有可能情况的尝试获取锁的方式,为何在刚进入lock方法时还要通过compareAndSetState(0, 1)去获取锁,毕竟后者只有在锁未被任何线程持有时才能执行成功,我们完全可以把compareAndSetState(0, 1)去掉,对最后的结果不会有任何影响。这种在进行通用逻辑处理之前针对某些特殊情况提前进行处理的方式在后面还会看到,一个直观的想法就是它能提升性能，而代价是牺牲一定的代码简洁性。</p>
<p>退回到上层的acquire方法,</p>
<pre><code class="language-java">public final void acquire(int arg) {
    if (!tryAcquire(arg) &amp;&amp;  //当前线程尝试获取锁,若获取成功返回true,否则false
        acquireQueued(addWaiter(Node.EXCLUSIVE), arg))  //只有当前线程获取锁失败才会执行者这部分代码
        selfInterrupt();
}
</code></pre>
<p>tryAcquire(arg)返回成功,则说明当前线程成功获取了锁(第一次获取或者重入),由取反和&amp;&amp;可知,整个流程到这结束，只有当前线程获取锁失败才会执行后面的判断。先来看addWaiter(Node.EXCLUSIVE)部分,这部分代码描述了当线程获取锁失败时如何安全的加入同步等待队列。</p>
<p>这部分逻辑在addWaiter()方法中</p>
<pre><code class="language-java">/**
 * Creates and enqueues node for current thread and given mode.
 *
 * @param mode Node.EXCLUSIVE for exclusive, Node.SHARED for shared
 * @return the new node
 */
private Node addWaiter(Node mode) {
    Node node = new Node(Thread.currentThread(), mode);//首先创建一个新节点,并将当前线程实例封装在内部,mode这里为null
    // Try the fast path of enq; backup to full enq on failure
    Node pred = tail;
    if (pred != null) {
        node.prev = pred;
        if (compareAndSetTail(pred, node)) {
            pred.next = node;
            return node;
        }
    }
    enq(node);//入队的逻辑这里都有
    return node;
}
</code></pre>
<p>首先创建了一个新节点,并将当前线程实例封装在其内部,之后我们直接看enq(node)方法就可以了,中间这部分逻辑在enq(node)中都有,之所以加上这部分“重复代码”和尝试获取锁时的“重复代码”一样,对某些特殊情况<br>
进行提前处理,牺牲一定的代码可读性换取性能提升。</p>
<pre><code class="language-java">/**
 * Inserts node into queue, initializing if necessary. See picture above.
 * @param node the node to insert
 * @return node's predecessor
 */
private Node enq(final Node node) {
    for (;;) {
        Node t = tail;//t指向当前队列的最后一个节点,队列为空则为null
        if (t == null) { // Must initialize  //队列为空
            if (compareAndSetHead(new Node())) //构造新结点,CAS方式设置为队列首元素,当head==null时更新成功
                tail = head;//尾指针指向首结点
        } else {  //队列不为空
            node.prev = t;
            if (compareAndSetTail(t, node)) { //CAS将尾指针指向当前结点,当t(原来的尾指针)==tail(当前真实的尾指针)时执行成功
                t.next = node;    //原尾结点的next指针指向当前结点
                return t;
            }
        }
    }
}
</code></pre>
<p>这里有两个CAS操作:</p>
<ul>
<li>compareAndSetHead(new Node()),CAS方式更新head指针,仅当原值为null时更新成功</li>
</ul>
<pre><code class="language-java">/**
 * CAS head field. Used only by enq.
 */
private final boolean compareAndSetHead(Node update) {
    return unsafe.compareAndSwapObject(this, headOffset, null, update);
}
</code></pre>
<ul>
<li>compareAndSetTail(t, node),CAS方式更新tial指针,仅当原值为t时更新成功</li>
</ul>
<pre><code class="language-java">/**
 * CAS tail field. Used only by enq.
 */
private final boolean compareAndSetTail(Node expect, Node update) {
    return unsafe.compareAndSwapObject(this, tailOffset, expect, update);
}
</code></pre>
<p>外层的for循环保证了所有获取锁失败的线程经过失败重试后最后都能加入同步队列。因为AQS的同步队列是不带哨兵结点的,故当队列为空时要进行特殊处理,这部分在if分句中。注意当前线程所在的结点不能直接插入<br>
空队列,因为阻塞的线程是由前驱结点进行唤醒的。故先要插入一个结点作为队列首元素,当锁释放时由它来唤醒后面被阻塞的线程,从逻辑上这个队列首元素也可以表示当前正获取锁的线程,虽然并不一定真实持有其线程实例。</p>
<p>首先通过new Node()创建一个空结点，然后以CAS方式让头指针指向该结点(该结点并非当前线程所在的结点),若该操作成功,则将尾指针也指向该结点。这部分的操作流程可以用下图表示<br>
<img src="https://tinaxiawuhao.github.io/post-images/1634801748941.png" alt="" loading="lazy"></p>
<p>当队列不为空,则执行通用的入队逻辑,这部分在else分句中</p>
<pre><code class="language-java">else {  //队列不为空
    node.prev = t;
    if (compareAndSetTail(t, node)) { //CAS将尾指针指向当前结点,当t(原来的尾指针)==tail(当前真实的尾指针)时执行成功
        t.next = node;    //原尾结点的next指针指向当前结点
        return t;
    }
</code></pre>
<p>首先当前线程所在的结点的前向指针pre指向当前线程认为的尾结点,源码中用t表示。然后以CAS的方式将尾指针指向当前结点,该操作仅当tail=t,即尾指针在进行CAS前未改变时成功。若CAS执行成功,则将原尾结点的后向指针next指向新的尾结点。整个过程如下图所示</p>
<figure data-type="image" tabindex="9"><img src="https://tinaxiawuhao.github.io/post-images/1634801777081.png" alt="" loading="lazy"></figure>
<p>整个入队的过程并不复杂,是典型的CAS加失败重试的乐观锁策略。其中只有更新头指针和更新尾指针这两步进行了CAS同步,可以预见高并发场景下性能是非常好的。但是本着质疑精神我们不禁会思考下这么做真的线程安全吗？<br>
<img src="https://tinaxiawuhao.github.io/post-images/1634801800984.png" alt="" loading="lazy"></p>
<ul>
<li>1.队列为空的情况:<br>
因为队列为空,故head=tail=null,假设线程执行2成功,则在其执行3之前,因为tail=null,其他进入该方法的线程因为head不为null将在2处不停的失败,所以3即使没有同步也不会有线程安全问题。</li>
<li>2.队列不为空的情况:<br>
假设线程执行5成功,则此时4的操作必然也是正确的(当前结点的prev指针确实指向了队列尾结点,换句话说tail指针没有改变,如若不然5必然执行失败),又因为4执行成功,当前节点在队列中的次序已经确定了,所以6何时执行对线程安全不会有任何影响,比如下面这种情况</li>
</ul>
<figure data-type="image" tabindex="10"><img src="https://tinaxiawuhao.github.io/post-images/1634801836174.png" alt="" loading="lazy"></figure>
<p>为了确保真的理解了它,可以思考这个问题:把enq方法图中的4放到5之后,整个入队的过程还线程安全吗？</p>
<p>到这为止,获取锁失败的线程加入同步队列的逻辑就结束了。但是线程加入同步队列后会做什么我们并不清楚,这部分在acquireQueued方法中</p>
<figure data-type="image" tabindex="11"><img src="https://tinaxiawuhao.github.io/post-images/1634801857466.png" alt="" loading="lazy"></figure>
<p>acquireQueued方法的源码</p>
<pre><code class="language-java">/**
 * Acquires in exclusive uninterruptible mode for thread already in
 * queue. Used by condition wait methods as well as acquire.
 *
 * @param node the node
 * @param arg the acquire argument
 * @return {@code true} if interrupted while waiting
 */
final boolean acquireQueued(final Node node, int arg) {
    boolean failed = true;
    try {
        boolean interrupted = false;
        //死循环,正常情况下线程只有获得锁才能跳出循环
        for (;;) {
            final Node p = node.predecessor();//获得当前线程所在结点的前驱结点
            //第一个if分句
            if (p == head &amp;&amp; tryAcquire(arg)) { 
                setHead(node); //将当前结点设置为队列头结点
                p.next = null; // help GC
                failed = false;
                return interrupted;//正常情况下死循环唯一的出口
            }
            //第二个if分句
            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;  //判断是否要阻塞当前线程
                parkAndCheckInterrupt())      //阻塞当前线程
                interrupted = true;
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}
</code></pre>
<p>这段代码主要的内容都在for循环中,这是一个死循环,主要有两个if分句构成。第一个if分句中,当前线程首先会判断前驱结点是否是头结点,如果是则尝试获取锁,获取锁成功则会设置当前结点为头结点(更新头指针)。为什么必须前驱结点为头结点才尝试去获取锁？因为头结点表示当前正占有锁的线程,正常情况下该线程释放锁后会通知后面结点中阻塞的线程,阻塞线程被唤醒后去获取锁,这是我们希望看到的。然而还有一种情况,就是前驱结点取消了等待,此时当前线程也会被唤醒,这时候就不应该去获取锁,而是往前回溯一直找到一个没有取消等待的结点,然后将自身连接在它后面。一旦我们成功获取了锁并成功将自身设置为头结点,就会跳出for循环。否则就会执行第二个if分句:确保前驱结点的状态为SIGNAL,然后阻塞当前线程。</p>
<p>先来看shouldParkAfterFailedAcquire(p, node)，从方法名上我们可以大概猜出这是判断是否要阻塞当前线程的,方法内容如下</p>
<pre><code class="language-java">/**
 * Checks and updates status for a node that failed to acquire.
 * Returns true if thread should block. This is the main signal
 * control in all acquire loops.  Requires that pred == node.prev.
 *
 * @param pred node's predecessor holding status
 * @param node the node
 * @return {@code true} if thread should block
 */
private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) {
    int ws = pred.waitStatus;
    if (ws == Node.SIGNAL) //状态为SIGNAL

        /*
         * This node has already set status asking a release
         * to signal it, so it can safely park.
         */
        return true;
    if (ws &gt; 0) { //状态为CANCELLED,
        /*
         * Predecessor was cancelled. Skip over predecessors and
         * indicate retry.
         */
        do {
            node.prev = pred = pred.prev;
        } while (pred.waitStatus &gt; 0);
        pred.next = node;
    } else { //状态为初始化状态(ReentrentLock语境下)
        /*
         * waitStatus must be 0 or PROPAGATE.  Indicate that we
         * need a signal, but don't park yet.  Caller will need to
         * retry to make sure it cannot acquire before parking.
         */
        compareAndSetWaitStatus(pred, ws, Node.SIGNAL);
    }
    return false;
}
</code></pre>
<p>可以看到针对前驱结点pred的状态会进行不同的处理</p>
<ul>
<li>1.pred状态为SIGNAL,则返回true,表示要阻塞当前线程。</li>
<li>2.pred状态为CANCELLED,则一直往队列头部回溯直到找到一个状态不为CANCELLED的结点,将当前节点node挂在这个结点的后面。</li>
<li>3.pred的状态为初始化状态,此时通过compareAndSetWaitStatus(pred, ws, Node.SIGNAL)方法将pred的状态改为SIGNAL。</li>
</ul>
<p>其实这个方法的含义很简单,就是确保当前结点的前驱结点的状态为SIGNAL,SIGNAL意味着线程释放锁后会唤醒后面阻塞的线程。毕竟,只有确保能够被唤醒，当前线程才能放心的阻塞。</p>
<p>但是要注意只有在前驱结点已经是SIGNAL状态后才会执行后面的方法立即阻塞,对应上面的第一种情况。其他两种情况则因为返回false而重新执行一遍<br>
for循环。这种延迟阻塞其实也是一种高并发场景下的优化,试想我如果在重新执行循环的时候成功获取了锁,是不是线程阻塞唤醒的开销就省了呢？</p>
<p>最后我们来看看阻塞线程的方法parkAndCheckInterrupt</p>
<p>shouldParkAfterFailedAcquire返回true表示应该阻塞当前线程,则会执行parkAndCheckInterrupt方法,这个方法比较简单,底层调用了LockSupport来阻塞当前线程,源码如下:</p>
<pre><code class="language-java">/**
 * Convenience method to park and then check if interrupted
 *
 * @return {@code true} if interrupted
 */
private final boolean parkAndCheckInterrupt() {
    LockSupport.park(this);
    return Thread.interrupted();
}
</code></pre>
<p>该方法内部通过调用LockSupport的park方法来阻塞当前线程</p>
<blockquote>
<p>LockSupport就是通过控制变量<code>_counter</code>来对线程阻塞唤醒进行控制的。原理有点类似于信号量机制。</p>
<ul>
<li>当调用<code>park()</code>方法时，会将_counter置为0，同时判断前值，小于1说明前面被<code>unpark</code>过,则直接退出，否则将使该线程阻塞。</li>
<li>当调用<code>unpark()</code>方法时，会将_counter置为1，同时判断前值，小于1会进行线程唤醒，否则直接退出。<br>
形象的理解，线程阻塞需要消耗凭证(permit)，这个凭证最多只有1个。当调用park方法时，如果有凭证，则会直接消耗掉这个凭证然后正常退出；但是如果没有凭证，就必须阻塞等待凭证可用；而unpark则相反，它会增加一个凭证，但凭证最多只能有1个。</li>
<li>为什么可以先唤醒线程后阻塞线程？<br>
因为unpark获得了一个凭证,之后调用park因为有凭证消费，故不会阻塞。</li>
<li>为什么唤醒两次后阻塞两次会阻塞线程。<br>
因为凭证的数量最多为1，连续调用两次unpark和调用一次unpark效果一样，只会增加一个凭证；而调用两次park却需要消费两个凭证。</li>
</ul>
</blockquote>
<p>下面通过一张流程图来说明线程从加入同步队列到成功获取锁的过程<br>
<img src="https://tinaxiawuhao.github.io/post-images/1634801891432.png" alt="" loading="lazy"></p>
<p>概括的说,线程在同步队列中会尝试获取锁,失败则被阻塞,被唤醒后会不停的重复这个过程,直到线程真正持有了锁,并将自身结点置于队列头部。</p>
<p>ReentrantLock非公平模式下的加锁流程如下<br>
<img src="https://tinaxiawuhao.github.io/post-images/1634801907228.png" alt="" loading="lazy"></p>
<h4 id="解锁">解锁</h4>
<p>解锁源码如下：</p>
<figure data-type="image" tabindex="12"><img src="https://tinaxiawuhao.github.io/post-images/1634801926669.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="13"><img src="https://tinaxiawuhao.github.io/post-images/1634801941512.png" alt="" loading="lazy"></figure>
<pre><code class="language-java">public void unlock() {
    sync.release(1);  
}
public final boolean release(int arg) {
    if (tryRelease(arg)) { //释放锁(state-1),若释放后锁可被其他线程获取(state=0),返回true
        Node h = head;
        //当前队列不为空且头结点状态不为初始化状态(0)   
        if (h != null &amp;&amp; h.waitStatus != 0)
            unparkSuccessor(h);  //唤醒同步队列中被阻塞的线程
        return true;
    }
    return false;
}
</code></pre>
<p>正确找到sync的实现类,找到真正的入口方法,主要内容都在一个if语句中,先看下判断条件tryRelease方法</p>
<figure data-type="image" tabindex="14"><img src="https://tinaxiawuhao.github.io/post-images/1634801958450.png" alt="" loading="lazy"></figure>
<pre><code class="language-java">protected final boolean tryRelease(int releases) {
    int c = getState() - releases; //计算待更新的state值
    if (Thread.currentThread() != getExclusiveOwnerThread())
        throw new IllegalMonitorStateException();
    boolean free = false;
    if (c == 0) { //待更新的state值为0,说明持有锁的线程未重入,一旦释放锁其他线程将能获取
        free = true; 
        setExclusiveOwnerThread(null);//清除锁的持有线程标记
    }
    setState(c);//更新state值
    return free;
}
</code></pre>
<p>tryRelease其实只是将线程持有锁的次数减1,即将state值减1,若减少后线程将完全释放锁(state值为0),则该方法将返回true,否则返回false。由于执行该方法的线程必然持有锁,故该方法不需要任何同步操作。<br>
若当前线程已经完全释放锁,即锁可被其他线程使用,则还应该唤醒后续等待线程。不过在此之前需要进行两个条件的判断：</p>
<ul>
<li>h!=null是为了防止队列为空,即没有任何线程处于等待队列中,那么也就不需要进行唤醒的操作</li>
<li>h.waitStatus != 0是为了防止队列中虽有线程,但该线程还未阻塞,由前面的分析知,线程在阻塞自己前必须设置前驱结点的状态为SIGNAL,否则它不会阻塞自己。</li>
</ul>
<p>接下来就是唤醒线程的操作,unparkSuccessor(h)源码如下</p>
<figure data-type="image" tabindex="15"><img src="https://tinaxiawuhao.github.io/post-images/1634801976600.png" alt="" loading="lazy"></figure>
<pre><code class="language-java">private void unparkSuccessor(Node node) {
    /*
     * If status is negative (i.e., possibly needing signal) try
     * to clear in anticipation of signalling.  It is OK if this
     * fails or if status is changed by waiting thread.
     */
    int ws = node.waitStatus;
    if (ws &lt; 0)
        compareAndSetWaitStatus(node, ws, 0);

    /*
     * Thread to unpark is held in successor, which is normally
     * just the next node.  But if cancelled or apparently null,
     * traverse backwards from tail to find the actual
     * non-cancelled successor.
     */
    Node s = node.next;
    if (s == null || s.waitStatus &gt; 0) {
        s = null;
        for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev)
            if (t.waitStatus &lt;= 0)
                s = t;
    }
    if (s != null)
        LockSupport.unpark(s.thread);
}
</code></pre>
<p>一般情况下只要唤醒后继结点的线程就行了,但是后继结点可能已经取消等待,所以从队列尾部往前回溯,找到离头结点最近的正常结点,并唤醒其线程。</p>
<p><strong>解锁流程源码总结</strong></p>
<figure data-type="image" tabindex="16"><img src="https://tinaxiawuhao.github.io/post-images/1634801989557.png" alt="" loading="lazy"></figure>
<h3 id="公平锁相比非公平锁的不同">公平锁相比非公平锁的不同</h3>
<p>公平锁模式下,对锁的获取有严格的条件限制。在同步队列有线程等待的情况下,所有线程在获取锁前必须先加入同步队列。队列中的线程按加入队列的先后次序获得锁。<br>
从公平锁加锁的入口开始,<br>
<img src="https://tinaxiawuhao.github.io/post-images/1634802000468.png" alt="" loading="lazy"></p>
<p>对比非公平锁,少了非重入式获取锁的方法,这是第一个不同点</p>
<p>接着看获取锁的通用方法tryAcquire(),该方法在线程未进入队列,加入队列阻塞前和阻塞后被唤醒时都会执行。<br>
<img src="https://tinaxiawuhao.github.io/post-images/1634802012961.png" alt="" loading="lazy"></p>
<p>在真正CAS获取锁之前加了判断,内容如下</p>
<pre><code class="language-java">public final boolean hasQueuedPredecessors() {
    // The correctness of this depends on head being initialized
    // before tail and on head.next being accurate if the current
    // thread is first in queue.
    Node t = tail; // Read fields in reverse initialization order
    Node h = head;
    Node s;
    return h != t &amp;&amp;
        ((s = h.next) == null || s.thread != Thread.currentThread());
}
</code></pre>
<p>从方法名我们就可知道这是判断队列中是否有优先级更高的等待线程,队列中哪个线程优先级最高？由于头结点是当前获取锁的线程,队列中的第二个结点代表的线程优先级最高。<br>
那么我们只要判断队列中第二个结点是否存在以及这个结点是否代表当前线程就行了。这里分了两种情况进行探讨:</p>
<ol>
<li>第二个结点已经完全插入,但是这个结点是否就是当前线程所在结点还未知,所以通过s.thread != Thread.currentThread()进行判断,如果为true,说明第二个结点代表其他线程。</li>
<li>第二个结点并未完全插入,我们知道结点入队一共分三步：</li>
</ol>
<ul>
<li>1.待插入结点的pre指针指向原尾结点</li>
<li>2.CAS更新尾指针</li>
<li>3.原尾结点的next指针指向新插入结点</li>
</ul>
<p>所以(s = h.next) == null 就是用来判断2刚执行成功但还未执行3这种情况的。这种情况第二个结点必然属于其他线程。<br>
以上两种情况都会使该方法返回true,即当前有优先级更高的线程在队列中等待,那么当前线程将不会执行CAS操作去获取锁,保证了线程获取锁的顺序与加入同步队列的顺序一致，很好的保证了公平性,但也增加了获取锁的成本。</p>
<h3 id="一些疑问的解答">一些疑问的解答</h3>
<h4 id="为什么基于fifo的同步队列可以实现非公平锁">为什么基于FIFO的同步队列可以实现非公平锁？</h4>
<p>由FIFO队列的特性知,先加入同步队列等待的线程会比后加入的线程更靠近队列的头部,那么它将比后者更早的被唤醒,它也就能更早的得到锁。从这个意义上,对于在同步队列中等待的线程而言,它们获得锁的顺序和加入同步队列的顺序一致，这显然是一种公平模式。然而,线程并非只有在加入队列后才有机会获得锁,哪怕同步队列中已有线程在等待,非公平锁的不公平之处就在于此。回看下非公平锁的加锁流程,线程在进入同步队列等待之前有两次抢占锁的机会:</p>
<ul>
<li>第一次是非重入式的获取锁,只有在当前锁未被任何线程占有(包括自身)时才能成功;</li>
<li>第二次是在进入同步队列前,包含所有情况的获取锁的方式。</li>
</ul>
<p>只有这两次获取锁都失败后,线程才会构造结点并加入同步队列等待。而线程释放锁时是先释放锁(修改state值),然后才唤醒后继结点的线程的。试想下这种情况,线程A已经释放锁,但还没来得及唤醒后继线程C,而这时另一个线程B刚好尝试获取锁,此时锁恰好不被任何线程持有,它将成功获取锁而不用加入队列等待。线程C被唤醒尝试获取锁,而此时锁已经被线程B抢占,故而其获取失败并继续在队列中等待。整个过程如下图所示<br>
<img src="https://tinaxiawuhao.github.io/post-images/1634802025981.png" alt="" loading="lazy"></p>
<p>如果以线程第一次尝试获取锁到最后成功获取锁的次序来看,非公平锁确实很不公平。因为在队列中等待很久的线程相比还未进入队列等待的线程并没有优先权,甚至竞争也处于劣势:在队列中的线程要等待其他线程唤醒,在获取锁之前还要检查前驱结点是否为头结点。在锁竞争激烈的情况下,在队列中等待的线程可能迟迟竞争不到锁。这也就非公平在高并发情况下会出现的饥饿问题。那我们再开发中为什么大多使用会导致饥饿的非公平锁？很简单,因为它性能好啊。</p>
<h4 id="为什么非公平锁性能好">为什么非公平锁性能好</h4>
<p>非公平锁对锁的竞争是抢占式的(队列中线程除外),线程在进入等待队列前可以进行两次尝试,这大大增加了获取锁的机会。这种好处体现在两个方面:</p>
<ul>
<li>1.线程不必加入等待队列就可以获得锁,不仅免去了构造结点并加入队列的繁琐操作,同时也节省了线程阻塞唤醒的开销,线程阻塞和唤醒涉及到线程上下文的切换和操作系统的系统调用,是非常耗时的。在高并发情况下,如果线程持有锁的时间非常短,短到线程入队阻塞的过程超过线程持有并释放锁的时间开销,那么这种抢占式特性对并发性能的提升会更加明显。</li>
<li>2.减少CAS竞争。如果线程必须要加入阻塞队列才能获取锁,那入队时CAS竞争将变得异常激烈,CAS操作虽然不会导致失败线程挂起,但不断失败重试导致的对CPU的浪费也不能忽视。除此之外,加锁流程中至少有两处通过将某些特殊情况提前来减少CAS操作的竞争,增加并发情况下的性能。一处就是获取锁时将非重入的情况提前,如下图所示<br>
<img src="https://tinaxiawuhao.github.io/post-images/1634802037809.png" alt="" loading="lazy"></li>
</ul>
<p>另一处就是入队的操作,将同步队列非空的情况提前处理<br>
<img src="https://tinaxiawuhao.github.io/post-images/1634802048793.png" alt="" loading="lazy"></p>
<p>这两部分的代码在之后的通用逻辑处理中都有,很显然属于重复代码,但因为避免了执行无意义的流程代码,比如for循环,获取同步状态等,高并发场景下也能减少CAS竞争失败的可能。</p>
<h3 id="读写锁reentrantreadwritelock">读写锁ReentrantReadWriteLock</h3>
<p>首先明确一下，不是说 ReentrantLock 不好，只是 ReentrantLock 某些时候有局限。如果使用 ReentrantLock，可能本身是为了防止线程 A 在写数据、线程 B 在读数据造成的数据不一致，但这样，如果线程 C 在读数据、线程 D 也在读数据，读数据是不会改变数据的，没有必要加锁，但是还是加锁了，降低了程序的性能。因为这个，才诞生了读写锁 ReadWriteLock。</p>
<p>ReadWriteLock 是一个读写锁接口，读写锁是用来提升并发程序性能的锁分离技术，ReentrantReadWriteLock 是 ReadWriteLock 接口的一个具体实现，实现了读写的分离，读锁是共享的，写锁是独占的，读和读之间不会互斥，读和写、写和读、写和写之间才会互斥，提升了读写的性能。</p>
<p>而读写锁有以下三个重要的特性：</p>
<p>（1）公平选择性：支持非公平（默认）和公平的锁获取方式，吞吐量还是非公平优于公平。</p>
<p>（2）重进入：读锁和写锁都支持线程重进入。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[netty零拷贝]]></title>
        <id>https://tinaxiawuhao.github.io/post/Ts_mpMa6r/</id>
        <link href="https://tinaxiawuhao.github.io/post/Ts_mpMa6r/">
        </link>
        <updated>2021-10-13T06:11:02.000Z</updated>
        <content type="html"><![CDATA[<p>零拷贝的应用程序要求内核（kernel）直接将数据从磁盘文件拷贝到套接字（Socket），而无须通过应用程序。零拷贝不仅提高了应用程序的性能，而且减少了内核和用户模式见上下文切换。</p>
<h3 id="数据传输传统方法">数据传输：传统方法</h3>
<p>从文件中读取数据，并将数据传输到网络上的另一个程序的场景：从下图可以看出，拷贝的操作需要4次用户模式和内核模式之间的上下文切换，而且在操作完成前数据被复制了4次。(DMA：直接内存拷贝)</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1634105723930.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1634105729894.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1634107211607.png" alt="" loading="lazy"></figure>
<p>从磁盘中copy放到一个内存buf中，然后将buf通过socket传输给用户,下面是伪代码实现：</p>
<p>read(file, tmp_buf, len);<br>
write(socket, tmp_buf, len);</p>
<p>从图中可以看出文件经历了4次copy过程：</p>
<p>1.首先，调用read方法，文件从user模式拷贝到了kernel模式；（用户模式-&gt;内核模式的上下文切换，在内部发送sys_read() 从文件中读取数据，存储到一个内核地址空间缓存区中）</p>
<p>2.之后CPU控制将kernel模式数据拷贝到user模式下；（内核模式-&gt; 用户模式的上下文切换，read()调用返回，数据被存储到用户地址空间的缓存区中）</p>
<p>3.调用write时候，先将user模式下的内容copy到kernel模式下的socket的buffer中（用户模式-&gt;内核模式，数据再次被放置在内核缓存区中，send（）套接字调用）</p>
<p>4.最后将kernel模式下的socket buffer的数据copy到网卡设备中；（send套接字调用返回）</p>
<p>从图中看2，3两次copy是多余的，数据从kernel模式到user模式走了一圈，浪费了2次copy。</p>
<h3 id="数据传输mmap-优化">数据传输：mmap 优化</h3>
<p>mmap 通过内存映射，将文件映射到内核缓冲区，同时，用户空间可以共享内核空间的数据。这样，在进行网络传输时，就可以减少内核空间到用户空间的拷贝次数。如下图：</p>
<figure data-type="image" tabindex="4"><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MjM2NTUzLWM1ZWEwMGI3OGUxYjkzZmQucG5n?x-oss-process=image/format,png" alt="mmap 流程" loading="lazy"></figure>
<p>如上图，user buffer 和 kernel buffer 共享 index.html。如果你想把硬盘的 index.html 传输到网络中，再也不用拷贝到用户空间，再从用户空间拷贝到 Socket 缓冲区。</p>
<p>现在，你只需要从内核缓冲区拷贝到 Socket 缓冲区即可，这将减少一次内存拷贝（从 4 次变成了 3 次），但不减少上下文切换次数。</p>
<h3 id="数据传输零拷贝方法">数据传输：零拷贝方法</h3>
<p>从传统的场景看，会注意到上图，第2次和第3次拷贝根本就是多余的。应用程序只是起到缓存数据被将传回到套接字的作用而已，别无他用。</p>
<p>应用程序使用zero-copy来请求kernel直接把disk的数据传输到socket中，而不是通过应用程序传输。zero-copy大大提高了应用程序的性能，并且减少了kernel和user模式的上下文切换。</p>
<p>数据可以直接从read buffer 读缓存区传输到套接字缓冲区，也就是省去了将操作系统的read buffer 拷贝到程序的buffer，以及从程序buffer拷贝到socket buffer的步骤，直接将read buffer拷贝到socket buffer。JDK NIO中的的<code>transferTo()</code> 方法就能够让您实现这个操作，这个实现依赖于操作系统底层的sendFile（）实现的：</p>
<pre><code class="language-java">public void transferTo(long position, long count, WritableByteChannel target);
</code></pre>
<p>底层调用sendFile方法：</p>
<pre><code class="language-java">#include &lt;sys/socket.h&gt;
ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);
</code></pre>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1634105775492.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1634105782639.png" alt="" loading="lazy"></figure>
<p>使用了zero-copy技术后，整个过程如下：</p>
<p>1.transferTo()方法使得文件的内容直接copy到了一个read buffer（kernel buffer）中</p>
<p>2.然后数据（kernel buffer）copy到socket buffer中</p>
<p>3.最后将socket buffer中的数据copy到网卡设备（protocol engine）中传输；</p>
<p>这个显然是一个伟大的进步：这里上下文切换从4次减少到2次，同时把数据copy的次数从4次降低到3次；</p>
<p><strong>但是这是zero-copy么，答案是否定的；</strong></p>
<p>linux 2.1 内核开始引入了sendfile函数，用于将文件通过socket传输。</p>
<pre><code class="language-java">sendfile(socket, file, len);
</code></pre>
<p>该函数通过一次调用完成了文件的传输。 该函数通过一次系统调用完成了文件的传输，减少了原来read/write方式的模式切换。此外更是减少了数据的copy，sendfile的详细过程如图：</p>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1634107245108.png" alt="" loading="lazy"></figure>
<p>通过sendfile传送文件只需要一次系统调用，当调用sendfile时：</p>
<p>1.首先通过DMA将数据从磁盘读取到kernel buffer中</p>
<p>2.然后将kernel buffer数据拷贝到socket buffer中</p>
<p>3.最后将socket buffer中的数据copy到网卡设备中（protocol buffer）发送；</p>
<p>sendfile与read/write模式相比，少了一次copy。但是从上述过程中发现从kernel buffer中将数据copy到socket buffer是没有必要的；</p>
<p>Linux2.4 内核对sendfile做了改进，如图：</p>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1634107253678.png" alt="" loading="lazy"></figure>
<p>改进后的处理过程如下：</p>
<ol>
<li>将文件拷贝到kernel buffer中；(DMA引擎将文件内容copy到内核缓存区)</li>
<li>向socket buffer中追加当前要发生的数据在kernel buffer中的位置和偏移量；</li>
<li>根据socket buffer中的位置和偏移量直接将kernel buffer的数据copy到网卡设备（protocol engine）中；</li>
</ol>
<p>从图中看到，linux 2.1内核中的 “<strong>数据被copy到socket buffe</strong>r”的动作，在Linux2.4 内核做了优化，取而代之的是只包含关于数据的位置和长度的信息的描述符被追加到了socket buffer 缓冲区中。<strong>DMA引擎直接把数据从内核缓冲区传输到协议引擎</strong>（protocol engine），从而消除了最后一次CPU copy。经过上述过程，数据只经过了2次copy就从磁盘传送出去了。这个才是真正的Zero-Copy(这里的零拷贝是针对kernel来讲的，数据在kernel模式下是Zero-Copy)。</p>
<p>正是Linux2.4的内核做了改进，Java中的TransferTo()实现了Zero-Copy,如下图：</p>
<figure data-type="image" tabindex="9"><img src="https://tinaxiawuhao.github.io/post-images/1634105813030.png" alt="" loading="lazy"></figure>
<p>Zero-Copy技术的使用场景有很多，比如Kafka, 又或者是Netty等，可以大大提升程序的性能。</p>
<p>首先我们说零拷贝，是从操作系统的角度来说的。因为内核缓冲区之间，没有数据是重复的（只有 kernel buffer 有一份数据，sendFile 2.1 版本实际上有 2 份数据，算不上零拷贝）。例如我们刚开始的例子，内核缓存区和 Socket 缓冲区的数据就是重复的。</p>
<p>而零拷贝不仅仅带来更少的数据复制，还能带来其他的性能优势，例如更少的上下文切换，更少的 CPU 缓存伪共享以及无 CPU 校验和计算。</p>
<p>mmap 和 sendFile 的区别。</p>
<ol>
<li>mmap 适合小数据量读写，sendFile 适合大文件传输。</li>
<li>mmap 需要 4 次上下文切换，3 次数据拷贝；sendFile 需要 3 次上下文切换，最少 2 次数据拷贝。</li>
<li>sendFile 可以利用 DMA 方式，减少 CPU 拷贝，mmap 则不能（必须从内核拷贝到 Socket 缓冲区）。</li>
</ol>
<p>在这个选择上：rocketMQ 在消费消息时，使用了 mmap。kafka 使用了 sendFile。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[netty异步任务调度 ( TaskQueue | ScheduleTaskQueue | SocketChannel 管理 )]]></title>
        <id>https://tinaxiawuhao.github.io/post/b3vVP1a3A/</id>
        <link href="https://tinaxiawuhao.github.io/post/b3vVP1a3A/">
        </link>
        <updated>2021-10-08T03:13:12.000Z</updated>
        <content type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1633676052562.jfif" alt="" loading="lazy"></figure>
<h3 id="一-任务队列">一、 任务队列</h3>
<p>任务队列的任务 Task 应用场景 :</p>
<ol>
<li>
<p>自定义任务 : 自己开发的任务 , 然后将该任务提交到任务队列中 ;</p>
</li>
<li>
<p>自定义定时任务 : 自己开发的任务 , 然后将该任务提交到任务队列中 , 同时可以指定任务的执行时间 ;</p>
</li>
<li>
<p>其它线程调度任务 : 上面的任务都是在当前的 NioEventLoop ( 反应器 Reactor 线程 ) 中的任务队列中排队执行 , 在其它线程中也可以调度本线程的 Channel 通道与该线程对应的客户端进行数据读写 ;</p>
</li>
</ol>
<h3 id="二-处理器-handler-同步异步操作">二、 处理器 Handler 同步异步操作</h3>
<p>在之前的 Netty 服务器与客户端项目中 , 用户自定义的 Handler 处理器 , 该处理器继承了 ChannelInboundHandlerAdapter 类 , 在重写的 public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception 方法中 , 执行的业务逻辑要注意以下两点 :</p>
<p><code>同步操作</code> : 如果在该业务逻辑中只执行一个短时间的操作 , 那么可以直接执行 ;<br>
<code>异步操作</code> : 如果在该业务逻辑中执行访问数据库 , 访问网络 , 读写本地文件 , 执行一系列复杂计算等耗时操作 , 肯定不能在该方法中处理 , 这样会阻塞整个线程 ; 正确的做法是将耗时的操作放入任务队列 TaskQueue , 异步执行 ;</p>
<p>在 ChannelInboundHandlerAdapter 的 channelRead 方法执行时 , 客户端与服务器端的反应器 Reactor 线程 NioEventLoop 是处于阻塞状态的 , 此时服务器端与客户端同时都处于阻塞状态 , 这样肯定不行 , 因为 NioEventLoop 需要为多个客户端服务 , 不能因为与单一客户端交互而产生阻塞 ;</p>
<h3 id="三-异步任务-用户自定义任务">三、 异步任务 ( 用户自定义任务 )</h3>
<ol>
<li>
<p>用户自定义任务流程 :</p>
<p>① 获取通道 : 首先获取 通道 Channel ;</p>
<p>② 获取线程 : 获取通道对应的 EventLoop 线程 , 就是 NioEventLoop , 该 NioEventLoop 中封装了任务队列 TaskQueue ;</p>
<p>③ 任务入队 : 向任务队列 TaskQueue 中放入异步任务 Runnable , 调用 NioEventLoop 线程的 execute 方法 , 即可将上述 Runnable 异步任务放入任务队列 TaskQueue ;</p>
</li>
<li>
<p>多任务执行 : 如果用户连续向任务队列中放入了多个任务 , NioEventLoop 会按照顺序先后执行这些任务 , 注意任务队列中的任务 是先后执行 , 不是同时执行 ;</p>
<p>顺序执行任务 ( 不是并发 ) : 任务队列任务执行机制是顺序执行的 ; 先执行第一个 , 执行完毕后 , 从任务队列中获取第二个任务 , 执行完毕之后 , 依次从任务队列中取出任务执行 , 前一个任务执行完毕后 , 才从任务队列中取出下一个任务执行 ;</p>
</li>
<li>
<p>代码示例 : 监听到客户端上传数据后 , channelRead 回调 , 执行 获取通道 -&gt; 获取线程 -&gt; 异步任务调度 流程 ;</p>
<pre><code class="language-java">/**
 * Handler 处理者, 是 NioEventLoop 线程中处理业务逻辑的类
 *
 * 继承 : 该业务逻辑处理者 ( Handler ) 必须继承 Netty 中的 ChannelInboundHandlerAdapter 类
 * 才可以设置给 NioEventLoop 线程
 *
 * 规范 : 该 Handler 类中需要按照业务逻辑处理规范进行开发
 */
public class ServerHandr extends ChannelInboundHandlerAdapter {

    /**
     * 读取数据 : 在服务器端读取客户端发送的数据
     * @param ctx
     *      通道处理者上下文对象 : 封装了 管道 ( Pipeline ) , 通道 ( Channel ), 客户端地址信息
     *      管道 ( Pipeline ) : 注重业务逻辑处理 , 可以关联很多 Handler
     *      通道 ( Channel ) : 注重数据读写
     * @param msg
     *      客户端上传的数据
     * @throws Exception
     */
    @Override
    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
        // 1 . 从 ChannelHandlerContext ctx 中获取通道
        Channel channel = ctx.channel();
        // 2 . 获取通道对应的事件循环
        EventLoop eventLoop = channel.eventLoop();
        // 3 . 在 Runnable 中用户自定义耗时操作, 异步执行该操作, 该操作不能阻塞在此处执行
        eventLoop.execute(new Runnable() {
            @Override
            public void run() {
                //执行耗时操作
            }
        });
    }
}
</code></pre>
</li>
</ol>
<h3 id="四-异步任务-用户自定义定时任务">四、 异步任务 ( 用户自定义定时任务 )</h3>
<ol>
<li>
<p>用户自定义定时任务 与 用户自定义任务流程基本类似 , 有以下两个不同之处 :</p>
<p><em>① 调度方法 :</em></p>
<p>定时异步任务使用 schedule 方法进行调度 ;<br>
普通异步任务使用 execute 方法进行调度 ;</p>
<p><em>② 任务队列 :</em></p>
<p>定时异步任务提交到 ScheduleTaskQueue 任务队列中 ;<br>
普通异步任务提交到 TaskQueue 任务队列中 ;</p>
</li>
<li>
<p>用户自定义定时任务流程 :</p>
<p>① 获取通道 : 首先获取 通道 Channel ;</p>
<p>② 获取线程 : 获取通道对应的 EventLoop 线程 , 就是 NioEventLoop , 该 NioEventLoop 中封装了任务队列 TaskQueue ;</p>
<p>③ 任务入队 : 向任务队列 ScheduleTaskQueue 中放入异步任务 Runnable , 调用 NioEventLoop 线程的 schedule 方法 , 即可将上述 Runnable 异步任务放入任务队列 ScheduleTaskQueue ;</p>
</li>
<li>
<p>代码示例 : 监听到客户端上传数据后 , channelRead 回调 , 执行 获取通道 -&gt; 获取线程 -&gt; 异步任务调度 流程 ;</p>
<pre><code class="language-java">/**
 * Handler 处理者, 是 NioEventLoop 线程中处理业务逻辑的类
 *
 * 继承 : 该业务逻辑处理者 ( Handler ) 必须继承 Netty 中的 ChannelInboundHandlerAdapter 类
 * 才可以设置给 NioEventLoop 线程
 *
 * 规范 : 该 Handler 类中需要按照业务逻辑处理规范进行开发
 */
public class ServerHandr extends ChannelInboundHandlerAdapter {

    /**
     * 读取数据 : 在服务器端读取客户端发送的数据
     * @param ctx
     *      通道处理者上下文对象 : 封装了 管道 ( Pipeline ) , 通道 ( Channel ), 客户端地址信息
     *      管道 ( Pipeline ) : 注重业务逻辑处理 , 可以关联很多 Handler
     *      通道 ( Channel ) : 注重数据读写
     * @param msg
     *      客户端上传的数据
     * @throws Exception
     */
    @Override
    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
        // 1 . 从 ChannelHandlerContext ctx 中获取通道
        Channel channel = ctx.channel();
        // 2 . 获取通道对应的事件循环
        EventLoop eventLoop = channel.eventLoop();
        // 3 . 在 Runnable 中用户自定义耗时操作, 异步执行该操作, 该操作不能阻塞在此处执行
        // schedule(Runnable command, long delay, TimeUnit unit)
        // Runnable command 参数 : 异步任务
        // long delay 参数 : 延迟执行时间
        // TimeUnit unit参数 : 延迟时间单位, 秒, 毫秒, 分钟
        eventLoop.schedule(new Runnable() {
            @Override
            public void run() {
                //执行耗时操作
            }
        }, 100, TimeUnit.MILLISECONDS);
    }
}
</code></pre>
</li>
</ol>
<h3 id="五-异步任务-其它线程向本线程调度任务">五、 异步任务 ( 其它线程向本线程调度任务 )</h3>
<ol>
<li>
<p>通过EventExecutorGroup线程池获取不同线程执行异步耗时任务</p>
</li>
<li>
<p>代码示例（一）</p>
<pre><code class="language-java">// 服务器启动对象, 需要为该对象配置各种参数
ServerBootstrap bootstrap = new ServerBootstrap();
// 添加线程组异步执行耗时任务
final EventExecutorGroup businessGroup = new DefaultEventExecutorGroup(16);
bootstrap.group(bossGroup, workerGroup) // 设置 主从 线程组 , 分别对应 主 Reactor 和 从 Reactor
        .channel(NioServerSocketChannel.class)  // 设置 NIO 网络套接字通道类型
        .option(ChannelOption.SO_BACKLOG, 128)  // 设置线程队列维护的连接个数
        .childOption(ChannelOption.SO_KEEPALIVE, true)  // 设置连接状态行为, 保持连接状态
        .childHandler(  // 为 WorkerGroup 线程池对应的 NioEventLoop 设置对应的事件 处理器 Handler
                new ChannelInitializer&lt;SocketChannel&gt;() {// 创建通道初始化对象
                    @Override
                    protected void initChannel(SocketChannel ch) throws Exception {
                        // 该方法在服务器与客户端连接建立成功后会回调
                        // 为 管道 Pipeline 设置处理器 Hanedler
                        ch.pipeline().addLast(businessGroup,new NettyServerHandler());
                    }
                }
        );
</code></pre>
</li>
<li>
<p>代码示例（二）</p>
<pre><code class="language-java">public class NettyServerHandler extends SimpleChannelInboundHandler&lt;Object&gt; {
	final EventExecutorGroup businessGroup = new DefaultEventExecutorGroup(16);

    @Override
    protected void channelRead0(ChannelHandlerContext ctx, Object obj) throws Exception {
       businessGroup.submit(new Callable&lt;Object&gt;() {
            @Override
            public Object call() throws Exception {
                //业务处理
                return null;
            }
        });
    }
}
</code></pre>
</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[netty_nio_Reactor模式]]></title>
        <id>https://tinaxiawuhao.github.io/post/wvy4g9Zbn/</id>
        <link href="https://tinaxiawuhao.github.io/post/wvy4g9Zbn/">
        </link>
        <updated>2021-09-30T02:14:42.000Z</updated>
        <content type="html"><![CDATA[<p>Reactor有三种模式：</p>
<ol>
<li>单reactor单线程工作原理图</li>
</ol>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1636082432432.jfif" alt="" loading="lazy"></figure>
<blockquote>
<p>dispatch与handler在同一个线程中处理. redis就是采用这种模式</p>
</blockquote>
<ol>
<li>单reactor多线程工作原理图</li>
</ol>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1656503549678.png" alt="" loading="lazy"></figure>
<blockquote>
<p>（1） reactor对象通过select监控客户端请求事件，收到事件后，通过dispatch进行分发</p>
</blockquote>
<blockquote>
<p>（2）如果建立连接请求，则由Acceptor通过accept处理连接请求，然后创建一个Handler对象处理完成连接后的各种事件</p>
</blockquote>
<blockquote>
<p>（3）如果不是连接请求，则由reactor分发调用连接对应的Handler来处理</p>
</blockquote>
<blockquote>
<p>（4）Handler只负责响应事件，不做具体的业务处理， 通过read读取数据后分发给后面的work线程池中的某个线程。</p>
</blockquote>
<blockquote>
<p>（5）work线程池会分配一个独立的线程完成真正的业务 ，并将处理完的业务结果返回给Handler</p>
</blockquote>
<blockquote>
<p>（6）Handler收到响应结果后，通过send将结果返回给client</p>
</blockquote>
<p>优点：</p>
<blockquote>
<p>（1） 可以充分利用多核cpu的处理能力</p>
</blockquote>
<blockquote>
<p>（2） 多线程数据共享和访问比较复杂 ，reactor处理了所有的事件监听和响应，而且是在单线程中运行，在高并发场景容易出现性能瓶颈</p>
</blockquote>
<ol>
<li>主从reactor多线程工作原理图</li>
</ol>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1656503563223.png" alt="" loading="lazy"></figure>
<blockquote>
<p>（1）Reactor主线程MainReactor对象通过select监听连接事件，收到连接事件后，通过Acceptor处理连接事件</p>
</blockquote>
<blockquote>
<p>（2）当Acceptor处理连接事件后，MainReactor将连接分配给SubReactor,</p>
</blockquote>
<blockquote>
<p>（3）SubReactor将连接加入到连接监听队列进行监听，并创建Handler进行各种事件处理</p>
</blockquote>
<blockquote>
<p>（4）当有新的事件发生时， subreactor就会调用对应的handler处理，</p>
</blockquote>
<blockquote>
<p>（5）handler通过read读取数据后，分发给后面的worker线程处理</p>
</blockquote>
<blockquote>
<p>（6）worker线程池会分配独立的worker线程进行业务处理，并返回结果</p>
</blockquote>
<blockquote>
<p>（7）handler收到响应结果后，再通过send将结果返回给client</p>
</blockquote>
<p><img src="https://tinaxiawuhao.github.io/post-images/1632970988216.jpg" alt="" loading="lazy"><br>
<img src="https://tinaxiawuhao.github.io/post-images/1632970993792.jpg" alt="" loading="lazy"></p>
<p>实现Reactor模式我们需要实现以下几个类：</p>
<p><strong>InputSource:</strong> 外部输入类，用来表示需要reactor去处理的原始对象</p>
<p><strong>Event</strong>: reactor模式的事件类，可以理解为将输入原始对象根据不同状态包装成一个事件类，reactor模式里处理的斗士event事件对象</p>
<p><strong>EventType</strong>: 枚举类型表示事件的不同类型</p>
<p><strong>EventHandler</strong>: 处理事件的抽象类，里面包含了不同事件处理器的公共逻辑和公共对象</p>
<p><strong>AcceptEventHandler\ReadEventhandler等</strong>: 继承自EventHandler的具体事件处理器的实现类，一般根据事件不同的状态来定义不同的处理器</p>
<p><strong>Dispatcher</strong>: 事件分发器，整个reactor模式解决的主要问题就是在接收到任务后根据分发器快速进行分发给相应的事件处理器，不需要从开始状态就阻塞</p>
<p><strong>Selector</strong>: 事件轮循选择器，selector主要实现了轮循队列中的事件状态，取出当前能够处理的状态</p>
<p><strong>Acceptor</strong>:reactor的事件接收类，负责初始化selector和接收缓冲队列</p>
<p><strong>Server</strong>:负责启动reactor服务并启动相关服务接收请求</p>
<p><strong>InputSource.java</strong></p>
<pre><code class="language-java">import lombok.AllArgsConstructor;
import lombok.Data;

@Data
@AllArgsConstructor
public class InputSource {
    private final Object data;
    private final long id;
}
</code></pre>
<p><strong>Event.java</strong></p>
<pre><code class="language-java">import lombok.Getter;
import lombok.Setter;

@Getter
@Setter
public class Event {
    private InputSource source;
    private EventType type;
}
</code></pre>
<p><strong>EventType</strong></p>
<pre><code class="language-java">public enum EventType {
    ACCEPT,
    READ,
    WRITE;
}
</code></pre>
<p><strong>EventHandler.java</strong></p>
<pre><code class="language-java">@Getter
@Setter
public abstract class EventHandler {

    private InputSource source;
    public abstract void handle(Event event);
}
</code></pre>
<p><strong>AcceptEventHandler.java</strong></p>
<pre><code class="language-java">public class AcceptEventHandler extends EventHandler {
    private Selector selector;

    public AcceptEventHandler(Selector selector) {
        this.selector = selector;
    }

    @Override
    public void handle(Event event) {
        //处理Accept的event事件
        if (event.getType() == EventType.ACCEPT) {

            //TODO 处理ACCEPT状态的事件

            //将事件状态改为下一个READ状态，并放入selector的缓冲队列中
            Event readEvent = new Event();
            readEvent.setSource(event.getSource());
            readEvent.setType(EventType.READ);

            selector.addEvent(readEvent);
        }
    }
}
</code></pre>
<p><strong>Dispatcher.java</strong></p>
<pre><code class="language-java">import java.util.List;
import java.util.Map;
import java.util.concurrent.ConcurrentHashMap;

public class Dispatcher {
    //通过ConcurrentHashMap来维护不同事件处理器
    Map&lt;EventType, EventHandler&gt; eventHandlerMap = new ConcurrentHashMap&lt;EventType, EventHandler&gt;();
    //本例只维护一个selector负责事件选择，netty为了保证性能实现了多个selector来保证循环处理性能，不同事件加入不同的selector的事件缓冲队列
    Selector selector;

    Dispatcher(Selector selector) {
        this.selector = selector;
    }

    //在Dispatcher中注册eventHandler
    public void registEventHandler(EventType eventType, EventHandler eventHandler) {
        eventHandlerMap.put(eventType, eventHandler);

    }

    public void removeEventHandler(EventType eventType) {
        eventHandlerMap.remove(eventType);
    }

    public void handleEvents() {
        dispatch();
    }

    //此例只是实现了简单的事件分发给相应的处理器处理，例子中的处理器都是同步，在reactor模式的典型实现NIO中都是在handle异步处理，来保证非阻塞
    private void dispatch() {
        while (true) {
            List&lt;Event&gt; events = selector.select();

            for (Event event : events) {
                EventHandler eventHandler = eventHandlerMap.get(event.getType());
                eventHandler.handle(event);
            }
        }
    }
}
</code></pre>
<p><strong>Selector.java</strong></p>
<pre><code class="language-java">import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.BlockingQueue;
import java.util.concurrent.LinkedBlockingQueue;

public class Selector {
    //定义一个链表阻塞queue实现缓冲队列，用于保证线程安全
    private final BlockingQueue&lt;Event&gt; eventQueue = new LinkedBlockingQueue&lt;Event&gt;();
    //定义一个object用于synchronize方法块上锁
    private final Object lock = new Object();

    List&lt;Event&gt; select() {
        return select(0);
    }

    //
    List&lt;Event&gt; select(long timeout) {
        if (timeout &gt; 0) {
            if (eventQueue.isEmpty()) {
                synchronized (lock) {
                    if (eventQueue.isEmpty()) {
                        try {
                            lock.wait(timeout);
                        } catch (InterruptedException ignored) {
                        }
                    }
                }

            }
        }
        //TODO 例子中只是简单的将event列表全部返回，可以在此处增加业务逻辑，选出符合条件的event进行返回
        List&lt;Event&gt; events = new ArrayList&lt;Event&gt;();
        eventQueue.drainTo(events);
        return events;
    }

    public void addEvent(Event e) {
        //将event事件加入队列
        boolean success = eventQueue.offer(e);
        if (success) {
            synchronized (lock) {
                //如果有新增事件则对lock对象解锁
                lock.notify();
            }

        }
    }

}
</code></pre>
<p><strong>Acceptor.java</strong></p>
<pre><code class="language-java">import java.util.concurrent.BlockingQueue;
import java.util.concurrent.LinkedBlockingQueue;

public class Acceptor implements Runnable{
    private final int port; // server socket port
    private final Selector selector;

    // 代表 serversocket，通过LinkedBlockingQueue来模拟外部输入请求队列
    private final BlockingQueue&lt;InputSource&gt; sourceQueue = new LinkedBlockingQueue&lt;InputSource&gt;();

    Acceptor(Selector selector, int port) {
        this.selector = selector;
        this.port = port;
    }

    //外部有输入请求后，需要加入到请求队列中
    public void addNewConnection(InputSource source) {
        sourceQueue.offer(source);
    }

    public int getPort() {
        return this.port;
    }

    public void run() {
        while (true) {

            InputSource source = null;
            try {
                // 相当于 serversocket.accept()，接收输入请求，该例从请求队列中获取输入请求
                source = sourceQueue.take();
            } catch (InterruptedException e) {
                // ignore it;
            }

            //接收到InputSource后将接收到event设置type为ACCEPT，并将source赋值给event
            if (source != null) {
                Event acceptEvent = new Event();
                acceptEvent.setSource(source);
                acceptEvent.setType(EventType.ACCEPT);

                selector.addEvent(acceptEvent);
            }

        }
    }
}
</code></pre>
<p><strong>Server.java</strong></p>
<pre><code class="language-java">public class Server {
    Selector selector = new Selector();
    Dispatcher eventLooper = new Dispatcher(selector);
    Acceptor acceptor;

    Server(int port) {
        acceptor = new Acceptor(selector, port);
    }

    public void start() {
        eventLooper.registEventHandler(EventType.ACCEPT, new AcceptEventHandler(selector));
        new Thread(acceptor, &quot;Acceptor-&quot; + acceptor.getPort()).start();
        eventLooper.handleEvents();
    }
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[saiku自动对接kylin]]></title>
        <id>https://tinaxiawuhao.github.io/post/0wQHSTDWt/</id>
        <link href="https://tinaxiawuhao.github.io/post/0wQHSTDWt/">
        </link>
        <updated>2021-09-28T06:56:08.000Z</updated>
        <content type="html"><![CDATA[<p>saiku通过添加schema和datasource的形式管理对接入系统的数据源，然后提供界面作为直观的分析数据方式，界面产生mdx，由mondrian连接数据源，解析mdx和执行查询</p>
<p>kylin提供大规模数据的olap能力，通过saiku与kylin的对接，利用saiku的友好界面来很方面的查询</p>
<p>如上的整合，需要手动配置数据源，编写schema的操作，感觉比较繁琐，可以通过修改saiku的代码，到kylin中获取project和cube的各种信息，根据一定规则转换生成schema并作为数据源管理起来，这样就很直接将saiku与kylin无缝对接起来。</p>
<h3 id="代码案例">代码案例</h3>
<p><strong>saiku-wabapp</strong></p>
<pre><code class="language-xml">#saiku-beans.properties
sylin.user=ADMIN
sylin.password=ADMIN
sylin.cube.url=http://localhost:7070/kylin/api/cubes
sylin.cubedesc.url=http://localhost:7070/kylin/api/cube_desc
sylin.model.url=http://localhost:7070/kylin/api/model
sylin.url=localhost:7070
</code></pre>
<pre><code class="language-java">//saiku-beans.xml
 &lt;bean id=&quot;repositoryDsManager&quot; class=&quot;org.saiku.service.datasource.RepositoryDatasourceManager&quot; init-method=&quot;load&quot; destroy-method=&quot;unload&quot;&gt;
     &lt;!--aop:scoped-proxy/--&gt;
         ......
         &lt;property name=&quot;sylinUser&quot; value=&quot;${sylin.user}&quot;/&gt;
         &lt;property name=&quot;sylinPassWord&quot; value=&quot;${sylin.password}&quot;/&gt;
         &lt;property name=&quot;sylinCubeUrl&quot; value=&quot;${sylin.cube.url}&quot;/&gt;
         &lt;property name=&quot;sylinCubeDescUrl&quot; value=&quot;${sylin.cubedesc.url}&quot;/&gt;
         &lt;property name=&quot;sylinModelUrl&quot; value=&quot;${sylin.model.url}&quot;/&gt;
         &lt;property name=&quot;sylinUrl&quot; value=&quot;${sylin.url}&quot;/&gt;
 &lt;/bean&gt;
</code></pre>
<p><strong>saiku-service</strong></p>
<pre><code class="language-java">public class RepositoryDatasourceManager implements IDatasourceManager, ApplicationListener&lt;HttpSessionCreatedEvent&gt; {
	private String sylinUser;
    private String sylinPassWord;
    private String sylinCubeUrl;
    private String sylinCubeDescUrl;
    private String sylinModelUrl;
    private String sylinUrl;
    //get.set省略
    ......
    private void loadDatasources(Properties ext) {
        datasources.clear();

        List&lt;DataSource&gt; exporteddatasources = null;

        try {
            String result = execute(sylinCubeUrl);
            JSONArray ja = JSON.parseArray(result);
            for (int i = 0; i &lt; ja.size(); i++) {
                JSONObject js = JSONObject.parseObject(ja.getString(i));
                String newCubeName = js.getString(&quot;project&quot;) + &quot;#&quot; + js.getString(&quot;name&quot;);
                datasources.put(js.getString(&quot;name&quot;), getSaikuDatasource(newCubeName));
            }
        } catch (Exception e) {
            log.error(&quot;Failed add sylin cube to datasource&quot;, e);
            e.printStackTrace();
        }

       ......
    }
     private SaikuDatasource getSaikuDatasource(String datasourceName) throws Exception {
        if (datasourceName.contains(&quot;#&quot;)) {
            String cubeName = datasourceName.split(&quot;#&quot;)[1].trim();
            String cubeDescString = execute(sylinCubeDescUrl + &quot;/&quot; + cubeName);
            CubeDesc cubeDesc = OBJECT_MAPPER.readValue(JSON.parseArray(cubeDescString).getString(0), CubeDesc.class);
            //CubeDesc cubeDesc = JSONObject.parseObject(JSON.parseArray(cubeDescString).getString(0), CubeDesc.class);
            String modelName = cubeDesc.getModelName();
            String cubeModelString = execute(sylinModelUrl + &quot;/&quot; + modelName);
            DataModelDesc modelDesc = OBJECT_MAPPER.readValue(cubeModelString, DataModelDesc.class);
            //DataModelDesc modelDesc = JSONObject.parseObject(cubeModelString, DataModelDesc.class);
            if (cubeDesc != null &amp;&amp; modelDesc != null) {
                addSchema(SchemaUtil.createSchema(datasourceName, cubeDesc, modelDesc), &quot;/datasources/&quot; + datasourceName.replace(&quot;#&quot;, &quot;.&quot;) + &quot;.xml&quot;, datasourceName);
            }
            String project = new String();
            if (datasourceName.contains(&quot;#&quot;)) {
                project = datasourceName.split(&quot;#&quot;)[0].trim();
            } else {
                project = datasourceName;
            }

            Properties properties = new Properties();
            properties.put(&quot;location&quot;, &quot;jdbc:mondrian:Jdbc=jdbc:kylin://&quot; + sylinUrl + &quot;/&quot; + project + &quot;;JdbcDrivers=org.apache.kylin.jdbc.Driver&quot; + &quot;;Catalog=mondrian:///datasources/&quot; + datasourceName.replace(&quot;#&quot;, &quot;.&quot;) + &quot;.xml&quot;);
            properties.put(&quot;driver&quot;, &quot;mondrian.olap4j.MondrianOlap4jDriver&quot;);
            properties.put(&quot;username&quot;, sylinUser);
            properties.put(&quot;password&quot;, sylinPassWord);
            properties.put(&quot;security.enabled&quot;, false);
            properties.put(&quot;advanced&quot;, false);
            return new SaikuDatasource(cubeName, SaikuDatasource.Type.OLAP, properties);
        }
        return null;
    }

    private String execute(String url) throws URISyntaxException, IOException {
        int httpConnectionTimeoutMs = 30000;
        int httpSocketTimeoutMs = 120000;
        final HttpParams httpParams = new BasicHttpParams();
        final PoolingClientConnectionManager cm = new PoolingClientConnectionManager();
        HttpConnectionParams.setSoTimeout(httpParams, httpSocketTimeoutMs);
        HttpConnectionParams.setConnectionTimeout(httpParams, httpConnectionTimeoutMs);
        cm.setDefaultMaxPerRoute(20);
        cm.setMaxTotal(200);
        HttpGet get = newGet(url);
        get.setURI(new URI(url));
        DefaultHttpClient client = new DefaultHttpClient(cm, httpParams);
        if (sylinUser != null &amp;&amp; sylinPassWord != null) {
            CredentialsProvider provider = new BasicCredentialsProvider();
            UsernamePasswordCredentials credentials = new UsernamePasswordCredentials(sylinUser, sylinPassWord);
            provider.setCredentials(AuthScope.ANY, credentials);
            client.setCredentialsProvider(provider);
        }
        HttpResponse response = client.execute(get);
        if (response.getStatusLine().getStatusCode() != 200) {
            throw new IOException(&quot;Invalid response &quot; + response.getStatusLine().getStatusCode());
        }

        String result = getContent(response);
        return result;
    }

    private HttpGet newGet(String url) {
        HttpGet get = new HttpGet();
        addHttpHeaders(get);
        return get;
    }

    private void addHttpHeaders(HttpRequestBase method) {
        method.addHeader(&quot;Accept&quot;, &quot;application/json, text/plain, */*&quot;);
        method.addHeader(&quot;Content-Type&quot;, &quot;application/json&quot;);
        String basicAuth = DatatypeConverter
                .printBase64Binary((sylinUser + &quot;:&quot; + sylinPassWord).getBytes(StandardCharsets.UTF_8));
        method.addHeader(&quot;Authorization&quot;, &quot;Basic &quot; + basicAuth);
    }

    private String getContent(HttpResponse response) throws IOException {
        InputStreamReader reader = null;
        BufferedReader rd = null;
        StringBuffer result = new StringBuffer();
        try {
            reader = new InputStreamReader(response.getEntity().getContent(), StandardCharsets.UTF_8);
            rd = new BufferedReader(reader);
            String line = null;
            while ((line = rd.readLine()) != null) {
                result.append(line);
            }
        } finally {
            IOUtils.closeQuietly(reader);
            IOUtils.closeQuietly(rd);
        }
        return result.toString();
    }
}
</code></pre>
<p><strong>mondrian3.0语法工具类</strong></p>
<pre><code class="language-java">package org.saiku.service.util;

import org.apache.kylin.cube.model.CubeDesc;
import org.apache.kylin.cube.model.DimensionDesc;
import org.apache.kylin.metadata.model.*;

import java.util.*;

public class SchemaUtil1 {
    private static String newLine = &quot;\r\n&quot;;
    private static Set&lt;String&gt; aggSet = new HashSet&lt;String&gt;(){
        {
            add(&quot;sum&quot;);
            add(&quot;min&quot;);
            add(&quot;max&quot;);
            add(&quot;count&quot;);
            add(&quot;count_distinct&quot;);
        }

    };


    public static String createSchema(String dataSourceName, CubeDesc cubeDesc, DataModelDesc modelDesc) {
        StringBuffer sb = new StringBuffer();
        sb = appendSchema(sb, dataSourceName, cubeDesc, modelDesc);
        return sb.toString();
    }

    public static StringBuffer appendSchema(StringBuffer sb, String dataSourceName, CubeDesc cubeDesc, DataModelDesc modelDesc) {
        sb.append(&quot;&lt;?xml version='1.0'?&gt;&quot;).append(newLine)
                .append(&quot;&lt;Schema name='&quot; + dataSourceName.split(&quot;#&quot;)[0].trim()+&quot;'&gt;&quot;)
                .append(newLine);
        sb = appendCube(sb, dataSourceName, cubeDesc, modelDesc);
        sb.append(&quot;&lt;/Schema&gt;&quot;).append(newLine);
        return sb;
    }

    public static StringBuffer appendCube(StringBuffer sb, String cubeName, CubeDesc cubeDesc, DataModelDesc modelDesc) {
        sb.append(&quot;&lt;Cube name='&quot; + cubeName.split(&quot;#&quot;)[1] + &quot;'&gt;&quot;).append(newLine);
        sb.append(&quot;&lt;Table name='&quot;+dealTableName(modelDesc.getRootFactTableName())+&quot;'/&gt;&quot;).append(newLine);
        HashMap&lt;String,String&gt; aliasTableMap = new HashMap&lt;String,String&gt;();
        HashMap&lt;String,String&gt; aliasTableJoinMap = new HashMap&lt;String,String&gt;();
        aliasTableMap.put(dealTableName(modelDesc.getRootFactTableName()),dealTableName(modelDesc.getRootFactTableName()));
        for(JoinTableDesc joinTableDesc:modelDesc.getJoinTables()) {
            aliasTableMap.put(joinTableDesc.getAlias(),dealTableName(joinTableDesc.getTable()));
            if(joinTableDesc.getJoin().getPrimaryKey().length == 1){
                aliasTableJoinMap.put(dealTableName(joinTableDesc.getAlias()),joinTableDesc.getJoin().getPrimaryKey()[0].concat(&quot;#&quot;).concat(joinTableDesc.getJoin().getForeignKey()[0]));
            }
        }

        for(DimensionDesc dimensionDesc: cubeDesc.getDimensions()){
            // tableSet.add(dealTableName(dimensionDesc.getTable()));
            if(aliasTableMap.get(dealTableName(dimensionDesc.getTable())).equals(dealTableName(modelDesc.getRootFactTableName()))){
                sb.append(&quot;&lt;Dimension name='&quot;+dimensionDesc.getName()+&quot;'&gt;&quot;).append(newLine);
                sb.append(&quot;&lt;Hierarchy name='&quot;+dimensionDesc.getName()+&quot;' hasAll='true' allMemberName='All &quot;+dimensionDesc.getName()+&quot;'&gt;&quot;).append(newLine);

            }else if(aliasTableJoinMap.get(dealTableName(dimensionDesc.getTable()))==null){
                continue;
            } else if(aliasTableJoinMap.get(dealTableName(dimensionDesc.getTable()))!=null &amp;&amp; aliasTableJoinMap.get(dealTableName(dimensionDesc.getTable())).split(&quot;#&quot;)[1].split(&quot;\\.&quot;)[0]
                    .equals(dealTableName(modelDesc.getRootFactTableName()))){
                sb.append(&quot;&lt;Dimension name='&quot;+dimensionDesc.getName()+&quot;' foreignKey='&quot;+aliasTableJoinMap.get(dealTableName(dimensionDesc.getTable()))
                        .split(&quot;#&quot;)[1].split(&quot;\\.&quot;)[1]+&quot;'&gt;&quot;).append(newLine);

                sb.append(&quot;&lt;Hierarchy name='&quot;+dimensionDesc.getName()+&quot;' hasAll='true' allMemberName='All &quot;+dimensionDesc.getName()+&quot;' primaryKey='&quot;+
                        aliasTableJoinMap.get(dealTableName(dimensionDesc.getTable())).split(&quot;#&quot;)[0].split(&quot;\\.&quot;)[1]+&quot;'&gt;&quot;).append(newLine);

                sb.append(&quot;&lt;Table name='&quot;+aliasTableMap.get(dealTableName(dimensionDesc.getTable()))+&quot;'/&gt;&quot;).append(newLine);

            } else if(aliasTableJoinMap.get(aliasTableJoinMap.get(dealTableName(dimensionDesc.getTable())).split(&quot;#&quot;)[1].split(&quot;\\.&quot;)[0])
                    .split(&quot;#&quot;)[1].split(&quot;\\.&quot;)[0].equals(dealTableName(modelDesc.getRootFactTableName()))){
                sb.append(&quot;&lt;Dimension name='&quot;+dimensionDesc.getName()+&quot;' foreignKey='&quot;+aliasTableJoinMap.get(aliasTableJoinMap.get(dealTableName(dimensionDesc.getTable()))
                        .split(&quot;#&quot;)[1].split(&quot;\\.&quot;)[0]).split(&quot;#&quot;)[1].split(&quot;\\.&quot;)[1]+&quot;'&gt;&quot;).append(newLine);

                sb.append(&quot;&lt;Hierarchy name='&quot;+dimensionDesc.getName()+&quot;' hasAll='true' allMemberName='All &quot;+dimensionDesc.getName()+&quot;' primaryKey='&quot;+
                        aliasTableJoinMap.get(aliasTableJoinMap.get(dealTableName(dimensionDesc.getTable())).split(&quot;#&quot;)[1].split(&quot;\\.&quot;)[0])
                                .split(&quot;#&quot;)[0].split(&quot;\\.&quot;)[1]+&quot;' primaryKeyTable='&quot;+aliasTableMap.get(aliasTableJoinMap.get(dealTableName(dimensionDesc.getTable()))
                        .split(&quot;#&quot;)[1].split(&quot;\\.&quot;)[0])+&quot;'&gt;&quot;).append(newLine);

                sb.append(&quot;&lt;Join leftKey='&quot;+aliasTableJoinMap.get(dealTableName(dimensionDesc.getTable())).split(&quot;#&quot;)[1].split(&quot;\\.&quot;)[1]+&quot;' rightAlias='&quot;+aliasTableMap.get(dimensionDesc.getTable())+
                        &quot;' rightKey='&quot;+aliasTableJoinMap.get(dealTableName(dimensionDesc.getTable())).split(&quot;#&quot;)[0].split(&quot;\\.&quot;)[1]+&quot;'&gt;&quot;).append(newLine);

                sb.append(&quot;&lt;Table name='&quot;+aliasTableMap.get(aliasTableJoinMap.get(dealTableName(dimensionDesc.getTable())).split(&quot;#&quot;)[1].split(&quot;\\.&quot;)[0])+&quot;'/&gt;&quot;).append(newLine);
                sb.append(&quot;&lt;Table name='&quot;+aliasTableMap.get(dimensionDesc.getTable())+&quot;'/&gt;&quot;).append(newLine);
                sb.append(&quot;&lt;/Join&gt;&quot;).append(newLine);
            } else {
                continue;
            }
            Set&lt;String&gt; columns = getColumns(dimensionDesc);
            for(String column:columns){
                sb.append(&quot;&lt;Level name='&quot;+column+&quot;' column='&quot;+column+&quot;' table='&quot;+aliasTableMap.get(dimensionDesc.getTable())+&quot;'/&gt;&quot;).append(newLine);
            }
            sb.append(&quot;&lt;/Hierarchy&gt;&quot;).append(newLine);
            sb.append(&quot;&lt;/Dimension&gt;&quot;).append(newLine);
        }
        for (MeasureDesc measureDesc : cubeDesc.getMeasures()) {
            int i=0;
            String table = measureDesc.getFunction().getParameter().getValue().split(&quot;\\.&quot;)[0];
            final boolean flag = Arrays.stream(modelDesc.getJoinTables()).anyMatch(item -&gt; table.equals(dealTableName(item.getTable())));
            if(table.equals(dealTableName(modelDesc.getRootFactTableName()))||flag||table.equals(&quot;1&quot;)){
                addMeasure(sb,measureDesc,getColumn(cubeDesc,modelDesc,dealTableName(modelDesc.getRootFactTableName())));
            }
        }

        sb.append(&quot;&lt;/Cube&gt;&quot;).append(newLine);
        return sb;
    }



    public static String dealTableName(String tableName){
        if(tableName.contains(&quot;.&quot;))
            return tableName.split(&quot;\\.&quot;)[1];
        else
            return tableName;
    }

    public static StringBuffer addMeasure(StringBuffer sb, MeasureDesc measureDesc, String defaultColumn) {
        FunctionDesc funtionDesc = measureDesc.getFunction();
        String aggregator = funtionDesc.getExpression().trim().toLowerCase();
        if(aggSet.contains(aggregator.toLowerCase())){
            //mondrian only have distinct-count
            if(aggregator.equals(&quot;count_distinct&quot;)){
                aggregator = &quot;distinct-count&quot;;
            }
            if(funtionDesc.getParameter().getValue().equals(&quot;1&quot;)) {
                sb.append(&quot;&lt;Measure aggregator='&quot; + aggregator + &quot;' column='&quot; + defaultColumn + &quot;' name='&quot; + measureDesc.getName() + &quot;' visible='true'/&gt;&quot;)
                        .append(newLine);
            }
            else
                sb.append(&quot;&lt;Measure aggregator='&quot; + aggregator + &quot;' column='&quot; + funtionDesc.getParameter().getValue().split(&quot;\\.&quot;)[1] + &quot;' name='&quot; + measureDesc.getName() + &quot;' visible='true'/&gt;&quot;)
                        .append(newLine);
            return sb;
        }
        return sb;
    }

    public static String getColumn(CubeDesc cubeDesc,DataModelDesc dataModelDesc,String tableName){
        List&lt;MeasureDesc&gt; measureDescList = cubeDesc.getMeasures();
        for(MeasureDesc measureDesc:measureDescList){
            if(measureDesc.getFunction().getParameter().getValue().split(&quot;\\.&quot;)[0].equals(tableName)){
                return measureDesc.getFunction().getParameter().getValue().split(&quot;\\.&quot;)[1];
            }
        }
        if(dataModelDesc.getMetrics().length&gt;0){
            return dataModelDesc.getMetrics()[0];
        }

        for(ModelDimensionDesc modelDimensionDesc:dataModelDesc.getDimensions()){
            if(modelDimensionDesc.getTable().equals(tableName)){
                return modelDimensionDesc.getColumns()[0];
            }
        }
        return null;
    }

    public static Set&lt;String&gt; getColumns(DimensionDesc dimensionDesc){
        Set&lt;String&gt; columns = new HashSet&lt;String&gt;();
        if (dimensionDesc.getColumn() != null || dimensionDesc.getDerived() != null) {
            if(dimensionDesc.getColumn() != null) {
                columns.add(dimensionDesc.getColumn());
            }
            if (dimensionDesc.getDerived() != null) {
                for (String derived : dimensionDesc.getDerived()) {
                    columns.add(derived);
                }
            }
        } else {
            columns.add(dimensionDesc.getName());
        }
        return columns;
    }
}
</code></pre>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;Schema name=&quot;Mondrian&quot;&gt;  &lt;!--模型定义--&gt;
&lt;Cube name=&quot;Person&quot;&gt;     &lt;!--立方体 ，一个立方体有多个维度--&gt;
    &lt;Table name=&quot;PERSON&quot; /&gt;  &lt;!--立方体对应的表 --&gt;
     &lt;Dimension name=&quot;部门&quot; foreignKey=&quot;USERID&quot; &gt; &lt;!--定义维度 --&gt;
        &lt;Hierarchy  hasAll=&quot;true&quot; primaryKey=&quot;USERID&quot; allMemberName=&quot;所有部门&quot; &gt; &lt;!--定义维度下面的层次，层次包含很多层 --&gt;
          &lt;Table name=&quot;PERSON&quot; alias=&quot;a&quot;/&gt;                                   &lt;!--定义维度获取数据的来源-表 --&gt;
        &lt;Level name=&quot;部门&quot; column=&quot;DEPARTMENT&quot; uniqueMembers=&quot;true&quot; /&gt; &lt;!--定义层次的层，每个层对应数据库中对应的字段 --&gt;
        &lt;Level name=&quot;姓名&quot; column=&quot;USERNAME&quot; uniqueMembers=&quot;true&quot; /&gt;           
        &lt;/Hierarchy&gt;
    &lt;/Dimension&gt;     
    &lt;Dimension name=&quot;性别&quot;  foreignKey=&quot;USERID&quot; &gt;
        &lt;Hierarchy hasAll=&quot;true&quot; primaryKey=&quot;USERID&quot; allMemberName=&quot;所有性别&quot;&gt;         
            &lt;Table name=&quot;PERSON&quot; alias=&quot;b&quot; /&gt;
        &lt;Level name=&quot;性别&quot; column=&quot;SEX&quot;   uniqueMembers=&quot;true&quot; /&gt;
        &lt;/Hierarchy&gt;
    &lt;/Dimension&gt;
    &lt;Dimension name=&quot;专业技术资格类别&quot;  foreignKey=&quot;USERID&quot; &gt;
        &lt;Hierarchy hasAll=&quot;true&quot; primaryKey=&quot;USERID&quot; allMemberName=&quot;所有专业技术资格类别&quot;&gt;         
            &lt;Table name=&quot;PERSON&quot; alias=&quot;c&quot; /&gt;
        &lt;Level name=&quot;资格类别&quot; column=&quot;ZYJSLB&quot;   uniqueMembers=&quot;true&quot; /&gt;
        &lt;/Hierarchy&gt;
    &lt;/Dimension&gt;
    &lt;Dimension name=&quot;专业技术资格等级&quot;  foreignKey=&quot;USERID&quot; &gt;
        &lt;Hierarchy hasAll=&quot;true&quot; primaryKey=&quot;USERID&quot; allMemberName=&quot;所有专业技术资格等级&quot;&gt;         
            &lt;Table name=&quot;PERSON&quot; alias=&quot;d&quot; /&gt;
        &lt;Level name=&quot;资格等级&quot; column=&quot;ZYJSDJ&quot;   uniqueMembers=&quot;true&quot; /&gt;
        &lt;/Hierarchy&gt;
    &lt;/Dimension&gt;
     &lt;Dimension name=&quot;职系&quot;  foreignKey=&quot;USERID&quot; &gt;
        &lt;Hierarchy hasAll=&quot;true&quot; primaryKey=&quot;USERID&quot; allMemberName=&quot;所有职系&quot;&gt;         
            &lt;Table name=&quot;PERSON&quot; alias=&quot;e&quot; /&gt;
        &lt;Level name=&quot;职系&quot; column=&quot;ZHIXI&quot;   uniqueMembers=&quot;true&quot; /&gt;
        &lt;/Hierarchy&gt;
    &lt;/Dimension&gt;
    &lt;Dimension name=&quot;民族&quot;  foreignKey=&quot;USERID&quot; &gt;
        &lt;Hierarchy hasAll=&quot;true&quot; primaryKey=&quot;USERID&quot; allMemberName=&quot;所有民族&quot;&gt;         
            &lt;Table name=&quot;PERSON&quot; alias=&quot;f&quot; /&gt;
        &lt;Level name=&quot;民族&quot; column=&quot;NATIONALITY&quot;   uniqueMembers=&quot;true&quot; /&gt;
        &lt;/Hierarchy&gt;
    &lt;/Dimension&gt;
    &lt;Dimension name=&quot;学历&quot;  foreignKey=&quot;USERID&quot; &gt;
        &lt;Hierarchy hasAll=&quot;true&quot; primaryKey=&quot;USERID&quot; allMemberName=&quot;所有学历&quot;&gt;         
            &lt;Table name=&quot;PERSON&quot; alias=&quot;g&quot; /&gt;
        &lt;Level name=&quot;学历&quot; column=&quot;XUELI&quot;   uniqueMembers=&quot;true&quot; /&gt;
        &lt;/Hierarchy&gt;
    &lt;/Dimension&gt;       
    &lt;Measure name=&quot;人数&quot; column=&quot;USERID&quot; aggregator=&quot;distinct count&quot; /&gt;       &lt;!--指标/度量，采用distinct count聚合 --&gt;
    &lt;/Cube&gt;
&lt;/Schema&gt;
</code></pre>
<p><strong>mondrian4.0语法工具类</strong></p>
<pre><code class="language-java">package org.saiku.service.util;

import org.apache.kylin.cube.model.CubeDesc;
import org.apache.kylin.cube.model.DimensionDesc;
import org.apache.kylin.cube.model.RowKeyDesc;
import org.apache.kylin.metadata.model.*;

import java.util.*;

public class SchemaUtil {
    private static final String newLine = &quot;\r\n&quot;;
    private static Map&lt;String, String&gt; map;

    public static String createSchema(String dataSourceName, CubeDesc cubeDesc, DataModelDesc modelDesc) {
        StringBuffer sb = new StringBuffer();
        sb = appendSchema(sb, dataSourceName, cubeDesc, modelDesc);
//        System.out.println(&quot;********************************&quot; + sb.toString());
        return sb.toString();
    }

    public static StringBuffer appendSchema(StringBuffer sb, String dataSourceName, CubeDesc cubeDesc, DataModelDesc modelDesc) {
        sb.append(&quot;&lt;?xml version='1.0'?&gt;&quot;).append(newLine)
                .append(&quot;&lt;Schema name='&quot;).append(dataSourceName.split(&quot;#&quot;)[0].trim()).append(&quot;' metamodelVersion='4.0'&gt;&quot;)
//                .append(&quot;&lt;Schema name='&quot; + dataSourceName + &quot;' metamodelVersion='4.0'&gt;&quot;)
                .append(newLine);
        appendTable(sb, modelDesc);
        appendDimension(sb, modelDesc);
        appendCube(sb, dataSourceName, cubeDesc, modelDesc);
        sb.append(&quot;&lt;/Schema&gt;&quot;).append(newLine);
        return sb;
    }

    public static StringBuffer appendTable(StringBuffer sb, DataModelDesc modelDesc) {
        StringBuilder linkSb = new StringBuilder();
        //获取所有关系表
        final List&lt;ModelDimensionDesc&gt; tables = modelDesc.getDimensions();
        sb.append(&quot;&lt;PhysicalSchema&gt;&quot;).append(newLine);
        //添加表关联关系
        final JoinTableDesc[] joinTables = modelDesc.getJoinTables();
        for (JoinTableDesc joinTableDesc : joinTables) {
            String factTablename = dealModelTableName(joinTableDesc.getJoin().getForeignKey()[0]);
            String Column = dealTableName(joinTableDesc.getJoin().getForeignKey()[0]);
            String joinTablename = dealModelTableName(joinTableDesc.getJoin().getPrimaryKey()[0]);
            String joinColumn = dealTableName(joinTableDesc.getJoin().getPrimaryKey()[0]);
            linkSb.append(&quot;&lt;Link source='&quot;).append(factTablename).append(&quot;' target='&quot;).append(joinTablename).append(&quot;'&gt;&quot;).append(newLine)
                    .append(&quot;&lt;ForeignKey&gt;&quot;).append(newLine)
                    .append(&quot;&lt;Column name='&quot;).append(Column).append(&quot;'/&gt;&quot;).append(newLine)
                    .append(&quot;&lt;/ForeignKey&gt;&quot;).append(newLine)
                    .append(&quot;&lt;/Link&gt;&quot;).append(newLine);
            //清空map
            map = new HashMap&lt;&gt;();
            tables.forEach(item -&gt; {
                if (item.getTable().equals(factTablename)) {
                    map.put(factTablename, Column);
                }
                if (item.getTable().equals(joinTablename)) {
                    map.put(joinTablename, joinColumn);
                }
            });
        }
        //添加表
        for (String tableName : map.keySet()) {
            sb.append(&quot;&lt;Table name='&quot;).append(tableName).append(&quot;'&gt;&quot;).append(newLine)
                    .append(&quot;&lt;Key&gt;&quot;).append(newLine).append(&quot;&lt;Column name='&quot;).append(map.get(tableName)).append(&quot;'/&gt;&quot;).append(newLine)
                    .append(&quot;&lt;/Key&gt;&quot;).append(newLine)
                    .append(&quot;&lt;/Table&gt;&quot;).append(newLine);
        }

        sb.append(linkSb);
        linkSb.delete(0, linkSb.length());
        sb.append(&quot;&lt;/PhysicalSchema&gt;&quot;).append(newLine);
        return sb;
    }

    public static Map&lt;String, JoinDesc&gt; getJoinDesc(DataModelDesc modelDesc) {
        Map&lt;String, JoinDesc&gt; joinDescMap = new HashMap&lt;String, JoinDesc&gt;();
        for (JoinTableDesc lookupDesc : modelDesc.getJoinTables()) {
            if (!joinDescMap.containsKey(dealTableName(lookupDesc.getTable())))
                joinDescMap.put(dealTableName(lookupDesc.getTable()), lookupDesc.getJoin());
        }
        return joinDescMap;
    }

    public static void appendDimension(StringBuffer sb, DataModelDesc modelDesc) {
        StringBuilder hierSb = new StringBuilder();
        for (ModelDimensionDesc dimensionDesc : modelDesc.getDimensions()) {
            sb.append(&quot;&lt;Dimension name='&quot;).append(dimensionDesc.getTable()).append(&quot;' key='&quot;).append(map.get(dimensionDesc.getTable())).append(&quot;' table='&quot;).append(dimensionDesc.getTable()).append(&quot;'&gt;&quot;).append(newLine);
            sb.append(&quot;&lt;Attributes&gt;&quot;).append(newLine);
            hierSb.append(&quot;&lt;Hierarchies&gt;&quot;).append(newLine);
            hierSb.append(&quot;&lt;Hierarchy  name='&quot;).append(dimensionDesc.getTable()).append(&quot;' hasAll='true'&gt;&quot;).append(newLine);
            for (String column : dimensionDesc.getColumns()) {
                // add Attributes to stringbuffer
                addAttribute(sb, column);
                addHierarchy(hierSb, column);
            }
            sb.append(&quot;&lt;/Attributes&gt;&quot;).append(newLine);
            hierSb.append(&quot;&lt;/Hierarchy&gt;&quot;).append(newLine);
            hierSb.append(&quot;&lt;/Hierarchies&gt;&quot;).append(newLine);
            sb.append(hierSb);
            hierSb.delete(0, hierSb.length());
            sb.append(&quot;&lt;/Dimension&gt;&quot;).append(newLine);
        }
    }

    public static Set&lt;String&gt; getColumns(DimensionDesc dimensionDesc) {
        Set&lt;String&gt; columns = new HashSet&lt;String&gt;();
        if (dimensionDesc.getColumn() != null || dimensionDesc.getDerived() != null) {
            if (dimensionDesc.getColumn() != null) {
//                for (String column : dimensionDesc.getColumn()) {
                columns.add(dimensionDesc.getColumn());
//                }
            }
            if (dimensionDesc.getDerived() != null) {
                columns.addAll(Arrays.asList(dimensionDesc.getDerived()));
            }
        } else {
            columns.add(dimensionDesc.getName());
        }
        return columns;
    }

    public static StringBuffer addAttribute(StringBuffer sb, String attr) {
        sb.append(&quot;&lt;Attribute name='&quot;).append(attr).append(&quot;' keyColumn='&quot;).append(attr).append(&quot;' hasHierarchy='false'/&gt;&quot;).append(newLine);
        return sb;
    }

    public static void addHierarchy(StringBuilder sb, String attr) {
        sb.append(&quot;&lt;Level attribute='&quot;).append(attr).append(&quot;'/&gt;&quot;).append(newLine);
    }


    public static String dealTableName(String tableName) {
        if (tableName.contains(&quot;.&quot;))
            return tableName.split(&quot;\\.&quot;)[1];
        else
            return tableName;
    }

    public static String dealModelTableName(String tableName) {
        if (tableName.contains(&quot;.&quot;))
            return tableName.split(&quot;\\.&quot;)[0];
        else
            return tableName;
    }

    public static StringBuffer appendCube(StringBuffer sb, String cubeName, CubeDesc cubeDesc, DataModelDesc modelDesc) {
        sb.append(&quot;&lt;Cube name='&quot;).append(cubeName.split(&quot;#&quot;)[1].trim()).append(&quot;'&gt;&quot;).append(newLine);
        addCubeDimension(sb, modelDesc.getDimensions());
        sb.append(&quot;&lt;MeasureGroups&gt;&quot;).append(newLine);

        Map&lt;String, Map&lt;String, MeasureDesc&gt;&gt; allMap = new HashMap();

        MeasureDesc one = new MeasureDesc();
        for (MeasureDesc measureDesc : cubeDesc.getMeasures()) {
            final String tableName = dealModelTableName(measureDesc.getFunction().getParameter().getValue());
            final String columnName = dealTableName(measureDesc.getFunction().getParameter().getValue());
            if (&quot;1&quot;.equals(tableName)) {
                one = measureDesc;
            } else {
                if (Objects.isNull(allMap.get(tableName))) {
                    Map&lt;String, MeasureDesc&gt; map = new HashMap();
                    if (Objects.nonNull(one)) {
                        map.put(columnName, one);
                        one = null;
                    }
                    map.put(columnName, measureDesc);
                    allMap.put(tableName, map);
                } else {
                    allMap.get(tableName).put(columnName, measureDesc);
                }
            }
        }

        allMap.forEach((tableName, value) -&gt; {
            sb.append(&quot;&lt;MeasureGroup table='&quot;).append(dealTableName(tableName)).append(&quot;'&gt;&quot;).append(newLine);
            addDimensionLink(sb, modelDesc);
            sb.append(&quot;&lt;Measures&gt;&quot;).append(newLine);
            value.forEach((columnName, measureDesc) -&gt; {
                addMeasure(sb, measureDesc, getColumn(cubeDesc));
            });
            sb.append(&quot;&lt;/Measures&gt;&quot;).append(newLine);
            sb.append(&quot;&lt;/MeasureGroup&gt;&quot;).append(newLine);
        });
        sb.append(&quot;&lt;/MeasureGroups&gt;&quot;).append(newLine);
        sb.append(&quot;&lt;/Cube&gt;&quot;).append(newLine);
        return sb;
    }

    public static void addCubeDimension(StringBuffer sb, List&lt;ModelDimensionDesc&gt; dimensionDescs) {
        sb.append(&quot;&lt;Dimensions&gt;&quot;).append(newLine);
        for (ModelDimensionDesc dimensionDesc : dimensionDescs) {
            sb.append(&quot;&lt;Dimension source='&quot;).append(dimensionDesc.getTable()).append(&quot;' visible='true'/&gt;&quot;).append(newLine);
        }
        sb.append(&quot;&lt;/Dimensions&gt;&quot;).append(newLine);
    }

    public static void addDimensionLink(StringBuffer sb, DataModelDesc modelDesc) {
        sb.append(&quot;&lt;DimensionLinks&gt;&quot;).append(newLine);
        for(ModelDimensionDesc dimensionDesc : modelDesc.getDimensions()) {
            if(dimensionDesc.getTable().contains(dealTableName(modelDesc.getRootFactTableName()))) {
                sb.append(&quot;&lt;FactLink dimension='&quot;).append(dimensionDesc.getTable()).append(&quot;'/&gt;&quot;).append(newLine);
            }else{
                sb.append(&quot;&lt;ForeignKeyLink dimension='&quot;).append(dimensionDesc.getTable()).append(&quot;' foreignKeyColumn='&quot;).append(map.get(dimensionDesc.getTable())).append(&quot;'/&gt;&quot;).append(newLine);
            }
        }
        sb.append(&quot; &lt;/DimensionLinks&gt;&quot;).append(newLine);
    }

    public static StringBuffer addMeasure(StringBuffer sb, MeasureDesc measureDesc, String defaultColumn) {
        FunctionDesc funtionDesc = measureDesc.getFunction();
        String aggregator = funtionDesc.getExpression().trim().toLowerCase();
        //mondrian only have distinct-count
        if (aggregator.equals(&quot;count_distinct&quot;)) {
            aggregator = &quot;distinct-count&quot;;
        }
        if (funtionDesc.getParameter().getValue().equals(&quot;1&quot;)) {
            sb.append(&quot;&lt;Measure aggregator='&quot;).append(aggregator).append(&quot;' column='&quot;).append(dealTableName(defaultColumn)).append(&quot;' name='&quot;).append(measureDesc.getName()).append(&quot;' visible='true'/&gt;&quot;)
                    .append(newLine);
        } else
            sb.append(&quot;&lt;Measure aggregator='&quot;).append(aggregator).append(&quot;' column='&quot;).append(dealTableName(funtionDesc.getParameter().getValue())).append(&quot;' name='&quot;).append(measureDesc.getName()).append(&quot;' visible='true'/&gt;&quot;)
                    .append(newLine);
        return sb;
    }

    public static Set&lt;String&gt; getTables(List&lt;DimensionDesc&gt; dimensionDescList) {
        Set&lt;String&gt; tables = new HashSet&lt;String&gt;();
        for (DimensionDesc dimensionDesc : dimensionDescList) {
            String table = dealTableName(dimensionDesc.getTable());
            tables.add(table);
        }
        return tables;
    }

    public static String getColumn(CubeDesc cubeDesc) {
        RowKeyDesc rowKey = cubeDesc.getRowkey();
        return rowKey.getRowKeyColumns()[0].getColumn();
    }
}
</code></pre>
<pre><code class="language-xml">&lt;?xml version='1.0'?&gt;
&lt;Schema name='xiaowei' metamodelVersion='4.0'&gt;
&lt;PhysicalSchema&gt;
	&lt;Table name='TBL_FARM_INCOME_STATICS'&gt;
		&lt;Key&gt;
			&lt;Column name='COMPANY_ID'/&gt;
		&lt;/Key&gt;
	&lt;/Table&gt;
	&lt;Table name='TBL_CUSTOMER'&gt;
		&lt;Key&gt;
			&lt;Column name='COMPANY_ID'/&gt;
		&lt;/Key&gt;
	&lt;/Table&gt;
	&lt;Link source='TBL_FARM_INCOME_STATICS' target='TBL_CUSTOMER'&gt;
		&lt;ForeignKey&gt;
			&lt;Column name='COMPANY_ID'/&gt;
		&lt;/ForeignKey&gt;
	&lt;/Link&gt;
&lt;/PhysicalSchema&gt;
&lt;Dimension name='TBL_FARM_INCOME_STATICS' table='TBL_FARM_INCOME_STATICS' key='COMPANY_ID'&gt;
	&lt;Attributes&gt;
		&lt;Attribute name='COMPANY_ID' keyColumn='COMPANY_ID' hasHierarchy='false'/&gt;
		&lt;Attribute name='INCOME_DATE' keyColumn='INCOME_DATE' hasHierarchy='false'/&gt;
	&lt;/Attributes&gt;

	&lt;Hierarchies&gt;
		&lt;Hierarchy name='TBL_FARM_INCOME_STATICS' allMemberName='All Warehouses'&gt;
			&lt;Level attribute='COMPANY_ID'/&gt;
			&lt;Level attribute='INCOME_DATE'/&gt;
		&lt;/Hierarchy&gt;
	&lt;/Hierarchies&gt;
&lt;/Dimension&gt;

&lt;Dimension name='TBL_CUSTOMER' table='TBL_CUSTOMER' key='COMPANY_ID'&gt;
	&lt;Attributes&gt;
		&lt;Attribute name='COMPANY_ID' keyColumn='COMPANY_ID' hasHierarchy='false'/&gt;
		&lt;Attribute name='CUSTOMER_TYPE' keyColumn='CUSTOMER_TYPE' hasHierarchy='false'/&gt;
		&lt;Attribute name='PHONE' keyColumn='PHONE' hasHierarchy='false'/&gt;
	&lt;/Attributes&gt;

	&lt;Hierarchies&gt;
		&lt;Hierarchy name='TBL_CUSTOMER' allMemberName='All Warehouses'&gt;
			&lt;Level attribute='COMPANY_ID'/&gt;
			&lt;Level attribute='CUSTOMER_TYPE'/&gt;
			&lt;Level attribute='PHONE'/&gt;
		&lt;/Hierarchy&gt;
	&lt;/Hierarchies&gt;
&lt;/Dimension&gt;

&lt;Cube name='tbl_farm_income_statics'&gt;
&lt;Dimensions&gt;
&lt;Dimension source='TBL_FARM_INCOME_STATICS' visible='true'/&gt;
&lt;Dimension source='TBL_CUSTOMER' visible='true'/&gt;
&lt;/Dimensions&gt;
&lt;MeasureGroups&gt;
	&lt;MeasureGroup table='TBL_CUSTOMER'&gt;
		&lt;Measures&gt;
			&lt;Measure aggregator='sum' column='CONSUME_AMMOUT' name='CONSUME_AMMOUT_SUM' visible='true'/&gt;
		&lt;/Measures&gt;
		&lt;DimensionLinks&gt;
			&lt;FactLink dimension='TBL_FARM_INCOME_STATICS'/&gt;
			&lt;ForeignKeyLink dimension='TBL_CUSTOMER' foreignKeyColumn='COMPANY_ID'/&gt;
		&lt;/DimensionLinks&gt;
	&lt;/MeasureGroup&gt;

	&lt;MeasureGroup table='TBL_FARM_INCOME_STATICS'&gt;
		&lt;Measures&gt;
			&lt;Measure aggregator='count' column='COMPANY_ID' name='_COUNT_' visible='true'/&gt;
			&lt;Measure aggregator='sum' column='REFUND_AMOUNT' name='REFUND_AMOUNT_SUM' visible='true'/&gt;
			&lt;Measure aggregator='sum' column='COMMON_REFUND_AMOUNT' name='COMMON_REFUND_AMOUNT_SUM' visible='true'/&gt;
			&lt;Measure aggregator='sum' column='COMMON_INCOME' name='COMMON_INCOME_SUM' visible='true'/&gt;
			&lt;Measure aggregator='sum' column='SALE_AMOUNT' name='SALE_AMOUNT_SUM' visible='true'/&gt;
			&lt;Measure aggregator='sum' column='RENEW_AMOUNT' name='RENEW_AMOUNT_SUM' visible='true'/&gt;
			&lt;Measure aggregator='sum' column='TOTAL_AMOUNT' name='TOTAL_AMOUNT_SUM' visible='true'/&gt;
		&lt;/Measures&gt;
		&lt;DimensionLinks&gt;
			&lt;FactLink dimension='TBL_FARM_INCOME_STATICS'/&gt;
			&lt;ForeignKeyLink dimension='TBL_CUSTOMER' foreignKeyColumn='COMPANY_ID'/&gt;
		&lt;/DimensionLinks&gt;
	&lt;/MeasureGroup&gt;
&lt;/MeasureGroups&gt;
&lt;/Cube&gt;
&lt;/Schema&gt;

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[同步 异步 阻塞 非阻塞]]></title>
        <id>https://tinaxiawuhao.github.io/post/1SOcADwUR/</id>
        <link href="https://tinaxiawuhao.github.io/post/1SOcADwUR/">
        </link>
        <updated>2021-09-27T02:28:54.000Z</updated>
        <content type="html"><![CDATA[<h3 id="io操作">IO操作</h3>
<pre><code>IO分两阶段（一旦拿到数据后就变成了数据操作，不再是IO）：
    1.数据准备阶段
    2.内核空间复制数据到用户进程缓冲区（用户空间）阶段

在操作系统中，程序运行的空间分为内核空间和用户空间。
    应用程序都是运行在用户空间的，所以它们能操作的数据也都在用户空间。


阻塞IO和非阻塞IO的区别在于第一步发起IO请求是否会被阻塞：
    如果阻塞直到完成那么就是传统的阻塞IO，如果不阻塞，那么就是非阻塞IO。

一般来讲：
    阻塞IO模型、非阻塞IO模型、IO复用模型(select/poll/epoll)、信号驱动IO模型都属于同步IO，因为阶段2是阻塞的(尽管时间很短)。

同步IO和异步IO的区别就在于第二个步骤是否阻塞：
    如果不阻塞，而是操作系统帮你做完IO操作再将结果返回给你，那么就是异步IO
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1632709893088.png" alt="" loading="lazy"></figure>
<h3 id="同步和异步io-阻塞和非阻塞io">同步和异步IO 阻塞和非阻塞IO</h3>
<pre><code>同步和异步IO的概念：

	同步是用户线程发起I/O请求后需要等待或者轮询内核I/O操作完成后才能继续执行

	异步是用户线程发起I/O请求后仍需要继续执行，当内核I/O操作完成后会通知用户线程，或者调用用户线程注册的回调函数

阻塞和非阻塞IO的概念：

	阻塞是指I/O操作需要彻底完成后才能返回用户空间

	非阻塞是指I/O操作被调用后立即返回一个状态值，无需等I/O操作彻底完成
</code></pre>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1632709914348.png" alt="" loading="lazy"></figure>
<h3 id="同步与异步线程间调用">同步与异步（线程间调用）</h3>
<pre><code>同步与异步是对应于调用者与被调用者，它们是线程之间的关系，两个线程之间要么是同步的，要么是异步的

	同步操作时，调用者需要等待被调用者返回结果，才会进行下一步操作

	而异步则相反，调用者不需要等待被调用者返回调用，即可进行下一步操作，被调用者通常依靠事件、回调等机制来通知调用者结果
</code></pre>
<h3 id="阻塞与非阻塞线程内调用">阻塞与非阻塞（线程内调用）</h3>
<pre><code>阻塞与非阻塞是对同一个线程来说的，在某个时刻，线程要么处于阻塞，要么处于非阻塞


阻塞和非阻塞关注的是程序在等待调用结果（消息，返回值）时的状态：

    阻塞调用是指调用结果返回之前，当前线程会被挂起。调用线程只有在得到结果之后才会返回。

    非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。
</code></pre>
<h3 id="同步与异步调用线程通信">同步与异步调用/线程/通信</h3>
<pre><code>同步就是两种东西通过一种机制实现步调一致，异步是两种东西不必步调一致


一、同步调用与异步调用：

    在用在调用场景中，无非是对调用结果的不同处理。

    同步调用就是调用一但返回，就能知道结果，而异步是返回时不一定知道结果，还得通过其他机制来获知结果，如：

        a. 状态 b. 通知 c. 回调函数


二、同步线程与异步线程：

    同步线程：即两个线程步调要一致，其中一个线程可能要阻塞等待另外一个线程的运行，要相互协商。快的阻塞一下等到慢的步调一致。

    异步线程：步调不用一致，各自按各自的步调运行，不受另一个线程的影响。


三、同步通信与异步通信：

    同步和异步是指：发送方和接收方是否协调步调一致

    同步通信是指：发送方和接收方通过一定机制，实现收发步调协调。
        如：发送方发出数据后，等接收方发回响应以后才发下一个数据包的通讯方式

    异步通信是指：发送方的发送不管接收方的接收状态。
        如：发送方发出数据后，不等接收方发回响应，接着发送下个数据包的通讯方式。


阻塞可以是实现同步的一种手段！例如两个东西需要同步，一旦出现不同步情况，我就阻塞快的一方，使双方达到同步。

同步是两个对象之间的关系，而阻塞是一个对象的状态。
</code></pre>
<h3 id="四种组合方式">四种组合方式</h3>
<pre><code>同步阻塞方式：
    发送方发送请求之后一直等待响应。
    接收方处理请求时进行的IO操作如果不能马上等到返回结果，就一直等到返回结果后，才响应发送方，期间不能进行其他工作。

同步非阻塞方式：
	发送方发送请求之后，一直等待响应。
	接受方处理请求时进行的IO操作如果不能马上的得到结果，就立即返回，取做其他事情。
	但是由于没有得到请求处理结果，不响应发送方，发送方一直等待。
	当IO操作完成以后，将完成状态和结果通知接收方，接收方再响应发送方，发送方才进入下一次请求过程。（实际不应用）

异步阻塞方式：
	发送方向接收方请求后，不等待响应，可以继续其他工作。
	接收方处理请求时进行IO操作如果不能马上得到结果，就一直等到返回结果后，才响应发送方，期间不能进行其他操作。 （实际不应用）

异步非阻塞方式：
	发送方向接收方请求后，不等待响应，可以继续其他工作。
	接收方处理请求时进行IO操作如果不能马上得到结果，也不等待，而是马上返回去做其他事情。
	当IO操作完成以后，将完成状态和结果通知接收方，接收方再响应发送方。（效率最高）
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[NIO-FileChannel]]></title>
        <id>https://tinaxiawuhao.github.io/post/7Wmx9Q2PP/</id>
        <link href="https://tinaxiawuhao.github.io/post/7Wmx9Q2PP/">
        </link>
        <updated>2021-09-17T08:28:44.000Z</updated>
        <content type="html"><![CDATA[<h3 id="nio介绍">NIO介绍</h3>
<p>在讲解Channel之前，首先了解一下NIO， Java NIO全称java non-blocking IO，是从Java 1.4版本开始引入的一个新的IO API（New IO），可以替代标准的Java IO API，NIO与原来的IO有同样的作用和目的，但是使用的方式完全不同。IO与 NIO区别：</p>
<table>
<thead>
<tr>
<th>IO</th>
<th>NIO</th>
</tr>
</thead>
<tbody>
<tr>
<td>面向流（Stream Orientend）</td>
<td>面向缓冲区（Buffer Orientend）</td>
</tr>
<tr>
<td>阻塞IO（Blocking IO )</td>
<td>非阻塞IO（Non Blocking IO）</td>
</tr>
<tr>
<td></td>
<td>选择器（Selector）</td>
</tr>
</tbody>
</table>
<p>NIO支持面向缓冲区的、基于通道的IO操作并以更加高效的方式进行文件的读写操作，其核心API为Channel(通道)，Buffer(缓冲区), Selector(选择器)。Channel负责传输，Buffer负责存储 。</p>
<h3 id="缓冲区">缓冲区</h3>
<pre><code class="language-java">public class BioTest {
    @Test
    public void test1() {
        //1.初始化缓冲区数组
        ByteBuffer bf = ByteBuffer.allocate(1024);
        System.out.println(&quot;==========allocate============&quot;);
        System.out.println(bf.position());
        System.out.println(bf.limit());
        System.out.println(bf.capacity());

        //2.put插入数据
        bf.put(&quot;asasas&quot;.getBytes());
        System.out.println(&quot;==========put============&quot;);
        System.out.println(bf.position());
        System.out.println(bf.limit());
        System.out.println(bf.capacity());

        //3.改为读状态
        bf.flip();
        System.out.println(&quot;==========flip============&quot;);
        System.out.println(bf.position());
        System.out.println(bf.limit());
        System.out.println(bf.capacity());

        //4.获取缓冲区数据
        final byte[] bytes = new byte[bf.limit()];
        bf.get(bytes);
        System.out.println(&quot;==========get============&quot;);
        System.out.println(new String(bytes,0,bytes.length));
        System.out.println(bf.position());
        System.out.println(bf.limit());
        System.out.println(bf.capacity());

        //5.重置读状态
        bf.rewind();
        System.out.println(&quot;==========rewind============&quot;);
        System.out.println(bf.position());
        System.out.println(bf.limit());
        System.out.println(bf.capacity());

        //6.清除数据标识
        bf.clear();
        System.out.println(&quot;==========clear============&quot;);
        System.out.println(bf.position());
        System.out.println(bf.limit());
        System.out.println(bf.capacity());
    }
}
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1631867929854.png" alt="" loading="lazy"></figure>
<h3 id="直接缓冲区与非直接缓冲区">直接缓冲区与非直接缓冲区：</h3>
<p>非直接缓冲区：通过 allocate() 方法分配缓冲区，将缓冲区建立在 JVM 的内存中<br>
直接缓冲区：通过 allocateDirect() 方法分配直接缓冲区，将缓冲区建立在物理内存中。可以提高效率</p>
<ol>
<li>字节缓冲区要么是直接的，要么是非直接的。如果为直接字节缓冲区，则 Java 虚拟机会尽最大努力直接在机 此缓冲区上执行本机 I/O 操作。也就是说，在每次调用基础操作系统的一个本机 I/O 操作之前（或之后），</li>
<li>虚拟机都会尽量避免将缓冲区的内容复制到中间缓冲区中（或从中间缓冲区中复制内容）。</li>
<li>直接字节缓冲区可以通过调用此类的 allocateDirect() 工厂方法 来创建。此方法返回的 缓冲区进行分配和取消分配所需成本通常高于非直接缓冲区 。直接缓冲区的内容可以驻留在常规的垃圾回收堆之外，因此，它们对应用程序的内存需求量造成的影响可能并不明显。所以，建议将直接缓冲区主要分配给那些易受基础系统的本机 I/O 操作影响的大型、持久的缓冲区。一般情况下，最好仅在直接缓冲区能在程序性能方面带来明显好处时分配它们。</li>
<li>直接字节缓冲区还可以过 通过FileChannel 的 map() 方法 将文件区域直接映射到内存中来创建 。该方法返回MappedByteBuffer 。Java 平台的实现有助于通过 JNI 从本机代码创建直接字节缓冲区。如果以上这些缓冲区中的某个缓冲区实例指的是不可访问的内存区域，则试图访问该区域不会更改该缓冲区的内容，并且将会在访问期间或稍后的某个时间导致抛出不确定的异常。</li>
<li>字节缓冲区是直接缓冲区还是非直接缓冲区可通过调用其 isDirect() 方法来确定。提供此方法是为了能够在性能关键型代码中执行显式缓冲区管理。</li>
</ol>
<p>非直接缓冲区：</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1632797370169.png" alt="" loading="lazy"></figure>
<p>直接缓冲区：</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1632797378679.png" alt="" loading="lazy"></figure>
<h3 id="通道channel">通道（Channel ）</h3>
<p>通道表示打开到 IO 设备(例如：文件、套接字)的连接。若需要使用 NIO 系统，需要获取用于连接 IO 设备的通道以及用于容纳数据的缓冲区。然后操作缓冲区，对数据进行处理。<br>
　　Channel相比IO中的Stream更加高效，可以异步双向传输，但是必须和buffer一起使用。</p>
<p>主要实现类</p>
<pre><code class="language-java">FileChannel，读写文件中的数据。
SocketChannel，通过TCP读写网络中的数据。
ServerSockectChannel，监听新进来的TCP连接，像Web服务器那样。对每一个新进来的连接都会创建一个SocketChannel。
DatagramChannel，通过UDP读写网络中的数据。
</code></pre>
<h3 id="channel聚集gather写入">Channel聚集(gather)写入</h3>
<p>聚集写入（ Gathering Writes）是指将多个 Buffer 中的数据“聚集”到 Channel。 特别注意：按照缓冲区的顺序，写入 position 和 limit 之间的数据到 Channel 。</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1631867939574.png" alt="" loading="lazy"></figure>
<h3 id="channel分散scatter读取">Channel分散(scatter)读取</h3>
<p>分散读取（ Scattering Reads）是指从 Channel 中读取的数据“分散” 到多个 Buffer 中。 特别注意：按照缓冲区的顺序，从 Channel 中读取的数据依次将 Buffer 填满。</p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1631867947387.png" alt="" loading="lazy"></figure>
<h3 id="零拷贝filechannel的transferto和transferfrom">“零拷贝”（FileChannel的transferTo和transferFrom）</h3>
<blockquote>
<p>Java NIO中提供的FileChannel拥有transferTo和transferFrom两个方法，可直接把FileChannel中的数据拷贝到另外一个Channel，或者直接把另外一个Channel中的数据拷贝到FileChannel。该接口常被用于高效的网络/文件的数据传输和大文件拷贝。在操作系统支持的情况下，通过该方法传输数据并不需要将源数据从内核态拷贝到用户态，再从用户态拷贝到目标通道的内核态，同时也避免了两次用户态和内核态间的上下文切换，也即使用了“零拷贝”，所以其性能一般高于Java IO中提供的方法。</p>
</blockquote>
<h3 id="代码案例">代码案例</h3>
<pre><code class="language-java">/**
 * @author wuhao
 * @desc 本地io:
 * 　　 FileInputStreanm/FileOutputStream
 * 　　RandomAccessFile
 * 网络io:
 * 　　Socket
 * 　　ServerSocket
 * 　　DatagramSocket
 * @date 2021-09-17 15:22:26
 */
public class ChannelTest {

    //利用通道完成文件的复制,非直接缓冲区
    @Test
    @SneakyThrows
    public void test(){
        FileInputStream fis = new FileInputStream(&quot;D:\\1.jpg&quot;);
        FileOutputStream fos = new FileOutputStream(&quot;D:\\2.jpg&quot;);
        //获取通道
        FileChannel inChannel = fis.getChannel();
        FileChannel outChannel = fos.getChannel();
        //分配指定大小缓存区
        ByteBuffer buff = ByteBuffer.allocate(1024);// position 0 ,limit 1024
        //将通道的数据存入缓存区
        while(inChannel.read(buff)!=-1){// position 1024 ,limit 1024 ,相当于put
            //切换读模式
            buff.flip();//position 0 ,limit 1024
            //将缓存去的数据写入通道
            outChannel.write(buff);//position 1024 ,limit 1024,相当于get
            //清空缓冲区
            buff.clear();//position 0 ,limit 1024
        }
        outChannel.close();
        inChannel.close();
        fis.close();
        fos.close();
    }

    //利用通道完成文件的复制,直接缓冲区,利用物理内存映射文件
    //会出现文件复制完了，但程序还没结束，原因是JVM资源还在用，当垃圾回收机制回收之后程序就会结束,不稳定
    @Test
    @SneakyThrows
    public void test1(){
        FileChannel inChannel = FileChannel.open(Paths.get(&quot;D:\\1.jpg&quot;), StandardOpenOption.READ);
        FileChannel outChannel = FileChannel.open(Paths.get(&quot;D:\\4.jpg&quot;), StandardOpenOption.READ,StandardOpenOption.WRITE,StandardOpenOption.CREATE);
        //内存映射文件
        MappedByteBuffer inMapBuff = inChannel.map(FileChannel.MapMode.READ_ONLY, 0, inChannel.size());//==allocateDirect
        MappedByteBuffer outMapBuff = outChannel.map(FileChannel.MapMode.READ_WRITE, 0, inChannel.size());
        byte[] by = new byte[inMapBuff.limit()];
        inMapBuff.get(by);
        outMapBuff.put(by);
        outChannel.close();
        inChannel.close();
    }

    /**
     * 从源信道读取字节到这个通道的文件中。如果源通道的剩余空间小于 count 个字节，则所传输的字节数要小于请求的字节数。这种方法可能比从源通道读取并写入此通道的简单循环更有效率。
     * @param SRC 源通道
     * @param position 调动开始的文件内的位置，必须是非负的
     * @param count 要传输的最大字节数，必须是非负
     * @return 传输文件的大小（单位字节），可能为零，
     * public abstract long transferFrom(ReadableByteChannel src, long position, long count)　throws IOException;
     */
    //复制图片，利用直接缓存区
    @Test
    @SneakyThrows
    public void test2(){
        FileChannel inChannel = FileChannel.open(Paths.get(&quot;D:\\1.jpg&quot;), StandardOpenOption.READ);
        FileChannel outChannel = FileChannel.open(Paths.get(&quot;D:\\2.jpg&quot;), StandardOpenOption.READ, StandardOpenOption.WRITE, StandardOpenOption.CREATE);
        outChannel.transferFrom(inChannel, 0, inChannel.size());
        inChannel.close();
        outChannel.close();
    }

    /**
     * 将字节从这个通道的文件传输到给定的可写字节通道。
     * @param position 调动开始的文件内的位置，必须是非负的
     * @param count 要传输的最大字节数，必须是非负
     * @param target 目标通道
     * @return 传输文件的大小（单位字节），可能为零，
     * public abstract long transferTo(long position, long count, WritableByteChannel target) throws IOException;
     */
    //复制图片，利用直接缓存区
    @Test
    @SneakyThrows
    public void test3(){
        FileChannel inChannel = FileChannel.open(Paths.get(&quot;D:\\1.jpg&quot;), StandardOpenOption.READ);
        FileChannel outChannel = FileChannel.open(Paths.get(&quot;D:\\3.jpg&quot;), StandardOpenOption.READ, StandardOpenOption.WRITE, StandardOpenOption.CREATE);
        inChannel.transferTo(0, inChannel.size(), outChannel);
        inChannel.close();
        outChannel.close();
    }

    // 分散读取聚集写入实现文件复制

    @Test
    @SneakyThrows
    public void test4(){
        RandomAccessFile randomAccessFile = null;
        RandomAccessFile randomAccessFile1 = null;
        FileChannel inChannel = null;
        FileChannel outChannel = null;
        try {
            randomAccessFile = new RandomAccessFile(new File(&quot;d:\\old.txt&quot;), &quot;rw&quot;);
            randomAccessFile1 = new RandomAccessFile(new File(&quot;d:\\new.txt&quot;), &quot;rw&quot;);
            inChannel = randomAccessFile.getChannel();
            outChannel = randomAccessFile1.getChannel();
            // 分散为三个bytebuffer读取,capcity要设置的足够大，不然如果文件太大，会导致复制的内容不完整
            ByteBuffer byteBuffer1 = ByteBuffer.allocate(1024);
            ByteBuffer byteBuffer2 = ByteBuffer.allocate(1024);
            ByteBuffer byteBuffer3 = ByteBuffer.allocate(10240);
            ByteBuffer[] bbs = new ByteBuffer[]{byteBuffer1,byteBuffer2,byteBuffer3};

            inChannel.read(bbs);// 分散读取

            // 切换为写入模式
            for (int i = 0; i &lt; bbs.length; i++) {
                bbs[i].flip();
            }

            outChannel.write(bbs);

        } catch (Exception ex) {
            ex.printStackTrace();
        }
    }
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[服务器变慢诊断命令]]></title>
        <id>https://tinaxiawuhao.github.io/post/Um55sd5Z3/</id>
        <link href="https://tinaxiawuhao.github.io/post/Um55sd5Z3/">
        </link>
        <updated>2021-09-15T06:59:00.000Z</updated>
        <content type="html"><![CDATA[<h3 id="top命令详解">top命令详解</h3>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1631692082043.png" alt="" loading="lazy"></figure>
<p><strong>第一行，任务队列信息，同 uptime 命令的执行结果</strong></p>
<blockquote>
<p>系统时间：07:27:05</p>
<p>运行时间：up 1:57 min,</p>
<p>当前登录用户： 3 user</p>
<p>负载均衡(uptime) load average: 0.00, 0.00, 0.00</p>
<p>average后面的三个数分别是1分钟、5分钟、15分钟的负载情况。</p>
<p>load average数据是每隔5秒钟检查一次活跃的进程数，然后按特定算法计算出的数值。如果这个数除以逻辑CPU的数量，结果高于5的时候就表明系统在超负荷运转了</p>
</blockquote>
<p><strong>第二行，Tasks — 任务（进程）</strong></p>
<blockquote>
<p>总进程:150 total, 运行:1 running, 休眠:149 sleeping, 停止: 0 stopped, 僵尸进程: 0 zombie</p>
</blockquote>
<p><strong>第三行，cpu状态信息</strong></p>
<blockquote>
<p>0.0%us【user space】— 用户空间占用CPU的百分比。</p>
<p>0.3%sy【sysctl】— 内核空间占用CPU的百分比。</p>
<p>0.0%ni【】— 改变过优先级的进程占用CPU的百分比</p>
<p>99.7%id【idolt】— 空闲CPU百分比</p>
<p>0.0%wa【wait】— IO等待占用CPU的百分比</p>
<p>0.0%hi【Hardware IRQ】— 硬中断占用CPU的百分比</p>
<p>0.0%si【Software Interrupts】— 软中断占用CPU的百分比</p>
</blockquote>
<p><strong>第四行,内存状态</strong></p>
<blockquote>
<p>1003020k total,  234464k used,  777824k free,  24084k buffers【缓存的内存量】</p>
</blockquote>
<p><strong>第五行，swap交换分区信息</strong></p>
<blockquote>
<p>2031612k total,   536k used, 2031076k free,  505864k cached【缓冲的交换区总量】</p>
</blockquote>
<blockquote>
<p>备注：</p>
<p>可用内存=free + buffer + cached</p>
<p>对于内存监控，在top里我们要时刻监控第五行swap交换分区的used，如果这个数值在不断的变化，说明内核在不断进行内存和swap的数据交换，这是真正的内存不够用了。</p>
<p>第四行中使用中的内存总量（used）指的是现在系统内核控制的内存数，</p>
<p>第四行中空闲内存总量（free）是内核还未纳入其管控范围的数量。</p>
<p>纳入内核管理的内存不见得都在使用中，还包括过去使用过的现在可以被重复利用的内存，内核并不把这些可被重新使用的内存交还到free中去，因此在linux上free内存会越来越少，但不用为此担心。</p>
</blockquote>
<p><strong>第六行，空行</strong></p>
<p><strong>第七行以下：各进程（任务）的状态监控</strong></p>
<blockquote>
<p>PID — 进程id<br>
USER — 进程所有者<br>
PR — 进程优先级<br>
NI — nice值。负值表示高优先级，正值表示低优先级<br>
VIRT — 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES<br>
RES — 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA<br>
SHR — 共享内存大小，单位kb<br>
S —进程状态。D=不可中断的睡眠状态 R=运行 S=睡眠 T=跟踪/停止 Z=僵尸进程<br>
%CPU — 上次更新到现在的CPU时间占用百分比<br>
%MEM — 进程使用的物理内存百分比<br>
TIME+ — 进程使用的CPU时间总计，单位1/100秒<br>
COMMAND — 进程名称（命令名/命令行）</p>
</blockquote>
<p><strong>详解</strong></p>
<blockquote>
<p>**VIRT：virtual memory usage 虚拟内存<br>
**1、进程“需要的”虚拟内存大小，包括进程使用的库、代码、数据等<br>
2、假如进程申请100m的内存，但实际只使用了10m，那么它会增长100m，而不是实际的使用量</p>
<p><strong>RES：resident memory usage 常驻内存</strong><br>
1、进程当前使用的内存大小，但不包括swap out<br>
2、包含其他进程的共享<br>
3、如果申请100m的内存，实际使用10m，它只增长10m，与VIRT相反<br>
4、关于库占用内存的情况，它只统计加载的库文件所占内存大小</p>
<p><strong>SHR：shared memory 共享内存</strong><br>
1、除了自身进程的共享内存，也包括其他进程的共享内存<br>
2、虽然进程只使用了几个共享库的函数，但它包含了整个共享库的大小<br>
3、计算某个进程所占的物理内存大小公式：RES – SHR<br>
4、swap out后，它将会降下来</p>
<p><strong>DATA</strong><br>
1、数据占用的内存。如果top没有显示，按f键可以显示出来。<br>
2、真正的该程序要求的数据空间，是真正在运行中要使用的。</p>
<p><strong>top 运行中可以通过 top 的内部命令对进程的显示方式进行控制。内部命令如下：</strong><br>
s – 改变画面更新频率<br>
l – 关闭或开启第一部分第一行 top 信息的表示<br>
t – 关闭或开启第一部分第二行 Tasks 和第三行 Cpus 信息的表示<br>
m – 关闭或开启第一部分第四行 Mem 和 第五行 Swap 信息的表示<br>
N – 以 PID 的大小的顺序排列表示进程列表<br>
P – 以 CPU 占用率大小的顺序排列进程列表<br>
M – 以内存占用率大小的顺序排列进程列表<br>
h – 显示帮助<br>
n – 设置在进程列表所显示进程的数量<br>
q – 退出 top<br>
s – 改变画面更新周期</p>
</blockquote>
<h3 id="vmstat命令详解">vmstat命令详解</h3>
<p>vmstat命令是最常见的Linux/Unix监控工具，可以展现给定时间间隔的服务器的状态值,包括服务器的CPU使用率，内存使用，虚拟内存交换情况,IO读写情况。这个命令是我查看Linux/Unix最喜爱的命令，一个是Linux/Unix都支持，二是相比top，我可以看到整个机器的CPU,内存,IO的使用情况，而不是单单看到各个进程的CPU使用率和内存使用率(使用场景不一样)。</p>
<p>一般vmstat工具的使用是通过两个数字参数来完成的，第一个参数是采样的时间间隔数，单位是秒，第二个参数是采样的次数，如:</p>
<pre><code>root@ubuntu:~# vmstat 2 1
procs -----------memory---------- ---swap-- -----io---- -system-- ----cpu----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa
 1  0      0 3498472 315836 3819540    0    0     0     1    2    0  0  0 100  0
</code></pre>
<p>2表示每个两秒采集一次服务器状态，1表示只采集一次。</p>
<p>实际上，在应用过程中，我们会在一段时间内一直监控，不想监控直接结束vmstat就行了,例如:</p>
<pre><code>root@ubuntu:~# vmstat 2  
procs -----------memory---------- ---swap-- -----io---- -system-- ----cpu----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa
 1  0      0 3499840 315836 3819660    0    0     0     1    2    0  0  0 100  0
 0  0      0 3499584 315836 3819660    0    0     0     0   88  158  0  0 100  0
 0  0      0 3499708 315836 3819660    0    0     0     2   86  162  0  0 100  0
 0  0      0 3499708 315836 3819660    0    0     0    10   81  151  0  0 100  0
 1  0      0 3499732 315836 3819660    0    0     0     2   83  154  0  0 100  0
</code></pre>
<p>这表示vmstat每2秒采集数据，一直采集，直到我结束程序，这里采集了5次数据我就结束了程序。</p>
<p><strong>参数详解</strong></p>
<blockquote>
<p><strong>r</strong> 表示运行队列(就是说多少个进程真的分配到CPU)，我测试的服务器目前CPU比较空闲，没什么程序在跑，当这个值超过了CPU数目，就会出现CPU瓶颈了。这个也和top的负载有关系，一般负载超过了3就比较高，超过了5就高，超过了10就不正常了，服务器的状态很危险。top的负载类似每秒的运行队列。如果运行队列过大，表示你的CPU很繁忙，一般会造成CPU使用率很高。</p>
<p><strong>b</strong> 表示阻塞的进程,这个不多说，进程阻塞，大家懂的。</p>
<p><strong>swpd</strong> 虚拟内存已使用的大小，如果大于0，表示你的机器物理内存不足了，如果不是程序内存泄露的原因，那么你该升级内存了或者把耗内存的任务迁移到其他机器。</p>
<p><strong>free</strong>  空闲的物理内存的大小，我的机器内存总共8G，剩余3415M。</p>
<p><strong>buff</strong>  Linux/Unix系统是用来存储，目录里面有什么内容，权限等的缓存，我本机大概占用300多M</p>
<p><strong>cache</strong> cache直接用来记忆我们打开的文件,给文件做缓冲，我本机大概占用300多M(这里是Linux/Unix的聪明之处，把空闲的物理内存的一部分拿来做文件和目录的缓存，是为了提高 程序执行的性能，当程序使用内存时，buffer/cached会很快地被使用。)</p>
<p><strong>si</strong> 每秒从磁盘读入虚拟内存的大小，如果这个值大于0，表示物理内存不够用或者内存泄露了，要查找耗内存进程解决掉。我的机器内存充裕，一切正常。</p>
<p><strong>so</strong> 每秒虚拟内存写入磁盘的大小，如果这个值大于0，同上。</p>
<p><strong>bi</strong> 块设备每秒接收的块数量，这里的块设备是指系统上所有的磁盘和其他块设备，默认块大小是1024byte，我本机上没什么IO操作，所以一直是0，但是我曾在处理拷贝大量数据(2-3T)的机器上看过可以达到140000/s，磁盘写入速度差不多140M每秒</p>
<p><strong>bo</strong> 块设备每秒发送的块数量，例如我们读取文件，bo就要大于0。bi和bo一般都要接近0，不然就是IO过于频繁，需要调整。</p>
<p><strong>in</strong> 每秒CPU的中断次数，包括时间中断</p>
<p><strong>cs</strong> 每秒上下文切换次数，例如我们调用系统函数，就要进行上下文切换，线程的切换，也要进程上下文切换，这个值要越小越好，太大了，要考虑调低线程或者进程的数目,例如在apache和nginx这种web服务器中，我们一般做性能测试时会进行几千并发甚至几万并发的测试，选择web服务器的进程可以由进程或者线程的峰值一直下调，压测，直到cs到一个比较小的值，这个进程和线程数就是比较合适的值了。系统调用也是，每次调用系统函数，我们的代码就会进入内核空间，导致上下文切换，这个是很耗资源，也要尽量避免频繁调用系统函数。上下文切换次数过多表示你的CPU大部分浪费在上下文切换，导致CPU干正经事的时间少了，CPU没有充分利用，是不可取的。</p>
<p><strong>us</strong> 用户CPU时间，我曾经在一个做加密解密很频繁的服务器上，可以看到us接近100,r运行队列达到80(机器在做压力测试，性能表现不佳)。</p>
<p><strong>sy</strong> 系统CPU时间，如果太高，表示系统调用时间长，例如是IO操作频繁。</p>
<p><strong>id</strong> 空闲 CPU时间，一般来说，id + us + sy = 100,一般我认为id是空闲CPU使用率，us是用户CPU使用率，sy是系统CPU使用率。</p>
<p><strong>wt</strong> 等待IO CPU时间。</p>
</blockquote>
<h3 id="pid命令详解">pid命令详解</h3>
<p>pidstat是sysstat工具的一个命令，用于监控全部或指定进程的cpu、内存、线程、设备IO等系统资源的占用情况。pidstat首次运行时显示自系统启动开始的各项统计信息，之后运行pidstat将显示自上次运行该命令以后的统计信息。用户可以通过指定统计的次数和时间来获得所需的统计信息。</p>
<p>pidstat 的用法：</p>
<pre><code>pidstat [ 选项 ] [ &lt;时间间隔&gt; ] [ &lt;次数&gt; ]
</code></pre>
<p>如下图：</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1631692116794.png" alt="" loading="lazy"></figure>
<p><strong>常用的参数：</strong></p>
<ul>
<li>-u：默认的参数，显示各个进程的cpu使用统计</li>
<li>-r：显示各个进程的内存使用统计</li>
<li>-d：显示各个进程的IO使用情况</li>
<li>-p：指定进程号</li>
<li>-w：显示每个进程的上下文切换情况</li>
<li>-t：显示选择任务的线程的统计信息外的额外信息</li>
<li>-T { TASK | CHILD | ALL }<br>
这个选项指定了pidstat监控的。TASK表示报告独立的task，CHILD关键字表示报告进程下所有线程统计信息。ALL表示报告独立的task和task下面的所有线程。<br>
注意：task和子线程的全局的统计信息和pidstat选项无关。这些统计信息不会对应到当前的统计间隔，这些统计信息只有在子线程kill或者完成的时候才会被收集。</li>
<li>-V：版本号</li>
<li>-h：在一行上显示了所有活动，这样其他程序可以容易解析。</li>
<li>-I：在SMP环境，表示任务的CPU使用率/内核数量</li>
<li>-l：显示命令名和所有参数</li>
</ul>
<pre><code>pidstat
pidstat -u -p ALL
</code></pre>
<p>pidstat 和 pidstat -u -p ALL 是等效的。<br>
pidstat 默认显示了所有进程的cpu使用率。</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1631692161313.png" alt="" loading="lazy"></figure>
<p><strong>参数详解</strong></p>
<ul>
<li>
<p>PID：进程ID</p>
</li>
<li>
<p>%usr：进程在用户空间占用cpu的百分比</p>
</li>
<li>
<p>%system：进程在内核空间占用cpu的百分比</p>
</li>
<li>
<p>%guest：进程在虚拟机占用cpu的百分比</p>
</li>
<li>
<p>%CPU：进程占用cpu的百分比</p>
</li>
<li>
<p>CPU：处理进程的cpu编号</p>
</li>
<li>
<p>Command：当前进程对应的命令</p>
</li>
</ul>
<h3 id="free命令详解">free命令详解</h3>
<p>free 命令显示系统内存的使用情况，包括物理内存、交换内存(swap)和内核缓冲区内存。</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1631692175318.png" alt="" loading="lazy"></figure>
<p>如果加上 -h 选项，输出的结果会友好很多：</p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1631692195242.png" alt="" loading="lazy"></figure>
<p>有时我们需要持续的观察内存的状况，此时可以使用 -s 选项并指定间隔的秒数：</p>
<pre><code>$ free -h -s 3
</code></pre>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1631692210174.png" alt="" loading="lazy"></figure>
<p>上面的命令每隔 3 秒输出一次内存的使用情况，直到你按下 ctrl + c。</p>
<p>由于 free 命令本身比较简单，所以本文的重点会放在如何通过 free 命令了解系统当前的内存使用状况。</p>
<p><strong>输出说明</strong><br>
<strong>Mem</strong> 行(第二行)是内存的使用情况。<br>
<strong>Swap</strong> 行(第三行)是交换空间的使用情况。<br>
<strong>total</strong> 列显示系统总的可用物理内存和交换空间大小。<br>
<strong>used</strong> 列显示已经被使用的物理内存和交换空间。<br>
<strong>free</strong> 列显示还有多少物理内存和交换空间可用使用。<br>
<strong>shared</strong> 列显示被共享使用的物理内存大小。<br>
<strong>buff/cache</strong> 列显示被 buffer 和 cache 使用的物理内存大小。<br>
<strong>available</strong> 列显示还可以被应用程序使用的物理内存大小。</p>
<h3 id="df命令详解">df命令详解</h3>
<p>Linux df（英文全拼：disk free） 命令用于显示目前在 Linux 系统上的文件系统磁盘使用情况统计。</p>
<p><strong>语法</strong></p>
<pre><code>df [选项]... [FILE]...
</code></pre>
<ul>
<li>文件-a, --all 包含所有的具有 0 Blocks 的文件系统</li>
<li>文件--block-size={SIZE} 使用 {SIZE} 大小的 Blocks</li>
<li>文件-h, --human-readable 使用人类可读的格式(预设值是不加这个选项的...)</li>
<li>文件-H, --si 很像 -h, 但是用 1000 为单位而不是用 1024</li>
<li>文件-i, --inodes 列出 inode 资讯，不列出已使用 block</li>
<li>文件-k, --kilobytes 就像是 --block-size=1024</li>
<li>文件-l, --local 限制列出的文件结构</li>
<li>文件-m, --megabytes 就像 --block-size=1048576</li>
<li>文件--no-sync 取得资讯前不 sync (预设值)</li>
<li>文件-P, --portability 使用 POSIX 输出格式</li>
<li>文件--sync 在取得资讯前 sync</li>
<li>文件-t, --type=TYPE 限制列出文件系统的 TYPE</li>
<li>文件-T, --print-type 显示文件系统的形式</li>
<li>文件-x, --exclude-type=TYPE 限制列出文件系统不要显示 TYPE</li>
<li>文件-v (忽略)</li>
<li>文件--help 显示这个帮手并且离开</li>
<li>文件--version 输出版本资讯并且离开</li>
</ul>
<p><strong>实例</strong></p>
<p>显示文件系统的磁盘使用情况统计：</p>
<pre><code># df 
Filesystem     1K-blocks    Used     Available Use% Mounted on 
/dev/sda6       29640780 4320704     23814388  16%     / 
udev             1536756       4     1536752    1%     /dev 
tmpfs             617620     888     616732     1%     /run 
none                5120       0     5120       0%     /run/lock 
none             1544044     156     1543888    1%     /run/shm 
</code></pre>
<p>第一列指定文件系统的名称，第二列指定一个特定的文件系统1K-块1K是1024字节为单位的总内存。用和可用列正在使用中，分别指定的内存量。</p>
<p>使用列指定使用的内存的百分比，而最后一栏&quot;安装在&quot;指定的文件系统的挂载点。</p>
<p>df也可以显示磁盘使用的文件系统信息：</p>
<pre><code># df test 
Filesystem     1K-blocks    Used      Available Use% Mounted on 
/dev/sda6       29640780    4320600   23814492  16%       / 
</code></pre>
<p>用一个-i选项的df命令的输出显示inode信息而非块使用量。</p>
<pre><code>df -i 
Filesystem      Inodes    IUsed    IFree     IUse% Mounted on 
/dev/sda6      1884160    261964   1622196   14%        / 
udev           212748     560      212188    1%         /dev 
tmpfs          216392     477      215915    1%         /run 
none           216392     3        216389    1%         /run/lock 
none           216392     8        216384    1%         /run/shm 
</code></pre>
<p>显示所有的信息:</p>
<pre><code># df --total 
Filesystem     1K-blocks    Used    Available Use% Mounted on 
/dev/sda6       29640780 4320720    23814372  16%     / 
udev             1536756       4    1536752   1%      /dev 
tmpfs             617620     892    616728    1%      /run 
none                5120       0    5120      0%      /run/lock 
none             1544044     156    1543888   1%      /run/shm 
total           33344320 4321772    27516860  14% 
</code></pre>
<p>我们看到输出的末尾，包含一个额外的行，显示总的每一列。</p>
<p>-h选项，通过它可以产生可读的格式df命令的输出：</p>
<pre><code># df -h 
Filesystem      Size  Used   Avail Use% Mounted on 
/dev/sda6       29G   4.2G   23G   16%     / 
udev            1.5G  4.0K   1.5G   1%     /dev 
tmpfs           604M  892K   603M   1%     /run 
none            5.0M     0   5.0M   0%     /run/lock 
none            1.5G  156K   1.5G   1%     /run/shm 
</code></pre>
<p>我们可以看到输出显示的数字形式的'G'（千兆字节），&quot;M&quot;（兆字节）和&quot;K&quot;（千字节）。</p>
<p>这使输出容易阅读和理解，从而使显示可读的。请注意，第二列的名称也发生了变化，为了使显示可读的&quot;大小&quot;。</p>
<h3 id="iostat命令详解">iostat命令详解</h3>
<p>用法：iostat [ 选项 ] [ &lt;时间间隔&gt; [ &lt;次数&gt; ]]</p>
<p>常用选项说明：</p>
<pre><code>-c：只显示系统CPU统计信息，即单独输出avg-cpu结果，不包括device结果
-d：单独输出Device结果，不包括cpu结果
-k/-m：输出结果以kB/mB为单位，而不是以扇区数为单位
-x:输出更详细的io设备统计信息
interval/count：每次输出间隔时间，count表示输出次数，不带count表示循环输出
</code></pre>
<p>说明：更多选项使用使用man iostat查看</p>
<p><strong>实例</strong></p>
<p>1、iostat，结果为从系统开机到当前执行时刻的统计信息</p>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1631692226555.png" alt="" loading="lazy"></figure>
<p>输出含义：</p>
<p>avg-cpu: 总体cpu使用情况统计信息，对于多核cpu，这里为所有cpu的平均值。重点关注iowait值，表示CPU用于等待io请求的完成时间。</p>
<p>Device: 各磁盘设备的IO统计信息。各列含义如下：</p>
<pre><code>Device: 以sdX形式显示的设备名称
tps: 每秒进程下发的IO读、写请求数量
KB_read/s: 每秒从驱动器读入的数据量，单位为K。
KB_wrtn/s: 每秒从驱动器写入的数据量，单位为K。
KB_read: 读入数据总量，单位为K。
KB_wrtn: 写入数据总量，单位为K。
</code></pre>
<p>2、iostat -x -k -d 1 2。每隔1S输出磁盘IO的详细详细，总共采样2次。</p>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1631692235192.png" alt="" loading="lazy"></figure>
<p>以上各列的含义如下：</p>
<pre><code>rrqm/s: 每秒对该设备的读请求被合并次数，文件系统会对读取同块(block)的请求进行合并
wrqm/s: 每秒对该设备的写请求被合并次数
r/s: 每秒完成的读次数
w/s: 每秒完成的写次数
rkB/s: 每秒读数据量(kB为单位)
wkB/s: 每秒写数据量(kB为单位)
avgrq-sz:平均每次IO操作的数据量(扇区数为单位)
avgqu-sz: 平均等待处理的IO请求队列长度
await: 平均每次IO请求等待时间(包括等待时间和处理时间，毫秒为单位)
svctm: 平均每次IO请求的处理时间(毫秒为单位)
%util: 采用周期内用于IO操作的时间比率，即IO队列非空的时间比率
</code></pre>
<p>重点关注参数</p>
<blockquote>
<p>1、iowait% 表示CPU等待IO时间占整个CPU周期的百分比，如果iowait值超过50%，或者明显大于%system、%user以及%idle，表示IO可能存在问题。</p>
<p>2、avgqu-sz 表示磁盘IO队列长度，即IO等待个数。</p>
<p>3、await 表示每次IO请求等待时间，包括等待时间和处理时间</p>
<p>4、svctm 表示每次IO请求处理的时间</p>
<p>5、%util 表示磁盘忙碌情况，一般该值超过80%表示该磁盘可能处于繁忙状态。</p>
</blockquote>
<h3 id="ifstat命令详解">ifstat命令详解</h3>
<p>统计网络接口流量状态</p>
<p>下载</p>
<pre><code class="language-shell">wget http://gael.roualland.free.fr/ifstat/ifstat-1.1.tar.gz
</code></pre>
<p>编译安装</p>
<pre><code class="language-shell">tar -zxvf ifstat-1.1.tar.gz
cd ifstat-1.1
./configure            
make
make install # 默认会安装到/usr/local/bin/目录中
</code></pre>
<p><code>注释</code>：执行which ifstat输出/usr/local/bin/ifstat</p>
<p>选项</p>
<blockquote>
<p>-l 监测环路网络接口（lo）。缺省情况下，ifstat监测活动的所有非环路网络接口。经使用发现，加上-l参数能监测所有的网络接口的信息，而不是只监测 lo的接口信息，也就是说，加上-l参数比不加-l参数会多一个lo接口的状态信息。<br>
-a 监测能检测到的所有网络接口的状态信息。使用发现，比加上-l参数还多一个plip0的接口信息，搜索一下发现这是并口（网络设备中有一 个叫PLIP (Parallel Line Internet Protocol). 它提供了并口...）<br>
-z 隐藏流量是无的接口，例如那些接口虽然启动了但是未用的<br>
-i 指定要监测的接口,后面跟网络接口名<br>
-s 等于加-d snmp:[comm@][#]host[/nn]] 参数，通过SNMP查询一个远程主机<br>
-h 显示简短的帮助信息<br>
-n 关闭显示周期性出现的头部信息（也就是说，不加-n参数运行ifstat时最顶部会出现网络接口的名称，当一屏显示不下时，会再一次出现接口的名称，提示我们显示的流量信息具体是哪个网络接口的。加上-n参数把周期性的显示接口名称关闭，只显示一次）<br>
-t 在每一行的开头加一个时间 戳（能告诉我们具体的时间）<br>
-T 报告所有监测接口的全部带宽（最后一列有个total，显示所有的接口的in流量和所有接口的out流量，简单的把所有接口的in流量相加,out流量相 加）<br>
-w  用指定的列宽，而不是为了适应接口名称的长度而去自动放大列宽<br>
-W 如果内容比终端窗口的宽度还要宽就自动换行<br>
-S 在同一行保持状态更新（不滚动不换行）注：如果不喜欢屏幕滚动则此项非常方便，与bmon的显示方式类似<br>
-b 用kbits/s显示带宽而不是kbytes/s<br>
-q 安静模式，警告信息不出现<br>
-v 显示版本信息<br>
-d 指定一个驱动来收集状态信息</p>
</blockquote>
<p><strong>实例</strong><br>
默认使用</p>
<pre><code class="language-shell"> #ifstat
       eth0                eth1       
 KB/s in  KB/s out   KB/s in  KB/s out
    0.07      0.20      0.00      0.00
    0.07      0.15      0.58      0.00
</code></pre>
<p>默认ifstat不监控回环接口，显示的流量单位是KB。</p>
<pre><code class="language-shell">ifstat -tT
  time           eth0                eth1                eth2                eth3               Total      
HH:MM:ss   KB/s in  KB/s out   KB/s in  KB/s out   KB/s in  KB/s out   KB/s in  KB/s out   KB/s in  KB/s out
16:53:04      0.84      0.62   1256.27   1173.05      0.12      0.18      0.00      0.00   1257.22   1173.86
16:53:05      0.57      0.40      0.57      0.76      0.00      0.00      0.00      0.00      1.14      1.17
16:53:06      1.58      0.71      0.42      0.78      0.00      0.00      0.00      0.00      2.01      1.48
16:53:07      0.57      0.40      1.91      2.61      0.00      0.00      0.00      0.00      2.48      3.01
16:53:08      0.73      0.40    924.02   1248.91      0.00      0.00      0.00      0.00    924.76   1249.31
</code></pre>
<p>监控所有网络接口</p>
<pre><code class="language-shell">ifstat -a
        lo                 eth0                eth1       
 KB/s in  KB/s out   KB/s in  KB/s out   KB/s in  KB/s out
    0.00      0.00      0.28      0.58      0.06      0.06
    0.00      0.00      1.41      1.13      0.00      0.00
    0.61      0.61      0.26      0.23      0.00      0.00
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[CAS/ABA/AtomicReference]]></title>
        <id>https://tinaxiawuhao.github.io/post/2nzKhQbUe/</id>
        <link href="https://tinaxiawuhao.github.io/post/2nzKhQbUe/">
        </link>
        <updated>2021-09-13T03:27:29.000Z</updated>
        <content type="html"><![CDATA[<p>锁是用来做并发最简单的方式，当然代价也是最高的。</p>
<p>独占锁是一种悲观锁，synchronized就是一种独占锁；它假设最坏的情况，并且只有在确保其它线程不会造成干扰的情况下执行，会导致其它所有需要锁的线程挂起直到持有锁的线程释放锁。</p>
<p>所谓乐观锁就是每次不加锁,假设没有冲突而去完成某项操作;如果发生冲突了那就去重试，直到成功为止。</p>
<p>CAS(Compare And Swap)是一种有名的无锁算法。CAS算法是乐观锁的一种实现。CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B并返回true，否则返回false。</p>
<blockquote>
<p>注:synchronized和ReentrantLock都是悲观锁。</p>
</blockquote>
<blockquote>
<p>注:什么时候使用悲观锁效率更高、什么使用使用乐观锁效率更高，要根据实际情况来判断选择。</p>
</blockquote>
<p>提示:atomic中包下的类，采用的即为CAS乐观算法。</p>
<p>以AtomicInteger的public final int getAndSet(int newValue)方法，进行简单说明，<br>
该方法是这样的:</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1631512353549.png" alt="" loading="lazy"></figure>
<p>其调用了Unsafe类的public final int getAndSetInt(Object var1, long var2, int var4)方法:</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1631512364454.png" alt="" loading="lazy"></figure>
<p>而该方法又do{…}while(…)循环调用了本地方法public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5);</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1631512374405.png" alt="" loading="lazy"></figure>
<p>注:至于Windows/Linux下public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5)本地方法是如何实现的，推荐阅读https://blog.csdn.net/v123411739/article/details/79561458。</p>
<p><strong>CAS(Compare And Swap)原理简述：</strong></p>
<pre><code>   某一线程执行一个CAS逻辑(如上图线程A),如果中途有其他线程修改了共享变量的值(如:上图中线程A执行到笑脸那一刻时),导致这个线程的CAS逻辑运算后得到的值与期望结果不一致，那么这个线程会再次执行CAS逻辑(这里是一个do while循环),直到成功为止。
</code></pre>
<p><strong>ABA问题：</strong></p>
<pre><code>  就是说一个线程把数据A变为了B，然后又重新变成了A。此时另外一个线程读取的时候，发现A没有变化，就误以为是原来的那个A。这就是有名的ABA问题。
</code></pre>
<blockquote>
<p>注:根据实际情况，判断是否处理ABA问题。如果ABA问题并不会影响我们的业务结果，可以选择性处理或不处理;如果<br>
ABA会影响我们的业务结果的，这时就必须处理ABA问题了。<br>
追注:对于AtomicInteger等,没有什么可修改的属性;且我们只在意其结果值，所以对于这些类来说，本身就算发生了ABA现象，也不会对原线程的结果造成什么影响。</p>
</blockquote>
<p>AtomicReference原子应用类，可以保证你在修改对象引用时的线程安全性，比较时可以按照偏移量进行<br>
怎样使用AtomicReference：</p>
<pre><code class="language-java">AtomicReference&lt;String&gt; ar = new AtomicReference&lt;String&gt;();
ar.set(&quot;hello&quot;);
//CAS操作更新
ar.compareAndSet(&quot;hello&quot;, &quot;hello1&quot;);
</code></pre>
<p>AtomicReference的成员变量：</p>
<pre><code class="language-java">private static final long serialVersionUID = -1848883965231344442L;
//unsafe类,提供cas操作的功能
private static final Unsafe unsafe = Unsafe.getUnsafe();
//value变量的偏移地址,说的就是下面那个value,这个偏移地址在static块里初始化
private static final long valueOffset;
//实际传入需要原子操作的那个类实例
private volatile V value;
</code></pre>
<p>类装载的时候初始化偏移地址：</p>
<pre><code class="language-java">static {
        try {
            valueOffset = unsafe.objectFieldOffset
                (AtomicReference.class.getDeclaredField(&quot;value&quot;));
        } catch (Exception ex) { throw new Error(ex); }
    }
</code></pre>
<p>compareAndSet方法：</p>
<pre><code class="language-java">//就是调用Unsafe的cas操作,传入对象,expect值,偏移地址,需要更新的值,即可,如果更新成功,返回true,如果失败,返回false
public final boolean compareAndSet(V expect, V update) {
        return unsafe.compareAndSwapObject(this, valueOffset, expect, update);
    }
</code></pre>
<p>对于String变量来说,必须是对象相同才视为相同,而不是字符串的内容相同就可以相同:</p>
<pre><code class="language-java">AtomicReference&lt;String&gt; ar = new AtomicReference&lt;String&gt;();
ar.set(&quot;hello&quot;);
System.out.println(ar.compareAndSet(new String(&quot;hello&quot;), &quot;hello1&quot;));//false
</code></pre>
<p>AtomicReference可解决volatile不具有原子性i++操作<br>
AtomicReference可以保证结果是正确的.</p>
<pre><code class="language-java">private static volatile Integer num1 = 0;
private static AtomicReference&lt;Integer&gt; ar=new AtomicReference&lt;Integer&gt;(num1);

public void dfasd111() throws InterruptedException{
    for (int i = 0; i &lt; 1000; i++) {
        new Thread(new Runnable(){
            @Override
            public void run() {
                for (int i = 0; i &lt; 10000; i++)
                    while(true){
                        Integer temp=ar.get();
                        if(ar.compareAndSet(temp, temp+1))break;
                    }
            }       
        }).start();
    }
    Thread.sleep(10000);
    System.out.println(ar.get()); //10000000
}
</code></pre>
<p>类似i++这样的&quot;读-改-写&quot;复合操作(在一个操作序列中, 后一个操作依赖前一次操作的结果), 在多线程并发处理的时候会出现问题, 因为可能一个线程修改了变量, 而另一个线程没有察觉到这样变化, 当使用原子变量之后, 则将一系列的复合操作合并为一个原子操作,从而避免这种问题, i++=&gt;i.incrementAndGet()</p>
<p>这里的compareAndSet方法即cas操作本身是原子的，但是在某些场景下会出现异常场景</p>
<p>此处说一下ABA问题：</p>
<p>比如，我们只是简单得要做一个数值加法，即使在我取得期望值后，这个数字被不断的修改，只要它最终改回了我的期望值，我的加法计算就不会出错。也就是说，当你修改的对象没有过程的状态信息，所有的信息都只保存于对象的数值本身。</p>
<p>但是，在现实中，还可能存在另外一种场景。就是我们是否能修改对象的值，不仅取决于当前值，还和对象的过程变化有关，这时，AtomicReference就无能为力了。</p>
<p><strong>AtomicStampedReference与AtomicReference的区别：</strong><br>
AtomicStampedReference它内部不仅维护了对象值，还维护了一个时间戳（我这里把它称为时间戳，实际上它可以使任何一个整数，它使用整数来表示状态值）。当AtomicStampedReference对应的数值被修改时，除了更新数据本身外，还必须要更新时间戳。当AtomicStampedReference设置对象值时，对象值以及时间戳都必须满足期望值，写入才会成功。因此，即使对象值被反复读写，写回原值，只要时间戳发生变化，就能防止不恰当的写入。</p>
<p><strong>解决ABA问题</strong></p>
<pre><code class="language-java">
public static void main(String[] args) {
 
        String str1 = &quot;aaa&quot;;
        String str2 = &quot;bbb&quot;;
        AtomicStampedReference&lt;String&gt; reference = new AtomicStampedReference&lt;String&gt;(str1,1);
        reference.compareAndSet(str1,str2,reference.getStamp(),reference.getStamp()+1);
        System.out.println(&quot;reference.getReference() = &quot; + reference.getReference());
 
        boolean b = reference.attemptStamp(str2, reference.getStamp() + 1);
        System.out.println(&quot;b: &quot;+b);
        System.out.println(&quot;reference.getStamp() = &quot;+reference.getStamp());
 
        boolean c = reference.weakCompareAndSet(str2,&quot;ccc&quot;,4, reference.getStamp()+1);
        System.out.println(&quot;reference.getReference() = &quot;+reference.getReference());
        System.out.println(&quot;c = &quot; + c);
    }
 
输出:
reference.getReference() = bbb
b: true
reference.getStamp() = 3
reference.getReference() = bbb
c = false
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[代理模式]]></title>
        <id>https://tinaxiawuhao.github.io/post/CO5c8R39E/</id>
        <link href="https://tinaxiawuhao.github.io/post/CO5c8R39E/">
        </link>
        <updated>2021-09-13T03:18:02.000Z</updated>
        <content type="html"><![CDATA[<p>静态代理、JDK动态代理以及CGLIB动态代理<br>
代理模式是java中最常用的设计模式之一，尤其是在spring框架中广泛应用。对于java的代理模式，一般可分为：静态代理、动态代理、以及CGLIB实现动态代理。<br>
对于上述三种代理模式，分别进行说明。</p>
<h2 id="静态代理">静态代理</h2>
<p>静态代理其实就是在程序运行之前，提前写好被代理方法的代理类，编译后运行。在程序运行之前，class已经存在。<br>
下面我们实现一个静态代理demo:</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1634527030816.png" alt="" loading="lazy"></figure>
<p>定义一个接口Target</p>
<pre><code class="language-java">package com.test.proxy;

public interface Target {

    public String execute();

}
</code></pre>
<p>TargetImpl 实现接口Target</p>
<pre><code class="language-java">package com.test.proxy;

public class TargetImpl implements Target {

    @Override
    public String execute() {
        System.out.println(&quot;TargetImpl execute！&quot;);
        return &quot;execute&quot;;
    }

}
</code></pre>
<p>代理类</p>
<pre><code class="language-java">package com.test.proxy;

public class Proxy implements Target{

    private Target target;
    
    public Proxy(Target target) {
        this.target = target;
    }
    
    @Override
    public String execute() {
        System.out.println(&quot;perProcess&quot;);
        String result = this.target.execute();
        System.out.println(&quot;postProcess&quot;);
        return result;
    }

}
</code></pre>
<p>测试类:</p>
<pre><code class="language-java">package com.test.proxy;

public class ProxyTest {

    public static void main(String[] args) {
    
        Target target = new TargetImpl();
        Proxy p = new Proxy(target);
        String result =  p.execute();
        System.out.println(result);
    }

}
</code></pre>
<p>运行结果:</p>
<blockquote>
<p>perProcess<br>
TargetImpl execute！<br>
postProcess<br>
execute</p>
</blockquote>
<p>静态代理需要针对被代理的方法提前写好代理类，如果被代理的方法非常多则需要编写很多代码，因此，对于上述缺点，通过动态代理的方式进行了弥补。</p>
<h2 id="动态代理">动态代理</h2>
<h3 id="jdk代理">jdk代理</h3>
<p>动态代理主要是通过反射机制，在运行时动态生成所需代理的class.</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1634527039701.png" alt="" loading="lazy"></figure>
<p>接口</p>
<pre><code class="language-java">package com.test.dynamic;

public interface Target {

    public String execute();

}
</code></pre>
<p>实现类</p>
<pre><code class="language-java">package com.test.dynamic;

public class TargetImpl implements Target {

    @Override
    public String execute() {
        System.out.println(&quot;TargetImpl execute！&quot;);
        return &quot;execute&quot;;
    }

}
</code></pre>
<p>代理类</p>
<pre><code class="language-java">package com.test.dynamic;


import java.lang.reflect.InvocationHandler;
import java.lang.reflect.Method;

public class DynamicProxyHandler implements InvocationHandler{

    private Target target;
    
    public DynamicProxyHandler(Target target) {
        this.target = target;
    }
    
    @Override
    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
        System.out.println(&quot;========before==========&quot;);
        Object result = method.invoke(target,args);
        System.out.println(&quot;========after===========&quot;);
        return result;
    }

}
</code></pre>
<p>测试类</p>
<pre><code class="language-java">package com.test.dynamic;

import java.lang.reflect.Proxy;

public class DynamicProxyTest {

    public static void main(String[] args) {
        Target target = new TargetImpl();
        DynamicProxyHandler handler = new DynamicProxyHandler(target);
        Target proxySubject = (Target) Proxy.newProxyInstance(TargetImpl.class.getClassLoader(),TargetImpl.class.getInterfaces(),handler);
        String result = proxySubject.execute();
        System.out.println(result);
    }

}
</code></pre>
<p>运行结果：</p>
<blockquote>
<p><mark><mark><mark><mark>before</mark></mark></mark></mark>==<br>
TargetImpl execute！<br>
<mark><mark><mark><mark>after</mark></mark></mark></mark>===<br>
execute</p>
</blockquote>
<p>无论是动态代理还是静态带领，都需要定义接口，然后才能实现代理功能。这同样存在局限性，因此，为了解决这个问题，出现了第三种代理方式：cglib代理。</p>
<h3 id="cglib代理">cglib代理</h3>
<p>CGLib采用了非常底层的字节码技术，其原理是通过字节码技术为一个类创建子类，并在子类中采用方法拦截的技术拦截所有父类方法的调用，顺势织入横切逻辑。JDK动态代理与CGLib动态代理均是实现Spring AOP的基础。</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1634527048720.png" alt="" loading="lazy"></figure>
<p>目标类</p>
<pre><code class="language-java">package com.test.cglib;

public class Target {

    public String execute() {
        String message = &quot;-----------test------------&quot;;
        System.out.println(message);
        return message;
    }

}
</code></pre>
<p>通用代理类</p>
<pre><code class="language-java">package com.test.cglib;

import net.sf.cglib.proxy.MethodInterceptor;
import net.sf.cglib.proxy.MethodProxy;

import java.lang.reflect.Method;

public class MyMethodInterceptor implements MethodInterceptor{

    @Override
    public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable {
        System.out.println(&quot;&gt;&gt;&gt;&gt;MethodInterceptor start...&quot;);
        Object result = proxy.invokeSuper(obj,args);
        System.out.println(&quot;&gt;&gt;&gt;&gt;MethodInterceptor ending...&quot;);
        return &quot;result&quot;;
    }

}
</code></pre>
<p>测试类</p>
<pre><code class="language-java">package com.test.cglib;

import net.sf.cglib.proxy.Enhancer;

public class CglibTest {

    public static void main(String[] args) {
        System.out.println(&quot;***************&quot;);
        Target target = new Target();
        CglibTest test = new CglibTest();
        Target proxyTarget = (Target) test.createProxy(Target.class);
        String res = proxyTarget.execute();
        System.out.println(res);
    }
    
    public Object createProxy(Class targetClass) {
        Enhancer enhancer = new Enhancer();
        enhancer.setSuperclass(targetClass);
        enhancer.setCallback(new MyMethodInterceptor());
        return enhancer.create();
    }

}
</code></pre>
<p>执行结果:</p>
<hr>
<blockquote>
<p>MethodInterceptor start...<br>
-----------test------------<br>
MethodInterceptor ending...<br>
result</p>
</blockquote>
<p>代理对象的生成过程由Enhancer类实现，大概步骤如下：</p>
<ol>
<li>生成代理类Class的二进制字节码；</li>
<li>通过Class.forName加载二进制字节码，生成Class对象；</li>
<li>通过反射机制获取实例构造，并初始化代理类对象。</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[OOM]]></title>
        <id>https://tinaxiawuhao.github.io/post/QvbaHSogu/</id>
        <link href="https://tinaxiawuhao.github.io/post/QvbaHSogu/">
        </link>
        <updated>2021-09-13T01:54:41.000Z</updated>
        <content type="html"><![CDATA[<h3 id="stack-overflow">Stack overflow</h3>
<pre><code class="language-java">public class StackOverFlowErrorDemo {
    public static void main(String[] args) {
        StackOverFlowError();
    }

    private static void StackOverFlowError() {
        StackOverFlowError();
    }
}
</code></pre>
<pre><code class="language-java">Exception in thread &quot;main&quot; java.lang.StackOverflowError
	at com.example.interview.oom.StackOverFlowErrorDemo.StackOverFlowError(StackOverFlowErrorDemo.java:14)
</code></pre>
<p>递归调用自身方法，不断向栈内压入栈帧，直到撑破栈空间，重复次数不确定</p>
<h3 id="outofmemoryerrorjava-heap-space">OutOfMemoryError：Java heap space</h3>
<pre><code class="language-java">/**
 * @author wuhao
 * @desc -Xmx10m -Xms10m -XX:+PrintGCDetails
 * 最大堆内存10M,初始堆内存10M,打印GC详细信息
 * @date 2021-09-10 15:14:50
 */
public class JavaHeapSpaceDemo {
    public static void main(String[] args) {
//        String str= &quot;java&quot;;
//        while (true){
//            str+=str+new Random().nextInt(111111)+new Random().nextInt(121312);
//            str.intern();
//        }
        //创建大对象
        byte[] bytes=new byte[20*1024*1024];
    }
}
</code></pre>
<pre><code class="language-java">Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space
	at com.example.interview.oom.JavaHeapSpaceDemo.main(JavaHeapSpaceDemo.java:18)
</code></pre>
<p>常量池，对象空间地址位于堆空间中，循环生成String或者生成超大对象会导致堆空间被占满溢出</p>
<h3 id="outofmemoryerrorgc-overhead-limit-exceeded">OutOfMemoryError：GC overhead limit exceeded</h3>
<pre><code class="language-java">/**
 * @author wuhao
 * @desc -Xmx20m -Xms10m -XX:+PrintGCDetails
 * 最大堆内存20M,初始堆内存10M,堆外内存(直接内存)5M,打印GC信息
 * GC overhead limit exceeded:超出GC开销限制
 * @date 2021-09-10 15:24:48
 */
public class GCOverHeadDemo {
    public static void main(String[] args) {
        int i=0;
        List&lt;String&gt; list=new ArrayList&lt;&gt;();
        while (true){
            list.add(String.valueOf(++i).intern());
        }
    }
}
</code></pre>
<pre><code class="language-java">[Full GC (Ergonomics) [PSYoungGen: 2560K-&gt;0K(4608K)] [ParOldGen: 13581K-&gt;818K(10752K)] 16141K-&gt;818K(15360K), [Metaspace: 3626K-&gt;3626K(1056768K)], 0.0078165 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] 
Heap
 PSYoungGen      total 4608K, used 219K [0x00000000ff980000, 0x0000000100000000, 0x0000000100000000)
  eden space 2560K, 8% used [0x00000000ff980000,0x00000000ff9b6f28,0x00000000ffc00000)
  from space 2048K, 0% used [0x00000000ffe00000,0x00000000ffe00000,0x0000000100000000)
  to   space 2048K, 0% used [0x00000000ffc00000,0x00000000ffc00000,0x00000000ffe00000)
 ParOldGen       total 10752K, used 818K [0x00000000fec00000, 0x00000000ff680000, 0x00000000ff980000)
  object space 10752K, 7% used [0x00000000fec00000,0x00000000fecccac0,0x00000000ff680000)
 Metaspace       used 3719K, capacity 4536K, committed 4864K, reserved 1056768K
  class space    used 406K, capacity 428K, committed 512K, reserved 1048576K
Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: GC overhead limit exceeded
	at java.lang.Integer.toString(Integer.java:401)
	at java.lang.String.valueOf(String.java:3099)
	at com.example.interview.oom.GCOverHeadDemo.main(GCOverHeadDemo.java:17)
</code></pre>
<p>最大堆内存要大于初始堆内存给GC创造条件，如果两值相等就没有重新分配堆空间操作会直接爆出Java heap space异常</p>
<h3 id="outofmemoryerrordirect-buffer-memory">OutOfMemoryError：Direct buffer memory</h3>
<pre><code class="language-java">import java.nio.ByteBuffer;
/**
 * @author wuhao
 * @desc -Xmx20m -Xms10m -XX:+PrintGCDetails -XX:MaxDirectMemorySize=5m
 * 最大堆内存20M,初始堆内存10M,堆外内存(直接内存)5M,打印GC信息
 * @date 2021-09-10 15:38:57
 */
public class DirectBufferMemoryDemo {
    public static void main(String[] args) {
        System.out.println(&quot;配置的DirectMemory&quot;+(sun.misc.VM.maxDirectMemory()/(double)1024/1024)+&quot;mb&quot;);
        ByteBuffer bf=ByteBuffer.allocateDirect(6*1024*1024);
    }
}
</code></pre>
<pre><code class="language-java">[GC (Allocation Failure) [PSYoungGen: 2048K-&gt;504K(2560K)] 2048K-&gt;758K(9728K), 0.0008256 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
配置的DirectMemory5.0mb
[GC (System.gc()) [PSYoungGen: 908K-&gt;504K(2560K)] 1162K-&gt;862K(9728K), 0.0009251 secs] [Times: user=0.06 sys=0.00, real=0.00 secs] 
[Full GC (System.gc()) [PSYoungGen: 504K-&gt;0K(2560K)] [ParOldGen: 358K-&gt;801K(7168K)] 862K-&gt;801K(9728K), [Metaspace: 3500K-&gt;3500K(1056768K)], 0.0046698 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] 
Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Direct buffer memory
	at java.nio.Bits.reserveMemory(Bits.java:694)
	at java.nio.DirectByteBuffer.&lt;init&gt;(DirectByteBuffer.java:123)
	at java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:311)
	at com.example.interview.oom.DirectBufferMemoryDemo.main(DirectBufferMemoryDemo.java:13)
Heap
 PSYoungGen      total 2560K, used 1068K [0x00000000ff980000, 0x00000000ffc80000, 0x0000000100000000)
  eden space 2048K, 52% used [0x00000000ff980000,0x00000000ffa8b200,0x00000000ffb80000)
  from space 512K, 0% used [0x00000000ffc00000,0x00000000ffc00000,0x00000000ffc80000)
  to   space 512K, 0% used [0x00000000ffb80000,0x00000000ffb80000,0x00000000ffc00000)
 ParOldGen       total 7168K, used 801K [0x00000000fec00000, 0x00000000ff300000, 0x00000000ff980000)
  object space 7168K, 11% used [0x00000000fec00000,0x00000000fecc86d0,0x00000000ff300000)
 Metaspace       used 4057K, capacity 4568K, committed 4864K, reserved 1056768K
  class space    used 446K, capacity 460K, committed 512K, reserved 1048576K
</code></pre>
<p>allocateDirect分配的字节缓冲区用中文叫做直接缓冲区（DirectByteBuffer），用allocate分配的ByteBuffer叫做堆字节缓冲区(HeapByteBuffer)..</p>
<p>其实根据类名就可以看出，HeapByteBuffer所创建的字节缓冲区就是在jvm堆中的，即内部所维护的java字节数组。而DirectByteBuffer是直接操作操作系统本地代码创建的内存缓冲数组（c、c++的数组）。</p>
<p>HeapByteBuffer底层其实是java的字节数组，而java字节数组是一个java对象，对象的内存是由jvm的堆进行管理的，那么不可避免的是GC时年轻代的eden、suvivor到老年代的各种复制以及回收。。。当字节数组比较小的时候还好说，如果是大对象，那么对于jvm的GC来说是一个很大的负担。。而使用DirectByteBuffer，则是把字节数组交给操作系统管理（堆外内存）</p>
<h3 id="outofmemoryerrorunable-to-create-to-native-thread">OutOfMemoryError：Unable to create to native thread</h3>
<pre><code class="language-java">public class UnableToCreateToNativeThreadDemo {
   
    public static void main(String[] args) {
        for (int i = 0; ; i++) {
            System.out.println(&quot;================ i=&quot; + i);
            new Thread(() -&gt; {
                try {
                    Thread.sleep(Integer.MAX_VALUE);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }, &quot;&quot; + i).start();
        }
    }
}
</code></pre>
<p>linux一般用户可以最大创建1024个线程，不要在电脑上随意尝试</p>
<h3 id="meta-space">meta space</h3>
<pre><code class="language-java">/**
 * @author wuhao
 * @desc -XX:MetaspaceSize=8m -XX:MaxMetaspaceSize=8m -XX:+PrintGCDetails
 * @date 2021-09-13 10:36:15
 */
public class MetaSpaceOOMDemo {
    static class OOMTest{

    }
    public static void main(String[] args) {
        int i=0;
        try {
            while (true){
                i++;
                Enhancer enhancer=new Enhancer();
                enhancer.setSuperclass(OOMTest.class);
                enhancer.setUseCache(false);
                enhancer.setCallback(new MethodInterceptor() {
                    @Override
                    public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable {
                        return methodProxy.invokeSuper(o,args);
                    }
                });
                enhancer.create();
            }
        }catch (Throwable e){
            System.out.println(&quot;=========&quot;+i+&quot;次后发生了异常&quot;);
        }

    }
}
</code></pre>
<pre><code class="language-java">[Full GC (Last ditch collection) [PSYoungGen: 0K-&gt;0K(116224K)] [ParOldGen: 2016K-&gt;2016K(225792K)] 2016K-&gt;2016K(342016K), [Metaspace: 9911K-&gt;9911K(1058816K)], 0.0093402 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] 
Heap
 PSYoungGen      total 116224K, used 3425K [0x00000000d6400000, 0x00000000de400000, 0x0000000100000000)
  eden space 115712K, 2% used [0x00000000d6400000,0x00000000d67584a0,0x00000000dd500000)
  from space 512K, 0% used [0x00000000de380000,0x00000000de380000,0x00000000de400000)
  to   space 5120K, 0% used [0x00000000dda00000,0x00000000dda00000,0x00000000ddf00000)
 ParOldGen       total 225792K, used 2016K [0x0000000082c00000, 0x0000000090880000, 0x00000000d6400000)
  object space 225792K, 0% used [0x0000000082c00000,0x0000000082df8128,0x0000000090880000)
 Metaspace       used 9942K, capacity 10090K, committed 10240K, reserved 1058816K
  class space    used 884K, capacity 913K, committed 1024K, reserved 1048576K
Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Metaspace
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[类加载]]></title>
        <id>https://tinaxiawuhao.github.io/post/DikSLfU_z/</id>
        <link href="https://tinaxiawuhao.github.io/post/DikSLfU_z/">
        </link>
        <updated>2021-09-09T05:41:07.000Z</updated>
        <content type="html"><![CDATA[<h2 id="类加载过程">类加载过程</h2>
<p>在java中编译并不进行链接工作，类型的加载、链接和初始化工作都是在jvm执行过程中进行的。在Java程序启动时，jvm通过加载指定的类，然后调用该类的main方法而启动。在JVM启动过程中， 外部class字节码文件会经过一系列过程转化为JVM中执行的数据，这一系列过程我们称为类加载过程。</p>
<h3 id="类加载整体流程">类加载整体流程</h3>
<p>从类被JVM加载到内存开始到卸载出内存为止，整个生命周期包括：加载、链接、初始化、使用和卸载五个过程。其中链接又包括验证、准备和解析三个过程。如下图所示：</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1619321177632.png" alt="" loading="lazy"></figure>
<h3 id="类加载时机">类加载时机</h3>
<p>java虚拟机规范通过对初始化阶段进行严格规定，来保证初始化的完成，而作为其之前的必须启动的过程，加载、验证、准备也需要在此之前开始。</p>
<p>Java虚拟机规定，以下五种情况必须对类进行初始化：</p>
<ol>
<li>
<p>虚拟机在用户指定包含main方法的主类后启动时，必须先对主类进行初始化。</p>
</li>
<li>
<p>当使用new关键字对类进行实例化时、读取或者写入类的静态字段时、调用类的静态方法时，必须先触发对该类的实例化。</p>
</li>
<li>
<p>使用反射对类进行反射调用时，如果该类没有初始化先对其进行初始化。</p>
</li>
<li>
<p>初始化一个类，而该类的父类还未初始化，需要先对其父类进行初始化。</p>
</li>
<li>
<p>在JDK1.7之后的版本中使用动态语言支持，java.lang.invoke.MethodHandle实例解析的结果是REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，而该句柄对应的类 还未初始化，必须先触发其实例化。</p>
</li>
</ol>
<h3 id="加载">加载</h3>
<p>在加载阶段，虚拟机需要完成三件事：</p>
<ol>
<li>
<p>通过一个类的全限定名来获取此类的class字节码二进制流。</p>
</li>
<li>
<p>将这个字节码二进制流中的静态存储结构转化为方法区中的运行时数据结构。</p>
</li>
<li>
<p>在内存中生成一个代表该类的java.lang.Class对象，作为方法区中这个类的各种数据的访问入口。</p>
</li>
</ol>
<p>对于Class对象，Java虚拟机规范并没有规定要存储在堆中，HotSpot虚拟机将其存放在方法区中。</p>
<h3 id="验证">验证</h3>
<p>验证作为链接的第一步，大致会完成四个阶段的检验：</p>
<ol>
<li>
<p>文件格式验证：该阶段主要在字节流转化为方法区中的运行时数据时，负责检查字节流是否符合Class文件规范，保证其可以正确的被解析并存储在方法区中。后面的检查都是基于方法区的 存储结构进行检验，不会再直接操作字节流。</p>
</li>
<li>
<p>元数据验证：该阶段负责分析存储于方法区的结构是否符合Java语言规范。此阶段进行数据类型的校验，保证符合不存在非法的元数据信息。</p>
</li>
<li>
<p>字节码验证：元数据验证保证了字节码中的数据符合语言的规范，该阶段则负责分析数据流和控制流，确定方法体的合法性，保证被校验的方法在运行时不会危害虚拟机的运行。</p>
</li>
<li>
<p>符号引用验证：在解析阶段会将虚拟机中的符号引用转化为直接引用，该阶段则负责对各种符号引用进行匹配性校验，保证外部依赖真实存在，并且符合外部依赖类、字段、方法的访问性。</p>
</li>
</ol>
<h3 id="准备">准备</h3>
<p>准备阶段正式为类的字段变量（被static修饰的类变量）分配内存并设置初始值。这些变量存储在方法区中。当类字段为常量类型（即被static final修饰），由于字段的值已经确定，并不会在后面修改，此时会直接赋值为指定的值。</p>
<h3 id="解析">解析</h3>
<p>解析阶段将常量池中的符号引用替换为直接引用。在字节码文件中，类、接口、字段、方法等类型都是由一组符号来表示。其形式由java虚拟机规范中的Class文件格式定义。在虚拟机执行 指定指令之前，需要将符号引用转化为目标的指针、相对偏移量或者句柄，这样可以通过此类直接引用在内存中定位调用的具体位置。</p>
<h3 id="初始化">初始化</h3>
<p>在类的class文件中。包含两个特殊的方法：clinit和init，这两方法由编译器自动生成，分别代表类构造器和构造函数，其中构造函数编程实现，初始化阶段就是负责调用类构造器，来初始化 变量和资源。</p>
<p>clinit方法由编译器自动收集类的赋值动作和静态语句块（static）中的语句合并生成的，有以下特点：</p>
<ol>
<li>
<p>编译器收集顺序又代码顺序决定，静态语句块只能访问它之前定义的变量，在它之后定义的变量只能进行赋值不能访问。</p>
</li>
<li>
<p>虚拟机保证在子类的clinit方法执行前，父类的clinit已经执行完毕。</p>
</li>
<li>
<p>clinit不是必须的，如果一个类或接口没有变量赋值和静态代码块，则编译器可以不生成clinit。</p>
</li>
<li>
<p>虚拟机会保证clinit方法在多线程中被正确的加锁和同步。如果多个线程同时初始化一个类，那么只有一个线程执行clinit，其他线程会被阻塞。</p>
</li>
</ol>
<h2 id="双亲委派模型">双亲委派模型</h2>
<h3 id="类加载器">类加载器</h3>
<ol>
<li>
<p>定义：实现类加载阶段的“通过一个里的全限定名来获取描述此类的二进制字节流”的动作的代码模块成为“类加载器”。对于任意一个类，都需要由加载它的类加载器和这个类本身一同确立其在java虚拟机中的唯一性，每一个类加载器，都拥有一个独立的类名称空间。比较两个类是否“相等”，只有在这两个类是同一个类加载器加载的前提下才有意义。</p>
</li>
<li>
<p>类加载器种类</p>
<p>从Java虚拟机的角度只有两种类加载器：</p>
<p>（1）启动类加载器（BootStrap ClassLoader），这个类加载器使用C++语言实现，是虚拟机自身的一部分。</p>
<p>（2）另一种就是所有其他类的加载器，这些类加载器都是由Java语言实现，独立于虚拟机外部，并且都继承自抽象类java.lang.ClassLoader。</p>
<p>从Java开发人员的角度，类加载器还可分为3种系统提供的类加载器和用户自定义的类加载器。</p>
<p>（1）启动类加载器（BootStrap ClassLoader）：负责加载存放java_home\lib目录中的，或者被-Xbootclasspath参数所指定的路径中的类。</p>
<p>（2）扩展类加载器（Extension ClassLoader）：这个加载器sun.misc.Launcher</p>
<p>ExtClassLoader实现，它负责加载java_home\lib\ext目录中的，或者被java.ext.dirs系统变量所指定的路径中的所有类库，开发者可以直接使用扩展类加载器。 如果应用程序中没有自定义的类加载器，一般情况下 这个就是程序中默认的类加载器。</p>
<p>（3）自定义类加载器（User ClassLoader）：用户自定义的类加载器。用户在编写自己定义的类加载器时，如果需要把请求委派给引导类加载器，那直接使用numm代替即可。要创建用户自己 的类加载器，只需要继承java.lang.ClassLoader，然后覆盖它的findClass(String name)方法即可。如果要符合双亲委派模型，则重写findClass()方法。如果要破坏的话，则重写 loadClass()方法。</p>
</li>
</ol>
<p><strong>双亲委派模型</strong></p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1619321193747.webp" alt="" loading="lazy"></figure>
<p>上图展示的类加载器之间的这种层次关系称为类加载器的双亲委派模型。</p>
<ol>
<li>
<p>双亲委派模型要求除了顶层的启动类加载器之外，其余的类加载器都应当有自己的父类加载器。</p>
</li>
<li>
<p>类加载器的双亲委派模型在jdk1.2被引入，但它不是一个强制性的约束模型，而是Java设计者推荐给开发者的一种类加载器的实现方式。</p>
</li>
</ol>
<p>双亲委派模型的工作过程如下：</p>
<ol>
<li>
<p>如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成。</p>
</li>
<li>
<p>每一层的类加载器都重复第一步，因此所有的类加载请求最终都传送到了顶层的类加载器中。</p>
</li>
<li>
<p>只有父类加载器返回自己无法完成这个加载请求，子加载器才会尝试自己去加载。</p>
</li>
</ol>
<h2 id="对象的创建-存储和访问">对象的创建、存储和访问</h2>
<h3 id="对象的创建">对象的创建</h3>
<ol>
<li>
<p>类加载检查：虚拟机遇到一条new指令，首先检查这个指令的参数是否能在常量池中（Class文件的静态常量池）定位到这个类的符号引用，并且检查这个符号引用代表的类是否 已经被加载、解析和初始化过。如果没有，那必须先执行相应的类加载过程。</p>
</li>
<li>
<p>分配内存：对象所需内存大小在类加载完成后便可完全确定，为对象分配空间的任务等同于把一块确定大小的内存从Java堆中划分出来。但是不同垃圾回收器的算法会导致堆内存存在两种情况：绝对规整和相互交错。（比如标记清楚算法和标记整理算法）</p>
<p>（1）指针碰撞：假设Java堆内存是绝对规整的，所有用过的内存都存放在一起，空闲的内存存放在另一边，中间放着一个指示器作为分界点的指示器，所分配的内存就仅仅是把那个指针向空闲空间那边挪动一段与对象大小相等的距离，这种分配方式成为”指针碰撞“。</p>
<p>（2）空闲列表：如果是相互交错的，那么虚拟机会维护一个列表，记录哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划给对象实例，并更新列表上的记录。这种分配方式成为”空闲列表“。</p>
</li>
<li>
<p>分配内存的并发问题：即使是仅仅修改一个指针所指向的位置，在并发情况下也不是线程安全的，可能出现正在给对象A分配内存，指针还没来得及修改，对象B又同时使用了原来的 指针来分配内存的情况。针对这个问题有两种解决方案：</p>
<p>（1）失败重试：对分配内存空间的动作进行同步处理，虚拟机采用CAS和失败重试机制保证更新操作的原子性。</p>
<p>（2）本地线程分配缓存：哪个线程要分配内存，就在哪个线程的TLAB（Thread Local Allocation Buffer）上分配，只有TLAB用完并分配新的TLAB时，才需要同步锁定。</p>
</li>
<li>
<p>内存空间初始化零值：内存分配完成后，虚拟机需要将分配到的内存空间都初始化零值，这一步操作保证了对象的实例字段（成员变量）在Java代码中可以不赋值就直接使用，程序能够访问到这些字段的数据类型所对应的零值。</p>
</li>
<li>
<p>对象设置：接下来虚拟机会对对象进行必要的设置，例如这个对象是哪个类的实例，如何才能找到类的元数据信息、对象的哈希吗、对象的GC分代年龄等信息。这些信息存放在对象头中。至此一个新的对象产生了。</p>
</li>
<li>
<p>实例构造器的init方法：虽然对象产生了，但是init方法并没有执行，所欲字段还需要赋值（包括成员变量赋值，普通语句块执行，构造函数执行等。）</p>
</li>
</ol>
<h3 id="clinit和init">Clinit和init</h3>
<h4 id="clinit">Clinit</h4>
<p>类构造器的方法，与类的初始化有关。例如静态变量（类变量）和静态对象赋值，静态语句块的执行。如果一个类中没有静态语句块，也没有静态变量或静态对象的赋值， 那么编译器可以不为这个类生成方法。</p>
<h4 id="init">init</h4>
<p>实例构造器（即成员变量，成员对象等），例如成员变量和成员对象的赋值，普通语句块的执行，构造函数的执行。</p>
<h3 id="对象的内存布局">对象的内存布局</h3>
<p>在HotSpot虚拟机中，对象在内存中存储的布局可以分为三个区域：对象头、实例数据和对齐填充。</p>
<h4 id="对象头">对象头</h4>
<p>对象头包括两部分信息：运行时数据和类型指针。</p>
<h4 id="运行时数据">运行时数据</h4>
<p>第一部分用于存储对象自身的运行时数据，如哈希吗（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等。<br>
<img src="https://tinaxiawuhao.github.io/post-images/1619321205464.webp" alt="" loading="lazy"></p>
<p>下面是HotSpot虚拟机对象头Mark Word：</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1619321212070.webp" alt="" loading="lazy"></figure>
<h4 id="类型指针">类型指针</h4>
<p>对象头的另一部分是类型指针，即对象指向他元数据的指针，虚拟机可以通过这个指针确定这个对象是哪个类的实例。但是如果对象是一个Java数组，那么在对象头中还必须有一块用于记录数据长度的数据。</p>
<h4 id="对象的实例数据">对象的实例数据</h4>
<p>接着数据头的是对象的实例数据，这部分是真正存储的有效信息。无论是从父类中继承下来的还是在子类中定义的，都需要记录下来。</p>
<h4 id="对齐填充">对齐填充</h4>
<p>最后一部分对齐填充并不是必然存在的，也没有特别的含义，仅仅起着占位符的作用。由于HotSpot虚拟机的自动内存管理系统要求对象的起始地址必须是8字节的整数倍，也就是 对象的大小必须是8字节的整数倍。而对象头部分是8字节的倍数，当实例数据没有对齐的时候，需要对齐填充凑够8字节的整数倍。</p>
<h4 id="对象的访问定位">对象的访问定位</h4>
<p>建立对象是为了使用对象，我们的Java程序需要通过栈上的引用数据来操作堆上的具体对象。对象的访问方式取决于虚拟机的实现，目前主流的访问方式有使用句柄和直接指针两种。</p>
<p>句柄引用和直接引用不同在于：使用句柄引用的话，那么Java对堆中将会划分出一块内存来作为句柄池，引用中存储的就是对象的句柄地址，但是直接引用引用中存储的直接就是对象地址。Java使用的是直接指针访问对象的方式，因为它最大的好处就是速度更快，它节省了一次指针定位的时间开销，由于对象的访问在Java中非常频繁，因此这类开销积少成多后也是一项 非常可观的执行成本。</p>
<p>下面是通过直接指针访问对象<br>
<img src="https://tinaxiawuhao.github.io/post-images/1619321218990.png" alt="" loading="lazy"></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[线程池ThreadPoolExecutor]]></title>
        <id>https://tinaxiawuhao.github.io/post/y8VkHlUlp/</id>
        <link href="https://tinaxiawuhao.github.io/post/y8VkHlUlp/">
        </link>
        <updated>2021-09-08T08:05:07.000Z</updated>
        <content type="html"><![CDATA[<h3 id="executors目前提供了5种不同的线程池创建配置">Executors目前提供了5种不同的线程池创建配置：</h3>
<ol>
<li>
<p>newCachedThreadPool（），它是用来处理大量短时间工作任务的线程池，具有几个鲜明特点：它会试图缓存线程并重用，当无缓存线程可用时，就会创建新的工作线程；如果线程闲置时间超过60秒，则被终止并移除缓存；长时间闲置时，这种线程池，不会消耗什么资源。其内部使用SynchronousQueue作为工作队列。</p>
</li>
<li>
<p>newFixedThreadPool（int nThreads），重用指定数目（nThreads）的线程，其背后使用的是无界的工作队列，任何时候最多有nThreads个工作线程是活动的。这意味着，如果任务数量超过了活动线程数目，将在工作队列中等待空闲线程出现；如果工作线程退出，将会有新的工作线程被创建，以补足指定数目nThreads。</p>
</li>
<li>
<p>newSingleThreadExecutor()，它的特点在于工作线程数目限制为1，操作一个无界的工作队列，所以它保证了所有的任务都是被顺序执行，最多会有一个任务处于活动状态，并且不予许使用者改动线程池实例，因此可以避免改变线程数目。</p>
</li>
<li>
<p>newSingleThreadScheduledExecutor()和newScheduledThreadPool(int corePoolSize)，创建的是个ScheduledExecutorService，可以进行定时或周期性的工作调度，区别在于单一工作线程还是多个工作线程。</p>
</li>
<li>
<p>newWorkStealingPool(int parallelism)，这是一个经常被人忽略的线程池，Java 8 才加入这个创建方法，其内部会构建<a href="https://docs.oracle.com/javase/9/docs/api/java/util/concurrent/ForkJoinPool.html">ForkJoinPool</a>，利用<a href="https://en.wikipedia.org/wiki/Work_stealing">Work-Stealing</a>算法，并行地处理任务，不保证处理顺序。</p>
</li>
</ol>
<pre><code class="language-java">public class MyThreadPool {
    public static void main(String[] args) {
//        ExecutorService executorService = Executors.newFixedThreadPool(5);
//        ExecutorService executorService= Executors.newSingleThreadExecutor();
//        ExecutorService executorService= Executors.newCachedThreadPool();
//        ExecutorService executorService= Executors.newScheduledThreadPool(5);

        ExecutorService executorService = new ThreadPoolExecutor(2,
                5,
                2,
                TimeUnit.SECONDS,
                new LinkedBlockingQueue&lt;Runnable&gt;(3),
                Executors.defaultThreadFactory(),
                new ThreadPoolExecutor.AbortPolicy()
        );
        ThreadPoolInit(executorService);
    }

    private static void ThreadPoolInit(ExecutorService executorService) {

        try {
            for (int i = 1; i &lt;= 10; i++) {
                executorService.execute(() -&gt; {
                    System.out.println(Thread.currentThread().getName() + &quot;办理业务&quot;);
                });
            }
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            executorService.shutdown();
        }
    }
}

</code></pre>
<h3 id="executor框架的基本组成">Executor框架的基本组成</h3>
<p><img src="https://tinaxiawuhao.github.io/post-images/1631088364651.png" alt="" loading="lazy"><br>
而我们创建时，一般使用它的子类：ThreadPoolExecutor.</p>
<pre><code class="language-java">public ThreadPoolExecutor(int corePoolSize,  
                              int maximumPoolSize,  
                              long keepAliveTime,  
                              TimeUnit unit,  
                              BlockingQueue&lt;Runnable&gt; workQueue,  
                              ThreadFactory threadFactory,  
                              RejectedExecutionHandler handler)
</code></pre>
<p>这是其中最重要的一个构造方法，这个方法决定了创建出来的线程池的各种属性，下面依靠一张图来更好的理解线程池和这几个参数：</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1631088504377.png" alt="" loading="lazy"></figure>
<p>（1）corePoolSize：线程池中常驻核心线程数</p>
<p>（2）maximumPoolSize：线程池能够容纳同时执行的最大线程数，此值必须大于等于1</p>
<p>（3）keepAliveTime：多余的空闲线程存活时间。当前线程池数量超过corePoolSize时，当空闲时间到达keepAliveTime值时，多余空闲线程会被销毁直到只剩下corePoolSize个线程为止。</p>
<p>（4）unit：keepAliveTime的时间单位</p>
<p>（5）workQueue：任务队列，被提交但尚未执行的任务</p>
<p>（6）threadFactory：表示生成线程池中的工作线程的线程工厂，用于创建线程，一般为默认线程工厂即可</p>
<p>（7）handler：拒绝策略，表示当队列满了并且工作线程大于等于线程池的最大线程数（maximumPoolSize）时如何来拒绝来请求的Runnable的策略</p>
<h3 id="handler的拒绝策略">handler的拒绝策略：</h3>
<p>有四种：</p>
<ol>
<li>第一种AbortPolicy:不执行新任务，直接抛出异常，提示线程池已满</li>
<li>第二种DisCardPolicy:不执行新任务，也不抛出异常</li>
<li>第三种DisCardOldSetPolicy:将消息队列中的第一个任务替换为当前新进来的任务执行</li>
<li>第四种CallerRunsPolicy:直接调用execute来执行当前任务</li>
</ol>
<h3 id="在spring项目中的使用">在spring项目中的使用</h3>
<p>先创建一个线程池的配置，让Spring Boot加载，用来定义如何创建一个<code>ThreadPoolTaskExecutor</code>，要使用<code>@Configuration</code>和@<code>EnableAsync</code>这两个注解，表示这是个配置类，并且是线程池的配置类</p>
<pre><code class="language-java">@Configuration
@EnableAsync
public class ExecutorConfig {

    private static final Logger logger = LoggerFactory.getLogger(ExecutorConfig.class);

    @Value(&quot;${async.executor.thread.core_pool_size}&quot;)
    private int corePoolSize;
    @Value(&quot;${async.executor.thread.max_pool_size}&quot;)
    private int maxPoolSize;
    @Value(&quot;${async.executor.thread.queue_capacity}&quot;)
    private int queueCapacity;
    @Value(&quot;${async.executor.thread.name.prefix}&quot;)
    private String namePrefix;

    @Bean(name = &quot;asyncServiceExecutor&quot;)
    public Executor asyncServiceExecutor() {
        logger.info(&quot;start asyncServiceExecutor&quot;);
        ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();
        //配置核心线程数
        executor.setCorePoolSize(corePoolSize);
        //配置最大线程数
        executor.setMaxPoolSize(maxPoolSize);
        //配置队列大小
        executor.setQueueCapacity(queueCapacity);
        //配置线程池中的线程的名称前缀
        executor.setThreadNamePrefix(namePrefix);

        // rejection-policy：当pool已经达到max size的时候，如何处理新任务
        // CALLER_RUNS：不在新线程中执行任务，而是有调用者所在的线程来执行
        executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy());
        //执行初始化
        executor.initialize();
        return executor;
    }
}
</code></pre>
<p><code>@Value</code>是我配置在<code>application.properties</code>，可以参考配置，自由定义</p>
<pre><code class="language-xml"># 异步线程配置
# 配置核心线程数
async.executor.thread.core_pool_size = 5
# 配置最大线程数
async.executor.thread.max_pool_size = 5
# 配置队列大小
async.executor.thread.queue_capacity = 99999
# 配置线程池中的线程的名称前缀
async.executor.thread.name.prefix = async-service-
</code></pre>
<p>创建一个Service接口，是异步线程的接口</p>
<pre><code class="language-java">public interface AsyncService {

    /** * 执行异步任务 * 可以根据需求，自己加参数拟定，我这里就做个测试演示 */
    void executeAsync();
}
</code></pre>
<p>实现类</p>
<pre><code class="language-java">@Service
public class AsyncServiceImpl implements AsyncService {

    private static final Logger logger = LoggerFactory.getLogger(AsyncServiceImpl.class);

    @Override
    @Async(&quot;asyncServiceExecutor&quot;)
    public void executeAsync() {
        logger.info(&quot;start executeAsync&quot;);

        System.out.println(&quot;异步线程要做的事情&quot;);
        System.out.println(&quot;可以在这里执行批量插入等耗时的事情&quot;);

        logger.info(&quot;end executeAsync&quot;);
    }
}
</code></pre>
<p>将Service层的服务异步化，在<code>executeAsync()</code>方法上增加注解<code>@Async(&quot;asyncServiceExecutor&quot;)</code>，<code>asyncServiceExecutor</code>方法是前面<strong>ExecutorConfig.java</strong> 中的方法名，表明<code>executeAsync</code>方法进入的线程池是<code>asyncServiceExecutor</code>方法创建的</p>
<p>接下来就是在Controller里或者是哪里通过注解<code>@Autowired</code>注入这个Service</p>
<pre><code class="language-java">@Autowired
private AsyncService asyncService;

@GetMapping(&quot;/async&quot;)
public void async(){
    asyncService.executeAsync();
}
</code></pre>
<p><strong>用postmain或者其他工具来多次测试请求一下</strong></p>
<pre><code class="language-java"> 2018-07-16 22:15:47.655  INFO 10516 --- [async-service-5] c.u.d.e.executor.impl.AsyncServiceImpl   : start executeAsync
异步线程要做的事情
可以在这里执行批量插入等耗时的事情
2018-07-16 22:15:47.655  INFO 10516 --- [async-service-5] c.u.d.e.executor.impl.AsyncServiceImpl   : end executeAsync
2018-07-16 22:15:47.770  INFO 10516 --- [async-service-1] c.u.d.e.executor.impl.AsyncServiceImpl   : start executeAsync
异步线程要做的事情
可以在这里执行批量插入等耗时的事情
2018-07-16 22:15:47.770  INFO 10516 --- [async-service-1] c.u.d.e.executor.impl.AsyncServiceImpl   : end executeAsync
2018-07-16 22:15:47.816  INFO 10516 --- [async-service-2] c.u.d.e.executor.impl.AsyncServiceImpl   : start executeAsync
异步线程要做的事情
可以在这里执行批量插入等耗时的事情
2018-07-16 22:15:47.816  INFO 10516 --- [async-service-2] c.u.d.e.executor.impl.AsyncServiceImpl   : end executeAsync
2018-07-16 22:15:48.833  INFO 10516 --- [async-service-3] c.u.d.e.executor.impl.AsyncServiceImpl   : start executeAsync
异步线程要做的事情
可以在这里执行批量插入等耗时的事情
2018-07-16 22:15:48.834  INFO 10516 --- [async-service-3] c.u.d.e.executor.impl.AsyncServiceImpl   : end executeAsync
2018-07-16 22:15:48.986  INFO 10516 --- [async-service-4] c.u.d.e.executor.impl.AsyncServiceImpl   : start executeAsync
异步线程要做的事情
可以在这里执行批量插入等耗时的事情
2018-07-16 22:15:48.987  INFO 10516 --- [async-service-4] c.u.d.e.executor.impl.AsyncServiceImpl   : end executeAsync
</code></pre>
<p>通过以上日志可以发现，<code>[async-service-]</code>是有多个线程的，显然已经在我们配置的线程池中执行了，并且每次请求中，controller的起始和结束日志都是连续打印的，表明每次请求都快速响应了，而耗时的操作都留给线程池中的线程去异步执行；</p>
<p>虽然我们已经用上了线程池，但是还不清楚线程池当时的情况，有多少线程在执行，多少在队列中等待呢？这里我创建了一个ThreadPoolTaskExecutor的子类，在每次提交线程的时候都会将当前线程池的运行状况打印出来</p>
<pre><code class="language-java">import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor;
import org.springframework.util.concurrent.ListenableFuture;

import java.util.concurrent.Callable;
import java.util.concurrent.Future;
import java.util.concurrent.ThreadPoolExecutor;

/** * @Author: ChenBin * @Date: 2018/7/16/0016 22:19 */
public class VisiableThreadPoolTaskExecutor extends ThreadPoolTaskExecutor {


    private static final Logger logger = LoggerFactory.getLogger(VisiableThreadPoolTaskExecutor.class);

    private void showThreadPoolInfo(String prefix) {
        ThreadPoolExecutor threadPoolExecutor = getThreadPoolExecutor();

        if (null == threadPoolExecutor) {
            return;
        }

        logger.info(&quot;{}, {},taskCount [{}], completedTaskCount [{}], activeCount [{}], queueSize [{}]&quot;,
                this.getThreadNamePrefix(),
                prefix,
                threadPoolExecutor.getTaskCount(),
                threadPoolExecutor.getCompletedTaskCount(),
                threadPoolExecutor.getActiveCount(),
                threadPoolExecutor.getQueue().size());
    }

    @Override
    public void execute(Runnable task) {
        showThreadPoolInfo(&quot;1. do execute&quot;);
        super.execute(task);
    }

    @Override
    public void execute(Runnable task, long startTimeout) {
        showThreadPoolInfo(&quot;2. do execute&quot;);
        super.execute(task, startTimeout);
    }

    @Override
    public Future&lt;?&gt; submit(Runnable task) {
        showThreadPoolInfo(&quot;1. do submit&quot;);
        return super.submit(task);
    }

    @Override
    public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) {
        showThreadPoolInfo(&quot;2. do submit&quot;);
        return super.submit(task);
    }

    @Override
    public ListenableFuture&lt;?&gt; submitListenable(Runnable task) {
        showThreadPoolInfo(&quot;1. do submitListenable&quot;);
        return super.submitListenable(task);
    }

    @Override
    public &lt;T&gt; ListenableFuture&lt;T&gt; submitListenable(Callable&lt;T&gt; task) {
        showThreadPoolInfo(&quot;2. do submitListenable&quot;);
        return super.submitListenable(task);
    }
}
</code></pre>
<p>如上所示，showThreadPoolInfo方法中将任务总数、已完成数、活跃线程数，队列大小都打印出来了，然后Override了父类的execute、submit等方法，在里面调用showThreadPoolInfo方法，这样每次有任务被提交到线程池的时候，都会将当前线程池的基本情况打印到日志中；</p>
<p>修改<code>ExecutorConfig.java</code>的<code>asyncServiceExecutor</code>方法，将<code>ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor()</code>改为<code>ThreadPoolTaskExecutor executor = new VisiableThreadPoolTaskExecutor()</code></p>
<pre><code class="language-java">@Bean(name = &quot;asyncServiceExecutor&quot;)
    public Executor asyncServiceExecutor() {
        logger.info(&quot;start asyncServiceExecutor&quot;);
        //在这里修改
        ThreadPoolTaskExecutor executor = new VisiableThreadPoolTaskExecutor();
        //配置核心线程数
        executor.setCorePoolSize(corePoolSize);
        //配置最大线程数
        executor.setMaxPoolSize(maxPoolSize);
        //配置队列大小
        executor.setQueueCapacity(queueCapacity);
        //配置线程池中的线程的名称前缀
        executor.setThreadNamePrefix(namePrefix);

        // rejection-policy：当pool已经达到max size的时候，如何处理新任务
        // CALLER_RUNS：不在新线程中执行任务，而是有调用者所在的线程来执行
        executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy());
        //执行初始化
        executor.initialize();
        return executor;
    }
</code></pre>
<p>再次启动该工程测试</p>
<pre><code class="language-java">2018-07-16 22:23:30.951  INFO 14088 --- [nio-8087-exec-2] u.d.e.e.i.VisiableThreadPoolTaskExecutor : async-service-, 2. do submit,taskCount [0], completedTaskCount [0], activeCount [0], queueSize [0]
2018-07-16 22:23:30.952  INFO 14088 --- [async-service-1] c.u.d.e.executor.impl.AsyncServiceImpl   : start executeAsync
异步线程要做的事情
可以在这里执行批量插入等耗时的事情
2018-07-16 22:23:30.953  INFO 14088 --- [async-service-1] c.u.d.e.executor.impl.AsyncServiceImpl   : end executeAsync
2018-07-16 22:23:31.351  INFO 14088 --- [nio-8087-exec-3] u.d.e.e.i.VisiableThreadPoolTaskExecutor : async-service-, 2. do submit,taskCount [1], completedTaskCount [1], activeCount [0], queueSize [0]
2018-07-16 22:23:31.353  INFO 14088 --- [async-service-2] c.u.d.e.executor.impl.AsyncServiceImpl   : start executeAsync
异步线程要做的事情
可以在这里执行批量插入等耗时的事情
2018-07-16 22:23:31.353  INFO 14088 --- [async-service-2] c.u.d.e.executor.impl.AsyncServiceImpl   : end executeAsync
2018-07-16 22:23:31.927  INFO 14088 --- [nio-8087-exec-5] u.d.e.e.i.VisiableThreadPoolTaskExecutor : async-service-, 2. do submit,taskCount [2], completedTaskCount [2], activeCount [0], queueSize [0]
2018-07-16 22:23:31.929  INFO 14088 --- [async-service-3] c.u.d.e.executor.impl.AsyncServiceImpl   : start executeAsync
异步线程要做的事情
可以在这里执行批量插入等耗时的事情
2018-07-16 22:23:31.930  INFO 14088 --- [async-service-3] c.u.d.e.executor.impl.AsyncServiceImpl   : end executeAsync
2018-07-16 22:23:32.496  INFO 14088 --- [nio-8087-exec-7] u.d.e.e.i.VisiableThreadPoolTaskExecutor : async-service-, 2. do submit,taskCount [3], completedTaskCount [3], activeCount [0], queueSize [0]
2018-07-16 22:23:32.498  INFO 14088 --- [async-service-4] c.u.d.e.executor.impl.AsyncServiceImpl   : start executeAsync
异步线程要做的事情
可以在这里执行批量插入等耗时的事情
2018-07-16 22:23:32.499  INFO 14088 --- [async-service-4] c.u.d.e.executor.impl.AsyncServiceImpl   : end executeAsync
</code></pre>
<p>注意这一行日志：</p>
<pre><code class="language-java">2018-07-16 22:23:32.496  INFO 14088 --- [nio-8087-exec-7] u.d.e.e.i.VisiableThreadPoolTaskExecutor : async-service-, 2. do submit,taskCount [3], completedTaskCount [3], activeCount [0], queueSize [0]
</code></pre>
<p>这说明提交任务到线程池的时候，调用的是submit(Callable task)这个方法，当前已经提交了3个任务，完成了3个，当前有0个线程在处理任务，还剩0个任务在队列中等待，线程池的基本情况一路了然</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[手写一个生产者消费者模式]]></title>
        <id>https://tinaxiawuhao.github.io/post/5QxJ3UtmK/</id>
        <link href="https://tinaxiawuhao.github.io/post/5QxJ3UtmK/">
        </link>
        <updated>2021-09-08T07:46:13.000Z</updated>
        <content type="html"><![CDATA[<pre><code class="language-java">import lombok.SneakyThrows;
import org.springframework.util.StringUtils;

import java.util.concurrent.ArrayBlockingQueue;
import java.util.concurrent.BlockingQueue;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicInteger;

class MyResource {
    private volatile Boolean FLAG = true;
    private final AtomicInteger atomicInteger = new AtomicInteger();
    BlockingQueue&lt;String&gt; blockingQueue = null;

    public MyResource(BlockingQueue&lt;String&gt; blockingQueue) {
        this.blockingQueue = blockingQueue;
        System.out.println(blockingQueue.getClass().getName());
    }

    @SneakyThrows
    public void myProd() {
        String data = null;
        while (FLAG) {
            data = String.valueOf(atomicInteger.incrementAndGet());
            if (blockingQueue.offer(data, 2L, TimeUnit.SECONDS)) {
                System.out.println(Thread.currentThread().getName() + &quot;插入数据&quot; + data + &quot;成功&quot;);
            } else {
                System.out.println(Thread.currentThread().getName() + &quot;插入数据&quot; + data + &quot;失败&quot;);
            }
            TimeUnit.SECONDS.sleep(1L);
        }
        System.out.println(Thread.currentThread().getName() + &quot;生产停止&quot;);
    }

    @SneakyThrows
    public void myConsumer() {
        String result = null;
        while (FLAG) {
            result = blockingQueue.poll(2L, TimeUnit.SECONDS);
            if (StringUtils.isEmpty(result)) {
                FLAG = false;
                System.out.println(Thread.currentThread().getName() + &quot;超过2秒没有取到值，结束&quot;);
                return;
            }
            System.out.println(Thread.currentThread().getName() + &quot;消费数据&quot; + result + &quot;成功&quot;);
        }
    }

    public void stop(){
        FLAG=false;
    }
}

public class ProdConsumer_BlockQueue {

    @SneakyThrows
    public static void main(String[] args) {
        MyResource myResource = new MyResource(new ArrayBlockingQueue&lt;&gt;(10));
        new Thread(() -&gt; {
            System.out.println(Thread.currentThread().getName() + &quot;生产线程启动&quot;);
            myResource.myProd();
        }, &quot;Prod&quot;).start();

        new Thread(() -&gt; {
            System.out.println(Thread.currentThread().getName() + &quot;消费线程启动&quot;);
            myResource.myConsumer();
        }, &quot;Consumer&quot;).start();

        TimeUnit.SECONDS.sleep(5L);
        System.out.println(&quot;5秒时间到，结束&quot;);
        myResource.stop();
    }


}
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1631087515332.png" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[阻塞队列BlockingQueue]]></title>
        <id>https://tinaxiawuhao.github.io/post/volSqv4Kf/</id>
        <link href="https://tinaxiawuhao.github.io/post/volSqv4Kf/">
        </link>
        <updated>2021-09-08T07:40:12.000Z</updated>
        <content type="html"><![CDATA[<h2 id="为什么要使用阻塞队列">为什么要使用阻塞队列</h2>
<p>之前，介绍了一下 ThreadPoolExecutor 的各参数的含义（<a href="https://tianxiawuhao.github.io/post/y8VkHlUlp">线程池ThreadPoolExecutor</a>），其中有一个 BlockingQueue，它是一个阻塞队列。那么，小伙伴们有没有想过，为什么此处的线程池要用阻塞队列呢？</p>
<p>我们知道队列是先进先出的。当放入一个元素的时候，会放在队列的末尾，取出元素的时候，会从队头取。那么，当队列为空或者队列满的时候怎么办呢。</p>
<p>这时，阻塞队列，会自动帮我们处理这种情况。</p>
<p>当阻塞队列为空的时候，从队列中取元素的操作就会被阻塞。当阻塞队列满的时候，往队列中放入元素的操作就会被阻塞。</p>
<p>而后，一旦空队列有数据了，或者满队列有空余位置时，被阻塞的线程就会被自动唤醒。</p>
<p>这就是阻塞队列的好处，你不需要关心线程何时被阻塞，也不需要关心线程何时被唤醒，一切都由阻塞队列自动帮我们完成。我们只需要关注具体的业务逻辑就可以了。</p>
<p>而这种阻塞队列经常用在生产者消费者模式中。（可参看：<a href="https://tianxiawuhao.github.io/post/5QxJ3UtmK">手写一个生产者消费者模式</a>）</p>
<h2 id="常用的阻塞队列">常用的阻塞队列</h2>
<p>那么，一般我们用到的阻塞队列有哪些呢。下面，通过idea的类图，列出来常用的阻塞队列，然后一个一个讲解（不懂怎么用的，可以参考这篇文章：<a href="https://blog.csdn.net/qq_26542493/article/details/104512954">怎么用IDEA快速查看类图关系</a>）。</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1631086948386.jpg" alt="" loading="lazy"></figure>
<p>阻塞队列中，所有常用的方法都在 BlockingQueue 接口中定义。如</p>
<p>插入元素的方法： put，offer，add。移除元素的方法： remove，poll，take。</p>
<p>它们有四种不同的处理方式，第一种是在失败时抛出异常，第二种是在失败时返回特殊值，第三种是一直阻塞当前线程，最后一种是在指定时间内阻塞，否则返回特殊值。（以上特殊值，是指在插入元素时，失败返回false，在取出元素时，失败返回null）</p>
<table>
<thead>
<tr>
<th></th>
<th>抛异常</th>
<th>特殊值</th>
<th>阻塞</th>
<th>超时</th>
</tr>
</thead>
<tbody>
<tr>
<td>插入</td>
<td>add(e)</td>
<td>offer(e)</td>
<td>put(e)</td>
<td>offer(e,time,unit)</td>
</tr>
<tr>
<td>移除</td>
<td>remove()</td>
<td>poll()</td>
<td>take()</td>
<td>poll(time,unit)</td>
</tr>
</tbody>
</table>
<p><strong>1） ArrayBlockingQueue</strong></p>
<p>这是一个由数组结构组成的有界阻塞队列。首先看下它的构造方法，有三个。</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1631086962267.jpg" alt="" loading="lazy"></figure>
<p>第一个可以指定队列的大小，第二个还可以指定队列是否公平，不指定的话，默认是非公平。它是使用 ReentrantLock 的公平锁和非公平锁实现的（后续讲解AQS时，会详细说明）。</p>
<p>简单理解就是，ReentrantLock 内部会维护一个有先后顺序的等待队列，假如有五个任务一起过来，都被阻塞了。如果是公平的，则等待队列中等待最久的任务就会先进入阻塞队列。如果是非公平的，那么这五个线程就需要抢锁，谁先抢到，谁就先进入阻塞队列。</p>
<p>第三个构造方法，是把一个集合的元素初始化到阻塞队列中。</p>
<p>另外，ArrayBlockingQueue 没有实现读写分离，也就是说，读和写是不能同时进行的。因为，它读写时用的是同一把锁，如下图所示：</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1631086978381.jpg" alt="" loading="lazy"></figure>
<p><strong>2) LinkedBlockingQueue</strong></p>
<p>这是一个由链表结构组成的有界阻塞队列。它的构造方法有三个。</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1631086987611.jpg" alt="" loading="lazy"></figure>
<p>可以看到和 ArrayBlockingQueue 的构造方法大同小异，不过是，LinkedBlockingQueue 可以不指定队列的大小，默认值是 Integer.MAX_VALUE 。</p>
<p>但是，最好不要这样做，建议指定一个固定大小。因为，如果生产者的速度比消费者的速度大的多的情况下，这会导致阻塞队列一直膨胀，直到系统内存被耗尽（此时，还没达到队列容量的最大值）。</p>
<p>此外，LinkedBlockingQueue 实现了读写分离，可以实现数据的读和写互不影响，这在高并发的场景下，对于效率的提高无疑是非常巨大的。</p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1631086997560.jpg" alt="" loading="lazy"></figure>
<p><strong>3） SynchronousQueue</strong></p>
<p>这是一个没有缓冲的无界队列。什么意思，看一下它的 size 方法：</p>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1631087010961.jpg" alt="" loading="lazy"></figure>
<p>总是返回 0 ，因为它是一个没有容量的队列。</p>
<p>当执行插入元素的操作时，必须等待一个取出操作。也就是说，put元素的时候，必须等待 take 操作。</p>
<p>那么，有的同学就好奇了，这没有容量，还叫什么队列啊，这有什么意义呢。</p>
<p>我的理解是，这适用于并发任务不大，而且生产者和消费者的速度相差不多的场景下，直接把生产者和消费者对接，不用经过队列的入队出队这一系列操作。所以，效率上会高一些。</p>
<p>可以去查看一下 Excutors.newCachedThreadPool 方法用的就是这种队列。</p>
<p>这个队列有两个构造方法，用于传入是公平还是非公平，默认是非公平。</p>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1631087023429.jpg" alt="" loading="lazy"></figure>
<p><strong>4）PriorityBlockingQueue</strong></p>
<p>这是一个支持优先级排序的无界队列。有四个构造方法：</p>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1631087030940.jpg" alt="" loading="lazy"></figure>
<p>可以指定初始容量大小（注意初始容量并不代表最大容量），或者不指定，默认大小为 11。也可以传入一个比较器，把元素按一定的规则排序，不指定比较器的话，默认是自然顺序。</p>
<p>PriorityBlockingQueue 是基于二叉树最小堆实现的，每当取元素的时候，就会把优先级最高的元素取出来。我们测试一下：</p>
<pre><code class="language-java">public class Person {
    private int id;
    private String name;

    public int getId() {
        return id;
    }

    public void setId(int id) {
        this.id = id;
    }

    public String getName() {
        return name;
    }

    public void setName(String name) {
        this.name = name;
    }

    @Override
    public String toString() {
        return &quot;Person{&quot; +
                &quot;id=&quot; + id +
                &quot;, name='&quot; + name + '\'' +
                '}';
    }

    public Person(int id, String name) {
        this.id = id;
        this.name = name;
    }

    public Person() {
    }
}

public class QueueTest {
    public static void main(String[] args) throws InterruptedException {

        PriorityBlockingQueue&lt;Person&gt; priorityBlockingQueue = new PriorityBlockingQueue&lt;&gt;(1, new Comparator&lt;Person&gt;() {
            @Override
            public int compare(Person o1, Person o2) {
                return o1.getId() - o2.getId();
            }
        });

        Person p2 = new Person(7, &quot;李四&quot;);
        Person p1 = new Person(9, &quot;张三&quot;);
        Person p3 = new Person(6, &quot;王五&quot;);
        Person p4 = new Person(2, &quot;赵六&quot;);
        priorityBlockingQueue.add(p1);
        priorityBlockingQueue.add(p2);
        priorityBlockingQueue.add(p3);
        priorityBlockingQueue.add(p4);

		//由于二叉树最小堆实现，用这种方式直接打印元素，不能保证有序
        System.out.println(priorityBlockingQueue);
        System.out.println(priorityBlockingQueue.take());
        System.out.println(priorityBlockingQueue);
        System.out.println(priorityBlockingQueue.take());
        System.out.println(priorityBlockingQueue);

    }
}
</code></pre>
<p>打印结果：</p>
<pre><code class="language-json">[Person{id=2, name='赵六'}, Person{id=6, name='王五'}, Person{id=7, name='李四'}, Person{id=9, name='张三'}]
Person{id=2, name='赵六'}
[Person{id=6, name='王五'}, Person{id=9, name='张三'}, Person{id=7, name='李四'}]
Person{id=6, name='王五'}
[Person{id=7, name='李四'}, Person{id=9, name='张三'}]
</code></pre>
<p>可以看到，第一次取出的是 id 最小值 2， 第二次取出的是 6 。</p>
<p><strong>5）DelayQueue</strong></p>
<p>这是一个带有延迟时间的无界阻塞队列。队列中的元素，只有等延时时间到了，才能取出来。此队列一般用于过期数据的删除，或任务调度。以下，模拟一下定长时间的数据删除。</p>
<p>首先定义数据元素，需要实现 Delayed 接口，实现 getDelay 方法用于计算剩余时间，和 CompareTo方法用于优先级排序。</p>
<pre><code class="language-java">public class DelayData implements Delayed {

    private int id;
    private String name;
    //数据到期时间
    private long endTime;
    private TimeUnit timeUnit = TimeUnit.MILLISECONDS;

    public int getId() {
        return id;
    }

    public void setId(int id) {
        this.id = id;
    }

    public String getName() {
        return name;
    }

    public void setName(String name) {
        this.name = name;
    }

    public long getEndTime() {
        return endTime;
    }

    public void setEndTime(long endTime) {
        this.endTime = endTime;
    }

    public DelayData(int id, String name, long endTime) {
        this.id = id;
        this.name = name;
        //需要把传入的时间endTime 加上当前系统时间，作为数据的到期时间
        this.endTime = endTime + System.currentTimeMillis();
    }

    public DelayData() {
    }

    @Override
    public long getDelay(TimeUnit unit) {
        return this.endTime - System.currentTimeMillis();
    }

    @Override
    public int compareTo(Delayed o) {
        return o.getDelay(this.timeUnit) - this.getDelay(this.timeUnit) &lt; 0 ? 1: -1;
    }

}
</code></pre>
<p>模拟三条数据，分别设置不同的过期时间：</p>
<pre><code class="language-java">public class ProcessData {
    public static void main(String[] args) throws InterruptedException {
        DelayQueue&lt;DelayData&gt; delayQueue = new DelayQueue&lt;&gt;();

        DelayData a = new DelayData(5, &quot;A&quot;, 5000);
        DelayData b = new DelayData(8, &quot;B&quot;, 8000);
        DelayData c = new DelayData(2, &quot;C&quot;, 2000);

        delayQueue.add(a);
        delayQueue.add(b);
        delayQueue.add(c);

        System.out.println(&quot;开始计时时间:&quot; + System.currentTimeMillis());
        for (int i = 0; i &lt; 3; i++) {
            DelayData data = delayQueue.take();
            System.out.println(&quot;id:&quot;+data.getId()+&quot;，数据:&quot;+data.getName()+&quot;被移除，当前时间:&quot;+System.currentTimeMillis());
        }
    }
}
</code></pre>
<p>最后结果：</p>
<pre><code class="language-json">开始计时时间:1583333583216
id:2，数据:C被移除，当前时间:1583333585216
id:5，数据:A被移除，当前时间:1583333588216
id:8，数据:B被移除，当前时间:1583333591216
</code></pre>
<p>可以看到，数据是按过期时间长短，按顺序移除的。C的时间最短 2 秒，然后过了 3 秒 A 也过期，再过 3 秒，B 过期。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Redis的缓存淘汰策略LRU]]></title>
        <id>https://tinaxiawuhao.github.io/post/bGEB86JC1/</id>
        <link href="https://tinaxiawuhao.github.io/post/bGEB86JC1/">
        </link>
        <updated>2021-09-03T08:38:27.000Z</updated>
        <content type="html"><![CDATA[<p>redis缓存淘汰策略与Redis键的过期删除策略并不完全相同，前者是在Redis内存使用超过一定值的时候（一般这个值可以配置）使用的淘汰策略；而后者是通过定期删除+惰性删除两者结合的方式进行内存淘汰的。</p>
<h3 id="redis内存不足的缓存淘汰策略">Redis内存不足的缓存淘汰策略</h3>
<ul>
<li>noeviction：当内存使用超过配置的时候会返回错误，不会驱逐任何键</li>
<li>allkeys-lru：加入键的时候，如果过限，首先通过LRU算法驱逐最久没有使用的键</li>
<li>volatile-lru：加入键的时候如果过限，首先从设置了过期时间的键集合中驱逐最久没有使用的键</li>
<li>allkeys-random：加入键的时候如果过限，从所有key随机删除</li>
<li>volatile-random：加入键的时候如果过限，从过期键的集合中随机驱逐</li>
<li>volatile-ttl：从配置了过期时间的键中驱逐马上就要过期的键</li>
<li>volatile-lfu：从所有配置了过期时间的键中驱逐使用频率最少的键</li>
<li>allkeys-lfu：从所有键中驱逐使用频率最少的键</li>
</ul>
<h3 id="lru算法实现">lru算法实现</h3>
<h4 id="取巧算法">取巧算法</h4>
<pre><code class="language-java">
import java.util.LinkedHashMap;
import java.util.Map;

class LRUCache&lt;K,V&gt; extends LinkedHashMap&lt;K,V&gt; {

    private int capacity;

    /**
     * the ordering mode
     * - &lt;tt&gt;true&lt;/tt&gt; for access-order,
     * - &lt;tt&gt;false&lt;/tt&gt; for insertion-order
     * @param capacity
     */
    public LRUCache(int capacity) {
        super(capacity, 0.75F, true);
        this.capacity = capacity;
    }

    //数据超过容量大小删除
    @Override
    protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) {
        return super.size()&gt;capacity;
    }

}
</code></pre>
<h4 id="数据结构实现">数据结构实现</h4>
<pre><code class="language-java">
import java.util.HashMap;
import java.util.Map;

class LRUCacheDemo {

    //构建承载体node
    class Node&lt;K, V&gt; {
        K key;
        V value;
        Node&lt;K, V&gt; prev;
        Node&lt;K, V&gt; next;

        public Node() {
            this.prev = this.next = null;
        }

        public Node(K key, V value) {
            this.key = key;
            this.value = value;
            this.prev = this.next = null;
        }
    }

    //构建双向队列
    class DoubleLinkedList&lt;K, V&gt; {
        Node&lt;K, V&gt; head;
        Node&lt;K, V&gt; tail;

        public DoubleLinkedList() {
            head = new Node&lt;&gt;();
            tail = new Node&lt;&gt;();
            head.next = tail;
            tail.prev = head;
        }

        //添加头节点
        public void addHead(Node&lt;K, V&gt; node) {
            node.next = head.next;
            node.prev = head;
            head.next.prev = node;
            head.next = node;
        }

        //删除节点
        public void removeNode(Node&lt;K, V&gt; node) {
            node.next.prev = node.prev;
            node.prev.next = node.next;
            node.prev = null;
            node.next = null;
        }

        //获取最后一个节点
        public Node getLast() {
            return tail.prev;
        }
    }

    private int cacheSize;
    Map&lt;Object, Node&lt;Object, Object&gt;&gt; map;
    DoubleLinkedList&lt;Object, Object&gt; doubleLinkedList;

    public LRUCacheDemo(int cacheSize) {
        this.cacheSize = cacheSize;
        this.map = new HashMap&lt;&gt;();
        this.doubleLinkedList = new DoubleLinkedList&lt;&gt;();
    }

    public Object get(Object key) {
        if (!map.containsKey(key)) {
            return -1;
        }
        final Node&lt;Object, Object&gt; node = map.get(key);
        this.doubleLinkedList.removeNode(node);
        this.doubleLinkedList.addHead(node);
        return node.value;
    }

    public void put(Object key, Object value) {
        if (map.containsKey(key)) {
            final Node&lt;Object, Object&gt; node = map.get(key);
            node.value = value;
            map.put(key, node);
            this.doubleLinkedList.removeNode(node);
            this.doubleLinkedList.addHead(node);
        }else{
            if(map.size()==this.cacheSize){
                final Node last = this.doubleLinkedList.getLast();
                map.remove(last.key);
                doubleLinkedList.removeNode(last);
            }
            //新增
            Node&lt;Object,Object&gt; newNode=new Node&lt;&gt;(key,value);
            map.put(key, newNode);
            this.doubleLinkedList.addHead(newNode);
        }
    }

}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[list、set、map等集合类线程不安全的问题及解决方法]]></title>
        <id>https://tinaxiawuhao.github.io/post/GALzQf_b-/</id>
        <link href="https://tinaxiawuhao.github.io/post/GALzQf_b-/">
        </link>
        <updated>2021-09-03T08:34:53.000Z</updated>
        <content type="html"><![CDATA[<h3 id="list">List</h3>
<p>ArrayList不是线程安全类，在多线程同时写的情况下，会抛出java.util.ConcurrentModificationException异常。</p>
<pre><code class="language-java">private static void listNotSafe() {
    List&lt;String&gt; list=new ArrayList&lt;&gt;();
    for (int i = 1; i &lt;= 30; i++) {
        new Thread(() -&gt; {
            list.add(UUID.randomUUID().toString().substring(0, 8));
            System.out.println(Thread.currentThread().getName() + &quot;\t&quot; + list);
        }, String.valueOf(i)).start();
    }
}
</code></pre>
<p>解决方法：</p>
<ol>
<li>使用Vector（ArrayList所有方法加synchronized，太重）。</li>
<li>使用Collections.synchronizedList()转换成线程安全类。</li>
<li>使用java.concurrent.CopyOnWriteArrayList（推荐）。<br>
CopyOnWriteArrayList这是JUC的类，通过写时复制来实现读写分离。比如其add()方法，就是先复制一个新数组，长度为原数组长度+1，然后将新数组最后一个元素设为添加的元素。</li>
</ol>
<pre><code class="language-java">public boolean add(E e) {
    final ReentrantLock lock = this.lock;
    lock.lock();
    try {
        //得到旧数组
        Object[] elements = getArray();
        int len = elements.length;
        //复制新数组
        Object[] newElements = Arrays.copyOf(elements, len + 1);
        //设置新元素
        newElements[len] = e;
        //设置新数组
        setArray(newElements);
        return true;
    } finally {
        lock.unlock();
    }
}
</code></pre>
<h3 id="set">Set</h3>
<p>跟List类似，HashSet和TreeSet都不是线程安全的，与之对应的有CopyOnWriteSet这个线程安全类。这个类底层维护了一个CopyOnWriteArrayList数组。</p>
<pre><code class="language-java">private final CopyOnWriteArrayList&lt;E&gt; al;
public CopyOnWriteArraySet() {
    al = new CopyOnWriteArrayList&lt;E&gt;();
}
</code></pre>
<p>使用Collections.synchronizedList()转换成线程安全类。</p>
<p>HashSet和HashMap<br>
HashSet底层是用HashMap实现的。既然是用HashMap实现的，那HashMap.put()需要传两个参数，而HashSet.add()只传一个参数，这是为什么？实际上HashSet.add()就是调用的HashMap.put()，只不过Value被写死了，是一个private static final Object对象。</p>
<h3 id="map">Map</h3>
<p>HashMap不是线程安全的，Hashtable是线程安全的，但是跟Vector类似，太重量级。所以也有类似CopyOnWriteMap，只不过叫ConcurrentHashMap。</p>
<p>关于集合安全类</p>
<pre><code class="language-java">import java.util.*;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.CopyOnWriteArrayList;
import java.util.concurrent.CopyOnWriteArraySet;

public class ContainerNotSafeDemo {
    public static void main(String[] args) {
        listNotSafe();
        setNoSafe();
        mapNotSafe();
    }

    private static void mapNotSafe() {
        //Map&lt;String,String&gt; map=new HashMap&lt;&gt;();
        Map&lt;String, String&gt; map = new ConcurrentHashMap&lt;&gt;();
        for (int i = 1; i &lt;= 30; i++) {
            new Thread(() -&gt; {
                map.put(Thread.currentThread().getName(), UUID.randomUUID().toString().substring(0, 8));
                System.out.println(Thread.currentThread().getName() + &quot;\t&quot; + map);
            }, String.valueOf(i)).start();
        }
    }

    private static void setNoSafe() {
        //Set&lt;String&gt; set=new HashSet&lt;&gt;();
        Set&lt;String&gt; set = new CopyOnWriteArraySet&lt;&gt;();
        for (int i = 1; i &lt;= 30; i++) {
            new Thread(() -&gt; {
                set.add(UUID.randomUUID().toString().substring(0, 8));
                System.out.println(Thread.currentThread().getName() + &quot;\t&quot; + set);
            }, String.valueOf(i)).start();
        }
    }

    private static void listNotSafe() {
        //List&lt;String&gt; list=new ArrayList&lt;&gt;();
        List&lt;String&gt; list = new CopyOnWriteArrayList&lt;&gt;();
        for (int i = 1; i &lt;= 30; i++) {
            new Thread(() -&gt; {
                list.add(UUID.randomUUID().toString().substring(0, 8));
                System.out.println(Thread.currentThread().getName() + &quot;\t&quot; + list);
            }, String.valueOf(i)).start();
        }
    }
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[gradle依赖,插件]]></title>
        <id>https://tinaxiawuhao.github.io/post/Fe3q50EYd/</id>
        <link href="https://tinaxiawuhao.github.io/post/Fe3q50EYd/">
        </link>
        <updated>2021-07-06T11:35:25.000Z</updated>
        <content type="html"><![CDATA[<h1 id="依赖">依赖</h1>
<h2 id="configurations">configurations</h2>
<p>设置configurations 配置依赖信息</p>
<p>build.gradle</p>
<pre><code class="language-java">configurations {
    // 针对需要组件API的消费者的配置
    exposedApi {
        // canBeResolved 为true 则为可解析配置，为消费者
        canBeResolved = false
        // canBeConsumed 为true 则为消费析配置，为生产者
        canBeConsumed = true
    }
    // 为需要实现该组件的消费者提供的配置。
    exposedRuntime {
        canBeResolved = false
        canBeConsumed = true
    }
}
</code></pre>
<h2 id="依赖方式">依赖方式</h2>
<h3 id="模块依赖">模块依赖</h3>
<p>build.gradle</p>
<pre><code class="language-java">dependencies {
    runtimeOnly group: 'org.springframework', name: 'spring-core', version: '2.5'
    runtimeOnly 'org.springframework:spring-core:2.5',
            'org.springframework:spring-aop:2.5'
    runtimeOnly(
        [group: 'org.springframework', name: 'spring-core', version: '2.5'],
        [group: 'org.springframework', name: 'spring-aop', version: '2.5']
    )
    runtimeOnly('org.hibernate:hibernate:3.0.5') {
        transitive = true
    }
    runtimeOnly group: 'org.hibernate', name: 'hibernate', version: '3.0.5', transitive: true
    runtimeOnly(group: 'org.hibernate', name: 'hibernate', version: '3.0.5') {
        transitive = true
    }
}
</code></pre>
<h3 id="文件依赖">文件依赖</h3>
<p>build.gradle</p>
<pre><code class="language-java">dependencies {
    runtimeOnly files('libs/a.jar', 'libs/b.jar')
    runtimeOnly fileTree('libs') { include '*.jar' }
}
</code></pre>
<h3 id="项目依赖">项目依赖</h3>
<p>build.gradle</p>
<pre><code class="language-java">dependencies {
    implementation project(':shared')
}
</code></pre>
<h2 id="依赖方式-2">依赖方式</h2>
<ul>
<li>compileOnly —用于编译生产代码所必需的依赖关系，但不应该属于运行时类路径的一部分</li>
<li>implementation（取代compile）-用于编译和运行时</li>
<li>runtimeOnly（取代runtime）-仅在运行时使用，不用于编译</li>
<li>testCompileOnly—与compileOnly测试相同</li>
<li>testImplementation —测试相当于 implementation</li>
<li>testRuntimeOnly —测试相当于 runtimeOnly</li>
</ul>
<h2 id="repositories">repositories</h2>
<p>流行的公共存储库包括Maven Central， Bintray JCenter和Google Android存储库。<br>
<img src="https://tinaxiawuhao.github.io/post-images/1658230851306.png" alt="" loading="lazy"></p>
<pre><code class="language-java">repositories {
    
    mavenCentral() // Maven Central存储库  
    jcenter() // JCenter Maven存储库
    google() // Google Maven存储库
        
    mavenLocal()   // 将本地Maven缓存添加为存储库（不推荐）
    //flat存储库解析器
    flatDir {
        dirs 'lib'
    }
    flatDir {
        dirs 'lib1', 'lib2'
    }
    
    //添加定制的Maven仓库
    maven {
        url &quot;http://repo.mycompany.com/maven2&quot;
        // 为JAR文件添加附加的Maven存储库
        artifactUrls &quot;http://repo.mycompany.com/jars&quot;
    }
    
    //Ivy
     ivy {
        url &quot;http://repo.mycompany.com/repo&quot;
        layout &quot;maven&quot;  // 有效的命名布局值是'gradle'（默认值）'maven'和'ivy'。
    }
}
</code></pre>
<h3 id="声明存储库过滤器">声明存储库过滤器</h3>
<p>声明存储库内容</p>
<p>build.gradle</p>
<pre><code class="language-java">repositories {
    maven {
        url &quot;https://repo.mycompany.com/maven2&quot;
        content {
            // this repository *only* contains artifacts with group &quot;my.company&quot;
            includeGroup &quot;my.company&quot;
        }
    }
    jcenter {
        content {
            // this repository contains everything BUT artifacts with group starting with &quot;my.company&quot;
            excludeGroupByRegex &quot;my\\.company.*&quot;
        }
    }
}
</code></pre>
<p>默认情况下，存储库包含所有内容，不包含任何内容：</p>
<ul>
<li>如果声明include，那么它排除了一切 include 以外的内容。</li>
<li>如果声明exclude，则它将包括除exclude之外的所有内容。</li>
<li>如果声明include和exclude，则它仅包括显式包括但不排除的内容。</li>
</ul>
<h3 id="分割快照和发行版">分割快照和发行版</h3>
<p>build.gradle</p>
<pre><code class="language-java">repositories {
    maven {
        url &quot;https://repo.mycompany.com/releases&quot;
        mavenContent {
            releasesOnly()
        }
    }
    maven {
        url &quot;https://repo.mycompany.com/snapshots&quot;
        mavenContent {
            snapshotsOnly()
        }
    }
}
</code></pre>
<h3 id="支持的元数据源">支持的元数据源</h3>
<p>受支持的元数据源</p>
<table>
<thead>
<tr>
<th style="text-align:left">元数据源</th>
<th style="text-align:left">描述</th>
<th style="text-align:left">排序</th>
<th style="text-align:left">Maven</th>
<th style="text-align:left">Ivy/flat dir</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">gradleMetadata()</td>
<td style="text-align:left">寻找Gradle.module文件</td>
<td style="text-align:left">1</td>
<td style="text-align:left">是</td>
<td style="text-align:left">是</td>
</tr>
<tr>
<td style="text-align:left">mavenPom()</td>
<td style="text-align:left">查找Maven.pom文件</td>
<td style="text-align:left">2</td>
<td style="text-align:left">是</td>
<td style="text-align:left">是</td>
</tr>
<tr>
<td style="text-align:left">ivyDescriptor()</td>
<td style="text-align:left">查找ivy.xml文件</td>
<td style="text-align:left">2</td>
<td style="text-align:left">没有</td>
<td style="text-align:left">是</td>
</tr>
<tr>
<td style="text-align:left">artifact()</td>
<td style="text-align:left">直接寻找artifact</td>
<td style="text-align:left">3</td>
<td style="text-align:left">是</td>
<td style="text-align:left">是</td>
</tr>
</tbody>
</table>
<p>从Gradle 5.3开始，解析元数据文件（无论是Ivy还是Maven）时，Gradle将寻找一个标记，指示存在匹配的Gradle Module元数据文件。如果找到它，它将代替Ivy或Maven文件使用。</p>
<p>从Gradle5.6开始，您可以通过添加ignoreGradleMetadataRedirection()到metadataSources声明来禁用此行为。</p>
<p>例.不使用gradle元数据重定向的Maven存储库</p>
<p>build.gradle</p>
<pre><code class="language-java">repositories {
    maven {
        url &quot;http://repo.mycompany.com/repo&quot;
        metadataSources {
            mavenPom()
            artifact()
            ignoreGradleMetadataRedirection()
        }
    }
}
</code></pre>
<h2 id="gav坐标">GAV坐标</h2>
<p>GAV坐标一般指group，artifact，version</p>
<h2 id="变体">变体</h2>
<p>构建变体是针对不同环境的配置，例如android开发中一般有debug和release两种变体<br>
<img src="https://tinaxiawuhao.github.io/post-images/1658230892932.png" alt="" loading="lazy"></p>
<h3 id="声明功能变体">声明功能变体</h3>
<p>可以通过应用<code>java</code>或<code>java-library</code>插件来声明功能变体。以下代码说明了如何声明名为<code>mongodbSupport</code>的功能：</p>
<p>示例1.声明一个功能变量</p>
<pre><code class="language-java">Groovy``Kotlin
</code></pre>
<p>build.gradle</p>
<pre><code class="language-java">group = 'org.gradle.demo'
version = '1.0'
 
java {
    registerFeature('mongodbSupport') {
        usingSourceSet(sourceSets.main)
    }
}
</code></pre>
<h2 id="元数据">元数据</h2>
<p>从存储库中提取的每个模块都有与之关联的元数据，例如其组，名称，版本以及它提供的带有工件和依赖项的不同变体</p>
<p>可配置组件元数据规则的示例</p>
<p>build.gradle</p>
<pre><code class="language-java">class TargetJvmVersionRule implements ComponentMetadataRule {
    final Integer jvmVersion
    @Inject TargetJvmVersionRule(Integer jvmVersion) {
        this.jvmVersion = jvmVersion
    }
 
    @Inject ObjectFactory getObjects() { }
 
    void execute(ComponentMetadataContext context) {
        context.details.withVariant(&quot;compile&quot;) {
            attributes {
                attribute(TargetJvmVersion.TARGET_JVM_VERSION_ATTRIBUTE, jvmVersion)
                attribute(Usage.USAGE_ATTRIBUTE, objects.named(Usage, Usage.JAVA_API))
            }
        }
    }
}
dependencies {
    components {
        withModule(&quot;commons-io:commons-io&quot;, TargetJvmVersionRule) {
            params(7)
        }
        withModule(&quot;commons-collections:commons-collections&quot;, TargetJvmVersionRule) {
            params(8)
        }
    }
    implementation(&quot;commons-io:commons-io:2.6&quot;)
    implementation(&quot;commons-collections:commons-collections:3.2.2&quot;)
}
</code></pre>
<p>可以通过以下方法进行修改变体：</p>
<ul>
<li>allVariants：修改组件的所有变体</li>
<li>withVariant(name)：修改由名称标识的单个变体</li>
<li>addVariant(name)或addVariant(name, base)：从头开始 或通过 复制 现有变体的详细信息（基础）向组件添加新变体</li>
</ul>
<p>可以调整每个变体的以下详细信息：</p>
<ul>
<li>标识变体的属性-attributes {}块</li>
<li>该变体提供的功能-withCapabilities { }块</li>
<li>变体的依赖项，包括丰富的版本-withDependencies {}块</li>
<li>变体的依赖关系约束，包括丰富版本-withDependencyConstraints {}块</li>
<li>构成变体实际内容的已发布文件的位置-withFiles { }块</li>
</ul>
<h2 id="平台">平台</h2>
<h3 id="使用平台">使用平台</h3>
<p>获取平台中声明的版本</p>
<p>build.gradle</p>
<pre><code class="language-java">dependencies {
    // get recommended versions from the platform project
    api platform(project(':platform'))
    // no version required
    api 'commons-httpclient:commons-httpclient'
}
</code></pre>
<p>platform表示法是一种简写表示法，实际上在后台执行了一些操作：</p>
<ul>
<li>它将org.gradle.category属性设置为platform，这意味着Gradle将选择依赖项的 平台 组件。</li>
<li>它默认设置endorseStrictVersions行为， 这意味着如果平台声明了严格的依赖关系，则将强制执行它们。</li>
</ul>
<p>这意味着默认情况下，对平台的依赖项会触发该平台中定义的所有严格版本的继承， 这对于平台作者确保所有使用者在依赖项的版本方面都遵循自己的决定很有用。 可以通过显式调用doNotEndorseStrictVersions方法来将其关闭。</p>
<p>例.依靠一个BOM导入其依赖约束</p>
<p>build.gradle</p>
<pre><code class="language-java">dependencies {
    // import a BOM
    implementation platform('org.springframework.boot:spring-boot-dependencies:1.5.8.RELEASE')
 
    // define dependencies without versions
    implementation 'com.google.code.gson:gson'
    implementation 'dom4j:dom4j'
}
</code></pre>
<p>导入BOM，确保其定义的版本覆盖找到的任何其他版本</p>
<p>build.gradle</p>
<pre><code class="language-java">dependencies {
    // import a BOM. The versions used in this file will override any other version found in the graph
    implementation enforcedPlatform('org.springframework.boot:spring-boot-dependencies:1.5.8.RELEASE')
 
    // define dependencies without versions
    implementation 'com.google.code.gson:gson'
    implementation 'dom4j:dom4j'
 
    // this version will be overridden by the one found in the BOM
    implementation 'org.codehaus.groovy:groovy:1.8.6'
}
</code></pre>
<h2 id="capability">Capability</h2>
<h3 id="声明组件的capability">声明组件的capability</h3>
<p>build.gradle</p>
<pre><code class="language-java">configurations {
    apiElements {
        outgoing {
            capability(&quot;com.acme:my-library:1.0&quot;)
            capability(&quot;com.other:module:1.1&quot;)
        }
    }
    runtimeElements {
        outgoing {
            capability(&quot;com.acme:my-library:1.0&quot;)
            capability(&quot;com.other:module:1.1&quot;)
        }
    }
}
</code></pre>
<h3 id="解决冲突">解决冲突</h3>
<p>按Capability（能力）解决冲突，（若存在相同能力的依赖性会失败）</p>
<p>build.gradle</p>
<pre><code class="language-java">@CompileStatic
class AsmCapability implements ComponentMetadataRule {
    void execute(ComponentMetadataContext context) {
        context.details.with {
            if (id.group == &quot;asm&quot; &amp;&amp; id.name == &quot;asm&quot;) {
                allVariants {
                    it.withCapabilities {
                        // Declare that ASM provides the org.ow2.asm:asm capability, but with an older version
                        it.addCapability(&quot;org.ow2.asm&quot;, &quot;asm&quot;, id.version)
                    }
                }
            }
        }
    }
}
 
</code></pre>
<p>一个带有日志框架隐式冲突的构建文件</p>
<p>build.gradle</p>
<pre><code class="language-java">dependencies {
    // Activate the &quot;LoggingCapability&quot; rule
    components.all(LoggingCapability)
}
 
@CompileStatic
class LoggingCapability implements ComponentMetadataRule {
    final static Set&lt;String&gt; LOGGING_MODULES = [&quot;log4j&quot;, &quot;log4j-over-slf4j&quot;] as Set&lt;String&gt;
 
    void execute(ComponentMetadataContext context) {
        context.details.with {
            if (LOGGING_MODULES.contains(id.name)) {
                allVariants {
                    it.withCapabilities {
                        // Declare that both log4j and log4j-over-slf4j provide the same capability
                        it.addCapability(&quot;log4j&quot;, &quot;log4j&quot;, id.version)
                    }
                }
            }
        }
    }
}
</code></pre>
<h2 id="版本">版本</h2>
<h3 id="版本规则">版本规则</h3>
<p>Gradle支持不同的版本字符串声明方式：</p>
<ul>
<li>
<p>一个确切的版本：比如<code>1.3</code>，<code>1.3.0-beta3</code>，<code>1.0-20150201.131010-1</code></p>
</li>
<li>
<p>一个Maven风格的版本范围：例如</p>
<pre><code class="language-java">[1.0,)
</code></pre>
<pre><code class="language-java">[1.1, 2.0)
</code></pre>
<pre><code class="language-java">(1.2, 1.5]
</code></pre>
<ul>
<li><code>[</code>和<code>]</code>的符号表示包含性约束; <code>(</code>和<code>)</code>表示排他性约束。</li>
<li>当上界或下界缺失时，该范围没有上界或下界。</li>
<li>符号<code>]</code>可以被用来代替<code>(</code>用于排他性下界，<code>[</code>代替<code>)</code>用于排他性上界。例如<code>]1.0, 2.0[</code></li>
</ul>
</li>
<li>
<p>前缀版本范围：例如</p>
<pre><code class="language-java">1.+
</code></pre>
<pre><code class="language-java">1.3.+
</code></pre>
<ul>
<li>仅包含与<code>+</code>之前部分完全匹配的版本。</li>
<li><code>+</code>本身的范围将包括任何版本。</li>
</ul>
</li>
<li>
<p>一个latest-status版本：例如latest.integration，latest.release</p>
</li>
<li>
<p>Maven的SNAPSHOT版本标识符：例如1.0-SNAPSHOT，1.4.9-beta1-SNAPSHOT</p>
</li>
</ul>
<h3 id="版本排序">版本排序</h3>
<ul>
<li>每个版本均分为其组成的“部分”：
<ul>
<li>字符[. - _ +]用于分隔版本的不同“部分”。</li>
<li>同时包含数字和字母的任何部分都将分为以下各个部分： <code>1a1 == 1.a.1</code></li>
<li>仅比较版本的各个部分。实际的分隔符并不重要：<code>1.a.1 == 1-a+1 == 1.a-1 == 1a1</code></li>
</ul>
</li>
<li>使用以下规则比较2个版本的等效部分：
<ul>
<li>如果两个部分都是数字，则最高数字值 较高 ：<code>1.1&lt;1.2</code></li>
<li>如果一个部分是数值，则认为它 高于 非数字部分：<code>1.a&lt;1.1</code></li>
<li>如果两个部分都不是数字，则按字母顺序比较，区分大小写：<code>1.A&lt; 1.B&lt; 1.a&lt;1.b</code></li>
<li>有额外数字部分的版本被认为比没有数字部分的版本高：<code>1.1&lt;1.1.0</code></li>
<li>带有额外的非数字部分的版本被认为比没有数字部分的版本低：<code>1.1.a&lt;1.1</code></li>
</ul>
</li>
<li>某些字符串值出于排序目的具有特殊含义：
<ul>
<li>字符串dev被认为比任何其他字符串部分低：<code>1.0-dev&lt; 1.0-alpha&lt; 1.0-rc</code>。</li>
<li>字符串rc、release和final被认为比任何其他字符串部分都高（按顺序排列：<code>1.0-zeta&lt; 1.0-rc&lt; 1.0-release&lt; 1.0-final&lt; 1.0</code>。</li>
<li>字符串SNAPSHOT没有特殊意义，和其他字符串部分一样按字母顺序排序：<code>1.0-alpha&lt; 1.0-SNAPSHOT&lt; 1.0-zeta&lt; 1.0-rc&lt; 1.0</code>。</li>
<li>数值快照版本没有特殊意义，和其他数值部分一样进行排序：<code>1.0&lt; 1.0-20150201.121010-123&lt; 1.1</code>。</li>
</ul>
</li>
</ul>
<p>简单来说:数字&gt;final&gt;release&gt;rc&gt;字母&gt;dev</p>
<h3 id="声明没有版本的依赖">声明没有版本的依赖</h3>
<p>对于较大的项目，建议的做法是声明没有版本的依赖项， 并将依赖项约束 用于版本声明。 优势在于，依赖关系约束使您可以在一处管理所有依赖关系的版本，包括可传递的依赖关系。</p>
<p>build.gradle</p>
<pre><code class="language-java">dependencies {
    implementation 'org.springframework:spring-web'
}
 
dependencies {
    constraints {
        implementation 'org.springframework:spring-web:5.0.2.RELEASE'
    }
}
</code></pre>
<h3 id="依赖方式-3">依赖方式</h3>
<h4 id="strictly">strictly</h4>
<blockquote>
<p>与该版本符号不匹配的任何版本将被排除。这是最强的版本声明。<br>
在声明的依赖项上，strictly可以降级版本。<br>
在传递依赖项上，如果无法选择此子句可接受的版本，将导致依赖项解析失败。<br>
有关详细信息，请参见覆盖依赖项版本。<br>
该术语支持动态版本。</p>
</blockquote>
<p>定义后，将覆盖先前的require声明并清除之前的 reject。</p>
<h4 id="require">require</h4>
<blockquote>
<p>表示所选版本不能低于require可接受的版本，但可以通过冲突解决方案提高，即使更高版本具有排他性更高的界限。<br>
这就是依赖项上的直接版本所转换的内容。该术语支持动态版本。</p>
</blockquote>
<p>定义后，将覆盖先前的strictly声明并清除之前的 reject。</p>
<h4 id="prefer">prefer</h4>
<blockquote>
<p>这是一个非常软的版本声明。仅当对该模块的版本没有更强的非动态观点时，才适用。<br>
该术语不支持动态版本。</p>
</blockquote>
<p>定义可以补充strictly或require。</p>
<p>在级别层次结构之外还有一个附加术语：</p>
<h4 id="reject">reject</h4>
<blockquote>
<p>声明模块不接受特定版本。如果唯一的可选版本也被拒绝，这将导致依赖项解析失败。该术语支持动态版本。</p>
</blockquote>
<h3 id="动态版本">动态版本</h3>
<p>build.gradle</p>
<pre><code class="language-java">plugins {
    id 'java-library'
}
 
repositories {
    mavenCentral()
}
 
dependencies {
    implementation 'org.springframework:spring-web:5.+'
}
</code></pre>
<h3 id="版本快照">版本快照</h3>
<p>声明一个版本变化的依赖</p>
<p>build.gradle</p>
<pre><code class="language-java"> 
plugins {
    id 'java-library'
}
 
repositories {
    mavenCentral()
    maven {
        url 'https://repo.spring.io/snapshot/'
    }
}
 
dependencies {
    implementation 'org.springframework:spring-web:5.0.3.BUILD-SNAPSHOT'
}
 
</code></pre>
<h3 id="以编程方式控制依赖项缓存">以编程方式控制依赖项缓存</h3>
<p>您可以使用ResolutionStrategy 对配置进行编程来微调缓存的某些方面。 如果您想永久更改设置，则编程方式非常有用。</p>
<p>默认情况下，Gradle将动态版本缓存24小时。 要更改Gradle将解析后的版本缓存为动态版本的时间，请使用：</p>
<p>例.动态版本缓存控制</p>
<p>build.gradle</p>
<pre><code class="language-java">configurations.all {
    resolutionStrategy.cacheDynamicVersionsFor 10, 'minutes'
}
 
</code></pre>
<p>默认情况下，Gradle会将更改的模块缓存24小时。 要更改Gradle将为更改的模块缓存元数据和工件的时间，请使用：</p>
<p>例.改变模块缓存控制</p>
<p>build.gradle</p>
<pre><code class="language-java">configurations.all {
    resolutionStrategy.cacheChangingModulesFor 4, 'hours'
}
</code></pre>
<h3 id="锁定配置">锁定配置</h3>
<p>锁定特定配置</p>
<p>build.gradle</p>
<pre><code class="language-java">configurations {
    compileClasspath {
        resolutionStrategy.activateDependencyLocking()
    }
}
</code></pre>
<p>锁定所有配置</p>
<p>build.gradle</p>
<pre><code class="language-java">dependencyLocking {
    lockAllConfigurations()
}
</code></pre>
<p>解锁特定配置</p>
<p>build.gradle</p>
<pre><code class="language-java">configurations {
    compileClasspath {
        resolutionStrategy.deactivateDependencyLocking()
    }
}
</code></pre>
<h4 id="锁定buildscript类路径配置">锁定buildscript类路径配置</h4>
<p>如果将插件应用于构建，则可能还需要利用依赖锁定。为了锁定用于脚本插件的classpath配置，请执行以下操作：</p>
<p>build.gradle</p>
<pre><code class="language-java">buildscript {
    configurations.classpath {
        resolutionStrategy.activateDependencyLocking()
    }
}
 
</code></pre>
<h4 id="使用锁定模式微调依赖项锁定行为">使用锁定模式微调依赖项锁定行为</h4>
<p>虽然默认锁定模式的行为如上所述，但是还有其他两种模式可用：</p>
<ul>
<li>Strict模式 ：在该模式下，除了上述验证外，如果被标记为锁定的配置没有与之相关联的锁定状态，则依赖性锁定将失败。</li>
<li>Lenient模式：在这种模式下，依存关系锁定仍将固定动态版本，但除此之外，依赖解析的变化不再是错误。</li>
</ul>
<p>锁定模式可以从dependencyLocking块中进行控制，如下所示：</p>
<p>build.gradle</p>
<pre><code class="language-java">dependencyLocking {
    lockMode = LockMode.STRICT
}
</code></pre>
<h3 id="版本冲突">版本冲突</h3>
<p>用force强制执行一个依赖版本</p>
<p>build.gradle</p>
<pre><code class="language-java">dependencies {
    implementation 'org.apache.httpcomponents:httpclient:4.5.4'
    implementation('commons-codec:commons-codec:1.9') {
        force = true
    }
}
</code></pre>
<p>排除特定依赖声明的传递依赖</p>
<p>build.gradle</p>
<pre><code class="language-java">dependencies {
    implementation('commons-beanutils:commons-beanutils:1.9.4') {
        exclude group: 'commons-collections', module: 'commons-collections'
    }
}
</code></pre>
<p>版本冲突时失败</p>
<p>build.gradle</p>
<pre><code class="language-java">configurations.all {
    resolutionStrategy {
        failOnVersionConflict()
    }
}
 
</code></pre>
<p>使用动态版本时失败</p>
<p>build.gradle</p>
<pre><code class="language-java">configurations.all {
    resolutionStrategy {
        failOnDynamicVersions()
    }
}
</code></pre>
<p>改变版本时失败</p>
<p>build.gradle</p>
<pre><code class="language-java">configurations.all {
    resolutionStrategy {
        failOnChangingVersions()
    }
}
</code></pre>
<p>解析无法再现时失败</p>
<p>build.gradle</p>
<pre><code class="language-java">configurations.all {
    resolutionStrategy {
        failOnNonReproducibleResolution()
    }
}
 
</code></pre>
<h1 id="插件">插件</h1>
<p>插件作用：将插件应用于项目可以使插件扩展项目的功能。它可以执行以下操作：</p>
<ul>
<li>扩展Gradle模型（例如，添加可以配置的新DSL元素）</li>
<li>根据约定配置项目（例如，添加新任务或配置合理的默认值）</li>
<li>应用特定的配置（例如，添加组织存储库或强制执行标准）</li>
</ul>
<p>简单来说，插件可以拓展项目功能，如任务，依赖，拓展属性，约束</p>
<h2 id="插件类型">插件类型</h2>
<ul>
<li>二进制插件 ：通过实现插件接口以编程方式编写二进制插件，或使用Gradle的一种DSL语言以声明方式编写二进制插件</li>
<li>脚本插件 ：脚本插件是其他构建脚本，可以进一步配置构建，并通常采用声明式方法来操纵构建</li>
</ul>
<p>插件通常起初是脚本插件（因为它们易于编写），然后，随着代码变得更有价值，它被迁移到可以轻松测试并在多个项目或组织之间共享的二进制插件。</p>
<h2 id="应用插件">应用插件</h2>
<h3 id="二进制插件">二进制插件</h3>
<p>实现了org.gradle.api.Plugin接口</p>
<pre><code class="language-java">apply plugin: 'com.android.application'
</code></pre>
<h4 id="apply-plugin">apply plugin</h4>
<pre><code class="language-java">apply plugin: 'java'  //id
==
apply plugin: org.gradle.api.plugins.JavaPlugin //类型
==
apply plugin: JavaPlugin          //org.gradle.api.plugins默认导入
</code></pre>
<h4 id="plugins-dsl">plugins DSL</h4>
<pre><code class="language-java">plugins {
    id 'java' //应用核心插件
    id 'com.jfrog.bintray' version '0.4.1' //应用社区插件
    id 'com.example.hello' version '1.0.0' apply false //使用`apply false`语法告诉Gradle不要将插件应用于当前项目
}
</code></pre>
<h3 id="脚本插件">脚本插件</h3>
<p>脚本插件会自动解析，可以从本地文件系统或远程位置的脚本中应用。可以将多个脚本插件（任意一种形式）应用于给定目标。</p>
<pre><code class="language-java">apply from:'version.gradle'
</code></pre>
<p>apply可传入内容</p>
<pre><code class="language-java">void apply(Map&lt;String,? options);
void apply(Closure closure);
void apply(Action&lt;? super ObjectConfigurationAction&gt; action);
</code></pre>
<h2 id="定义插件">定义插件</h2>
<p>定义一个带有ID的buildSrc插件<br>
buildSrc / build.gradle</p>
<pre><code class="language-java">plugins {
    id 'java-gradle-plugin'
}
gradlePlugin {
    plugins {
        myPlugins {
            id = 'my-plugin'
            implementationClass = 'my.MyPlugin'
        }
    }
}
</code></pre>
<h2 id="第三方插件">第三方插件</h2>
<p>通过将插件添加到构建脚本classpath中，然后应用该插件，可以将已发布为外部jar文件的二进制插件添加到项目中。可以使用buildscript {}块将外部jar添加到构建脚本classpath中。</p>
<pre><code class="language-java">buildscript {
    repositories {
        google()
        jcenter()
    }
    dependencies {
        classpath &quot;com.android.tools.build:gradle:4.0.1&quot;
    }
}
</code></pre>
<h2 id="插件管理">插件管理</h2>
<p>pluginManagement {}块只能出现在settings.gradle文件中，必须是文件中的第一个块，也可以以settings形式出现在初始化脚本中。</p>
<p>settings.gradle</p>
<pre><code class="language-java">pluginManagement {
    plugins {
    }
    resolutionStrategy {
    }
    repositories {
    }
}
rootProject.name = 'plugin-management'
</code></pre>
<p>init.gradle</p>
<pre><code class="language-java">settingsEvaluated { settings -&gt;
    settings.pluginManagement {
        plugins {
        }
        resolutionStrategy {
        }
        repositories {
        }
    }
}
</code></pre>
<p>例：通过pluginManagement管理插件版本。</p>
<p>settings.gradle</p>
<pre><code class="language-java">pluginManagement {
  plugins {
        id 'com.example.hello' version &quot;${helloPluginVersion}&quot;
  }
}
 
</code></pre>
<p>gradle.properties</p>
<pre><code class="language-java">helloPluginVersion=1.0.0
</code></pre>
<h2 id="自定义插件存储库">自定义插件存储库</h2>
<p>要指定自定义插件存储库，请使用repositories {}块其中的pluginManagement {}：</p>
<p>settings.gradle</p>
<pre><code class="language-java">pluginManagement {
    repositories {
        maven {
            url '../maven-repo'
        }
        gradlePluginPortal()
        ivy {
            url '../ivy-repo'
        }
    }
}
</code></pre>
<h1 id="java库">java库</h1>
<p>导入java</p>
<pre><code class="language-java">apply plugin:'java'
</code></pre>
<p>自定义路径</p>
<pre><code class="language-java">sourceSets {
    main {
         java {
            srcDirs = ['src']
         }
    }
 
    test {
        java {
            srcDirs = ['test']
        }
    }
}
sourceSets {
    main {
        java {
            srcDir 'thirdParty/src/main/java'
        }
    }
}
</code></pre>
<p>导入依赖</p>
<pre><code class="language-java"> repositories {
        jcenter()
 }
dependencies {
     implementation group:'com.android.support',name:'appcompat-v7',version:'28.0.0'
     implementation 'com.android.support:appcompat-v7:28.0.0'
     implementation protect(':p')
     implementation file('libs/ss.jar','libs/ss2.jar')
         
    implementation fileTree(dir: &quot;libs&quot;, include: [&quot;*.jar&quot;])
}
</code></pre>
<p>多项目 设置 settings.gradle</p>
<pre><code class="language-java">include ':app'
rootProject.name = &quot;GradleTest&quot;
</code></pre>
<h1 id="安卓实用">安卓实用</h1>
<h2 id="设置签名">设置签名</h2>
<pre><code class="language-java">android  {
    signingConfig = {
        release {
            storeFile file(&quot;MYKEY.keystore&quot;)
            storePassword &quot;storePassword&quot;
            keyAlias &quot;keyAlias&quot;
            keyPassword &quot;keyPassword&quot;
        }
    }
}
</code></pre>
<h2 id="自定义输出apk文件名称">自定义输出apk文件名称</h2>
<pre><code class="language-java">applicationVariants.all { variant -&gt;
       variant.outputs.all { output -&gt;
           def fileName = &quot;自定义名称_${variant.versionName}_release.apk&quot;
           def outFile = output.outputFile
           if (outFile != null &amp;&amp; outFile.name.endsWith('.apk')) {
               outputFileName = fileName
           }
       }
   }
</code></pre>
<h2 id="动态androidmanifest">动态AndroidManifest</h2>
<pre><code class="language-java">&lt;meta-data android:name=&quot;paramName&quot; android:value=&quot;${PARAM_NAME}&quot;&gt;
android {
    productFlavors{
        google{
            manifestPlaceholders.put(&quot;PARAM_NAME&quot;,'google')
        }
    }
}
</code></pre>
<h2 id="多渠道">多渠道</h2>
<pre><code class="language-java">android {
    productFlavors{
        google{
            
        },
        baidu{
            
        }
    }
    productFlavors.all{ flavor-&gt;
        manifestPlaceholders.put(&quot;PARAM_NAME&quot;,name)
    }
}
</code></pre>
<h2 id="adb设置">adb设置</h2>
<p>adb工具</p>
<pre><code class="language-java">android {
    adbOptions{
        timeOutInMs = 5000 //5s超时
        installOptions '-r','-s' //安装指令
    }
}
</code></pre>
<h2 id="dexoptions">dexOptions</h2>
<p>dex工具</p>
<pre><code class="language-java">android {
    dexOptions{
        incremental true //增量
        javaMaxHeapSize '4G'//dx最大队内存
        jumboMode true //强制开启jumbo跳过65535限制
        preDexLibraries true //提高增量构建速度
            threadCount 1 //dx线程数量
    }
}
</code></pre>
<h2 id="ant">Ant</h2>
<p>例.将嵌套元素传递给Ant任</p>
<p>build.gradle</p>
<pre><code class="language-java">task zip {
    doLast {
        ant.zip(destfile: 'archive.zip') {
            fileset(dir: 'src') {
                include(name: '**.xml')
                exclude(name: '**.java')
            }
        }
    }
}
</code></pre>
<p>例.使用Ant类型</p>
<p>build.gradle</p>
<pre><code class="language-java">task list {
    doLast {
        def path = ant.path {
            fileset(dir: 'libs', includes: '*.jar')
        }
        path.list().each {
            println it
        }
    }
}
</code></pre>
<p>例.使用定制的Ant任务</p>
<p>build.gradle</p>
<pre><code class="language-java">task check {
    doLast {
        ant.taskdef(resource: 'checkstyletask.properties') {
            classpath {
                fileset(dir: 'libs', includes: '*.jar')
            }
        }
        ant.checkstyle(config: 'checkstyle.xml') {
            fileset(dir: 'src')
        }
    }
}
</code></pre>
<h2 id="lint">Lint</h2>
<p>Lint：android tool目录下的工具，一个代码扫描工具，能够帮助我们识别资源、代码结构存在的问题</p>
<pre><code class="language-java">lintOptions
android {
    lintOptions{
        abortOnError true //发生错误时推出Gradle
        absolutePaths true //配置错误输出是否显示绝对路径
        check 'NewApi','InlinedApi' // 检查lint check的issue id            
        enable 'NewApi','InlinedApi' //启动 lint check的issue id
        disable 'NewApi','InlinedApi' //关闭 lint check的issue id
        checkAllWarnings true //检查所有警告issue
        ignoreWarning true //忽略警告检查，默认false
        checkReleaseBuilds true //检查致命错误，默认true
        explainIssues true //错误报告是否包含解释说明，默认true
        htmlOutput new File(&quot;/xx.html&quot;) //html报告输出路径
        htmlReport true // 是否生成html报告，默认true
        lintConfig new File(&quot;/xx.xml&quot;) //lint配置
        noLines true // 输出不带行号 默认true
        quite true // 安静模式
        showAll true //是否显示所有输出，不截断
    }
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[gradle-Logging]]></title>
        <id>https://tinaxiawuhao.github.io/post/wYNztHepH/</id>
        <link href="https://tinaxiawuhao.github.io/post/wYNztHepH/">
        </link>
        <updated>2021-07-05T11:34:29.000Z</updated>
        <content type="html"><![CDATA[<h3 id="logging">Logging</h3>
<h3 id="日志级别">日志级别</h3>
<table>
<thead>
<tr>
<th style="text-align:left">日志级别</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">ERROR</td>
<td style="text-align:left">错误讯息</td>
</tr>
<tr>
<td style="text-align:left">QUIET</td>
<td style="text-align:left">重要信息消息</td>
</tr>
<tr>
<td style="text-align:left">WARNING</td>
<td style="text-align:left">警告讯息</td>
</tr>
<tr>
<td style="text-align:left">LIFECYCLE</td>
<td style="text-align:left">进度信息消息</td>
</tr>
<tr>
<td style="text-align:left">INFO</td>
<td style="text-align:left">信息讯息</td>
</tr>
<tr>
<td style="text-align:left">DEBUG</td>
<td style="text-align:left">调试信息</td>
</tr>
</tbody>
</table>
<h3 id="选择日志级别">选择日志级别</h3>
<p>可以通过命令行选项或者gradle.properties文件配置</p>
<table>
<thead>
<tr>
<th style="text-align:left">选项</th>
<th style="text-align:left">输出日志级别</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">没有记录选项</td>
<td style="text-align:left">LIFECYCLE及更高</td>
</tr>
<tr>
<td style="text-align:left">-q or--quiet</td>
<td style="text-align:left">QUIET及更高</td>
</tr>
<tr>
<td style="text-align:left">-w or --warn</td>
<td style="text-align:left">WARNING及更高</td>
</tr>
<tr>
<td style="text-align:left">-i or --info</td>
<td style="text-align:left">INFO及更高</td>
</tr>
<tr>
<td style="text-align:left">-d or --debug</td>
<td style="text-align:left">DEBUG及更高版本（即所有日志消息）</td>
</tr>
</tbody>
</table>
<h3 id="stacktrace命令行选项">Stacktrace命令行选项</h3>
<p><strong>-s or --stacktrace</strong></p>
<p>打印简洁的堆栈跟踪信息，推荐使用</p>
<p><strong>-S or --full-stacktrace</strong></p>
<p>打印完整的堆栈跟踪信息。</p>
<h3 id="编写日志">编写日志</h3>
<h4 id="使用stdout编写日志消息">使用stdout编写日志消息</h4>
<pre><code class="language-shell">println 'A message which is logged at QUIET level'
</code></pre>
<h4 id="编写自己的日志消息">编写自己的日志消息</h4>
<pre><code class="language-java">logger.quiet('An info log message which is always logged.')
logger.error('An error log message.')
logger.warn('A warning log message.')
logger.lifecycle('A lifecycle info log message.')
logger.info('An info log message.')
logger.debug('A debug log message.')
logger.trace('A trace log message.') // Gradle never logs TRACE level logs
 
// 用占位符写一条日志消息
logger.info('A {} log message', 'info')
</code></pre>
<p>logger构建脚本提供了一个属性，该脚本是Logger的实例。该接口扩展了SLF4JLogger接口，并向其中添加了一些Gradle特定的方法</p>
<h3 id="使用slf4j写入日志消息">使用SLF4J写入日志消息</h3>
<pre><code class="language-java">import org.slf4j.LoggerFactory
 
def slf4jLogger = LoggerFactory.getLogger('some-logger')
slf4jLogger.info('An info log message logged using SLF4j')
</code></pre>
<h3 id="构建生命周期">构建生命周期</h3>
<p>Gradle的核心是一种基于依赖性的编程语言，这意味着你可以定义任务和任务之间的依赖关系。 Gradle保证这些任务按照其依赖关系的顺序执行，并且每个任务只执行一次。 这些任务形成一个定向无环图。</p>
<h4 id="构建阶段">构建阶段</h4>
<p>Gradle构建具有三个不同的阶段。</p>
<ul>
<li>
<p>初始化</p>
<p>Gradle支持单项目和多项目构建。在初始化阶段，Gradle决定要参与构建的项目，并为每个项目创建一个Project实例。</p>
</li>
<li>
<p>配置</p>
<p>在此阶段，将配置项目对象。执行作为构建一部分的 所有 项目的构建脚本。</p>
</li>
<li>
<p>执行</p>
<p>Gradle确定要在配置阶段创建和配置的任务子集。子集由传递给gradle命令的任务名称参数和当前目录确定。然后Gradle执行每个选定的任务。</p>
</li>
</ul>
<h4 id="设置文件">设置文件</h4>
<p>默认名称是settings.gradle</p>
<p>项目构建在多项目层次结构的根项目中必须具有一个settings.gradle文件。</p>
<p>对于单项目构建，设置文件是可选的</p>
<h4 id="初始化">初始化</h4>
<p>查找settings.gradle文件判断是否多项目</p>
<p>没有settings.gradle或settings.gradle没有多项目配置则为单项目</p>
<p>例：将test任务添加到每个具有特定属性集的项目</p>
<p>build.gradle</p>
<pre><code class="language-java"> allprojects {
    afterEvaluate { project -&gt;
        if (project.hasTests) {
            println &quot;Adding test task to $project&quot;
            project.task('test') {
                doLast {
                    println &quot;Running tests for $project&quot;
                }
            }
        }
    }
}
 
</code></pre>
<p>输出 gradle -q test</p>
<pre><code class="language-shell">&gt; gradle -q test
Adding test task to project ':project-a'
Running tests for project ':project-a'
</code></pre>
<h3 id="初始化脚本">初始化脚本</h3>
<p>初始化脚本与Gradle中的其他脚本相似。但是，这些脚本在构建开始之前运行。初始化脚本不能访问buildSrc项目中的类。</p>
<h4 id="使用初始化脚本">使用初始化脚本</h4>
<p>有几种使用初始化脚本的方法：</p>
<ul>
<li>在命令行中指定一个文件。命令行选项是-I或-init-script，后面是脚本的路径。</li>
</ul>
<p>命令行选项可以出现一次以上，每次都会添加另一个 init 脚本。 如果命令行上指定的文件不存在，编译将失败。</p>
<ul>
<li>在 <em>USER_HOME</em> /.gradle/目录中放置一个名为init.gradle（或init.gradle.ktsKotlin）的文件。</li>
<li>在 <em>USER_HOME</em> /.gradle/init.d/目录中放置一个以.gradle（或.init.gradle.ktsKotlin）结尾的文件。</li>
<li>在Gradle发行版的 <em>GRADLE_HOME</em> /init.d/目录中放置一个以.gradle（或.init.gradle.ktsKotlin）结尾的文件。这使您可以打包包含一些自定义构建逻辑和插件的自定义Gradle发行版。您可以将其与Gradle Wrapper结合使用，以使自定义逻辑可用于企业中的所有内部版本。</li>
</ul>
<p>如果发现一个以上的初始化脚本，它们将按照上面指定的顺序依次执行。</p>
<p>示例</p>
<p>build.gradle</p>
<pre><code class="language-java">repositories {
    mavenCentral()
}
 
task showRepos {
    doLast {
        println &quot;All repos:&quot;
        println repositories.collect { it.name }
    }
}
 
</code></pre>
<p>init.gradle</p>
<pre><code class="language-java">allprojects {
    repositories {
        mavenLocal()
    }
}
</code></pre>
<p>运行任务：</p>
<pre><code class="language-shell">gradle --init-script init.gradle -q showRepos
</code></pre>
<h4 id="初始化脚本里面依赖添加依赖">初始化脚本里面依赖添加依赖</h4>
<p>init.gradle</p>
<pre><code class="language-java">initscript {
    repositories {
        mavenCentral()
    }
    dependencies {
        classpath 'org.apache.commons:commons-math:2.0'
    }
}
</code></pre>
<h3 id="多项目">多项目</h3>
<p>可在settings.gradle文件中设置多个项目关系，如下项目结构</p>
<pre><code class="language-shell">.
├── app
│   ...
│   └── build.gradle
└── settings.gradle
</code></pre>
<p>settings.gradle</p>
<pre><code class="language-java">rootProject.name = 'basic-multiproject' //根项目名
include 'app' //子项目
 
</code></pre>
<p>子项目间依赖</p>
<pre><code class="language-java">dependencies {
    implementation(project(&quot;:shared&quot;))
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Groovy基础]]></title>
        <id>https://tinaxiawuhao.github.io/post/4WWjxpN2N/</id>
        <link href="https://tinaxiawuhao.github.io/post/4WWjxpN2N/">
        </link>
        <updated>2021-07-04T11:33:24.000Z</updated>
        <content type="html"><![CDATA[<h3 id="groovy基础">Groovy基础</h3>
<h3 id="基本规则">基本规则</h3>
<ul>
<li>没有分号</li>
<li>方法括号可以省略</li>
<li>方法可以不写return，返回最后一句代码</li>
<li>代码块可以作为参数传递</li>
</ul>
<h3 id="定义">定义</h3>
<pre><code class="language-java">def param = 'hello world'
def param1 = &quot;hello world&quot;
println &quot;${param1} ,li&quot; 
</code></pre>
<p>${}里面可以放变量，也可以是表达式，只有双引号里面可以使用</p>
<h3 id="声明变量">声明变量</h3>
<p>可以在构建脚本中声明两种变量：局部变量和额外属性。</p>
<h4 id="局部变量">局部变量</h4>
<p>局部变量用def关键字声明。它们仅在声明它们的范围内可见。局部变量是基础Groovy语言的功能。</p>
<pre><code class="language-java">def dest = &quot;dest&quot;
task copy(type: Copy) {
    from &quot;source&quot;
    into dest
}
</code></pre>
<h4 id="ext属性">ext属性</h4>
<p>Gradle的域模型中的所有增强对象都可以容纳额外的用户定义属性。</p>
<p>可以通过拥有对象的ext属性添加，读取和设置其他属性。可以使用一个ext块一次添加多个属性。</p>
<pre><code class="language-java">plugins {
    id 'java'
}
 
ext {
    springVersion = &quot;3.1.0.RELEASE&quot;
    emailNotification = &quot;build@master.org&quot;
}
 
sourceSets.all { ext.purpose = null }
 
sourceSets {
    main {
        purpose = &quot;production&quot;
    }
    test {
        purpose = &quot;test&quot;
    }
    plugin {
        purpose = &quot;production&quot;
    }
}
 
task printProperties {
    doLast {
        println springVersion
        println emailNotification
        sourceSets.matching { it.purpose == &quot;production&quot; }.each { println it.name }
    }
}
</code></pre>
<p>输出 gradle -q printProperties</p>
<pre><code class="language-shell">&gt; gradle -q printProperties
3.1.0.RELEASE
build@master.org
main
plugin
</code></pre>
<h4 id="变量范围本地和脚本范围">变量范围：本地和脚本范围</h4>
<p>用类型修饰符声明的变量在闭包中可见，但在方法中不可见。</p>
<pre><code class="language-java">String localScope1 = 'localScope1'
def localScope2 = 'localScope2'
scriptScope = 'scriptScope'
 
println localScope1
println localScope2
println scriptScope
 
closure = {
    println localScope1
    println localScope2
    println scriptScope
}
 
def method() {
    try {
        localScope1
    } catch (MissingPropertyException e) {
        println 'localScope1NotAvailable'
    }
    try {
        localScope2
    } catch(MissingPropertyException e) {
        println 'localScope2NotAvailable'
    }
    println scriptScope
}
 
closure.call()
method()
</code></pre>
<p>输出 groovy scope.groovy</p>
<pre><code class="language-shell">&gt; groovy作用域
localScope1
localScope2
scriptScope
localScope1
localScope2
scriptScope
localScope1NotAvailable
localScope2NotAvailable
scriptScope
</code></pre>
<h3 id="对象">对象</h3>
<h4 id="使用对象">使用对象</h4>
<p>您可以按照以下易读的方式配置任意对象。</p>
<p>build.gradle</p>
<pre><code class="language-java">import java.text.FieldPosition
 
task configure {
    doLast {
        def pos = configure(new FieldPosition(10)) {
            beginIndex = 1
            endIndex = 5
        }
        println pos.beginIndex
        println pos.endIndex
    }
}
&gt; gradle -q configure
1
5
</code></pre>
<h4 id="使用外部脚本配置任意对象">使用外部脚本配置任意对象</h4>
<p>您也可以使用外部脚本配置任意对象。</p>
<p>build.gradle</p>
<pre><code class="language-java">task configure {
    doLast {
        def pos = new java.text.FieldPosition(10)
        // Apply the script
        apply from: 'other.gradle', to: pos
        println pos.beginIndex
        println pos.endIndex
    }
}
</code></pre>
<p>other.gradle</p>
<pre><code class="language-java">// Set properties.
beginIndex = 1
endIndex = 5
</code></pre>
<p>输出 gradle -q configure</p>
<pre><code class="language-shell">&gt; gradle -q configure
1
5
</code></pre>
<h3 id="属性访问器">属性访问器</h3>
<p>Groovy自动将属性引用转换为对适当的getter或setter方法的调用。</p>
<p>build.gradle</p>
<pre><code class="language-java">// Using a getter method
println project.buildDir
println getProject().getBuildDir()
 
// Using a setter method
project.buildDir = 'target'
getProject().setBuildDir('target')
</code></pre>
<h3 id="闭包">闭包</h3>
<p>闭包（闭合代码块，可以引用传入的变量）</p>
<pre><code class="language-java">task testClosure {
    doLast {
        func {
            println it
        }
        funa { a, b -&gt;
            println a + b
        }
    }
}
 
def funa(closure) {
    closure(10, 3)
}
 
def func(closure) {
    closure(10)
}
</code></pre>
<h4 id="闭包委托">闭包委托</h4>
<p>每个闭包都有一个<code>delegate</code>对象，Groovy使用该对象来查找不是闭包的局部变量或参数的变量和方法引用。</p>
<p>例.闭包委托</p>
<pre><code class="language-java">class Info {
    int id;
    String code;
 
    def log() {
        println(&quot;code:${code};id:${id}&quot;)
    }
}
 
def info(Closure&lt;Info&gt; closure) {
    Info p = new Info()
    closure.delegate = p
    // 委托模式优先
    closure.setResolveStrategy(Closure.DELEGATE_FIRST)
    closure(p)
}
 
task configClosure {
    doLast {
        info {
            code = &quot;cix&quot;
            id = 1
            log()
        }
    }
}
</code></pre>
<p>输出</p>
<pre><code class="language-shell">&gt; Task :configClosure
code:cix;id:1
 
BUILD SUCCESSFUL in 276ms
</code></pre>
<p>例：使用必包委托设置依赖</p>
<pre><code class="language-java">dependencies {
    assert delegate == project.dependencies
    testImplementation('junit:junit:4.13')
    delegate.testImplementation('junit:junit:4.13')
}
</code></pre>
<h3 id="方法">方法</h3>
<h4 id="方法调用上的可选括号">方法调用上的可选括号</h4>
<p>括号对于方法调用是可选的。</p>
<p>build.gradle</p>
<pre><code class="language-java">test.systemProperty 'some.prop', 'value'
test.systemProperty('some.prop', 'value')
</code></pre>
<h4 id="闭包作为方法中的最后一个参数">闭包作为方法中的最后一个参数</h4>
<p>当方法的最后一个参数是闭包时，可以将闭包放在方法调用之后：</p>
<p>build.gradle</p>
<pre><code class="language-java">repositories {
    println &quot;in a closure&quot;
}
repositories() { println &quot;in a closure&quot; }
repositories({ println &quot;in a closure&quot; })
</code></pre>
<h3 id="集合">集合</h3>
<h4 id="list">List</h4>
<pre><code class="language-java">def list = [1,2,3,4]
println list[0] // 1
println list[-1] // 4 最后一个
println list[-2] // 3 倒数第二个
println list[0..2] // 第1-3个
 
list.each { //迭代
    println it
}
</code></pre>
<h4 id="map">Map</h4>
<pre><code class="language-java">def map= ['name':'li', 'age':18]
println map[name] // li
println map.age // 18
 
list.each { //迭代
    println &quot;${it.key}:${it.value}&quot;
}
 
</code></pre>
<h3 id="javabean">JavaBean</h3>
<pre><code class="language-java">class A{
    private int a; //可通过A().a 获取修改
    public int getB(){//可通过A().b获取，但不能修改
        1
    }
}
</code></pre>
<p>build.gradle</p>
<pre><code class="language-java">// List literal
test.includes = ['org/gradle/api/**', 'org/gradle/internal/**']
 
List&lt;String&gt; list = new ArrayList&lt;String&gt;()
list.add('org/gradle/api/**')
list.add('org/gradle/internal/**')
test.includes = list
 
// Map literal.
Map&lt;String, String&gt; map = [key1:'value1', key2: 'value2']
 
// Groovy will coerce named arguments
// into a single map argument
apply plugin: 'java'
</code></pre>
<h3 id="默认导入">默认导入</h3>
<p>为了使构建脚本更简洁，Gradle自动向Gradle脚本添加了一些类。</p>
<pre><code class="language-java">import org.gradle.*
import org.gradle.api.*
import org.gradle.api.artifacts.*
import org.gradle.api.artifacts.component.*
import org.gradle.api.artifacts.dsl.*
import org.gradle.api.artifacts.ivy.*
import org.gradle.api.artifacts.maven.*
import org.gradle.api.artifacts.query.*
import org.gradle.api.artifacts.repositories.*
import org.gradle.api.artifacts.result.*
import org.gradle.api.artifacts.transform.*
import org.gradle.api.artifacts.type.*
import org.gradle.api.artifacts.verification.*
import org.gradle.api.attributes.*
import org.gradle.api.attributes.java.*
import org.gradle.api.capabilities.*
import org.gradle.api.component.*
import org.gradle.api.credentials.*
import org.gradle.api.distribution.*
import org.gradle.api.distribution.plugins.*
import org.gradle.api.execution.*
import org.gradle.api.file.*
import org.gradle.api.initialization.*
import org.gradle.api.initialization.definition.*
import org.gradle.api.initialization.dsl.*
import org.gradle.api.invocation.*
import org.gradle.api.java.archives.*
import org.gradle.api.jvm.*
import org.gradle.api.logging.*
import org.gradle.api.logging.configuration.*
import org.gradle.api.model.*
import org.gradle.api.plugins.*
import org.gradle.api.plugins.antlr.*
import org.gradle.api.plugins.quality.*
import org.gradle.api.plugins.scala.*
import org.gradle.api.provider.*
import org.gradle.api.publish.*
import org.gradle.api.publish.ivy.*
import org.gradle.api.publish.ivy.plugins.*
import org.gradle.api.publish.ivy.tasks.*
import org.gradle.api.publish.maven.*
import org.gradle.api.publish.maven.plugins.*
import org.gradle.api.publish.maven.tasks.*
import org.gradle.api.publish.plugins.*
import org.gradle.api.publish.tasks.*
import org.gradle.api.reflect.*
import org.gradle.api.reporting.*
import org.gradle.api.reporting.components.*
import org.gradle.api.reporting.dependencies.*
import org.gradle.api.reporting.dependents.*
import org.gradle.api.reporting.model.*
import org.gradle.api.reporting.plugins.*
import org.gradle.api.resources.*
import org.gradle.api.services.*
import org.gradle.api.specs.*
import org.gradle.api.tasks.*
import org.gradle.api.tasks.ant.*
import org.gradle.api.tasks.application.*
import org.gradle.api.tasks.bundling.*
import org.gradle.api.tasks.compile.*
import org.gradle.api.tasks.diagnostics.*
import org.gradle.api.tasks.incremental.*
import org.gradle.api.tasks.javadoc.*
import org.gradle.api.tasks.options.*
import org.gradle.api.tasks.scala.*
import org.gradle.api.tasks.testing.*
import org.gradle.api.tasks.testing.junit.*
import org.gradle.api.tasks.testing.junitplatform.*
import org.gradle.api.tasks.testing.testng.*
import org.gradle.api.tasks.util.*
import org.gradle.api.tasks.wrapper.*
import org.gradle.authentication.*
import org.gradle.authentication.aws.*
import org.gradle.authentication.http.*
import org.gradle.build.event.*
import org.gradle.buildinit.plugins.*
import org.gradle.buildinit.tasks.*
import org.gradle.caching.*
import org.gradle.caching.configuration.*
import org.gradle.caching.http.*
import org.gradle.caching.local.*
import org.gradle.concurrent.*
import org.gradle.external.javadoc.*
import org.gradle.ide.visualstudio.*
import org.gradle.ide.visualstudio.plugins.*
import org.gradle.ide.visualstudio.tasks.*
import org.gradle.ide.xcode.*
import org.gradle.ide.xcode.plugins.*
import org.gradle.ide.xcode.tasks.*
import org.gradle.ivy.*
import org.gradle.jvm.*
import org.gradle.jvm.application.scripts.*
import org.gradle.jvm.application.tasks.*
import org.gradle.jvm.platform.*
import org.gradle.jvm.plugins.*
import org.gradle.jvm.tasks.*
import org.gradle.jvm.tasks.api.*
import org.gradle.jvm.test.*
import org.gradle.jvm.toolchain.*
import org.gradle.language.*
import org.gradle.language.assembler.*
import org.gradle.language.assembler.plugins.*
import org.gradle.language.assembler.tasks.*
import org.gradle.language.base.*
import org.gradle.language.base.artifact.*
import org.gradle.language.base.compile.*
import org.gradle.language.base.plugins.*
import org.gradle.language.base.sources.*
import org.gradle.language.c.*
import org.gradle.language.c.plugins.*
import org.gradle.language.c.tasks.*
import org.gradle.language.coffeescript.*
import org.gradle.language.cpp.*
import org.gradle.language.cpp.plugins.*
import org.gradle.language.cpp.tasks.*
import org.gradle.language.java.*
import org.gradle.language.java.artifact.*
import org.gradle.language.java.plugins.*
import org.gradle.language.java.tasks.*
import org.gradle.language.javascript.*
import org.gradle.language.jvm.*
import org.gradle.language.jvm.plugins.*
import org.gradle.language.jvm.tasks.*
import org.gradle.language.nativeplatform.*
import org.gradle.language.nativeplatform.tasks.*
import org.gradle.language.objectivec.*
import org.gradle.language.objectivec.plugins.*
import org.gradle.language.objectivec.tasks.*
import org.gradle.language.objectivecpp.*
import org.gradle.language.objectivecpp.plugins.*
import org.gradle.language.objectivecpp.tasks.*
import org.gradle.language.plugins.*
import org.gradle.language.rc.*
import org.gradle.language.rc.plugins.*
import org.gradle.language.rc.tasks.*
import org.gradle.language.routes.*
import org.gradle.language.scala.*
import org.gradle.language.scala.plugins.*
import org.gradle.language.scala.tasks.*
import org.gradle.language.scala.toolchain.*
import org.gradle.language.swift.*
import org.gradle.language.swift.plugins.*
import org.gradle.language.swift.tasks.*
import org.gradle.language.twirl.*
import org.gradle.maven.*
import org.gradle.model.*
import org.gradle.nativeplatform.*
import org.gradle.nativeplatform.platform.*
import org.gradle.nativeplatform.plugins.*
import org.gradle.nativeplatform.tasks.*
import org.gradle.nativeplatform.test.*
import org.gradle.nativeplatform.test.cpp.*
import org.gradle.nativeplatform.test.cpp.plugins.*
import org.gradle.nativeplatform.test.cunit.*
import org.gradle.nativeplatform.test.cunit.plugins.*
import org.gradle.nativeplatform.test.cunit.tasks.*
import org.gradle.nativeplatform.test.googletest.*
import org.gradle.nativeplatform.test.googletest.plugins.*
import org.gradle.nativeplatform.test.plugins.*
import org.gradle.nativeplatform.test.tasks.*
import org.gradle.nativeplatform.test.xctest.*
import org.gradle.nativeplatform.test.xctest.plugins.*
import org.gradle.nativeplatform.test.xctest.tasks.*
import org.gradle.nativeplatform.toolchain.*
import org.gradle.nativeplatform.toolchain.plugins.*
import org.gradle.normalization.*
import org.gradle.platform.base.*
import org.gradle.platform.base.binary.*
import org.gradle.platform.base.component.*
import org.gradle.platform.base.plugins.*
import org.gradle.play.*
import org.gradle.play.distribution.*
import org.gradle.play.platform.*
import org.gradle.play.plugins.*
import org.gradle.play.plugins.ide.*
import org.gradle.play.tasks.*
import org.gradle.play.toolchain.*
import org.gradle.plugin.devel.*
import org.gradle.plugin.devel.plugins.*
import org.gradle.plugin.devel.tasks.*
import org.gradle.plugin.management.*
import org.gradle.plugin.use.*
import org.gradle.plugins.ear.*
import org.gradle.plugins.ear.descriptor.*
import org.gradle.plugins.ide.*
import org.gradle.plugins.ide.api.*
import org.gradle.plugins.ide.eclipse.*
import org.gradle.plugins.ide.idea.*
import org.gradle.plugins.javascript.base.*
import org.gradle.plugins.javascript.coffeescript.*
import org.gradle.plugins.javascript.envjs.*
import org.gradle.plugins.javascript.envjs.browser.*
import org.gradle.plugins.javascript.envjs.http.*
import org.gradle.plugins.javascript.envjs.http.simple.*
import org.gradle.plugins.javascript.jshint.*
import org.gradle.plugins.javascript.rhino.*
import org.gradle.plugins.signing.*
import org.gradle.plugins.signing.signatory.*
import org.gradle.plugins.signing.signatory.pgp.*
import org.gradle.plugins.signing.type.*
import org.gradle.plugins.signing.type.pgp.*
import org.gradle.process.*
import org.gradle.swiftpm.*
import org.gradle.swiftpm.plugins.*
import org.gradle.swiftpm.tasks.*
import org.gradle.testing.base.*
import org.gradle.testing.base.plugins.*
import org.gradle.testing.jacoco.plugins.*
import org.gradle.testing.jacoco.tasks.*
import org.gradle.testing.jacoco.tasks.rules.*
import org.gradle.testkit.runner.*
import org.gradle.vcs.*
import org.gradle.vcs.git.*
import org.gradle.work.*
import org.gradle.workers.*
</code></pre>
<h3 id="导入依赖">导入依赖</h3>
<pre><code class="language-java">buildscript {
    repositories {
        mavenCentral()
    }
    dependencies {
        classpath group: 'commons-codec', name: 'commons-codec', version: '1.2'
    }
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[gradle项目与任务]]></title>
        <id>https://tinaxiawuhao.github.io/post/lhyr_DiZc/</id>
        <link href="https://tinaxiawuhao.github.io/post/lhyr_DiZc/">
        </link>
        <updated>2021-07-03T11:32:31.000Z</updated>
        <content type="html"><![CDATA[<h3 id="项目与任务">项目与任务</h3>
<p>Gradle中的所有内容都位于两个基本概念之上：</p>
<ul>
<li>projects ：每个Gradle构建都由一个或多个 projects组成 ，一个projects代表什么取决于您使用Gradle做的事情。例如，一个projects可能代表一个JAR库或一个Web应用程序。</li>
<li>tasks ：每个projects由一个或多个 tasks组成 。tasks代表构建执行的一些原子工作。这可能是编译某些类，创建JAR，生成Javadoc或将一些存档发布到存储库。</li>
</ul>
<h3 id="项目">项目</h3>
<p>表.项目属性</p>
<table>
<thead>
<tr>
<th style="text-align:left">名称</th>
<th style="text-align:left">类型</th>
<th style="text-align:left">默认值</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">project</td>
<td style="text-align:left">Project</td>
<td style="text-align:left">该Project实例</td>
</tr>
<tr>
<td style="text-align:left">name</td>
<td style="text-align:left">String</td>
<td style="text-align:left">项目目录的名称。</td>
</tr>
<tr>
<td style="text-align:left">path</td>
<td style="text-align:left">String</td>
<td style="text-align:left">项目的绝对路径。</td>
</tr>
<tr>
<td style="text-align:left">description</td>
<td style="text-align:left">String 项目说明。</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">projectDir</td>
<td style="text-align:left">File</td>
<td style="text-align:left">包含构建脚本的目录。</td>
</tr>
<tr>
<td style="text-align:left">buildDir</td>
<td style="text-align:left">File</td>
<td style="text-align:left"><em>projectDir</em> /build</td>
</tr>
<tr>
<td style="text-align:left">group</td>
<td style="text-align:left">Object</td>
<td style="text-align:left">unspecified</td>
</tr>
<tr>
<td style="text-align:left">version</td>
<td style="text-align:left">Object</td>
<td style="text-align:left">unspecified</td>
</tr>
<tr>
<td style="text-align:left">ant</td>
<td style="text-align:left">ant build</td>
<td style="text-align:left">一个AntBuilder实例</td>
</tr>
</tbody>
</table>
<h3 id="任务">任务</h3>
<h4 id="定义任务">定义任务</h4>
<ol>
<li>使用字符串作为任务名称定义任务</li>
<li>使用tasks容器定义任务</li>
<li>使用DSL特定语法定义任务</li>
</ol>
<p>例：<br>
<strong>build.gradle</strong></p>
<pre><code class="language-java">// 使用字符串作为任务名称定义任务
task('hello') {
    doLast {
        println &quot;hello&quot;
    }
}
// 使用tasks容器定义任务
tasks.create('hello') {
    doLast {
        println &quot;hello&quot;
    }
}
// 使用DSL特定语法定义任务
task(hello) {
    doLast {
        println &quot;hello&quot;
    }
}
task('copy', type: Copy) {
    from(file('srcDir'))
    into(buildDir)
}
</code></pre>
<h4 id="定位任务">定位任务</h4>
<ul>
<li>使用DSL特定语法访问任务</li>
<li>通过任务集合访问任务</li>
<li>通过路径访问</li>
<li>按任务类型访问任务</li>
</ul>
<pre><code class="language-java">task hello
task copy(type: Copy)
 
 
// 使用DSL特定语法访问任务
println hello.name
println project.hello.name
 
println copy.destinationDir
println project.copy.destinationDir
 
// 通过任务集合访问任务
println tasks.hello.name
println tasks.named('hello').get().name
 
println tasks.copy.destinationDir
println tasks.named('copy').get().destinationDir
 
 
//按任务类型访问任务
tasks.withType(Tar).configureEach {
    enabled = false
}
 
task test {
    dependsOn tasks.withType(Copy)
}
</code></pre>
<p>通过路径访问</p>
<p><strong>project-a / build.gradle</strong></p>
<pre><code class="language-shell">task hello
</code></pre>
<p><strong>build.gradle</strong></p>
<pre><code class="language-java">task hello
 
println tasks.getByPath('hello').path
println tasks.getByPath(':hello').path
println tasks.getByPath('project-a:hello').path
println tasks.getByPath(':project-a:hello').path
</code></pre>
<h4 id="配置任务">配置任务</h4>
<h5 id="使用api配置任务">使用API配置任务</h5>
<p>例：<br>
<strong>build.gradle</strong></p>
<pre><code class="language-java">Copy myCopy = tasks.getByName(&quot;myCopy&quot;)
myCopy.from 'resources'
myCopy.into 'target'
myCopy.include('**/*.txt', '**/*.xml', '**/*.properties')
</code></pre>
<h5 id="使用dsl特定语法配置任务">使用DSL特定语法配置任务</h5>
<p>例：<br>
<strong>build.gradle</strong></p>
<pre><code class="language-java">// Configure task using Groovy dynamic task configuration block
myCopy {
   from 'resources'
   into 'target'
}
myCopy.include('**/*.txt', '**/*.xml', '**/*.properties')
</code></pre>
<h5 id="用配置块定义一个任务">用配置块定义一个任务</h5>
<p>例：<br>
<strong>build.gradle</strong></p>
<pre><code class="language-java">task copy(type: Copy) {
   from 'resources'
   into 'target'
   include('**/*.txt', '**/*.xml', '**/*.properties')
}
</code></pre>
<h4 id="将参数传递给任务构造函数">将参数传递给任务构造函数</h4>
<p>与Task在创建后配置可变属性相反，您可以将参数值传递给Task类的构造函数。为了将值传递给Task构造函数，您必须使用@javax.inject.Inject注释相关的构造函数。</p>
<p>首先创建带有@Inject构造函数的任务类</p>
<pre><code class="language-java">class CustomTask extends DefaultTask {
    final String message
    final int number
 
    @Inject
    CustomTask(String message, int number) {
        this.message = message
        this.number = number
    }
}
</code></pre>
<p>然后创建一个任务，并在参数列表的末尾传递构造函数参数。</p>
<pre><code class="language-java">tasks.create('myTask', CustomTask, 'hello', 42)
</code></pre>
<p>你也可以使用Map创建带有构造函数参数的任务</p>
<pre><code class="language-java">task myTask(type: CustomTask, constructorArgs: ['hello', 42])
</code></pre>
<h4 id="向任务添加依赖项">向任务添加依赖项</h4>
<p>从另一个项目添加对任务的依赖</p>
<pre><code class="language-java">project('project-a') {
    task taskX {
        dependsOn ':project-b:taskY'
        doLast {
            println 'taskX'
        }
    }
}
 
project('project-b') {
    task taskY {
        doLast {
            println 'taskY'
        }
    }
}
</code></pre>
<h4 id="使用任务对象添加依赖">使用任务对象添加依赖</h4>
<pre><code class="language-java">task taskX {
    doLast {
        println 'taskX'
    }
}
 
task taskY {
    doLast {
        println 'taskY'
    }
}
 
 
taskX.dependsOn taskY
</code></pre>
<h4 id="使用惰性块添加依赖项">使用惰性块添加依赖项</h4>
<pre><code class="language-java">task taskX {
    doLast {
        println 'taskX'
    }
}
 
// Using a Groovy Closure
taskX.dependsOn {
    tasks.findAll { task -&gt; task.name.startsWith('lib') }
}
 
task lib1 {
    doLast {
        println 'lib1'
    }
}
 
task lib2 {
    doLast {
        println 'lib2'
    }
}
 
task notALib {
    doLast {
        println 'notALib'
    }
}
</code></pre>
<h4 id="任务排序">任务排序</h4>
<p>控制任务排序的两种方式：</p>
<ul>
<li>must run after ：必须在之后运行</li>
<li>should run after：应该在之后运行</li>
</ul>
<p>例</p>
<pre><code class="language-java">task taskX {
    doLast {
        println 'taskX'
    }
}
task taskY {
    doLast {
        println 'taskY'
    }
}
taskY.mustRunAfter taskX
</code></pre>
<p>should run after被忽略的情况</p>
<ul>
<li>引入排序周期。</li>
<li>使用并行执行时，除了 &quot;should run after &quot;任务外，一个任务的所有依赖关系都已被满足，</li>
</ul>
<p>引入排序周期例子</p>
<pre><code class="language-java">task taskX {
    doLast {
        println 'taskX'
    }
}
task taskY {
    doLast {
        println 'taskY'
    }
}
task taskZ {
    doLast {
        println 'taskZ'
    }
}
taskX.dependsOn taskY
taskY.dependsOn taskZ
taskZ.shouldRunAfter taskX
</code></pre>
<h4 id="为任务添加描述">为任务添加描述</h4>
<p>您可以在任务中添加描述。执行gradle tasks时将显示此描述。</p>
<p>build.gradle</p>
<pre><code class="language-java">task copy(type: Copy) {
   description 'Copies the resource directory to the target directory.'
   from 'resources'
   into 'target'
   include('**/*.txt', '**/*.xml', '**/*.properties')
}
</code></pre>
<h4 id="跳过任务">跳过任务</h4>
<p>onlyIf跳过</p>
<pre><code class="language-java">hello.onlyIf { !project.hasProperty('skipHello') }
//StopExecutionException跳过
compile.doFirst {
    if (true) { throw new StopExecutionException() }
}
</code></pre>
<p>禁用任务</p>
<pre><code class="language-java">task disableMe {
    doLast {
        println 'This should not be printed if the task is disabled.'
    }
}
disableMe.enabled = false
</code></pre>
<p>任务超时</p>
<pre><code class="language-java">task hangingTask() {
    doLast {
        Thread.sleep(100000)
    }
    timeout = Duration.ofMillis(500)
}
</code></pre>
<h4 id="任务规则">任务规则</h4>
<p>有时您想执行一个任务，该任务的行为取决于较大或无限数量的参数值范围。提供此类任务的一种非常好的表达方式是任务规则：</p>
<p>任务规则</p>
<pre><code class="language-java">tasks.addRule(&quot;Pattern: ping&lt;ID&gt;&quot;) { String taskName -&gt;
    if (taskName.startsWith(&quot;ping&quot;)) {
        task(taskName) {
            doLast {
                println &quot;Pinging: &quot; + (taskName - 'ping')
            }
        }
    }
}
 
task groupPing {
    dependsOn pingServer1, pingServer2
}
&gt; gradle -q groupPing
 
Ping：Server1
Ping：Server2
</code></pre>
<h4 id="终结器任务">终结器任务</h4>
<p>计划运行终结任务时，终结任务会自动添加到任务图中。即使完成任务失败，也将执行终结器任务。</p>
<pre><code class="language-java">task taskX {
    doLast {
        println 'taskX'
    }
}
task taskY {
    doLast {
        println 'taskY'
    }
}
taskX.finalizedBy taskY
&gt; gradle -q taskX
 
TaskX
TaskY
</code></pre>
<h4 id="动态任务">动态任务</h4>
<p>Groovy或Kotlin的功能可用于定义任务以外的其他功能。例如，您还可以使用它来动态创建任务。</p>
<p>build.gradle</p>
<pre><code class="language-java">4.times { counter -&gt;
    task &quot;task$counter&quot; {
        doLast {
            println &quot;I'm task number $counter&quot;
        }
    }
}
</code></pre>
<p>gradle -q task1 输出</p>
<pre><code class="language-shell">&gt; gradle -q task1
I'm task number 1
</code></pre>
<h4 id="groovy_dsl快捷方式符号">Groovy_DSL快捷方式符号</h4>
<p>访问任务有一种方便的表示法。每个任务都可以作为构建脚本的属性来使用：</p>
<p>例.作为构建脚本的属性访问任务</p>
<p>build.gradle</p>
<pre><code class="language-java">task hello {
    doLast {
        println 'Hello world!'
    }
}
hello.doLast {
    println &quot;Greetings from the $hello.name task.&quot;
}
</code></pre>
<p>输出 gradle -q hello</p>
<pre><code class="language-shell">&gt; gradle -q hello
Hello world!
Greetings from the hello task.
</code></pre>
<p>这将启用非常可读的代码，尤其是在使用插件提供的任务（例如compile任务）时。</p>
<h4 id="额外任务属性">额外任务属性</h4>
<p>您可以将自己的属性添加到任务。要添加名为的属性myProperty，请设置ext.myProperty为初始值。从那时起，可以像预定义的任务属性一样读取和设置属性。</p>
<p>build.gradle</p>
<pre><code class="language-java">task myTask {
    ext.myProperty = &quot;myValue&quot;
}
 
task printTaskProperties {
    doLast {
        println myTask.myProperty
    }
}
</code></pre>
<p>输出 gradle -q printTaskProperties</p>
<pre><code class="language-shell">&gt; gradle -q printTaskProperties
myValue
</code></pre>
<p>额外的属性不仅限于任务。您可以在Extra属性中阅读有关它们的更多信息。</p>
<h4 id="默认任务">默认任务</h4>
<p>Gradle允许您定义一个或多个默认任务。</p>
<p>build.gradle</p>
<pre><code class="language-java">defaultTasks 'clean', 'run'
 
task clean {
    doLast {
        println 'Default Cleaning!'
    }
}
 
task run {
    doLast {
        println 'Default Running!'
    }
}
 
task other {
    doLast {
        println &quot;I'm not a default task!&quot;
    }
}
</code></pre>
<p>输出 gradle -q</p>
<pre><code class="language-shell">&gt; gradle -q
Default Cleaning!
Default Running!
</code></pre>
<p>这等效于运行gradle clean run。在多项目构建中，每个子项目可以有其自己的特定默认任务。如果子项目未指定默认任务，则使用父项目的默认任务（如果已定义）。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Gradle基础]]></title>
        <id>https://tinaxiawuhao.github.io/post/Ke4qDxE4l/</id>
        <link href="https://tinaxiawuhao.github.io/post/Ke4qDxE4l/">
        </link>
        <updated>2021-07-02T11:31:04.000Z</updated>
        <content type="html"><![CDATA[<h1 id="gradle概述">Gradle概述</h1>
<p>Gradle是专注于灵活性和性能的开源构建自动化工具，一般使用Groovy或KotlinDSL编写构建脚本。 本文只使用Groovy</p>
<h2 id="gradle的特点">Gradle的特点：</h2>
<ul>
<li>高性能</li>
</ul>
<p>Gradle通过仅运行需要运行的任务来避免不必要的工作。 可以使用构建缓存来重用以前运行的任务输出，甚至可以使用其他计算机（具有共享的构建缓存）重用任务输出。</p>
<ul>
<li>JVM基础</li>
</ul>
<p>Gradle在JVM上运行。熟悉Java的用户来可以在构建逻辑中使用标准Java API，例如自定义任务类型和插件。 这使得Gradle跨平台更加简单。（Gradle不仅限于构建JVM项目，它甚至附带对构建本机项目的支持。）</p>
<ul>
<li>约束</li>
</ul>
<p>和Maven一样，Gradle通过实现约束使常见类型的项目（例如Java项目）易于构建。 应用适当的插件，您可以轻松地为许多项目使用精简的构建脚本。 但是这些约定并没有限制您：Gradle允许您覆盖它们，添加自己的任务以及对基于约定的构建进行许多其他自定义操作。</p>
<ul>
<li>可扩展性</li>
</ul>
<p>您可以轻松扩展Gradle以提供您自己的任务类型甚至构建模型。</p>
<ul>
<li>IDE支持</li>
</ul>
<p>支持IDE：Android Studio，IntelliJ IDEA，Eclipse和NetBeans。 Gradle还支持生成将项目加载到Visual Studio所需的解决方案文件。</p>
<ul>
<li>可洞察性</li>
</ul>
<p>构建扫描提供了有关构建运行的广泛信息，可用于识别构建问题。他们特别擅长帮助您确定构建性能的问题。 您还可以与其他人共享构建扫描，如果您需要咨询以解决构建问题，这将特别有用。</p>
<h2 id="您需要了解有关gradle的五件事">您需要了解有关Gradle的五件事</h2>
<p>本节在官方文档里面反复提及，具体可见<a href="https://docs.gradle.org/current/userguide/what_is_gradle.html#five_things">Gradle文档</a></p>
<h3 id="1-gradle是通用的构建工具">1. Gradle是通用的构建工具</h3>
<p>Gradle允许您构建任何软件，因为它不关心你具体的工作。</p>
<h3 id="2-核心模型基于任务">2. 核心模型基于任务</h3>
<p>Gradle将其构建模型建模为任务（工作单元）的有向无环图（DAG）。这意味着构建实质上配置了一组任务，并根据它们的依赖关系将它们连接在一起以创建该DAG。创建任务图后，Gradle将确定需要按顺序运行的任务，然后继续执行它们。</p>
<p>任务本身包括以下部分，它们通过依赖链接在一起：</p>
<ul>
<li>动作-做某事的工作，例如复制文件或编译源代码</li>
<li>输入-操作使用或对其进行操作的值，文件和目录</li>
<li>输出-操作修改或生成的文件和目录</li>
</ul>
<h3 id="3-gradle有几个固定的构建阶段">3. Gradle有几个固定的构建阶段</h3>
<p>重要的是要了解Gradle分三个阶段评估和执行构建脚本：</p>
<ul>
<li>初始化</li>
</ul>
<p>设置构建环境，并确定哪些项目将参与其中。</p>
<ul>
<li>配置</li>
</ul>
<p>构造和配置构建的任务图，然后根据用户要运行的任务确定需要运行的任务和运行顺序。</p>
<ul>
<li>执行</li>
</ul>
<p>运行在配置阶段结束时选择的任务。</p>
<p>这些阶段构成了Gradle的构建生命周期。</p>
<h3 id="4-gradle的扩展方式不止一种">4. Gradle的扩展方式不止一种</h3>
<p>Gradle捆绑的构建逻辑不可能满足所有构建情况，大多数构建都有一些特殊要求，你需要添加自定义构建逻辑。Gradle提供了多种机制来扩展它，例如：</p>
<ul>
<li>自定义任务类型。</li>
<li>自定义任务动作。</li>
<li>项目和任务的额外属性。</li>
<li>自定义约束。</li>
<li>自定义module。</li>
</ul>
<h3 id="5-构建脚本针对api运行">5. 构建脚本针对API运行</h3>
<p>可以将Gradle的构建脚本视为可执行代码，但设计良好的构建脚本描述了构建软件需要哪些步骤，而不关心这些步骤应该如何完成工作。</p>
<p>由于Gradle在JVM上运行，因此构建脚本也可以使用标准Java API。Groovy构建脚本可以另外使用Groovy API，而Kotlin构建脚本可以使用Kotlin。</p>
<h2 id="功能的生命周期">功能的生命周期</h2>
<p>功能可以处于以下四种状态之一：</p>
<ul>
<li>Internal：内部功能，不提供接口</li>
<li>Incubating： 孵化功能。在成为公共功能之前会继续更改</li>
<li>Public：公共功能，可放心使用</li>
<li>Deprecated：废弃功能，将在未来删除</li>
</ul>
<h1 id="gradle安装">Gradle安装</h1>
<h2 id="安装jdk">安装JDK</h2>
<p>安装JDK过程已有太多资料，本文不做详细介绍。可使用命令检测自己电脑是否成功安装</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1658230657737.png" alt="" loading="lazy"></figure>
<h2 id="安装gradle">安装Gradle</h2>
<h3 id="用软件包安装gradle">用软件包安装Gradle</h3>
<p>SDKMAN</p>
<pre><code class="language-shell">sdk install gradle
</code></pre>
<p>Homebrew</p>
<pre><code class="language-shell">brew install gradle
</code></pre>
<h3 id="手动安装推荐方式">手动安装（推荐方式）</h3>
<h4 id="下载">下载</h4>
<p><a href="https://services.gradle.org/distributions/">services.gradle.org/distributions</a> （全部版本目录地址，可以查看最新版本）<br>
<a href="https://services.gradle.org/distributions/gradle-7.5-all.zip">services.gradle.org/distributions/gradle-7.5-all.zip</a> （截止至2022.07.18最新）</p>
<p>建议下载：<a href="https://services.gradle.org/distributions/gradle-7.0.3-all.zip">services.gradle.org/distributions/gradle-7.0.2-all.zip</a> (支持jdk8)</p>
<h4 id="文件介绍">文件介绍</h4>
<pre><code class="language-java">gradle-7.0.2-docs.zip  //文档
gradle-7.0.2-src.zip  //源码
gradle-7.0.2-bin.zip  //软件包
gradle-7.0.2-all.zip   //全部文件
   bin ：运行文件
   lib：依赖库
   docs：文档
   src：源文件
   init.d :初始化脚本目录，可自己添加
</code></pre>
<h4 id="配置环境变量">配置环境变量</h4>
<pre><code class="language-shell">export GRADLE_HOME=/Users/temp/gradle-7.0.2
export PATH=$PATH:$GRADLE_HOME/bin
</code></pre>
<h4 id="运行">运行</h4>
<p>输入gradle -v 检测是否配置成功</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1658230676105.png" alt="" loading="lazy"></figure>
<h3 id="helloword">HelloWord</h3>
<p>编写一个build.gradle文件，输入以下内容</p>
<pre><code class="language-java">task hello{
    doLast {
        println 'Hello World'
    }
}
</code></pre>
<p>命令行输入<code>gradle -q hello</code>即可运行</p>
<h1 id="gradle-wrapper">Gradle Wrapper</h1>
<h2 id="定义">定义</h2>
<p>Gradle Wrapper是一个脚本，可调用Gradle的声明版本，并在必要时预先下载。因此，开发人员可以快速启动并运行Gradle项目，而无需遵循手动安装过程<br>
<img src="https://tinaxiawuhao.github.io/post-images/1658230693887.png" alt="" loading="lazy"></p>
<h2 id="添加wrapper">添加wrapper</h2>
<p>在build.gradle同级目录下使用命令<code>gradle wrapper</code>可以生成gradle wrapper目录</p>
<pre><code class="language-java">gradle wrapper
</code></pre>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1658230710999.png" alt="" loading="lazy"></figure>
<ul>
<li>
<p>gradle-wrapper.jar</p>
<p>WrapJAR文件，其中包含用于下载Gradle发行版的代码。</p>
</li>
<li>
<p>gradle-wrapper.properties</p>
<p>一个属性文件，负责配置Wrapper运行时行为，例如与该版本兼容的Gradle版本。请注意，更多常规设置（例如，将 Wrap配置为使用代理）需要进入其他文件。</p>
</li>
<li>
<p>gradlew， gradlew.bat</p>
<p>一个shell脚本和一个Windows批处理脚本，用于使用 Wrap程序执行构建。</p>
</li>
</ul>
<p>可以通过命令控制生成选项</p>
<pre><code class="language-shell">#用于下载和执行 Wrap程序的Gradle版本。
--gradle-version

#Wrap使用的Gradle分布类型。可用的选项是bin和all。默认值为bin。
--distribution-type

#指向Gradle分发ZIP文件的完整URL。使用此选项，--gradle-version并且--distribution-     type过时的网址已经包含此信息。如果您想在公司网络内部托管Gradle发行版，则此选项非常有价值。
--gradle-distribution-url

#SHA256哈希和用于验证下载的Gradle分布。
--gradle-distribution-sha256-sum
</code></pre>
<p>例：</p>
<pre><code class="language-shell">gradle wrapper --gradle-version 7.0.2 --distribution-type all
</code></pre>
<h2 id="wrapper属性文件">Wrapper属性文件</h2>
<p>一般生成Wrapper会得到如下属性文件 gradle-wrapper.properties</p>
<pre><code class="language-java">distributionBase=GRADLE_USER_HOME
distributionPath=wrapper/dists
distributionUrl=https\://services.gradle.org/distributions/gradle-7.4.1-bin.zip
zipStoreBase=GRADLE_USER_HOME
zipStorePath=wrapper/dists
</code></pre>
<p>GRADLE_USER_HOME是你的环境变量，如果没配置，则默认是用户目录下的.gradle文件夹</p>
<ul>
<li>distributionBase 下载的 Gradle压缩包解压后存储的主目录</li>
<li>distributionPath 相对于 distributionBase的解压后的 Gradle压缩包的路径</li>
<li>zipStoreBase 同 distributionBase，只不过是存放 zip压缩包的</li>
<li>zipStorePath 同 distributionPath，只不过是存放 zip压缩包的</li>
<li>distributionUrl Gradle发行版压缩包的下载地址</li>
</ul>
<h2 id="使用wrapper构建">使用wrapper构建</h2>
<p>在 gradlew目录下执行命令：<br>
windows：</p>
<pre><code class="language-shell">gradlew.bat build
</code></pre>
<p>shell：</p>
<pre><code class="language-shell">./gradlew build
</code></pre>
<h2 id="升级">升级</h2>
<ul>
<li>更改gradle-wrapper.properties文件中的distributionUrl属性</li>
<li>使用gradlew wrap --gradle-version 命令</li>
</ul>
<pre><code class="language-shell">./gradlew wrap --gradle-version 7.4.2
</code></pre>
<h2 id="自定义gradle_wrap">自定义Gradle_Wrap</h2>
<p>可以通过自定义wrapper少去一些重复操作或定制功能，如</p>
<p>build.gradle</p>
<pre><code class="language-java">tasks.named('wrapper') {
    distributionType = Wrapper.DistributionType.ALL
}
task wrapper(type: Wrapper) {
    gradleVersion = '7.4.2'
}
</code></pre>
<h1 id="gradle-环境">Gradle 环境</h1>
<h2 id="环境变量">环境变量</h2>
<p><code>GRADLE_OPTS</code></p>
<p>指定启动Gradle客户端VM时要使用的JVM参数。客户端VM仅处理命令行输入/输出，因此很少需要更改其VM选项。实际的构建由Gradle守护程序运行，不受此环境变量的影响。</p>
<p><code>GRADLE_USER_HOME</code></p>
<p>指定Gradle用户的主目录（如果未设置，则默认为$USER_HOME/.gradle）。</p>
<p><code>JAVA_HOME</code></p>
<p>指定要用于客户端VM的JDK安装目录。除非Gradle属性文件使用org.gradle.java.home指定了另一个虚拟机，否则此虚拟机也用于守护程序。</p>
<p>注意：命令行选项和系统属性优先于环境变量。</p>
<h2 id="gradle属性">Gradle属性</h2>
<p>你可以通过以下方式自己配置你的项目属性，如果存在多个，则从上到下优先读取 ：</p>
<ul>
<li>系统属性，例如在命令行上设置 <code>-Dgradle.user.home</code></li>
<li>GRADLE_USER_HOME目录中的<code>gradle.properties</code></li>
<li>项目根目录中的<code>gradle.properties</code></li>
<li>Gradle安装目录中的<code>gradle.properties</code></li>
</ul>
<p>gradle.properties</p>
<pre><code class="language-shell"># 当设置为true时，Gradle将在可能的情况下重用任何先前构建的任务输出，从而使构建速度更快
org.gradle.caching=true
 
# 设置为true时，单个输入属性哈希值和每个任务的构建缓存键都记录在控制台上。
org.gradle.caching.debug=true
 
# 启用按需孵化配置，Gradle将尝试仅配置必要的项目。
org.gradle.configureondemand=true
 
# 自定义控制台输出的颜色或详细程度。默认值取决于Gradle的调用方式。可选(auto,plain,rich,verbose)
org.gradle.console=auto
 
# 当设置true的Gradle守护进程来运行构建。默认值为true。
org.gradle.daemon=true
 
# 在指定的空闲毫秒数后，Gradle守护程序将自行终止。默认值为10800000（3小时）。
org.gradle.daemon.idletimeout=10800000
 
# 设置true为时，Gradle将在启用远程调试的情况下运行构建，侦听端口5005。
# 请注意，这等同于添加-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=5005到JVM命令行，并且将挂起虚拟机，直到连接了调试器。
# 默认值为false。
org.gradle.debug=true
 
# 指定用于Gradle构建过程的Java主页。可以将值设置为jdk或jre位置，但是，根据您的构建方式，使用JDK更安全。
# 如果未指定设置，则从您的环境（JAVA_HOME或的路径java）派生合理的默认值。这不会影响用于启动Gradle客户端VM的Java版本（请参阅环境变量）。
org.gradle.java.home=/usr/bin/java
        
# 指定用于Gradle守护程序的JVM参数。该设置对于配置JVM内存设置以提高构建性能特别有用。这不会影响Gradle客户端VM的JVM设置。
org.gradle.jvmargs=-Xmx2048m
 
# 当设置为quiet,warn,lifecycle,info,debug时，Gradle将使用此日志级别。这些值不区分大小写。该lifecycle级别是默认级别。
# 可选(quiet,warn,lifecycle,info,debug)
org.gradle.logging.level=debug
 
# 配置后，Gradle将分叉到org.gradle.workers.maxJVM以并行执行项目
org.gradle.parallel=true
        
# 指定Gradle守护程序及其启动的所有进程的调度优先级。默认值为normal。(low,normal)
org.gradle.priority=normal
        
# 在监视文件系统时配置详细日志记录。 默认为关闭 。
org.gradle.vfs.verbose=true
 
# 切换观看文件系统。允许Gradle在下一个版本中重用有关文件系统的信息。 默认为关闭 。
org.gradle.vfs.watch=true
 
# 当设置为all，summary或者none，Gradle会使用不同的预警类型的显示器。(all,fail,summary,none)
org.gradle.warning.mode=all
 
# 配置后，Gradle将最多使用给定数量的工人。默认值为CPU处理器数。
org.gradle.workers.max=5
</code></pre>
<h3 id="系统属性">系统属性</h3>
<pre><code class="language-shell"># 指定用户名以使用HTTP基本认证从服务器下载Gradle发行版
systemProp.gradle.wrapperUser = myuser
# 指定使用Gradle Wrapper下载Gradle发行版的密码
systemProp.gradle.wrapperPassword = mypassword
# 指定Gradle用户的主目录
systemProp.gradle.user.home=(path to directory)
</code></pre>
<h3 id="项目属性">项目属性</h3>
<pre><code class="language-shell">org.gradle.project.foo = bar
</code></pre>
<h2 id="守护程序">守护程序</h2>
<p>Gradle在Java虚拟机（JVM）上运行，并使用一些支持库，这些库需要很短的初始化时间。但有时启动会比较慢。<br>
解决此问题的方法是Gradle Daemon ：这是一个长期存在的后台进程，与以前相比，它可以更快地执行构建。</p>
<p>可通过命令获取运行守护程序状态</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1658230731202.png" alt="" loading="lazy"></figure>
<p>IDLE为空闲，BUSY为繁忙，STOPPED则已关闭</p>
<p>守护程序默认打开，可通过以下属性关闭<br>
<code>.gradle/gradle.properties</code></p>
<pre><code class="language-shell">org.gradle.daemon=false
</code></pre>
<p>也可用命令gradle --stop手动关闭守护程序</p>
<h1 id="gradle命令行">Gradle命令行</h1>
<p>命令行格式</p>
<pre><code class="language-shell">gradle [taskName ...] [--option-name ...]
</code></pre>
<p>如果指定了多个任务，则应以空格分隔。</p>
<p>选项和参数之间建议使用<code>=</code>来指定。</p>
<pre><code class="language-shell">--console=plain
</code></pre>
<p>启用行为的选项具有长形式的选项，并带有由指定的反函数<code>--no-</code>。以下是相反的情况。</p>
<pre><code class="language-shell">--build-cache
--no-build-cache
</code></pre>
<p>许多命令具有缩写。例如以下命令是等效的：</p>
<pre><code class="language-shell">--help
-h
</code></pre>
<p>使用Wrapper时候应该用<code>./gradlew</code>或<code>gradlew.bat</code>取代<code>gradle</code></p>
<pre><code class="language-shell">#获取帮助
gradle -?
gradle -h
gradle -help
 
# 显示所选项目的子项目列表，以层次结构显示。
gradle projects
#查看可执行task
gradle task
#查看可执行task帮助
gradle help -task
 
# 在Gradle构建中，通常的`build`任务是指定组装所有输出并运行所有检查。
gradle build
# 执行所有验证任务（包括test和linting）。
gradle check
# 清理项目
gradle clean
#强制刷新依赖
gradle --refresh-dependencies assemble
 
#缩写调用
gradle startCmd
== 
gradle sc
 
 
# 执行任务
gradle myTask
# 执行多个任务
gradle myTask test
# 执行 dist任务但排除test任务
gradle dist --exclude-task test
# 强制执行任务
gradle test --rerun-tasks
 
# 持续构建
# gradle test --continue
 
# 生成扫描会提供完整的可视化报告，说明哪些依赖项存在于哪些配置，可传递依赖项和依赖项版本选择中。
$ gradle myTask --scan
 
# 所选项目的依赖项列表
$ gradle dependencies
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[gradle详情]]></title>
        <id>https://tinaxiawuhao.github.io/post/29jyrX-eN/</id>
        <link href="https://tinaxiawuhao.github.io/post/29jyrX-eN/">
        </link>
        <updated>2021-07-01T11:57:30.000Z</updated>
        <content type="html"><![CDATA[<h3 id="一-依赖管理">一 依赖管理</h3>
<p>implementation:会将指定的依赖添加到编译路径，并且会将该依赖打包到输出，但是这个依赖在编译时不能暴露给其他模块，例如依赖此模块的其他模块。这种方式指定的依赖在编译时只能在当前模块中访问。</p>
<p>api:使用api配置的依赖会将对应的依赖添加到编译路径，并将依赖打包输出，但是这个依赖是可以传递的，比如模块A依赖模块B，B依赖库C，模块B在编译时能够访问到库C，但是与implemetation不同的是，在模块A中库C也是可以访问的。</p>
<p>compileOnly:compileOnly修饰的依赖会添加到编译路径中，但是不会打包，因此只能在编译时访问，且compileOnly修饰的依赖不会传递。</p>
<p>runtimeOnly:这个与compileOnly相反，它修饰的依赖不会添加到编译路径中，但是被打包，运行时使用。没有使用过。</p>
<p>annotationProcessor:用于注解处理器的依赖配置</p>
<pre><code class="language-java">dependencies {
    // 本地项目
    api project(':com.test.core:core-common')  
    //外部依赖
    implementation 'org.springframework.boot:spring-boot-starter'
    compileOnly 'org.projectlombok:lombok'
    annotationProcessor 'org.projectlombok:lombok'
    testImplementation 'org.springframework.boot:spring-boot-starter-test'
}
</code></pre>
<h3 id="二-仓库">二 仓库</h3>
<p><strong>远程仓库</strong><br>
使用Maven中央仓库，maven仓库的URL为：<a href="https://links.jianshu.com/go?to=http%3A%2F%2Frepo1.maven.org%2Fmaven2%2F">http://repo1.maven.org/maven2/</a></p>
<pre><code class="language-java">repositories {
    mavenCentral()
}
</code></pre>
<p>使用Maven远程仓库</p>
<pre><code class="language-java">repositories {
    //阿里云远程仓库
    maven { url 'https://maven.aliyun.com/repository/central'}
	maven { url 'https://maven.aliyun.com/repository/public' }
    mavenCentral()
}
</code></pre>
<p><strong>本地仓库</strong><br>
配置Gradle使用maven本地仓库：<code>CRADLE_USER_HOME：D:.m2\repository</code></p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1657022747903.png" alt="img" loading="lazy"></figure>
<p>修改配置build.gradle：</p>
<pre><code class="language-java">/**
 * 指定所使用的仓库，mavenCentral()表示使用中央仓库，
 * 此刻项目中所需要的jar包都会默认从中央仓库下载到本地指定目录
 * 配置mavenLocal()表示引入jar包的时候，先从本地仓库中找，没有再去中央仓库下载
 */
repositories {
    mavenLocal()
    mavenCentral()
}
</code></pre>
<p><strong>修改或者添加额外的私有仓库地址</strong><br>
直接修改 settings.gradle 来添加其它仓库：</p>
<pre><code class="language-java">// settings.gradle
//pluginManagement {}块只能出现在settings.gradle文件中，必须是文件中的第一个块，也可以以settings形式出现在初始化脚本中。
pluginManagement {
    repositories {
		maven { url 'https://maven.aliyun.com/repository/central'}
		maven { url 'https://maven.aliyun.com/repository/public' }
		mavenCentral()
		gradlePluginPortal()
		maven {
			url 'https://repo.spring.io/release'
		}
		if (version.endsWith('-SNAPSHOT')) {
			maven { url &quot;https://repo.spring.io/snapshot&quot; }
		}
	}
}
</code></pre>
<h3 id="三-多项目构建">三 多项目构建</h3>
<p>多项目构成：allProjects = root项目+各子项目<br>
settings文件声明了所需的配置来实例化项目的层次结构。在默认情况下，这个文件被命名为settings.gradle，并且和根项目的build.gradle文件放在一起，该文件在初始化阶段被执行。根项目就像一个容器，子项目会迭代访问它的配置并注入到自己的配置中。</p>
<p><strong>多项目构建</strong><br>
多项目构建总是需要指定一个树根，树中的每一个节点代表一个项目，每一个Project对象都指定有一个表示在树中位置的路径；在设置文件中我们还可以使用一套方法来自定义构建项目树。<br>
settings.gradle作用就是用于多项目构建，一般像这样：</p>
<pre><code class="language-java">//父模块名称
rootProject.name = 'nacos'
//引入子模块
include 'sentinel'
include 'openfeign'
include 'loadbalancer'
include 'gateway'
include 'rocketmq'
include 'sleuth'
include 'seata'
include 'provide'
findProject(':iot-service:user-center')?.name = 'user-center'
</code></pre>
<p><strong>buildScript</strong><br>
buildScript块的repositories主要是为了Gradle脚本自身的执行，获取脚本依赖插件。<br>
buildscript中的声明是gradle脚本自身需要使用的资源。可以声明的资源包括依赖项、第三方插件、maven仓库地址等。<br>
gradle在执行脚本时，会优先执行buildscript代码块中的内容，然后才会执行剩余的build脚本。</p>
<pre><code class="language-java">buildscript {
    ext {
        //spring-cloud-dependencies 2020.0.0 默认不在加载bootstrap 配置文件，
        //如果项目中要用bootstrap 配置文件 需要手动添加spring-cloud-starter-bootstrap 依赖，不然启动项目会报错的。
        set('springCloudVersion', &quot;2021.0.3&quot;)
        //定义一个变量，统一规定springboot的版本
        set('springBootVersion', &quot;2.6.8&quot;)
        set('alibabaVersion', &quot;2.2.7.RELEASE&quot;)
        set('lombok', &quot;1.18.16&quot;)
        set('knife4j', &quot;2.0.9&quot;)
        set('hutool', &quot;4.6.3&quot;)
        set('rocketmq', &quot;2.2.2&quot;)
    }
    repositories {
        mavenLocal()
        maven { url 'https://maven.aliyun.com/repository/central' }
        maven { url 'https://maven.aliyun.com/repository/public' }
        mavenCentral()
    }

    dependencies {
        //用来打包
        classpath(&quot;org.springframework.boot:spring-boot-gradle-plugin:${springBootVersion}&quot;)
    }
}
</code></pre>
<p>ext：ext是自定义属性，现在很多人都喜欢把所有关于版本的信息都利用ext放在另一个自己新建的gradle文件中集中管理。</p>
<p><strong>allprojects</strong><br>
allprojects块的repositories用于多项目构建，为所有项目提供共同所需依赖包。而子项目可以配置自己的repositories以获取自己独需的依赖包。</p>
<blockquote>
<p>buildscript和allprojects的作用和区别：<br>
buildscript中的声明是gradle脚本自身需要使用的资源，就是说它自己需要的资源，跟你其它模块其实并没有什么关系。而allprojects声明的却是<code>所有module</code>所需要使用的资源，就是说你的每个module都需要用同一个第三库的时候，可以在allprojects里面声明。</p>
</blockquote>
<pre><code class="language-java">allprojects {
    apply plugin: 'java-library'
    apply plugin: 'idea'

    //下面两句必须在所有子项目中添加，否则导致import了看起来没问题，但是编译时找不到其他模块的类。
    group = 'com.example'
    version = '0.0.1-SNAPSHOT'
    // 指定JDK版本
    sourceCompatibility = 1.8
    targetCompatibility = 1.8

    repositories {
        mavenLocal()
        maven { url 'https://maven.aliyun.com/repository/central' }
        maven { url 'https://maven.aliyun.com/repository/public' }
        mavenCentral()
    }

    //指定编码格式
    tasks.withType(JavaCompile) {
        options.encoding = &quot;UTF-8&quot;
    }
}
</code></pre>
<p><strong>subprojects子项目通用配置</strong><br>
subprojects是对所有Child Project的配置:</p>
<pre><code class="language-java">subprojects {
    apply plugin: 'java-library'
    apply plugin: 'idea'
    apply plugin: 'org.springframework.boot'
    //dependency-management 插件
    apply plugin: 'io.spring.dependency-management'

    repositories {
        mavenLocal()
        maven { url 'https://maven.aliyun.com/repository/central' }
        maven { url 'https://maven.aliyun.com/repository/public' }
        mavenCentral()
    }
    
    dependencies {
        implementation(enforcedPlatform(&quot;org.springframework.cloud:spring-cloud-dependencies:${springCloudVersion}&quot;))
        implementation(enforcedPlatform(&quot;com.alibaba.cloud:spring-cloud-alibaba-dependencies:${alibabaVersion}&quot;))
        implementation(enforcedPlatform(&quot;org.springframework.boot:spring-boot-dependencies:${springBootVersion}&quot;))
        implementation &quot;com.github.xiaoymin:knife4j-spring-boot-starter:${knife4j}&quot;
        implementation &quot;cn.hutool:hutool-all:${hutool}&quot;
        implementation 'org.springframework.boot:spring-boot-starter'
        implementation 'com.alibaba.cloud:spring-cloud-starter-alibaba-nacos-config'
        implementation('com.alibaba.cloud:spring-cloud-starter-alibaba-nacos-discovery'){
            exclude group: 'org.springframework.cloud', module: 'spring-cloud-starter-netflix-ribbon'
        }
        implementation 'org.springframework.cloud:spring-cloud-starter-bootstrap'
        compileOnly(&quot;org.projectlombok:lombok:${lombok}&quot;)
        annotationProcessor 'org.springframework.boot:spring-boot-configuration-processor'
        annotationProcessor(&quot;org.projectlombok:lombok:${lombok}&quot;)
        testImplementation(&quot;org.springframework.boot:spring-boot-starter-test:${springBootVersion}&quot;)
    }

    jar {
        manifest.attributes provider: 'gradle'
    }

}
</code></pre>
<h3 id="四-gradleproperties">四 gradle.properties</h3>
<p>gradle中的常用属性可以写在gradle.properties中。<br>
  一般我们都把全局属性都编写在一个工具类中，如果是有环境的切换的话，那么我们还会定义一个标志来进行相应的变换。对于项目而言，有时候需要配置某些敏感信息。比如密码，帐号等。而这些信息需要被很多类共同使用，所以必须有一个全局的配置。当需要把项目push到git上时，我们不希望别人看到我们项目的key，token等。我们可以将这些信息设置在gradle.properties中。<br>
只有在Android中才可使用。</p>
<pre><code class="language-java">AppKey = 1234567890
</code></pre>
<p>在build.gradle(module app)中进行变量的重定义，即将配置内容转化成java能够使用的形式:</p>
<pre><code class="language-java">android {
    buildTypes {
        release {
            minifyEnabled true
            proguardFiles getDefaultProguardFile('proguard-android.txt'), 'proguard-rules.pro'
            //buildConfigField用于给BuildConfig文件添加一个字段
            buildConfigField(&quot;String&quot;,&quot;KEY&quot;,&quot;\&quot;${AppKey}\&quot;&quot;)
        }
        debug{
            buildConfigField(&quot;String&quot;,&quot;KEY&quot;,&quot;\&quot;${AppKey}\&quot;&quot;)
        }
    }
}
</code></pre>
<h3 id="五-gradle-插件plugins">五 Gradle 插件(Plugins)</h3>
<p>Gradle 也可以用下面的方式声明使用的插件：</p>
<pre><code class="language-java">// plugins DSL
plugins {
    id 'org.springframework.boot' version '2.2.1.RELEASE'
    id 'io.spring.dependency-management' version '1.0.8.RELEASE'
    id 'java'
}

// apply plugin
apply plugin: 'java-library'
apply plugin: 'idea'
apply plugin: 'org.springframework.boot'
//dependency-management 插件
apply plugin: 'io.spring.dependency-management'
</code></pre>
<p>其实是从 Gradle 官方的插件仓库<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fplugins.gradle.org%2Fm2%2F">https://plugins.gradle.org/m2/</a>下载的。</p>
<h3 id="六-常见的task命令">六 常见的task命令</h3>
<p><code>build</code>:当运行gradle build命令时Gradle将会编译和测试你的代码，并且创建一个包含类和资源的JAR文件。<br>
<code>clean</code>:当运行gradle clean命令时Gradle将会删除build生成的目录和所有生成的文件。<br>
<code>assemble</code>:当运行gradle assemble命令时Gradle将会编译并打包代码，但是并不运行单元测试。<br>
<code>check</code>:当运行gradle check命令时Gradle将会编译并测试你的代码，其他的插件会加入更多的检查步骤。</p>
<h3 id="七-gradle-wrapper">七 gradle-wrapper</h3>
<p>Wrapper是对Gradle的一层包装，便于在团队开发过程中统一Gradle构建的版本号，这样大家都可以使用统一的Gradle版本进行构建。</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1657022568864.png" alt="img" loading="lazy"></figure>
<pre><code class="language-java">distributionBase=GRADLE_USER_HOME
distributionPath=wrapper/dists
distributionUrl=https\://services.gradle.org/distributions/gradle-7.4.2-bin.zip
#distributionUrl=file:///E:/gradle/gradle-7.4.2-all.zip
zipStoreBase=GRADLE_USER_HOME
zipStorePath=wrapper/dists
</code></pre>
<p>distributionUrl是要下载的gradle的地址，使用哪个版本的gradle，就在这里修改。</p>
<p>gradle的3种版本：<br>
gradle-xx-all.zip是完整版，包含了各种二进制文件，源代码文件，和离线的文档。<br>
gradle-xx-bin.zip是二进制版，只包含了二进制文件（可执行文件），没有文档和源代码。<br>
gradle-xx-src.zip是源码版，只包含了Gradle源代码，不能用来编译你的工程。</p>
<p>zipStoreBase和zipStorePath组合在一起，是下载的gradle-3.1-bin.zip所存放的位置。<br>
zipStorePath是zipStoreBase指定的目录下的子目录。</p>
<p>distributionBase和distributionPath组合在一起，是解压gradle-5.6.4-bin.zip之后的文件的存放位置。<br>
distributionPath是distributionBase指定的目录下的子目录。</p>
<p>下载位置可以和解压位置不一样。</p>
<p>zipStoreBase和distributionBase有两种取值：GRADLE_USER_HOME和PROJECT。<br>
其中，GRADLE_USER_HOME表示用户目录。<br>
在windows下是%USERPROFILE%/.gradle，例如C:\Users&lt;user_name&gt;.gradle\。<br>
在linux下是$HOME/.gradle，例如~/.gradle。<br>
PROJECT表示工程的当前目录，即gradlew所在的目录。</p>
<h3 id="八-依赖分组">八 依赖分组</h3>
<p>Gradle 依赖是分组的 ,分组是在 org.gradle.api.Project 中的 configurations 中配置的 ,如 &quot; implementation &quot; , &quot; compile &quot; 等都是分组 , 这些分组都是在 org.gradle.api.Project#configurations 中进行配置 , 也就是 build.gradle#configurations 中配置 ;</p>
<p><strong>build.gradle#configurations 自定义依赖分组</strong></p>
<p>在 build.gradle 中配置 configurations :</p>
<pre><code class="language-groovy">configurations {
  hello {
  }
}
</code></pre>
<p>则可以在 dependencies 中使上述在 configurations 配置的依赖分组 hello ,</p>
<pre><code class="language-java">dependencies {
  hello 'com.android.support:appcompat-v7:28.0.0'
}
</code></pre>
<h3 id="九-依赖版本冲突">九 依赖版本冲突</h3>
<p>Gradle对解决传递依赖提供了两种策略，使用最新版本或者直接导致构建失败。默认的策略是使用最新版本。虽然这样的策略能够解决一些问题，但是还是不够。常见的一种情况是，NoSuchMethond或者ClassNotFound。这时候，你可能需要一些特殊手段，比如排除不想要的传递依赖。<br>
排除传递依赖的方式有两种：</p>
<blockquote>
<p>1.使用transitive = false排除</p>
<p>2.在具体的某个dependency中使用exclude排除</p>
<p>3.使用force强制依赖某个版本</p>
</blockquote>
<pre><code class="language-java">(1) 方案一：针对 A 或 D 配置 transitive。
    这里针对A配置，不解析A模块的传递依赖，因此当前Module的依赖关系树中不再包含 B1 和 C，这里需要手动添加依赖 C
dependencies {
    implementation A {
      transitive = false
    }
    implementation C
    implementation D {
      //transitive = false
    }
}

(2) 方案二：针对 A 或 D 配置 exclude规则，此处针对A配置，依赖关系树中不再包含B1
dependencies {
    implementation A {
      exclude  B1
    }
    implementation D {
      //exclude  B2
    }
}

(3) 方案三：使用force强制依赖某个版本，如强制依赖 B1 或者 B2
        以下是在顶层build.gradle中配置，强制所有module依赖B1
configurations.all {
    resolutionStrategy {
       force B1
       // force B2
    }
}
</code></pre>
<h3 id="十-springcloud-gradle管理">十 springcloud-gradle管理</h3>
<p><strong>parent:settings.gradle</strong></p>
<pre><code class="language-groovy">rootProject.name = 'nacos'
include 'sentinel'
include 'openfeign'
include 'loadbalancer'
include 'gateway'
include 'rocketmq'
include 'sleuth'
include 'seata'
include 'provide'
</code></pre>
<p><strong>parent:build.gradle</strong></p>
<pre><code class="language-groovy">buildscript {
    ext {
        //spring-cloud-dependencies 2020.0.0 默认不在加载bootstrap 配置文件，
        //如果项目中要用bootstrap 配置文件 需要手动添加spring-cloud-starter-bootstrap 依赖，不然启动项目会报错的。
        set('springCloudVersion', &quot;2021.0.3&quot;)
        //定义一个变量，统一规定springboot的版本
        set('springBootVersion', &quot;2.6.8&quot;)
        set('alibabaVersion', &quot;2.2.7.RELEASE&quot;)
        set('lombok', &quot;1.18.16&quot;)
        set('knife4j', &quot;2.0.9&quot;)
        set('hutool', &quot;4.6.3&quot;)
        set('rocketmq', &quot;2.2.2&quot;)
    }
    repositories {
        mavenLocal()
        maven { url 'https://maven.aliyun.com/repository/central' }
        maven { url 'https://maven.aliyun.com/repository/public' }
        mavenCentral()
    }

    dependencies {
        //用来打包
        classpath(&quot;org.springframework.boot:spring-boot-gradle-plugin:${springBootVersion}&quot;)
    }
}

allprojects {
    apply plugin: 'java-library'
    apply plugin: 'idea'

    //下面两句必须在所有子项目中添加，否则导致import了看起来没问题，但是编译时找不到其他模块的类。
    group = 'com.example'
    version = '0.0.1-SNAPSHOT'
    // 指定JDK版本
    sourceCompatibility = 1.8
    targetCompatibility = 1.8

    repositories {
        mavenLocal()
        maven { url 'https://maven.aliyun.com/repository/central' }
        maven { url 'https://maven.aliyun.com/repository/public' }
        mavenCentral()
    }

    //指定编码格式
    tasks.withType(JavaCompile) {
        options.encoding = &quot;UTF-8&quot;
    }
}


subprojects {
    apply plugin: 'java-library'
    apply plugin: 'idea'
    apply plugin: 'org.springframework.boot'
    //dependency-management 插件
    apply plugin: 'io.spring.dependency-management'

    dependencies {
        implementation(enforcedPlatform(&quot;org.springframework.cloud:spring-cloud-dependencies:${springCloudVersion}&quot;))
        implementation(enforcedPlatform(&quot;com.alibaba.cloud:spring-cloud-alibaba-dependencies:${alibabaVersion}&quot;))
        implementation(enforcedPlatform(&quot;org.springframework.boot:spring-boot-dependencies:${springBootVersion}&quot;))
        implementation &quot;com.github.xiaoymin:knife4j-spring-boot-starter:${knife4j}&quot;
        implementation &quot;cn.hutool:hutool-all:${hutool}&quot;
        implementation 'org.springframework.boot:spring-boot-starter'
        implementation 'com.alibaba.cloud:spring-cloud-starter-alibaba-nacos-config'
        implementation('com.alibaba.cloud:spring-cloud-starter-alibaba-nacos-discovery'){
            exclude group: 'org.springframework.cloud', module: 'spring-cloud-starter-netflix-ribbon'
        }
        implementation 'org.springframework.cloud:spring-cloud-starter-bootstrap'
        compileOnly(&quot;org.projectlombok:lombok:${lombok}&quot;)
        annotationProcessor 'org.springframework.boot:spring-boot-configuration-processor'
        annotationProcessor(&quot;org.projectlombok:lombok:${lombok}&quot;)
        testImplementation(&quot;org.springframework.boot:spring-boot-starter-test:${springBootVersion}&quot;)
    }

    jar {
        manifest.attributes provider: 'gradle'
    }

}
</code></pre>
<p><strong>gateway:build.gradle</strong></p>
<pre><code class="language-groovy">dependencies {
	implementation &quot;org.springframework.cloud:spring-cloud-starter-gateway&quot;
	implementation &quot;org.springframework.cloud:spring-cloud-starter-loadbalancer&quot;
}
</code></pre>
<p><strong>openfeign:build.gradle</strong></p>
<pre><code class="language-groovy">dependencies {
	implementation 'org.springframework.boot:spring-boot-starter-web'
	implementation &quot;org.springframework.cloud:spring-cloud-starter-openfeign&quot;
	implementation &quot;org.springframework.cloud:spring-cloud-starter-loadbalancer&quot;
}

</code></pre>
<p><strong>rocketmq:build.gradle</strong></p>
<pre><code class="language-groovy">dependencies {
	implementation 'org.springframework.boot:spring-boot-starter-web'
	implementation &quot;org.apache.rocketmq:rocketmq-spring-boot-starter:${rocketmq}&quot;
}
</code></pre>
<p><strong>sentinel:build.gradle</strong></p>
<pre><code class="language-groovy">dependencies {
	implementation 'org.springframework.boot:spring-boot-starter-web'
	implementation 'com.alibaba.cloud:spring-cloud-starter-alibaba-sentinel'
	implementation 'org.springframework.boot:spring-boot-starter-actuator'
}
</code></pre>
<h3 id="项目构建-gradle-docker打包">项目构建--Gradle--Docker打包</h3>
<p>在<code>build.gradle</code>中引入插件。</p>
<pre><code class="language-java"> id &quot;com.google.cloud.tools.jib&quot; version &quot;3.2.1&quot;
</code></pre>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1657022594521.png" alt="img" loading="lazy"></figure>
<p><strong>配置</strong><br>
配置打包时的基础镜像、容器配置、私服地址等，和Maven 插件中的一样，只是采用闭包的书写方式。</p>
<p><a href="https://github.com/GoogleContainerTools/jib/tree/master/jib-gradle-plugin#quickstart">Jib 官网文档</a></p>
<pre><code class="language-java">jib {
    // 基础镜像，来自dockerhub,如果是私服，需要加上鉴权信息，和to下的auth节点相同
    // https://hub.docker.com/
    from {
        image = 'xx'
    }
    // 构建后的镜像名称以及私服地址、鉴权信息
    to {
        image = 'xx'
        auth {
            username = '登录账号'
            password = '登录密码'
        }
    }
    // 容器相关设置
    container {
        // 创建时间
        creationTime = new Date()
        // JVM 启动参数
        jvmFlags = ['-Djava.security.egd=file:/dev/./urandom', '-Dspring.profiles.active=prod', '-Dfile.encoding=utf-8', '-Duser.timezone=GMT+08']
        // 启动类
        // mainClass = 'com.xxx.RunApplication'
        // 容器在运行时公开的端口
        ports = ['8080']
        // 放置应用程序内容的容器上的根目录
        appRoot = '/deploy/service'
    }
}
</code></pre>
<h4 id="使用ideadocker插件布署">使用IdeaDocker插件布署</h4>
<p><strong>Idea安装插件</strong></p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1657022607710.png" alt="img" loading="lazy"></figure>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1657022616011.png" alt="img" loading="lazy"></figure>
<p><strong>安装docker插件</strong></p>
<ol>
<li>配置docker：</li>
</ol>
<figure data-type="image" tabindex="6"><img src="https://tinaxiawuhao.github.io/post-images/1657022629349.png" alt="img" loading="lazy"></figure>
<figure data-type="image" tabindex="7"><img src="https://tinaxiawuhao.github.io/post-images/1657022637131.png" alt="img" loading="lazy"></figure>
<figure data-type="image" tabindex="8"><img src="https://tinaxiawuhao.github.io/post-images/1657022644128.png" alt="img" loading="lazy"></figure>
<p><strong>配置Dockerfile文件</strong><br>
1）新建Dockerfile文件会自动弹出。</p>
<figure data-type="image" tabindex="9"><img src="https://tinaxiawuhao.github.io/post-images/1657022651578.png" alt="img" loading="lazy"></figure>
<p>在工程根目录下新建Dockerfile文件，内容如下：</p>
<pre><code class="language-dockerfile">FROM openjdk:8
COPY build/libs/iot-eruake-1.0.0.jar app.jar
RUN bash -c &quot;touch /app.jar&quot;
EXPOSE 8080
ENTRYPOINT [&quot;java&quot;,&quot;-jar&quot;,&quot;app.jar&quot;]
</code></pre>
<p><strong>创建docker镜像</strong></p>
<figure data-type="image" tabindex="10"><img src="https://tinaxiawuhao.github.io/post-images/1657022660226.png" alt="img" loading="lazy"></figure>
<figure data-type="image" tabindex="11"><img src="https://tinaxiawuhao.github.io/post-images/1657022667209.png" alt="img" loading="lazy"></figure>
<figure data-type="image" tabindex="12"><img src="https://tinaxiawuhao.github.io/post-images/1657022673583.png" alt="img" loading="lazy"></figure>
<figure data-type="image" tabindex="13"><img src="https://tinaxiawuhao.github.io/post-images/1657022680599.png" alt="img" loading="lazy"></figure>
<p><strong>发布完成</strong></p>
<figure data-type="image" tabindex="14"><img src="https://tinaxiawuhao.github.io/post-images/1657022687210.png" alt="img" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[IdWorker雪花算法]]></title>
        <id>https://tinaxiawuhao.github.io/post/4WluurBt3/</id>
        <link href="https://tinaxiawuhao.github.io/post/4WluurBt3/">
        </link>
        <updated>2021-06-08T08:23:00.000Z</updated>
        <content type="html"><![CDATA[<pre><code class="language-java">package com.ihrm.common.utils;

import java.lang.management.ManagementFactory;
import java.net.InetAddress;
import java.net.NetworkInterface;

//雪花算法代码实现
public class IdWorker {
    // 时间起始标记点，作为基准，一般取系统的最近时间（一旦确定不能变动）
    private final static long twepoch = 1288834974657L;
    // 机器标识位数
    private final static long workerIdBits = 5L;
    // 数据中心标识位数
    private final static long datacenterIdBits = 5L;
    // 机器ID最大值
    private final static long maxWorkerId = -1L ^ (-1L &lt;&lt; workerIdBits);
    // 数据中心ID最大值
    private final static long maxDatacenterId = -1L ^ (-1L &lt;&lt; datacenterIdBits);
    // 毫秒内自增位
    private final static long sequenceBits = 12L;
    // 机器ID偏左移12位
    private final static long workerIdShift = sequenceBits;
    // 数据中心ID左移17位
    private final static long datacenterIdShift = sequenceBits + workerIdBits;
    // 时间毫秒左移22位
    private final static long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits;
    //毫秒内自增最大值
    private final static long sequenceMask = -1L ^ (-1L &lt;&lt; sequenceBits);
    /* 上次生产id时间戳 */
    private static long lastTimestamp = -1L;
    // 0，并发控制
    private long sequence = 0L;
    private final long workerId;
    // 数据标识id部分
    private final long datacenterId;

    public IdWorker() {
        this.datacenterId = getDatacenterId(maxDatacenterId);
       this.workerId = getMaxWorkerId(datacenterId, maxWorkerId);
    }

    /**
     * @param workerId     工作机器ID
     * @param datacenterId 序列号
     */
    public IdWorker(long workerId, long datacenterId) {
        if (workerId &gt; maxWorkerId || workerId &lt; 0) {
            throw new IllegalArgumentException(String.format(&quot;worker Id can't be greater than % d or less than 0&quot;, maxWorkerId));
        }
        if (datacenterId &gt; maxDatacenterId || datacenterId &lt; 0) {
            throw new IllegalArgumentException(String.format(&quot;datacenter Id can't be greater than % d or less than 0&quot;, maxDatacenterId));
        }
        this.workerId = workerId;
        this.datacenterId = datacenterId;
    }

    /**
     * 获取下一个ID
     *
     * @return
     */
    public synchronized long nextId() {
        long timestamp = timeGen();
        if (timestamp &lt; lastTimestamp) {
            throw new RuntimeException(String.format(&quot;Clock moved backwards. Refusing to generate id for %d milliseconds &quot;, lastTimestamp - timestamp));
        }
        if (lastTimestamp == timestamp) {
            // 当前毫秒内，则+1
            sequence = (sequence + 1) &amp; sequenceMask;
            if (sequence == 0) {
                // 当前毫秒内计数满了，则等待下一秒
                timestamp = tilNextMillis(lastTimestamp);
            }
        } else {
            sequence = 0L;
        }
        lastTimestamp = timestamp;
        // ID偏移组合生成最终的ID，并返回ID
        long nextId = ((timestamp - twepoch) &lt;&lt; timestampLeftShift)
                | (datacenterId &lt;&lt; datacenterIdShift)
                | (workerId &lt;&lt; workerIdShift) | sequence;
        return nextId;
    }

    private long tilNextMillis(final long lastTimestamp) {
        long timestamp = this.timeGen();
        while (timestamp &lt;= lastTimestamp) {
            timestamp = this.timeGen();
        }
        return timestamp;
    }

    private long timeGen() {
        return System.currentTimeMillis();
    }

    /**
     * &lt;p&gt;
     * 获取 maxWorkerId
     * &lt;/p&gt;
     */
    protected static long getMaxWorkerId(long datacenterId, long maxWorkerId) {
        StringBuffer mpid = new StringBuffer();
        mpid.append(datacenterId);
        String name = ManagementFactory.getRuntimeMXBean().getName();
        if (!name.isEmpty()) {
            /*
             * GET jvmPid
             */
            mpid.append(name.split(&quot;@&quot;)[0]);
        }
        /*
         * MAC + PID 的 hashcode 获取16个低位
         */
        return (mpid.toString().hashCode() &amp; 0xffff) % (maxWorkerId + 1);
    }

    /**
     * &lt;p&gt;
     * 数据标识id部分
     * &lt;/p&gt;
     */
    protected static long getDatacenterId(long maxDatacenterId) {
        long id = 0L;
        try {
            InetAddress ip = InetAddress.getLocalHost();
            NetworkInterface network = NetworkInterface.getByInetAddress(ip);
            if (network == null) {
                id = 1L;
            } else {
                byte[] mac = network.getHardwareAddress();
                id = ((0x000000FF &amp; (long) mac[mac.length - 1])
                        | (0x0000FF00 &amp; (((long) mac[mac.length - 2]) &lt;&lt; 8))) &gt;&gt; 6;
                id = id % (maxDatacenterId + 1);
            }
        } catch (Exception e) {
            System.out.println(&quot; getDatacenterId: &quot; + e.getMessage());
        }
        return id;
    }
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[RestTemplate]]></title>
        <id>https://tinaxiawuhao.github.io/post/fFTlwaLS_/</id>
        <link href="https://tinaxiawuhao.github.io/post/fFTlwaLS_/">
        </link>
        <updated>2021-06-07T05:34:32.000Z</updated>
        <content type="html"><![CDATA[<h3 id="spring环境下">spring环境下</h3>
<p>首先导入springboot 的 web 包</p>
<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<p>在启动类同包下创建RestTemplate.java类</p>
<pre><code class="language-java">import org.apache.http.client.HttpClient;
import org.apache.http.client.config.RequestConfig;
import org.apache.http.impl.client.DefaultHttpRequestRetryHandler;
import org.apache.http.impl.client.HttpClientBuilder;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.http.client.ClientHttpRequestFactory;
import org.springframework.http.client.HttpComponentsClientHttpRequestFactory;
import org.springframework.web.client.RestTemplate;

@Configuration
public class RestTempleConfig {

    @Bean
    public RestTemplate restTemplate() {

        //生成一个设置了连接超时时间、请求超时时间
        RequestConfig config = RequestConfig.custom()
                .setConnectionRequestTimeout(10000)
                .setConnectTimeout(10000)
                .setSocketTimeout(30000).build();

        // 设置异常重试
        HttpClientBuilder builder = HttpClientBuilder.create()
                .setDefaultRequestConfig(config)
                .setRetryHandler(new DefaultHttpRequestRetryHandler(3, false));
        HttpClient httpClient = builder.build();

        ClientHttpRequestFactory requestFactory =
                new HttpComponentsClientHttpRequestFactory(httpClient);
        RestTemplate restTemplate = new RestTemplate(requestFactory);
        // 日志拦截
        //restTemplate.setInterceptors(Collections.singletonList(new RestTemplateConsumerLogger()));

        return restTemplate;
    }
}
</code></pre>
<h3 id="非spring环境下">非spring环境下</h3>
<p>导入相关依赖包(注意版本相适应)</p>
<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;org.springframework&lt;/groupId&gt;
    &lt;artifactId&gt;spring-web&lt;/artifactId&gt;
    &lt;version&gt;5.2.16.RELEASE&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt;
    &lt;artifactId&gt;httpclient&lt;/artifactId&gt;
    &lt;version&gt;4.5.2&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;
    &lt;artifactId&gt;jackson-core&lt;/artifactId&gt;
    &lt;version&gt;2.12.1&lt;/version&gt;
    &lt;scope&gt;compile&lt;/scope&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;
    &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt;
    &lt;version&gt;2.12.1&lt;/version&gt;
    &lt;scope&gt;compile&lt;/scope&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;
    &lt;artifactId&gt;jackson-annotations&lt;/artifactId&gt;
    &lt;version&gt;2.12.1&lt;/version&gt;
    &lt;scope&gt;compile&lt;/scope&gt;
&lt;/dependency&gt;
</code></pre>
<h3 id="resttemplate">RestTemplate</h3>
<p>RestTemplate定义了36个与REST资源交互的方法，大多数都对应于HTTP的方法。 其中只有11个独立的方法，其中有十个有三种重载形式，而第十一个则重载了六次，这样一共形成了36个方法。</p>
<ol>
<li>
<p>getForEntity() 发送一个HTTP GET请求，返回的ResponseEntity包含了响应体所映射成的对象</p>
</li>
<li>
<p>getForObject() 发送一个HTTP GET请求，返回的请求体将映射为一个对象</p>
</li>
<li>
<p>postForEntity() POST 数据到一个URL，返回包含一个对象的ResponseEntity，这个对象是从响应体中映射得到的</p>
</li>
<li>
<p>postForObject() POST 数据到一个URL，返回根据响应体匹配形成的对象</p>
</li>
<li>
<p>exchange() 在URL上执行特定的HTTP方法，返回包含对象的ResponseEntity，这个对象是从响应体中映射得到的</p>
</li>
<li>
<p>execute() 在URL上执行特定的HTTP方法，返回一个从响应体映射得到的对象</p>
</li>
<li>
<p>delete() 在特定的URL上对资源执行HTTP DELETE操作</p>
</li>
<li>
<p>headForHeaders() 发送HTTP HEAD请求，返回包含特定资源URL的HTTP头</p>
</li>
<li>
<p>optionsForAllow() 发送HTTP OPTIONS请求，返回对特定URL的Allow头信息</p>
</li>
<li>
<p>postForLocation() POST 数据到一个URL，返回新创建资源的URL</p>
</li>
<li>
<p>put() PUT 资源到特定的URL</p>
</li>
</ol>
<h4 id="getforentity">getForEntity</h4>
<p>get请求就和正常在浏览器url上发送请求一样</p>
<pre><code class="language-java">RestTemplate restTemplate = new RestTemplate();
ResponseEntity&lt;String&gt; responseEntity=restTemplate.getForEntity(url+&quot;?name={1}&quot;, String.class, &quot;username&quot;);
String body = responseEntity.getBody();
</code></pre>
<pre><code class="language-java">RestTemplate restTemplate = new RestTemplate();
ResponseEntity&lt;TokenBeen&gt; responseEntity =restTemplate.getForEntity(url+&quot;?name={1}&quot;, TokenBeen.class, &quot;username&quot;);
if(responseEntity!=null){
    TokenBeen body = responseEntity.getBody();
}
</code></pre>
<pre><code class="language-java">#注意map的key要和参数中占位符相同
RestTemplate restTemplate = new RestTemplate();
Map&lt;String, String&gt; params = new HashMap&lt;&gt;();
params.put(&quot;name&quot;, &quot;username&quot;);
ResponseEntity&lt;String&gt; responseEntity = restTemplate.getForEntity(url+&quot;?name={name}&quot;, String.class, params);
String body = responseEntity.getBody();
</code></pre>
<pre><code class="language-java">RestTemplate restTemplate = new RestTemplate();
UriComponents uriConponents = UriComponentsBuilder.fromUriString(url+&quot;?name={name}&quot;).build().expand(&quot;username&quot;).encode();
URI uri = uriConponents.toUri();
ResponseEntity&lt;String&gt; responseEntity = restTemplate.getForEntity(uri, String.class);
String body = responseEntity.getBody();
</code></pre>
<pre><code class="language-java">@GetMapping(&quot;getForEntity/{id}&quot;)
public User getById(@PathVariable(name = &quot;id&quot;) String id) {
    ResponseEntity&lt;User&gt; response = restTemplate.getForEntity(&quot;http://localhost/get/{id}&quot;, User.class, id);
    User user = response.getBody();
    return user;
}
</code></pre>
<h4 id="getforobject">getForObject</h4>
<p>getForObject 和 getForEntity 用法几乎相同,getForObject函数可以看作是对getForEntity进一步封装,指示返回值返回的是响应体,省去了我们 再去 getBody()</p>
<pre><code class="language-java">RestTemplate restTemplate = new RestTemplate();
//注意参数中是uri
UriComponents uriConponents = UriComponentsBuilder.fromUriString(url+&quot;?name={name}&quot;).build().expand(&quot;username&quot;).encode();
URI uri = uriConponents.toUri();
String body = restTemplate.getForObject(uri, String.class);
</code></pre>
<pre><code class="language-java">RestTemplate restTemplate = new RestTemplate();
//注意参数中是uri
UriComponents uriConponents = UriComponentsBuilder.fromUriString(url+&quot;?name={name}&quot;).build().expand(&quot;username&quot;).encode();
URI uri = uriConponents.toUri();
TokenBeen body = restTemplate.getForObject(uri, TokenBeen.class);
</code></pre>
<pre><code class="language-java">@GetMapping(&quot;getForObject/{id}&quot;)
public User getById(@PathVariable(name = &quot;id&quot;) String id) {
    User user = restTemplate.getForObject(&quot;http://localhost/get/{id}&quot;, User.class, id);
    return user;
}
</code></pre>
<h4 id="postforentity">postForEntity</h4>
<pre><code class="language-java">public &lt;T&gt; T postForObject(String url, @Nullable Object request, Class&lt;T&gt; responseType, Object... uriVariables)throws RestClientException {} 
public &lt;T&gt; T postForObject(String url, @Nullable Object request, Class&lt;T&gt; responseType, Map&lt;String, ?&gt; uriVariables) throws RestClientException {} 
public &lt;T&gt; T postForObject(URI url, @Nullable Object request, Class&lt;T&gt; responseType) throws RestClientException {}
</code></pre>
<pre><code class="language-java">RestTemplate restTemplate = new RestTemplate();
HttpHeaders headers = new HttpHeaders();
//header参数
MediaType type = MediaType.parseMediaType(&quot;application/json; charset=UTF-8&quot;);
headers.setContentType(type);
headers.add(&quot;Accept&quot;, MediaType.APPLICATION_JSON.toString());
//body参数
JSONObject param = new JSONObject();
param.put(&quot;username&quot;, &quot;123&quot;);
HttpEntity&lt;JSONObject&gt; formEntity = new HttpEntity&lt;&gt;(param, headers);
//发送请求
String result = restTemplate.postForObject(url, formEntity, String.class);
</code></pre>
<pre><code class="language-java">@RequestMapping(&quot;saveUser&quot;)
public String save(User user) {
    ResponseEntity&lt;String&gt; response = restTemplate.postForEntity(&quot;http://localhost/save&quot;, user, String.class);
    String body = response.getBody();
    return body;
}
</code></pre>
<h4 id="postforobject">postForObject</h4>
<p>用法与 getForObject 一样</p>
<pre><code class="language-java">@RequestMapping(&quot;saveUser&quot;)
public String save(User user) {
    String body = restTemplate.postForObject(&quot;http://localhost/save&quot;, user, String.class);
    return body;
}
</code></pre>
<h4 id="exchange">exchange</h4>
<pre><code class="language-java">@PostMapping(&quot;demo&quot;)
public void demo(Integer id, String name){
 
    HttpHeaders headers = new HttpHeaders();//header参数
    headers.add(&quot;authorization&quot;,Auth);
    headers.setContentType(MediaType.APPLICATION_JSON);

    JSONObject content = new JSONObject();//放入body中的json参数
    content.put(&quot;userId&quot;, id);
    content.put(&quot;name&quot;, name);

    //post发送
    HttpEntity&lt;JSONObject&gt; request = new HttpEntity&lt;&gt;(content,headers); //组装
    ResponseEntity&lt;String&gt; response = template.exchange(&quot;http://localhost:8080/demo&quot;,HttpMethod.POST,request,String.class);
    //返回指定对象
    ParameterizedTypeReference&lt;User&gt; responseBodyType = new ParameterizedTypeReference&lt;RestBean&lt;String&gt;&gt;() {};
    User user = template.exchange(&quot;http://localhost:8080/demo&quot;,HttpMethod.POST,request,responseBodyType);
    
    
    //get发送
    HttpEntity&lt;String&gt; request = new HttpEntity&lt;&gt;(&quot;parameters&quot;,headers); //组装
    ResponseEntity&lt;String&gt; response = template.exchange(&quot;http://localhost:8080/demo&quot;,HttpMethod.GET,request,String.class);
    //返回指定对象
    ResponseEntity&lt;User&gt; response = template.exchange(&quot;http://localhost:8080/demo&quot;,HttpMethod.GET,request,User.class);
}
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1623908192461.png" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[SpringBoot  JWT实现]]></title>
        <id>https://tinaxiawuhao.github.io/post/ZsckGVdlz/</id>
        <link href="https://tinaxiawuhao.github.io/post/ZsckGVdlz/">
        </link>
        <updated>2021-06-06T08:50:36.000Z</updated>
        <content type="html"><![CDATA[<h3 id="springboot-jwt实现">SpringBoot  JWT实现</h3>
<p>（只是实现了jwt,没有生成证书,安全性得不到保障,证书安全验证查看<a href="https://tinaxiawuhao.github.io/post/wWtT_Oc9B/">Spring security JWT</a>）</p>
<pre><code class="language-java">&lt;dependency&gt;
    &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt;
    &lt;artifactId&gt;jjwt&lt;/artifactId&gt;
    &lt;version&gt;0.6.0&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<pre><code class="language-java">import io.jsonwebtoken.JwtBuilder;
import io.jsonwebtoken.Jwts;
import io.jsonwebtoken.SignatureAlgorithm;

import java.util.Date;

public class CreateJwtTest3 {
    public static void main(String[] args) {
        //为了方便测试，我们将过期时间设置为1分钟
        long now = System.currentTimeMillis();//当前时间
        long exp = now + 1000 * 60;//过期时间为1分钟
        JwtBuilder builder = Jwts.builder().setId(&quot;888&quot;)
                .setSubject(&quot;小白&quot;)
                .setIssuedAt(new Date())
                .signWith(SignatureAlgorithm.HS256, &quot;itcast&quot;)
                .setExpiration(new Date(exp))
                .claim(&quot;roles&quot;, &quot;admin&quot;) //自定义claims存储数据
                .claim(&quot;logo&quot;, &quot;logo.png&quot;);
        System.out.println(builder.compact());
    }
}
</code></pre>
<pre><code class="language-java">import io.jsonwebtoken.Claims;
import io.jsonwebtoken.Jwts;
import org.apache.commons.lang3.time.DateFormatUtils;

import java.util.Date;

public class ParseJwtTest {
    public static void main(String[] args) {
        String token = &quot;eyJhbGciOiJIUzI1NiJ9.eyJqdGkiOiI4ODgiLCJzdWIiOiLlsI_nmb0iLCJpYXQiOjE1NjExMDE3MzIsImV4cCI6MTU2MTEwMTc5MSwicm9sZXMiOiJhZG1pbiIsImxvZ28iOiJsb2dvLnBuZyJ9.5iVVdTw747L3ScHeCqle-bwj3cezK8NnE7VilQWOr8Y&quot;;
        Claims claims = Jwts.parser().setSigningKey(&quot;itcast&quot;).parseClaimsJws(token).getBody();
        System.out.println(&quot;id:&quot; + claims.getId());
        System.out.println(&quot;subject:&quot; + claims.getSubject());
        System.out.println(&quot;roles:&quot; + claims.get(&quot;roles&quot;));
        System.out.println(&quot;logo:&quot; + claims.get(&quot;logo&quot;));
        System.out.println(&quot;签发时间:&quot;+ DateFormatUtils.format(claims.getIssuedAt(),&quot;yyyy-MM-dd hh:mm:ss&quot;));
        System.out.println(&quot;过期时间:&quot;+DateFormatUtils.format(claims.getExpiration(),&quot;yyyy-MM-dd hh:mm:ss&quot;));
        System.out.println(&quot;当前时间:&quot;+DateFormatUtils.format(new Date(),&quot;yyyy-MM-dd hh:mm:ss&quot;));
    }
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[JWT介绍]]></title>
        <id>https://tinaxiawuhao.github.io/post/wWtT_Oc9B/</id>
        <link href="https://tinaxiawuhao.github.io/post/wWtT_Oc9B/">
        </link>
        <updated>2021-06-05T08:45:38.000Z</updated>
        <content type="html"><![CDATA[<h2 id="jwt介绍">JWT介绍</h2>
<p>在介绍JWT之前先看一下传统校验令牌的方法，如下图：</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1623401311518.png" alt="" loading="lazy"></figure>
<p>资源服务器授权流程如上图，客户端先去授权服务器申请令牌，申请令牌后，携带令牌访问资源服务器，资源服务器访问授权服务校验令牌的合法性，授权服务会返回校验结果，如果校验成功会返回用户信息给资源服务器，资源服务器如果接收到的校验结果通过了，则返回资源给客户端</p>
<p><strong>问题：</strong></p>
<p>传统授权方法的问题是用户每次请求资源服务，资源服务都需要携带令牌访问认证服务去校验令牌的合法性，并根据令牌获取用户的相关信息，性能低下。</p>
<p><strong>解决：</strong></p>
<p>使用JWT的思路是，用户认证通过会得到一个JWT令牌，JWT令牌中已经包括了用户相关的信息，客户端只需要携带JWT访问资源服务，资源服务根据事先约定的算法自行完成令牌校验，无需每次都请求认证服务完成授权。</p>
<p>JWT令牌授权过程如下图：</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1623401320289.png" alt="" loading="lazy"></figure>
<h3 id="什么是jwt">什么是JWT？</h3>
<p>JSON Web Token（JWT）是一个开放的行业标准（RFC 7519），它定义了一种简介的、自包含的协议格式，用于在通信双方传递json对象，传递的信息经过数字签名可以被验证和信任。JWT可以使用HMAC算法或使用RSA的公钥/私钥对来签名，防止被篡改。</p>
<blockquote>
<p>官网：https://jwt.io/</p>
<p>标准：https://tools.ietf.org/html/rfc7519</p>
</blockquote>
<h4 id="优点">优点：</h4>
<ol>
<li>
<p>jwt基于json，非常方便解析。</p>
</li>
<li>
<p>可以在令牌中自定义丰富的内容，易扩展。</p>
</li>
<li>
<p>通过非对称加密算法及数字签名技术，JWT防止篡改，安全性高。</p>
</li>
<li>
<p>资源服务使用JWT可不依赖认证服务即可完成授权。</p>
</li>
</ol>
<h4 id="缺点">缺点：</h4>
<ol>
<li>JWT令牌较长，占存储空间比较大。</li>
</ol>
<h4 id="令牌结构">令牌结构</h4>
<p>通过学习JWT令牌结构为自定义jwt令牌打好基础。</p>
<p>JWT令牌由三部分组成，每部分中间使用点（.）分隔，比如：xxxxx.yyyyy.zzzzz</p>
<p><strong>Header</strong></p>
<p>头部包括令牌的类型（即JWT）及使用的哈希算法（如HMAC SHA256或RSA）</p>
<p>一个例子如下：</p>
<p>下边是Header部分的内容</p>
<pre><code class="language-json">{
    &quot;alg&quot;: &quot;HS256&quot;,
    &quot;typ&quot;: &quot;JWT&quot;
}
</code></pre>
<p>将上边的内容使用Base64Url编码，得到一个字符串就是JWT令牌的第一部分。</p>
<p><strong>Payload</strong></p>
<p>第二部分是负载，内容也是一个json对象，它是存放有效信息的地方，它可以存放jwt提供的现成字段，比如：iss（签发者）,exp（过期时间戳）, sub（面向的用户）等，也可自定义字段。</p>
<p>此部分不建议存放敏感信息，因为此部分可以解码还原原始内容。</p>
<p>最后将第二部分负载使用Base64Url编码，得到一个字符串就是JWT令牌的第二部分。</p>
<pre><code class="language-json"> {
    &quot;sub&quot;: &quot;1234567890&quot;,
    &quot;name&quot;: &quot;456&quot;,
    &quot;admin&quot;: true
}
</code></pre>
<p><strong>Signature</strong></p>
<p>第三部分是签名，此部分用于防止jwt内容被篡改。这个部分使用base64url将前两部分进行编码，编码后使用点（.）连接组成字符串，最后使用header中声明签名算法进行签名。</p>
<pre><code class="language-java">HMACSHA256(base64UrlEncode(header) + &quot;.&quot; +base64UrlEncode(payload),secret)
</code></pre>
<p><code>base64UrlEncode(header)</code>：jwt令牌的第一部分。</p>
<p><code>base64UrlEncode(payload)</code>：jwt令牌的第二部分。</p>
<p><code>secret</code>：签名所使用的密钥。</p>
<h3 id="jwt入门">JWT入门</h3>
<p>Spring Security 提供对JWT的支持，本节我们使用Spring Security 提供的JwtHelper来创建JWT令牌，校验JWT令牌等操作。</p>
<h3 id="生成私钥和公钥">生成私钥和公钥</h3>
<p>JWT令牌生成采用非对称加密算法</p>
<ol>
<li>
<p>生成密钥证书</p>
<p>下边命令生成密钥证书，采用RSA 算法每个证书包含公钥和私钥</p>
<pre><code class="language-java">keytool -genkeypair -alias xckey -keyalg RSA -keypass xuecheng -keystore xc.keystore -storepass xuechengkeystore
</code></pre>
<blockquote>
<p>Keytool 是一个java提供的证书管理工具</p>
<p>-alias：密钥的别名</p>
<p>-keyalg：使用的hash算法</p>
<p>-keypass：密钥的访问密码</p>
<p>-keystore：密钥库文件名，xc.keystore保存了生成的证书</p>
<p>-storepass：密钥库的访问密码</p>
</blockquote>
<p><strong>查询证书信息</strong></p>
<pre><code class="language-java">keytool -list -keystore xc.keystore
</code></pre>
<p><strong>删除别名</strong></p>
<pre><code class="language-java">keytool -delete -alias xckey -keystore xc.keystore
</code></pre>
</li>
<li>
<p>导出公钥</p>
<p>openssl是一个加解密工具包，这里使用openssl来导出公钥信息。安装 openssl：http://slproweb.com/products/Win32OpenSSL.html</p>
<p>配置openssl的path环境变量，本文配置在<code>D:\OpenSSL-Win64\bin</code>  <code>cmd</code>进入<code>xc.keystore</code>文件所在目录执行如下命令：</p>
<pre><code class="language-java">keytool ‐list ‐rfc ‐‐keystore xc.keystore | openssl x509 ‐inform pem ‐pubkey
</code></pre>
<p>输入密钥库密码：</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1623908661423.png" alt="" loading="lazy"></figure>
<p>下边这一段就是公钥内容：</p>
<pre><code class="language-java">-----BEGIN PUBLIC KEY----- MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAijyxMdq4S6L1Af1rtB8SjCZHNgsQG8JTfGy55eYvzG0B/E4AudR2prSRBvF7NYPL47scRCNPgLnvbQczBHbBug6uOr78qnWsYxHlW6Aa5dI5NsmOD4DLtSw8eX0hFyK5Fj6ScYOSFBz9cd1nNTvx2+oIv0lJDcpQdQhsfgsEr1ntvWterZt/8r7xNN83gHYuZ6TM5MYvjQNBc5qC7Krs9wM7UoQuL+s0X6RlOib7/mcLn/lFLsLDdYQAZkSDx/6+t+1oHdMarChIPYT1sx9Dwj2j2mvFNDTKKKKAq0cv14Vrhz67Vjmz2yMJePDqUi0JYS2r0iIo7n8vN7s83v5uOQIDAQAB 
-----END PUBLIC KEY-----
</code></pre>
<p>将上边的公钥拷贝到文本文件中，合并为一行。</p>
</li>
</ol>
<h3 id="生成jwt令牌">生成jwt令牌</h3>
<p>在认证工程创建测试类，测试jwt令牌的生成与验证。</p>
<pre><code class="language-java">@Test
public void testCreateJwt(){
//证书文件
String key_location = &quot;xc.keystore&quot;;
//密钥库密码
String keystore_password = &quot;xuechengkeystore&quot;;
//访问证书路径
ClassPathResource resource = new ClassPathResource(key_location);
//密钥工厂
KeyStoreKeyFactory keyStoreKeyFactory = new KeyStoreKeyFactory(resource,
keystore_password.toCharArray());
//密钥的密码，此密码和别名要匹配

String keypassword = &quot;xuecheng&quot;;
//密钥别名
String alias = &quot;xckey&quot;;
//密钥对（密钥和公钥）
KeyPair keyPair = keyStoreKeyFactory.getKeyPair(alias,keypassword.toCharArray());
//私钥
RSAPrivateKey aPrivate = (RSAPrivateKey) keyPair.getPrivate();
//定义payload信息
Map&lt;String, Object&gt; tokenMap = new HashMap&lt;&gt;();
tokenMap.put(&quot;id&quot;, &quot;123&quot;);
tokenMap.put(&quot;name&quot;, &quot;mrt&quot;);
tokenMap.put(&quot;roles&quot;, &quot;r01,r02&quot;);
tokenMap.put(&quot;ext&quot;, &quot;1&quot;);
//生成jwt令牌
Jwt jwt = JwtHelper.encode(JSON.toJSONString(tokenMap), new RsaSigner(aPrivate));
//取出jwt令牌
String token = jwt.getEncoded();
System.out.println(&quot;token=&quot;+token);
} //资源服务使用公钥验证jwt的合法性，并对jwt解码
</code></pre>
<h3 id="验证jwt令牌">验证jwt令牌</h3>
<pre><code class="language-java">@Test
public void testVerify(){
//jwt令牌
String token
=&quot;eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHQiOiIxIiwicm9sZXMiOiJyMDEscjAyIiwibmFtZSI6Im1ydCIsImlkIjoiMTIzIn0.KK7_67N5d1Dthd1PgDHMsbi0UlmjGRcm_XJUUwseJ2eZyJJWoPP2IcEZgAU3tUaaKEHUf9wSRwaDgwhrwfyIcSHbs8oy3zOQEL8j5AOjzBBs7vnRmB7DbSaQD7eJiQVJOXO1QpdmEFgjhc_IBCVTJCVWgZw60IEW1_Lg5tqaLvCiIl26K48pJB5fle2zgYMzqR1L2LyTFkq39rG57VOqqSCi3dapsZQd4ctq95SJCXgGdrUDWtD52rp5o6_0uq‐mrbRdRxkrQfsa1j8C5IW2‐T4eUmiN3f9wF9JxUK1__XC1OQkOn‐ZTBCdqwWIygDFbU7sf6KzfHJTm5vfjp6NIA&quot;;
//公钥
String publickey = &quot;‐‐‐‐‐BEGIN PUBLIC KEY‐‐‐‐‐
MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAijyxMdq4S6L1Af1rtB8SjCZHNgsQG8JTfGy55eYvzG0B/E4AudR2prSRBvF7NYPL47scRCNPgLnvbQczBHbBug6uOr78qnWsYxHlW6Aa5dI5NsmOD4DLtSw8eX0hFyK5Fj6ScYOSFBz9cd1nNTvx2+oIv0lJDcpQdQhsfgsEr1ntvWterZt/8r7xNN83gHYuZ6TM5MYvjQNBc5qC7Krs9wM7UoQuL+s0X6RlOib7/mcLn/lFLsLDdYQAZkSDx/6+t+1oHdMarChIPYT1sx9Dwj2j2mvFNDTKKKKAq0cv14Vrhz67Vjmz2yMJePDqUi0JYS2r0iIo7n8vN7s83v5u
OQIDAQAB
‐‐‐‐‐END PUBLIC KEY‐‐‐‐‐&quot;;

//校验jwt
Jwt jwt = JwtHelper.decodeAndVerify(token, new RsaVerifier(publickey));
//获取jwt原始内容
String claims = jwt.getClaims();
//jwt令牌
String encoded = jwt.getEncoded();
System.out.println(encoded);
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[zookeeper概述]]></title>
        <id>https://tinaxiawuhao.github.io/post/DOckY7njv/</id>
        <link href="https://tinaxiawuhao.github.io/post/DOckY7njv/">
        </link>
        <updated>2021-06-04T06:27:35.000Z</updated>
        <content type="html"><![CDATA[<h2 id="zookeeper是什么">zookeeper是什么</h2>
<p>Zookeeper 分布式服务框架是Apache Hadoop 的一个子项目，它主要是用来解决分布式应用中经常遇到的一些数据管理问题，如：统一命名服务、状态同步服务、集群管理、分布式应用配置项的管理等。</p>
<p>简单的说，zookeeper=文件系统+通知机制。</p>
<h2 id="zookeeper提供了什么">zookeeper提供了什么</h2>
<h3 id="1-文件系统">1、 文件系统</h3>
<p>Zookeeper维护一个类似文件系统的数据结构：</p>
<p>​                            <img src="https://tinaxiawuhao.github.io/post-images/1622442641935.png" alt="" loading="lazy"></p>
<p>​    每个子目录项如 NameService 都被称作为 znode，和文件系统一样，我们能够自由的增加、删除znode，在一个znode下增加、删除子znode，唯一的不同在于znode是可以存储数据的。</p>
<p>有四种类型的znode：</p>
<ol>
<li>
<p>PERSISTENT-持久化目录节点</p>
<p>客户端与zookeeper断开连接后，该节点依旧存在</p>
</li>
<li>
<p>PERSISTENT_SEQUENTIAL-持久化顺序编号目录节点</p>
<p>客户端与zookeeper断开连接后，该节点依旧存在，只是Zookeeper给该节点名称进行顺序编号</p>
</li>
<li>
<p>EPHEMERAL-临时目录节点</p>
<p>客户端与zookeeper断开连接后，该节点被删除</p>
</li>
<li>
<p>EPHEMERAL_SEQUENTIAL-临时顺序编号目录节点</p>
<p>客户端与zookeeper断开连接后，该节点被删除，只是Zookeeper给该节点名称进行顺序编号</p>
</li>
</ol>
<h3 id="2-通知机制">2、 通知机制</h3>
<p>​    客户端注册监听它关心的目录节点，当目录节点发生变化（数据改变、被删除、子目录节点增加删除）时，zookeeper会通知客户端。</p>
<h2 id="我们能用zookeeper做什么">我们能用zookeeper做什么</h2>
<h3 id="1-命名服务">1、 命名服务</h3>
<p>​    这个似乎最简单，在zookeeper的文件系统里创建一个目录，即有唯一的path。在我们使用tborg无法确定上游程序的部署机器时即可与下游程序约定好path，通过path即能互相探索发现，不见不散了。</p>
<h3 id="2-配置管理">2、 配置管理</h3>
<p>​    程序总是需要配置的，如果程序分散部署在多台机器上，要逐个改变配置就变得困难。好吧，现在把这些配置全部放到zookeeper上去，保存在 Zookeeper 的某个目录节点中，然后所有相关应用程序对这个目录节点进行监听，一旦配置信息发生变化，每个应用程序就会收到 Zookeeper 的通知，然后从 Zookeeper 获取新的配置信息应用到系统中就好。</p>
<p>​                     <img src="https://tinaxiawuhao.github.io/post-images/1622442667808.png" alt="" loading="lazy"></p>
<h3 id="3-集群管理">3、 集群管理</h3>
<p>所谓集群管理无在乎两点：是否有机器退出和加入、选举master。</p>
<p>​    对于第一点，所有机器约定在父目录GroupMembers下创建临时目录节点，然后监听父目录节点的子节点变化消息。一旦有机器挂掉，该机器与 zookeeper的连接断开，其所创建的临时目录节点被删除，所有其他机器都收到通知：某个兄弟目录被删除，于是，所有人都知道：它下船了。新机器加入 也是类似，所有机器收到通知：新兄弟目录加入。</p>
<p>​    对于第二点，我们稍微改变一下，所有机器创建临时顺序编号目录节点，每次选取编号最小的机器作为master就好。</p>
<p>​                 <img src="https://tinaxiawuhao.github.io/post-images/1622442682095.png" alt="" loading="lazy"></p>
<h3 id="4-分布式锁">4、 分布式锁</h3>
<p>​    有了zookeeper的一致性文件系统，锁的问题变得容易。锁服务可以分为两类，一个是保持独占，另一个是控制时序。</p>
<p>​    对于第一类，我们将zookeeper上的一个znode看作是一把锁，通过createznode的方式来实现。所有客户端都去创建 /distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。厕所有言：来也冲冲，去也冲冲，用完删除掉自己创建的distribute_lock 节点就释放出锁。</p>
<p>​    对于第二类， /distribute_lock 已经预先存在，所有客户端在它下面创建临时顺序编号目录节点，和选master一样，编号最小的获得锁，用完删除，依次方便。</p>
<p>​                     <img src="https://tinaxiawuhao.github.io/post-images/1622442696117.png" alt="" loading="lazy"></p>
<h3 id="5-队列管理">5、队列管理</h3>
<p>两种类型的队列：</p>
<ol>
<li>
<p>同步队列，当一个队列的成员都聚齐时，这个队列才可用，否则一直等待所有成员到达。</p>
</li>
<li>
<p>队列按照 FIFO 方式进行入队和出队操作。</p>
<p>第一类，在约定目录下创建临时目录节点，监听节点数目是否是我们要求的数目。</p>
<p>第二类，和分布式锁服务中的控制时序场景基本原理一致，入列有编号，出列按编号。</p>
</li>
</ol>
<p>​     终于了解完我们能用zookeeper做什么了，可是作为一个程序员，我们总是想狂热了解zookeeper是如何做到这一点的，单点维护一个文件系统没有什么难度，可是如果是一个集群维护一个文件系统保持数据的一致性就非常困难了。</p>
<h3 id="6-分布式与数据复制">6、分布式与数据复制</h3>
<p>Zookeeper作为一个集群提供一致的数据服务，自然，它要在所有机器间做数据复制。数据复制的好处：</p>
<ol>
<li>
<p>容错<br>
一个节点出错，不致于让整个系统停止工作，别的节点可以接管它的工作；</p>
</li>
<li>
<p>提高系统的扩展能力<br>
把负载分布到多个节点上，或者增加节点来提高系统的负载能力；</p>
</li>
<li>
<p>提高性能<br>
让客户端本地访问就近的节点，提高用户访问速度。</p>
</li>
</ol>
<p>从客户端读写访问的透明度来看，数据复制集群系统分下面两种：</p>
<ol>
<li>
<p>写主(WriteMaster)<br>
对数据的修改提交给指定的节点。读无此限制，可以读取任何一个节点。这种情况下客户端需要对读与写进行区别，俗称读写分离；</p>
</li>
<li>
<p>写任意(Write Any)<br>
对数据的修改可提交给任意的节点，跟读一样。这种情况下，客户端对集群节点的角色与变化透明。</p>
</li>
</ol>
<p>​    对zookeeper来说，它采用的方式是写任意。通过增加机器，它的读吞吐能力和响应能力扩展性非常好，而写，随着机器的增多吞吐能力肯定下降（这 也是它建立observer的原因），而响应能力则取决于具体实现方式，是延迟复制保持最终一致性，还是立即复制快速响应。</p>
<p>我们关注的重点还是在如何保证数据在集群所有机器的一致性，这就涉及到paxos算法。</p>
<h3 id="7-数据一致性与paxos算法">7、数据一致性与paxos算法</h3>
<p>​    据说Paxos算法的难理解与算法的知名度一样令人敬仰，所以我们先看如何保持数据的一致性，这里有个原则就是：</p>
<blockquote>
<p>在一个分布式数据库系统中，如果各节点的初始状态一致，每个节点都执行相同的操作序列，那么他们最后能得到一个一致的状态。</p>
</blockquote>
<p>​    Paxos算法解决的什么问题呢，解决的就是保证每个节点执行相同的操作序列。好吧，这还不简单，master维护一个全局写队列，所有写操作都必须 放入这个队列编号，那么无论我们写多少个节点，只要写操作是按编号来的，就能保证一致性。没错，就是这样，可是如果master挂了呢。</p>
<p>​    Paxos算法通过投票来对写操作进行全局编号，同一时刻，只有一个写操作被批准，同时并发的写操作要去争取选票，只有获得过半数选票的写操作才会被 批准（所以永远只会有一个写操作得到批准），其他的写操作竞争失败只好再发起一轮投票，就这样，在日复一日年复一年的投票中，所有写操作都被严格编号排 序。编号严格递增，当一个节点接受了一个编号为100的写操作，之后又接受到编号为99的写操作（因为网络延迟等很多不可预见原因），它马上能意识到自己 数据不一致了，自动停止对外服务并重启同步过程。任何一个节点挂掉都不会影响整个集群的数据一致性（总2n+1台，除非挂掉大于n台）。</p>
<p><strong>总结</strong></p>
<p>​    Zookeeper 作为 Hadoop 项目中的一个子项目，是 Hadoop 集群管理的一个必不可少的模块，它主要用来控制集群中的数据，如它管理 Hadoop 集群中的 NameNode，还有 Hbase 中 Master Election、Server 之间状态同步等。</p>
<h1 id="zookeeper工作原理">Zookeeper工作原理</h1>
<p>​    ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，它包含一个简单的原语集，分布式应用程序可以基于它实现同步服务，配置维护和 命名服务等。Zookeeper是hadoop的一个子项目，其发展历程无需赘述。在分布式应用中，由于工程师不能很好地使用锁机制，以及基于消息的协调 机制不适合在某些应用中使用，因此需要有一种可靠的、可扩展的、分布式的、可配置的协调机制来统一系统的状态。Zookeeper的目的就在于此。</p>
<h2 id="zookeeper的基本概念">Zookeeper的基本概念</h2>
<h3 id="11-角色">1.1 角色</h3>
<p>Zookeeper中的角色主要有以下三类，如下表所示：</p>
<p>​             <img src="https://tinaxiawuhao.github.io/post-images/1622442715591.png" alt="" loading="lazy"></p>
<p>系统模型如图所示：</p>
<p>​            <img src="https://tinaxiawuhao.github.io/post-images/1622442726565.jpg" alt="" loading="lazy"></p>
<h3 id="12-设计目的">1.2 设计目的</h3>
<ol>
<li>
<p>最终一致性：client不论连接到哪个Server，展示给它都是同一个视图，这是zookeeper最重要的性能。</p>
</li>
<li>
<p>可靠性：具有简单、健壮、良好的性能，如果消息m被到一台服务器接受，那么它将被所有的服务器接受。</p>
</li>
<li>
<p>实时性：Zookeeper保证客户端将在一个时间间隔范围内获得服务器的更新信息，或者服务器失效的信息。但由于网络延时等原因，Zookeeper不能保证两个客户端能同时得到刚更新的数据，如果需要最新数据，应该在读数据之前调用sync()接口。</p>
</li>
<li>
<p>等待无关（wait-free）：慢的或者失效的client不得干预快速的client的请求，使得每个client都能有效的等待。</p>
</li>
<li>
<p>原子性：更新只能成功或者失败，没有中间状态。</p>
</li>
<li>
<p>顺序性：包括全局有序和偏序两种：全局有序是指如果在一台服务器上消息a在消息b前发布，则在所有Server上消息a都将在消息b前被发布；偏序是指如果一个消息b在消息a后被同一个发送者发布，a必将排在b前面。</p>
</li>
</ol>
<h2 id="zookeeper的流程设计">ZooKeeper的流程设计</h2>
<p>​    Zookeeper的核心是原子广播，这个机制保证了各个Server之间的同步。实现这个机制的协议叫做Zab协议。Zab协议有两种模式，它们分 别是恢复模式（选主）和广播模式（同步）。当服务启动或者在领导者崩溃后，Zab就进入了恢复模式，当领导者被选举出来，且大多数Server完成了和 leader的状态同步以后，恢复模式就结束了。状态同步保证了leader和Server具有相同的系统状态。</p>
<p>​    为了保证事务的顺序一致性，zookeeper采用了递增的事务id号（zxid）来标识事务。所有的提议（proposal）都在被提出的时候加上 了zxid。实现中zxid是一个64位的数字，它高32位是epoch用来标识leader关系是否改变，每次一个leader被选出来，它都会有一个 新的epoch，标识当前属于那个leader的统治时期。低32位用于递增计数。</p>
<p>每个Server在工作过程中有三种状态：</p>
<ul>
<li>LOOKING：当前Server不知道leader是谁，正在搜寻</li>
<li>LEADING：当前Server即为选举出来的leader</li>
<li>FOLLOWING：leader已经选举出来，当前Server与之同步</li>
</ul>
<h3 id="21-选主流程">2.1 选主流程</h3>
<p>当leader崩溃或者leader失去大多数的follower，这时候zk进入恢复模式，恢复模式需要重新选举出一个新的leader，让所有的 Server都恢复到一个正确的状态。Zk的选举算法有两种：一种是基于basic paxos实现的，另外一种是基于fast paxos算法实现的。系统默认的选举算法为fast paxos。先介绍basic paxos流程：</p>
<p>​    1 .选举线程由当前Server发起选举的线程担任，其主要功能是对投票结果进行统计，并选出推荐的Server；</p>
<p>​    2 .选举线程首先向所有Server发起一次询问(包括自己)；</p>
<p>​    3 .选举线程收到回复后，验证是否是自己发起的询问(验证zxid是否一致)，然后获取对方的id(myid)，并存储到当前询问对象列表中，最后获取对方提议的leader相关信息(    id,zxid)，并将这些信息存储到当次选举的投票记录表中；</p>
<p>​    4.  收到所有Server回复以后，就计算出zxid最大的那个Server，并将这个Server相关信息设置成下一次要投票的Server；</p>
<p>​    5.  线程将当前zxid最大的Server设置为当前Server要推荐的Leader，如果此时获胜的Server获得n/2 + 1的Server票数， 设置当前推荐的leader为获胜的Server，将根据获胜的Server相关信息设置自己的状态，否则，继续这个过程，直到leader被选举出来。</p>
<p>通过流程分析我们可以得出：要使Leader获得多数Server的支持，则Server总数必须是奇数2n+1，且存活的Server的数目不得少于n+1.</p>
<p>每个Server启动后都会重复以上流程。在恢复模式下，如果是刚从崩溃状态恢复的或者刚启动的server还会从磁盘快照中恢复数据和会话信息，zk会记录事务日志并定期进行快照，方便在恢复时进行状态恢复。选主的具体流程图如下所示：</p>
<p>​                     <img src="https://tinaxiawuhao.github.io/post-images/1622442743429.png" alt="" loading="lazy"></p>
<p>fast paxos流程是在选举过程中，某Server首先向所有Server提议自己要成为leader，当其它Server收到提议以后，解决epoch和 zxid的冲突，并接受对方的提议，然后向对方发送接受提议完成的消息，重复这个流程，最后一定能选举出Leader。其流程图如下所示：</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1622442753556.png" alt="" loading="lazy"></figure>
<h3 id="22-同步流程">2.2 同步流程</h3>
<p>选完leader以后，zk就进入状态同步过程。</p>
<p>​    1. leader等待server连接；</p>
<p>​    2 .Follower连接leader，将最大的zxid发送给leader；</p>
<p>​    3 .Leader根据follower的zxid确定同步点；</p>
<p>​    4 .完成同步后通知follower 已经成为uptodate状态；</p>
<p>​    5 .Follower收到uptodate消息后，又可以重新接受client的请求进行服务了。</p>
<p>流程图如下所示：</p>
<p>​                 <img src="https://tinaxiawuhao.github.io/post-images/1622442765596.jpg" alt="" loading="lazy"></p>
<h3 id="23-工作流程">2.3 工作流程</h3>
<h4 id="231-leader工作流程">2.3.1 Leader工作流程</h4>
<p>Leader主要有三个功能：</p>
<p>​    1 .恢复数据；</p>
<p>​    2 .维持与Learner的心跳，接收Learner请求并判断Learner的请求消息类型；</p>
<p>​    3 .Learner的消息类型主要有PING消息、REQUEST消息、ACK消息、REVALIDATE消息，根据不同的消息类型，进行不同的处理。</p>
<p>​    PING消息是指Learner的心跳信息；REQUEST消息是Follower发送的提议信息，包括写请求及同步请求；ACK消息是 Follower的对提议的回复，超过半数的Follower通过，则commit该提议；REVALIDATE消息是用来延长SESSION有效时间。<br>
Leader的工作流程简图如下所示，在实际实现中，流程要比下图复杂得多，启动了三个线程来实现功能。</p>
<p>​                <img src="https://tinaxiawuhao.github.io/post-images/1622442776052.png" alt="" loading="lazy"></p>
<h4 id="232-follower工作流程">2.3.2 Follower工作流程</h4>
<p>Follower主要有四个功能：</p>
<p>​    1. 向Leader发送请求（PING消息、REQUEST消息、ACK消息、REVALIDATE消息）；</p>
<p>​    2 .接收Leader消息并进行处理；</p>
<p>​    3 .接收Client的请求，如果为写请求，发送给Leader进行投票；</p>
<p>​    4 .返回Client结果。</p>
<p>Follower的消息循环处理如下几种来自Leader的消息：</p>
<p>​    1 .PING消息： 心跳消息；</p>
<p>​    2 .PROPOSAL消息：Leader发起的提案，要求Follower投票；</p>
<p>​    3 .COMMIT消息：服务器端最新一次提案的信息；</p>
<p>​    4 .UPTODATE消息：表明同步完成；</p>
<p>​    5 .REVALIDATE消息：根据Leader的REVALIDATE结果，关闭待revalidate的session还是允许其接受消息；</p>
<p>​    6 .SYNC消息：返回SYNC结果到客户端，这个消息最初由客户端发起，用来强制得到最新的更新。</p>
<p>Follower的工作流程简图如下所示，在实际实现中，Follower是通过5个线程来实现功能的。</p>
<p>​             <img src="https://tinaxiawuhao.github.io/post-images/1622442788398.png" alt="" loading="lazy"></p>
<p>对于observer的流程不再叙述，observer流程和Follower的唯一不同的地方就是observer不会参加leader发起的投票。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Gossip协议]]></title>
        <id>https://tinaxiawuhao.github.io/post/BmWrFaJAQ/</id>
        <link href="https://tinaxiawuhao.github.io/post/BmWrFaJAQ/">
        </link>
        <updated>2021-06-03T06:05:22.000Z</updated>
        <content type="html"><![CDATA[<h2 id="gossip">Gossip</h2>
<blockquote>
<p>Gossip协议是一个通信协议，一种传播消息的方式，灵感来自于：瘟疫、社交网络等。使用Gossip协议的有：<a href="https://tinaxiawuhao.github.io/post/FWuQD6Kxu/">Redis Cluster</a>、Consul、Apache Cassandra等。</p>
</blockquote>
<h3 id="六度分隔理论">六度分隔理论</h3>
<p>说到社交网络，就不得不提著名的六度分隔理论。1967年，哈佛大学的心理学教授Stanley Milgram想要描绘一个连结人与社区的人际连系网。做过一次连锁信实验，结果发现了“六度分隔”现象。简单地说：“你和任何一个陌生人之间所间隔的人不会超过六个，也就是说，最多通过六个人你就能够认识任何一个陌生人。</p>
<p>数学解释该理论：若每个人平均认识260人，其六度就是260↑6 =1,188,137,600,000。消除一些节点重复，那也几乎覆盖了整个地球人口若干多多倍，这也是Gossip协议的雏形。</p>
<h3 id="原理">原理</h3>
<p>Gossip协议基本思想就是：一个节点想要分享一些信息给网络中的其他的一些节点。于是，它周期性的随机选择一些节点，并把信息传递给这些节点。这些收到信息的节点接下来会做同样的事情，即把这些信息传递给其他一些随机选择的节点。一般而言，信息会周期性的传递给N个目标节点，而不只是一个。这个N被称为fanout（这个单词的本意是扇出）。</p>
<h3 id="用途">用途</h3>
<p>Gossip协议的主要用途就是信息传播和扩散：即把一些发生的事件传播到全世界。它们也被用于数据库复制，信息扩散，集群成员身份确认，故障探测等。</p>
<p>基于Gossip协议的一些有名的系统：Apache Cassandra，Redis（Cluster模式），Consul等。</p>
<h3 id="图解">图解</h3>
<p>接下来通过多张图片剖析Gossip协议是如何运行的。如下图所示，Gossip协议是周期循环执行的。图中的公式表示Gossip协议把信息传播到每一个节点需要多少次循环动作，需要说明的是，公式中的20表示整个集群有20个节点，4表示某个节点会向4个目标节点传播消息：</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1622442855693.jpg" alt="" loading="lazy"></figure>
<p>Gossip Protocol</p>
<p>如下图所示，红色的节点表示其已经“受到感染”，即接下来要传播信息的源头，连线表示这个初始化感染的节点能正常连接的节点（其不能连接的节点只能靠接下来感染的节点向其传播消息）。并且N等于4，我们假设4根较粗的线路，就是它第一次传播消息的线路：</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1622442872607.jpg" alt="" loading="lazy"></figure>
<p>first infected node</p>
<p>第一次消息完成传播后，新增了4个节点会被“感染”，即这4个节点也收到了消息。这时候，总计有5个节点变成红色：</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1622442882247.jpg" alt="" loading="lazy"></figure>
<p>infected nodes</p>
<p>那么在下一次传播周期时，总计有5个节点，且这5个节点每个节点都会向4个节点传播消息。最后，经过3次循环，20个节点全部被感染（都变成红色节点），即说明需要传播的消息已经传播给了所有节点：</p>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1622442890305.jpg" alt="" loading="lazy"></figure>
<p>infected all nodes</p>
<p>需要说明的是，20个节点且设置fanout=4，公式结果是2.16，这只是个近似值。真实传递时，可能需要3次甚至4次循环才能让所有节点收到消息。这是因为每个节点在传播消息的时候，是随机选择N个节点的，这样的话，就有可能某个节点会被选中2次甚至更多次。</p>
<h3 id="发送消息">发送消息</h3>
<p>由前面对Gossip协议图解分析可知，节点传播消息是周期性的，并且每个节点有它自己的周期。另外，节点发送消息时的目标节点数由参数fanout决定。至于往哪些目标节点发送，则是随机的。</p>
<p>一旦消息被发送到目标节点，那么目标节点也会被感染。一旦某个节点被感染，那么它也会向其他节点传播消息，试图感染更多的节点。最终，每一个节点都会被感染，即消息被同步给了所有节点：</p>
<h3 id="可扩展性">可扩展性</h3>
<p>Gossip协议是可扩展的，因为它只需要O(logN) 个周期就能把消息传播给所有节点。某个节点在往固定数量节点传播消息过程中，并不需要等待确认（ack），并且，即使某条消息传播过程中丢失，它也不需要做任何补偿措施。打个比方，某个节点本来需要将消息传播给4个节点，但是由于网络或者其他原因，只有3个消息接收到消息，即使这样，这对最终所有节点接收到消息是没有任何影响的。</p>
<p>如下表格所示，假定fanout=4，那么在节点数分别是20、40、80、160时，消息传播到所有节点需要的循环次数对比，在节点成倍扩大的情况下，循环次数并没有增加很多。所以，Gossip协议具备可扩展性：</p>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1622442912159.jpg" alt="" loading="lazy"></figure>
<h3 id="失败容错">失败容错</h3>
<p>Gossip也具备失败容错的能力，即使网络故障等一些问题，Gossip协议依然能很好的运行。因为一个节点会多次分享某个需要传播的信息，即使不能连通某个节点，其他被感染的节点也会尝试向这个节点传播信息。</p>
<h3 id="健壮性">健壮性</h3>
<p>Gossip协议下，没有任何扮演特殊角色的节点（比如leader等）。任何一个节点无论什么时候下线或者加入，并不会破坏整个系统的服务质量。</p>
<p>然而，Gossip协议也有不完美的地方，例如，拜占庭问题（Byzantine）。即，如果有一个恶意传播消息的节点，Gossip协议的分布式系统就会出问题。</p>
<blockquote>
<p>作者：阿飞的博客<br>
原文地址：https://www.jianshu.com/p/54eab117e6ae</p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[CAP/BASE]]></title>
        <id>https://tinaxiawuhao.github.io/post/cxyiXFW2S/</id>
        <link href="https://tinaxiawuhao.github.io/post/cxyiXFW2S/">
        </link>
        <updated>2021-06-02T02:44:25.000Z</updated>
        <content type="html"><![CDATA[<h3 id="cap原则">CAP原则</h3>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1622442944478.png" alt="" loading="lazy"></figure>
<blockquote>
<p>CAP原则又称CAP定理，指的是在一个分布式系统中， Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），三者不可得兼。</p>
</blockquote>
<p><strong>CAP原则是NOSQL数据库的基石。</strong></p>
<p>分布式系统的CAP理论：理论首先把分布式系统中的三个特性进行了如下归纳：</p>
<ul>
<li>一致性（C）：在分布式系统中的所有数据备份，在同一时刻是否同样的值。（等同于所有节点访问同一份最新的数据副本）</li>
<li>可用性（A）：在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求。（对数据更新具备高可用性）</li>
<li>分区容忍性（P）：以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据正常返回，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择。</li>
</ul>
<h4 id="一致性与可用性的决择编辑">一致性与可用性的决择编辑</h4>
<p>CAP理论就是说在分布式存储系统中，最多只能实现上面的两点。而由于当前的网络硬件肯定会出现延迟丢包等问题，所以分区容忍性是我们必须需要实现的。所以我们只能在一致性和可用性之间进行权衡，没有NoSQL系统能同时保证这三点。</p>
<p>对于web2.0网站来说，关系数据库的很多主要特性却往往无用武之地</p>
<ol>
<li>
<p>数据库事务一致性需求<br>
　　很多web实时系统并不要求严格的数据库事务，对读一致性的要求很低，有些场合对写一致性要求并不高。允许实现最终一致性。</p>
</li>
<li>
<p>数据库的写实时性和读实时性需求<br>
　　对关系数据库来说，插入一条数据之后立刻查询，是肯定可以读出来这条数据的，但是对于很多web应用来说，并不要求这么高的实时性，比方说发一条消息之 后，过几秒乃至十几秒之后，我的订阅者才看到这条动态是完全可以接受的。</p>
</li>
<li>
<p>对复杂的SQL查询，特别是多表关联查询的需求<br>
　　任何大数据量的web系统，都非常忌讳多个大表的关联查询，以及复杂的数据分析类型的报表查询，特别是SNS类型的网站，从需求以及产品设计角 度，就避免了这种情况的产生。往往更多的只是单表的主键查询，以及单表的简单条件分页查询，SQL的功能被极大的弱化了。</p>
</li>
</ol>
<h4 id="cap定理的证明">CAP定理的证明</h4>
<p>现在我们就来证明一下，为什么不能同时满足三个特性？</p>
<p>假设有两台服务器，一台放着应用A和数据库V，一台放着应用B和数据库V，他们之间的网络可以互通，也就相当于分布式系统的两个部分。</p>
<p>在满足一致性的时候，两台服务器 N1和N2，一开始两台服务器的数据是一样的，DB0=DB0。在满足可用性的时候，用户不管是请求N1或者N2，都会得到立即响应。在满足分区容错性的情况下，N1和N2有任何一方宕机，或者网络不通的时候，都不会影响N1和N2彼此之间的正常运作。</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1629103855489.png" alt="" loading="lazy"></figure>
<p>当用户通过N1中的A应用请求数据更新到服务器DB0后，这时N1中的服务器DB0变为DB1，通过分布式系统的数据同步更新操作，N2服务器中的数据库V0也更新为了DB1，这时，用户通过B向数据库发起请求得到的数据就是即时更新后的数据DB1。</p>
<p>上面是正常运作的情况，但分布式系统中，最大的问题就是网络传输问题，现在假设一种极端情况，N1和N2之间的网络断开了，但我们仍要支持这种网络异常，也就是满足分区容错性，那么这样能不能同时满足一致性和可用性呢？</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1629103871249.png" alt="" loading="lazy"></figure>
<p>假设N1和N2之间通信的时候网络突然出现故障，有用户向N1发送数据更新请求，那N1中的数据DB0将被更新为DB1，由于网络是断开的，N2中的数据库仍旧是DB0；</p>
<p>如果这个时候，有用户向N2发送数据读取请求，由于数据还没有进行同步，应用程序没办法立即给用户返回最新的数据DB1，怎么办呢？有二种选择，第一，牺牲数据一致性，响应旧的数据DB0给用户；第二，牺牲可用性，阻塞等待，直到网络连接恢复，数据更新操作完成之后，再给用户响应最新的数据DB1。</p>
<p>上面的过程比较简单，但也说明了要满足分区容错性的分布式系统，只能在一致性和可用性两者中，选择其中一个。也就是说分布式系统不可能同时满足三个特性。这就需要我们在搭建系统时进行取舍了，那么，怎么取舍才是更好的策略呢?</p>
<h4 id="取舍策略">取舍策略</h4>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1622442957998.png" alt="" loading="lazy"></figure>
<p>CAP三个特性只能满足其中两个，那么取舍的策略就共有三种：</p>
<p><strong>CA without P：</strong> 如果不要求P（不允许分区），则C（强一致性）和A（可用性）是可以保证的。但放弃P的同时也就意味着放弃了系统的扩展性，也就是分布式节点受限，没办法部署子节点，这是违背分布式系统设计的初衷的。传统的关系型数据库RDBMS：Oracle、MySQL就是CA。</p>
<p><strong>CP without A：</strong> 如果不要求A（可用），相当于每个请求都需要在服务器之间保持强一致，而P（分区）会导致同步时间无限延长(也就是等待数据同步完才能正常访问服务)，一旦发生网络故障或者消息丢失等情况，就要牺牲用户的体验，等待所有数据全部一致了之后再让用户访问系统。设计成CP的系统其实不少，最典型的就是分布式数据库，如Redis、HBase等。对于这些分布式数据库来说，数据的一致性是最基本的要求，因为如果连这个标准都达不到，那么直接采用关系型数据库就好，没必要再浪费资源来部署分布式数据库。</p>
<p><strong>AP wihtout C：</strong> 要高可用并允许分区，则需放弃一致性。一旦分区发生，节点之间可能会失去联系，为了高可用，每个节点只能用本地数据提供服务，而这样会导致全局数据的不一致性。典型的应用就如某米的抢购手机场景，可能前几秒你浏览商品的时候页面提示是有库存的，当你选择完商品准备下单的时候，系统提示你下单失败，商品已售完。这其实就是先在 A（可用性）方面保证系统可以正常的服务，然后在数据的一致性方面做了些牺牲，虽然多少会影响一些用户体验，但也不至于造成用户购物流程的严重阻塞。</p>
<h3 id="base理论">BASE理论</h3>
<blockquote>
<p>BASE是Basically Available（基本可用）、Soft state（软状态）和Eventually consistent（最终一致性）三个短语的简写，BASE是对CAP中一致性和可用性权衡的结果，其来源于对大规模互联网系统分布式实践的结论，是基于CAP定理逐步演化而来的，其核心思想是即使无法做到强一致性（Strong consistency），但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性（Eventual consistency）。接下来我们着重对BASE中的三要素进行详细讲解。</p>
</blockquote>
<h4 id="基本可用">基本可用</h4>
<p>基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性——但请注意，这绝不等价于系统不可用，以下两个就是“基本可用”的典型例子。</p>
<ul>
<li>响应时间上的损失：正常情况下，一个在线搜索引擎需要0.5秒内返回给用户相应的查询结果，但由于出现异常（比如系统部分机房发生断电或断网故障），查询结果的响应时间增加到了1~2秒。</li>
<li>功能上的损失：正常情况下，在一个电子商务网站上进行购物，消费者几乎能够顺利地完成每一笔订单，但是在一些节日大促购物高峰的时候，由于消费者的购物行为激增，为了保护购物系统的稳定性，部分消费者可能会被引导到一个降级页面。</li>
</ul>
<h4 id="弱状态">弱状态</h4>
<p>弱状态也称为软状态，和硬状态相对，是指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。</p>
<h4 id="最终一致性">最终一致性</h4>
<blockquote>
<p>最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性</p>
</blockquote>
<p>亚马逊首席技术官Werner Vogels在于2008年发表的一篇文章中对最终一致性进行了非常详细的介绍。他认为最终一致性是一种特殊的弱一致性：系统能够保证在没有其他新的更新操作的情况下，数据最终一定能够达到一致的状态，因此所有客户端对系统的数据访问都能够获取到最新的值。同时，在没有发生故障的前提下，数据达到一致状态的时间延迟，取决于网络延迟，系统负载和数据复制方案设计等因素。</p>
<p>在实际工程实践中，最终一致性存在以下五类主要变种。</p>
<ol>
<li>
<p>因果一致性：</p>
<p>因果一致性是指，如果进程A在更新完某个数据项后通知了进程B，那么进程B之后对该数据项的访问都应该能够获取到进程A更新后的最新值，并且如果进程B要对该数据项进行更新操作的话，务必基于进程A更新后的最新值，即不能发生丢失更新情况。与此同时，与进程A无因果关系的进程C的数据访问则没有这样的限制。</p>
</li>
<li>
<p>读己之所写：</p>
<p>读己之所写是指，进程A更新一个数据项之后，它自己总是能够访问到更新过的最新值，而不会看到旧值。也就是说，对于单个数据获取者而言，其读取到的数据一定不会比自己上次写入的值旧。因此，读己之所写也可以看作是一种特殊的因果一致性。</p>
</li>
<li>
<p>会话一致性：</p>
<p>会话一致性将对系统数据的访问过程框定在了一个会话当中：系统能保证在同一个有效的会话中实现“读己之所写”的一致性，也就是说，执行更新操作之后，客户端能够在同一个会话中始终读取到该数据项的最新值。</p>
</li>
<li>
<p>单调读一致性：</p>
<p>单调读一致性是指如果一个进程从系统中读取出一个数据项的某个值后，那么系统对于该进程后续的任何数据访问都不应该返回更旧的值。</p>
</li>
<li>
<p>单调写一致性：</p>
<p>单调写一致性是指，一个系统需要能够保证来自同一个进程的写操作被顺序地执行。</p>
</li>
</ol>
<p>以上就是最终一致性的五类常见的变种，在时间系统实践中，可以将其中的若干个变种互相结合起来，以构建一个具有最终一致性的分布式系统。事实上，可以将其中的若干个变种相互结合起来，以构建一个具有最终一致性特性的分布式系统。事实上，最终一致性并不是只有那些大型分布式系统才设计的特性，许多现代的关系型数据库都采用了最终一致性模型。在现代关系型数据库中，大多都会采用同步和异步方式来实现主备数据复制技术。在同步方式中，数据的复制国耻鞥通常是更新事务的一部分，因此在事务完成后，主备数据库的数据就会达到一致。而在异步方式中，备库的更新往往存在延时，这取决于事务日志在主备数据库之间传输的时间长短，如果传输时间过长或者甚至在日志传输过程中出现异常导致无法及时将事务应用到备库上，那么狠显然，从备库中读取的的数据将是旧的，因此就出现了不一致的情况。当然，无论是采用多次重试还是认为数据订正，关系型数据库还是能搞保证最终数据达到一致——这就是系统提供最终一致性保证的经典案例。</p>
<p>总的来说，BASE理论面向的是大型高可用可扩展的分布式系统，和传统事务的ACID特性使相反的，它完全不同于ACID的强一致性模型，而是提出通过牺牲强一致性来获得可用性，并允许数据在一段时间内是不一致的，但最终达到一致状态。但同时，在实际的分布式场景中，不同业务单元和组件对数据一致性的要求是不同的，因此在具体的分布式系统架构设计过程中，ACID特性与BASE理论往往又会结合在一起使用。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[MyBatis 缓存详解]]></title>
        <id>https://tinaxiawuhao.github.io/post/P-yYZmx9j/</id>
        <link href="https://tinaxiawuhao.github.io/post/P-yYZmx9j/">
        </link>
        <updated>2021-06-01T08:51:37.000Z</updated>
        <content type="html"><![CDATA[<p>缓存是一般的ORM 框架都会提供的功能，目的就是提升查询的效率和减少数据库的压力。跟Hibernate 一样，MyBatis 也有一级缓存和二级缓存，并且预留了集成第三方缓存的接口。</p>
<p>缓存体系结构：</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1622193533861.png" alt="" loading="lazy"></figure>
<p>MyBatis 跟缓存相关的类都在cache 包里面，其中有一个Cache 接口，只有一个默认的实现类 <code>PerpetualCache</code>，它是用<code>HashMap</code> 实现的。</p>
<p>所有的缓存实现类总体上可分为三类：基本缓存、淘汰算法缓存、装饰器缓存。</p>
<table>
<thead>
<tr>
<th style="text-align:center">缓存实现类</th>
<th style="text-align:center">描述</th>
<th style="text-align:center">作用</th>
<th style="text-align:center">装饰条件</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">基本缓存</td>
<td style="text-align:center">缓存基本实现类</td>
<td style="text-align:center">默认是PerpetualCache，也可以自定义比如RedisCache等，具备基本功能的缓存类</td>
<td style="text-align:center">无</td>
</tr>
<tr>
<td style="text-align:center">LruCache</td>
<td style="text-align:center">LRU策略的缓存</td>
<td style="text-align:center">当缓存达到上限时，删除最近最少使用的缓存</td>
<td style="text-align:center">eviction=“LRU” （默认）</td>
</tr>
<tr>
<td style="text-align:center">FifoCache</td>
<td style="text-align:center">FIFO策略的缓存</td>
<td style="text-align:center">当缓存达到上限时，删除最先入队的缓存</td>
<td style="text-align:center">eviction=“FIFO”</td>
</tr>
<tr>
<td style="text-align:center">SoftCache/WeakCache</td>
<td style="text-align:center">带清理策略的缓存</td>
<td style="text-align:center">通过JVM的软引用和弱引用来实现缓存，当JVM内存不足时，会自动清理掉这些缓存</td>
<td style="text-align:center">eviction=“SOFT”/eviction=“WEAK”</td>
</tr>
<tr>
<td style="text-align:center">LoggingCache</td>
<td style="text-align:center">带日志功能的缓存</td>
<td style="text-align:center">比如输出缓存命中率</td>
<td style="text-align:center">基本</td>
</tr>
<tr>
<td style="text-align:center">SynchronizedCache</td>
<td style="text-align:center">同步缓存</td>
<td style="text-align:center">基于Synchronized关键字实现，解决并发问题</td>
<td style="text-align:center">基本</td>
</tr>
<tr>
<td style="text-align:center">BlockingCache</td>
<td style="text-align:center">阻塞缓存</td>
<td style="text-align:center">通过在get/put方式中加锁，保证只有一个线程操作缓存，基于Java重入锁实现</td>
<td style="text-align:center">blocking=true</td>
</tr>
<tr>
<td style="text-align:center">SerializedCache</td>
<td style="text-align:center">支持序列化的缓存</td>
<td style="text-align:center">将对象序列化以后存到缓存中，取出是反序列化</td>
<td style="text-align:center">readOnly=false(默认)</td>
</tr>
<tr>
<td style="text-align:center">ScheduledCache</td>
<td style="text-align:center">定时调度的缓存</td>
<td style="text-align:center">在进行 get/put/remove/getSize 等操作前，判断 缓存时间是否超过了设置的最长缓存时间（默认是 一小时），如果是则清空缓存–即每隔一段时间清 空一次缓存</td>
<td style="text-align:center">flushInterval不为空</td>
</tr>
<tr>
<td style="text-align:center">TransactionalCache</td>
<td style="text-align:center">事务缓存</td>
<td style="text-align:center">在二级缓存中使用，可以一次存入多个缓存，删除多个缓存</td>
<td style="text-align:center">在TransactionalCacheManager中用Map维护对应关系</td>
</tr>
</tbody>
</table>
<h3 id="一级缓存本地缓存">一级缓存（本地缓存）</h3>
<p>一级缓存也叫本地缓存，MyBatis 的一级缓存是在会话（SqlSession）层面进行缓存的。MyBatis 的一级缓存是默认开启的，不需要任何的配置。首先我们必须去弄清楚一个问题，在MyBatis 执行的流程里面，涉及到这么多的对象，那么缓存<code>PerpetualCache</code> 应该放在哪个对象里面去维护？如果要在同一个会话里面共享一级缓存，这个对象肯定是在SqlSession 里面创建的，作为SqlSession 的一个属性。</p>
<p><code>DefaultSqlSession</code> 里面只有两个属性，Configuration 是全局的，所以缓存只可能放在Executor 里面维护——<code>SimpleExecutor/ReuseExecutor/BatchExecutor</code> 的父类<code>BaseExecutor</code>的构造函数中持有了<code>PerpetualCache</code>。在同一个会话里面，多次执行相同的SQL 语句，会直接从内存取到缓存的结果，不会再发送SQL 到数据库。但是不同的会话里面，即使执行的SQL 一模一样（通过一个Mapper 的同一个方法的相同参数调用），也不能使用到一级缓存。</p>
<p>如下图所示，MyBatis会在一次会话的表示----一个SqlSession对象中创建一个本地缓存(local cache)，对于每一次查询，都会尝试根据查询的条件去本地缓存中查找是否在缓存中，如果在缓存中，就直接从缓存中取出，然后返回给用户；否则，从数据库读取数据，将查询结果存入缓存并返回给用户。</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1622193556324.png" alt="" loading="lazy"></figure>
<p>一级缓存的生命周期有多长？</p>
<ol>
<li>MyBatis在开启一个数据库会话时，会 创建一个新的<code>SqlSession</code>对象，<code>SqlSession</code>对象中会有一个新的Executor对象，Executor对象中持有一个新的<code>PerpetualCache</code>对象；当会话结束时，<code>SqlSession</code>对象及其内部的Executor对象还有<code>PerpetualCache</code>对象也一并释放掉。</li>
<li>如果<code>SqlSession</code>调用了close()方法，会释放掉一级缓存<code>PerpetualCache</code>对象，一级缓存将不可用；</li>
<li>如果<code>SqlSession</code>调用了<code>clearCache()</code>，会清空<code>PerpetualCache</code>对象中的数据，但是该对象仍可使用；</li>
<li><code>SqlSession</code>中执行了任何一个update操作(update()、delete()、insert()) ，都会清空<code>PerpetualCache</code>对象的数据，但是该对象可以继续使用；</li>
</ol>
<p>SqlSession 一级缓存的工作流程：</p>
<ol>
<li>对于某个查询，根据<code>statementId</code>,<code>params</code>,<code>rowBounds</code>来构建一个key值，根据这个key值去缓存Cache中取出对应的key值存储的缓存结果</li>
<li>判断从Cache中根据特定的key值取的数据数据是否为空，即是否命中；</li>
<li>如果命中，则直接将缓存结果返回；</li>
<li>如果没命中：</li>
</ol>
<ul>
<li>
<ol>
<li>去数据库中查询数据，得到查询结果；</li>
<li>将key和查询到的结果分别作为key,value对存储到Cache中；</li>
<li>将查询结果返回；</li>
</ol>
</li>
</ul>
<p>接下来我们来验证一下，MyBatis 的一级缓存到底是不是只能在一个会话里面共享，以及跨会话（不同session）操作相同的数据会产生什么问题。判断是否命中缓存：如果再次发送SQL 到数据库执行，说明没有命中缓存；如果直接打印对象，说明是从内存缓存中取到了结果。</p>
<ol>
<li>
<p>在同一个session 中共享（不同session 不能共享）</p>
</li>
<li>
<p>同一个会话中，update（包括delete）会导致一级缓存被清空</p>
</li>
<li>
<p>其他会话更新了数据，导致读取到脏数据（一级缓存不能跨会话共享）</p>
</li>
</ol>
<p>一级缓存的不足：</p>
<p>使用一级缓存的时候，因为缓存不能跨会话共享，不同的会话之间对于相同的数据可能有不一样的缓存。在有多个会话或者分布式环境下，会存在脏数据的问题。如果要解决这个问题，就要用到二级缓存。MyBatis 一级缓存（MyBaits 称其为 Local Cache）无法关闭，但是有两种级别可选：</p>
<ol>
<li>session 级别的缓存，在同一个 sqlSession 内，对同样的查询将不再查询数据库，直接从缓存中。</li>
<li>statement 级别的缓存，避坑： 为了避免这个问题，可以将一级缓存的级别设为 statement 级别的，这样每次查询结束都会清掉一级缓存。</li>
</ol>
<h3 id="二级缓存">二级缓存</h3>
<p>二级缓存是用来解决一级缓存不能跨会话共享的问题的，范围是<code>namespace</code> 级别的，可以被多个<code>SqlSession</code> 共享（只要是同一个接口里面的相同方法，都可以共享），生命周期和应用同步。如果你的MyBatis使用了二级缓存，并且你的Mapper和select语句也配置使用了二级缓存，那么在执行select查询的时候，MyBatis会先从二级缓存中取输入，其次才是一级缓存，即MyBatis查询数据的顺序是：二级缓存  —&gt; 一级缓存 —&gt; 数据库。</p>
<p>作为一个作用范围更广的缓存，它肯定是在SqlSession 的外层，否则不可能被多个SqlSession 共享。而一级缓存是在SqlSession 内部的，所以第一个问题，肯定是工作在一级缓存之前，也就是只有取不到二级缓存的情况下才到一个会话中去取一级缓存。第二个问题，二级缓存放在哪个对象中维护呢？ 要跨会话共享的话，SqlSession 本身和它里面的BaseExecutor 已经满足不了需求了，那我们应该在BaseExecutor 之外创建一个对象。</p>
<p>实际上MyBatis 用了一个装饰器的类来维护，就是<code>CachingExecutor</code>。如果启用了二级缓存，MyBatis 在创建Executor 对象的时候会对Executor 进行装饰。<code>CachingExecutor</code> 对于查询请求，会判断二级缓存是否有缓存结果，如果有就直接返回，如果没有委派交给真正的查询器Executor 实现类，比如<code>SimpleExecutor</code> 来执行查询，再走到一级缓存的流程。最后会把结果缓存起来，并且返回给用户。</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1622193575153.png" alt="" loading="lazy"></figure>
<p>开启二级缓存的方法</p>
<p>第一步：配置 <code>mybatis.configuration.cache-enabled=true</code>，只要没有显式地设置<code>cacheEnabled=false</code>，都会用<code>CachingExecutor</code> 装饰基本的执行器。</p>
<p>第二步：在Mapper.xml 中配置<cache/>标签：</p>
<pre><code class="language-xml">&lt;cache type=&quot;org.apache.ibatis.cache.impl.PerpetualCache&quot;
    size=&quot;1024&quot;
eviction=&quot;LRU&quot;
flushInterval=&quot;120000&quot;
readOnly=&quot;false&quot;/&gt;
</code></pre>
<p>基本上就是这样。这个简单语句的效果如下:</p>
<ul>
<li>映射语句文件中的所有 select 语句的结果将会被缓存。</li>
<li>映射语句文件中的所有 insert、update 和 delete 语句会刷新缓存。</li>
<li>缓存会使用最近最少使用算法（LRU, Least Recently Used）算法来清除不需要的缓存。</li>
<li>缓存不会定时进行刷新（也就是说，没有刷新间隔）。</li>
<li>缓存会保存列表或对象（无论查询方法返回哪种）的 1024 个引用。</li>
<li>缓存会被视为读/写缓存，这意味着获取到的对象并不是共享的，可以安全地被调用者修改，而不干扰其他调用者或线程所做的潜在修改。</li>
</ul>
<p>这个更高级的配置创建了一个 FIFO 缓存，每隔 60 秒刷新，最多可以存储结果对象或列表的 512 个引用，而且返回的对象被认为是只读的，因此对它们进行修改可能会在不同线程中的调用者产生冲突。可用的清除策略有：</p>
<ul>
<li>LRU – 最近最少使用：移除最长时间不被使用的对象。</li>
<li>FIFO – 先进先出：按对象进入缓存的顺序来移除它们。</li>
<li>SOFT – 软引用：基于垃圾回收器状态和软引用规则移除对象。</li>
<li>WEAK – 弱引用：更积极地基于垃圾收集器状态和弱引用规则移除对象。</li>
</ul>
<p>默认的清除策略是 LRU。</p>
<p><strong><code>flushInterval</code></strong>（刷新间隔）属性可以被设置为任意的正整数，设置的值应该是一个以毫秒为单位的合理时间量。 默认情况是不设置，也就是没有刷新间隔，缓存仅仅会在调用语句时刷新。</p>
<p><strong><code>size</code></strong>（引用数目）属性可以被设置为任意正整数，要注意欲缓存对象的大小和运行环境中可用的内存资源。默认值是 1024。</p>
<p><strong><code>readOnly</code></strong>（只读）属性可以被设置为 true 或 false。只读的缓存会给所有调用者返回缓存对象的相同实例。 因此这些对象不能被修改。这就提供了可观的性能提升。而可读写的缓存会（通过序列化）返回缓存对象的拷贝。 速度上会慢一些，但是更安全，因此默认值是 false。</p>
<p>注：二级缓存是事务性的。这意味着，当 SqlSession 完成并提交时，或是完成并回滚，但没有执行 <code>flushCache=true</code>的 <code>insert/delete/update</code> 语句时，缓存会获得更新。</p>
<p><code>Mapper.xml</code> 配置了<cache>之后，select()会被缓存。update()、delete()、insert()会刷新缓存。：如果<code>cacheEnabled=true</code>，<code>Mapper.xml</code> 没有配置标签，还有二级缓存吗？（没有）还会出现CachingExecutor 包装对象吗？（会）</p>
<p>只要<code>cacheEnabled=true</code> 基本执行器就会被装饰。有没有配置<cache>，决定了在启动的时候会不会创建这个mapper 的Cache 对象，只是最终会影响到<code>CachingExecutorquery</code> 方法里面的判断。如果某些查询方法对数据的实时性要求很高，不需要二级缓存，怎么办？我们可以在单个Statement ID 上显式关闭二级缓存（默认是true）：</p>
<pre><code class="language-xml">&lt;select id=&quot;selectBlog&quot; resultMap=&quot;BaseResultMap&quot; useCache=&quot;false&quot;&gt;
</code></pre>
<h4 id="第三方缓存做二级缓存">第三方缓存做二级缓存</h4>
<p>除了MyBatis 自带的二级缓存之外，我们也可以通过实现Cache 接口来自定义二级缓存。MyBatis 官方提供了一些第三方缓存集成方式，比如ehcache 和redis：https://github.com/mybatis/redis-cache ,这里就不过多介绍了。当然，我们也可以使用独立的缓存服务，不使用MyBatis 自带的二级缓存。</p>
<p>pom 文件引入依赖：</p>
<pre><code class="language-java">&lt;dependency&gt;
	&lt;groupId&gt;org.mybatis.caches&lt;/groupId&gt;
	&lt;artifactId&gt;mybatis-redis&lt;/artifactId&gt;
	&lt;version&gt;1.0.0-beta2&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<p>MybatisRedisCache</p>
<pre><code class="language-java">
import com.xxx.util.JsonUtils;
import org.apache.ibatis.cache.Cache;
import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;
import org.springframework.data.redis.core.RedisTemplate;
 
import java.util.concurrent.locks.ReadWriteLock;
import java.util.concurrent.locks.ReentrantReadWriteLock;
 
/**
 * Mybatis - redis二级缓存
 *
 */
public final class MybatisRedisCache implements Cache {
    /**
     * 日志工具类
     */
    private static final Logger logger = LogManager.getLogger(MybatisRedisCache.class);
 
    /**
     * 读写锁
     */
    private final ReadWriteLock readWriteLock = new ReentrantReadWriteLock();
    /**
     * ID
     */
    private String id;
 
    /**
     * 集成redisTemplate
     */
    private static RedisTemplate redisTemplate;
 
    public MybatisRedisCache() {
    }
 
    public MybatisRedisCache(String id) {
        if (id == null) {
            throw new IllegalArgumentException(&quot;Cache instances require an ID&quot;);
        } else {
            logger.debug(&quot;MybatisRedisCache.id={}&quot;, id);
            this.id = id;
        }
    }
 
 
    @Override
    public String getId() {
        return this.id;
    }
 
    @Override
    public int getSize() {
        try {
            Long size = redisTemplate.opsForHash().size(this.id.toString());
            logger.debug(&quot;MybatisRedisCache.getSize: {}-&gt;{}&quot;, id, size);
            return size.intValue();
        } catch (Exception e) {
            e.printStackTrace();
        }
        return 0;
    }
 
    @Override
    public void putObject(final Object key, final Object value) {
        try {
            logger.debug(&quot;MybatisRedisCache.putObject: {}-&gt;{}-&gt;{}&quot;, id, key, JsonUtils.toJson(value));
            redisTemplate.opsForHash().put(this.id.toString(), key.toString(), value);
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
 
    @Override
    public Object getObject(final Object key) {
        try {
            Object hashVal = redisTemplate.opsForHash().get(this.id.toString(), key.toString());
            logger.debug(&quot;MybatisRedisCache.getObject: {}-&gt;{}-&gt;{}&quot;, id, key, JsonUtils.toJson(hashVal));
            return hashVal;
        } catch (Exception e) {
            e.printStackTrace();
            return null;
        }
    }
 
    @Override
    public Object removeObject(final Object key) {
        try {
            redisTemplate.opsForHash().delete(this.id.toString(), key.toString());
            logger.debug(&quot;MybatisRedisCache.removeObject: {}-&gt;{}-&gt;{}&quot;, id, key);
        } catch (Exception e) {
            e.printStackTrace();
        }
        return null;
    }
 
    @Override
    public void clear() {
        try {
            redisTemplate.delete(this.id.toString());
            logger.debug(&quot;MybatisRedisCache.clear: {}&quot;, id);
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
 
    @Override
    public ReadWriteLock getReadWriteLock() {
        return this.readWriteLock;
    }
 
    @Override
    public String toString() {
        return &quot;MybatisRedisCache {&quot; + this.id + &quot;}&quot;;
    }
 
    /**
     * 设置redisTemplate
     *
     * @param redisTemplate
     */
    public void setRedisTemplate(RedisTemplate redisTemplate) {
        MybatisRedisCache.redisTemplate = redisTemplate;
    }
}
</code></pre>
<p>RedisConfig</p>
<pre><code class="language-java">import com.fasterxml.jackson.annotation.JsonAutoDetect;
import com.fasterxml.jackson.annotation.PropertyAccessor;
import com.fasterxml.jackson.databind.ObjectMapper;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.data.redis.connection.RedisConnectionFactory;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer;
import org.springframework.data.redis.serializer.StringRedisSerializer;

/**
 * Redis配置
 *
 */

@Configuration
public class RedisConfig {

    /**
     * 配置RedisTemplate
     *
     * @param factory
     * @return
     */
    @Bean
    public RedisTemplate redisTemplate(RedisConnectionFactory factory, Jackson2JsonRedisSerializer redisJsonSerializer) {
        RedisTemplate&lt;Object, Object&gt; template = new RedisTemplate&lt;&gt;();
        //redis连接工厂
        template.setConnectionFactory(factory);
        StringRedisSerializer stringRedisSerializer = new StringRedisSerializer();
        //redis.key序列化器
        template.setKeySerializer(stringRedisSerializer);
        //redis.value序列化器
        template.setValueSerializer(redisJsonSerializer);
        //redis.hash.key序列化器
        template.setHashKeySerializer(stringRedisSerializer);
        //redis.hash.value序列化器
        template.setHashValueSerializer(redisJsonSerializer);
        //调用其他初始化逻辑
        template.afterPropertiesSet();
        //这里设置redis事务一致
        template.setEnableTransactionSupport(true);
        return template;
    }

    /**
     * 配置redis Json序列化器
     *
     * @return
     */
    @Bean
    public Jackson2JsonRedisSerializer redisJsonSerializer() {
        //使用Jackson2JsonRedisSerializer来序列化和反序列化redis的value值（默认使用JDK的序列化方式）
        Jackson2JsonRedisSerializer serializer = new Jackson2JsonRedisSerializer(Object.class);
        ObjectMapper mapper = new ObjectMapper();
        mapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);
        mapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);
        serializer.setObjectMapper(mapper);
        return serializer;
    }

}
</code></pre>
<p>开启Mybatis二级缓存设置</p>
<p>方式1：mybatis-config.xml</p>
<pre><code class="language-java">&lt;configuration&gt;
    &lt;settings&gt;
        &lt;!-- 开启二级缓存 --&gt;
        &lt;setting name=&quot;cacheEnabled&quot; value=&quot;true&quot;/&gt;
    &lt;/settings&gt;
   ...
&lt;/configuration&gt;
</code></pre>
<p>方式2：Springboot - application.properties</p>
<pre><code class="language-java">#使全局的映射器启用或禁用缓存。
mybatis.configuration.cache-enabled=true
</code></pre>
<p>Mapper.xml 配置，type 使用RedisCache：</p>
<pre><code class="language-java">&lt;cache type=&quot;org.mybatis.caches.redis.RedisCache&quot;
eviction=&quot;FIFO&quot; flushInterval=&quot;60000&quot; size=&quot;512&quot; readOnly=&quot;true&quot;/&gt;
</code></pre>
<p>redis.properties 配置：</p>
<pre><code class="language-java">host=localhost
port=6379
connectionTimeout=5000
soTimeout=5000
database=0
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[springBoot概述]]></title>
        <id>https://tinaxiawuhao.github.io/post/O58auJO44/</id>
        <link href="https://tinaxiawuhao.github.io/post/O58auJO44/">
        </link>
        <updated>2021-05-31T08:29:40.000Z</updated>
        <content type="html"><![CDATA[<h2 id="spring-boot-优点">Spring Boot 优点</h2>
<ol>
<li>容易上手，提升开发效率，为 Spring 开发提供一个更快、更广泛的入门体验。</li>
<li>开箱即用，远离繁琐的配置。</li>
<li>提供了一系列大型项目通用的非业务性功能，例如：内嵌服务器、安全管理、运行数据监控、运行状况检查和外部化配置等。</li>
<li>没有代码生成，也不需要XML配置。</li>
<li>避免大量的 Maven 导入和各种版本冲突。</li>
</ol>
<h2 id="spring-boot-的核心注解是哪个它主要由哪几个注解组成的">Spring Boot 的核心注解是哪个？它主要由哪几个注解组成的？</h2>
<p>启动类上面的注解是@SpringBootApplication，它也是 Spring Boot 的核心注解，主要组合包含了以下 3 个注解：</p>
<p><code>@SpringBootConfiguration</code>：组合了 @Configuration 注解，实现配置文件的功能。</p>
<p><code>@EnableAutoConfiguration</code>：打开自动配置的功能，也可以关闭某个自动配置的选项，如关闭数据源自动配置功能： <code>@SpringBootApplication(exclude = { DataSourceAutoConfiguration.class })</code>。</p>
<p><code>@ComponentScan</code>：Spring组件扫描。</p>
<p>所有其它 Spring 组件(如Controller层、Service层、Dao层、定时器等)都必须放在应用  @SpringBootApplication 注解所在类的同包或者其子包下面，因为应用从启动类开始启动，然后会扫描启动类同包及其子包下面的组件，如果放在其它地方则会因为扫描不到而加载不了</p>
<h2 id="javaconfig">JavaConfig</h2>
<p><code>Spring JavaConfig</code> 是 Spring 社区的产品，它提供了配置 Spring IoC 容器的纯Java 方法。因此它有助于避免使用 XML 配置。使用 JavaConfig 的优点在于：</p>
<p>（1）面向对象的配置。由于配置被定义为 JavaConfig 中的类，因此用户可以充分利用 Java 中的面向对象功能。一个配置类可以继承另一个，重写它的@Bean 方法等。</p>
<p>（2）减少或消除 XML 配置。基于依赖注入原则的外化配置的好处已被证明。但是，许多开发人员不希望在 XML 和 Java 之间来回切换。JavaConfig 为开发人员提供了一种纯 Java 方法来配置与 XML 配置概念相似的 Spring 容器。从技术角度来讲，只使用 JavaConfig 配置类来配置容器是可行的，但实际上很多人认为将JavaConfig 与 XML 混合匹配是理想的。</p>
<p>（3）类型安全和重构友好。JavaConfig 提供了一种类型安全的方法来配置 Spring容器。由于 Java 5.0 对泛型的支持，现在可以按类型而不是按名称检索 bean，不需要任何强制转换或基于字符串的查找。</p>
<pre><code class="language-java">/**
 * @ConfigurationProperties 表示 告诉 SpringBoot 将本类中的所有属性和配置文件中相关的配置进行绑定；
 * prefix = &quot;user&quot; 表示 将配置文件中 key 为 user 的下面所有的属性与本类属性进行一一映射注入值，如果配置文件中
 * 不存在 &quot;user&quot; 的 key，则不会为 POJO 注入值，属性值仍然为默认值
 * @Component 将本来标识为一个 Spring 组件，因为只有是容器中的组件，容器才会为 @ConfigurationProperties 提供此注入功能
 * @PropertySource (value = { &quot; classpath : user.properties &quot; }) 指明加载类路径下的哪个配置文件来注入值
 */
@PropertySource(value = {&quot;classpath:user.properties&quot;})
@Component
@ConfigurationProperties(prefix = &quot;user&quot;)
public class User {
    private Integer id;
    private String lastName;
    private Integer age;
    private Date birthday;
    private List&lt;String&gt; colorList;
    private Map&lt;String, String&gt; cityMap;
}
/**
 * 文中的@Configuration 可以替换为@Component运行结果是一样的，但是两者是有不同的，@Configuration会为配置类生成CGLIB代理Class，@Component不会
 */
@PropertySource(value = {&quot;classpath:user.properties&quot;})
@Configuration
public class User {
    @Value(${user.id})
    private Integer id;
     @Value(${user.lastName})
    private String lastName;
     @Value(${user.age})
    private Integer age;
     @Value(${user.birthday})
    private Date birthday;
     @Value(${user.colorList})
    private List&lt;String&gt; colorList;
     @Value(${user.maps})
    private Map&lt;String, String&gt; cityMap;
}
</code></pre>
<p><strong>user.properties</strong></p>
<pre><code class="language-java">user.id=111
user.lastName=张无忌
user.age=120
user.birthday=2018/07/11
user.colorList=red,yellow,green,blacnk
user.cityMap.mapK1=长沙市
user.cityMap.mapK2=深圳市
user.maps=&quot;{mapK1: '长沙市', mapK2: '深圳市'}&quot;
</code></pre>
<h2 id="spring-boot-自动配置">Spring Boot 自动配置</h2>
<p>注解 @EnableAutoConfiguration, @Configuration, @ConditionalOnClass 就是自动配置的核心，</p>
<p>@EnableAutoConfiguration 给容器导入META-INF/spring.factories 里定义的自动配置类。</p>
<p>筛选有效的自动配置类。</p>
<p>每一个自动配置类结合对应的 xxxProperties.java 读取配置文件进行自动配置功能</p>
<h2 id="spring-boot-配置加载顺序">Spring Boot 配置加载顺序</h2>
<p>Spring Boot 支持多种外部配置方式，如下所示，从上往下加载优先级由高到低，内容相同时覆盖，不相同时累加。</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1622190707004.png" alt="" loading="lazy"></figure>
<p>如果在不同的目录中存在多个配置文件，它的读取顺序是：<br>
1、config/application.properties（项目根目录中config目录下）<br>
2、config/application.yml<br>
3、application.properties（项目根目录下）<br>
4、application.yml<br>
5、resources/config/application.properties（项目resources目录中config目录下）<br>
6、resources/config/application.yml<br>
7、resources/application.properties（项目的resources目录下）<br>
8、resources/application.yml</p>
<h2 id="yaml-配置">YAML 配置</h2>
<p>YAML 现在可以算是非常流行的一种配置文件格式了，无论是前端还是后端，都可以见到 YAML 配置。那么 YAML 配置和传统的 properties 配置相比到底有哪些优势呢？</p>
<ol>
<li>配置有序，在一些特殊的场景下，配置有序很关键</li>
<li>支持数组，数组中的元素可以是基本数据类型也可以是对象</li>
<li>简洁</li>
</ol>
<p>相比 properties 配置文件，YAML 还有一个缺点，就是不支持 <code>@PropertySource</code> 注解导入自定义的 YAML 配置。</p>
<h2 id="spring-boot-是否可以使用-xml-配置">Spring Boot 是否可以使用 XML 配置</h2>
<p>Spring Boot 推荐使用 Java 配置而非 XML 配置，但是 Spring Boot 中也可以使用 XML 配置，通过 <code>@ImportResource</code> 注解可以引入一个 XML 配置。</p>
<h2 id="spring-boot-核心配置文件bootstrapproperties和-applicationproperties-有何区别">spring boot 核心配置文件bootstrap.properties和 application.properties 有何区别</h2>
<p>单纯做 Spring Boot 开发，可能不太容易遇到 <code>bootstrap.properties</code> 配置文件，但是在结合 Spring Cloud 时，这个配置就会经常遇到了，特别是在需要加载一些远程配置文件的时侯。</p>
<p>spring boot 核心的两个配置文件：</p>
<ul>
<li>bootstrap (. yml 或者 . properties)：boostrap 由父 ApplicationContext 加载的，比 applicaton 优先加载，配置在应用程序上下文的引导阶段生效。一般来说我们在 Spring Cloud Config 或者 Nacos 中会用到它。且 boostrap 里面的属性不能被覆盖；</li>
<li>application (. yml 或者 . properties)： 由ApplicatonContext 加载，用于 spring boot 项目的自动化配置。</li>
</ul>
<h2 id="spring-profiles">Spring Profiles</h2>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1622190724869.png" alt="" loading="lazy"></figure>
<pre><code class="language-yaml">spring:
 profiles:
  active: devel #指定激活哪个环境配置，激活后，第一个文档内容失效;不指定时，以第一个文档为准
server:
 port: 8083
--- #&quot;---&quot;用于分隔不同的profiles（）文档块
spring:
 profiles: devel #指定环境标识为&quot;devel&quot;,相当于&quot;application-{profile}.properties/yml&quot;中的profile
server:
 port: 8081
---
spring:
 profiles: deploy #指定环境标识为&quot;deploy&quot;,相当于&quot;application-{profile}.properties/yml&quot;中的profile
server:
 port: 8082
</code></pre>
<h2 id="比较一下-spring-security-和-shiro-各自的优缺点">比较一下 Spring Security 和 Shiro 各自的优缺点</h2>
<p>由于 Spring Boot 官方提供了大量的非常方便的开箱即用的 Starter ，包括 Spring Security 的 Starter ，使得在 Spring Boot 中使用 Spring Security 变得更加容易，甚至只需要添加一个依赖就可以保护所有的接口，所以，如果是 Spring Boot 项目，一般选择 Spring Security 。当然这只是一个建议的组合，单纯从技术上来说，无论怎么组合，都是没有问题的。Shiro 和 Spring Security 相比，主要有如下一些特点：</p>
<ol>
<li>Spring Security 是一个重量级的安全管理框架；Shiro 则是一个轻量级的安全管理框架</li>
<li>Spring Security 概念复杂，配置繁琐；Shiro 概念简单、配置简单</li>
<li>Spring Security 功能强大；Shiro 功能简单</li>
</ol>
<h2 id="spring-boot-中如何解决跨域问题">Spring Boot 中如何解决跨域问题</h2>
<p>跨域可以在前端通过 JSONP 来解决，但是 JSONP 只可以发送 GET 请求，无法发送其他类型的请求，在 RESTful 风格的应用中，就显得非常鸡肋，因此我们推荐在后端通过 CORS，(Cross-origin resource sharing） 来解决跨域问题。这种解决方案并非 Spring Boot 特有的，在传统的 SSM 框架中，就可以通过 CORS 来解决跨域问题，只不过之前我们是在 XML 文件中配置 CORS ，现在可以通过实现WebMvcConfigurer接口然后重写addCorsMappings方法解决跨域问题。</p>
<pre><code class="language-java">@Configuration
public class CorsConfig implements WebMvcConfigurer {

    @Override
    public void addCorsMappings(CorsRegistry registry) {
        registry.addMapping(&quot;/**&quot;)
                .allowedOrigins(&quot;*&quot;)
                .allowCredentials(true)
                .allowedMethods(&quot;GET&quot;, &quot;POST&quot;, &quot;PUT&quot;, &quot;DELETE&quot;, &quot;OPTIONS&quot;)
                .maxAge(3600);
    }

}
</code></pre>
<p>项目中前后端分离部署，所以需要解决跨域的问题。</p>
<p>我们使用cookie存放用户登录的信息，在spring拦截器进行权限控制，当权限不符合时，直接返回给用户固定的json结果。</p>
<p>当用户登录以后，正常使用；当用户退出登录状态时或者token过期时，由于拦截器和跨域的顺序有问题，出现了跨域的现象。</p>
<p>我们知道一个http请求，先走filter，到达servlet后才进行拦截器的处理，如果我们把cors放在filter里，就可以优先于权限拦截器执行。</p>
<pre><code class="language-java">@Configuration
public class CorsConfig {
    @Bean
    public CorsFilter corsFilter() {
        CorsConfiguration corsConfiguration = new CorsConfiguration();
        corsConfiguration.addAllowedOrigin(&quot;*&quot;);
        corsConfiguration.addAllowedHeader(&quot;*&quot;);
        corsConfiguration.addAllowedMethod(&quot;*&quot;);
        corsConfiguration.setAllowCredentials(true);
        UrlBasedCorsConfigurationSource urlBasedCorsConfigurationSource = new UrlBasedCorsConfigurationSource();
        urlBasedCorsConfigurationSource.registerCorsConfiguration(&quot;/**&quot;, corsConfiguration);
        return new CorsFilter(urlBasedCorsConfigurationSource);
    }
}
</code></pre>
<h2 id="spring-boot-中的监视器">Spring Boot 中的监视器</h2>
<p>Spring boot actuator 是 spring 启动框架中的重要功能之一。Spring boot 监视器可帮助您访问生产环境中正在运行的应用程序的当前状态。有几个指标必须在生产环境中进行检查和监控。即使一些外部应用程序可能正在使用这些服务来向相关人员触发警报消息。监视器模块公开了一组可直接作为 HTTP URL 访问的REST 端点来检查状态。</p>
<h2 id="注册-servlet-三大组件-servlet-filter-listener">注册 Servlet 三大组件 Servlet、Filter、Listener</h2>
<h3 id="继承接口实现方式">继承，接口实现方式</h3>
<h4 id="servletregistrationbean-注册-servlet">ServletRegistrationBean 注册 Servlet</h4>
<p>1、自定义类继承 javax.servlet.http.HttpServlet，然后重写其 doGet 与 doPost 方法，在方法中编写控制代码；</p>
<p>2、第二步将 ServletRegistrationBean 组件添加到 Spring 容器中</p>
<pre><code class="language-java">import javax.servlet.ServletException;
import javax.servlet.http.HttpServlet;
import javax.servlet.http.HttpServletRequest;
import javax.servlet.http.HttpServletResponse;
import java.io.IOException;
/**
 * Created by Administrator 
 * 标准的 Servlet 实现 HttpServlet；重写其 doGet 、doPost 方法
 */
public class BookServlet extends HttpServlet {
    @Override
    protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {
        this.doPost(req, resp);
    }
    @Override
    protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {
        System.out.println(&quot;:com.lct.servlet.BookServlet:&quot; + req.getRequestURL());
        /**讲求转发到后台的 user/users 请求去，即会进入*/
        req.getRequestDispatcher(&quot;user/users&quot;).forward(req, resp);
    }
}
</code></pre>
<p>3、上面 Serlvet 转发到下面的 UserControllr 控制器中</p>
<p>4、@Configuration 配置类相当于以前的 beans.xml 中的配置，将 ServletRegistrationBean 也添加到 Spring 容器中来</p>
<pre><code class="language-java">import com.lct.component.MyLocaleResolve;
import com.lct.servlet.BookServlet;
import org.springframework.boot.web.server.WebServerFactoryCustomizer;
import org.springframework.boot.web.servlet.ServletRegistrationBean;
import org.springframework.boot.web.servlet.server.ConfigurableServletWebServerFactory;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.web.servlet.LocaleResolver;
/**
 * Created by Administrator 
 * 自定义配置类
 */
@Configuration
public class MyMvcConfig {
    /**
     * 注册 Servlet 三大组件 之  Servlet
     * 添加 ServletRegistrationBean ，就相当于以前在 web.xml 中配置的 &lt;servlet&gt;&lt;/servlet&gt;标签
     */
    @Bean
    public ServletRegistrationBean myServlet() {
        /**第二个参数是个不定参数组，可以配置映射多个请求
         * 相当于以前在 web.xml中配置的 &lt;servlet-mapptin&gt;&lt;/servlet-mapptin&gt;*/
        ServletRegistrationBean registrationBean = new ServletRegistrationBean(new
                BookServlet(), &quot;/bookServlet&quot;);
        return registrationBean;
    }
}
</code></pre>
<p>5、运行测试：</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1622190757311.gif" alt="" loading="lazy"></figure>
<h4 id="filterregistrationbean-注册-filter">FilterRegistrationBean 注册 Filter</h4>
<p>1、Filter(过滤器) 是 Servlet 技术中最实用的技术之一</p>
<p>2、Web 开发人员通过 Filter 技术，对 web 服务器管理的所有 web 资源(如动态的 Jsp、 Servlet，以及静态的 image、 html、CSS、JS 文件等) 进行过滤拦截，从而实现一些特殊的功能(如实现 URL 级别的权限访问控制、过滤敏感词汇、压缩响应信息等)</p>
<p>3、Filter 主要用于对用户请求进行预处理，也可以对 HttpServletResponse 进行后期处理(如编码设置，返回时禁用浏览器缓存等)</p>
<p>4、Filter 使用完整流程：Filter 对用户请求进行预处理，接着将请求交给 Servlet 进行处理并生成响应，最后 Filter 再对服务器响应进行后处理。</p>
<p>5、Servlet 的 Filter 经常会拿来与 Spring MVC 的 Interceptor(拦截器) 做对比</p>
<p>​	1）拦截器是基于 Java 的反射机制的，而过滤器是基于函数回调</p>
<p>​	2）拦截器不依赖与 servle t容器，过滤器依赖与 servlet 容器</p>
<p>​	3）拦截器可以访问 action 上下文、值栈里的对象，而过滤器不能访问</p>
<p>​	4）在 action 的生命周期中，拦截器可以多次被调用，而过滤器只能在容器初始化时被调用一次</p>
<p>​	5）拦截器可以获取 IOC 容器中的各个 bean，而过滤器就不行，这点很重要，在拦截器里注入一个 service，可以调用业务逻辑</p>
<p>​	6）SpringMVC 有自己的拦截器</p>
<pre><code class="language-java">import javax.servlet.*;
import javax.servlet.http.HttpServletRequest;
import java.io.IOException;
/**
 * Created by Administrator 
 * 标准 Servlet 过滤器，实现 javax.servlet.Filter 接口
 * 并重写它的 三个方法
 */
public class SystemFilter implements Filter {
    @Override
    public void init(FilterConfig filterConfig) throws ServletException {
        System.out.println(&quot;javax.servlet.Filter：：服务器启动....&quot;);
    }
    @Override
    public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException {
        /**
         * 转为 HttpServletRequest 输出请求路径 容易查看 请求地址
         */
        HttpServletRequest request = (HttpServletRequest) servletRequest;
        System.out.println(&quot;javax.servlet.Filter：：过滤器放行前....&quot; + request.getRequestURL());
        filterChain.doFilter(servletRequest, servletResponse);
        System.out.println(&quot;javax.servlet.Filter：：过滤器返回后....&quot; + request.getRequestURL());
    }
    @Override
    public void destroy() {
        System.out.println(&quot;javax.servlet.Filter：：服务器关闭....&quot;);
    }
}
</code></pre>
<p>6、使用 FilterRegistrationBean 添加 FIlter ：</p>
<pre><code class="language-java">import com.lct.component.MyLocaleResolve;
import com.lct.filter.SystemFilter;
import com.lct.servlet.BookServlet;
import org.springframework.boot.web.server.WebServerFactoryCustomizer;
import org.springframework.boot.web.servlet.FilterRegistrationBean;
import org.springframework.boot.web.servlet.ServletRegistrationBean;
import org.springframework.boot.web.servlet.server.ConfigurableServletWebServerFactory;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.web.servlet.LocaleResolver;
import javax.servlet.DispatcherType;
import java.util.Arrays;
/**
 * Created by Administrator 
 * 自定义配置类
 */
@Configuration
public class MyMvcConfig {
    /**
     * 注册 Servlet 三大组件 之  Filter (过滤器)
     * 添加 FilterRegistrationBean ，就相当于以前在 web.xml 中配置的 &lt;filter&gt;&lt;/filter&gt; 标签
     */
    @Bean
    public FilterRegistrationBean myFilter() {
        FilterRegistrationBean registrationBean = new FilterRegistrationBean();
        /**同样添加自定义的 Filter*/
        registrationBean.setFilter(new SystemFilter());
        /**然后设置过滤的路径，参数是个集合 ,相当于 web.xml中配置的 &lt;filter-mapptin&gt;&lt;/filter-mapptin&gt;
         * &quot;/*&quot;: 表示过滤所有 get 与 post 请求*/
        registrationBean.setUrlPatterns(Arrays.asList(&quot;/*&quot;));
        /**
         * setDispatcherTypes 相当于 web.xml 配置中 &lt;filter-mapptin&gt; 下的 &lt;dispatcher&gt; 标签
         * 用于过滤非常规的 get 、post 请求
         * REQUEST：默认方式，写了之后会过滤所有静态资源的请求
         * FORWARD：过滤所有的转发请求，无论是 jsp 中的 &lt;jsp:forward&lt;/&gt;、&lt;%@ page errorPage= %&gt;、还是后台的转发
         * INCLUDE：过滤 jsp 中的动态包含&lt;jsp:include 请求
         * ERROR：过滤在 web.xml 配置的全局错误页面
         * 了解即可，实际中也很少这么做
         */
        registrationBean.setDispatcherTypes(DispatcherType.REQUEST);
        return registrationBean;
    }
}
</code></pre>
<h4 id="servletlistenerregistrationbean-注册-listener">ServletListenerRegistrationBean 注册 Listener</h4>
<p>1、自定义监听器：</p>
<pre><code class="language-java">import javax.servlet.ServletContextEvent;
import javax.servlet.ServletContextListener;
/**
 * Created by Administrator on 2018/8/11 0011.
 * 标准 Servlet 监听器，实现 javax.servlet.ServletContextListener 接口
 * 然后实现方法
 * ServletContextListener：属于 Servlet 应用启动关闭监听器，监听容器初始化与销毁
 */
public class SystemListener implements ServletContextListener {
    @Override
    public void contextInitialized(ServletContextEvent servletContextEvent) {
        System.out.println(&quot;com.lct.listener.SystemListener::服务器启动.....&quot;);
    }
    @Override
    public void contextDestroyed(ServletContextEvent servletContextEvent) {
        System.out.println(&quot;com.lct.listener.SystemListener::服务器关闭.....&quot;);
    }
}
</code></pre>
<p>2、注册 ServletListenerRegistrationBean：</p>
<pre><code class="language-java">import com.lct.component.MyLocaleResolve;
import com.lct.filter.SystemFilter;
import com.lct.listener.SystemListener;
import com.lct.servlet.BookServlet;
import org.springframework.boot.web.server.WebServerFactoryCustomizer;
import org.springframework.boot.web.servlet.FilterRegistrationBean;
import org.springframework.boot.web.servlet.ServletListenerRegistrationBean;
import org.springframework.boot.web.servlet.ServletRegistrationBean;
import org.springframework.boot.web.servlet.server.ConfigurableServletWebServerFactory;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.web.servlet.LocaleResolver;
import java.util.Arrays;
/**
 * Created by Administrator 
 * 自定义配置类
 */
@Configuration
public class MyMvcConfig {
    /**
     * 注册 Servlet 三大组件 之  Listner
     * 添加 ServletListenerRegistrationBean ，就相当于以前在 web.xml 中配置的 &lt;listener&gt;&lt;/listener&gt;标签
     */
    @Bean
    public ServletListenerRegistrationBean myListener() {
        /**ServletListenerRegistrationBean&lt;T extends EventListener&gt; 属于的是泛型，可以注册常见的任意监听器
         * 将自己的监听器注册进来*/
        ServletListenerRegistrationBean registrationBean = new ServletListenerRegistrationBean(new SystemListener());
        return registrationBean;
    }
}
</code></pre>
<h3 id="注解方式">注解方式</h3>
<p>1、Servlet 三大组件 Servlet、Filter、Listener 在传统项目中需要在 web.xml 中进行相应的配置。Servlet 3.0 开始在 javax.servlet.annotation 包下提供 3 个对应</p>
<p>的 @WebServlet、@WebFilter、@WebListener 注解来简化操作。</p>
<p>2、Spring Boot 应用中这三个注解默认是不被扫描的，需要在项目启动类上添加 @ServletComponentScan 注解, 表示对 Servlet 组件扫描。</p>
<h4 id="webservlet">@WebServlet</h4>
<pre><code class="language-java">import javax.servlet.ServletException;
import javax.servlet.annotation.WebServlet;
import javax.servlet.http.HttpServlet;
import javax.servlet.http.HttpServletRequest;
import javax.servlet.http.HttpServletResponse;
import java.io.IOException;
 
/**
 * 标准的 Servlet ，实现 javax.servlet.http.HttpServlet. 重写其 doGet 、doPost 方法
 * name :表示 servlet 名称，可以不写，默认为空
 * urlPatterns: 表示请求的路径，如 http://ip:port/context-path/userServlet
 */
@WebServlet(name = &quot;UserServlet&quot;, urlPatterns = {&quot;/userServlet&quot;})
public class UserServlet extends HttpServlet {
    @Override
    protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {
        this.doPost(req, resp);
    }
 
    @Override
    protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {
        StringBuffer requestURL = req.getRequestURL();
        System.out.println(&quot;com.wmx.servlet.UserServlet -- &quot; + requestURL);
        resp.sendRedirect(&quot;/index.html&quot;);//浏览器重定向到服务器下的 index.html 页面
    }
}
</code></pre>
<h4 id="webfilter">@WebFilter</h4>
<pre><code class="language-java">import javax.servlet.*;
import javax.servlet.annotation.WebFilter;
import javax.servlet.http.HttpServletRequest;
import java.io.IOException;
 
/**
 * 标准 Servlet 过滤器，实现 javax.servlet.Filter 接口，并重现它的 3 个方法
 * filterName：表示过滤器名称，可以不写
 * value：配置请求过滤的规则，如 &quot;/*&quot; 表示过滤所有请求，包括静态资源，如 &quot;/user/*&quot; 表示 /user 开头的所有请求
 */
@WebFilter(filterName = &quot;SystemFilter&quot;, value = {&quot;/*&quot;})
public class SystemFilter implements Filter {
 
    @Override
    public void init(FilterConfig filterConfig) throws ServletException {
        System.out.println(&quot;com.wmx.servlet.SystemFilter -- 系统启动...&quot;);
    }
 
    @Override
    public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException {
        //转为 HttpServletRequest 输出请求路径
        HttpServletRequest request = (HttpServletRequest) servletRequest;
        System.out.println(&quot;com.wmx.servlet.SystemFilter -- 过滤器放行前....&quot; + request.getRequestURL());
        filterChain.doFilter(servletRequest, servletResponse);
        System.out.println(&quot;com.wmx.servlet.SystemFilter -- 过滤器返回后....&quot; + request.getRequestURL());
    }
 
    @Override
    public void destroy() {
        System.out.println(&quot;com.wmx.servlet.SystemFilter -- 系统关闭...&quot;);
    }
}
</code></pre>
<h4 id="weblistener">@WebListener</h4>
<pre><code class="language-java">import javax.servlet.ServletContextEvent;
import javax.servlet.ServletContextListener;
import javax.servlet.annotation.WebListener;
 
/**
 * 标准 Servlet 监听器，实现 javax.servlet.ServletContextListener 接口，并重写方法
 * ServletContextListener 属于 Servlet 应用启动关闭监听器，监听容器初始化与销毁。常用的监听器还有：
 * ServletRequestListener：HttpServletRequest 对象的创建和销毁监听器
 * HttpSessionListener：HttpSession 数据对象创建和销毁监听器
 * HttpSessionAttributeListener 监听HttpSession中属性变化
 * ServletRequestAttributeListener 监听ServletRequest中属性变化
 */
@WebListener
public class SystemListener implements ServletContextListener {
    @Override
    public void contextInitialized(ServletContextEvent sce) {
        System.out.println(&quot;com.wmx.servlet.SystemListener -- 服务器启动.&quot;);
    }
 
    @Override
    public void contextDestroyed(ServletContextEvent sce) {
        System.out.println(&quot;com.wmx.servlet.SystemListener -- 服务器关闭.&quot;);
    }
}
</code></pre>
<h4 id="servletcomponentscan">@ServletComponentScan</h4>
<p>Spring Boot 应用中这三个注解默认是不被扫描的，需要在项目启动类上添加 @ServletComponentScan 注解, 表示对 Servlet 组件扫描。</p>
<pre><code class="language-java">import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.boot.web.servlet.ServletComponentScan;
 
@SpringBootApplication
@ServletComponentScan //对 servlet 注解进行扫描
public class RedisStuWebApplication {
    public static void main(String[] args) {
        SpringApplication.run(RedisStuWebApplication.class, args);
    }
}
</code></pre>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1622190795511.gif" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[SpringMVC工作原理]]></title>
        <id>https://tinaxiawuhao.github.io/post/7cW_XVJ41/</id>
        <link href="https://tinaxiawuhao.github.io/post/7cW_XVJ41/">
        </link>
        <updated>2021-05-30T03:08:06.000Z</updated>
        <content type="html"><![CDATA[<p>SpringMVC的工作原理图：</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1622171698834.jpeg" alt="" loading="lazy"></figure>
<p><strong>SpringMVC流程</strong></p>
<p>1、 用户发送请求至前端控制器DispatcherServlet。</p>
<p>2、 DispatcherServlet收到请求调用HandlerMapping处理器映射器。</p>
<p>3、 处理器映射器找到具体的处理器(可以根据xml配置、注解进行查找)，生成处理器对象及处理器拦截器(如果有则生成)一并返回给DispatcherServlet。</p>
<p>4、 DispatcherServlet调用HandlerAdapter处理器适配器。</p>
<p>5、 HandlerAdapter经过适配调用具体的处理器(Controller，也叫后端控制器)。</p>
<p>6、 Controller执行完成返回ModelAndView。</p>
<p>7、 HandlerAdapter将controller执行结果ModelAndView返回给DispatcherServlet。</p>
<p>8、 DispatcherServlet将ModelAndView传给ViewReslover视图解析器。</p>
<p>9、 ViewReslover解析后返回具体View。</p>
<p>10、DispatcherServlet根据View进行渲染视图（即将模型数据填充至视图中）。</p>
<p>11、 DispatcherServlet响应用户。</p>
<p><strong>组件说明：</strong></p>
<p>以下组件通常使用框架提供实现：</p>
<p>DispatcherServlet：作为前端控制器，整个流程控制的中心，控制其它组件执行，统一调度，降低组件之间的耦合性，提高每个组件的扩展性。</p>
<p>HandlerMapping：通过扩展处理器映射器实现不同的映射方式，例如：配置文件方式，实现接口方式，注解方式等。</p>
<p>HandlAdapter：通过扩展处理器适配器，支持更多类型的处理器。</p>
<p>ViewResolver：通过扩展视图解析器，支持更多类型的视图解析，例如：jsp、freemarker、pdf、excel等。</p>
<p><strong>组件：</strong></p>
<p><strong>1、前端控制器DispatcherServlet（不需要工程师开发）,由框架提供</strong></p>
<p>作用：接收请求，响应结果，相当于转发器，中央处理器。有了dispatcherServlet减少了其它组件之间的耦合度。</p>
<p>用户请求到达前端控制器，它就相当于mvc模式中的c，dispatcherServlet是整个流程控制的中心，由它调用其它组件处理用户的请求，dispatcherServlet的存在降低了组件之间的耦合性。</p>
<p><strong>2、处理器映射器HandlerMapping(不需要工程师开发),由框架提供</strong></p>
<p>作用：根据请求的url查找Handler</p>
<p>HandlerMapping负责根据用户请求找到Handler即处理器，springmvc提供了不同的映射器实现不同的映射方式，例如：配置文件方式，实现接口方式，注解方式等。</p>
<p><strong>3、处理器适配器HandlerAdapter</strong></p>
<p>作用：按照特定规则（HandlerAdapter要求的规则）去执行Handler</p>
<p>通过HandlerAdapter对处理器进行执行，这是适配器模式的应用，通过扩展适配器可以对更多类型的处理器进行执行。</p>
<p><strong>4、处理器Handler(需要工程师开发)</strong></p>
<p><strong>注意：编写Handler时按照HandlerAdapter的要求去做，这样适配器才可以去正确执行Handler</strong></p>
<p>Handler 是继DispatcherServlet前端控制器的后端控制器，在DispatcherServlet的控制下Handler对具体的用户请求进行处理。</p>
<p>由于Handler涉及到具体的用户业务请求，所以一般情况需要工程师根据业务需求开发Handler。</p>
<p><strong>5、视图解析器View resolver(不需要工程师开发),由框架提供</strong></p>
<p>作用：进行视图解析，根据逻辑视图名解析成真正的视图（view）</p>
<p>View Resolver负责将处理结果生成View视图，View Resolver首先根据逻辑视图名解析成物理视图名即具体的页面地址，再生成View视图对象，最后对View进行渲染将处理结果通过页面展示给用户。 springmvc框架提供了很多的View视图类型，包括：jstlView、freemarkerView、pdfView等。</p>
<p>一般情况下需要通过页面标签或页面模版技术将模型数据通过页面展示给用户，需要由工程师根据业务需求开发具体的页面。</p>
<p><strong>6、视图View(需要工程师开发jsp...)</strong></p>
<p>View是一个接口，实现类支持不同的View类型（jsp、freemarker、pdf...）</p>
<p><strong>核心架构的具体流程步骤如下：</strong></p>
<p>1、首先用户发送请求——&gt;DispatcherServlet，前端控制器收到请求后自己不进行处理，而是委托给其他的解析器进行处理，作为统一访问点，进行全局的流程控制；</p>
<p>2、DispatcherServlet——&gt;HandlerMapping， HandlerMapping 将会把请求映射为HandlerExecutionChain 对象（包含一个Handler 处理器（页面控制器）对象、多个HandlerInterceptor 拦截器）对象，通过这种策略模式，很容易添加新的映射策略；</p>
<p>3、DispatcherServlet——&gt;HandlerAdapter，HandlerAdapter 将会把处理器包装为适配器，从而支持多种类型的处理器，即适配器设计模式的应用，从而很容易支持很多类型的处理器；</p>
<p>4、HandlerAdapter——&gt;处理器功能处理方法的调用，HandlerAdapter 将会根据适配的结果调用真正的处理器的功能处理方法，完成功能处理；并返回一个ModelAndView 对象（包含模型数据、逻辑视图名）；</p>
<p>5、ModelAndView的逻辑视图名——&gt; ViewResolver， ViewResolver 将把逻辑视图名解析为具体的View，通过这种策略模式，很容易更换其他视图技术；</p>
<p>6、View——&gt;渲染，View会根据传进来的Model模型数据进行渲染，此处的Model实际是一个Map数据结构，因此很容易支持其他视图技术；</p>
<p>7、返回控制权给DispatcherServlet，由DispatcherServlet返回响应给用户，到此一个流程结束。</p>
<p>下边两个组件通常情况下需要开发：</p>
<p>Handler：处理器，即后端控制器用controller表示。</p>
<p>View：视图，即展示给用户的界面，视图中通常需要标签语言展示模型数据。</p>
<p><strong>在讲SpringMVC之前我们先来看一下什么是MVC模式</strong></p>
<p>MVC：MVC是一种设计模式</p>
<p>MVC的原理图：</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1622171719747.png" alt="" loading="lazy"></figure>
<p><strong>分析：</strong></p>
<p>M-Model 模型（完成业务逻辑：有javaBean构成，service+dao+entity）</p>
<p>V-View 视图（做界面的展示  jsp，html……）</p>
<p>C-Controller 控制器（接收请求—&gt;调用模型—&gt;根据结果派发页面）</p>
<p><strong>springMVC是什么：</strong></p>
<p>springMVC是一个MVC的开源框架，springMVC=struts2+spring，springMVC就相当于是Struts2加上sring的整合，但是这里有一个疑惑就是，springMVC和spring是什么样的关系呢？这个在百度百科上有一个很好的解释：意思是说，springMVC是spring的一个后续产品，其实就是spring在原有基础上，又提供了web应用的MVC模块，可以简单的把springMVC理解为是spring的一个模块（类似AOP，IOC这样的模块），网络上经常会说springMVC和spring无缝集成，其实springMVC就是spring的一个子模块，所以根本不需要同spring进行整合。</p>
<p><strong>SpringMVC的原理图：</strong></p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1622171762295.png" alt="" loading="lazy"></figure>
<p><strong>看到这个图大家可能会有很多的疑惑，现在我们来看一下这个图的步骤：（可以对比MVC的原理图进行理解）</strong></p>
<p>第一步:用户发起请求到前端控制器（DispatcherServlet）</p>
<p>第二步：前端控制器请求处理器映射器（HandlerMappering）去查找处理器（Handle）：通过xml配置或者注解进行查找</p>
<p>第三步：找到以后处理器映射器（HandlerMappering）像前端控制器返回执行链（HandlerExecutionChain）</p>
<p>第四步：前端控制器（DispatcherServlet）调用处理器适配器（HandlerAdapter）去执行处理器（Handler）</p>
<p>第五步：处理器适配器去执行Handler</p>
<p>第六步：Handler执行完给处理器适配器返回ModelAndView</p>
<p>第七步：处理器适配器向前端控制器返回ModelAndView</p>
<p>第八步：前端控制器请求视图解析器（ViewResolver）去进行视图解析</p>
<p>第九步：视图解析器像前端控制器返回View</p>
<p>第十步：前端控制器对视图进行渲染</p>
<p>第十一步：前端控制器向用户响应结果</p>
<p><strong>看到这些步骤我相信大家很感觉非常的乱，这是正常的，但是这里主要是要大家理解springMVC中的几个组件：</strong></p>
<p>前端控制器（DispatcherServlet）：接收请求，响应结果，相当于电脑的CPU。</p>
<p>处理器映射器（HandlerMapping）：根据URL去查找处理器</p>
<p>处理器（Handler）：（需要程序员去写代码处理逻辑的）</p>
<p>处理器适配器（HandlerAdapter）：会把处理器包装成适配器，这样就可以支持多种类型的处理器，类比笔记本的适配器（适配器模式的应用）</p>
<p>视图解析器（ViewResovler）：进行视图解析，多返回的字符串，进行处理，可以解析成对应的页面</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[elasticSearch基础概念汇总]]></title>
        <id>https://tinaxiawuhao.github.io/post/w_tIMVx00/</id>
        <link href="https://tinaxiawuhao.github.io/post/w_tIMVx00/">
        </link>
        <updated>2021-05-29T07:17:08.000Z</updated>
        <content type="html"><![CDATA[<h3 id="1什么是elasticsearch">1.什么是ElasticSearch？</h3>
<p>Elasticsearch是一个基于Lucene的搜索引擎。它提供了具有HTTP Web界面和无架构JSON文档的分布式，多租户能力的全文搜索引擎。Elasticsearch是用Java开发的，根据Apache许可条款作为开源发布。它可以用于全文搜索，结构化搜索以及分析，当然你也可以将这三者进行组合。</p>
<h3 id="2为什么要使用elasticsearch">2.为什么要使用Elasticsearch?</h3>
<p>用数据库，也可以实现搜索的功能，为什么还需要搜索引擎呢？</p>
<p>就像 <a href="https://link.zhihu.com/?target=https%3A//stackoverflow.com/questions/51639166/elasticsearch-vs-relational-database">Stackoverflow</a> 的网友说的：</p>
<blockquote>
<p>A relational database can store data and also index it. A search engine can index data but also store it.</p>
</blockquote>
<p>数据库（理论上来讲，ES 也是数据库，这里的数据库，指的是关系型数据库），首先是存储，搜索只是顺便提供的功能，</p>
<p>而搜索引擎，首先是搜索，但是不把数据存下来就搜不了，所以只好存一存。</p>
<p>术业有专攻，专攻搜索的搜索引擎，自然会提供更强大的搜索能力。。</p>
<ol>
<li>Elasticsearch是分布式的。不需要其他组件，分发是实时的，被叫做”Push replication”。</li>
<li>Elasticsearch 完全支持 Apache Lucene 的接近实时的搜索。</li>
<li>处理多租户（<a href="http://en.wikipedia.org/wiki/Multitenancy">multitenancy</a>）不需要特殊配置，而Solr则需要更多的高级设置。</li>
<li>Elasticsearch 采用 Gateway 的概念，使得完备份更加简单。</li>
<li>各节点组成对等的网络结构，某些节点出现故障时会自动分配其他节点代替其进行工作。</li>
</ol>
<h3 id="3elasticsearch是如何实现master选举的">3.Elasticsearch是如何实现Master选举的？</h3>
<ul>
<li>Elasticsearch的选主是ZenDiscovery模块负责的，主要包含Ping（节点之间通过这个RPC来发现彼此）和Unicast（单播模块包含一个主机列表以控制哪些节点需要ping通）这两部分；</li>
<li>对所有可以成为master的节点（<strong>node.master: true</strong>）根据nodeId字典排序，每次选举每个节点都把自己所知道节点排一次序，然后选出第一个（第0位）节点，暂且认为它是master节点。</li>
<li>如果对某个节点的投票数达到一定的值（可以成为master节点数n/2+1）并且该节点自己也选举自己，那这个节点就是master。否则重新选举一直到满足上述条件。</li>
<li><em>补充：master节点的职责主要包括集群、节点和索引的管理，不负责文档级别的管理；data节点可以关闭http功能</em>。</li>
</ul>
<h3 id="4elasticsearch中如何避免脑裂">4.Elasticsearch中如何避免脑裂？</h3>
<p>为了避免产生脑裂，ES采用了常见的分布式系统思路，保证选举出的master被多数派(quorum)的master-eligible node认可，以此来保证只有一个master。这个quorum通过以下配置进行配置：</p>
<pre><code class="language-java">conf/elasticsearch.yml:
    discovery.zen.minimum_master_nodes: 2
</code></pre>
<h3 id="5elasticsearch中的倒排索引">5.Elasticsearch中的倒排索引</h3>
<h4 id="为什么叫倒排索引">为什么叫倒排索引</h4>
<p>在没有搜索引擎时，我们是直接输入一个网址，然后获取网站内容，这时我们的行为是：<code>document -&gt; to -&gt; words</code> 通过文章，获取里面的单词，此谓「正向索引」，forward index.后来，我们希望能够输入一个单词，找到含有这个单词，或者和这个单词有关系的文章：<code>word -&gt; to -&gt; documents</code>于是我们把这种索引，成为inverted index，直译过来，应该叫「反向索引」，国内翻译成「倒排索引」。</p>
<h4 id="倒排索引的内部结构">倒排索引的内部结构</h4>
<p>首先，在数据生成的时候，比如爬虫爬到一篇文章，这时我们需要对这篇文章进行分析，将文本拆解成一个个单词。</p>
<p>这个过程很复杂，比如“生存还是死亡”，你要如何让分词器自动将它分解为“生存”、“还是”、“死亡”三个词语，然后把“还是”这个无意义的词语干掉。这里不展开，感兴趣的同学可以查看关于「分析器」的内容。</p>
<p>接着，把这两个词语以及它对应的文档id存下来：</p>
<table>
<thead>
<tr>
<th>word</th>
<th>documentId</th>
</tr>
</thead>
<tbody>
<tr>
<td>生存</td>
<td>1</td>
</tr>
<tr>
<td>死亡</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>接着爬虫继续爬，又爬到一个含有“生存”的文档，于是索引变成：</p>
<table>
<thead>
<tr>
<th>word</th>
<th>documentId</th>
</tr>
</thead>
<tbody>
<tr>
<td>生存</td>
<td>1，2</td>
</tr>
<tr>
<td>死亡</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>下次搜索“生存”，就会返回文档ID是 1、2两份文档。然而上面这套索引的实现，给小孩子当玩具玩还行，要上生产环境，那还远着。想想看，这个世界上那么多单词，中文、英文、日文、韩文 … 你每次搜索一个单词，我都要全局遍历一遍，很明显不行。于是有了排序，我们需要对单词进行排序，像 B+ 树一样，可以在页里实现二分查找。光排序还不行，你单词都放在磁盘呢，磁盘 IO 慢的不得了，所以 Mysql 特意把索引缓存到了内存。你说好，我也学 Mysql 的，放内存，3，2，1，放，哐当，内存爆了。哪本字典，会把所有单词都贴在目录里的？</p>
<p>所以，上图：</p>
<figure data-type="image" tabindex="1"><img src="https://tinaxiawuhao.github.io/post-images/1622014331550.png" alt="" loading="lazy"></figure>
<p>Lucene 的倒排索，增加了最左边的一层「字典树」<code>term index</code>，它不存储所有的单词，只存储单词前缀，通过字典树找到单词所在的块，也就是单词的大概位置，再在块里二分查找，找到对应的单词，再找到单词对应的文档列表。</p>
<p>当然，内存寸土寸金，能省则省，所以 Lucene 还用了 <code>FST（Finite State Transducers）</code>对它进一步压缩。</p>
<p>最右边的 Posting List ，别看它只是存一个文档 ID 数组，但是它在设计时，遇到的问题可不少。</p>
<p><strong>Frame Of Reference</strong></p>
<p>原生的 Posting List 有两个痛点：</p>
<ul>
<li><strong>如何压缩以节省磁盘空间</strong></li>
<li><strong>如何快速求交并集（intersections and unions）</strong></li>
</ul>
<p>先来聊聊压缩。我们来简化下 Lucene 要面对的问题，假设有这样一个数组：<strong>[73, 300, 302, 332, 343, 372]</strong></p>
<p>Lucene 里，数据是按 Segment 存储的，每个 Segment 最多存 65536 个文档 ID， 所以文档 ID 的范围，从 0 到 2^16-1，所以如果不进行任何处理，那么每个元素都会占用 2 bytes ，对应上面的数组，就是 6 * 2 = 12 bytes.</p>
<p>怎么压缩呢？</p>
<p><strong>压缩，就是尽可能降低每个数据占用的空间，同时又能让信息不失真，能够还原回来。</strong></p>
<p><strong>Step 1：Delta-encode —— 增量编码</strong></p>
<p>我们只记录元素与元素之间的增量，于是数组变成了：[73, 227, 2, 30, 11, 29]</p>
<p><strong>Step 2：Split into blocks —— 分割成块</strong></p>
<p>Lucene里每个块是 256 个文档 ID，这样可以保证每个块，增量编码后，每个元素都不会超过 256（1 byte）.为了方便演示，我们假设每个块是 3 个文档 ID：</p>
<p><strong>[73, 227, 2], [30, 11, 29]</strong></p>
<p><strong>Step 3：Bit packing —— 按需分配空间</strong></p>
<p>对于第一个块，[73, 227, 2]，最大元素是227，需要 8 bits，好，那我给你这个块的每个元素，都分配 8 bits的空间。但是对于第二个块，[30, 11, 29]，最大的元素才30，只需要 5 bits，那我就给你每个元素，只分配 5 bits 的空间，足矣。这一步，可以说是把吝啬发挥到极致，精打细算，按需分配。</p>
<p>以上三个步骤，共同组成了一项编码技术，Frame Of Reference（FOR）：</p>
<figure data-type="image" tabindex="2"><img src="https://tinaxiawuhao.github.io/post-images/1622014347604.png" alt="" loading="lazy"></figure>
<p><strong>Roaring bitmaps</strong></p>
<p>接着来聊聊 Posting List 的第二个痛点 —— 如何快速求交并集（intersections and unions）。</p>
<p>在 Lucene 中查询，通常不只有一个查询条件，比如我们想搜索：</p>
<ul>
<li>含有“生存”相关词语的文档</li>
<li>文档发布时间在最近一个月</li>
<li>文档发布者是平台的特约作者</li>
</ul>
<p>这样就需要根据三个字段，去三棵倒排索引里去查，当然，磁盘里的数据，上一节提到过，用了 FOR 进行压缩，所以我们要把数据进行反向处理，即解压，才能还原成原始的文档 ID，然后把这三个文档 ID 数组在内存中做一个交集。</p>
<blockquote>
<p>即使没有多条件查询， Lucene 也需要频繁求并集，因为 Lucene 是分片存储的。</p>
</blockquote>
<p>同样，我们把 Lucene 遇到的问题，简化成一道算法题。</p>
<p>假设有下面三个数组：</p>
<pre><code class="language-java">[64, 300, 303, 343]

[73, 300, 302, 303, 343, 372]

[303, 311, 333, 343]
</code></pre>
<p>求它们的交集。</p>
<p><strong>Option 1: Integer 数组</strong></p>
<p>直接用原始的文档 ID ，可能你会说，那就逐个数组遍历一遍吧，遍历完就知道交集是什么了。</p>
<p>其实对于有序的数组，用跳表（skip table）可以更高效，这里就不展开了，因为不管是从性能，还是空间上考虑，Integer 数组都不靠谱，假设有100M 个文档 ID，每个文档 ID 占 2 bytes，那已经是 200 MB，而这些数据是要放到内存中进行处理的，把这么大量的数据，从磁盘解压后丢到内存，内存肯定撑不住。</p>
<p><strong>Option 2: Bitmap</strong></p>
<p>假设有这样一个数组：<strong>[3,6,7,10]</strong> 那么我们可以这样来表示：<strong>[0,0,1,0,0,1,1,0,0,1]</strong> 看出来了么，对，<strong>我们用 0 表示角标对应的数字不存在，用 1 表示存在。</strong></p>
<p>这样带来了两个好处：</p>
<ul>
<li>节省空间：既然我们只需要0和1，那每个文档 ID 就只需要 1 bit，还是假设有 100M 个文档，那只需要 100M bits = 100M * 1/8 bytes = 12.5 MB，比之前用 Integer 数组 的 200 MB，优秀太多</li>
<li>运算更快：0 和 1，天然就适合进行位运算，求交集，「与」一下，求并集，「或」一下，一切都回归到计算机的起点</li>
</ul>
<p><strong>Option 3: Roaring Bitmaps</strong></p>
<p>细心的你可能发现了，bitmap 有个硬伤，就是不管你有多少个文档，你占用的空间都是一样的，之前说过，Lucene Posting List 的每个 Segement 最多放 65536 个文档ID，举一个极端的例子，有一个数组，里面只有两个文档 ID：<strong>[0, 65535]<strong>用 Bitmap，要怎么表示？</strong>[1,0,0,0,….(超级多个0),…,0,0,1]</strong></p>
<p>你需要 65536 个 bit，也就是 65536/8 = 8192 bytes，而用 Integer 数组，你只需要 2 * 2 bytes = 4 bytes</p>
<p>呵呵，死板的 bitmap。可见在文档数量不多的时候，使用 Integer 数组更加节省内存。</p>
<p>我们来算一下临界值，很简单，无论文档数量多少，bitmap都需要 8192 bytes，而 Integer 数组则和文档数量成线性相关，每个文档 ID 占 2 bytes，所以：<code>8192 / 2 = 4096</code>当文档数量少于 4096 时，用 Integer 数组，否则，用 bitmap.</p>
<figure data-type="image" tabindex="3"><img src="https://tinaxiawuhao.github.io/post-images/1622014361997.png" alt="" loading="lazy"></figure>
<blockquote>
<p>这里补充一下 Roaring bitmaps 和 之前讲的 Frame Of Reference 的关系。<br>
Frame Of Reference 是压缩数据，减少磁盘占用空间，所以当我们从磁盘取数据时，也需要一个反向的过程，即解压，解压后才有我们上面看到的这样子的文档ID数组：[73, 300, 302, 303, 343, 372] ，接着我们需要对数据进行处理，求交集或者并集，这时候数据是需要放到内存进行处理的，我们有三个这样的数组，这些数组可能很大，而内存空间比磁盘还宝贵，于是需要更强有力的压缩算法，同时还要有利于快速的求交并集，于是有了Roaring Bitmaps 算法。<br>
另外，Lucene 还会把从磁盘取出来的数据，通过 Roaring bitmaps 处理后，缓存到内存中，Lucene 称之为 filter cache.</p>
</blockquote>
<h3 id="6elasticsearch中的集群-节点-索引-文档-类型是什么">6.ElasticSearch中的集群、节点、索引、文档、类型是什么？</h3>
<p><strong><code>群集</code></strong> 是一个或多个节点（服务器）的集合，它们共同保存您的整个数据，并提供跨所有节点的联合索引和搜索功能。群集由唯一名称标识，默认情况下为“elasticsearch”。此名称很重要，因为如果节点设置为按名称加入群集，则该节点只能是群集的一部分。</p>
<p><strong><code>节点</code></strong> 是属于集群一部分的单个服务器。它存储数据并参与群集索引和搜索功能。</p>
<p><strong><code>索引</code></strong> 就像关系数据库中的“数据库”。它有一个定义多种类型的映射。索引是逻辑名称空间，映射到一个或多个主分片，并且可以有零个或多个副本分片。 MySQL =&gt;数据库 　　 ElasticSearch =&gt;索引</p>
<p><strong><code>文档</code></strong> 类似于关系数据库中的一行。不同之处在于索引中的每个文档可以具有不同的结构（字段），但是对于通用字段应该具有相同的数据类型。 MySQL =&gt; Databases =&gt;Tables =&gt; Columns / Rows  ElasticSearch =&gt; Indices =&gt; Types =&gt;具有属性的文档</p>
<p><strong><code>类型</code></strong> 是索引的逻辑类别/分区，其语义完全取决于用户。</p>
<h3 id="7elasticsearch中的分片是什么">7.ElasticSearch中的分片是什么?</h3>
<p>在大多数环境中，每个节点都在单独的盒子或虚拟机上运行。</p>
<p><strong><code>索引</code></strong>  - 在Elasticsearch中，索引是文档的集合。</p>
<p><strong><code>分片</code></strong>  -因为Elasticsearch是一个分布式搜索引擎，所以索引通常被分割成分布在多个节点上的被称为分片的元素。</p>
<p><strong><code>Segment</code></strong> -每个shard（分片）包含多个segment（段），每一个segment都是一个倒排索引<br>
在查询的时，会把所有的segment查询结果汇总归并后最为最终的分片查询结果返回<br>
1.segment是不可变的，物理上你并不能从中删除信息，所以在删除文档的时候，是在文档上面打上一个删除的标记，然后在执行段合并的时候，进行删除<br>
2.索引segment段的个数越多，搜索性能越低且消耗内存更多</p>
<p>​		<strong><code>副本</code></strong>  -一个索引被分解成碎片以便于分发和扩展。副本是分片的副本。</p>
<p>​		<strong><code>分析器</code></strong>  -在ElasticSearch中索引数据时，数据由为索引定义的Analyzer在内部进行转换。 分析器由一个Tokenizer和零个或多个TokenFilter组成。编译器可以在一个或多个CharFilter之前。分析模块允许您在逻辑名称下注册分析器，然后可以在映射定义或某些API中引用它们。Elasticsearch附带了许多可以随时使用的预建分析器。或者，您可以组合内置的字符过滤器，编译器和过滤器器来创建自定义分析器。</p>
<p>​		<strong><code>编译器</code></strong>  -编译器用于将字符串分解为术语或标记流。一个简单的编译器可能会将字符串拆分为任何遇到空格或标点的地方。Elasticsearch有许多内置标记器，可用于构建自定义分析器。</p>
<h3 id="8详细描述一下elasticsearch索引文档的过程">8.详细描述一下Elasticsearch索引文档的过程。</h3>
<ul>
<li>协调节点默认使用文档ID参与计算（也支持通过routing），以便为路由提供合适的分片。</li>
</ul>
<pre><code>shard = hash(document_id) % (num_of_primary_shards)
</code></pre>
<ul>
<li>当分片所在的节点接收到来自协调节点的请求后，会将请求写入到Memory Buffer，然后定时（默认是每隔1秒）写入到Filesystem Cache，这个从Momery Buffer到Filesystem Cache的过程就叫做refresh；</li>
<li>当然在某些情况下，存在Momery Buffer和Filesystem Cache的数据可能会丢失，ES是通过translog的机制来保证数据的可靠性的。其实现机制是接收到请求后，同时也会写入到translog中，当Filesystem cache中的数据写入到磁盘中时，才会清除掉，这个过程叫做flush；</li>
<li>在flush过程中，内存中的缓冲将被清除，内容被写入一个新段，段的fsync将创建一个新的提交点，并将内容刷新到磁盘，旧的translog将被删除并开始一个新的translog。</li>
<li>flush触发的时机是定时触发（默认30分钟）或者translog变得太大（默认为512M）时；</li>
</ul>
<figure data-type="image" tabindex="4"><img src="https://tinaxiawuhao.github.io/post-images/1622018263120.jpeg" alt="" loading="lazy"></figure>
<p><em>补充：关于Lucene的Segement：</em></p>
<ul>
<li>Lucene索引是由多个段组成，段本身是一个功能齐全的倒排索引。</li>
<li>段是不可变的，允许Lucene将新的文档增量地添加到索引中，而不用从头重建索引。</li>
<li>对于每一个搜索请求而言，索引中的所有段都会被搜索，并且每个段会消耗CPU的时钟周、文件句柄和内存。这意味着段的数量越多，搜索性能会越低。</li>
<li>为了解决这个问题，Elasticsearch会合并小段到一个较大的段，提交新的合并段到磁盘，并删除那些旧的小段。</li>
</ul>
<h3 id="9详细描述一下elasticsearch更新和删除文档的过程">9.详细描述一下Elasticsearch更新和删除文档的过程</h3>
<ul>
<li>删除和更新也都是写操作，但是Elasticsearch中的文档是不可变的，因此不能被删除或者改动以展示其变更；</li>
<li>磁盘上的每个段都有一个相应的.del文件。当删除请求发送后，文档并没有真的被删除，而是在.del文件中被标记为删除。该文档依然能匹配查询，但是会在结果中被过滤掉。当段合并时，在.del文件中被标记为删除的文档将不会被写入新段。</li>
<li>在新的文档被创建时，Elasticsearch会为该文档指定一个版本号，当执行更新时，旧版本的文档在.del文件中被标记为删除，新版本的文档被索引到一个新段。旧版本的文档依然能匹配查询，但是会在结果中被过滤掉。</li>
</ul>
<h3 id="10详细描述一下elasticsearch搜索的过程">10.详细描述一下Elasticsearch搜索的过程</h3>
<ul>
<li>搜索被执行成一个两阶段过程，我们称之为 Query Then Fetch；</li>
<li>在初始<em>查询阶段</em>时，查询会广播到索引中每一个分片拷贝（主分片或者副本分片）。 每个分片在本地执行搜索并构建一个匹配文档的大小为 from + size 的优先队列。<em>PS：在搜索的时候是会查询Filesystem Cache的，但是有部分数据还在Memory Buffer，所以搜索是近实时的。</em></li>
<li>每个分片返回各自优先队列中 <strong>所有文档的 ID 和排序值</strong> 给协调节点，它合并这些值到自己的优先队列中来产生一个全局排序后的结果列表。</li>
<li>接下来就是 <em>取回阶段</em>，协调节点辨别出哪些文档需要被取回并向相关的分片提交多个 GET 请求。每个分片加载并 <em>丰富</em> 文档，如果有需要的话，接着返回文档给协调节点。一旦所有的文档都被取回了，协调节点返回结果给客户端。</li>
<li><em>补充：Query Then Fetch的搜索类型在文档相关性打分的时候参考的是本分片的数据，这样在文档数量较少的时候可能不够准确，DFS Query Then Fetch增加了一个预查询的处理，询问Term和Document frequency，这个评分更准确，但是性能会变差。</em></li>
</ul>
<figure data-type="image" tabindex="5"><img src="https://tinaxiawuhao.github.io/post-images/1622014432949.jpeg" alt="" loading="lazy"></figure>
<h3 id="11elasticsearch对于大数据量上亿量级的聚合如何实现">11.Elasticsearch对于大数据量（上亿量级）的聚合如何实现？</h3>
<ul>
<li>Elasticsearch 提供的首个近似聚合是cardinality 度量。它提供一个字段的基数，即该字段的<em>distinct</em>或者<em>unique</em>值的数目。它是基于HLL算法的。HLL 会先对我们的输入作哈希运算，然后根据哈希运算的结果中的 bits 做概率估算从而得到基数。其特点是：可配置的精度，用来控制内存的使用（更精确 ＝ 更多内存）；小的数据集精度是非常高的；我们可以通过配置参数，来设置去重需要的固定内存使用量。无论数千还是数十亿的唯一值，内存使用量只与你配置的精确度相关。</li>
</ul>
<h3 id="12在并发情况下elasticsearch如果保证读写一致">12.在并发情况下，Elasticsearch如果保证读写一致？</h3>
<ul>
<li>可以通过版本号使用乐观并发控制，以确保新版本不会被旧版本覆盖，由应用层来处理具体的冲突；</li>
<li>另外对于写操作，一致性级别支持quorum/one/all，默认为quorum，即只有当大多数分片可用时才允许写操作。但即使大多数可用，也可能存在因为网络等原因导致写入副本失败，这样该副本被认为故障，分片将会在一个不同的节点上重建。</li>
<li>对于读操作，可以设置replication为sync(默认)，这使得操作在主分片和副本分片都完成后才会返回；如果设置replication为async时，也可以通过设置搜索请求参数_preference为primary来查询主分片，确保文档是最新版本。</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[elasticSearch查询语句]]></title>
        <id>https://tinaxiawuhao.github.io/post/AdeCmc8BU/</id>
        <link href="https://tinaxiawuhao.github.io/post/AdeCmc8BU/">
        </link>
        <updated>2021-05-28T06:13:34.000Z</updated>
        <content type="html"><![CDATA[<!-- more -->
<blockquote>
<p>原文：https://distributedbytes.timojo.com/2016/07/23-useful-elasticsearch-example-queries.html<br>
作者：Tim Ojo</p>
</blockquote>
<p>为了演示不同类型的 ElasticSearch 的查询，我们将使用以下字段搜索书籍文档的集合（ title（标题）, authors（作者）, summary（摘要）, publish_date（发布日期）和 num_reviews（浏览数））。</p>
<p>在这之前，首先我们应该先创建一个新的索引（index），并批量导入一些文档：</p>
<p>创建索引：</p>
<pre><code class="language-json">PUT /bookdb_index
    { &quot;settings&quot;: { &quot;number_of_shards&quot;: 1 }} 
</code></pre>
<p>批量上传文档：</p>
<pre><code class="language-json">POST /bookdb_index/book/_bulk
    { &quot;index&quot;: { &quot;_id&quot;: 1 }}
    { &quot;title&quot;: &quot;Elasticsearch: The Definitive Guide&quot;, &quot;authors&quot;: [&quot;clinton gormley&quot;, &quot;zachary tong&quot;], &quot;summary&quot; : &quot;A distibuted real-time search and analytics engine&quot;, &quot;publish_date&quot; : &quot;2015-02-07&quot;, &quot;num_reviews&quot;: 20, &quot;publisher&quot;: &quot;oreilly&quot; }
    { &quot;index&quot;: { &quot;_id&quot;: 2 }}
    { &quot;title&quot;: &quot;Taming Text: How to Find, Organize, and Manipulate It&quot;, &quot;authors&quot;: [&quot;grant ingersoll&quot;, &quot;thomas morton&quot;, &quot;drew farris&quot;], &quot;summary&quot; : &quot;organize text using approaches such as full-text search, proper name recognition, clustering, tagging, information extraction, and summarization&quot;, &quot;publish_date&quot; : &quot;2013-01-24&quot;, &quot;num_reviews&quot;: 12, &quot;publisher&quot;: &quot;manning&quot; }
    { &quot;index&quot;: { &quot;_id&quot;: 3 }}
    { &quot;title&quot;: &quot;Elasticsearch in Action&quot;, &quot;authors&quot;: [&quot;radu gheorge&quot;, &quot;matthew lee hinman&quot;, &quot;roy russo&quot;], &quot;summary&quot; : &quot;build scalable search applications using Elasticsearch without having to do complex low-level programming or understand advanced data science algorithms&quot;, &quot;publish_date&quot; : &quot;2015-12-03&quot;, &quot;num_reviews&quot;: 18, &quot;publisher&quot;: &quot;manning&quot; }
    { &quot;index&quot;: { &quot;_id&quot;: 4 }}
    { &quot;title&quot;: &quot;Solr in Action&quot;, &quot;authors&quot;: [&quot;trey grainger&quot;, &quot;timothy potter&quot;], &quot;summary&quot; : &quot;Comprehensive guide to implementing a scalable search engine using Apache Solr&quot;, &quot;publish_date&quot; : &quot;2014-04-05&quot;, &quot;num_reviews&quot;: 23, &quot;publisher&quot;: &quot;manning&quot; }
</code></pre>
<h2 id="例子">例子</h2>
<h3 id="1基本比对查询">1.基本比对查询</h3>
<p>执行基本的全文本（匹配）查询有两种方式：使用Search Lite API（它希望所有搜索参数都作为URL的一部分传入），或使用完整的JSON请求正文（允许您使用完整的Elasticsearch DSL)。</p>
<p>这是一个基本的匹配查询，它在所有字段中搜索字符串“ guide”</p>
<pre><code class="language-json">GET /bookdb_index/book/_search?q=guide

[Results]
&quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;1&quot;,
        &quot;_score&quot;: 0.28168046,
        &quot;_source&quot;: {
          &quot;title&quot;: &quot;Elasticsearch: The Definitive Guide&quot;,
          &quot;authors&quot;: [
            &quot;clinton gormley&quot;,
            &quot;zachary tong&quot;
          ],
          &quot;summary&quot;: &quot;A distibuted real-time search and analytics engine&quot;,
          &quot;publish_date&quot;: &quot;2015-02-07&quot;,
          &quot;num_reviews&quot;: 20,
          &quot;publisher&quot;: &quot;manning&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;4&quot;,
        &quot;_score&quot;: 0.24144039,
        &quot;_source&quot;: {
          &quot;title&quot;: &quot;Solr in Action&quot;,
          &quot;authors&quot;: [
            &quot;trey grainger&quot;,
            &quot;timothy potter&quot;
          ],
          &quot;summary&quot;: &quot;Comprehensive guide to implementing a scalable search engine using Apache Solr&quot;,
          &quot;publish_date&quot;: &quot;2014-04-05&quot;,
          &quot;num_reviews&quot;: 23,
          &quot;publisher&quot;: &quot;manning&quot;
        }
      }
    ]

</code></pre>
<p>该查询的完整版本如下所示，其产生的结果与上述搜索精简版相同。</p>
<pre><code class="language-java">{
    &quot;query&quot;: {
        &quot;multi_match&quot; : {
            &quot;query&quot; : &quot;guide&quot;,
            &quot;fields&quot; : [&quot;_all&quot;]
        }
    }
}
 
</code></pre>
<p>使用<code>multi_match</code>关键字代替关键字<code>match</code>是对多个字段运行相同查询的便捷快捷方式。该<code>fields</code>属性指定要查询的字段，在这种情况下，我们要查询文档中的所有字段。<br>
这两个API均允许您指定要搜索的字段。例如，要在标题字段中搜索带有“in action”字样的图书，请执行以下操作：</p>
<pre><code class="language-java">GET /bookdb_index/book/_search?q=title:in action

[Results]
&quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;4&quot;,
        &quot;_score&quot;: 0.6259885,
        &quot;_source&quot;: {
          &quot;title&quot;: &quot;Solr in Action&quot;,
          &quot;authors&quot;: [
            &quot;trey grainger&quot;,
            &quot;timothy potter&quot;
          ],
          &quot;summary&quot;: &quot;Comprehensive guide to implementing a scalable search engine using Apache Solr&quot;,
          &quot;publish_date&quot;: &quot;2014-04-05&quot;,
          &quot;num_reviews&quot;: 23,
          &quot;publisher&quot;: &quot;manning&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;3&quot;,
        &quot;_score&quot;: 0.5975345,
        &quot;_source&quot;: {
          &quot;title&quot;: &quot;Elasticsearch in Action&quot;,
          &quot;authors&quot;: [
            &quot;radu gheorge&quot;,
            &quot;matthew lee hinman&quot;,
            &quot;roy russo&quot;
          ],
          &quot;summary&quot;: &quot;build scalable search applications using Elasticsearch without having to do complex low-level programming or understand advanced data science algorithms&quot;,
          &quot;publish_date&quot;: &quot;2015-12-03&quot;,
          &quot;num_reviews&quot;: 18,
          &quot;publisher&quot;: &quot;manning&quot;
        }
      }
    ]
 
</code></pre>
<p>但是，全身DSL在创建更复杂的查询（如我们将在后面看到）以及指定您希望如何返回结果方面给您更大的灵活性。在下面的示例中，我们指定要返回的结果数，开始的偏移量（用于分页），要返回的文档字段以及术语突出显示。</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;match&quot; : {
            &quot;title&quot; : &quot;in action&quot;
        }
    },
    &quot;size&quot;: 2,
    &quot;from&quot;: 0,
    &quot;_source&quot;: [ &quot;title&quot;, &quot;summary&quot;, &quot;publish_date&quot; ],
    &quot;highlight&quot;: {
        &quot;fields&quot; : {
            &quot;title&quot; : {}
        }
    }
}

[Results]
&quot;hits&quot;: {
    &quot;total&quot;: 2,
    &quot;max_score&quot;: 0.9105287,
    &quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;3&quot;,
        &quot;_score&quot;: 0.9105287,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;build scalable search applications using Elasticsearch without having to do complex low-level programming or understand advanced data science algorithms&quot;,
          &quot;title&quot;: &quot;Elasticsearch in Action&quot;,
          &quot;publish_date&quot;: &quot;2015-12-03&quot;
        },
        &quot;highlight&quot;: {
          &quot;title&quot;: [
            &quot;Elasticsearch &lt;em&gt;in&lt;/em&gt; &lt;em&gt;Action&lt;/em&gt;&quot;
          ]
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;4&quot;,
        &quot;_score&quot;: 0.9105287,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;Comprehensive guide to implementing a scalable search engine using Apache Solr&quot;,
          &quot;title&quot;: &quot;Solr in Action&quot;,
          &quot;publish_date&quot;: &quot;2014-04-05&quot;
        },
        &quot;highlight&quot;: {
          &quot;title&quot;: [
            &quot;Solr &lt;em&gt;in&lt;/em&gt; &lt;em&gt;Action&lt;/em&gt;&quot;
          ]
        }
      }
    ]
  }
 
</code></pre>
<p><strong>注意</strong>：对于多字查询，该<code>match</code>查询使您可以指定是否使用<code>and</code>运算符而不是默认<code>or</code>运算符。您还可以指定<code>minimum_should_match</code>选项来调整返回结果的相关性。可以在<a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/match-multi-word.html">这里</a>找到详细信息。</p>
<h3 id="2多字段搜索">2.多字段搜索</h3>
<p>正如我们已经看到的，要在搜索中查询多个文档字段（例如，在标题和摘要中搜索相同的查询字符串），则可以使用该<code>multi_match</code>查询。</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;multi_match&quot; : {
            &quot;query&quot; : &quot;elasticsearch guide&quot;,
            &quot;fields&quot;: [&quot;title&quot;, &quot;summary&quot;]
        }
    }
}

[Results]
&quot;hits&quot;: {
    &quot;total&quot;: 3,
    &quot;max_score&quot;: 0.9448582,
    &quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;1&quot;,
        &quot;_score&quot;: 0.9448582,
        &quot;_source&quot;: {
          &quot;title&quot;: &quot;Elasticsearch: The Definitive Guide&quot;,
          &quot;authors&quot;: [
            &quot;clinton gormley&quot;,
            &quot;zachary tong&quot;
          ],
          &quot;summary&quot;: &quot;A distibuted real-time search and analytics engine&quot;,
          &quot;publish_date&quot;: &quot;2015-02-07&quot;,
          &quot;num_reviews&quot;: 20,
          &quot;publisher&quot;: &quot;manning&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;3&quot;,
        &quot;_score&quot;: 0.17312013,
        &quot;_source&quot;: {
          &quot;title&quot;: &quot;Elasticsearch in Action&quot;,
          &quot;authors&quot;: [
            &quot;radu gheorge&quot;,
            &quot;matthew lee hinman&quot;,
            &quot;roy russo&quot;
          ],
          &quot;summary&quot;: &quot;build scalable search applications using Elasticsearch without having to do complex low-level programming or understand advanced data science algorithms&quot;,
          &quot;publish_date&quot;: &quot;2015-12-03&quot;,
          &quot;num_reviews&quot;: 18,
          &quot;publisher&quot;: &quot;manning&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;4&quot;,
        &quot;_score&quot;: 0.14965448,
        &quot;_source&quot;: {
          &quot;title&quot;: &quot;Solr in Action&quot;,
          &quot;authors&quot;: [
            &quot;trey grainger&quot;,
            &quot;timothy potter&quot;
          ],
          &quot;summary&quot;: &quot;Comprehensive guide to implementing a scalable search engine using Apache Solr&quot;,
          &quot;publish_date&quot;: &quot;2014-04-05&quot;,
          &quot;num_reviews&quot;: 23,
          &quot;publisher&quot;: &quot;manning&quot;
        }
      }
    ]
  }
 
</code></pre>
<p>请注意，命中数字3相匹配，因为在摘要中找到了“指南”一词。</p>
<h3 id="3提高字段重要性">3.提高字段重要性</h3>
<p>由于我们正在多个字段中进行搜索，因此我们可能希望提高特定字段中的得分。在以下人为设计的示例中，我们将摘要字段的得分提高了3倍，以提高摘要字段的重要性，这反过来又会增加文档<code>_id 4</code>的相关性。</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;multi_match&quot; : {
            &quot;query&quot; : &quot;elasticsearch guide&quot;,
            &quot;fields&quot;: [&quot;title&quot;, &quot;summary^3&quot;]
        }
    },
    &quot;_source&quot;: [&quot;title&quot;, &quot;summary&quot;, &quot;publish_date&quot;]
}

[Results]
&quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;1&quot;,
        &quot;_score&quot;: 0.31495273,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;A distibuted real-time search and analytics engine&quot;,
          &quot;title&quot;: &quot;Elasticsearch: The Definitive Guide&quot;,
          &quot;publish_date&quot;: &quot;2015-02-07&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;4&quot;,
        &quot;_score&quot;: 0.14965448,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;Comprehensive guide to implementing a scalable search engine using Apache Solr&quot;,
          &quot;title&quot;: &quot;Solr in Action&quot;,
          &quot;publish_date&quot;: &quot;2014-04-05&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;3&quot;,
        &quot;_score&quot;: 0.13094766,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;build scalable search applications using Elasticsearch without having to do complex low-level programming or understand advanced data science algorithms&quot;,
          &quot;title&quot;: &quot;Elasticsearch in Action&quot;,
          &quot;publish_date&quot;: &quot;2015-12-03&quot;
        }
      }
    ]
 
</code></pre>
<p><strong>注意</strong> ：Boosting不仅仅意味着计算出的分数会乘以Boosting系数。实际应用的升压值经过归一化和一些内部优化。有关增强工作原理的更多信息，请参见 <a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/query-time-boosting.html">Elasticsearch指南</a>。</p>
<h3 id="4布尔查询">4.布尔查询</h3>
<p>AND / OR / NOT运算符可用于微调我们的搜索查询，以提供更相关或更具体的结果。这是在搜索API中作为<code>bool</code>查询实现的。该<code>bool</code>查询接受一个<code>must</code>参数（等同于AND），一个<code>must_not</code>参数（等同于NOT）和一个<code>should</code>参数（等同于OR）。例如，如果我要搜索书名中带有“ Elasticsearch”或“ Solr”字样的书，则AND由“克林顿·戈姆利”（clinton gormley）创作，而不由“ radu gheorge”（radu gheorge）创作：</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;bool&quot;: {
            &quot;must&quot;: {
                &quot;bool&quot; : { &quot;should&quot;: [
                      { &quot;match&quot;: { &quot;title&quot;: &quot;Elasticsearch&quot; }},
                      { &quot;match&quot;: { &quot;title&quot;: &quot;Solr&quot; }} ] }
            },
            &quot;must&quot;: { &quot;match&quot;: { &quot;authors&quot;: &quot;clinton gormely&quot; }},
            &quot;must_not&quot;: { &quot;match&quot;: {&quot;authors&quot;: &quot;radu gheorge&quot; }}
        }
    }
}

[Results]
&quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;1&quot;,
        &quot;_score&quot;: 0.3672021,
        &quot;_source&quot;: {
          &quot;title&quot;: &quot;Elasticsearch: The Definitive Guide&quot;,
          &quot;authors&quot;: [
            &quot;clinton gormley&quot;,
            &quot;zachary tong&quot;
          ],
          &quot;summary&quot;: &quot;A distibuted real-time search and analytics engine&quot;,
          &quot;publish_date&quot;: &quot;2015-02-07&quot;,
          &quot;num_reviews&quot;: 20,
          &quot;publisher&quot;: &quot;oreilly&quot;
        }
      }
    ]
 
</code></pre>
<p><strong>注意</strong>：如您所见，布尔查询可以包装任何其他查询类型，包括其他布尔查询，以创建任意复杂或深度嵌套的查询。</p>
<h3 id="5模糊查询">5.模糊查询</h3>
<p>可以在“匹配”和“多匹配”查询中启用模糊匹配，以捕获拼写错误。模糊程度是根据距原始单词的Levenshtein距离指定的。</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;multi_match&quot; : {
            &quot;query&quot; : &quot;comprihensiv guide&quot;,
            &quot;fields&quot;: [&quot;title&quot;, &quot;summary&quot;],
            &quot;fuzziness&quot;: &quot;AUTO&quot;
        }
    },
    &quot;_source&quot;: [&quot;title&quot;, &quot;summary&quot;, &quot;publish_date&quot;],
    &quot;size&quot;: 1
}

[Results]
&quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;4&quot;,
        &quot;_score&quot;: 0.5961596,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;Comprehensive guide to implementing a scalable search engine using Apache Solr&quot;,
          &quot;title&quot;: &quot;Solr in Action&quot;,
          &quot;publish_date&quot;: &quot;2014-04-05&quot;
        }
      }
    ]
 
</code></pre>
<p><strong>注意</strong>：模糊度值<code>&quot;AUTO&quot;</code>等于指定<code>2</code>术语长度大于5时的值。但是，设置80％的人类拼写错误的编辑距离为<code>1</code>，并将模糊度设置为<code>1</code>可以改善整体搜索性能。有关更多信息，请参见《Elasticsearch最终指南》的“<a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/fuzziness.html">错别字和拼写错误”</a>一章。</p>
<h3 id="6通配符查询">6.通配符查询</h3>
<p>通配符查询使您可以指定要匹配的模式，而不是整个术语。<code>?</code>匹配任何字符并<code>*</code>匹配零个或多个字符。例如，要查找所有作者姓名以字母“ t”开头的记录</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;wildcard&quot; : {
            &quot;authors&quot; : &quot;t*&quot;
        }
    },
    &quot;_source&quot;: [&quot;title&quot;, &quot;authors&quot;],
    &quot;highlight&quot;: {
        &quot;fields&quot; : {
            &quot;authors&quot; : {}
        }
    }
}

[Results]
&quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;1&quot;,
        &quot;_score&quot;: 1,
        &quot;_source&quot;: {
          &quot;title&quot;: &quot;Elasticsearch: The Definitive Guide&quot;,
          &quot;authors&quot;: [
            &quot;clinton gormley&quot;,
            &quot;zachary tong&quot;
          ]
        },
        &quot;highlight&quot;: {
          &quot;authors&quot;: [
            &quot;zachary &lt;em&gt;tong&lt;/em&gt;&quot;
          ]
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;2&quot;,
        &quot;_score&quot;: 1,
        &quot;_source&quot;: {
          &quot;title&quot;: &quot;Taming Text: How to Find, Organize, and Manipulate It&quot;,
          &quot;authors&quot;: [
            &quot;grant ingersoll&quot;,
            &quot;thomas morton&quot;,
            &quot;drew farris&quot;
          ]
        },
        &quot;highlight&quot;: {
          &quot;authors&quot;: [
            &quot;&lt;em&gt;thomas&lt;/em&gt; morton&quot;
          ]
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;4&quot;,
        &quot;_score&quot;: 1,
        &quot;_source&quot;: {
          &quot;title&quot;: &quot;Solr in Action&quot;,
          &quot;authors&quot;: [
            &quot;trey grainger&quot;,
            &quot;timothy potter&quot;
          ]
        },
        &quot;highlight&quot;: {
          &quot;authors&quot;: [
            &quot;&lt;em&gt;trey&lt;/em&gt; grainger&quot;,
            &quot;&lt;em&gt;timothy&lt;/em&gt; potter&quot;
          ]
        }
      }
    ] 
 
</code></pre>
<h3 id="7正则表达式查询">7.正则表达式查询</h3>
<p>正则表达式查询使您可以指定比通配符查询更复杂的模式。</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;regexp&quot; : {
            &quot;authors&quot; : &quot;t[a-z]*y&quot;
        }
    },
    &quot;_source&quot;: [&quot;title&quot;, &quot;authors&quot;],
    &quot;highlight&quot;: {
        &quot;fields&quot; : {
            &quot;authors&quot; : {}
        }
    }
}

[Results]
&quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;4&quot;,
        &quot;_score&quot;: 1,
        &quot;_source&quot;: {
          &quot;title&quot;: &quot;Solr in Action&quot;,
          &quot;authors&quot;: [
            &quot;trey grainger&quot;,
            &quot;timothy potter&quot;
          ]
        },
        &quot;highlight&quot;: {
          &quot;authors&quot;: [
            &quot;&lt;em&gt;trey&lt;/em&gt; grainger&quot;,
            &quot;&lt;em&gt;timothy&lt;/em&gt; potter&quot;
          ]
        }
      }
    ]
 
</code></pre>
<h3 id="8匹配词组查询">8.匹配词组查询</h3>
<p>匹配词组查询要求查询字符串中的所有术语都存在于文档中，并按照查询字符串中指定的顺序并且彼此接近。默认情况下，术语必须彼此完全平行，但是您可以指定一个<code>slop</code>值，该值指示在仍将文档视为匹配项时允许相隔多远的术语。</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;multi_match&quot; : {
            &quot;query&quot;: &quot;search engine&quot;,
            &quot;fields&quot;: [&quot;title&quot;, &quot;summary&quot;],
            &quot;type&quot;: &quot;phrase&quot;,
            &quot;slop&quot;: 3
        }
    },
    &quot;_source&quot;: [ &quot;title&quot;, &quot;summary&quot;, &quot;publish_date&quot; ]
}

[Results]
&quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;4&quot;,
        &quot;_score&quot;: 0.22327082,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;Comprehensive guide to implementing a scalable search engine using Apache Solr&quot;,
          &quot;title&quot;: &quot;Solr in Action&quot;,
          &quot;publish_date&quot;: &quot;2014-04-05&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;1&quot;,
        &quot;_score&quot;: 0.16113183,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;A distibuted real-time search and analytics engine&quot;,
          &quot;title&quot;: &quot;Elasticsearch: The Definitive Guide&quot;,
          &quot;publish_date&quot;: &quot;2015-02-07&quot;
        }
      }
    ]
 
</code></pre>
<p><strong>注意</strong>：在上面的示例中，对于非短语类型查询，文档的<code>_id 1</code>得分通常更高，并且<code>_id 4</code>由于其字段长度较短而出现在文档的前面。但是，在进行短语查询时，会考虑到术语的接近度，因此文档<code>_id 4</code>得分会更高。</p>
<h3 id="9匹配词组前缀">9.匹配词组前缀</h3>
<p>匹配词组前缀查询可在查询时提供“按需输入”或“穷人”版本的自动完成功能，而无需以任何方式准备数据。像match_phrase查询一样，它接受一个<code>slop</code>参数以使单词顺序和相对位置的刚性降低一些。我还接受该<code>max_expansions</code>参数来限制匹配项的数量，以降低资源强度。</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;match_phrase_prefix&quot; : {
            &quot;summary&quot;: {
                &quot;query&quot;: &quot;search en&quot;,
                &quot;slop&quot;: 3,
                &quot;max_expansions&quot;: 10
            }
        }
    },
    &quot;_source&quot;: [ &quot;title&quot;, &quot;summary&quot;, &quot;publish_date&quot; ]
}

[Results]
&quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;4&quot;,
        &quot;_score&quot;: 0.5161346,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;Comprehensive guide to implementing a scalable search engine using Apache Solr&quot;,
          &quot;title&quot;: &quot;Solr in Action&quot;,
          &quot;publish_date&quot;: &quot;2014-04-05&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;1&quot;,
        &quot;_score&quot;: 0.37248808,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;A distibuted real-time search and analytics engine&quot;,
          &quot;title&quot;: &quot;Elasticsearch: The Definitive Guide&quot;,
          &quot;publish_date&quot;: &quot;2015-02-07&quot;
        }
      }
    ]
 
</code></pre>
<p><strong>注意</strong>：“按类型查询时搜索”会降低性能。更好的解决方案是按类型进行索引时间搜索。请查看<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-suggesters-completion.html">完成提示API</a>或使用<a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/_index_time_search_as_you_type.html">Edge-Ngram过滤器</a>以获取更多信息。</p>
<h3 id="10请求参数">10.请求参数</h3>
<p>该<code>query_string</code>查询提供了一种以简洁的速记语法执行多重匹配查询，布尔查询，增强查询，模糊匹配，通配符，正则表达式和范围查询的方法。在下面的示例中，我们对术语“ saerch算法”执行模糊搜索，其中作者之一是“ grant ingersoll”或“ tom morton”。我们搜索所有字段，但对摘要字段加2。</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;query_string&quot; : {
            &quot;query&quot;: &quot;(saerch~1 algorithm~1) AND (grant ingersoll)  OR (tom morton)&quot;,
            &quot;fields&quot;: [&quot;_all&quot;, &quot;summary^2&quot;]
        }
    },
    &quot;_source&quot;: [ &quot;title&quot;, &quot;summary&quot;, &quot;authors&quot; ],
    &quot;highlight&quot;: {
        &quot;fields&quot; : {
            &quot;summary&quot; : {}
        }
    }
}

[Results]
&quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;2&quot;,
        &quot;_score&quot;: 0.14558059,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;organize text using approaches such as full-text search, proper name recognition, clustering, tagging, information extraction, and summarization&quot;,
          &quot;title&quot;: &quot;Taming Text: How to Find, Organize, and Manipulate It&quot;,
          &quot;authors&quot;: [
            &quot;grant ingersoll&quot;,
            &quot;thomas morton&quot;,
            &quot;drew farris&quot;
          ]
        },
        &quot;highlight&quot;: {
          &quot;summary&quot;: [
            &quot;organize text using approaches such as full-text &lt;em&gt;search&lt;/em&gt;, proper name recognition, clustering, tagging, information extraction, and summarization&quot;
          ]
        }
      }
    ]
 
</code></pre>
<h3 id="11简单查询字符串">11.简单查询字符串</h3>
<p>该<code>simple_query_string</code>查询是该查询的一种版本<code>query_string</code>，它更适合在暴露给用户的单个搜索框中使用。它分别用+ / | /-代替了AND / OR / NOT的使用，并且丢弃了查询的无效部分，而不是在用户犯错时抛出异常。</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;simple_query_string&quot; : {
            &quot;query&quot;: &quot;(saerch~1 algorithm~1) + (grant ingersoll)  | (tom morton)&quot;,
            &quot;fields&quot;: [&quot;_all&quot;, &quot;summary^2&quot;]
        }
    },
    &quot;_source&quot;: [ &quot;title&quot;, &quot;summary&quot;, &quot;authors&quot; ],
    &quot;highlight&quot;: {
        &quot;fields&quot; : {
            &quot;summary&quot; : {}
        }
    }
} 
 
</code></pre>
<h3 id="12术语查询">12.术语查询</h3>
<p>以上示例是全文搜索的示例。有时，我们对结构化搜索更感兴趣，在结构化搜索中我们希望找到完全匹配并返回结果。在<code>term</code>与<code>terms</code>查询帮助我们在这里。在下面的示例中，我们正在搜索Manning Publications出版的索引中的所有书籍。</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;term&quot; : {
            &quot;publisher&quot;: &quot;manning&quot;
        }
    },
    &quot;_source&quot; : [&quot;title&quot;,&quot;publish_date&quot;,&quot;publisher&quot;]
}

[Results]
&quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;2&quot;,
        &quot;_score&quot;: 1.2231436,
        &quot;_source&quot;: {
          &quot;publisher&quot;: &quot;manning&quot;,
          &quot;title&quot;: &quot;Taming Text: How to Find, Organize, and Manipulate It&quot;,
          &quot;publish_date&quot;: &quot;2013-01-24&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;3&quot;,
        &quot;_score&quot;: 1.2231436,
        &quot;_source&quot;: {
          &quot;publisher&quot;: &quot;manning&quot;,
          &quot;title&quot;: &quot;Elasticsearch in Action&quot;,
          &quot;publish_date&quot;: &quot;2015-12-03&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;4&quot;,
        &quot;_score&quot;: 1.2231436,
        &quot;_source&quot;: {
          &quot;publisher&quot;: &quot;manning&quot;,
          &quot;title&quot;: &quot;Solr in Action&quot;,
          &quot;publish_date&quot;: &quot;2014-04-05&quot;
        }
      }
    ]
 
</code></pre>
<p>可以使用<code>terms</code>关键字代替并传递搜索词数组来指定多个词。</p>
<pre><code class="language-java">{
    &quot;query&quot;: {
        &quot;terms&quot; : {
            &quot;publisher&quot;: [&quot;oreilly&quot;, &quot;packt&quot;]
        }
    }
} 
 
</code></pre>
<h3 id="13字词查询-排序">13.字词查询-排序</h3>
<p>术语查询结果（与任何其他查询结果一样）可以轻松地进行排序。也允许多级排序</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;term&quot; : {
            &quot;publisher&quot;: &quot;manning&quot;
        }
    },
    &quot;_source&quot; : [&quot;title&quot;,&quot;publish_date&quot;,&quot;publisher&quot;],
    &quot;sort&quot;: [
        { &quot;publish_date&quot;: {&quot;order&quot;:&quot;desc&quot;}},
        { &quot;title&quot;: { &quot;order&quot;: &quot;desc&quot; }}
    ]
}

[Results]
&quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;3&quot;,
        &quot;_score&quot;: null,
        &quot;_source&quot;: {
          &quot;publisher&quot;: &quot;manning&quot;,
          &quot;title&quot;: &quot;Elasticsearch in Action&quot;,
          &quot;publish_date&quot;: &quot;2015-12-03&quot;
        },
        &quot;sort&quot;: [
          1449100800000,
          &quot;in&quot;
        ]
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;4&quot;,
        &quot;_score&quot;: null,
        &quot;_source&quot;: {
          &quot;publisher&quot;: &quot;manning&quot;,
          &quot;title&quot;: &quot;Solr in Action&quot;,
          &quot;publish_date&quot;: &quot;2014-04-05&quot;
        },
        &quot;sort&quot;: [
          1396656000000,
          &quot;solr&quot;
        ]
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;2&quot;,
        &quot;_score&quot;: null,
        &quot;_source&quot;: {
          &quot;publisher&quot;: &quot;manning&quot;,
          &quot;title&quot;: &quot;Taming Text: How to Find, Organize, and Manipulate It&quot;,
          &quot;publish_date&quot;: &quot;2013-01-24&quot;
        },
        &quot;sort&quot;: [
          1358985600000,
          &quot;to&quot;
        ]
      }
    ]
 
</code></pre>
<h3 id="14范围查询">14.范围查询</h3>
<p>另一个结构化查询示例是范围查询。在此示例中，我们搜索2015年出版的图书。</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;range&quot; : {
            &quot;publish_date&quot;: {
                &quot;gte&quot;: &quot;2015-01-01&quot;,
                &quot;lte&quot;: &quot;2015-12-31&quot;
            }
        }
    },
    &quot;_source&quot; : [&quot;title&quot;,&quot;publish_date&quot;,&quot;publisher&quot;]
}

[Results]
&quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;1&quot;,
        &quot;_score&quot;: 1,
        &quot;_source&quot;: {
          &quot;publisher&quot;: &quot;oreilly&quot;,
          &quot;title&quot;: &quot;Elasticsearch: The Definitive Guide&quot;,
          &quot;publish_date&quot;: &quot;2015-02-07&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;3&quot;,
        &quot;_score&quot;: 1,
        &quot;_source&quot;: {
          &quot;publisher&quot;: &quot;manning&quot;,
          &quot;title&quot;: &quot;Elasticsearch in Action&quot;,
          &quot;publish_date&quot;: &quot;2015-12-03&quot;
        }
      }
    ]
 
</code></pre>
<p><strong>注意</strong>：范围查询适用于日期，数字和字符串类型字段。</p>
<h3 id="15过滤查询">15.过滤查询</h3>
<p>筛选查询允许您筛选查询结果。对于我们的示例，我们正在查询标题或摘要中带有“ Elasticsearch”一词的图书，但我们希望将搜索结果过滤为仅包含20条或更多评论的图书。</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;filtered&quot;: {
            &quot;query&quot; : {
                &quot;multi_match&quot;: {
                    &quot;query&quot;: &quot;elasticsearch&quot;,
                    &quot;fields&quot;: [&quot;title&quot;,&quot;summary&quot;]
                }
            },
            &quot;filter&quot;: {
                &quot;range&quot; : {
                    &quot;num_reviews&quot;: {
                        &quot;gte&quot;: 20
                    }
                }
            }
        }
    },
    &quot;_source&quot; : [&quot;title&quot;,&quot;summary&quot;,&quot;publisher&quot;, &quot;num_reviews&quot;]
}

[Results]
&quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;1&quot;,
        &quot;_score&quot;: 0.5955761,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;A distibuted real-time search and analytics engine&quot;,
          &quot;publisher&quot;: &quot;oreilly&quot;,
          &quot;num_reviews&quot;: 20,
          &quot;title&quot;: &quot;Elasticsearch: The Definitive Guide&quot;
        }
      }
    ]
 
</code></pre>
<p><strong>注意</strong>：筛选查询并不要求存在要对其进行筛选的查询。如果未指定<code>match_all</code>查询，则运行查询，该查询基本上返回索引中的所有文档，然后对其进行过滤。实际上，首先运行过滤器，以减少需要查询的表面积。此外，过滤器在首次使用后会被缓存，这使其性能非常好。</p>
<p><strong>更新</strong>：已过滤的查询已从即将推出的Elasticsearch 5.0中删除，以支持bool查询。这是与上面相同的示例，改写为使用bool查询。返回的结果完全相同。</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;bool&quot;: {
            &quot;must&quot; : {
                &quot;multi_match&quot;: {
                    &quot;query&quot;: &quot;elasticsearch&quot;,
                    &quot;fields&quot;: [&quot;title&quot;,&quot;summary&quot;]
                }
            },
            &quot;filter&quot;: {
                &quot;range&quot; : {
                    &quot;num_reviews&quot;: {
                        &quot;gte&quot;: 20
                    }
                }
            }
        }
    },
    &quot;_source&quot; : [&quot;title&quot;,&quot;summary&quot;,&quot;publisher&quot;, &quot;num_reviews&quot;]
}
</code></pre>
<p>在下面的示例中，这也适用于多个过滤器。</p>
<h3 id="16多个过滤器">16.多个过滤器</h3>
<p>可以通过使用过滤器来组合多个过滤<code>bool</code>器。在下一个示例中，过滤器确定返回的结果必须至少具有20条评论，不得在2015年之前发布，而应由oreilly发布。</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;filtered&quot;: {
            &quot;query&quot; : {
                &quot;multi_match&quot;: {
                    &quot;query&quot;: &quot;elasticsearch&quot;,
                    &quot;fields&quot;: [&quot;title&quot;,&quot;summary&quot;]
                }
            },
            &quot;filter&quot;: {
                &quot;bool&quot;: {
                    &quot;must&quot;: {
                        &quot;range&quot; : { &quot;num_reviews&quot;: { &quot;gte&quot;: 20 } }
                    },
                    &quot;must_not&quot;: {
                        &quot;range&quot; : { &quot;publish_date&quot;: { &quot;lte&quot;: &quot;2014-12-31&quot; } }
                    },
                    &quot;should&quot;: {
                        &quot;term&quot;: { &quot;publisher&quot;: &quot;oreilly&quot; }
                    }
                }
            }
        }
    },
    &quot;_source&quot; : [&quot;title&quot;,&quot;summary&quot;,&quot;publisher&quot;, &quot;num_reviews&quot;, &quot;publish_date&quot;]
}

[Results]
&quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;1&quot;,
        &quot;_score&quot;: 0.5955761,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;A distibuted real-time search and analytics engine&quot;,
          &quot;publisher&quot;: &quot;oreilly&quot;,
          &quot;num_reviews&quot;: 20,
          &quot;title&quot;: &quot;Elasticsearch: The Definitive Guide&quot;,
          &quot;publish_date&quot;: &quot;2015-02-07&quot;
        }
      }
    ] 
 
</code></pre>
<h3 id="17功能评分字段值因子">17.功能评分：字段值因子</h3>
<p>在某些情况下，您可能希望将文档中特定字段的值纳入相关性分数的计算中。在您希望根据文档的受欢迎程度提高其相关性的情况下，这是典型的情况。在我们的示例中，我们希望增加受欢迎的书籍（根据评论数判断）。使用<code>field_value_factor</code>功能评分可以做到这一点。</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;function_score&quot;: {
            &quot;query&quot;: {
                &quot;multi_match&quot; : {
                    &quot;query&quot; : &quot;search engine&quot;,
                    &quot;fields&quot;: [&quot;title&quot;, &quot;summary&quot;]
                }
            },
            &quot;field_value_factor&quot;: {
                &quot;field&quot; : &quot;num_reviews&quot;,
                &quot;modifier&quot;: &quot;log1p&quot;,
                &quot;factor&quot; : 2
            }
        }
    },
    &quot;_source&quot;: [&quot;title&quot;, &quot;summary&quot;, &quot;publish_date&quot;, &quot;num_reviews&quot;]
}

[Results]
&quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;1&quot;,
        &quot;_score&quot;: 0.44831306,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;A distibuted real-time search and analytics engine&quot;,
          &quot;num_reviews&quot;: 20,
          &quot;title&quot;: &quot;Elasticsearch: The Definitive Guide&quot;,
          &quot;publish_date&quot;: &quot;2015-02-07&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;4&quot;,
        &quot;_score&quot;: 0.3718407,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;Comprehensive guide to implementing a scalable search engine using Apache Solr&quot;,
          &quot;num_reviews&quot;: 23,
          &quot;title&quot;: &quot;Solr in Action&quot;,
          &quot;publish_date&quot;: &quot;2014-04-05&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;3&quot;,
        &quot;_score&quot;: 0.046479136,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;build scalable search applications using Elasticsearch without having to do complex low-level programming or understand advanced data science algorithms&quot;,
          &quot;num_reviews&quot;: 18,
          &quot;title&quot;: &quot;Elasticsearch in Action&quot;,
          &quot;publish_date&quot;: &quot;2015-12-03&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;2&quot;,
        &quot;_score&quot;: 0.041432835,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;organize text using approaches such as full-text search, proper name recognition, clustering, tagging, information extraction, and summarization&quot;,
          &quot;num_reviews&quot;: 12,
          &quot;title&quot;: &quot;Taming Text: How to Find, Organize, and Manipulate It&quot;,
          &quot;publish_date&quot;: &quot;2013-01-24&quot;
        }
      }
    ]
 
</code></pre>
<p><strong>注意1</strong>：我们本来可以运行常规<code>multi_match</code>查询并按num_reviews字段进行排序，但是这样就失去了进行相关性评分的好处。<br>
<strong>注意2</strong>：还有许多其他参数可以调整对原始相关性得分的增强效果，例如“修饰符”，“因子”，“ boost_mode”等。这些参数在<a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/boosting-by-popularity.html">Elasticsearch指南</a>中进行了详细探讨。</p>
<h3 id="18作用分值衰减功能">18.作用分值：衰减功能</h3>
<p>假设您不想以某个字段的值递增，而希望拥有理想的目标值，并且希望该增益因子随着距离该值的增加而衰减。这通常在基于纬度/经度，价格或日期等数字字段的提升中很有用。在我们精心设计的示例中，我们正在搜索理想情况下于2014年6月左右出版的“搜索引擎”书籍。</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;function_score&quot;: {
            &quot;query&quot;: {
                &quot;multi_match&quot; : {
                    &quot;query&quot; : &quot;search engine&quot;,
                    &quot;fields&quot;: [&quot;title&quot;, &quot;summary&quot;]
                }
            },
            &quot;functions&quot;: [
                {
                    &quot;exp&quot;: {
                        &quot;publish_date&quot; : {
                            &quot;origin&quot;: &quot;2014-06-15&quot;,
                            &quot;offset&quot;: &quot;7d&quot;,
                            &quot;scale&quot; : &quot;30d&quot;
                        }
                    }
                }
            ],
            &quot;boost_mode&quot; : &quot;replace&quot;
        }
    },
    &quot;_source&quot;: [&quot;title&quot;, &quot;summary&quot;, &quot;publish_date&quot;, &quot;num_reviews&quot;]
}

[Results]
&quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;4&quot;,
        &quot;_score&quot;: 0.27420625,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;Comprehensive guide to implementing a scalable search engine using Apache Solr&quot;,
          &quot;num_reviews&quot;: 23,
          &quot;title&quot;: &quot;Solr in Action&quot;,
          &quot;publish_date&quot;: &quot;2014-04-05&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;1&quot;,
        &quot;_score&quot;: 0.005920768,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;A distibuted real-time search and analytics engine&quot;,
          &quot;num_reviews&quot;: 20,
          &quot;title&quot;: &quot;Elasticsearch: The Definitive Guide&quot;,
          &quot;publish_date&quot;: &quot;2015-02-07&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;2&quot;,
        &quot;_score&quot;: 0.000011564,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;organize text using approaches such as full-text search, proper name recognition, clustering, tagging, information extraction, and summarization&quot;,
          &quot;num_reviews&quot;: 12,
          &quot;title&quot;: &quot;Taming Text: How to Find, Organize, and Manipulate It&quot;,
          &quot;publish_date&quot;: &quot;2013-01-24&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;3&quot;,
        &quot;_score&quot;: 0.0000059171475,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;build scalable search applications using Elasticsearch without having to do complex low-level programming or understand advanced data science algorithms&quot;,
          &quot;num_reviews&quot;: 18,
          &quot;title&quot;: &quot;Elasticsearch in Action&quot;,
          &quot;publish_date&quot;: &quot;2015-12-03&quot;
        }
      }
    ]
 
</code></pre>
<h3 id="19功能评分脚本评分">19.功能评分：脚本评分</h3>
<p>如果内置的评分功能无法满足您的需求，则可以选择指定Groovy脚本进行评分。在我们的示例中，我们希望指定一个脚本，该脚本在决定要考虑评论数量的因素之前，先考虑publish_date。较新的书可能没有那么多的评论，因此不应因此受到惩罚。<br>
评分脚本如下所示：</p>
<pre><code class="language-java">publish_date = doc['publish_date'].value
num_reviews = doc['num_reviews'].value

if (publish_date &gt; Date.parse('yyyy-MM-dd', threshold).getTime()) {
  my_score = Math.log(2.5 + num_reviews)
} else {
  my_score = Math.log(1 + num_reviews)
}
return my_score
 
</code></pre>
<p>要动态使用评分脚本，我们使用<code>script_score</code>参数</p>
<pre><code class="language-java">POST /bookdb_index/book/_search
{
    &quot;query&quot;: {
        &quot;function_score&quot;: {
            &quot;query&quot;: {
                &quot;multi_match&quot; : {
                    &quot;query&quot; : &quot;search engine&quot;,
                    &quot;fields&quot;: [&quot;title&quot;, &quot;summary&quot;]
                }
            },
            &quot;functions&quot;: [
                {
                    &quot;script_score&quot;: {
                        &quot;params&quot; : {
                            &quot;threshold&quot;: &quot;2015-07-30&quot;
                        },
                        &quot;script&quot;: &quot;publish_date = doc['publish_date'].value; num_reviews = doc['num_reviews'].value; if (publish_date &gt; Date.parse('yyyy-MM-dd', threshold).getTime()) { return log(2.5 + num_reviews) }; return log(1 + num_reviews);&quot;
                    }
                }
            ]
        }
    },
    &quot;_source&quot;: [&quot;title&quot;, &quot;summary&quot;, &quot;publish_date&quot;, &quot;num_reviews&quot;]
}

[Results]
&quot;hits&quot;: {
    &quot;total&quot;: 4,
    &quot;max_score&quot;: 0.8463001,
    &quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;1&quot;,
        &quot;_score&quot;: 0.8463001,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;A distibuted real-time search and analytics engine&quot;,
          &quot;num_reviews&quot;: 20,
          &quot;title&quot;: &quot;Elasticsearch: The Definitive Guide&quot;,
          &quot;publish_date&quot;: &quot;2015-02-07&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;4&quot;,
        &quot;_score&quot;: 0.7067348,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;Comprehensive guide to implementing a scalable search engine using Apache Solr&quot;,
          &quot;num_reviews&quot;: 23,
          &quot;title&quot;: &quot;Solr in Action&quot;,
          &quot;publish_date&quot;: &quot;2014-04-05&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;3&quot;,
        &quot;_score&quot;: 0.08952084,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;build scalable search applications using Elasticsearch without having to do complex low-level programming or understand advanced data science algorithms&quot;,
          &quot;num_reviews&quot;: 18,
          &quot;title&quot;: &quot;Elasticsearch in Action&quot;,
          &quot;publish_date&quot;: &quot;2015-12-03&quot;
        }
      },
      {
        &quot;_index&quot;: &quot;bookdb_index&quot;,
        &quot;_type&quot;: &quot;book&quot;,
        &quot;_id&quot;: &quot;2&quot;,
        &quot;_score&quot;: 0.07602123,
        &quot;_source&quot;: {
          &quot;summary&quot;: &quot;organize text using approaches such as full-text search, proper name recognition, clustering, tagging, information extraction, and summarization&quot;,
          &quot;num_reviews&quot;: 12,
          &quot;title&quot;: &quot;Taming Text: How to Find, Organize, and Manipulate It&quot;,
          &quot;publish_date&quot;: &quot;2013-01-24&quot;
        }
      }
    ]
  }
 
</code></pre>
<p><strong>注意1</strong>：要使用动态脚本，必须为<code>config/elasticsearch.yaml</code>文件中的Elasticsearch实例启用动态脚本。也可以使用存储在Elasticsearch服务器上的脚本。查阅<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-scripting.html">Elasticsearch参考文档</a>了解更多信息。</p>
<p><strong>注意2</strong> ：JSON无法包含嵌入的换行符，因此分号用于分隔语句。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[docker安装ELK]]></title>
        <id>https://tinaxiawuhao.github.io/post/3D5Sr6L0c/</id>
        <link href="https://tinaxiawuhao.github.io/post/3D5Sr6L0c/">
        </link>
        <updated>2021-05-27T07:39:14.000Z</updated>
        <content type="html"><![CDATA[<h2 id="docker部署elasticsearch">Docker部署ElasticSearch</h2>
<h3 id="搜索elasticsearch镜像">搜索ElasticSearch镜像</h3>
<pre><code class="language-java">docker search elasticsearch
</code></pre>
<h3 id="拉取镜像">拉取镜像</h3>
<p>拉取镜像的时候，可以指定版本，如果不指定，默认使用latest。</p>
<pre><code class="language-java">docker pull elasticsearch:7.12.0
</code></pre>
<h3 id="查看镜像">查看镜像</h3>
<pre><code class="language-java">docker images
</code></pre>
<h3 id="docker-启动-elasticsearch">docker 启动 elasticsearch</h3>
<pre><code class="language-java"># --name : 为 elasticsearch 容器起个别名
# -e : 指定为单节点集群模式
# -i：表示运行容器
# -t：表示容器启动后会进入其命令行。加入这两个参数后，容器创建就能登录进去。即分配一个伪终端。
# -v：表示目录映射关系（前者是宿主机目录，后者是映射到宿主机上的目录），可以使用多个－v做多个目录或文件映射。注意：最好做目录映射，在宿主机上做修改，然后共享到容器上。
# -d：在run后面加上-d参数,则会创建一个守护式容器在后台运行（这样创建容器后不会自动登录容器，如果只加-i -t两个参数，创建后就会自动进去容器）。
# -p：表示端口映射，前者是宿主机端口，后者是容器内的映射端口。可以使用多个-p做多个端口映射
docker run -di --name elasticsearch -p 9200:9200 -p 9300:9300 -e &quot;discovery.type=single-node&quot; elasticsearch:7.12.0 
</code></pre>
<h3 id="elasticsearch配置">elasticsearch配置</h3>
<h4 id="创建elasticsearch滚动策略">创建elasticsearch滚动策略</h4>
<pre><code class="language-json"># 定义审计日志管理策略
curl -X PUT &quot;${host}/_ilm/policy/audit_policy&quot; -H 'Content-Type: application/json' -d'
{
  &quot;policy&quot;: {                       
    &quot;phases&quot;: {
      &quot;hot&quot;: {                      
        &quot;actions&quot;: {
          &quot;rollover&quot;: {             
            &quot;max_size&quot;: &quot;30GB&quot;,
            &quot;max_age&quot;: &quot;180d&quot;
          }
        }
      },
      &quot;delete&quot;: {
        &quot;min_age&quot;: &quot;180d&quot;,           
        &quot;actions&quot;: {
          &quot;delete&quot;: {}              
        }
      }
    }
  }
}
</code></pre>
<p>热数据最大30G,最多180天，数据最少保持180天后删除</p>
<h4 id="创建索引模板">创建索引模板</h4>
<pre><code class="language-json"># 导出日志索引模板
curl -X PUT &quot;${host}/_template/export_log_index_template&quot; -H 'Content-Type: application/json' -d'
{
  &quot;index_patterns&quot;: [
    &quot;export_log_index*&quot;
  ],
  &quot;settings&quot;: {
    &quot;number_of_shards&quot;: 1,
    &quot;number_of_replicas&quot;: 1,
    &quot;index.lifecycle.name&quot;: &quot;audit_policy&quot;,
    &quot;index.lifecycle.rollover_alias&quot;: &quot;export_log_index&quot;,
    &quot;index.max_result_window&quot;: &quot;100000&quot;
  },
  &quot;mappings&quot;: {
    &quot;properties&quot;: {
      &quot;applicationSide&quot;: {
        &quot;type&quot;: &quot;integer&quot;
      },
      &quot;exportComment&quot;: {
        &quot;type&quot;: &quot;keyword&quot;
      },
      &quot;exportFileSize&quot;: {
        &quot;type&quot;: &quot;integer&quot;
      },
      &quot;exportType&quot;: {
        &quot;type&quot;: &quot;integer&quot;
      },
      &quot;id&quot;: {
        &quot;type&quot;: &quot;keyword&quot;
      },
      &quot;operationTime&quot;: {
        &quot;type&quot;: &quot;date&quot;,
        &quot;store&quot;: true,
        &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss&quot;
      },
      &quot;operationUser&quot;: {
        &quot;type&quot;: &quot;keyword&quot;
      },
      &quot;operationUserName&quot;: {
        &quot;type&quot;: &quot;text&quot;,
        &quot;analyzer&quot;: &quot;ik_max_word&quot;,
        &quot;fields&quot;: {
          &quot;keyword&quot;: {
            &quot;type&quot;: &quot;keyword&quot;
          }
        }
      },
      &quot;remarks&quot;: {
        &quot;type&quot;: &quot;keyword&quot;
      },
      &quot;successful&quot;: {
        &quot;type&quot;: &quot;boolean&quot;
      }
    }
  }
}
</code></pre>
<h4 id="创建索引">创建索引</h4>
<pre><code class="language-json"># 创建导出日志索引，按日期命名
curl -X PUT &quot;${host}/%3Cexport_log_index-%7Bnow%2Fd%7D-1%3E&quot; -H 'Content-Type: application/json' -d'
{
  &quot;aliases&quot;: {
    &quot;export_log_index&quot;: {
      &quot;is_write_index&quot;: true
    }
  }
}
</code></pre>
<h2 id="docker-安装-kibana">docker 安装 kibana</h2>
<h3 id="拉取镜像-2">拉取镜像</h3>
<p>拉取镜像的时候，需要注意的是, <strong>kibana 的版本最好与 elasticsearch 保持一致</strong>, 避免发生不必要的错误</p>
<pre><code class="language-java">docker pull kibana:7.12.0
</code></pre>
<h3 id="查看镜像-2">查看镜像</h3>
<pre><code class="language-java">docker images
</code></pre>
<h3 id="docker-启动-kibana">docker 启动 kibana</h3>
<pre><code class="language-java"># -e : 指定环境变量配置, 提供汉化
# --like : 建立两个容器之间的关联, kibana 关联到 es
docker run -di --name kibana --link elasticsearch:elasticsearch -e &quot;I18N_LOCALE=zh-CN&quot; -p 5601:5601 kibana:7.12.0
# kibana 的汉化我感觉做的并不好
# 如果不习惯汉化, 可以把条件去除
docker run -di --name kibana --link elasticsearch:elasticsearch -p 5601:5601 kibana:7.12.0
</code></pre>
<h2 id="docker-安装-logstash">Docker 安装 Logstash</h2>
<h3 id="拉取镜像-3">拉取镜像</h3>
<p>拉取镜像的时候，需要注意的是, <strong>Logstash 的版本最好与 elasticsearch 保持一致</strong>, 避免发生不必要的错误</p>
<pre><code class="language-java">docker pull logstash:7.12.0
</code></pre>
<h3 id="查看镜像-3">查看镜像</h3>
<pre><code class="language-java">docker images
</code></pre>
<h3 id="文件映射">文件映射</h3>
<p>在本机建立配置文件和目录,用来存放所有配置的映射</p>
<pre><code class="language-java">/usr/local/logstash/config/logstash.yml
/usr/local/logstash/conf.d/
</code></pre>
<p>logstash.yml (文件内容)</p>
<pre><code class="language-java">path.config: /usr/share/logstash/conf.d/*.conf
path.logs: /var/log/logstash
</code></pre>
<p>conf.d/configuration.conf (文件内容)</p>
<p><strong>Filebeat和elasticsearch的交互</strong></p>
<pre><code class="language-json">input {
    beats {
    port =&gt; 5044
    codec =&gt; &quot;json&quot;
}
}

output {
  elasticsearch { 
    hosts =&gt; [&quot;elasticsearch:9200&quot;]，
	index =&gt; &quot;export_log_index&quot;
  }
  stdout { codec =&gt; rubydebug }
}
</code></pre>
<p><strong>mysql和elasticsearch的交互</strong></p>
<pre><code class="language-json">input {
  jdbc {
    jdbc_driver_class =&gt; &quot;com.mysql.jdbc.Driver&quot;
    jdbc_connection_string =&gt; &quot;jdbc:mysql://localhost:3306/db_example&quot;
    jdbc_user =&gt; root
    jdbc_password =&gt; ymruan123
    #启用追踪，如果为true，则需要指定tracking_column
    use_column_value =&gt; true
    #指定追踪的字段，
    tracking_column =&gt; &quot;last_updated&quot;
    #追踪字段的类型，目前只有数字(numeric)和时间类型(timestamp)，默认是数字类型
    tracking_column_type =&gt; &quot;numeric&quot;
    #记录最后一次运行的结果
    record_last_run =&gt; true
    #上面运行结果的保存位置
    last_run_metadata_path =&gt; &quot;jdbc-position.txt&quot;
    statement =&gt; &quot;SELECT * FROM user where last_updated &gt;:sql_last_value;&quot;
    schedule =&gt; &quot; * * * * * *&quot;
  }
}
output {
  elasticsearch {
    document_id =&gt; &quot;%{id}&quot;
    document_type =&gt; &quot;_doc&quot;
    index =&gt; &quot;export_log_index&quot;
    hosts =&gt; [&quot;http://localhost:9200&quot;]
  }
  stdout{
    codec =&gt; rubydebug
  }
}
</code></pre>
<p><strong>kafka和elasticsearch的交互</strong></p>
<pre><code class="language-json">input {
 kafka{
    topics =&gt; &quot;topic_export&quot;    #kafka中topic名称，记得创建该topic
    group_id =&gt; &quot;group_export&quot;     #默认为“logstash”
    codec =&gt; &quot;json&quot;    #与Shipper端output配置项一致
    consumer_threads =&gt; 1    #消费线程数，集群中所有logstash相加最好等于 topic 分区数
    bootstrap_servers =&gt; &quot;kafka:9092&quot;
    decorate_events =&gt; true    #在输出消息的时候回输出自身的信息，包括：消费消息的大小、topic来源以及consumer的group信息。
    type =&gt; &quot;topic_export&quot;  
    tags =&gt; [&quot;canal&quot;] # 标签，额外使用该参数可以在elastci中创建不同索引
  }
  
}
 
 
filter {
  # 把默认的data字段重命名为message字段，方便在elastic中显示
  mutate {
    rename =&gt; [&quot;data&quot;, &quot;message&quot;]
  }
  # 还可以使用其他的处理方式，在此就不再列出来了
}
 
output {
  elasticsearch {
    hosts =&gt; [&quot;http://172.17.107.187:9203&quot;, &quot;http://172.17.107.187:9201&quot;,&quot;http://172.17.107.187:9202&quot;]
    index =&gt; &quot;export_log_index&quot; # decorate_events=true的作用，可以使用metadata中的数据
    #user =&gt; &quot;elastic&quot;
    #password =&gt; &quot;escluter123456&quot;
  }
 }
</code></pre>
<p><strong>logback和和elasticsearch的交互</strong></p>
<p>引入依赖</p>
<pre><code class="language-xml">&lt;dependency&gt;
      &lt;groupId&gt;net.logstash.logback&lt;/groupId&gt;
      &lt;artifactId&gt;logstash-logback-encoder&lt;/artifactId&gt;
     &lt;version&gt;4.10&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<p>参数配置</p>
<pre><code class="language-json">input {
  # 应用日志
  tcp{
    type =&gt; &quot;app&quot;
    mode =&gt; &quot;server&quot;
    host =&gt; &quot;0.0.0.0&quot;
    port =&gt; 4560
    codec =&gt; json
  }
}

output {
   elasticsearch {
      hosts =&gt; &quot;http://127.0.0.1:9200&quot;
      index =&gt; &quot;export_log_index&quot;
    }
}

</code></pre>
<p>应用日志入口端口为4560，需要配置java客户端logstash入口</p>
<pre><code class="language-xml">&lt;!-- 这个是控制台日志输出格式 方便调试对比--&gt;
&lt;appender name=&quot;console&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;
    &lt;encoder&gt;
        &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss} %contextName %-5level %logger{50} -%msg%n&lt;/pattern&gt;
    &lt;/encoder&gt;
&lt;/appender&gt;
&lt;!--开启tcp格式的logstash传输，通过TCP协议连接Logstash--&gt;
&lt;appender name=&quot;STASH&quot; class=&quot;net.logstash.logback.appender.LogstashTcpSocketAppender&quot;&gt;
    &lt;destination&gt;127.0.0.1:9600&lt;/destination&gt;

    &lt;encoder class=&quot;net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder&quot;&gt;
        &lt;!--中文序列化--&gt;
        &lt;jsonFactoryDecorator class=&quot;net.logstash.logback.decorate.CharacterEscapesJsonFactoryDecorator&quot;&gt;
            &lt;escape&gt;
                &lt;targetCharacterCode&gt;10&lt;/targetCharacterCode&gt;
                &lt;escapeSequence&gt;\u2028&lt;/escapeSequence&gt;
            &lt;/escape&gt;
        &lt;/jsonFactoryDecorator&gt;
        &lt;providers&gt;
            &lt;pattern&gt;
                &lt;pattern&gt;
                    &lt;!--{
                    &quot;timestamp&quot;:&quot;%date{ISO8601}&quot;,
                    &quot;user&quot;:&quot;test&quot;,
                    &quot;message&quot;:&quot;[%d{yyyy-MM-dd HH:mm:ss.SSS}][%p][%t][%l{80}|%L]%m&quot;}%n
                    }--&gt;
                    {
                    &quot;timestamp&quot;: &quot;%date{\&quot;yyyy-MM-dd' 'HH:mm:ss,SSSZ\&quot;}&quot;,
                    &quot;level&quot;: &quot;%level&quot;,
                    &quot;thread&quot;: &quot;%thread&quot;,
                    &quot;class_name&quot;: &quot;%class&quot;,
                    &quot;line_number&quot;: &quot;%line&quot;,
                    &quot;message&quot;: &quot;%message&quot;,
                    &quot;stack_trace&quot;: &quot;%exception{5}&quot;,
                    &quot;req_id&quot;: &quot;%X{reqId}&quot;,
                    &quot;elapsed_time&quot;: &quot;#asLong{%X{elapsedTime}}&quot;
                    }
                &lt;/pattern&gt;
            &lt;/pattern&gt;
        &lt;/providers&gt;
        &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt;


    &lt;/encoder&gt;
    &lt;keepAliveDuration&gt;5 minutes&lt;/keepAliveDuration&gt;
&lt;/appender&gt;

&lt;root level=&quot;INFO&quot;&gt;
    &lt;appender-ref ref=&quot;STASH&quot;/&gt;
    &lt;appender-ref ref=&quot;console&quot;/&gt;
&lt;/root&gt;
</code></pre>
<h3 id="docker-启动-logstash">docker 启动 Logstash</h3>
<pre><code class="language-java">#docker容器互访 运行容器的时候加上参数link
docker run -id -p 5044:5044 --name logstash --link elasticsearch --link beats -v /usr/local/logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml -v /usr/local/logstash/conf.d/:/usr/share/logstash/conf.d/ logstash:7.4.1
</code></pre>
<h2 id="docker-安装-filebeat">Docker 安装 Filebeat</h2>
<h3 id="拉取镜像-4">拉取镜像</h3>
<p>拉取镜像的时候，需要注意的是, <strong>Filebeat 的版本最好与 elasticsearch 保持一致</strong>, 避免发生不必要的错误</p>
<pre><code class="language-java">docker pull store/elastic/filebeat:7.12.0
</code></pre>
<h3 id="查看镜像-4">查看镜像</h3>
<pre><code class="language-java">docker images
</code></pre>
<h3 id="文件映射-2">文件映射</h3>
<p><strong>下载默认官方配置文件</strong></p>
<pre><code class="language-http">wget https://raw.githubusercontent.com/elastic/beats/7.12/deploy/docker/filebeat.docker.yml
</code></pre>
<p>注意：文件放在宿主机/data/elk/filebeat目录下</p>
<p><strong>打开配置文件</strong><br>
<code>vim filebeat.docker.yml</code>，内容如下：</p>
<pre><code class="language-xml"># 日志输入配置
filebeat.inputs:
- type: log
  enabled: true
  paths:
  # 需要收集的日志所在的位置，可使用通配符进行配置
  #- /data/elk/*.log
  - /logs/*/*.log

#日志输出配置(采用 logstash 收集日志，5044为logstash端口)
output.logstash:
  hosts: ['192.168.12.183:5044']
</code></pre>
<h3 id="docker运行filebeat">docker运行Filebeat</h3>
<pre><code class="language-java">docker run --name filebeat --user=root -d --net somenetwork --volume=&quot;/usr/local/filebeat/log/nginx/:/var/log/nginx/&quot; --volume=&quot;/data/elk/filebeat/filebeat.docker.yml:/usr/share/filebeat/filebeat.yml&quot; --volume=&quot;/var/lib/docker/containers:/var/lib/docker/containers:ro&quot; --volume=&quot;/var/run/docker.sock:/var/run/docker.sock:ro&quot; store/elastic/filebeat:7.12.0
</code></pre>
]]></content>
    </entry>
</feed>